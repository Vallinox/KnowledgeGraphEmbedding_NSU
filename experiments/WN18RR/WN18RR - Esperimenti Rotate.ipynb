{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con Self Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-03 00:14:07,857 INFO     Model: RotatE\n",
      "2023-12-03 00:14:07,859 INFO     Data Path: data/wn18rr\n",
      "2023-12-03 00:14:07,859 INFO     #entity: 40943\n",
      "2023-12-03 00:14:07,859 INFO     #relation: 11\n",
      "2023-12-03 00:14:08,004 INFO     #train: 86835\n",
      "2023-12-03 00:14:08,009 INFO     #valid: 3034\n",
      "2023-12-03 00:14:08,013 INFO     #test: 3134\n",
      "2023-12-03 00:14:08,304 INFO     Model Parameter Configuration:\n",
      "2023-12-03 00:14:08,305 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-03 00:14:08,305 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-03 00:14:08,305 INFO     Parameter entity_embedding: torch.Size([40943, 1000]), require_grad = True\n",
      "2023-12-03 00:14:08,305 INFO     Parameter relation_embedding: torch.Size([11, 500]), require_grad = True\n",
      "2023-12-03 00:14:09,969 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-03 00:14:09,970 INFO     Start Training...\n",
      "2023-12-03 00:14:09,970 INFO     init_step = 0\n",
      "2023-12-03 00:14:09,970 INFO     batch_size = 512\n",
      "2023-12-03 00:14:09,970 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-03 00:14:09,970 INFO     hidden_dim = 500\n",
      "2023-12-03 00:14:09,970 INFO     gamma = 6.000000\n",
      "2023-12-03 00:14:09,970 INFO     negative_adversarial_sampling = True\n",
      "2023-12-03 00:14:09,970 INFO     adversarial_temperature = 0.500000\n",
      "2023-12-03 00:14:09,970 INFO     learning_rate = 0\n",
      "2023-12-03 00:14:20,074 INFO     Training average positive_sample_loss at step 0: 2.446145\n",
      "2023-12-03 00:14:20,074 INFO     Training average negative_sample_loss at step 0: 0.093440\n",
      "2023-12-03 00:14:20,074 INFO     Training average loss at step 0: 1.269792\n",
      "2023-12-03 00:14:20,074 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:14:20,976 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:14:52,577 INFO     Valid MRR at step 0: 0.000201\n",
      "2023-12-03 00:14:52,577 INFO     Valid MR at step 0: 20342.272742\n",
      "2023-12-03 00:14:52,577 INFO     Valid HITS@1 at step 0: 0.000000\n",
      "2023-12-03 00:14:52,577 INFO     Valid HITS@3 at step 0: 0.000000\n",
      "2023-12-03 00:14:52,577 INFO     Valid HITS@10 at step 0: 0.000000\n",
      "2023-12-03 00:14:58,317 INFO     Training average positive_sample_loss at step 100: 2.919692\n",
      "2023-12-03 00:14:58,318 INFO     Training average negative_sample_loss at step 100: 0.059145\n",
      "2023-12-03 00:14:58,318 INFO     Training average loss at step 100: 1.489418\n",
      "2023-12-03 00:15:04,391 INFO     Training average positive_sample_loss at step 200: 2.777005\n",
      "2023-12-03 00:15:04,391 INFO     Training average negative_sample_loss at step 200: 0.073714\n",
      "2023-12-03 00:15:04,391 INFO     Training average loss at step 200: 1.425359\n",
      "2023-12-03 00:15:10,447 INFO     Training average positive_sample_loss at step 300: 2.384369\n",
      "2023-12-03 00:15:10,447 INFO     Training average negative_sample_loss at step 300: 0.107056\n",
      "2023-12-03 00:15:10,447 INFO     Training average loss at step 300: 1.245713\n",
      "2023-12-03 00:15:17,122 INFO     Training average positive_sample_loss at step 400: 1.833029\n",
      "2023-12-03 00:15:17,122 INFO     Training average negative_sample_loss at step 400: 0.152266\n",
      "2023-12-03 00:15:17,122 INFO     Training average loss at step 400: 0.992648\n",
      "2023-12-03 00:15:23,221 INFO     Training average positive_sample_loss at step 500: 1.479332\n",
      "2023-12-03 00:15:23,221 INFO     Training average negative_sample_loss at step 500: 0.197456\n",
      "2023-12-03 00:15:23,221 INFO     Training average loss at step 500: 0.838394\n",
      "2023-12-03 00:15:28,644 INFO     Training average positive_sample_loss at step 600: 1.276890\n",
      "2023-12-03 00:15:28,645 INFO     Training average negative_sample_loss at step 600: 0.239895\n",
      "2023-12-03 00:15:28,645 INFO     Training average loss at step 600: 0.758393\n",
      "2023-12-03 00:15:35,277 INFO     Training average positive_sample_loss at step 700: 1.083148\n",
      "2023-12-03 00:15:35,277 INFO     Training average negative_sample_loss at step 700: 0.278458\n",
      "2023-12-03 00:15:35,277 INFO     Training average loss at step 700: 0.680803\n",
      "2023-12-03 00:15:41,392 INFO     Training average positive_sample_loss at step 800: 0.848548\n",
      "2023-12-03 00:15:41,393 INFO     Training average negative_sample_loss at step 800: 0.309856\n",
      "2023-12-03 00:15:41,393 INFO     Training average loss at step 800: 0.579202\n",
      "2023-12-03 00:15:47,521 INFO     Training average positive_sample_loss at step 900: 0.777844\n",
      "2023-12-03 00:15:47,522 INFO     Training average negative_sample_loss at step 900: 0.327174\n",
      "2023-12-03 00:15:47,522 INFO     Training average loss at step 900: 0.552509\n",
      "2023-12-03 00:15:53,639 INFO     Training average positive_sample_loss at step 1000: 0.715253\n",
      "2023-12-03 00:15:53,639 INFO     Training average negative_sample_loss at step 1000: 0.340711\n",
      "2023-12-03 00:15:53,639 INFO     Training average loss at step 1000: 0.527982\n",
      "2023-12-03 00:15:59,753 INFO     Training average positive_sample_loss at step 1100: 0.585534\n",
      "2023-12-03 00:15:59,754 INFO     Training average negative_sample_loss at step 1100: 0.349727\n",
      "2023-12-03 00:15:59,754 INFO     Training average loss at step 1100: 0.467631\n",
      "2023-12-03 00:16:05,662 INFO     Training average positive_sample_loss at step 1200: 0.545800\n",
      "2023-12-03 00:16:05,663 INFO     Training average negative_sample_loss at step 1200: 0.347904\n",
      "2023-12-03 00:16:05,663 INFO     Training average loss at step 1200: 0.446852\n",
      "2023-12-03 00:16:11,832 INFO     Training average positive_sample_loss at step 1300: 0.526767\n",
      "2023-12-03 00:16:11,832 INFO     Training average negative_sample_loss at step 1300: 0.344458\n",
      "2023-12-03 00:16:11,832 INFO     Training average loss at step 1300: 0.435612\n",
      "2023-12-03 00:16:18,318 INFO     Training average positive_sample_loss at step 1400: 0.476315\n",
      "2023-12-03 00:16:18,318 INFO     Training average negative_sample_loss at step 1400: 0.339449\n",
      "2023-12-03 00:16:18,318 INFO     Training average loss at step 1400: 0.407882\n",
      "2023-12-03 00:16:24,451 INFO     Training average positive_sample_loss at step 1500: 0.429733\n",
      "2023-12-03 00:16:24,451 INFO     Training average negative_sample_loss at step 1500: 0.330395\n",
      "2023-12-03 00:16:24,451 INFO     Training average loss at step 1500: 0.380064\n",
      "2023-12-03 00:16:29,874 INFO     Training average positive_sample_loss at step 1600: 0.426160\n",
      "2023-12-03 00:16:29,874 INFO     Training average negative_sample_loss at step 1600: 0.321017\n",
      "2023-12-03 00:16:29,874 INFO     Training average loss at step 1600: 0.373589\n",
      "2023-12-03 00:16:36,200 INFO     Training average positive_sample_loss at step 1700: 0.419130\n",
      "2023-12-03 00:16:36,201 INFO     Training average negative_sample_loss at step 1700: 0.310154\n",
      "2023-12-03 00:16:36,201 INFO     Training average loss at step 1700: 0.364642\n",
      "2023-12-03 00:16:42,607 INFO     Training average positive_sample_loss at step 1800: 0.361405\n",
      "2023-12-03 00:16:42,607 INFO     Training average negative_sample_loss at step 1800: 0.299916\n",
      "2023-12-03 00:16:42,607 INFO     Training average loss at step 1800: 0.330661\n",
      "2023-12-03 00:16:48,746 INFO     Training average positive_sample_loss at step 1900: 0.365561\n",
      "2023-12-03 00:16:48,747 INFO     Training average negative_sample_loss at step 1900: 0.286042\n",
      "2023-12-03 00:16:48,747 INFO     Training average loss at step 1900: 0.325802\n",
      "2023-12-03 00:16:54,823 INFO     Training average positive_sample_loss at step 2000: 0.364363\n",
      "2023-12-03 00:16:54,824 INFO     Training average negative_sample_loss at step 2000: 0.277291\n",
      "2023-12-03 00:16:54,824 INFO     Training average loss at step 2000: 0.320827\n",
      "2023-12-03 00:17:01,178 INFO     Training average positive_sample_loss at step 2100: 0.333703\n",
      "2023-12-03 00:17:01,178 INFO     Training average negative_sample_loss at step 2100: 0.266729\n",
      "2023-12-03 00:17:01,178 INFO     Training average loss at step 2100: 0.300216\n",
      "2023-12-03 00:17:06,768 INFO     Training average positive_sample_loss at step 2200: 0.322165\n",
      "2023-12-03 00:17:06,768 INFO     Training average negative_sample_loss at step 2200: 0.254831\n",
      "2023-12-03 00:17:06,769 INFO     Training average loss at step 2200: 0.288498\n",
      "2023-12-03 00:17:12,858 INFO     Training average positive_sample_loss at step 2300: 0.323616\n",
      "2023-12-03 00:17:12,858 INFO     Training average negative_sample_loss at step 2300: 0.245562\n",
      "2023-12-03 00:17:12,858 INFO     Training average loss at step 2300: 0.284589\n",
      "2023-12-03 00:17:19,409 INFO     Training average positive_sample_loss at step 2400: 0.314742\n",
      "2023-12-03 00:17:19,409 INFO     Training average negative_sample_loss at step 2400: 0.236566\n",
      "2023-12-03 00:17:19,409 INFO     Training average loss at step 2400: 0.275654\n",
      "2023-12-03 00:17:25,480 INFO     Training average positive_sample_loss at step 2500: 0.287011\n",
      "2023-12-03 00:17:25,480 INFO     Training average negative_sample_loss at step 2500: 0.226820\n",
      "2023-12-03 00:17:25,480 INFO     Training average loss at step 2500: 0.256915\n",
      "2023-12-03 00:17:31,537 INFO     Training average positive_sample_loss at step 2600: 0.291595\n",
      "2023-12-03 00:17:31,538 INFO     Training average negative_sample_loss at step 2600: 0.216844\n",
      "2023-12-03 00:17:31,538 INFO     Training average loss at step 2600: 0.254220\n",
      "2023-12-03 00:17:36,981 INFO     Training average positive_sample_loss at step 2700: 0.292821\n",
      "2023-12-03 00:17:36,981 INFO     Training average negative_sample_loss at step 2700: 0.209586\n",
      "2023-12-03 00:17:36,981 INFO     Training average loss at step 2700: 0.251204\n",
      "2023-12-03 00:17:43,376 INFO     Training average positive_sample_loss at step 2800: 0.262950\n",
      "2023-12-03 00:17:43,376 INFO     Training average negative_sample_loss at step 2800: 0.201372\n",
      "2023-12-03 00:17:43,376 INFO     Training average loss at step 2800: 0.232161\n",
      "2023-12-03 00:17:49,459 INFO     Training average positive_sample_loss at step 2900: 0.265003\n",
      "2023-12-03 00:17:49,459 INFO     Training average negative_sample_loss at step 2900: 0.193468\n",
      "2023-12-03 00:17:49,459 INFO     Training average loss at step 2900: 0.229235\n",
      "2023-12-03 00:17:55,539 INFO     Training average positive_sample_loss at step 3000: 0.267213\n",
      "2023-12-03 00:17:55,539 INFO     Training average negative_sample_loss at step 3000: 0.186629\n",
      "2023-12-03 00:17:55,539 INFO     Training average loss at step 3000: 0.226921\n",
      "2023-12-03 00:18:02,148 INFO     Training average positive_sample_loss at step 3100: 0.253685\n",
      "2023-12-03 00:18:02,148 INFO     Training average negative_sample_loss at step 3100: 0.180611\n",
      "2023-12-03 00:18:02,148 INFO     Training average loss at step 3100: 0.217148\n",
      "2023-12-03 00:18:07,615 INFO     Training average positive_sample_loss at step 3200: 0.239737\n",
      "2023-12-03 00:18:07,615 INFO     Training average negative_sample_loss at step 3200: 0.173058\n",
      "2023-12-03 00:18:07,615 INFO     Training average loss at step 3200: 0.206398\n",
      "2023-12-03 00:18:13,633 INFO     Training average positive_sample_loss at step 3300: 0.243801\n",
      "2023-12-03 00:18:13,633 INFO     Training average negative_sample_loss at step 3300: 0.166890\n",
      "2023-12-03 00:18:13,633 INFO     Training average loss at step 3300: 0.205345\n",
      "2023-12-03 00:18:19,943 INFO     Training average positive_sample_loss at step 3400: 0.245315\n",
      "2023-12-03 00:18:19,943 INFO     Training average negative_sample_loss at step 3400: 0.162338\n",
      "2023-12-03 00:18:19,943 INFO     Training average loss at step 3400: 0.203827\n",
      "2023-12-03 00:18:26,274 INFO     Training average positive_sample_loss at step 3500: 0.218051\n",
      "2023-12-03 00:18:26,274 INFO     Training average negative_sample_loss at step 3500: 0.156037\n",
      "2023-12-03 00:18:26,275 INFO     Training average loss at step 3500: 0.187044\n",
      "2023-12-03 00:18:32,335 INFO     Training average positive_sample_loss at step 3600: 0.224211\n",
      "2023-12-03 00:18:32,336 INFO     Training average negative_sample_loss at step 3600: 0.150449\n",
      "2023-12-03 00:18:32,336 INFO     Training average loss at step 3600: 0.187330\n",
      "2023-12-03 00:18:38,054 INFO     Training average positive_sample_loss at step 3700: 0.227313\n",
      "2023-12-03 00:18:38,054 INFO     Training average negative_sample_loss at step 3700: 0.145869\n",
      "2023-12-03 00:18:38,054 INFO     Training average loss at step 3700: 0.186591\n",
      "2023-12-03 00:18:44,330 INFO     Training average positive_sample_loss at step 3800: 0.210079\n",
      "2023-12-03 00:18:44,330 INFO     Training average negative_sample_loss at step 3800: 0.141506\n",
      "2023-12-03 00:18:44,330 INFO     Training average loss at step 3800: 0.175792\n",
      "2023-12-03 00:18:50,503 INFO     Training average positive_sample_loss at step 3900: 0.205558\n",
      "2023-12-03 00:18:50,503 INFO     Training average negative_sample_loss at step 3900: 0.136017\n",
      "2023-12-03 00:18:50,503 INFO     Training average loss at step 3900: 0.170788\n",
      "2023-12-03 00:18:56,592 INFO     Training average positive_sample_loss at step 4000: 0.209913\n",
      "2023-12-03 00:18:56,593 INFO     Training average negative_sample_loss at step 4000: 0.132249\n",
      "2023-12-03 00:18:56,593 INFO     Training average loss at step 4000: 0.171081\n",
      "2023-12-03 00:19:03,145 INFO     Training average positive_sample_loss at step 4100: 0.205979\n",
      "2023-12-03 00:19:03,145 INFO     Training average negative_sample_loss at step 4100: 0.128429\n",
      "2023-12-03 00:19:03,145 INFO     Training average loss at step 4100: 0.167204\n",
      "2023-12-03 00:19:09,236 INFO     Training average positive_sample_loss at step 4200: 0.188688\n",
      "2023-12-03 00:19:09,237 INFO     Training average negative_sample_loss at step 4200: 0.124046\n",
      "2023-12-03 00:19:09,237 INFO     Training average loss at step 4200: 0.156367\n",
      "2023-12-03 00:19:15,336 INFO     Training average positive_sample_loss at step 4300: 0.194720\n",
      "2023-12-03 00:19:15,336 INFO     Training average negative_sample_loss at step 4300: 0.120184\n",
      "2023-12-03 00:19:15,336 INFO     Training average loss at step 4300: 0.157452\n",
      "2023-12-03 00:19:20,865 INFO     Training average positive_sample_loss at step 4400: 0.196972\n",
      "2023-12-03 00:19:20,866 INFO     Training average negative_sample_loss at step 4400: 0.117469\n",
      "2023-12-03 00:19:20,866 INFO     Training average loss at step 4400: 0.157221\n",
      "2023-12-03 00:19:27,578 INFO     Training average positive_sample_loss at step 4500: 0.178504\n",
      "2023-12-03 00:19:27,578 INFO     Training average negative_sample_loss at step 4500: 0.113873\n",
      "2023-12-03 00:19:27,578 INFO     Training average loss at step 4500: 0.146188\n",
      "2023-12-03 00:19:33,815 INFO     Training average positive_sample_loss at step 4600: 0.180825\n",
      "2023-12-03 00:19:33,815 INFO     Training average negative_sample_loss at step 4600: 0.110263\n",
      "2023-12-03 00:19:33,815 INFO     Training average loss at step 4600: 0.145544\n",
      "2023-12-03 00:19:40,138 INFO     Training average positive_sample_loss at step 4700: 0.183027\n",
      "2023-12-03 00:19:40,139 INFO     Training average negative_sample_loss at step 4700: 0.107063\n",
      "2023-12-03 00:19:40,139 INFO     Training average loss at step 4700: 0.145045\n",
      "2023-12-03 00:19:46,674 INFO     Training average positive_sample_loss at step 4800: 0.175783\n",
      "2023-12-03 00:19:46,675 INFO     Training average negative_sample_loss at step 4800: 0.105018\n",
      "2023-12-03 00:19:46,675 INFO     Training average loss at step 4800: 0.140401\n",
      "2023-12-03 00:19:52,796 INFO     Training average positive_sample_loss at step 4900: 0.167057\n",
      "2023-12-03 00:19:52,796 INFO     Training average negative_sample_loss at step 4900: 0.101387\n",
      "2023-12-03 00:19:52,796 INFO     Training average loss at step 4900: 0.134222\n",
      "2023-12-03 00:19:58,283 INFO     Training average positive_sample_loss at step 5000: 0.171969\n",
      "2023-12-03 00:19:58,283 INFO     Training average negative_sample_loss at step 5000: 0.098565\n",
      "2023-12-03 00:19:58,283 INFO     Training average loss at step 5000: 0.135267\n",
      "2023-12-03 00:20:04,680 INFO     Training average positive_sample_loss at step 5100: 0.172465\n",
      "2023-12-03 00:20:04,681 INFO     Training average negative_sample_loss at step 5100: 0.096374\n",
      "2023-12-03 00:20:04,681 INFO     Training average loss at step 5100: 0.134419\n",
      "2023-12-03 00:20:11,084 INFO     Training average positive_sample_loss at step 5200: 0.154740\n",
      "2023-12-03 00:20:11,084 INFO     Training average negative_sample_loss at step 5200: 0.093839\n",
      "2023-12-03 00:20:11,084 INFO     Training average loss at step 5200: 0.124289\n",
      "2023-12-03 00:20:17,204 INFO     Training average positive_sample_loss at step 5300: 0.159472\n",
      "2023-12-03 00:20:17,204 INFO     Training average negative_sample_loss at step 5300: 0.090834\n",
      "2023-12-03 00:20:17,204 INFO     Training average loss at step 5300: 0.125153\n",
      "2023-12-03 00:20:23,337 INFO     Training average positive_sample_loss at step 5400: 0.164038\n",
      "2023-12-03 00:20:23,337 INFO     Training average negative_sample_loss at step 5400: 0.088972\n",
      "2023-12-03 00:20:23,337 INFO     Training average loss at step 5400: 0.126505\n",
      "2023-12-03 00:20:30,108 INFO     Training average positive_sample_loss at step 5500: 0.151648\n",
      "2023-12-03 00:20:30,109 INFO     Training average negative_sample_loss at step 5500: 0.087138\n",
      "2023-12-03 00:20:30,109 INFO     Training average loss at step 5500: 0.119393\n",
      "2023-12-03 00:20:35,549 INFO     Training average positive_sample_loss at step 5600: 0.149445\n",
      "2023-12-03 00:20:35,549 INFO     Training average negative_sample_loss at step 5600: 0.084329\n",
      "2023-12-03 00:20:35,549 INFO     Training average loss at step 5600: 0.116887\n",
      "2023-12-03 00:20:41,695 INFO     Training average positive_sample_loss at step 5700: 0.154139\n",
      "2023-12-03 00:20:41,695 INFO     Training average negative_sample_loss at step 5700: 0.082738\n",
      "2023-12-03 00:20:41,695 INFO     Training average loss at step 5700: 0.118439\n",
      "2023-12-03 00:20:48,340 INFO     Training average positive_sample_loss at step 5800: 0.150019\n",
      "2023-12-03 00:20:48,341 INFO     Training average negative_sample_loss at step 5800: 0.080803\n",
      "2023-12-03 00:20:48,341 INFO     Training average loss at step 5800: 0.115411\n",
      "2023-12-03 00:20:54,475 INFO     Training average positive_sample_loss at step 5900: 0.139692\n",
      "2023-12-03 00:20:54,476 INFO     Training average negative_sample_loss at step 5900: 0.078705\n",
      "2023-12-03 00:20:54,476 INFO     Training average loss at step 5900: 0.109198\n",
      "2023-12-03 00:21:00,662 INFO     Training average positive_sample_loss at step 6000: 0.144858\n",
      "2023-12-03 00:21:00,662 INFO     Training average negative_sample_loss at step 6000: 0.076874\n",
      "2023-12-03 00:21:00,662 INFO     Training average loss at step 6000: 0.110866\n",
      "2023-12-03 00:21:06,900 INFO     Training average positive_sample_loss at step 6100: 0.146420\n",
      "2023-12-03 00:21:06,901 INFO     Training average negative_sample_loss at step 6100: 0.075386\n",
      "2023-12-03 00:21:06,901 INFO     Training average loss at step 6100: 0.110903\n",
      "2023-12-03 00:21:12,889 INFO     Training average positive_sample_loss at step 6200: 0.133436\n",
      "2023-12-03 00:21:12,890 INFO     Training average negative_sample_loss at step 6200: 0.073623\n",
      "2023-12-03 00:21:12,890 INFO     Training average loss at step 6200: 0.103529\n",
      "2023-12-03 00:21:19,005 INFO     Training average positive_sample_loss at step 6300: 0.135527\n",
      "2023-12-03 00:21:19,005 INFO     Training average negative_sample_loss at step 6300: 0.071635\n",
      "2023-12-03 00:21:19,005 INFO     Training average loss at step 6300: 0.103581\n",
      "2023-12-03 00:21:25,121 INFO     Training average positive_sample_loss at step 6400: 0.139277\n",
      "2023-12-03 00:21:25,121 INFO     Training average negative_sample_loss at step 6400: 0.070377\n",
      "2023-12-03 00:21:25,121 INFO     Training average loss at step 6400: 0.104827\n",
      "2023-12-03 00:21:31,464 INFO     Training average positive_sample_loss at step 6500: 0.133186\n",
      "2023-12-03 00:21:31,464 INFO     Training average negative_sample_loss at step 6500: 0.069334\n",
      "2023-12-03 00:21:31,464 INFO     Training average loss at step 6500: 0.101260\n",
      "2023-12-03 00:21:37,565 INFO     Training average positive_sample_loss at step 6600: 0.128052\n",
      "2023-12-03 00:21:37,566 INFO     Training average negative_sample_loss at step 6600: 0.067317\n",
      "2023-12-03 00:21:37,566 INFO     Training average loss at step 6600: 0.097684\n",
      "2023-12-03 00:21:43,216 INFO     Training average positive_sample_loss at step 6700: 0.131180\n",
      "2023-12-03 00:21:43,216 INFO     Training average negative_sample_loss at step 6700: 0.065849\n",
      "2023-12-03 00:21:43,217 INFO     Training average loss at step 6700: 0.098514\n",
      "2023-12-03 00:21:49,454 INFO     Training average positive_sample_loss at step 6800: 0.132581\n",
      "2023-12-03 00:21:49,455 INFO     Training average negative_sample_loss at step 6800: 0.064914\n",
      "2023-12-03 00:21:49,455 INFO     Training average loss at step 6800: 0.098747\n",
      "2023-12-03 00:21:55,831 INFO     Training average positive_sample_loss at step 6900: 0.119651\n",
      "2023-12-03 00:21:55,831 INFO     Training average negative_sample_loss at step 6900: 0.063462\n",
      "2023-12-03 00:21:55,831 INFO     Training average loss at step 6900: 0.091556\n",
      "2023-12-03 00:22:01,941 INFO     Training average positive_sample_loss at step 7000: 0.124055\n",
      "2023-12-03 00:22:01,941 INFO     Training average negative_sample_loss at step 7000: 0.061887\n",
      "2023-12-03 00:22:01,942 INFO     Training average loss at step 7000: 0.092971\n",
      "2023-12-03 00:22:07,568 INFO     Training average positive_sample_loss at step 7100: 0.126639\n",
      "2023-12-03 00:22:07,568 INFO     Training average negative_sample_loss at step 7100: 0.060949\n",
      "2023-12-03 00:22:07,568 INFO     Training average loss at step 7100: 0.093794\n",
      "2023-12-03 00:22:14,249 INFO     Training average positive_sample_loss at step 7200: 0.118849\n",
      "2023-12-03 00:22:14,250 INFO     Training average negative_sample_loss at step 7200: 0.059944\n",
      "2023-12-03 00:22:14,250 INFO     Training average loss at step 7200: 0.089396\n",
      "2023-12-03 00:22:20,376 INFO     Training average positive_sample_loss at step 7300: 0.117624\n",
      "2023-12-03 00:22:20,376 INFO     Training average negative_sample_loss at step 7300: 0.058632\n",
      "2023-12-03 00:22:20,376 INFO     Training average loss at step 7300: 0.088128\n",
      "2023-12-03 00:22:26,364 INFO     Training average positive_sample_loss at step 7400: 0.120695\n",
      "2023-12-03 00:22:26,364 INFO     Training average negative_sample_loss at step 7400: 0.057506\n",
      "2023-12-03 00:22:26,364 INFO     Training average loss at step 7400: 0.089101\n",
      "2023-12-03 00:22:32,494 INFO     Training average positive_sample_loss at step 7500: 0.119052\n",
      "2023-12-03 00:22:32,494 INFO     Training average negative_sample_loss at step 7500: 0.056777\n",
      "2023-12-03 00:22:32,494 INFO     Training average loss at step 7500: 0.087914\n",
      "2023-12-03 00:22:38,580 INFO     Training average positive_sample_loss at step 7600: 0.110792\n",
      "2023-12-03 00:22:38,580 INFO     Training average negative_sample_loss at step 7600: 0.055529\n",
      "2023-12-03 00:22:38,580 INFO     Training average loss at step 7600: 0.083161\n",
      "2023-12-03 00:22:44,678 INFO     Training average positive_sample_loss at step 7700: 0.114889\n",
      "2023-12-03 00:22:44,678 INFO     Training average negative_sample_loss at step 7700: 0.054209\n",
      "2023-12-03 00:22:44,678 INFO     Training average loss at step 7700: 0.084549\n",
      "2023-12-03 00:22:50,775 INFO     Training average positive_sample_loss at step 7800: 0.117350\n",
      "2023-12-03 00:22:50,775 INFO     Training average negative_sample_loss at step 7800: 0.053732\n",
      "2023-12-03 00:22:50,775 INFO     Training average loss at step 7800: 0.085541\n",
      "2023-12-03 00:22:56,642 INFO     Training average positive_sample_loss at step 7900: 0.107638\n",
      "2023-12-03 00:22:56,642 INFO     Training average negative_sample_loss at step 7900: 0.053064\n",
      "2023-12-03 00:22:56,642 INFO     Training average loss at step 7900: 0.080351\n",
      "2023-12-03 00:23:02,757 INFO     Training average positive_sample_loss at step 8000: 0.109119\n",
      "2023-12-03 00:23:02,757 INFO     Training average negative_sample_loss at step 8000: 0.051594\n",
      "2023-12-03 00:23:02,757 INFO     Training average loss at step 8000: 0.080356\n",
      "2023-12-03 00:23:08,941 INFO     Training average positive_sample_loss at step 8100: 0.112596\n",
      "2023-12-03 00:23:08,941 INFO     Training average negative_sample_loss at step 8100: 0.051039\n",
      "2023-12-03 00:23:08,941 INFO     Training average loss at step 8100: 0.081817\n",
      "2023-12-03 00:23:15,303 INFO     Training average positive_sample_loss at step 8200: 0.107072\n",
      "2023-12-03 00:23:15,303 INFO     Training average negative_sample_loss at step 8200: 0.050201\n",
      "2023-12-03 00:23:15,304 INFO     Training average loss at step 8200: 0.078637\n",
      "2023-12-03 00:23:21,446 INFO     Training average positive_sample_loss at step 8300: 0.103951\n",
      "2023-12-03 00:23:21,446 INFO     Training average negative_sample_loss at step 8300: 0.049385\n",
      "2023-12-03 00:23:21,446 INFO     Training average loss at step 8300: 0.076668\n",
      "2023-12-03 00:23:27,269 INFO     Training average positive_sample_loss at step 8400: 0.106919\n",
      "2023-12-03 00:23:27,269 INFO     Training average negative_sample_loss at step 8400: 0.048514\n",
      "2023-12-03 00:23:27,269 INFO     Training average loss at step 8400: 0.077717\n",
      "2023-12-03 00:23:33,442 INFO     Training average positive_sample_loss at step 8500: 0.108838\n",
      "2023-12-03 00:23:33,443 INFO     Training average negative_sample_loss at step 8500: 0.047932\n",
      "2023-12-03 00:23:33,443 INFO     Training average loss at step 8500: 0.078385\n",
      "2023-12-03 00:23:39,593 INFO     Training average positive_sample_loss at step 8600: 0.098401\n",
      "2023-12-03 00:23:39,594 INFO     Training average negative_sample_loss at step 8600: 0.047207\n",
      "2023-12-03 00:23:39,594 INFO     Training average loss at step 8600: 0.072804\n",
      "2023-12-03 00:23:45,725 INFO     Training average positive_sample_loss at step 8700: 0.102843\n",
      "2023-12-03 00:23:45,725 INFO     Training average negative_sample_loss at step 8700: 0.046409\n",
      "2023-12-03 00:23:45,725 INFO     Training average loss at step 8700: 0.074626\n",
      "2023-12-03 00:23:51,521 INFO     Training average positive_sample_loss at step 8800: 0.104158\n",
      "2023-12-03 00:23:51,522 INFO     Training average negative_sample_loss at step 8800: 0.045726\n",
      "2023-12-03 00:23:51,522 INFO     Training average loss at step 8800: 0.074942\n",
      "2023-12-03 00:23:58,088 INFO     Training average positive_sample_loss at step 8900: 0.098154\n",
      "2023-12-03 00:23:58,088 INFO     Training average negative_sample_loss at step 8900: 0.045137\n",
      "2023-12-03 00:23:58,088 INFO     Training average loss at step 8900: 0.071646\n",
      "2023-12-03 00:24:04,156 INFO     Training average positive_sample_loss at step 9000: 0.097651\n",
      "2023-12-03 00:24:04,156 INFO     Training average negative_sample_loss at step 9000: 0.044392\n",
      "2023-12-03 00:24:04,156 INFO     Training average loss at step 9000: 0.071022\n",
      "2023-12-03 00:24:10,049 INFO     Training average positive_sample_loss at step 9100: 0.101031\n",
      "2023-12-03 00:24:10,050 INFO     Training average negative_sample_loss at step 9100: 0.043895\n",
      "2023-12-03 00:24:10,050 INFO     Training average loss at step 9100: 0.072463\n",
      "2023-12-03 00:24:16,461 INFO     Training average positive_sample_loss at step 9200: 0.099511\n",
      "2023-12-03 00:24:16,462 INFO     Training average negative_sample_loss at step 9200: 0.043317\n",
      "2023-12-03 00:24:16,462 INFO     Training average loss at step 9200: 0.071414\n",
      "2023-12-03 00:24:22,211 INFO     Training average positive_sample_loss at step 9300: 0.093093\n",
      "2023-12-03 00:24:22,211 INFO     Training average negative_sample_loss at step 9300: 0.042715\n",
      "2023-12-03 00:24:22,211 INFO     Training average loss at step 9300: 0.067904\n",
      "2023-12-03 00:24:28,275 INFO     Training average positive_sample_loss at step 9400: 0.096536\n",
      "2023-12-03 00:24:28,275 INFO     Training average negative_sample_loss at step 9400: 0.041946\n",
      "2023-12-03 00:24:28,275 INFO     Training average loss at step 9400: 0.069241\n",
      "2023-12-03 00:24:34,351 INFO     Training average positive_sample_loss at step 9500: 0.098673\n",
      "2023-12-03 00:24:34,351 INFO     Training average negative_sample_loss at step 9500: 0.041736\n",
      "2023-12-03 00:24:34,351 INFO     Training average loss at step 9500: 0.070204\n",
      "2023-12-03 00:24:40,888 INFO     Training average positive_sample_loss at step 9600: 0.090404\n",
      "2023-12-03 00:24:40,889 INFO     Training average negative_sample_loss at step 9600: 0.041151\n",
      "2023-12-03 00:24:40,889 INFO     Training average loss at step 9600: 0.065777\n",
      "2023-12-03 00:24:46,621 INFO     Training average positive_sample_loss at step 9700: 0.092709\n",
      "2023-12-03 00:24:46,621 INFO     Training average negative_sample_loss at step 9700: 0.040521\n",
      "2023-12-03 00:24:46,621 INFO     Training average loss at step 9700: 0.066615\n",
      "2023-12-03 00:24:52,352 INFO     Training average positive_sample_loss at step 9800: 0.095428\n",
      "2023-12-03 00:24:52,352 INFO     Training average negative_sample_loss at step 9800: 0.040040\n",
      "2023-12-03 00:24:52,352 INFO     Training average loss at step 9800: 0.067734\n",
      "2023-12-03 00:24:58,909 INFO     Training average positive_sample_loss at step 9900: 0.091871\n",
      "2023-12-03 00:24:58,909 INFO     Training average negative_sample_loss at step 9900: 0.039829\n",
      "2023-12-03 00:24:58,909 INFO     Training average loss at step 9900: 0.065850\n",
      "2023-12-03 00:25:13,145 INFO     Training average positive_sample_loss at step 10000: 0.089036\n",
      "2023-12-03 00:25:13,145 INFO     Training average negative_sample_loss at step 10000: 0.039181\n",
      "2023-12-03 00:25:13,145 INFO     Training average loss at step 10000: 0.064109\n",
      "2023-12-03 00:25:13,145 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:25:13,691 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:25:43,345 INFO     Valid MRR at step 10000: 0.455253\n",
      "2023-12-03 00:25:43,345 INFO     Valid MR at step 10000: 6230.521918\n",
      "2023-12-03 00:25:43,345 INFO     Valid HITS@1 at step 10000: 0.429960\n",
      "2023-12-03 00:25:43,345 INFO     Valid HITS@3 at step 10000: 0.465887\n",
      "2023-12-03 00:25:43,345 INFO     Valid HITS@10 at step 10000: 0.499670\n",
      "2023-12-03 00:25:49,166 INFO     Training average positive_sample_loss at step 10100: 0.091720\n",
      "2023-12-03 00:25:49,166 INFO     Training average negative_sample_loss at step 10100: 0.038643\n",
      "2023-12-03 00:25:49,166 INFO     Training average loss at step 10100: 0.065182\n",
      "2023-12-03 00:25:55,467 INFO     Training average positive_sample_loss at step 10200: 0.092766\n",
      "2023-12-03 00:25:55,468 INFO     Training average negative_sample_loss at step 10200: 0.038282\n",
      "2023-12-03 00:25:55,468 INFO     Training average loss at step 10200: 0.065524\n",
      "2023-12-03 00:26:01,789 INFO     Training average positive_sample_loss at step 10300: 0.084489\n",
      "2023-12-03 00:26:01,789 INFO     Training average negative_sample_loss at step 10300: 0.037902\n",
      "2023-12-03 00:26:01,789 INFO     Training average loss at step 10300: 0.061195\n",
      "2023-12-03 00:26:07,586 INFO     Training average positive_sample_loss at step 10400: 0.088113\n",
      "2023-12-03 00:26:07,587 INFO     Training average negative_sample_loss at step 10400: 0.037147\n",
      "2023-12-03 00:26:07,587 INFO     Training average loss at step 10400: 0.062630\n",
      "2023-12-03 00:26:13,563 INFO     Training average positive_sample_loss at step 10500: 0.090345\n",
      "2023-12-03 00:26:13,563 INFO     Training average negative_sample_loss at step 10500: 0.037014\n",
      "2023-12-03 00:26:13,563 INFO     Training average loss at step 10500: 0.063679\n",
      "2023-12-03 00:26:20,147 INFO     Training average positive_sample_loss at step 10600: 0.085602\n",
      "2023-12-03 00:26:20,147 INFO     Training average negative_sample_loss at step 10600: 0.036869\n",
      "2023-12-03 00:26:20,147 INFO     Training average loss at step 10600: 0.061235\n",
      "2023-12-03 00:26:25,949 INFO     Training average positive_sample_loss at step 10700: 0.084886\n",
      "2023-12-03 00:26:25,949 INFO     Training average negative_sample_loss at step 10700: 0.036084\n",
      "2023-12-03 00:26:25,949 INFO     Training average loss at step 10700: 0.060485\n",
      "2023-12-03 00:26:32,020 INFO     Training average positive_sample_loss at step 10800: 0.087518\n",
      "2023-12-03 00:26:32,020 INFO     Training average negative_sample_loss at step 10800: 0.035863\n",
      "2023-12-03 00:26:32,020 INFO     Training average loss at step 10800: 0.061690\n",
      "2023-12-03 00:26:38,601 INFO     Training average positive_sample_loss at step 10900: 0.086832\n",
      "2023-12-03 00:26:38,602 INFO     Training average negative_sample_loss at step 10900: 0.035705\n",
      "2023-12-03 00:26:38,602 INFO     Training average loss at step 10900: 0.061269\n",
      "2023-12-03 00:26:44,064 INFO     Training average positive_sample_loss at step 11000: 0.081320\n",
      "2023-12-03 00:26:44,064 INFO     Training average negative_sample_loss at step 11000: 0.035207\n",
      "2023-12-03 00:26:44,064 INFO     Training average loss at step 11000: 0.058264\n",
      "2023-12-03 00:26:49,546 INFO     Training average positive_sample_loss at step 11100: 0.084631\n",
      "2023-12-03 00:26:49,546 INFO     Training average negative_sample_loss at step 11100: 0.034791\n",
      "2023-12-03 00:26:49,546 INFO     Training average loss at step 11100: 0.059711\n",
      "2023-12-03 00:26:55,660 INFO     Training average positive_sample_loss at step 11200: 0.086178\n",
      "2023-12-03 00:26:55,660 INFO     Training average negative_sample_loss at step 11200: 0.034544\n",
      "2023-12-03 00:26:55,660 INFO     Training average loss at step 11200: 0.060361\n",
      "2023-12-03 00:27:01,621 INFO     Training average positive_sample_loss at step 11300: 0.080150\n",
      "2023-12-03 00:27:01,621 INFO     Training average negative_sample_loss at step 11300: 0.034342\n",
      "2023-12-03 00:27:01,621 INFO     Training average loss at step 11300: 0.057246\n",
      "2023-12-03 00:27:07,682 INFO     Training average positive_sample_loss at step 11400: 0.081549\n",
      "2023-12-03 00:27:07,682 INFO     Training average negative_sample_loss at step 11400: 0.033789\n",
      "2023-12-03 00:27:07,682 INFO     Training average loss at step 11400: 0.057669\n",
      "2023-12-03 00:27:13,744 INFO     Training average positive_sample_loss at step 11500: 0.083771\n",
      "2023-12-03 00:27:13,745 INFO     Training average negative_sample_loss at step 11500: 0.033485\n",
      "2023-12-03 00:27:13,745 INFO     Training average loss at step 11500: 0.058628\n",
      "2023-12-03 00:27:19,907 INFO     Training average positive_sample_loss at step 11600: 0.080743\n",
      "2023-12-03 00:27:19,907 INFO     Training average negative_sample_loss at step 11600: 0.033406\n",
      "2023-12-03 00:27:19,907 INFO     Training average loss at step 11600: 0.057074\n",
      "2023-12-03 00:27:25,956 INFO     Training average positive_sample_loss at step 11700: 0.078370\n",
      "2023-12-03 00:27:25,956 INFO     Training average negative_sample_loss at step 11700: 0.032898\n",
      "2023-12-03 00:27:25,956 INFO     Training average loss at step 11700: 0.055634\n",
      "2023-12-03 00:27:31,471 INFO     Training average positive_sample_loss at step 11800: 0.081586\n",
      "2023-12-03 00:27:31,471 INFO     Training average negative_sample_loss at step 11800: 0.032720\n",
      "2023-12-03 00:27:31,471 INFO     Training average loss at step 11800: 0.057153\n",
      "2023-12-03 00:27:37,618 INFO     Training average positive_sample_loss at step 11900: 0.082669\n",
      "2023-12-03 00:27:37,619 INFO     Training average negative_sample_loss at step 11900: 0.032654\n",
      "2023-12-03 00:27:37,619 INFO     Training average loss at step 11900: 0.057661\n",
      "2023-12-03 00:27:43,961 INFO     Training average positive_sample_loss at step 12000: 0.075565\n",
      "2023-12-03 00:27:43,961 INFO     Training average negative_sample_loss at step 12000: 0.032228\n",
      "2023-12-03 00:27:43,961 INFO     Training average loss at step 12000: 0.053897\n",
      "2023-12-03 00:27:50,051 INFO     Training average positive_sample_loss at step 12100: 0.079069\n",
      "2023-12-03 00:27:50,052 INFO     Training average negative_sample_loss at step 12100: 0.031901\n",
      "2023-12-03 00:27:50,052 INFO     Training average loss at step 12100: 0.055485\n",
      "2023-12-03 00:27:56,125 INFO     Training average positive_sample_loss at step 12200: 0.080181\n",
      "2023-12-03 00:27:56,126 INFO     Training average negative_sample_loss at step 12200: 0.031609\n",
      "2023-12-03 00:27:56,126 INFO     Training average loss at step 12200: 0.055895\n",
      "2023-12-03 00:28:02,251 INFO     Training average positive_sample_loss at step 12300: 0.076111\n",
      "2023-12-03 00:28:02,251 INFO     Training average negative_sample_loss at step 12300: 0.031517\n",
      "2023-12-03 00:28:02,251 INFO     Training average loss at step 12300: 0.053814\n",
      "2023-12-03 00:28:08,298 INFO     Training average positive_sample_loss at step 12400: 0.076165\n",
      "2023-12-03 00:28:08,298 INFO     Training average negative_sample_loss at step 12400: 0.031113\n",
      "2023-12-03 00:28:08,298 INFO     Training average loss at step 12400: 0.053639\n",
      "2023-12-03 00:28:14,213 INFO     Training average positive_sample_loss at step 12500: 0.078490\n",
      "2023-12-03 00:28:14,213 INFO     Training average negative_sample_loss at step 12500: 0.030832\n",
      "2023-12-03 00:28:14,214 INFO     Training average loss at step 12500: 0.054661\n",
      "2023-12-03 00:28:20,752 INFO     Training average positive_sample_loss at step 12600: 0.077836\n",
      "2023-12-03 00:28:20,753 INFO     Training average negative_sample_loss at step 12600: 0.030821\n",
      "2023-12-03 00:28:20,753 INFO     Training average loss at step 12600: 0.054328\n",
      "2023-12-03 00:28:26,839 INFO     Training average positive_sample_loss at step 12700: 0.073022\n",
      "2023-12-03 00:28:26,840 INFO     Training average negative_sample_loss at step 12700: 0.030453\n",
      "2023-12-03 00:28:26,840 INFO     Training average loss at step 12700: 0.051737\n",
      "2023-12-03 00:28:32,389 INFO     Training average positive_sample_loss at step 12800: 0.076184\n",
      "2023-12-03 00:28:32,390 INFO     Training average negative_sample_loss at step 12800: 0.030107\n",
      "2023-12-03 00:28:32,390 INFO     Training average loss at step 12800: 0.053146\n",
      "2023-12-03 00:28:38,476 INFO     Training average positive_sample_loss at step 12900: 0.077837\n",
      "2023-12-03 00:28:38,477 INFO     Training average negative_sample_loss at step 12900: 0.030124\n",
      "2023-12-03 00:28:38,477 INFO     Training average loss at step 12900: 0.053981\n",
      "2023-12-03 00:28:45,126 INFO     Training average positive_sample_loss at step 13000: 0.072232\n",
      "2023-12-03 00:28:45,126 INFO     Training average negative_sample_loss at step 13000: 0.029869\n",
      "2023-12-03 00:28:45,126 INFO     Training average loss at step 13000: 0.051050\n",
      "2023-12-03 00:28:51,087 INFO     Training average positive_sample_loss at step 13100: 0.074094\n",
      "2023-12-03 00:28:51,087 INFO     Training average negative_sample_loss at step 13100: 0.029638\n",
      "2023-12-03 00:28:51,087 INFO     Training average loss at step 13100: 0.051866\n",
      "2023-12-03 00:28:57,252 INFO     Training average positive_sample_loss at step 13200: 0.075886\n",
      "2023-12-03 00:28:57,252 INFO     Training average negative_sample_loss at step 13200: 0.029422\n",
      "2023-12-03 00:28:57,252 INFO     Training average loss at step 13200: 0.052654\n",
      "2023-12-03 00:29:03,895 INFO     Training average positive_sample_loss at step 13300: 0.073277\n",
      "2023-12-03 00:29:03,895 INFO     Training average negative_sample_loss at step 13300: 0.029260\n",
      "2023-12-03 00:29:03,895 INFO     Training average loss at step 13300: 0.051269\n",
      "2023-12-03 00:29:09,422 INFO     Training average positive_sample_loss at step 13400: 0.070862\n",
      "2023-12-03 00:29:09,423 INFO     Training average negative_sample_loss at step 13400: 0.028819\n",
      "2023-12-03 00:29:09,423 INFO     Training average loss at step 13400: 0.049840\n",
      "2023-12-03 00:29:15,484 INFO     Training average positive_sample_loss at step 13500: 0.074324\n",
      "2023-12-03 00:29:15,484 INFO     Training average negative_sample_loss at step 13500: 0.028831\n",
      "2023-12-03 00:29:15,484 INFO     Training average loss at step 13500: 0.051577\n",
      "2023-12-03 00:29:21,802 INFO     Training average positive_sample_loss at step 13600: 0.075535\n",
      "2023-12-03 00:29:21,802 INFO     Training average negative_sample_loss at step 13600: 0.028816\n",
      "2023-12-03 00:29:21,802 INFO     Training average loss at step 13600: 0.052176\n",
      "2023-12-03 00:29:28,076 INFO     Training average positive_sample_loss at step 13700: 0.068796\n",
      "2023-12-03 00:29:28,077 INFO     Training average negative_sample_loss at step 13700: 0.028494\n",
      "2023-12-03 00:29:28,077 INFO     Training average loss at step 13700: 0.048645\n",
      "2023-12-03 00:29:33,893 INFO     Training average positive_sample_loss at step 13800: 0.072213\n",
      "2023-12-03 00:29:33,893 INFO     Training average negative_sample_loss at step 13800: 0.028220\n",
      "2023-12-03 00:29:33,893 INFO     Training average loss at step 13800: 0.050217\n",
      "2023-12-03 00:29:39,714 INFO     Training average positive_sample_loss at step 13900: 0.073172\n",
      "2023-12-03 00:29:39,715 INFO     Training average negative_sample_loss at step 13900: 0.028110\n",
      "2023-12-03 00:29:39,715 INFO     Training average loss at step 13900: 0.050641\n",
      "2023-12-03 00:29:46,159 INFO     Training average positive_sample_loss at step 14000: 0.070036\n",
      "2023-12-03 00:29:46,159 INFO     Training average negative_sample_loss at step 14000: 0.028088\n",
      "2023-12-03 00:29:46,159 INFO     Training average loss at step 14000: 0.049062\n",
      "2023-12-03 00:29:52,284 INFO     Training average positive_sample_loss at step 14100: 0.069898\n",
      "2023-12-03 00:29:52,284 INFO     Training average negative_sample_loss at step 14100: 0.027754\n",
      "2023-12-03 00:29:52,284 INFO     Training average loss at step 14100: 0.048826\n",
      "2023-12-03 00:29:58,457 INFO     Training average positive_sample_loss at step 14200: 0.071987\n",
      "2023-12-03 00:29:58,457 INFO     Training average negative_sample_loss at step 14200: 0.027561\n",
      "2023-12-03 00:29:58,457 INFO     Training average loss at step 14200: 0.049774\n",
      "2023-12-03 00:30:04,729 INFO     Training average positive_sample_loss at step 14300: 0.071127\n",
      "2023-12-03 00:30:04,729 INFO     Training average negative_sample_loss at step 14300: 0.027583\n",
      "2023-12-03 00:30:04,729 INFO     Training average loss at step 14300: 0.049355\n",
      "2023-12-03 00:30:10,579 INFO     Training average positive_sample_loss at step 14400: 0.067438\n",
      "2023-12-03 00:30:10,579 INFO     Training average negative_sample_loss at step 14400: 0.027315\n",
      "2023-12-03 00:30:10,579 INFO     Training average loss at step 14400: 0.047377\n",
      "2023-12-03 00:30:16,645 INFO     Training average positive_sample_loss at step 14500: 0.069982\n",
      "2023-12-03 00:30:16,645 INFO     Training average negative_sample_loss at step 14500: 0.027067\n",
      "2023-12-03 00:30:16,645 INFO     Training average loss at step 14500: 0.048525\n",
      "2023-12-03 00:30:22,696 INFO     Training average positive_sample_loss at step 14600: 0.072010\n",
      "2023-12-03 00:30:22,696 INFO     Training average negative_sample_loss at step 14600: 0.027004\n",
      "2023-12-03 00:30:22,696 INFO     Training average loss at step 14600: 0.049507\n",
      "2023-12-03 00:30:29,257 INFO     Training average positive_sample_loss at step 14700: 0.066392\n",
      "2023-12-03 00:30:29,258 INFO     Training average negative_sample_loss at step 14700: 0.026894\n",
      "2023-12-03 00:30:29,258 INFO     Training average loss at step 14700: 0.046643\n",
      "2023-12-03 00:30:35,424 INFO     Training average positive_sample_loss at step 14800: 0.068480\n",
      "2023-12-03 00:30:35,424 INFO     Training average negative_sample_loss at step 14800: 0.026684\n",
      "2023-12-03 00:30:35,424 INFO     Training average loss at step 14800: 0.047582\n",
      "2023-12-03 00:30:41,149 INFO     Training average positive_sample_loss at step 14900: 0.070070\n",
      "2023-12-03 00:30:41,149 INFO     Training average negative_sample_loss at step 14900: 0.026608\n",
      "2023-12-03 00:30:41,149 INFO     Training average loss at step 14900: 0.048339\n",
      "2023-12-03 00:30:47,638 INFO     Training average positive_sample_loss at step 15000: 0.067887\n",
      "2023-12-03 00:30:47,638 INFO     Training average negative_sample_loss at step 15000: 0.026515\n",
      "2023-12-03 00:30:47,638 INFO     Training average loss at step 15000: 0.047201\n",
      "2023-12-03 00:30:53,694 INFO     Training average positive_sample_loss at step 15100: 0.066457\n",
      "2023-12-03 00:30:53,695 INFO     Training average negative_sample_loss at step 15100: 0.026338\n",
      "2023-12-03 00:30:53,695 INFO     Training average loss at step 15100: 0.046397\n",
      "2023-12-03 00:30:59,860 INFO     Training average positive_sample_loss at step 15200: 0.068413\n",
      "2023-12-03 00:30:59,861 INFO     Training average negative_sample_loss at step 15200: 0.026105\n",
      "2023-12-03 00:30:59,861 INFO     Training average loss at step 15200: 0.047259\n",
      "2023-12-03 00:31:06,242 INFO     Training average positive_sample_loss at step 15300: 0.069647\n",
      "2023-12-03 00:31:06,242 INFO     Training average negative_sample_loss at step 15300: 0.026226\n",
      "2023-12-03 00:31:06,242 INFO     Training average loss at step 15300: 0.047936\n",
      "2023-12-03 00:31:12,701 INFO     Training average positive_sample_loss at step 15400: 0.064113\n",
      "2023-12-03 00:31:12,701 INFO     Training average negative_sample_loss at step 15400: 0.025986\n",
      "2023-12-03 00:31:12,702 INFO     Training average loss at step 15400: 0.045050\n",
      "2023-12-03 00:31:18,576 INFO     Training average positive_sample_loss at step 15500: 0.066926\n",
      "2023-12-03 00:31:18,576 INFO     Training average negative_sample_loss at step 15500: 0.025647\n",
      "2023-12-03 00:31:18,577 INFO     Training average loss at step 15500: 0.046286\n",
      "2023-12-03 00:31:24,678 INFO     Training average positive_sample_loss at step 15600: 0.068412\n",
      "2023-12-03 00:31:24,678 INFO     Training average negative_sample_loss at step 15600: 0.025651\n",
      "2023-12-03 00:31:24,678 INFO     Training average loss at step 15600: 0.047031\n",
      "2023-12-03 00:31:31,198 INFO     Training average positive_sample_loss at step 15700: 0.064661\n",
      "2023-12-03 00:31:31,198 INFO     Training average negative_sample_loss at step 15700: 0.025659\n",
      "2023-12-03 00:31:31,198 INFO     Training average loss at step 15700: 0.045160\n",
      "2023-12-03 00:31:37,241 INFO     Training average positive_sample_loss at step 15800: 0.065011\n",
      "2023-12-03 00:31:37,242 INFO     Training average negative_sample_loss at step 15800: 0.025359\n",
      "2023-12-03 00:31:37,242 INFO     Training average loss at step 15800: 0.045185\n",
      "2023-12-03 00:31:43,350 INFO     Training average positive_sample_loss at step 15900: 0.067144\n",
      "2023-12-03 00:31:43,350 INFO     Training average negative_sample_loss at step 15900: 0.025361\n",
      "2023-12-03 00:31:43,350 INFO     Training average loss at step 15900: 0.046253\n",
      "2023-12-03 00:31:49,775 INFO     Training average positive_sample_loss at step 16000: 0.066674\n",
      "2023-12-03 00:31:49,775 INFO     Training average negative_sample_loss at step 16000: 0.025278\n",
      "2023-12-03 00:31:49,775 INFO     Training average loss at step 16000: 0.045976\n",
      "2023-12-03 00:31:55,503 INFO     Training average positive_sample_loss at step 16100: 0.062833\n",
      "2023-12-03 00:31:55,504 INFO     Training average negative_sample_loss at step 16100: 0.025066\n",
      "2023-12-03 00:31:55,504 INFO     Training average loss at step 16100: 0.043949\n",
      "2023-12-03 00:32:01,608 INFO     Training average positive_sample_loss at step 16200: 0.065907\n",
      "2023-12-03 00:32:01,608 INFO     Training average negative_sample_loss at step 16200: 0.024964\n",
      "2023-12-03 00:32:01,608 INFO     Training average loss at step 16200: 0.045435\n",
      "2023-12-03 00:32:07,708 INFO     Training average positive_sample_loss at step 16300: 0.066818\n",
      "2023-12-03 00:32:07,708 INFO     Training average negative_sample_loss at step 16300: 0.024894\n",
      "2023-12-03 00:32:07,708 INFO     Training average loss at step 16300: 0.045856\n",
      "2023-12-03 00:32:14,019 INFO     Training average positive_sample_loss at step 16400: 0.062546\n",
      "2023-12-03 00:32:14,020 INFO     Training average negative_sample_loss at step 16400: 0.024857\n",
      "2023-12-03 00:32:14,020 INFO     Training average loss at step 16400: 0.043701\n",
      "2023-12-03 00:32:20,128 INFO     Training average positive_sample_loss at step 16500: 0.063896\n",
      "2023-12-03 00:32:20,128 INFO     Training average negative_sample_loss at step 16500: 0.024597\n",
      "2023-12-03 00:32:20,128 INFO     Training average loss at step 16500: 0.044247\n",
      "2023-12-03 00:32:25,788 INFO     Training average positive_sample_loss at step 16600: 0.065736\n",
      "2023-12-03 00:32:25,788 INFO     Training average negative_sample_loss at step 16600: 0.024505\n",
      "2023-12-03 00:32:25,788 INFO     Training average loss at step 16600: 0.045121\n",
      "2023-12-03 00:32:32,149 INFO     Training average positive_sample_loss at step 16700: 0.063953\n",
      "2023-12-03 00:32:32,149 INFO     Training average negative_sample_loss at step 16700: 0.024596\n",
      "2023-12-03 00:32:32,149 INFO     Training average loss at step 16700: 0.044274\n",
      "2023-12-03 00:32:38,246 INFO     Training average positive_sample_loss at step 16800: 0.062197\n",
      "2023-12-03 00:32:38,247 INFO     Training average negative_sample_loss at step 16800: 0.024284\n",
      "2023-12-03 00:32:38,247 INFO     Training average loss at step 16800: 0.043241\n",
      "2023-12-03 00:32:44,340 INFO     Training average positive_sample_loss at step 16900: 0.064447\n",
      "2023-12-03 00:32:44,341 INFO     Training average negative_sample_loss at step 16900: 0.024267\n",
      "2023-12-03 00:32:44,341 INFO     Training average loss at step 16900: 0.044357\n",
      "2023-12-03 00:32:50,365 INFO     Training average positive_sample_loss at step 17000: 0.065429\n",
      "2023-12-03 00:32:50,365 INFO     Training average negative_sample_loss at step 17000: 0.024192\n",
      "2023-12-03 00:32:50,366 INFO     Training average loss at step 17000: 0.044811\n",
      "2023-12-03 00:32:56,738 INFO     Training average positive_sample_loss at step 17100: 0.060106\n",
      "2023-12-03 00:32:56,739 INFO     Training average negative_sample_loss at step 17100: 0.024094\n",
      "2023-12-03 00:32:56,739 INFO     Training average loss at step 17100: 0.042100\n",
      "2023-12-03 00:33:02,407 INFO     Training average positive_sample_loss at step 17200: 0.063321\n",
      "2023-12-03 00:33:02,407 INFO     Training average negative_sample_loss at step 17200: 0.023934\n",
      "2023-12-03 00:33:02,407 INFO     Training average loss at step 17200: 0.043628\n",
      "2023-12-03 00:33:08,485 INFO     Training average positive_sample_loss at step 17300: 0.064337\n",
      "2023-12-03 00:33:08,485 INFO     Training average negative_sample_loss at step 17300: 0.023925\n",
      "2023-12-03 00:33:08,486 INFO     Training average loss at step 17300: 0.044131\n",
      "2023-12-03 00:33:15,002 INFO     Training average positive_sample_loss at step 17400: 0.061403\n",
      "2023-12-03 00:33:15,003 INFO     Training average negative_sample_loss at step 17400: 0.023917\n",
      "2023-12-03 00:33:15,003 INFO     Training average loss at step 17400: 0.042660\n",
      "2023-12-03 00:33:20,954 INFO     Training average positive_sample_loss at step 17500: 0.061176\n",
      "2023-12-03 00:33:20,955 INFO     Training average negative_sample_loss at step 17500: 0.023529\n",
      "2023-12-03 00:33:20,955 INFO     Training average loss at step 17500: 0.042353\n",
      "2023-12-03 00:33:26,926 INFO     Training average positive_sample_loss at step 17600: 0.063203\n",
      "2023-12-03 00:33:26,926 INFO     Training average negative_sample_loss at step 17600: 0.023593\n",
      "2023-12-03 00:33:26,926 INFO     Training average loss at step 17600: 0.043398\n",
      "2023-12-03 00:33:33,513 INFO     Training average positive_sample_loss at step 17700: 0.063157\n",
      "2023-12-03 00:33:33,514 INFO     Training average negative_sample_loss at step 17700: 0.023712\n",
      "2023-12-03 00:33:33,514 INFO     Training average loss at step 17700: 0.043434\n",
      "2023-12-03 00:33:39,196 INFO     Training average positive_sample_loss at step 17800: 0.059665\n",
      "2023-12-03 00:33:39,196 INFO     Training average negative_sample_loss at step 17800: 0.023408\n",
      "2023-12-03 00:33:39,196 INFO     Training average loss at step 17800: 0.041536\n",
      "2023-12-03 00:33:45,260 INFO     Training average positive_sample_loss at step 17900: 0.061966\n",
      "2023-12-03 00:33:45,260 INFO     Training average negative_sample_loss at step 17900: 0.023363\n",
      "2023-12-03 00:33:45,260 INFO     Training average loss at step 17900: 0.042665\n",
      "2023-12-03 00:33:51,341 INFO     Training average positive_sample_loss at step 18000: 0.063332\n",
      "2023-12-03 00:33:51,341 INFO     Training average negative_sample_loss at step 18000: 0.023392\n",
      "2023-12-03 00:33:51,341 INFO     Training average loss at step 18000: 0.043362\n",
      "2023-12-03 00:33:57,692 INFO     Training average positive_sample_loss at step 18100: 0.059031\n",
      "2023-12-03 00:33:57,693 INFO     Training average negative_sample_loss at step 18100: 0.023219\n",
      "2023-12-03 00:33:57,693 INFO     Training average loss at step 18100: 0.041125\n",
      "2023-12-03 00:34:03,616 INFO     Training average positive_sample_loss at step 18200: 0.060435\n",
      "2023-12-03 00:34:03,616 INFO     Training average negative_sample_loss at step 18200: 0.023048\n",
      "2023-12-03 00:34:03,616 INFO     Training average loss at step 18200: 0.041741\n",
      "2023-12-03 00:34:09,671 INFO     Training average positive_sample_loss at step 18300: 0.062578\n",
      "2023-12-03 00:34:09,672 INFO     Training average negative_sample_loss at step 18300: 0.022948\n",
      "2023-12-03 00:34:09,672 INFO     Training average loss at step 18300: 0.042763\n",
      "2023-12-03 00:34:15,934 INFO     Training average positive_sample_loss at step 18400: 0.060577\n",
      "2023-12-03 00:34:15,934 INFO     Training average negative_sample_loss at step 18400: 0.023029\n",
      "2023-12-03 00:34:15,934 INFO     Training average loss at step 18400: 0.041803\n",
      "2023-12-03 00:34:22,113 INFO     Training average positive_sample_loss at step 18500: 0.059040\n",
      "2023-12-03 00:34:22,113 INFO     Training average negative_sample_loss at step 18500: 0.022859\n",
      "2023-12-03 00:34:22,113 INFO     Training average loss at step 18500: 0.040949\n",
      "2023-12-03 00:34:28,224 INFO     Training average positive_sample_loss at step 18600: 0.061326\n",
      "2023-12-03 00:34:28,224 INFO     Training average negative_sample_loss at step 18600: 0.022810\n",
      "2023-12-03 00:34:28,224 INFO     Training average loss at step 18600: 0.042068\n",
      "2023-12-03 00:34:34,358 INFO     Training average positive_sample_loss at step 18700: 0.062080\n",
      "2023-12-03 00:34:34,359 INFO     Training average negative_sample_loss at step 18700: 0.022818\n",
      "2023-12-03 00:34:34,359 INFO     Training average loss at step 18700: 0.042449\n",
      "2023-12-03 00:34:40,676 INFO     Training average positive_sample_loss at step 18800: 0.057197\n",
      "2023-12-03 00:34:40,676 INFO     Training average negative_sample_loss at step 18800: 0.022722\n",
      "2023-12-03 00:34:40,676 INFO     Training average loss at step 18800: 0.039960\n",
      "2023-12-03 00:34:46,678 INFO     Training average positive_sample_loss at step 18900: 0.059913\n",
      "2023-12-03 00:34:46,678 INFO     Training average negative_sample_loss at step 18900: 0.022662\n",
      "2023-12-03 00:34:46,678 INFO     Training average loss at step 18900: 0.041287\n",
      "2023-12-03 00:34:52,361 INFO     Training average positive_sample_loss at step 19000: 0.061476\n",
      "2023-12-03 00:34:52,361 INFO     Training average negative_sample_loss at step 19000: 0.022559\n",
      "2023-12-03 00:34:52,361 INFO     Training average loss at step 19000: 0.042018\n",
      "2023-12-03 00:34:58,946 INFO     Training average positive_sample_loss at step 19100: 0.058436\n",
      "2023-12-03 00:34:58,946 INFO     Training average negative_sample_loss at step 19100: 0.022409\n",
      "2023-12-03 00:34:58,946 INFO     Training average loss at step 19100: 0.040422\n",
      "2023-12-03 00:35:04,823 INFO     Training average positive_sample_loss at step 19200: 0.058353\n",
      "2023-12-03 00:35:04,824 INFO     Training average negative_sample_loss at step 19200: 0.022357\n",
      "2023-12-03 00:35:04,824 INFO     Training average loss at step 19200: 0.040355\n",
      "2023-12-03 00:35:10,900 INFO     Training average positive_sample_loss at step 19300: 0.060286\n",
      "2023-12-03 00:35:10,900 INFO     Training average negative_sample_loss at step 19300: 0.022426\n",
      "2023-12-03 00:35:10,900 INFO     Training average loss at step 19300: 0.041356\n",
      "2023-12-03 00:35:17,436 INFO     Training average positive_sample_loss at step 19400: 0.059944\n",
      "2023-12-03 00:35:17,436 INFO     Training average negative_sample_loss at step 19400: 0.022312\n",
      "2023-12-03 00:35:17,436 INFO     Training average loss at step 19400: 0.041128\n",
      "2023-12-03 00:35:23,471 INFO     Training average positive_sample_loss at step 19500: 0.056906\n",
      "2023-12-03 00:35:23,471 INFO     Training average negative_sample_loss at step 19500: 0.022271\n",
      "2023-12-03 00:35:23,471 INFO     Training average loss at step 19500: 0.039589\n",
      "2023-12-03 00:35:29,143 INFO     Training average positive_sample_loss at step 19600: 0.059389\n",
      "2023-12-03 00:35:29,143 INFO     Training average negative_sample_loss at step 19600: 0.022107\n",
      "2023-12-03 00:35:29,144 INFO     Training average loss at step 19600: 0.040748\n",
      "2023-12-03 00:35:35,071 INFO     Training average positive_sample_loss at step 19700: 0.060649\n",
      "2023-12-03 00:35:35,071 INFO     Training average negative_sample_loss at step 19700: 0.022149\n",
      "2023-12-03 00:35:35,071 INFO     Training average loss at step 19700: 0.041399\n",
      "2023-12-03 00:35:41,674 INFO     Training average positive_sample_loss at step 19800: 0.056688\n",
      "2023-12-03 00:35:41,674 INFO     Training average negative_sample_loss at step 19800: 0.022137\n",
      "2023-12-03 00:35:41,674 INFO     Training average loss at step 19800: 0.039412\n",
      "2023-12-03 00:35:47,776 INFO     Training average positive_sample_loss at step 19900: 0.057843\n",
      "2023-12-03 00:35:47,776 INFO     Training average negative_sample_loss at step 19900: 0.021947\n",
      "2023-12-03 00:35:47,776 INFO     Training average loss at step 19900: 0.039895\n",
      "2023-12-03 00:36:03,893 INFO     Training average positive_sample_loss at step 20000: 0.059519\n",
      "2023-12-03 00:36:03,893 INFO     Training average negative_sample_loss at step 20000: 0.021863\n",
      "2023-12-03 00:36:03,894 INFO     Training average loss at step 20000: 0.040691\n",
      "2023-12-03 00:36:03,894 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:36:04,446 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:36:33,734 INFO     Valid MRR at step 20000: 0.481485\n",
      "2023-12-03 00:36:33,735 INFO     Valid MR at step 20000: 4405.410349\n",
      "2023-12-03 00:36:33,735 INFO     Valid HITS@1 at step 20000: 0.444133\n",
      "2023-12-03 00:36:33,735 INFO     Valid HITS@3 at step 20000: 0.493408\n",
      "2023-12-03 00:36:33,735 INFO     Valid HITS@10 at step 20000: 0.554219\n",
      "2023-12-03 00:36:40,495 INFO     Training average positive_sample_loss at step 20100: 0.057468\n",
      "2023-12-03 00:36:40,496 INFO     Training average negative_sample_loss at step 20100: 0.021979\n",
      "2023-12-03 00:36:40,496 INFO     Training average loss at step 20100: 0.039723\n",
      "2023-12-03 00:36:46,278 INFO     Training average positive_sample_loss at step 20200: 0.056508\n",
      "2023-12-03 00:36:46,278 INFO     Training average negative_sample_loss at step 20200: 0.021834\n",
      "2023-12-03 00:36:46,278 INFO     Training average loss at step 20200: 0.039171\n",
      "2023-12-03 00:36:52,442 INFO     Training average positive_sample_loss at step 20300: 0.058844\n",
      "2023-12-03 00:36:52,442 INFO     Training average negative_sample_loss at step 20300: 0.021704\n",
      "2023-12-03 00:36:52,443 INFO     Training average loss at step 20300: 0.040274\n",
      "2023-12-03 00:36:58,918 INFO     Training average positive_sample_loss at step 20400: 0.059547\n",
      "2023-12-03 00:36:58,919 INFO     Training average negative_sample_loss at step 20400: 0.021750\n",
      "2023-12-03 00:36:58,919 INFO     Training average loss at step 20400: 0.040649\n",
      "2023-12-03 00:37:05,211 INFO     Training average positive_sample_loss at step 20500: 0.054614\n",
      "2023-12-03 00:37:05,212 INFO     Training average negative_sample_loss at step 20500: 0.021513\n",
      "2023-12-03 00:37:05,212 INFO     Training average loss at step 20500: 0.038064\n",
      "2023-12-03 00:37:11,480 INFO     Training average positive_sample_loss at step 20600: 0.057718\n",
      "2023-12-03 00:37:11,480 INFO     Training average negative_sample_loss at step 20600: 0.021545\n",
      "2023-12-03 00:37:11,480 INFO     Training average loss at step 20600: 0.039631\n",
      "2023-12-03 00:37:17,404 INFO     Training average positive_sample_loss at step 20700: 0.059053\n",
      "2023-12-03 00:37:17,404 INFO     Training average negative_sample_loss at step 20700: 0.021558\n",
      "2023-12-03 00:37:17,404 INFO     Training average loss at step 20700: 0.040306\n",
      "2023-12-03 00:37:23,974 INFO     Training average positive_sample_loss at step 20800: 0.055871\n",
      "2023-12-03 00:37:23,975 INFO     Training average negative_sample_loss at step 20800: 0.021547\n",
      "2023-12-03 00:37:23,975 INFO     Training average loss at step 20800: 0.038709\n",
      "2023-12-03 00:37:29,994 INFO     Training average positive_sample_loss at step 20900: 0.056221\n",
      "2023-12-03 00:37:29,994 INFO     Training average negative_sample_loss at step 20900: 0.021430\n",
      "2023-12-03 00:37:29,994 INFO     Training average loss at step 20900: 0.038826\n",
      "2023-12-03 00:37:36,038 INFO     Training average positive_sample_loss at step 21000: 0.057610\n",
      "2023-12-03 00:37:36,038 INFO     Training average negative_sample_loss at step 21000: 0.021294\n",
      "2023-12-03 00:37:36,039 INFO     Training average loss at step 21000: 0.039452\n",
      "2023-12-03 00:37:42,294 INFO     Training average positive_sample_loss at step 21100: 0.057879\n",
      "2023-12-03 00:37:42,295 INFO     Training average negative_sample_loss at step 21100: 0.021333\n",
      "2023-12-03 00:37:42,295 INFO     Training average loss at step 21100: 0.039606\n",
      "2023-12-03 00:37:48,411 INFO     Training average positive_sample_loss at step 21200: 0.054780\n",
      "2023-12-03 00:37:48,412 INFO     Training average negative_sample_loss at step 21200: 0.021283\n",
      "2023-12-03 00:37:48,412 INFO     Training average loss at step 21200: 0.038031\n",
      "2023-12-03 00:37:54,504 INFO     Training average positive_sample_loss at step 21300: 0.056988\n",
      "2023-12-03 00:37:54,505 INFO     Training average negative_sample_loss at step 21300: 0.021230\n",
      "2023-12-03 00:37:54,505 INFO     Training average loss at step 21300: 0.039109\n",
      "2023-12-03 00:38:00,157 INFO     Training average positive_sample_loss at step 21400: 0.057973\n",
      "2023-12-03 00:38:00,157 INFO     Training average negative_sample_loss at step 21400: 0.021169\n",
      "2023-12-03 00:38:00,157 INFO     Training average loss at step 21400: 0.039571\n",
      "2023-12-03 00:38:06,539 INFO     Training average positive_sample_loss at step 21500: 0.054073\n",
      "2023-12-03 00:38:06,539 INFO     Training average negative_sample_loss at step 21500: 0.021139\n",
      "2023-12-03 00:38:06,539 INFO     Training average loss at step 21500: 0.037606\n",
      "2023-12-03 00:38:12,659 INFO     Training average positive_sample_loss at step 21600: 0.055953\n",
      "2023-12-03 00:38:12,659 INFO     Training average negative_sample_loss at step 21600: 0.021029\n",
      "2023-12-03 00:38:12,659 INFO     Training average loss at step 21600: 0.038491\n",
      "2023-12-03 00:38:18,783 INFO     Training average positive_sample_loss at step 21700: 0.057403\n",
      "2023-12-03 00:38:18,783 INFO     Training average negative_sample_loss at step 21700: 0.021003\n",
      "2023-12-03 00:38:18,784 INFO     Training average loss at step 21700: 0.039203\n",
      "2023-12-03 00:38:24,942 INFO     Training average positive_sample_loss at step 21800: 0.055843\n",
      "2023-12-03 00:38:24,942 INFO     Training average negative_sample_loss at step 21800: 0.020916\n",
      "2023-12-03 00:38:24,942 INFO     Training average loss at step 21800: 0.038380\n",
      "2023-12-03 00:38:31,012 INFO     Training average positive_sample_loss at step 21900: 0.054583\n",
      "2023-12-03 00:38:31,012 INFO     Training average negative_sample_loss at step 21900: 0.020889\n",
      "2023-12-03 00:38:31,012 INFO     Training average loss at step 21900: 0.037736\n",
      "2023-12-03 00:38:36,530 INFO     Training average positive_sample_loss at step 22000: 0.056604\n",
      "2023-12-03 00:38:36,531 INFO     Training average negative_sample_loss at step 22000: 0.020924\n",
      "2023-12-03 00:38:36,531 INFO     Training average loss at step 22000: 0.038764\n",
      "2023-12-03 00:38:42,519 INFO     Training average positive_sample_loss at step 22100: 0.057016\n",
      "2023-12-03 00:38:42,519 INFO     Training average negative_sample_loss at step 22100: 0.020911\n",
      "2023-12-03 00:38:42,519 INFO     Training average loss at step 22100: 0.038963\n",
      "2023-12-03 00:38:48,330 INFO     Training average positive_sample_loss at step 22200: 0.052632\n",
      "2023-12-03 00:38:48,331 INFO     Training average negative_sample_loss at step 22200: 0.020775\n",
      "2023-12-03 00:38:48,331 INFO     Training average loss at step 22200: 0.036704\n",
      "2023-12-03 00:38:54,496 INFO     Training average positive_sample_loss at step 22300: 0.055364\n",
      "2023-12-03 00:38:54,496 INFO     Training average negative_sample_loss at step 22300: 0.020732\n",
      "2023-12-03 00:38:54,496 INFO     Training average loss at step 22300: 0.038048\n",
      "2023-12-03 00:38:59,990 INFO     Training average positive_sample_loss at step 22400: 0.057057\n",
      "2023-12-03 00:38:59,991 INFO     Training average negative_sample_loss at step 22400: 0.020685\n",
      "2023-12-03 00:38:59,991 INFO     Training average loss at step 22400: 0.038871\n",
      "2023-12-03 00:39:06,642 INFO     Training average positive_sample_loss at step 22500: 0.054332\n",
      "2023-12-03 00:39:06,643 INFO     Training average negative_sample_loss at step 22500: 0.020765\n",
      "2023-12-03 00:39:06,643 INFO     Training average loss at step 22500: 0.037549\n",
      "2023-12-03 00:39:12,744 INFO     Training average positive_sample_loss at step 22600: 0.054399\n",
      "2023-12-03 00:39:12,744 INFO     Training average negative_sample_loss at step 22600: 0.020627\n",
      "2023-12-03 00:39:12,745 INFO     Training average loss at step 22600: 0.037513\n",
      "2023-12-03 00:39:18,854 INFO     Training average positive_sample_loss at step 22700: 0.055724\n",
      "2023-12-03 00:39:18,855 INFO     Training average negative_sample_loss at step 22700: 0.020546\n",
      "2023-12-03 00:39:18,855 INFO     Training average loss at step 22700: 0.038135\n",
      "2023-12-03 00:39:25,048 INFO     Training average positive_sample_loss at step 22800: 0.055447\n",
      "2023-12-03 00:39:25,048 INFO     Training average negative_sample_loss at step 22800: 0.020586\n",
      "2023-12-03 00:39:25,048 INFO     Training average loss at step 22800: 0.038016\n",
      "2023-12-03 00:39:30,449 INFO     Training average positive_sample_loss at step 22900: 0.052873\n",
      "2023-12-03 00:39:30,450 INFO     Training average negative_sample_loss at step 22900: 0.020422\n",
      "2023-12-03 00:39:30,450 INFO     Training average loss at step 22900: 0.036647\n",
      "2023-12-03 00:39:36,574 INFO     Training average positive_sample_loss at step 23000: 0.055239\n",
      "2023-12-03 00:39:36,574 INFO     Training average negative_sample_loss at step 23000: 0.020501\n",
      "2023-12-03 00:39:36,574 INFO     Training average loss at step 23000: 0.037870\n",
      "2023-12-03 00:39:42,679 INFO     Training average positive_sample_loss at step 23100: 0.056259\n",
      "2023-12-03 00:39:42,679 INFO     Training average negative_sample_loss at step 23100: 0.020539\n",
      "2023-12-03 00:39:42,679 INFO     Training average loss at step 23100: 0.038399\n",
      "2023-12-03 00:39:49,191 INFO     Training average positive_sample_loss at step 23200: 0.052459\n",
      "2023-12-03 00:39:49,191 INFO     Training average negative_sample_loss at step 23200: 0.020411\n",
      "2023-12-03 00:39:49,191 INFO     Training average loss at step 23200: 0.036435\n",
      "2023-12-03 00:39:55,191 INFO     Training average positive_sample_loss at step 23300: 0.054144\n",
      "2023-12-03 00:39:55,191 INFO     Training average negative_sample_loss at step 23300: 0.020304\n",
      "2023-12-03 00:39:55,191 INFO     Training average loss at step 23300: 0.037224\n",
      "2023-12-03 00:40:00,748 INFO     Training average positive_sample_loss at step 23400: 0.055479\n",
      "2023-12-03 00:40:00,748 INFO     Training average negative_sample_loss at step 23400: 0.020244\n",
      "2023-12-03 00:40:00,748 INFO     Training average loss at step 23400: 0.037861\n",
      "2023-12-03 00:40:07,282 INFO     Training average positive_sample_loss at step 23500: 0.053830\n",
      "2023-12-03 00:40:07,282 INFO     Training average negative_sample_loss at step 23500: 0.020411\n",
      "2023-12-03 00:40:07,282 INFO     Training average loss at step 23500: 0.037120\n",
      "2023-12-03 00:40:13,239 INFO     Training average positive_sample_loss at step 23600: 0.052868\n",
      "2023-12-03 00:40:13,239 INFO     Training average negative_sample_loss at step 23600: 0.020164\n",
      "2023-12-03 00:40:13,239 INFO     Training average loss at step 23600: 0.036516\n",
      "2023-12-03 00:40:19,289 INFO     Training average positive_sample_loss at step 23700: 0.054642\n",
      "2023-12-03 00:40:19,289 INFO     Training average negative_sample_loss at step 23700: 0.020175\n",
      "2023-12-03 00:40:19,289 INFO     Training average loss at step 23700: 0.037409\n",
      "2023-12-03 00:40:25,656 INFO     Training average positive_sample_loss at step 23800: 0.055629\n",
      "2023-12-03 00:40:25,657 INFO     Training average negative_sample_loss at step 23800: 0.020260\n",
      "2023-12-03 00:40:25,657 INFO     Training average loss at step 23800: 0.037944\n",
      "2023-12-03 00:40:31,553 INFO     Training average positive_sample_loss at step 23900: 0.051337\n",
      "2023-12-03 00:40:31,553 INFO     Training average negative_sample_loss at step 23900: 0.020112\n",
      "2023-12-03 00:40:31,553 INFO     Training average loss at step 23900: 0.035725\n",
      "2023-12-03 00:40:37,668 INFO     Training average positive_sample_loss at step 24000: 0.053992\n",
      "2023-12-03 00:40:37,668 INFO     Training average negative_sample_loss at step 24000: 0.020081\n",
      "2023-12-03 00:40:37,668 INFO     Training average loss at step 24000: 0.037037\n",
      "2023-12-03 00:40:43,617 INFO     Training average positive_sample_loss at step 24100: 0.054855\n",
      "2023-12-03 00:40:43,617 INFO     Training average negative_sample_loss at step 24100: 0.019989\n",
      "2023-12-03 00:40:43,617 INFO     Training average loss at step 24100: 0.037422\n",
      "2023-12-03 00:40:49,857 INFO     Training average positive_sample_loss at step 24200: 0.052258\n",
      "2023-12-03 00:40:49,857 INFO     Training average negative_sample_loss at step 24200: 0.020168\n",
      "2023-12-03 00:40:49,857 INFO     Training average loss at step 24200: 0.036213\n",
      "2023-12-03 00:40:55,907 INFO     Training average positive_sample_loss at step 24300: 0.052576\n",
      "2023-12-03 00:40:55,907 INFO     Training average negative_sample_loss at step 24300: 0.019971\n",
      "2023-12-03 00:40:55,907 INFO     Training average loss at step 24300: 0.036273\n",
      "2023-12-03 00:41:01,969 INFO     Training average positive_sample_loss at step 24400: 0.054189\n",
      "2023-12-03 00:41:01,969 INFO     Training average negative_sample_loss at step 24400: 0.019969\n",
      "2023-12-03 00:41:01,969 INFO     Training average loss at step 24400: 0.037079\n",
      "2023-12-03 00:41:08,025 INFO     Training average positive_sample_loss at step 24500: 0.054180\n",
      "2023-12-03 00:41:08,025 INFO     Training average negative_sample_loss at step 24500: 0.020061\n",
      "2023-12-03 00:41:08,025 INFO     Training average loss at step 24500: 0.037120\n",
      "2023-12-03 00:41:14,147 INFO     Training average positive_sample_loss at step 24600: 0.051554\n",
      "2023-12-03 00:41:14,147 INFO     Training average negative_sample_loss at step 24600: 0.019882\n",
      "2023-12-03 00:41:14,147 INFO     Training average loss at step 24600: 0.035718\n",
      "2023-12-03 00:41:20,135 INFO     Training average positive_sample_loss at step 24700: 0.053555\n",
      "2023-12-03 00:41:20,135 INFO     Training average negative_sample_loss at step 24700: 0.019787\n",
      "2023-12-03 00:41:20,135 INFO     Training average loss at step 24700: 0.036671\n",
      "2023-12-03 00:41:26,250 INFO     Training average positive_sample_loss at step 24800: 0.054346\n",
      "2023-12-03 00:41:26,250 INFO     Training average negative_sample_loss at step 24800: 0.019971\n",
      "2023-12-03 00:41:26,250 INFO     Training average loss at step 24800: 0.037158\n",
      "2023-12-03 00:41:32,900 INFO     Training average positive_sample_loss at step 24900: 0.051098\n",
      "2023-12-03 00:41:32,900 INFO     Training average negative_sample_loss at step 24900: 0.019969\n",
      "2023-12-03 00:41:32,901 INFO     Training average loss at step 24900: 0.035534\n",
      "2023-12-03 00:41:38,663 INFO     Training average positive_sample_loss at step 25000: 0.052248\n",
      "2023-12-03 00:41:38,663 INFO     Training average negative_sample_loss at step 25000: 0.019490\n",
      "2023-12-03 00:41:38,663 INFO     Training average loss at step 25000: 0.035869\n",
      "2023-12-03 00:41:44,816 INFO     Training average positive_sample_loss at step 25100: 0.054214\n",
      "2023-12-03 00:41:44,816 INFO     Training average negative_sample_loss at step 25100: 0.019738\n",
      "2023-12-03 00:41:44,816 INFO     Training average loss at step 25100: 0.036976\n",
      "2023-12-03 00:41:51,436 INFO     Training average positive_sample_loss at step 25200: 0.052371\n",
      "2023-12-03 00:41:51,436 INFO     Training average negative_sample_loss at step 25200: 0.019814\n",
      "2023-12-03 00:41:51,436 INFO     Training average loss at step 25200: 0.036093\n",
      "2023-12-03 00:41:57,486 INFO     Training average positive_sample_loss at step 25300: 0.051331\n",
      "2023-12-03 00:41:57,487 INFO     Training average negative_sample_loss at step 25300: 0.019715\n",
      "2023-12-03 00:41:57,487 INFO     Training average loss at step 25300: 0.035523\n",
      "2023-12-03 00:42:03,607 INFO     Training average positive_sample_loss at step 25400: 0.053319\n",
      "2023-12-03 00:42:03,607 INFO     Training average negative_sample_loss at step 25400: 0.019656\n",
      "2023-12-03 00:42:03,607 INFO     Training average loss at step 25400: 0.036488\n",
      "2023-12-03 00:42:09,868 INFO     Training average positive_sample_loss at step 25500: 0.054104\n",
      "2023-12-03 00:42:09,868 INFO     Training average negative_sample_loss at step 25500: 0.019721\n",
      "2023-12-03 00:42:09,868 INFO     Training average loss at step 25500: 0.036912\n",
      "2023-12-03 00:42:15,908 INFO     Training average positive_sample_loss at step 25600: 0.050024\n",
      "2023-12-03 00:42:15,908 INFO     Training average negative_sample_loss at step 25600: 0.019675\n",
      "2023-12-03 00:42:15,908 INFO     Training average loss at step 25600: 0.034850\n",
      "2023-12-03 00:42:22,033 INFO     Training average positive_sample_loss at step 25700: 0.052205\n",
      "2023-12-03 00:42:22,033 INFO     Training average negative_sample_loss at step 25700: 0.019524\n",
      "2023-12-03 00:42:22,033 INFO     Training average loss at step 25700: 0.035865\n",
      "2023-12-03 00:42:27,997 INFO     Training average positive_sample_loss at step 25800: 0.053702\n",
      "2023-12-03 00:42:27,998 INFO     Training average negative_sample_loss at step 25800: 0.019587\n",
      "2023-12-03 00:42:27,998 INFO     Training average loss at step 25800: 0.036644\n",
      "2023-12-03 00:42:34,422 INFO     Training average positive_sample_loss at step 25900: 0.050991\n",
      "2023-12-03 00:42:34,422 INFO     Training average negative_sample_loss at step 25900: 0.019650\n",
      "2023-12-03 00:42:34,422 INFO     Training average loss at step 25900: 0.035321\n",
      "2023-12-03 00:42:40,495 INFO     Training average positive_sample_loss at step 26000: 0.051375\n",
      "2023-12-03 00:42:40,495 INFO     Training average negative_sample_loss at step 26000: 0.019444\n",
      "2023-12-03 00:42:40,495 INFO     Training average loss at step 26000: 0.035410\n",
      "2023-12-03 00:42:46,221 INFO     Training average positive_sample_loss at step 26100: 0.052771\n",
      "2023-12-03 00:42:46,221 INFO     Training average negative_sample_loss at step 26100: 0.019428\n",
      "2023-12-03 00:42:46,221 INFO     Training average loss at step 26100: 0.036099\n",
      "2023-12-03 00:42:52,857 INFO     Training average positive_sample_loss at step 26200: 0.052844\n",
      "2023-12-03 00:42:52,857 INFO     Training average negative_sample_loss at step 26200: 0.019538\n",
      "2023-12-03 00:42:52,857 INFO     Training average loss at step 26200: 0.036191\n",
      "2023-12-03 00:42:58,952 INFO     Training average positive_sample_loss at step 26300: 0.050446\n",
      "2023-12-03 00:42:58,953 INFO     Training average negative_sample_loss at step 26300: 0.019354\n",
      "2023-12-03 00:42:58,953 INFO     Training average loss at step 26300: 0.034900\n",
      "2023-12-03 00:43:04,878 INFO     Training average positive_sample_loss at step 26400: 0.051914\n",
      "2023-12-03 00:43:04,878 INFO     Training average negative_sample_loss at step 26400: 0.019346\n",
      "2023-12-03 00:43:04,878 INFO     Training average loss at step 26400: 0.035630\n",
      "2023-12-03 00:43:10,976 INFO     Training average positive_sample_loss at step 26500: 0.053030\n",
      "2023-12-03 00:43:10,977 INFO     Training average negative_sample_loss at step 26500: 0.019659\n",
      "2023-12-03 00:43:10,977 INFO     Training average loss at step 26500: 0.036344\n",
      "2023-12-03 00:43:17,060 INFO     Training average positive_sample_loss at step 26600: 0.049836\n",
      "2023-12-03 00:43:17,060 INFO     Training average negative_sample_loss at step 26600: 0.019307\n",
      "2023-12-03 00:43:17,060 INFO     Training average loss at step 26600: 0.034572\n",
      "2023-12-03 00:43:23,144 INFO     Training average positive_sample_loss at step 26700: 0.051379\n",
      "2023-12-03 00:43:23,144 INFO     Training average negative_sample_loss at step 26700: 0.019306\n",
      "2023-12-03 00:43:23,144 INFO     Training average loss at step 26700: 0.035342\n",
      "2023-12-03 00:43:29,239 INFO     Training average positive_sample_loss at step 26800: 0.052748\n",
      "2023-12-03 00:43:29,239 INFO     Training average negative_sample_loss at step 26800: 0.019337\n",
      "2023-12-03 00:43:29,239 INFO     Training average loss at step 26800: 0.036042\n",
      "2023-12-03 00:43:35,756 INFO     Training average positive_sample_loss at step 26900: 0.050894\n",
      "2023-12-03 00:43:35,756 INFO     Training average negative_sample_loss at step 26900: 0.019360\n",
      "2023-12-03 00:43:35,756 INFO     Training average loss at step 26900: 0.035127\n",
      "2023-12-03 00:43:41,791 INFO     Training average positive_sample_loss at step 27000: 0.050568\n",
      "2023-12-03 00:43:41,791 INFO     Training average negative_sample_loss at step 27000: 0.019360\n",
      "2023-12-03 00:43:41,791 INFO     Training average loss at step 27000: 0.034964\n",
      "2023-12-03 00:43:47,246 INFO     Training average positive_sample_loss at step 27100: 0.051785\n",
      "2023-12-03 00:43:47,246 INFO     Training average negative_sample_loss at step 27100: 0.019205\n",
      "2023-12-03 00:43:47,246 INFO     Training average loss at step 27100: 0.035495\n",
      "2023-12-03 00:43:53,570 INFO     Training average positive_sample_loss at step 27200: 0.052677\n",
      "2023-12-03 00:43:53,570 INFO     Training average negative_sample_loss at step 27200: 0.019192\n",
      "2023-12-03 00:43:53,570 INFO     Training average loss at step 27200: 0.035934\n",
      "2023-12-03 00:43:59,912 INFO     Training average positive_sample_loss at step 27300: 0.048792\n",
      "2023-12-03 00:43:59,912 INFO     Training average negative_sample_loss at step 27300: 0.019159\n",
      "2023-12-03 00:43:59,912 INFO     Training average loss at step 27300: 0.033975\n",
      "2023-12-03 00:44:05,970 INFO     Training average positive_sample_loss at step 27400: 0.051289\n",
      "2023-12-03 00:44:05,970 INFO     Training average negative_sample_loss at step 27400: 0.019158\n",
      "2023-12-03 00:44:05,970 INFO     Training average loss at step 27400: 0.035223\n",
      "2023-12-03 00:44:12,023 INFO     Training average positive_sample_loss at step 27500: 0.052147\n",
      "2023-12-03 00:44:12,024 INFO     Training average negative_sample_loss at step 27500: 0.019174\n",
      "2023-12-03 00:44:12,024 INFO     Training average loss at step 27500: 0.035660\n",
      "2023-12-03 00:44:18,377 INFO     Training average positive_sample_loss at step 27600: 0.050010\n",
      "2023-12-03 00:44:18,378 INFO     Training average negative_sample_loss at step 27600: 0.019201\n",
      "2023-12-03 00:44:18,378 INFO     Training average loss at step 27600: 0.034606\n",
      "2023-12-03 00:44:24,017 INFO     Training average positive_sample_loss at step 27700: 0.050217\n",
      "2023-12-03 00:44:24,017 INFO     Training average negative_sample_loss at step 27700: 0.019126\n",
      "2023-12-03 00:44:24,017 INFO     Training average loss at step 27700: 0.034672\n",
      "2023-12-03 00:44:30,145 INFO     Training average positive_sample_loss at step 27800: 0.051830\n",
      "2023-12-03 00:44:30,145 INFO     Training average negative_sample_loss at step 27800: 0.019130\n",
      "2023-12-03 00:44:30,145 INFO     Training average loss at step 27800: 0.035480\n",
      "2023-12-03 00:44:36,792 INFO     Training average positive_sample_loss at step 27900: 0.051378\n",
      "2023-12-03 00:44:36,792 INFO     Training average negative_sample_loss at step 27900: 0.019016\n",
      "2023-12-03 00:44:36,792 INFO     Training average loss at step 27900: 0.035197\n",
      "2023-12-03 00:44:42,912 INFO     Training average positive_sample_loss at step 28000: 0.048904\n",
      "2023-12-03 00:44:42,912 INFO     Training average negative_sample_loss at step 28000: 0.018883\n",
      "2023-12-03 00:44:42,912 INFO     Training average loss at step 28000: 0.033893\n",
      "2023-12-03 00:44:48,795 INFO     Training average positive_sample_loss at step 28100: 0.050934\n",
      "2023-12-03 00:44:48,795 INFO     Training average negative_sample_loss at step 28100: 0.018934\n",
      "2023-12-03 00:44:48,795 INFO     Training average loss at step 28100: 0.034934\n",
      "2023-12-03 00:44:54,584 INFO     Training average positive_sample_loss at step 28200: 0.052340\n",
      "2023-12-03 00:44:54,584 INFO     Training average negative_sample_loss at step 28200: 0.019054\n",
      "2023-12-03 00:44:54,584 INFO     Training average loss at step 28200: 0.035697\n",
      "2023-12-03 00:45:00,890 INFO     Training average positive_sample_loss at step 28300: 0.048895\n",
      "2023-12-03 00:45:00,891 INFO     Training average negative_sample_loss at step 28300: 0.019043\n",
      "2023-12-03 00:45:00,891 INFO     Training average loss at step 28300: 0.033969\n",
      "2023-12-03 00:45:07,006 INFO     Training average positive_sample_loss at step 28400: 0.050045\n",
      "2023-12-03 00:45:07,006 INFO     Training average negative_sample_loss at step 28400: 0.018943\n",
      "2023-12-03 00:45:07,006 INFO     Training average loss at step 28400: 0.034494\n",
      "2023-12-03 00:45:13,086 INFO     Training average positive_sample_loss at step 28500: 0.051268\n",
      "2023-12-03 00:45:13,086 INFO     Training average negative_sample_loss at step 28500: 0.018880\n",
      "2023-12-03 00:45:13,086 INFO     Training average loss at step 28500: 0.035074\n",
      "2023-12-03 00:45:19,363 INFO     Training average positive_sample_loss at step 28600: 0.050378\n",
      "2023-12-03 00:45:19,364 INFO     Training average negative_sample_loss at step 28600: 0.019007\n",
      "2023-12-03 00:45:19,364 INFO     Training average loss at step 28600: 0.034693\n",
      "2023-12-03 00:45:25,292 INFO     Training average positive_sample_loss at step 28700: 0.048931\n",
      "2023-12-03 00:45:25,293 INFO     Training average negative_sample_loss at step 28700: 0.018747\n",
      "2023-12-03 00:45:25,293 INFO     Training average loss at step 28700: 0.033839\n",
      "2023-12-03 00:45:31,076 INFO     Training average positive_sample_loss at step 28800: 0.050879\n",
      "2023-12-03 00:45:31,076 INFO     Training average negative_sample_loss at step 28800: 0.018887\n",
      "2023-12-03 00:45:31,076 INFO     Training average loss at step 28800: 0.034883\n",
      "2023-12-03 00:45:37,482 INFO     Training average positive_sample_loss at step 28900: 0.051956\n",
      "2023-12-03 00:45:37,482 INFO     Training average negative_sample_loss at step 28900: 0.018974\n",
      "2023-12-03 00:45:37,482 INFO     Training average loss at step 28900: 0.035465\n",
      "2023-12-03 00:45:43,943 INFO     Training average positive_sample_loss at step 29000: 0.047846\n",
      "2023-12-03 00:45:43,943 INFO     Training average negative_sample_loss at step 29000: 0.018899\n",
      "2023-12-03 00:45:43,944 INFO     Training average loss at step 29000: 0.033372\n",
      "2023-12-03 00:45:50,028 INFO     Training average positive_sample_loss at step 29100: 0.050158\n",
      "2023-12-03 00:45:50,028 INFO     Training average negative_sample_loss at step 29100: 0.018762\n",
      "2023-12-03 00:45:50,028 INFO     Training average loss at step 29100: 0.034460\n",
      "2023-12-03 00:45:56,053 INFO     Training average positive_sample_loss at step 29200: 0.051244\n",
      "2023-12-03 00:45:56,053 INFO     Training average negative_sample_loss at step 29200: 0.018754\n",
      "2023-12-03 00:45:56,053 INFO     Training average loss at step 29200: 0.034999\n",
      "2023-12-03 00:46:02,523 INFO     Training average positive_sample_loss at step 29300: 0.049147\n",
      "2023-12-03 00:46:02,523 INFO     Training average negative_sample_loss at step 29300: 0.018881\n",
      "2023-12-03 00:46:02,523 INFO     Training average loss at step 29300: 0.034014\n",
      "2023-12-03 00:46:08,249 INFO     Training average positive_sample_loss at step 29400: 0.049028\n",
      "2023-12-03 00:46:08,249 INFO     Training average negative_sample_loss at step 29400: 0.018604\n",
      "2023-12-03 00:46:08,249 INFO     Training average loss at step 29400: 0.033816\n",
      "2023-12-03 00:46:14,358 INFO     Training average positive_sample_loss at step 29500: 0.050621\n",
      "2023-12-03 00:46:14,358 INFO     Training average negative_sample_loss at step 29500: 0.018695\n",
      "2023-12-03 00:46:14,358 INFO     Training average loss at step 29500: 0.034658\n",
      "2023-12-03 00:46:20,959 INFO     Training average positive_sample_loss at step 29600: 0.050495\n",
      "2023-12-03 00:46:20,960 INFO     Training average negative_sample_loss at step 29600: 0.018777\n",
      "2023-12-03 00:46:20,960 INFO     Training average loss at step 29600: 0.034636\n",
      "2023-12-03 00:46:27,044 INFO     Training average positive_sample_loss at step 29700: 0.048240\n",
      "2023-12-03 00:46:27,044 INFO     Training average negative_sample_loss at step 29700: 0.018800\n",
      "2023-12-03 00:46:27,044 INFO     Training average loss at step 29700: 0.033520\n",
      "2023-12-03 00:46:32,981 INFO     Training average positive_sample_loss at step 29800: 0.049935\n",
      "2023-12-03 00:46:32,981 INFO     Training average negative_sample_loss at step 29800: 0.018602\n",
      "2023-12-03 00:46:32,981 INFO     Training average loss at step 29800: 0.034269\n",
      "2023-12-03 00:46:38,954 INFO     Training average positive_sample_loss at step 29900: 0.051085\n",
      "2023-12-03 00:46:38,954 INFO     Training average negative_sample_loss at step 29900: 0.018647\n",
      "2023-12-03 00:46:38,954 INFO     Training average loss at step 29900: 0.034866\n",
      "2023-12-03 00:46:56,810 INFO     Training average positive_sample_loss at step 30000: 0.048033\n",
      "2023-12-03 00:46:56,810 INFO     Training average negative_sample_loss at step 30000: 0.018746\n",
      "2023-12-03 00:46:56,810 INFO     Training average loss at step 30000: 0.033390\n",
      "2023-12-03 00:46:56,810 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:46:57,847 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:47:30,607 INFO     Valid MRR at step 30000: 0.480568\n",
      "2023-12-03 00:47:30,607 INFO     Valid MR at step 30000: 3693.904252\n",
      "2023-12-03 00:47:30,607 INFO     Valid HITS@1 at step 30000: 0.437376\n",
      "2023-12-03 00:47:30,607 INFO     Valid HITS@3 at step 30000: 0.495056\n",
      "2023-12-03 00:47:30,607 INFO     Valid HITS@10 at step 30000: 0.565755\n",
      "2023-12-03 00:47:36,696 INFO     Training average positive_sample_loss at step 30100: 0.049248\n",
      "2023-12-03 00:47:36,696 INFO     Training average negative_sample_loss at step 30100: 0.018591\n",
      "2023-12-03 00:47:36,696 INFO     Training average loss at step 30100: 0.033919\n",
      "2023-12-03 00:47:42,672 INFO     Training average positive_sample_loss at step 30200: 0.050491\n",
      "2023-12-03 00:47:42,673 INFO     Training average negative_sample_loss at step 30200: 0.018540\n",
      "2023-12-03 00:47:42,673 INFO     Training average loss at step 30200: 0.034515\n",
      "2023-12-03 00:47:49,430 INFO     Training average positive_sample_loss at step 30300: 0.049122\n",
      "2023-12-03 00:47:49,430 INFO     Training average negative_sample_loss at step 30300: 0.018731\n",
      "2023-12-03 00:47:49,430 INFO     Training average loss at step 30300: 0.033927\n",
      "2023-12-03 00:47:55,542 INFO     Training average positive_sample_loss at step 30400: 0.048112\n",
      "2023-12-03 00:47:55,543 INFO     Training average negative_sample_loss at step 30400: 0.018633\n",
      "2023-12-03 00:47:55,543 INFO     Training average loss at step 30400: 0.033372\n",
      "2023-12-03 00:48:01,213 INFO     Training average positive_sample_loss at step 30500: 0.050081\n",
      "2023-12-03 00:48:01,214 INFO     Training average negative_sample_loss at step 30500: 0.018594\n",
      "2023-12-03 00:48:01,214 INFO     Training average loss at step 30500: 0.034338\n",
      "2023-12-03 00:48:07,527 INFO     Training average positive_sample_loss at step 30600: 0.050843\n",
      "2023-12-03 00:48:07,527 INFO     Training average negative_sample_loss at step 30600: 0.018663\n",
      "2023-12-03 00:48:07,527 INFO     Training average loss at step 30600: 0.034753\n",
      "2023-12-03 00:48:13,871 INFO     Training average positive_sample_loss at step 30700: 0.047119\n",
      "2023-12-03 00:48:13,871 INFO     Training average negative_sample_loss at step 30700: 0.018615\n",
      "2023-12-03 00:48:13,871 INFO     Training average loss at step 30700: 0.032867\n",
      "2023-12-03 00:48:19,765 INFO     Training average positive_sample_loss at step 30800: 0.049169\n",
      "2023-12-03 00:48:19,766 INFO     Training average negative_sample_loss at step 30800: 0.018429\n",
      "2023-12-03 00:48:19,766 INFO     Training average loss at step 30800: 0.033799\n",
      "2023-12-03 00:48:25,908 INFO     Training average positive_sample_loss at step 30900: 0.050379\n",
      "2023-12-03 00:48:25,909 INFO     Training average negative_sample_loss at step 30900: 0.018437\n",
      "2023-12-03 00:48:25,909 INFO     Training average loss at step 30900: 0.034408\n",
      "2023-12-03 00:48:32,501 INFO     Training average positive_sample_loss at step 31000: 0.048253\n",
      "2023-12-03 00:48:32,501 INFO     Training average negative_sample_loss at step 31000: 0.018605\n",
      "2023-12-03 00:48:32,501 INFO     Training average loss at step 31000: 0.033429\n",
      "2023-12-03 00:48:38,191 INFO     Training average positive_sample_loss at step 31100: 0.048425\n",
      "2023-12-03 00:48:38,192 INFO     Training average negative_sample_loss at step 31100: 0.018439\n",
      "2023-12-03 00:48:38,192 INFO     Training average loss at step 31100: 0.033432\n",
      "2023-12-03 00:48:44,356 INFO     Training average positive_sample_loss at step 31200: 0.049774\n",
      "2023-12-03 00:48:44,357 INFO     Training average negative_sample_loss at step 31200: 0.018532\n",
      "2023-12-03 00:48:44,357 INFO     Training average loss at step 31200: 0.034153\n",
      "2023-12-03 00:48:51,123 INFO     Training average positive_sample_loss at step 31300: 0.049288\n",
      "2023-12-03 00:48:51,124 INFO     Training average negative_sample_loss at step 31300: 0.018440\n",
      "2023-12-03 00:48:51,124 INFO     Training average loss at step 31300: 0.033864\n",
      "2023-12-03 00:48:57,018 INFO     Training average positive_sample_loss at step 31400: 0.047324\n",
      "2023-12-03 00:48:57,019 INFO     Training average negative_sample_loss at step 31400: 0.018414\n",
      "2023-12-03 00:48:57,019 INFO     Training average loss at step 31400: 0.032869\n",
      "2023-12-03 00:49:03,169 INFO     Training average positive_sample_loss at step 31500: 0.049157\n",
      "2023-12-03 00:49:03,169 INFO     Training average negative_sample_loss at step 31500: 0.018324\n",
      "2023-12-03 00:49:03,170 INFO     Training average loss at step 31500: 0.033741\n",
      "2023-12-03 00:49:09,107 INFO     Training average positive_sample_loss at step 31600: 0.050457\n",
      "2023-12-03 00:49:09,107 INFO     Training average negative_sample_loss at step 31600: 0.018436\n",
      "2023-12-03 00:49:09,107 INFO     Training average loss at step 31600: 0.034447\n",
      "2023-12-03 00:49:15,593 INFO     Training average positive_sample_loss at step 31700: 0.046976\n",
      "2023-12-03 00:49:15,593 INFO     Training average negative_sample_loss at step 31700: 0.018330\n",
      "2023-12-03 00:49:15,593 INFO     Training average loss at step 31700: 0.032653\n",
      "2023-12-03 00:49:21,660 INFO     Training average positive_sample_loss at step 31800: 0.048456\n",
      "2023-12-03 00:49:21,660 INFO     Training average negative_sample_loss at step 31800: 0.018408\n",
      "2023-12-03 00:49:21,660 INFO     Training average loss at step 31800: 0.033432\n",
      "2023-12-03 00:49:27,603 INFO     Training average positive_sample_loss at step 31900: 0.049664\n",
      "2023-12-03 00:49:27,604 INFO     Training average negative_sample_loss at step 31900: 0.018335\n",
      "2023-12-03 00:49:27,604 INFO     Training average loss at step 31900: 0.034000\n",
      "2023-12-03 00:49:34,311 INFO     Training average positive_sample_loss at step 32000: 0.048735\n",
      "2023-12-03 00:49:34,311 INFO     Training average negative_sample_loss at step 32000: 0.018356\n",
      "2023-12-03 00:49:34,311 INFO     Training average loss at step 32000: 0.033546\n",
      "2023-12-03 00:49:40,209 INFO     Training average positive_sample_loss at step 32100: 0.047591\n",
      "2023-12-03 00:49:40,210 INFO     Training average negative_sample_loss at step 32100: 0.018412\n",
      "2023-12-03 00:49:40,210 INFO     Training average loss at step 32100: 0.033002\n",
      "2023-12-03 00:49:46,339 INFO     Training average positive_sample_loss at step 32200: 0.049122\n",
      "2023-12-03 00:49:46,339 INFO     Training average negative_sample_loss at step 32200: 0.018330\n",
      "2023-12-03 00:49:46,339 INFO     Training average loss at step 32200: 0.033726\n",
      "2023-12-03 00:49:52,586 INFO     Training average positive_sample_loss at step 32300: 0.049801\n",
      "2023-12-03 00:49:52,587 INFO     Training average negative_sample_loss at step 32300: 0.018420\n",
      "2023-12-03 00:49:52,587 INFO     Training average loss at step 32300: 0.034111\n",
      "2023-12-03 00:49:58,805 INFO     Training average positive_sample_loss at step 32400: 0.046229\n",
      "2023-12-03 00:49:58,806 INFO     Training average negative_sample_loss at step 32400: 0.018249\n",
      "2023-12-03 00:49:58,806 INFO     Training average loss at step 32400: 0.032239\n",
      "2023-12-03 00:50:04,888 INFO     Training average positive_sample_loss at step 32500: 0.048613\n",
      "2023-12-03 00:50:04,889 INFO     Training average negative_sample_loss at step 32500: 0.018286\n",
      "2023-12-03 00:50:04,889 INFO     Training average loss at step 32500: 0.033450\n",
      "2023-12-03 00:50:10,892 INFO     Training average positive_sample_loss at step 32600: 0.049710\n",
      "2023-12-03 00:50:10,893 INFO     Training average negative_sample_loss at step 32600: 0.018404\n",
      "2023-12-03 00:50:10,893 INFO     Training average loss at step 32600: 0.034057\n",
      "2023-12-03 00:50:17,464 INFO     Training average positive_sample_loss at step 32700: 0.047376\n",
      "2023-12-03 00:50:17,465 INFO     Training average negative_sample_loss at step 32700: 0.018325\n",
      "2023-12-03 00:50:17,465 INFO     Training average loss at step 32700: 0.032850\n",
      "2023-12-03 00:50:23,599 INFO     Training average positive_sample_loss at step 32800: 0.047578\n",
      "2023-12-03 00:50:23,599 INFO     Training average negative_sample_loss at step 32800: 0.018207\n",
      "2023-12-03 00:50:23,599 INFO     Training average loss at step 32800: 0.032892\n",
      "2023-12-03 00:50:29,724 INFO     Training average positive_sample_loss at step 32900: 0.049148\n",
      "2023-12-03 00:50:29,724 INFO     Training average negative_sample_loss at step 32900: 0.018246\n",
      "2023-12-03 00:50:29,724 INFO     Training average loss at step 32900: 0.033697\n",
      "2023-12-03 00:50:35,872 INFO     Training average positive_sample_loss at step 33000: 0.048614\n",
      "2023-12-03 00:50:35,873 INFO     Training average negative_sample_loss at step 33000: 0.018143\n",
      "2023-12-03 00:50:35,873 INFO     Training average loss at step 33000: 0.033378\n",
      "2023-12-03 00:50:41,588 INFO     Training average positive_sample_loss at step 33100: 0.046695\n",
      "2023-12-03 00:50:41,588 INFO     Training average negative_sample_loss at step 33100: 0.018154\n",
      "2023-12-03 00:50:41,588 INFO     Training average loss at step 33100: 0.032424\n",
      "2023-12-03 00:50:47,148 INFO     Training average positive_sample_loss at step 33200: 0.048445\n",
      "2023-12-03 00:50:47,149 INFO     Training average negative_sample_loss at step 33200: 0.018262\n",
      "2023-12-03 00:50:47,149 INFO     Training average loss at step 33200: 0.033353\n",
      "2023-12-03 00:50:53,365 INFO     Training average positive_sample_loss at step 33300: 0.049651\n",
      "2023-12-03 00:50:53,366 INFO     Training average negative_sample_loss at step 33300: 0.018302\n",
      "2023-12-03 00:50:53,366 INFO     Training average loss at step 33300: 0.033977\n",
      "2023-12-03 00:50:59,498 INFO     Training average positive_sample_loss at step 33400: 0.046456\n",
      "2023-12-03 00:50:59,498 INFO     Training average negative_sample_loss at step 33400: 0.018167\n",
      "2023-12-03 00:50:59,498 INFO     Training average loss at step 33400: 0.032312\n",
      "2023-12-03 00:51:05,596 INFO     Training average positive_sample_loss at step 33500: 0.047695\n",
      "2023-12-03 00:51:05,597 INFO     Training average negative_sample_loss at step 33500: 0.017995\n",
      "2023-12-03 00:51:05,597 INFO     Training average loss at step 33500: 0.032845\n",
      "2023-12-03 00:51:11,760 INFO     Training average positive_sample_loss at step 33600: 0.049067\n",
      "2023-12-03 00:51:11,761 INFO     Training average negative_sample_loss at step 33600: 0.018223\n",
      "2023-12-03 00:51:11,761 INFO     Training average loss at step 33600: 0.033645\n",
      "2023-12-03 00:51:18,096 INFO     Training average positive_sample_loss at step 33700: 0.047640\n",
      "2023-12-03 00:51:18,096 INFO     Training average negative_sample_loss at step 33700: 0.018308\n",
      "2023-12-03 00:51:18,096 INFO     Training average loss at step 33700: 0.032974\n",
      "2023-12-03 00:51:24,283 INFO     Training average positive_sample_loss at step 33800: 0.046908\n",
      "2023-12-03 00:51:24,283 INFO     Training average negative_sample_loss at step 33800: 0.018125\n",
      "2023-12-03 00:51:24,284 INFO     Training average loss at step 33800: 0.032517\n",
      "2023-12-03 00:51:29,848 INFO     Training average positive_sample_loss at step 33900: 0.048543\n",
      "2023-12-03 00:51:29,849 INFO     Training average negative_sample_loss at step 33900: 0.018050\n",
      "2023-12-03 00:51:29,849 INFO     Training average loss at step 33900: 0.033297\n",
      "2023-12-03 00:51:36,033 INFO     Training average positive_sample_loss at step 34000: 0.049242\n",
      "2023-12-03 00:51:36,033 INFO     Training average negative_sample_loss at step 34000: 0.018176\n",
      "2023-12-03 00:51:36,034 INFO     Training average loss at step 34000: 0.033709\n",
      "2023-12-03 00:51:42,331 INFO     Training average positive_sample_loss at step 34100: 0.045685\n",
      "2023-12-03 00:51:42,331 INFO     Training average negative_sample_loss at step 34100: 0.018203\n",
      "2023-12-03 00:51:42,331 INFO     Training average loss at step 34100: 0.031944\n",
      "2023-12-03 00:51:48,476 INFO     Training average positive_sample_loss at step 34200: 0.047766\n",
      "2023-12-03 00:51:48,476 INFO     Training average negative_sample_loss at step 34200: 0.018117\n",
      "2023-12-03 00:51:48,476 INFO     Training average loss at step 34200: 0.032942\n",
      "2023-12-03 00:51:54,650 INFO     Training average positive_sample_loss at step 34300: 0.049100\n",
      "2023-12-03 00:51:54,650 INFO     Training average negative_sample_loss at step 34300: 0.018082\n",
      "2023-12-03 00:51:54,650 INFO     Training average loss at step 34300: 0.033591\n",
      "2023-12-03 00:52:00,745 INFO     Training average positive_sample_loss at step 34400: 0.046564\n",
      "2023-12-03 00:52:00,746 INFO     Training average negative_sample_loss at step 34400: 0.018088\n",
      "2023-12-03 00:52:00,746 INFO     Training average loss at step 34400: 0.032326\n",
      "2023-12-03 00:52:06,898 INFO     Training average positive_sample_loss at step 34500: 0.047035\n",
      "2023-12-03 00:52:06,898 INFO     Training average negative_sample_loss at step 34500: 0.017974\n",
      "2023-12-03 00:52:06,898 INFO     Training average loss at step 34500: 0.032505\n",
      "2023-12-03 00:52:13,060 INFO     Training average positive_sample_loss at step 34600: 0.048494\n",
      "2023-12-03 00:52:13,060 INFO     Training average negative_sample_loss at step 34600: 0.018038\n",
      "2023-12-03 00:52:13,060 INFO     Training average loss at step 34600: 0.033266\n",
      "2023-12-03 00:52:19,742 INFO     Training average positive_sample_loss at step 34700: 0.048265\n",
      "2023-12-03 00:52:19,743 INFO     Training average negative_sample_loss at step 34700: 0.018206\n",
      "2023-12-03 00:52:19,743 INFO     Training average loss at step 34700: 0.033236\n",
      "2023-12-03 00:52:25,733 INFO     Training average positive_sample_loss at step 34800: 0.046229\n",
      "2023-12-03 00:52:25,734 INFO     Training average negative_sample_loss at step 34800: 0.018081\n",
      "2023-12-03 00:52:25,734 INFO     Training average loss at step 34800: 0.032155\n",
      "2023-12-03 00:52:31,405 INFO     Training average positive_sample_loss at step 34900: 0.047460\n",
      "2023-12-03 00:52:31,405 INFO     Training average negative_sample_loss at step 34900: 0.017866\n",
      "2023-12-03 00:52:31,405 INFO     Training average loss at step 34900: 0.032663\n",
      "2023-12-03 00:52:37,495 INFO     Training average positive_sample_loss at step 35000: 0.049139\n",
      "2023-12-03 00:52:37,495 INFO     Training average negative_sample_loss at step 35000: 0.018078\n",
      "2023-12-03 00:52:37,495 INFO     Training average loss at step 35000: 0.033608\n",
      "2023-12-03 00:52:43,658 INFO     Training average positive_sample_loss at step 35100: 0.045904\n",
      "2023-12-03 00:52:43,658 INFO     Training average negative_sample_loss at step 35100: 0.018035\n",
      "2023-12-03 00:52:43,658 INFO     Training average loss at step 35100: 0.031970\n",
      "2023-12-03 00:52:49,657 INFO     Training average positive_sample_loss at step 35200: 0.047006\n",
      "2023-12-03 00:52:49,657 INFO     Training average negative_sample_loss at step 35200: 0.017838\n",
      "2023-12-03 00:52:49,657 INFO     Training average loss at step 35200: 0.032422\n",
      "2023-12-03 00:52:55,755 INFO     Training average positive_sample_loss at step 35300: 0.048470\n",
      "2023-12-03 00:52:55,756 INFO     Training average negative_sample_loss at step 35300: 0.018208\n",
      "2023-12-03 00:52:55,756 INFO     Training average loss at step 35300: 0.033339\n",
      "2023-12-03 00:53:02,411 INFO     Training average positive_sample_loss at step 35400: 0.047396\n",
      "2023-12-03 00:53:02,411 INFO     Training average negative_sample_loss at step 35400: 0.018069\n",
      "2023-12-03 00:53:02,411 INFO     Training average loss at step 35400: 0.032732\n",
      "2023-12-03 00:53:08,103 INFO     Training average positive_sample_loss at step 35500: 0.046466\n",
      "2023-12-03 00:53:08,104 INFO     Training average negative_sample_loss at step 35500: 0.018080\n",
      "2023-12-03 00:53:08,104 INFO     Training average loss at step 35500: 0.032273\n",
      "2023-12-03 00:53:14,229 INFO     Training average positive_sample_loss at step 35600: 0.047487\n",
      "2023-12-03 00:53:14,229 INFO     Training average negative_sample_loss at step 35600: 0.017970\n",
      "2023-12-03 00:53:14,229 INFO     Training average loss at step 35600: 0.032728\n",
      "2023-12-03 00:53:20,648 INFO     Training average positive_sample_loss at step 35700: 0.048810\n",
      "2023-12-03 00:53:20,648 INFO     Training average negative_sample_loss at step 35700: 0.017993\n",
      "2023-12-03 00:53:20,648 INFO     Training average loss at step 35700: 0.033402\n",
      "2023-12-03 00:53:27,033 INFO     Training average positive_sample_loss at step 35800: 0.045364\n",
      "2023-12-03 00:53:27,034 INFO     Training average negative_sample_loss at step 35800: 0.017922\n",
      "2023-12-03 00:53:27,034 INFO     Training average loss at step 35800: 0.031643\n",
      "2023-12-03 00:53:33,015 INFO     Training average positive_sample_loss at step 35900: 0.047223\n",
      "2023-12-03 00:53:33,016 INFO     Training average negative_sample_loss at step 35900: 0.018021\n",
      "2023-12-03 00:53:33,016 INFO     Training average loss at step 35900: 0.032622\n",
      "2023-12-03 00:53:39,170 INFO     Training average positive_sample_loss at step 36000: 0.048310\n",
      "2023-12-03 00:53:39,171 INFO     Training average negative_sample_loss at step 36000: 0.017969\n",
      "2023-12-03 00:53:39,171 INFO     Training average loss at step 36000: 0.033140\n",
      "2023-12-03 00:53:45,851 INFO     Training average positive_sample_loss at step 36100: 0.046373\n",
      "2023-12-03 00:53:45,852 INFO     Training average negative_sample_loss at step 36100: 0.017818\n",
      "2023-12-03 00:53:45,852 INFO     Training average loss at step 36100: 0.032096\n",
      "2023-12-03 00:53:51,450 INFO     Training average positive_sample_loss at step 36200: 0.046421\n",
      "2023-12-03 00:53:51,451 INFO     Training average negative_sample_loss at step 36200: 0.017961\n",
      "2023-12-03 00:53:51,451 INFO     Training average loss at step 36200: 0.032191\n",
      "2023-12-03 00:53:57,637 INFO     Training average positive_sample_loss at step 36300: 0.047885\n",
      "2023-12-03 00:53:57,637 INFO     Training average negative_sample_loss at step 36300: 0.017848\n",
      "2023-12-03 00:53:57,637 INFO     Training average loss at step 36300: 0.032867\n",
      "2023-12-03 00:54:04,316 INFO     Training average positive_sample_loss at step 36400: 0.047358\n",
      "2023-12-03 00:54:04,316 INFO     Training average negative_sample_loss at step 36400: 0.017883\n",
      "2023-12-03 00:54:04,316 INFO     Training average loss at step 36400: 0.032620\n",
      "2023-12-03 00:54:10,456 INFO     Training average positive_sample_loss at step 36500: 0.045489\n",
      "2023-12-03 00:54:10,457 INFO     Training average negative_sample_loss at step 36500: 0.017863\n",
      "2023-12-03 00:54:10,457 INFO     Training average loss at step 36500: 0.031676\n",
      "2023-12-03 00:54:16,458 INFO     Training average positive_sample_loss at step 36600: 0.047163\n",
      "2023-12-03 00:54:16,458 INFO     Training average negative_sample_loss at step 36600: 0.017815\n",
      "2023-12-03 00:54:16,458 INFO     Training average loss at step 36600: 0.032489\n",
      "2023-12-03 00:54:22,083 INFO     Training average positive_sample_loss at step 36700: 0.048570\n",
      "2023-12-03 00:54:22,083 INFO     Training average negative_sample_loss at step 36700: 0.017916\n",
      "2023-12-03 00:54:22,083 INFO     Training average loss at step 36700: 0.033243\n",
      "2023-12-03 00:54:28,674 INFO     Training average positive_sample_loss at step 36800: 0.045343\n",
      "2023-12-03 00:54:28,674 INFO     Training average negative_sample_loss at step 36800: 0.017871\n",
      "2023-12-03 00:54:28,674 INFO     Training average loss at step 36800: 0.031607\n",
      "2023-12-03 00:54:34,801 INFO     Training average positive_sample_loss at step 36900: 0.046746\n",
      "2023-12-03 00:54:34,801 INFO     Training average negative_sample_loss at step 36900: 0.017813\n",
      "2023-12-03 00:54:34,801 INFO     Training average loss at step 36900: 0.032280\n",
      "2023-12-03 00:54:40,924 INFO     Training average positive_sample_loss at step 37000: 0.048013\n",
      "2023-12-03 00:54:40,924 INFO     Training average negative_sample_loss at step 37000: 0.017926\n",
      "2023-12-03 00:54:40,924 INFO     Training average loss at step 37000: 0.032969\n",
      "2023-12-03 00:54:47,443 INFO     Training average positive_sample_loss at step 37100: 0.046387\n",
      "2023-12-03 00:54:47,444 INFO     Training average negative_sample_loss at step 37100: 0.017782\n",
      "2023-12-03 00:54:47,444 INFO     Training average loss at step 37100: 0.032085\n",
      "2023-12-03 00:54:53,215 INFO     Training average positive_sample_loss at step 37200: 0.045626\n",
      "2023-12-03 00:54:53,216 INFO     Training average negative_sample_loss at step 37200: 0.017691\n",
      "2023-12-03 00:54:53,216 INFO     Training average loss at step 37200: 0.031659\n",
      "2023-12-03 00:54:59,359 INFO     Training average positive_sample_loss at step 37300: 0.047643\n",
      "2023-12-03 00:54:59,359 INFO     Training average negative_sample_loss at step 37300: 0.017947\n",
      "2023-12-03 00:54:59,359 INFO     Training average loss at step 37300: 0.032795\n",
      "2023-12-03 00:55:05,523 INFO     Training average positive_sample_loss at step 37400: 0.048160\n",
      "2023-12-03 00:55:05,524 INFO     Training average negative_sample_loss at step 37400: 0.017849\n",
      "2023-12-03 00:55:05,524 INFO     Training average loss at step 37400: 0.033005\n",
      "2023-12-03 00:55:11,910 INFO     Training average positive_sample_loss at step 37500: 0.044627\n",
      "2023-12-03 00:55:11,910 INFO     Training average negative_sample_loss at step 37500: 0.017818\n",
      "2023-12-03 00:55:11,911 INFO     Training average loss at step 37500: 0.031222\n",
      "2023-12-03 00:55:18,019 INFO     Training average positive_sample_loss at step 37600: 0.046817\n",
      "2023-12-03 00:55:18,020 INFO     Training average negative_sample_loss at step 37600: 0.017725\n",
      "2023-12-03 00:55:18,020 INFO     Training average loss at step 37600: 0.032271\n",
      "2023-12-03 00:55:23,762 INFO     Training average positive_sample_loss at step 37700: 0.047912\n",
      "2023-12-03 00:55:23,762 INFO     Training average negative_sample_loss at step 37700: 0.017745\n",
      "2023-12-03 00:55:23,762 INFO     Training average loss at step 37700: 0.032829\n",
      "2023-12-03 00:55:30,405 INFO     Training average positive_sample_loss at step 37800: 0.045613\n",
      "2023-12-03 00:55:30,405 INFO     Training average negative_sample_loss at step 37800: 0.017563\n",
      "2023-12-03 00:55:30,405 INFO     Training average loss at step 37800: 0.031588\n",
      "2023-12-03 00:55:36,498 INFO     Training average positive_sample_loss at step 37900: 0.046199\n",
      "2023-12-03 00:55:36,498 INFO     Training average negative_sample_loss at step 37900: 0.017737\n",
      "2023-12-03 00:55:36,498 INFO     Training average loss at step 37900: 0.031968\n",
      "2023-12-03 00:55:42,356 INFO     Training average positive_sample_loss at step 38000: 0.047531\n",
      "2023-12-03 00:55:42,356 INFO     Training average negative_sample_loss at step 38000: 0.017682\n",
      "2023-12-03 00:55:42,356 INFO     Training average loss at step 38000: 0.032607\n",
      "2023-12-03 00:55:48,730 INFO     Training average positive_sample_loss at step 38100: 0.046855\n",
      "2023-12-03 00:55:48,731 INFO     Training average negative_sample_loss at step 38100: 0.017810\n",
      "2023-12-03 00:55:48,731 INFO     Training average loss at step 38100: 0.032333\n",
      "2023-12-03 00:55:54,453 INFO     Training average positive_sample_loss at step 38200: 0.045076\n",
      "2023-12-03 00:55:54,453 INFO     Training average negative_sample_loss at step 38200: 0.017718\n",
      "2023-12-03 00:55:54,453 INFO     Training average loss at step 38200: 0.031397\n",
      "2023-12-03 00:56:00,561 INFO     Training average positive_sample_loss at step 38300: 0.046941\n",
      "2023-12-03 00:56:00,561 INFO     Training average negative_sample_loss at step 38300: 0.017752\n",
      "2023-12-03 00:56:00,561 INFO     Training average loss at step 38300: 0.032347\n",
      "2023-12-03 00:56:06,451 INFO     Training average positive_sample_loss at step 38400: 0.047663\n",
      "2023-12-03 00:56:06,451 INFO     Training average negative_sample_loss at step 38400: 0.017730\n",
      "2023-12-03 00:56:06,451 INFO     Training average loss at step 38400: 0.032697\n",
      "2023-12-03 00:56:12,909 INFO     Training average positive_sample_loss at step 38500: 0.044970\n",
      "2023-12-03 00:56:12,910 INFO     Training average negative_sample_loss at step 38500: 0.017784\n",
      "2023-12-03 00:56:12,910 INFO     Training average loss at step 38500: 0.031377\n",
      "2023-12-03 00:56:19,071 INFO     Training average positive_sample_loss at step 38600: 0.046414\n",
      "2023-12-03 00:56:19,072 INFO     Training average negative_sample_loss at step 38600: 0.017668\n",
      "2023-12-03 00:56:19,072 INFO     Training average loss at step 38600: 0.032041\n",
      "2023-12-03 00:56:25,023 INFO     Training average positive_sample_loss at step 38700: 0.047254\n",
      "2023-12-03 00:56:25,023 INFO     Training average negative_sample_loss at step 38700: 0.017665\n",
      "2023-12-03 00:56:25,023 INFO     Training average loss at step 38700: 0.032460\n",
      "2023-12-03 00:56:31,429 INFO     Training average positive_sample_loss at step 38800: 0.046114\n",
      "2023-12-03 00:56:31,429 INFO     Training average negative_sample_loss at step 38800: 0.017799\n",
      "2023-12-03 00:56:31,430 INFO     Training average loss at step 38800: 0.031956\n",
      "2023-12-03 00:56:37,306 INFO     Training average positive_sample_loss at step 38900: 0.045382\n",
      "2023-12-03 00:56:37,306 INFO     Training average negative_sample_loss at step 38900: 0.017603\n",
      "2023-12-03 00:56:37,306 INFO     Training average loss at step 38900: 0.031493\n",
      "2023-12-03 00:56:43,426 INFO     Training average positive_sample_loss at step 39000: 0.046814\n",
      "2023-12-03 00:56:43,426 INFO     Training average negative_sample_loss at step 39000: 0.017670\n",
      "2023-12-03 00:56:43,426 INFO     Training average loss at step 39000: 0.032242\n",
      "2023-12-03 00:56:49,862 INFO     Training average positive_sample_loss at step 39100: 0.047826\n",
      "2023-12-03 00:56:49,862 INFO     Training average negative_sample_loss at step 39100: 0.017725\n",
      "2023-12-03 00:56:49,862 INFO     Training average loss at step 39100: 0.032775\n",
      "2023-12-03 00:56:56,273 INFO     Training average positive_sample_loss at step 39200: 0.044339\n",
      "2023-12-03 00:56:56,273 INFO     Training average negative_sample_loss at step 39200: 0.017558\n",
      "2023-12-03 00:56:56,273 INFO     Training average loss at step 39200: 0.030948\n",
      "2023-12-03 00:57:01,818 INFO     Training average positive_sample_loss at step 39300: 0.046419\n",
      "2023-12-03 00:57:01,819 INFO     Training average negative_sample_loss at step 39300: 0.017579\n",
      "2023-12-03 00:57:01,819 INFO     Training average loss at step 39300: 0.031999\n",
      "2023-12-03 00:57:07,942 INFO     Training average positive_sample_loss at step 39400: 0.047101\n",
      "2023-12-03 00:57:07,943 INFO     Training average negative_sample_loss at step 39400: 0.017722\n",
      "2023-12-03 00:57:07,943 INFO     Training average loss at step 39400: 0.032411\n",
      "2023-12-03 00:57:14,603 INFO     Training average positive_sample_loss at step 39500: 0.045350\n",
      "2023-12-03 00:57:14,603 INFO     Training average negative_sample_loss at step 39500: 0.017662\n",
      "2023-12-03 00:57:14,604 INFO     Training average loss at step 39500: 0.031506\n",
      "2023-12-03 00:57:20,893 INFO     Training average positive_sample_loss at step 39600: 0.045708\n",
      "2023-12-03 00:57:20,893 INFO     Training average negative_sample_loss at step 39600: 0.017754\n",
      "2023-12-03 00:57:20,893 INFO     Training average loss at step 39600: 0.031731\n",
      "2023-12-03 00:57:27,109 INFO     Training average positive_sample_loss at step 39700: 0.047039\n",
      "2023-12-03 00:57:27,109 INFO     Training average negative_sample_loss at step 39700: 0.017673\n",
      "2023-12-03 00:57:27,109 INFO     Training average loss at step 39700: 0.032356\n",
      "2023-12-03 00:57:33,476 INFO     Training average positive_sample_loss at step 39800: 0.046840\n",
      "2023-12-03 00:57:33,476 INFO     Training average negative_sample_loss at step 39800: 0.017665\n",
      "2023-12-03 00:57:33,476 INFO     Training average loss at step 39800: 0.032253\n",
      "2023-12-03 00:57:38,939 INFO     Training average positive_sample_loss at step 39900: 0.044638\n",
      "2023-12-03 00:57:38,939 INFO     Training average negative_sample_loss at step 39900: 0.017845\n",
      "2023-12-03 00:57:38,939 INFO     Training average loss at step 39900: 0.031242\n",
      "2023-12-03 00:57:45,042 INFO     Change learning_rate to 0.000005 at step 40000\n",
      "2023-12-03 00:57:51,386 INFO     Training average positive_sample_loss at step 40000: 0.046326\n",
      "2023-12-03 00:57:51,386 INFO     Training average negative_sample_loss at step 40000: 0.017591\n",
      "2023-12-03 00:57:51,386 INFO     Training average loss at step 40000: 0.031959\n",
      "2023-12-03 00:57:51,386 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:57:51,951 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:58:23,067 INFO     Valid MRR at step 40000: 0.479155\n",
      "2023-12-03 00:58:23,067 INFO     Valid MR at step 40000: 3378.622610\n",
      "2023-12-03 00:58:23,068 INFO     Valid HITS@1 at step 40000: 0.435399\n",
      "2023-12-03 00:58:23,068 INFO     Valid HITS@3 at step 40000: 0.490606\n",
      "2023-12-03 00:58:23,068 INFO     Valid HITS@10 at step 40000: 0.569380\n",
      "2023-12-03 00:58:29,207 INFO     Training average positive_sample_loss at step 40100: 0.047603\n",
      "2023-12-03 00:58:29,208 INFO     Training average negative_sample_loss at step 40100: 0.016979\n",
      "2023-12-03 00:58:29,208 INFO     Training average loss at step 40100: 0.032291\n",
      "2023-12-03 00:58:35,845 INFO     Training average positive_sample_loss at step 40200: 0.044077\n",
      "2023-12-03 00:58:35,845 INFO     Training average negative_sample_loss at step 40200: 0.016820\n",
      "2023-12-03 00:58:35,845 INFO     Training average loss at step 40200: 0.030449\n",
      "2023-12-03 00:58:41,946 INFO     Training average positive_sample_loss at step 40300: 0.043578\n",
      "2023-12-03 00:58:41,946 INFO     Training average negative_sample_loss at step 40300: 0.016843\n",
      "2023-12-03 00:58:41,946 INFO     Training average loss at step 40300: 0.030211\n",
      "2023-12-03 00:58:48,061 INFO     Training average positive_sample_loss at step 40400: 0.043509\n",
      "2023-12-03 00:58:48,062 INFO     Training average negative_sample_loss at step 40400: 0.016663\n",
      "2023-12-03 00:58:48,062 INFO     Training average loss at step 40400: 0.030086\n",
      "2023-12-03 00:58:54,265 INFO     Training average positive_sample_loss at step 40500: 0.043309\n",
      "2023-12-03 00:58:54,266 INFO     Training average negative_sample_loss at step 40500: 0.016788\n",
      "2023-12-03 00:58:54,266 INFO     Training average loss at step 40500: 0.030048\n",
      "2023-12-03 00:59:00,262 INFO     Training average positive_sample_loss at step 40600: 0.042409\n",
      "2023-12-03 00:59:00,262 INFO     Training average negative_sample_loss at step 40600: 0.016847\n",
      "2023-12-03 00:59:00,262 INFO     Training average loss at step 40600: 0.029628\n",
      "2023-12-03 00:59:06,454 INFO     Training average positive_sample_loss at step 40700: 0.042267\n",
      "2023-12-03 00:59:06,454 INFO     Training average negative_sample_loss at step 40700: 0.016797\n",
      "2023-12-03 00:59:06,454 INFO     Training average loss at step 40700: 0.029532\n",
      "2023-12-03 00:59:12,911 INFO     Training average positive_sample_loss at step 40800: 0.042840\n",
      "2023-12-03 00:59:12,911 INFO     Training average negative_sample_loss at step 40800: 0.016790\n",
      "2023-12-03 00:59:12,911 INFO     Training average loss at step 40800: 0.029815\n",
      "2023-12-03 00:59:19,117 INFO     Training average positive_sample_loss at step 40900: 0.041897\n",
      "2023-12-03 00:59:19,118 INFO     Training average negative_sample_loss at step 40900: 0.016908\n",
      "2023-12-03 00:59:19,119 INFO     Training average loss at step 40900: 0.029402\n",
      "2023-12-03 00:59:25,237 INFO     Training average positive_sample_loss at step 41000: 0.041851\n",
      "2023-12-03 00:59:25,237 INFO     Training average negative_sample_loss at step 41000: 0.016694\n",
      "2023-12-03 00:59:25,237 INFO     Training average loss at step 41000: 0.029272\n",
      "2023-12-03 00:59:30,964 INFO     Training average positive_sample_loss at step 41100: 0.042214\n",
      "2023-12-03 00:59:30,965 INFO     Training average negative_sample_loss at step 41100: 0.016771\n",
      "2023-12-03 00:59:30,965 INFO     Training average loss at step 41100: 0.029493\n",
      "2023-12-03 00:59:37,589 INFO     Training average positive_sample_loss at step 41200: 0.041865\n",
      "2023-12-03 00:59:37,589 INFO     Training average negative_sample_loss at step 41200: 0.016765\n",
      "2023-12-03 00:59:37,589 INFO     Training average loss at step 41200: 0.029315\n",
      "2023-12-03 00:59:43,723 INFO     Training average positive_sample_loss at step 41300: 0.041509\n",
      "2023-12-03 00:59:43,724 INFO     Training average negative_sample_loss at step 41300: 0.016843\n",
      "2023-12-03 00:59:43,724 INFO     Training average loss at step 41300: 0.029176\n",
      "2023-12-03 00:59:49,786 INFO     Training average positive_sample_loss at step 41400: 0.041836\n",
      "2023-12-03 00:59:49,786 INFO     Training average negative_sample_loss at step 41400: 0.016828\n",
      "2023-12-03 00:59:49,786 INFO     Training average loss at step 41400: 0.029332\n",
      "2023-12-03 00:59:56,170 INFO     Training average positive_sample_loss at step 41500: 0.041829\n",
      "2023-12-03 00:59:56,170 INFO     Training average negative_sample_loss at step 41500: 0.016826\n",
      "2023-12-03 00:59:56,170 INFO     Training average loss at step 41500: 0.029328\n",
      "2023-12-03 01:00:01,876 INFO     Training average positive_sample_loss at step 41600: 0.041083\n",
      "2023-12-03 01:00:01,876 INFO     Training average negative_sample_loss at step 41600: 0.016863\n",
      "2023-12-03 01:00:01,876 INFO     Training average loss at step 41600: 0.028973\n",
      "2023-12-03 01:00:07,996 INFO     Training average positive_sample_loss at step 41700: 0.041671\n",
      "2023-12-03 01:00:07,996 INFO     Training average negative_sample_loss at step 41700: 0.016819\n",
      "2023-12-03 01:00:07,996 INFO     Training average loss at step 41700: 0.029245\n",
      "2023-12-03 01:00:14,076 INFO     Training average positive_sample_loss at step 41800: 0.041834\n",
      "2023-12-03 01:00:14,076 INFO     Training average negative_sample_loss at step 41800: 0.016690\n",
      "2023-12-03 01:00:14,076 INFO     Training average loss at step 41800: 0.029262\n",
      "2023-12-03 01:00:20,727 INFO     Training average positive_sample_loss at step 41900: 0.041306\n",
      "2023-12-03 01:00:20,728 INFO     Training average negative_sample_loss at step 41900: 0.016850\n",
      "2023-12-03 01:00:20,728 INFO     Training average loss at step 41900: 0.029078\n",
      "2023-12-03 01:00:26,614 INFO     Training average positive_sample_loss at step 42000: 0.041491\n",
      "2023-12-03 01:00:26,614 INFO     Training average negative_sample_loss at step 42000: 0.017023\n",
      "2023-12-03 01:00:26,614 INFO     Training average loss at step 42000: 0.029257\n",
      "2023-12-03 01:00:32,560 INFO     Training average positive_sample_loss at step 42100: 0.041302\n",
      "2023-12-03 01:00:32,561 INFO     Training average negative_sample_loss at step 42100: 0.016841\n",
      "2023-12-03 01:00:32,561 INFO     Training average loss at step 42100: 0.029072\n",
      "2023-12-03 01:00:38,972 INFO     Training average positive_sample_loss at step 42200: 0.041283\n",
      "2023-12-03 01:00:38,973 INFO     Training average negative_sample_loss at step 42200: 0.016880\n",
      "2023-12-03 01:00:38,973 INFO     Training average loss at step 42200: 0.029082\n",
      "2023-12-03 01:00:45,135 INFO     Training average positive_sample_loss at step 42300: 0.040942\n",
      "2023-12-03 01:00:45,135 INFO     Training average negative_sample_loss at step 42300: 0.016930\n",
      "2023-12-03 01:00:45,135 INFO     Training average loss at step 42300: 0.028936\n",
      "2023-12-03 01:00:51,183 INFO     Training average positive_sample_loss at step 42400: 0.041254\n",
      "2023-12-03 01:00:51,183 INFO     Training average negative_sample_loss at step 42400: 0.016918\n",
      "2023-12-03 01:00:51,183 INFO     Training average loss at step 42400: 0.029086\n",
      "2023-12-03 01:00:57,442 INFO     Training average positive_sample_loss at step 42500: 0.041758\n",
      "2023-12-03 01:00:57,443 INFO     Training average negative_sample_loss at step 42500: 0.016662\n",
      "2023-12-03 01:00:57,443 INFO     Training average loss at step 42500: 0.029210\n",
      "2023-12-03 01:01:03,731 INFO     Training average positive_sample_loss at step 42600: 0.040813\n",
      "2023-12-03 01:01:03,731 INFO     Training average negative_sample_loss at step 42600: 0.016839\n",
      "2023-12-03 01:01:03,731 INFO     Training average loss at step 42600: 0.028826\n",
      "2023-12-03 01:01:09,454 INFO     Training average positive_sample_loss at step 42700: 0.041229\n",
      "2023-12-03 01:01:09,454 INFO     Training average negative_sample_loss at step 42700: 0.016815\n",
      "2023-12-03 01:01:09,454 INFO     Training average loss at step 42700: 0.029022\n",
      "2023-12-03 01:01:15,573 INFO     Training average positive_sample_loss at step 42800: 0.041384\n",
      "2023-12-03 01:01:15,574 INFO     Training average negative_sample_loss at step 42800: 0.016645\n",
      "2023-12-03 01:01:15,574 INFO     Training average loss at step 42800: 0.029014\n",
      "2023-12-03 01:01:21,864 INFO     Training average positive_sample_loss at step 42900: 0.040973\n",
      "2023-12-03 01:01:21,865 INFO     Training average negative_sample_loss at step 42900: 0.016887\n",
      "2023-12-03 01:01:21,865 INFO     Training average loss at step 42900: 0.028930\n",
      "2023-12-03 01:01:28,017 INFO     Training average positive_sample_loss at step 43000: 0.040846\n",
      "2023-12-03 01:01:28,018 INFO     Training average negative_sample_loss at step 43000: 0.016902\n",
      "2023-12-03 01:01:28,018 INFO     Training average loss at step 43000: 0.028874\n",
      "2023-12-03 01:01:33,910 INFO     Training average positive_sample_loss at step 43100: 0.041280\n",
      "2023-12-03 01:01:33,910 INFO     Training average negative_sample_loss at step 43100: 0.016819\n",
      "2023-12-03 01:01:33,910 INFO     Training average loss at step 43100: 0.029049\n",
      "2023-12-03 01:01:40,162 INFO     Training average positive_sample_loss at step 43200: 0.041390\n",
      "2023-12-03 01:01:40,162 INFO     Training average negative_sample_loss at step 43200: 0.016863\n",
      "2023-12-03 01:01:40,162 INFO     Training average loss at step 43200: 0.029126\n",
      "2023-12-03 01:01:46,271 INFO     Training average positive_sample_loss at step 43300: 0.040869\n",
      "2023-12-03 01:01:46,271 INFO     Training average negative_sample_loss at step 43300: 0.016853\n",
      "2023-12-03 01:01:46,271 INFO     Training average loss at step 43300: 0.028861\n",
      "2023-12-03 01:01:52,352 INFO     Training average positive_sample_loss at step 43400: 0.041018\n",
      "2023-12-03 01:01:52,353 INFO     Training average negative_sample_loss at step 43400: 0.016899\n",
      "2023-12-03 01:01:52,353 INFO     Training average loss at step 43400: 0.028959\n",
      "2023-12-03 01:01:58,455 INFO     Training average positive_sample_loss at step 43500: 0.041368\n",
      "2023-12-03 01:01:58,455 INFO     Training average negative_sample_loss at step 43500: 0.016731\n",
      "2023-12-03 01:01:58,455 INFO     Training average loss at step 43500: 0.029049\n",
      "2023-12-03 01:02:05,104 INFO     Training average positive_sample_loss at step 43600: 0.040725\n",
      "2023-12-03 01:02:05,105 INFO     Training average negative_sample_loss at step 43600: 0.016975\n",
      "2023-12-03 01:02:05,105 INFO     Training average loss at step 43600: 0.028850\n",
      "2023-12-03 01:02:10,988 INFO     Training average positive_sample_loss at step 43700: 0.041061\n",
      "2023-12-03 01:02:10,989 INFO     Training average negative_sample_loss at step 43700: 0.016782\n",
      "2023-12-03 01:02:10,989 INFO     Training average loss at step 43700: 0.028922\n",
      "2023-12-03 01:02:16,745 INFO     Training average positive_sample_loss at step 43800: 0.041305\n",
      "2023-12-03 01:02:16,746 INFO     Training average negative_sample_loss at step 43800: 0.016734\n",
      "2023-12-03 01:02:16,746 INFO     Training average loss at step 43800: 0.029020\n",
      "2023-12-03 01:02:23,392 INFO     Training average positive_sample_loss at step 43900: 0.040695\n",
      "2023-12-03 01:02:23,392 INFO     Training average negative_sample_loss at step 43900: 0.016741\n",
      "2023-12-03 01:02:23,392 INFO     Training average loss at step 43900: 0.028718\n",
      "2023-12-03 01:02:29,520 INFO     Training average positive_sample_loss at step 44000: 0.040910\n",
      "2023-12-03 01:02:29,521 INFO     Training average negative_sample_loss at step 44000: 0.016845\n",
      "2023-12-03 01:02:29,521 INFO     Training average loss at step 44000: 0.028878\n",
      "2023-12-03 01:02:35,626 INFO     Training average positive_sample_loss at step 44100: 0.040939\n",
      "2023-12-03 01:02:35,626 INFO     Training average negative_sample_loss at step 44100: 0.016793\n",
      "2023-12-03 01:02:35,626 INFO     Training average loss at step 44100: 0.028866\n",
      "2023-12-03 01:02:41,431 INFO     Training average positive_sample_loss at step 44200: 0.041283\n",
      "2023-12-03 01:02:41,431 INFO     Training average negative_sample_loss at step 44200: 0.016642\n",
      "2023-12-03 01:02:41,431 INFO     Training average loss at step 44200: 0.028962\n",
      "2023-12-03 01:02:47,317 INFO     Training average positive_sample_loss at step 44300: 0.040629\n",
      "2023-12-03 01:02:47,318 INFO     Training average negative_sample_loss at step 44300: 0.016723\n",
      "2023-12-03 01:02:47,318 INFO     Training average loss at step 44300: 0.028676\n",
      "2023-12-03 01:02:53,418 INFO     Training average positive_sample_loss at step 44400: 0.040737\n",
      "2023-12-03 01:02:53,418 INFO     Training average negative_sample_loss at step 44400: 0.016639\n",
      "2023-12-03 01:02:53,418 INFO     Training average loss at step 44400: 0.028688\n",
      "2023-12-03 01:02:59,546 INFO     Training average positive_sample_loss at step 44500: 0.041333\n",
      "2023-12-03 01:02:59,546 INFO     Training average negative_sample_loss at step 44500: 0.016796\n",
      "2023-12-03 01:02:59,547 INFO     Training average loss at step 44500: 0.029065\n",
      "2023-12-03 01:03:06,180 INFO     Training average positive_sample_loss at step 44600: 0.040879\n",
      "2023-12-03 01:03:06,180 INFO     Training average negative_sample_loss at step 44600: 0.016609\n",
      "2023-12-03 01:03:06,180 INFO     Training average loss at step 44600: 0.028744\n",
      "2023-12-03 01:03:11,767 INFO     Training average positive_sample_loss at step 44700: 0.040761\n",
      "2023-12-03 01:03:11,768 INFO     Training average negative_sample_loss at step 44700: 0.016825\n",
      "2023-12-03 01:03:11,768 INFO     Training average loss at step 44700: 0.028793\n",
      "2023-12-03 01:03:17,917 INFO     Training average positive_sample_loss at step 44800: 0.041043\n",
      "2023-12-03 01:03:17,918 INFO     Training average negative_sample_loss at step 44800: 0.016697\n",
      "2023-12-03 01:03:17,918 INFO     Training average loss at step 44800: 0.028870\n",
      "2023-12-03 01:03:24,656 INFO     Training average positive_sample_loss at step 44900: 0.041087\n",
      "2023-12-03 01:03:24,656 INFO     Training average negative_sample_loss at step 44900: 0.016661\n",
      "2023-12-03 01:03:24,656 INFO     Training average loss at step 44900: 0.028874\n",
      "2023-12-03 01:03:30,773 INFO     Training average positive_sample_loss at step 45000: 0.040686\n",
      "2023-12-03 01:03:30,773 INFO     Training average negative_sample_loss at step 45000: 0.016814\n",
      "2023-12-03 01:03:30,773 INFO     Training average loss at step 45000: 0.028750\n",
      "2023-12-03 01:03:36,901 INFO     Training average positive_sample_loss at step 45100: 0.040974\n",
      "2023-12-03 01:03:36,901 INFO     Training average negative_sample_loss at step 45100: 0.016567\n",
      "2023-12-03 01:03:36,901 INFO     Training average loss at step 45100: 0.028771\n",
      "2023-12-03 01:03:42,598 INFO     Training average positive_sample_loss at step 45200: 0.040969\n",
      "2023-12-03 01:03:42,599 INFO     Training average negative_sample_loss at step 45200: 0.016695\n",
      "2023-12-03 01:03:42,599 INFO     Training average loss at step 45200: 0.028832\n",
      "2023-12-03 01:03:49,288 INFO     Training average positive_sample_loss at step 45300: 0.040896\n",
      "2023-12-03 01:03:49,288 INFO     Training average negative_sample_loss at step 45300: 0.016689\n",
      "2023-12-03 01:03:49,288 INFO     Training average loss at step 45300: 0.028792\n",
      "2023-12-03 01:03:55,265 INFO     Training average positive_sample_loss at step 45400: 0.040697\n",
      "2023-12-03 01:03:55,265 INFO     Training average negative_sample_loss at step 45400: 0.016659\n",
      "2023-12-03 01:03:55,265 INFO     Training average loss at step 45400: 0.028678\n",
      "2023-12-03 01:04:01,584 INFO     Training average positive_sample_loss at step 45500: 0.040980\n",
      "2023-12-03 01:04:01,584 INFO     Training average negative_sample_loss at step 45500: 0.016770\n",
      "2023-12-03 01:04:01,584 INFO     Training average loss at step 45500: 0.028875\n",
      "2023-12-03 01:04:08,201 INFO     Training average positive_sample_loss at step 45600: 0.041003\n",
      "2023-12-03 01:04:08,202 INFO     Training average negative_sample_loss at step 45600: 0.016637\n",
      "2023-12-03 01:04:08,202 INFO     Training average loss at step 45600: 0.028820\n",
      "2023-12-03 01:04:14,377 INFO     Training average positive_sample_loss at step 45700: 0.040680\n",
      "2023-12-03 01:04:14,377 INFO     Training average negative_sample_loss at step 45700: 0.016718\n",
      "2023-12-03 01:04:14,377 INFO     Training average loss at step 45700: 0.028699\n",
      "2023-12-03 01:04:19,951 INFO     Training average positive_sample_loss at step 45800: 0.040933\n",
      "2023-12-03 01:04:19,951 INFO     Training average negative_sample_loss at step 45800: 0.016769\n",
      "2023-12-03 01:04:19,951 INFO     Training average loss at step 45800: 0.028851\n",
      "2023-12-03 01:04:26,368 INFO     Training average positive_sample_loss at step 45900: 0.041046\n",
      "2023-12-03 01:04:26,369 INFO     Training average negative_sample_loss at step 45900: 0.016523\n",
      "2023-12-03 01:04:26,369 INFO     Training average loss at step 45900: 0.028784\n",
      "2023-12-03 01:04:32,749 INFO     Training average positive_sample_loss at step 46000: 0.040486\n",
      "2023-12-03 01:04:32,750 INFO     Training average negative_sample_loss at step 46000: 0.016726\n",
      "2023-12-03 01:04:32,750 INFO     Training average loss at step 46000: 0.028606\n",
      "2023-12-03 01:04:39,071 INFO     Training average positive_sample_loss at step 46100: 0.040757\n",
      "2023-12-03 01:04:39,072 INFO     Training average negative_sample_loss at step 46100: 0.016699\n",
      "2023-12-03 01:04:39,072 INFO     Training average loss at step 46100: 0.028728\n",
      "2023-12-03 01:04:45,253 INFO     Training average positive_sample_loss at step 46200: 0.041034\n",
      "2023-12-03 01:04:45,254 INFO     Training average negative_sample_loss at step 46200: 0.016632\n",
      "2023-12-03 01:04:45,254 INFO     Training average loss at step 46200: 0.028833\n",
      "2023-12-03 01:04:51,932 INFO     Training average positive_sample_loss at step 46300: 0.040798\n",
      "2023-12-03 01:04:51,932 INFO     Training average negative_sample_loss at step 46300: 0.016765\n",
      "2023-12-03 01:04:51,932 INFO     Training average loss at step 46300: 0.028781\n",
      "2023-12-03 01:04:57,682 INFO     Training average positive_sample_loss at step 46400: 0.040852\n",
      "2023-12-03 01:04:57,683 INFO     Training average negative_sample_loss at step 46400: 0.016509\n",
      "2023-12-03 01:04:57,683 INFO     Training average loss at step 46400: 0.028680\n",
      "2023-12-03 01:05:03,881 INFO     Training average positive_sample_loss at step 46500: 0.040957\n",
      "2023-12-03 01:05:03,881 INFO     Training average negative_sample_loss at step 46500: 0.016697\n",
      "2023-12-03 01:05:03,881 INFO     Training average loss at step 46500: 0.028827\n",
      "2023-12-03 01:05:10,483 INFO     Training average positive_sample_loss at step 46600: 0.041006\n",
      "2023-12-03 01:05:10,484 INFO     Training average negative_sample_loss at step 46600: 0.016563\n",
      "2023-12-03 01:05:10,484 INFO     Training average loss at step 46600: 0.028785\n",
      "2023-12-03 01:05:16,582 INFO     Training average positive_sample_loss at step 46700: 0.040634\n",
      "2023-12-03 01:05:16,582 INFO     Training average negative_sample_loss at step 46700: 0.016714\n",
      "2023-12-03 01:05:16,582 INFO     Training average loss at step 46700: 0.028674\n",
      "2023-12-03 01:05:22,694 INFO     Training average positive_sample_loss at step 46800: 0.040889\n",
      "2023-12-03 01:05:22,694 INFO     Training average negative_sample_loss at step 46800: 0.016578\n",
      "2023-12-03 01:05:22,694 INFO     Training average loss at step 46800: 0.028734\n",
      "2023-12-03 01:05:28,314 INFO     Training average positive_sample_loss at step 46900: 0.040888\n",
      "2023-12-03 01:05:28,314 INFO     Training average negative_sample_loss at step 46900: 0.016603\n",
      "2023-12-03 01:05:28,314 INFO     Training average loss at step 46900: 0.028746\n",
      "2023-12-03 01:05:34,488 INFO     Training average positive_sample_loss at step 47000: 0.040661\n",
      "2023-12-03 01:05:34,489 INFO     Training average negative_sample_loss at step 47000: 0.016527\n",
      "2023-12-03 01:05:34,489 INFO     Training average loss at step 47000: 0.028594\n",
      "2023-12-03 01:05:40,607 INFO     Training average positive_sample_loss at step 47100: 0.040821\n",
      "2023-12-03 01:05:40,607 INFO     Training average negative_sample_loss at step 47100: 0.016732\n",
      "2023-12-03 01:05:40,607 INFO     Training average loss at step 47100: 0.028776\n",
      "2023-12-03 01:05:46,288 INFO     Training average positive_sample_loss at step 47200: 0.040812\n",
      "2023-12-03 01:05:46,289 INFO     Training average negative_sample_loss at step 47200: 0.016557\n",
      "2023-12-03 01:05:46,289 INFO     Training average loss at step 47200: 0.028684\n",
      "2023-12-03 01:05:52,789 INFO     Training average positive_sample_loss at step 47300: 0.041020\n",
      "2023-12-03 01:05:52,789 INFO     Training average negative_sample_loss at step 47300: 0.016711\n",
      "2023-12-03 01:05:52,789 INFO     Training average loss at step 47300: 0.028866\n",
      "2023-12-03 01:05:58,979 INFO     Training average positive_sample_loss at step 47400: 0.040599\n",
      "2023-12-03 01:05:58,980 INFO     Training average negative_sample_loss at step 47400: 0.016617\n",
      "2023-12-03 01:05:58,980 INFO     Training average loss at step 47400: 0.028608\n",
      "2023-12-03 01:06:05,127 INFO     Training average positive_sample_loss at step 47500: 0.040911\n",
      "2023-12-03 01:06:05,130 INFO     Training average negative_sample_loss at step 47500: 0.016559\n",
      "2023-12-03 01:06:05,130 INFO     Training average loss at step 47500: 0.028735\n",
      "2023-12-03 01:06:11,548 INFO     Training average positive_sample_loss at step 47600: 0.041011\n",
      "2023-12-03 01:06:11,549 INFO     Training average negative_sample_loss at step 47600: 0.016642\n",
      "2023-12-03 01:06:11,549 INFO     Training average loss at step 47600: 0.028826\n",
      "2023-12-03 01:06:17,939 INFO     Training average positive_sample_loss at step 47700: 0.040546\n",
      "2023-12-03 01:06:17,940 INFO     Training average negative_sample_loss at step 47700: 0.016581\n",
      "2023-12-03 01:06:17,940 INFO     Training average loss at step 47700: 0.028564\n",
      "2023-12-03 01:06:23,452 INFO     Training average positive_sample_loss at step 47800: 0.040924\n",
      "2023-12-03 01:06:23,453 INFO     Training average negative_sample_loss at step 47800: 0.016510\n",
      "2023-12-03 01:06:23,453 INFO     Training average loss at step 47800: 0.028717\n",
      "2023-12-03 01:06:29,607 INFO     Training average positive_sample_loss at step 47900: 0.040975\n",
      "2023-12-03 01:06:29,608 INFO     Training average negative_sample_loss at step 47900: 0.016665\n",
      "2023-12-03 01:06:29,608 INFO     Training average loss at step 47900: 0.028820\n",
      "2023-12-03 01:06:36,349 INFO     Training average positive_sample_loss at step 48000: 0.040702\n",
      "2023-12-03 01:06:36,349 INFO     Training average negative_sample_loss at step 48000: 0.016501\n",
      "2023-12-03 01:06:36,349 INFO     Training average loss at step 48000: 0.028602\n",
      "2023-12-03 01:06:42,504 INFO     Training average positive_sample_loss at step 48100: 0.040797\n",
      "2023-12-03 01:06:42,504 INFO     Training average negative_sample_loss at step 48100: 0.016576\n",
      "2023-12-03 01:06:42,504 INFO     Training average loss at step 48100: 0.028686\n",
      "2023-12-03 01:06:47,930 INFO     Training average positive_sample_loss at step 48200: 0.040797\n",
      "2023-12-03 01:06:47,930 INFO     Training average negative_sample_loss at step 48200: 0.016659\n",
      "2023-12-03 01:06:47,930 INFO     Training average loss at step 48200: 0.028728\n",
      "2023-12-03 01:06:54,514 INFO     Training average positive_sample_loss at step 48300: 0.040827\n",
      "2023-12-03 01:06:54,515 INFO     Training average negative_sample_loss at step 48300: 0.016533\n",
      "2023-12-03 01:06:54,515 INFO     Training average loss at step 48300: 0.028680\n",
      "2023-12-03 01:07:00,597 INFO     Training average positive_sample_loss at step 48400: 0.040402\n",
      "2023-12-03 01:07:00,597 INFO     Training average negative_sample_loss at step 48400: 0.016518\n",
      "2023-12-03 01:07:00,597 INFO     Training average loss at step 48400: 0.028460\n",
      "2023-12-03 01:07:06,677 INFO     Training average positive_sample_loss at step 48500: 0.040917\n",
      "2023-12-03 01:07:06,678 INFO     Training average negative_sample_loss at step 48500: 0.016545\n",
      "2023-12-03 01:07:06,678 INFO     Training average loss at step 48500: 0.028731\n",
      "2023-12-03 01:07:12,839 INFO     Training average positive_sample_loss at step 48600: 0.041216\n",
      "2023-12-03 01:07:12,840 INFO     Training average negative_sample_loss at step 48600: 0.016567\n",
      "2023-12-03 01:07:12,840 INFO     Training average loss at step 48600: 0.028891\n",
      "2023-12-03 01:07:19,412 INFO     Training average positive_sample_loss at step 48700: 0.040431\n",
      "2023-12-03 01:07:19,412 INFO     Training average negative_sample_loss at step 48700: 0.016608\n",
      "2023-12-03 01:07:19,412 INFO     Training average loss at step 48700: 0.028519\n",
      "2023-12-03 01:07:24,942 INFO     Training average positive_sample_loss at step 48800: 0.040733\n",
      "2023-12-03 01:07:24,943 INFO     Training average negative_sample_loss at step 48800: 0.016506\n",
      "2023-12-03 01:07:24,943 INFO     Training average loss at step 48800: 0.028619\n",
      "2023-12-03 01:07:31,075 INFO     Training average positive_sample_loss at step 48900: 0.040931\n",
      "2023-12-03 01:07:31,075 INFO     Training average negative_sample_loss at step 48900: 0.016427\n",
      "2023-12-03 01:07:31,076 INFO     Training average loss at step 48900: 0.028679\n",
      "2023-12-03 01:07:37,687 INFO     Training average positive_sample_loss at step 49000: 0.040914\n",
      "2023-12-03 01:07:37,687 INFO     Training average negative_sample_loss at step 49000: 0.016575\n",
      "2023-12-03 01:07:37,687 INFO     Training average loss at step 49000: 0.028744\n",
      "2023-12-03 01:07:43,746 INFO     Training average positive_sample_loss at step 49100: 0.040706\n",
      "2023-12-03 01:07:43,746 INFO     Training average negative_sample_loss at step 49100: 0.016492\n",
      "2023-12-03 01:07:43,746 INFO     Training average loss at step 49100: 0.028599\n",
      "2023-12-03 01:07:49,826 INFO     Training average positive_sample_loss at step 49200: 0.040693\n",
      "2023-12-03 01:07:49,827 INFO     Training average negative_sample_loss at step 49200: 0.016385\n",
      "2023-12-03 01:07:49,827 INFO     Training average loss at step 49200: 0.028539\n",
      "2023-12-03 01:07:56,087 INFO     Training average positive_sample_loss at step 49300: 0.041081\n",
      "2023-12-03 01:07:56,088 INFO     Training average negative_sample_loss at step 49300: 0.016657\n",
      "2023-12-03 01:07:56,088 INFO     Training average loss at step 49300: 0.028869\n",
      "2023-12-03 01:08:01,837 INFO     Training average positive_sample_loss at step 49400: 0.040561\n",
      "2023-12-03 01:08:01,837 INFO     Training average negative_sample_loss at step 49400: 0.016475\n",
      "2023-12-03 01:08:01,837 INFO     Training average loss at step 49400: 0.028518\n",
      "2023-12-03 01:08:08,003 INFO     Training average positive_sample_loss at step 49500: 0.040560\n",
      "2023-12-03 01:08:08,003 INFO     Training average negative_sample_loss at step 49500: 0.016486\n",
      "2023-12-03 01:08:08,003 INFO     Training average loss at step 49500: 0.028523\n",
      "2023-12-03 01:08:14,095 INFO     Training average positive_sample_loss at step 49600: 0.041028\n",
      "2023-12-03 01:08:14,095 INFO     Training average negative_sample_loss at step 49600: 0.016421\n",
      "2023-12-03 01:08:14,095 INFO     Training average loss at step 49600: 0.028724\n",
      "2023-12-03 01:08:20,561 INFO     Training average positive_sample_loss at step 49700: 0.040877\n",
      "2023-12-03 01:08:20,562 INFO     Training average negative_sample_loss at step 49700: 0.016548\n",
      "2023-12-03 01:08:20,562 INFO     Training average loss at step 49700: 0.028712\n",
      "2023-12-03 01:08:26,707 INFO     Training average positive_sample_loss at step 49800: 0.040657\n",
      "2023-12-03 01:08:26,707 INFO     Training average negative_sample_loss at step 49800: 0.016466\n",
      "2023-12-03 01:08:26,707 INFO     Training average loss at step 49800: 0.028562\n",
      "2023-12-03 01:08:32,823 INFO     Training average positive_sample_loss at step 49900: 0.040846\n",
      "2023-12-03 01:08:32,824 INFO     Training average negative_sample_loss at step 49900: 0.016546\n",
      "2023-12-03 01:08:32,824 INFO     Training average loss at step 49900: 0.028696\n",
      "2023-12-03 01:08:51,002 INFO     Training average positive_sample_loss at step 50000: 0.040880\n",
      "2023-12-03 01:08:51,002 INFO     Training average negative_sample_loss at step 50000: 0.016493\n",
      "2023-12-03 01:08:51,002 INFO     Training average loss at step 50000: 0.028687\n",
      "2023-12-03 01:08:51,002 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 01:08:51,516 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 01:09:25,040 INFO     Valid MRR at step 50000: 0.479413\n",
      "2023-12-03 01:09:25,040 INFO     Valid MR at step 50000: 3338.464403\n",
      "2023-12-03 01:09:25,040 INFO     Valid HITS@1 at step 50000: 0.434740\n",
      "2023-12-03 01:09:25,040 INFO     Valid HITS@3 at step 50000: 0.492914\n",
      "2023-12-03 01:09:25,041 INFO     Valid HITS@10 at step 50000: 0.570699\n",
      "2023-12-03 01:09:31,209 INFO     Training average positive_sample_loss at step 50100: 0.040736\n",
      "2023-12-03 01:09:31,209 INFO     Training average negative_sample_loss at step 50100: 0.016478\n",
      "2023-12-03 01:09:31,209 INFO     Training average loss at step 50100: 0.028607\n",
      "2023-12-03 01:09:37,067 INFO     Training average positive_sample_loss at step 50200: 0.040817\n",
      "2023-12-03 01:09:37,068 INFO     Training average negative_sample_loss at step 50200: 0.016545\n",
      "2023-12-03 01:09:37,068 INFO     Training average loss at step 50200: 0.028681\n",
      "2023-12-03 01:09:43,156 INFO     Training average positive_sample_loss at step 50300: 0.040889\n",
      "2023-12-03 01:09:43,157 INFO     Training average negative_sample_loss at step 50300: 0.016416\n",
      "2023-12-03 01:09:43,157 INFO     Training average loss at step 50300: 0.028652\n",
      "2023-12-03 01:09:49,856 INFO     Training average positive_sample_loss at step 50400: 0.040673\n",
      "2023-12-03 01:09:49,856 INFO     Training average negative_sample_loss at step 50400: 0.016444\n",
      "2023-12-03 01:09:49,856 INFO     Training average loss at step 50400: 0.028558\n",
      "2023-12-03 01:09:55,899 INFO     Training average positive_sample_loss at step 50500: 0.040781\n",
      "2023-12-03 01:09:55,900 INFO     Training average negative_sample_loss at step 50500: 0.016459\n",
      "2023-12-03 01:09:55,900 INFO     Training average loss at step 50500: 0.028620\n",
      "2023-12-03 01:10:01,605 INFO     Training average positive_sample_loss at step 50600: 0.040824\n",
      "2023-12-03 01:10:01,605 INFO     Training average negative_sample_loss at step 50600: 0.016571\n",
      "2023-12-03 01:10:01,605 INFO     Training average loss at step 50600: 0.028698\n",
      "2023-12-03 01:10:08,145 INFO     Training average positive_sample_loss at step 50700: 0.040819\n",
      "2023-12-03 01:10:08,145 INFO     Training average negative_sample_loss at step 50700: 0.016572\n",
      "2023-12-03 01:10:08,145 INFO     Training average loss at step 50700: 0.028696\n",
      "2023-12-03 01:10:14,012 INFO     Training average positive_sample_loss at step 50800: 0.040460\n",
      "2023-12-03 01:10:14,012 INFO     Training average negative_sample_loss at step 50800: 0.016561\n",
      "2023-12-03 01:10:14,012 INFO     Training average loss at step 50800: 0.028510\n",
      "2023-12-03 01:10:20,104 INFO     Training average positive_sample_loss at step 50900: 0.040790\n",
      "2023-12-03 01:10:20,104 INFO     Training average negative_sample_loss at step 50900: 0.016410\n",
      "2023-12-03 01:10:20,104 INFO     Training average loss at step 50900: 0.028600\n",
      "2023-12-03 01:10:26,329 INFO     Training average positive_sample_loss at step 51000: 0.041093\n",
      "2023-12-03 01:10:26,329 INFO     Training average negative_sample_loss at step 51000: 0.016317\n",
      "2023-12-03 01:10:26,330 INFO     Training average loss at step 51000: 0.028705\n",
      "2023-12-03 01:10:32,708 INFO     Training average positive_sample_loss at step 51100: 0.040706\n",
      "2023-12-03 01:10:32,708 INFO     Training average negative_sample_loss at step 51100: 0.016517\n",
      "2023-12-03 01:10:32,708 INFO     Training average loss at step 51100: 0.028612\n",
      "2023-12-03 01:10:38,449 INFO     Training average positive_sample_loss at step 51200: 0.040445\n",
      "2023-12-03 01:10:38,450 INFO     Training average negative_sample_loss at step 51200: 0.016451\n",
      "2023-12-03 01:10:38,450 INFO     Training average loss at step 51200: 0.028448\n",
      "2023-12-03 01:10:44,345 INFO     Training average positive_sample_loss at step 51300: 0.041094\n",
      "2023-12-03 01:10:44,345 INFO     Training average negative_sample_loss at step 51300: 0.016411\n",
      "2023-12-03 01:10:44,345 INFO     Training average loss at step 51300: 0.028753\n",
      "2023-12-03 01:10:51,023 INFO     Training average positive_sample_loss at step 51400: 0.040593\n",
      "2023-12-03 01:10:51,023 INFO     Training average negative_sample_loss at step 51400: 0.016423\n",
      "2023-12-03 01:10:51,023 INFO     Training average loss at step 51400: 0.028508\n",
      "2023-12-03 01:10:57,127 INFO     Training average positive_sample_loss at step 51500: 0.040630\n",
      "2023-12-03 01:10:57,128 INFO     Training average negative_sample_loss at step 51500: 0.016327\n",
      "2023-12-03 01:10:57,128 INFO     Training average loss at step 51500: 0.028478\n",
      "2023-12-03 01:11:03,159 INFO     Training average positive_sample_loss at step 51600: 0.040967\n",
      "2023-12-03 01:11:03,159 INFO     Training average negative_sample_loss at step 51600: 0.016471\n",
      "2023-12-03 01:11:03,159 INFO     Training average loss at step 51600: 0.028719\n",
      "2023-12-03 01:11:09,270 INFO     Training average positive_sample_loss at step 51700: 0.040836\n",
      "2023-12-03 01:11:09,271 INFO     Training average negative_sample_loss at step 51700: 0.016454\n",
      "2023-12-03 01:11:09,271 INFO     Training average loss at step 51700: 0.028645\n",
      "2023-12-03 01:11:15,244 INFO     Training average positive_sample_loss at step 51800: 0.040524\n",
      "2023-12-03 01:11:15,244 INFO     Training average negative_sample_loss at step 51800: 0.016410\n",
      "2023-12-03 01:11:15,244 INFO     Training average loss at step 51800: 0.028467\n",
      "2023-12-03 01:11:21,338 INFO     Training average positive_sample_loss at step 51900: 0.040845\n",
      "2023-12-03 01:11:21,339 INFO     Training average negative_sample_loss at step 51900: 0.016329\n",
      "2023-12-03 01:11:21,339 INFO     Training average loss at step 51900: 0.028587\n",
      "2023-12-03 01:11:27,372 INFO     Training average positive_sample_loss at step 52000: 0.040992\n",
      "2023-12-03 01:11:27,372 INFO     Training average negative_sample_loss at step 52000: 0.016372\n",
      "2023-12-03 01:11:27,372 INFO     Training average loss at step 52000: 0.028682\n",
      "2023-12-03 01:11:34,071 INFO     Training average positive_sample_loss at step 52100: 0.040701\n",
      "2023-12-03 01:11:34,072 INFO     Training average negative_sample_loss at step 52100: 0.016482\n",
      "2023-12-03 01:11:34,072 INFO     Training average loss at step 52100: 0.028592\n",
      "2023-12-03 01:11:40,232 INFO     Training average positive_sample_loss at step 52200: 0.040817\n",
      "2023-12-03 01:11:40,232 INFO     Training average negative_sample_loss at step 52200: 0.016504\n",
      "2023-12-03 01:11:40,232 INFO     Training average loss at step 52200: 0.028661\n",
      "2023-12-03 01:11:46,391 INFO     Training average positive_sample_loss at step 52300: 0.040784\n",
      "2023-12-03 01:11:46,391 INFO     Training average negative_sample_loss at step 52300: 0.016425\n",
      "2023-12-03 01:11:46,391 INFO     Training average loss at step 52300: 0.028604\n",
      "2023-12-03 01:11:52,442 INFO     Training average positive_sample_loss at step 52400: 0.040827\n",
      "2023-12-03 01:11:52,443 INFO     Training average negative_sample_loss at step 52400: 0.016413\n",
      "2023-12-03 01:11:52,443 INFO     Training average loss at step 52400: 0.028620\n",
      "2023-12-03 01:11:58,672 INFO     Training average positive_sample_loss at step 52500: 0.040262\n",
      "2023-12-03 01:11:58,674 INFO     Training average negative_sample_loss at step 52500: 0.016463\n",
      "2023-12-03 01:11:58,674 INFO     Training average loss at step 52500: 0.028363\n",
      "2023-12-03 01:12:04,725 INFO     Training average positive_sample_loss at step 52600: 0.040806\n",
      "2023-12-03 01:12:04,725 INFO     Training average negative_sample_loss at step 52600: 0.016429\n",
      "2023-12-03 01:12:04,726 INFO     Training average loss at step 52600: 0.028617\n",
      "2023-12-03 01:12:11,113 INFO     Training average positive_sample_loss at step 52700: 0.041141\n",
      "2023-12-03 01:12:11,113 INFO     Training average negative_sample_loss at step 52700: 0.016341\n",
      "2023-12-03 01:12:11,113 INFO     Training average loss at step 52700: 0.028741\n",
      "2023-12-03 01:12:17,156 INFO     Training average positive_sample_loss at step 52800: 0.040370\n",
      "2023-12-03 01:12:17,156 INFO     Training average negative_sample_loss at step 52800: 0.016479\n",
      "2023-12-03 01:12:17,156 INFO     Training average loss at step 52800: 0.028424\n",
      "2023-12-03 01:12:23,024 INFO     Training average positive_sample_loss at step 52900: 0.040772\n",
      "2023-12-03 01:12:23,025 INFO     Training average negative_sample_loss at step 52900: 0.016505\n",
      "2023-12-03 01:12:23,025 INFO     Training average loss at step 52900: 0.028638\n",
      "2023-12-03 01:12:29,134 INFO     Training average positive_sample_loss at step 53000: 0.040966\n",
      "2023-12-03 01:12:29,135 INFO     Training average negative_sample_loss at step 53000: 0.016425\n",
      "2023-12-03 01:12:29,135 INFO     Training average loss at step 53000: 0.028695\n",
      "2023-12-03 01:12:35,756 INFO     Training average positive_sample_loss at step 53100: 0.040638\n",
      "2023-12-03 01:12:35,756 INFO     Training average negative_sample_loss at step 53100: 0.016297\n",
      "2023-12-03 01:12:35,756 INFO     Training average loss at step 53100: 0.028468\n",
      "2023-12-03 01:12:41,870 INFO     Training average positive_sample_loss at step 53200: 0.040701\n",
      "2023-12-03 01:12:41,871 INFO     Training average negative_sample_loss at step 53200: 0.016332\n",
      "2023-12-03 01:12:41,871 INFO     Training average loss at step 53200: 0.028517\n",
      "2023-12-03 01:12:48,006 INFO     Training average positive_sample_loss at step 53300: 0.041166\n",
      "2023-12-03 01:12:48,007 INFO     Training average negative_sample_loss at step 53300: 0.016489\n",
      "2023-12-03 01:12:48,007 INFO     Training average loss at step 53300: 0.028827\n",
      "2023-12-03 01:12:54,666 INFO     Training average positive_sample_loss at step 53400: 0.040528\n",
      "2023-12-03 01:12:54,666 INFO     Training average negative_sample_loss at step 53400: 0.016336\n",
      "2023-12-03 01:12:54,666 INFO     Training average loss at step 53400: 0.028432\n",
      "2023-12-03 01:13:00,174 INFO     Training average positive_sample_loss at step 53500: 0.040718\n",
      "2023-12-03 01:13:00,174 INFO     Training average negative_sample_loss at step 53500: 0.016435\n",
      "2023-12-03 01:13:00,174 INFO     Training average loss at step 53500: 0.028576\n",
      "2023-12-03 01:13:06,254 INFO     Training average positive_sample_loss at step 53600: 0.040887\n",
      "2023-12-03 01:13:06,254 INFO     Training average negative_sample_loss at step 53600: 0.016388\n",
      "2023-12-03 01:13:06,254 INFO     Training average loss at step 53600: 0.028637\n",
      "2023-12-03 01:13:12,404 INFO     Training average positive_sample_loss at step 53700: 0.040778\n",
      "2023-12-03 01:13:12,405 INFO     Training average negative_sample_loss at step 53700: 0.016416\n",
      "2023-12-03 01:13:12,405 INFO     Training average loss at step 53700: 0.028597\n",
      "2023-12-03 01:13:18,976 INFO     Training average positive_sample_loss at step 53800: 0.040512\n",
      "2023-12-03 01:13:18,977 INFO     Training average negative_sample_loss at step 53800: 0.016415\n",
      "2023-12-03 01:13:18,977 INFO     Training average loss at step 53800: 0.028464\n",
      "2023-12-03 01:13:25,041 INFO     Training average positive_sample_loss at step 53900: 0.040607\n",
      "2023-12-03 01:13:25,041 INFO     Training average negative_sample_loss at step 53900: 0.016340\n",
      "2023-12-03 01:13:25,041 INFO     Training average loss at step 53900: 0.028473\n",
      "2023-12-03 01:13:31,004 INFO     Training average positive_sample_loss at step 54000: 0.040836\n",
      "2023-12-03 01:13:31,004 INFO     Training average negative_sample_loss at step 54000: 0.016400\n",
      "2023-12-03 01:13:31,005 INFO     Training average loss at step 54000: 0.028618\n",
      "2023-12-03 01:13:37,450 INFO     Training average positive_sample_loss at step 54100: 0.040850\n",
      "2023-12-03 01:13:37,450 INFO     Training average negative_sample_loss at step 54100: 0.016413\n",
      "2023-12-03 01:13:37,450 INFO     Training average loss at step 54100: 0.028632\n",
      "2023-12-03 01:13:43,323 INFO     Training average positive_sample_loss at step 54200: 0.040857\n",
      "2023-12-03 01:13:43,323 INFO     Training average negative_sample_loss at step 54200: 0.016510\n",
      "2023-12-03 01:13:43,323 INFO     Training average loss at step 54200: 0.028684\n",
      "2023-12-03 01:13:49,468 INFO     Training average positive_sample_loss at step 54300: 0.040751\n",
      "2023-12-03 01:13:49,468 INFO     Training average negative_sample_loss at step 54300: 0.016331\n",
      "2023-12-03 01:13:49,468 INFO     Training average loss at step 54300: 0.028541\n",
      "2023-12-03 01:13:55,889 INFO     Training average positive_sample_loss at step 54400: 0.040778\n",
      "2023-12-03 01:13:55,889 INFO     Training average negative_sample_loss at step 54400: 0.016251\n",
      "2023-12-03 01:13:55,889 INFO     Training average loss at step 54400: 0.028515\n",
      "2023-12-03 01:14:02,253 INFO     Training average positive_sample_loss at step 54500: 0.040559\n",
      "2023-12-03 01:14:02,253 INFO     Training average negative_sample_loss at step 54500: 0.016353\n",
      "2023-12-03 01:14:02,253 INFO     Training average loss at step 54500: 0.028456\n",
      "2023-12-03 01:14:08,372 INFO     Training average positive_sample_loss at step 54600: 0.040527\n",
      "2023-12-03 01:14:08,372 INFO     Training average negative_sample_loss at step 54600: 0.016503\n",
      "2023-12-03 01:14:08,372 INFO     Training average loss at step 54600: 0.028515\n",
      "2023-12-03 01:14:14,126 INFO     Training average positive_sample_loss at step 54700: 0.041016\n",
      "2023-12-03 01:14:14,127 INFO     Training average negative_sample_loss at step 54700: 0.016351\n",
      "2023-12-03 01:14:14,127 INFO     Training average loss at step 54700: 0.028684\n",
      "2023-12-03 01:14:20,670 INFO     Training average positive_sample_loss at step 54800: 0.040399\n",
      "2023-12-03 01:14:20,670 INFO     Training average negative_sample_loss at step 54800: 0.016273\n",
      "2023-12-03 01:14:20,670 INFO     Training average loss at step 54800: 0.028336\n",
      "2023-12-03 01:14:26,691 INFO     Training average positive_sample_loss at step 54900: 0.040771\n",
      "2023-12-03 01:14:26,692 INFO     Training average negative_sample_loss at step 54900: 0.016494\n",
      "2023-12-03 01:14:26,692 INFO     Training average loss at step 54900: 0.028632\n",
      "2023-12-03 01:14:32,830 INFO     Training average positive_sample_loss at step 55000: 0.040865\n",
      "2023-12-03 01:14:32,830 INFO     Training average negative_sample_loss at step 55000: 0.016402\n",
      "2023-12-03 01:14:32,830 INFO     Training average loss at step 55000: 0.028634\n",
      "2023-12-03 01:14:38,856 INFO     Training average positive_sample_loss at step 55100: 0.040994\n",
      "2023-12-03 01:14:38,857 INFO     Training average negative_sample_loss at step 55100: 0.016335\n",
      "2023-12-03 01:14:38,857 INFO     Training average loss at step 55100: 0.028665\n",
      "2023-12-03 01:14:44,379 INFO     Training average positive_sample_loss at step 55200: 0.040619\n",
      "2023-12-03 01:14:44,380 INFO     Training average negative_sample_loss at step 55200: 0.016267\n",
      "2023-12-03 01:14:44,380 INFO     Training average loss at step 55200: 0.028443\n",
      "2023-12-03 01:14:50,591 INFO     Training average positive_sample_loss at step 55300: 0.040659\n",
      "2023-12-03 01:14:50,591 INFO     Training average negative_sample_loss at step 55300: 0.016334\n",
      "2023-12-03 01:14:50,591 INFO     Training average loss at step 55300: 0.028497\n",
      "2023-12-03 01:14:56,258 INFO     Training average positive_sample_loss at step 55400: 0.041019\n",
      "2023-12-03 01:14:56,258 INFO     Training average negative_sample_loss at step 55400: 0.016196\n",
      "2023-12-03 01:14:56,258 INFO     Training average loss at step 55400: 0.028607\n",
      "2023-12-03 01:15:02,513 INFO     Training average positive_sample_loss at step 55500: 0.040280\n",
      "2023-12-03 01:15:02,513 INFO     Training average negative_sample_loss at step 55500: 0.016453\n",
      "2023-12-03 01:15:02,513 INFO     Training average loss at step 55500: 0.028366\n",
      "2023-12-03 01:15:08,624 INFO     Training average positive_sample_loss at step 55600: 0.040596\n",
      "2023-12-03 01:15:08,625 INFO     Training average negative_sample_loss at step 55600: 0.016263\n",
      "2023-12-03 01:15:08,625 INFO     Training average loss at step 55600: 0.028430\n",
      "2023-12-03 01:15:14,788 INFO     Training average positive_sample_loss at step 55700: 0.041188\n",
      "2023-12-03 01:15:14,788 INFO     Training average negative_sample_loss at step 55700: 0.016383\n",
      "2023-12-03 01:15:14,788 INFO     Training average loss at step 55700: 0.028786\n",
      "2023-12-03 01:15:21,442 INFO     Training average positive_sample_loss at step 55800: 0.040343\n",
      "2023-12-03 01:15:21,442 INFO     Training average negative_sample_loss at step 55800: 0.016193\n",
      "2023-12-03 01:15:21,443 INFO     Training average loss at step 55800: 0.028268\n",
      "2023-12-03 01:15:27,036 INFO     Training average positive_sample_loss at step 55900: 0.040376\n",
      "2023-12-03 01:15:27,037 INFO     Training average negative_sample_loss at step 55900: 0.016318\n",
      "2023-12-03 01:15:27,037 INFO     Training average loss at step 55900: 0.028347\n",
      "2023-12-03 01:15:33,074 INFO     Training average positive_sample_loss at step 56000: 0.041164\n",
      "2023-12-03 01:15:33,074 INFO     Training average negative_sample_loss at step 56000: 0.016223\n",
      "2023-12-03 01:15:33,074 INFO     Training average loss at step 56000: 0.028693\n",
      "2023-12-03 01:15:39,447 INFO     Training average positive_sample_loss at step 56100: 0.040999\n",
      "2023-12-03 01:15:39,447 INFO     Training average negative_sample_loss at step 56100: 0.016348\n",
      "2023-12-03 01:15:39,447 INFO     Training average loss at step 56100: 0.028673\n",
      "2023-12-03 01:15:45,877 INFO     Training average positive_sample_loss at step 56200: 0.040395\n",
      "2023-12-03 01:15:45,877 INFO     Training average negative_sample_loss at step 56200: 0.016374\n",
      "2023-12-03 01:15:45,877 INFO     Training average loss at step 56200: 0.028385\n",
      "2023-12-03 01:15:51,704 INFO     Training average positive_sample_loss at step 56300: 0.040651\n",
      "2023-12-03 01:15:51,705 INFO     Training average negative_sample_loss at step 56300: 0.016313\n",
      "2023-12-03 01:15:51,705 INFO     Training average loss at step 56300: 0.028482\n",
      "2023-12-03 01:15:57,671 INFO     Training average positive_sample_loss at step 56400: 0.041036\n",
      "2023-12-03 01:15:57,672 INFO     Training average negative_sample_loss at step 56400: 0.016310\n",
      "2023-12-03 01:15:57,672 INFO     Training average loss at step 56400: 0.028673\n",
      "2023-12-03 01:16:04,353 INFO     Training average positive_sample_loss at step 56500: 0.040561\n",
      "2023-12-03 01:16:04,354 INFO     Training average negative_sample_loss at step 56500: 0.016258\n",
      "2023-12-03 01:16:04,354 INFO     Training average loss at step 56500: 0.028409\n",
      "2023-12-03 01:16:10,383 INFO     Training average positive_sample_loss at step 56600: 0.040413\n",
      "2023-12-03 01:16:10,383 INFO     Training average negative_sample_loss at step 56600: 0.016342\n",
      "2023-12-03 01:16:10,383 INFO     Training average loss at step 56600: 0.028377\n",
      "2023-12-03 01:16:16,542 INFO     Training average positive_sample_loss at step 56700: 0.041019\n",
      "2023-12-03 01:16:16,542 INFO     Training average negative_sample_loss at step 56700: 0.016329\n",
      "2023-12-03 01:16:16,542 INFO     Training average loss at step 56700: 0.028674\n",
      "2023-12-03 01:16:22,936 INFO     Training average positive_sample_loss at step 56800: 0.040984\n",
      "2023-12-03 01:16:22,937 INFO     Training average negative_sample_loss at step 56800: 0.016370\n",
      "2023-12-03 01:16:22,937 INFO     Training average loss at step 56800: 0.028677\n",
      "2023-12-03 01:16:28,535 INFO     Training average positive_sample_loss at step 56900: 0.040552\n",
      "2023-12-03 01:16:28,535 INFO     Training average negative_sample_loss at step 56900: 0.016291\n",
      "2023-12-03 01:16:28,535 INFO     Training average loss at step 56900: 0.028421\n",
      "2023-12-03 01:16:34,680 INFO     Training average positive_sample_loss at step 57000: 0.040620\n",
      "2023-12-03 01:16:34,680 INFO     Training average negative_sample_loss at step 57000: 0.016315\n",
      "2023-12-03 01:16:34,680 INFO     Training average loss at step 57000: 0.028468\n",
      "2023-12-03 01:16:40,694 INFO     Training average positive_sample_loss at step 57100: 0.040925\n",
      "2023-12-03 01:16:40,695 INFO     Training average negative_sample_loss at step 57100: 0.016460\n",
      "2023-12-03 01:16:40,695 INFO     Training average loss at step 57100: 0.028692\n",
      "2023-12-03 01:16:47,445 INFO     Training average positive_sample_loss at step 57200: 0.040339\n",
      "2023-12-03 01:16:47,445 INFO     Training average negative_sample_loss at step 57200: 0.016327\n",
      "2023-12-03 01:16:47,445 INFO     Training average loss at step 57200: 0.028333\n",
      "2023-12-03 01:16:53,555 INFO     Training average positive_sample_loss at step 57300: 0.040693\n",
      "2023-12-03 01:16:53,555 INFO     Training average negative_sample_loss at step 57300: 0.016421\n",
      "2023-12-03 01:16:53,555 INFO     Training average loss at step 57300: 0.028557\n",
      "2023-12-03 01:16:59,632 INFO     Training average positive_sample_loss at step 57400: 0.040899\n",
      "2023-12-03 01:16:59,632 INFO     Training average negative_sample_loss at step 57400: 0.016288\n",
      "2023-12-03 01:16:59,632 INFO     Training average loss at step 57400: 0.028593\n",
      "2023-12-03 01:17:05,654 INFO     Training average positive_sample_loss at step 57500: 0.040610\n",
      "2023-12-03 01:17:05,654 INFO     Training average negative_sample_loss at step 57500: 0.016382\n",
      "2023-12-03 01:17:05,654 INFO     Training average loss at step 57500: 0.028496\n",
      "2023-12-03 01:17:11,822 INFO     Training average positive_sample_loss at step 57600: 0.040642\n",
      "2023-12-03 01:17:11,823 INFO     Training average negative_sample_loss at step 57600: 0.016362\n",
      "2023-12-03 01:17:11,823 INFO     Training average loss at step 57600: 0.028502\n",
      "2023-12-03 01:17:17,814 INFO     Training average positive_sample_loss at step 57700: 0.040676\n",
      "2023-12-03 01:17:17,814 INFO     Training average negative_sample_loss at step 57700: 0.016243\n",
      "2023-12-03 01:17:17,814 INFO     Training average loss at step 57700: 0.028459\n",
      "2023-12-03 01:17:24,169 INFO     Training average positive_sample_loss at step 57800: 0.041001\n",
      "2023-12-03 01:17:24,169 INFO     Training average negative_sample_loss at step 57800: 0.016147\n",
      "2023-12-03 01:17:24,169 INFO     Training average loss at step 57800: 0.028574\n",
      "2023-12-03 01:17:30,550 INFO     Training average positive_sample_loss at step 57900: 0.040440\n",
      "2023-12-03 01:17:30,550 INFO     Training average negative_sample_loss at step 57900: 0.016532\n",
      "2023-12-03 01:17:30,550 INFO     Training average loss at step 57900: 0.028486\n",
      "2023-12-03 01:17:36,238 INFO     Training average positive_sample_loss at step 58000: 0.040728\n",
      "2023-12-03 01:17:36,238 INFO     Training average negative_sample_loss at step 58000: 0.016263\n",
      "2023-12-03 01:17:36,238 INFO     Training average loss at step 58000: 0.028495\n",
      "2023-12-03 01:17:42,342 INFO     Training average positive_sample_loss at step 58100: 0.040765\n",
      "2023-12-03 01:17:42,343 INFO     Training average negative_sample_loss at step 58100: 0.016191\n",
      "2023-12-03 01:17:42,343 INFO     Training average loss at step 58100: 0.028478\n",
      "2023-12-03 01:17:49,071 INFO     Training average positive_sample_loss at step 58200: 0.040581\n",
      "2023-12-03 01:17:49,071 INFO     Training average negative_sample_loss at step 58200: 0.016296\n",
      "2023-12-03 01:17:49,072 INFO     Training average loss at step 58200: 0.028438\n",
      "2023-12-03 01:17:55,106 INFO     Training average positive_sample_loss at step 58300: 0.040635\n",
      "2023-12-03 01:17:55,107 INFO     Training average negative_sample_loss at step 58300: 0.016422\n",
      "2023-12-03 01:17:55,107 INFO     Training average loss at step 58300: 0.028528\n",
      "2023-12-03 01:18:01,225 INFO     Training average positive_sample_loss at step 58400: 0.040688\n",
      "2023-12-03 01:18:01,226 INFO     Training average negative_sample_loss at step 58400: 0.016315\n",
      "2023-12-03 01:18:01,226 INFO     Training average loss at step 58400: 0.028502\n",
      "2023-12-03 01:18:08,033 INFO     Training average positive_sample_loss at step 58500: 0.040817\n",
      "2023-12-03 01:18:08,034 INFO     Training average negative_sample_loss at step 58500: 0.016364\n",
      "2023-12-03 01:18:08,034 INFO     Training average loss at step 58500: 0.028590\n",
      "2023-12-03 01:18:14,213 INFO     Training average positive_sample_loss at step 58600: 0.040597\n",
      "2023-12-03 01:18:14,213 INFO     Training average negative_sample_loss at step 58600: 0.016303\n",
      "2023-12-03 01:18:14,213 INFO     Training average loss at step 58600: 0.028450\n",
      "2023-12-03 01:18:19,784 INFO     Training average positive_sample_loss at step 58700: 0.040732\n",
      "2023-12-03 01:18:19,784 INFO     Training average negative_sample_loss at step 58700: 0.016339\n",
      "2023-12-03 01:18:19,784 INFO     Training average loss at step 58700: 0.028535\n",
      "2023-12-03 01:18:25,891 INFO     Training average positive_sample_loss at step 58800: 0.040802\n",
      "2023-12-03 01:18:25,891 INFO     Training average negative_sample_loss at step 58800: 0.016227\n",
      "2023-12-03 01:18:25,891 INFO     Training average loss at step 58800: 0.028514\n",
      "2023-12-03 01:18:32,244 INFO     Training average positive_sample_loss at step 58900: 0.040622\n",
      "2023-12-03 01:18:32,245 INFO     Training average negative_sample_loss at step 58900: 0.016175\n",
      "2023-12-03 01:18:32,245 INFO     Training average loss at step 58900: 0.028399\n",
      "2023-12-03 01:18:38,327 INFO     Training average positive_sample_loss at step 59000: 0.040646\n",
      "2023-12-03 01:18:38,328 INFO     Training average negative_sample_loss at step 59000: 0.016257\n",
      "2023-12-03 01:18:38,328 INFO     Training average loss at step 59000: 0.028452\n",
      "2023-12-03 01:18:44,488 INFO     Training average positive_sample_loss at step 59100: 0.040700\n",
      "2023-12-03 01:18:44,488 INFO     Training average negative_sample_loss at step 59100: 0.016275\n",
      "2023-12-03 01:18:44,488 INFO     Training average loss at step 59100: 0.028487\n",
      "2023-12-03 01:18:51,124 INFO     Training average positive_sample_loss at step 59200: 0.040690\n",
      "2023-12-03 01:18:51,125 INFO     Training average negative_sample_loss at step 59200: 0.016149\n",
      "2023-12-03 01:18:51,125 INFO     Training average loss at step 59200: 0.028420\n",
      "2023-12-03 01:18:56,779 INFO     Training average positive_sample_loss at step 59300: 0.040521\n",
      "2023-12-03 01:18:56,779 INFO     Training average negative_sample_loss at step 59300: 0.016246\n",
      "2023-12-03 01:18:56,779 INFO     Training average loss at step 59300: 0.028383\n",
      "2023-12-03 01:19:02,814 INFO     Training average positive_sample_loss at step 59400: 0.040751\n",
      "2023-12-03 01:19:02,814 INFO     Training average negative_sample_loss at step 59400: 0.016222\n",
      "2023-12-03 01:19:02,814 INFO     Training average loss at step 59400: 0.028486\n",
      "2023-12-03 01:19:09,077 INFO     Training average positive_sample_loss at step 59500: 0.041048\n",
      "2023-12-03 01:19:09,077 INFO     Training average negative_sample_loss at step 59500: 0.016245\n",
      "2023-12-03 01:19:09,077 INFO     Training average loss at step 59500: 0.028646\n",
      "2023-12-03 01:19:15,382 INFO     Training average positive_sample_loss at step 59600: 0.040395\n",
      "2023-12-03 01:19:15,382 INFO     Training average negative_sample_loss at step 59600: 0.016255\n",
      "2023-12-03 01:19:15,382 INFO     Training average loss at step 59600: 0.028325\n",
      "2023-12-03 01:19:21,564 INFO     Training average positive_sample_loss at step 59700: 0.040799\n",
      "2023-12-03 01:19:21,564 INFO     Training average negative_sample_loss at step 59700: 0.016208\n",
      "2023-12-03 01:19:21,564 INFO     Training average loss at step 59700: 0.028504\n",
      "2023-12-03 01:19:27,752 INFO     Training average positive_sample_loss at step 59800: 0.040900\n",
      "2023-12-03 01:19:27,753 INFO     Training average negative_sample_loss at step 59800: 0.016281\n",
      "2023-12-03 01:19:27,753 INFO     Training average loss at step 59800: 0.028590\n",
      "2023-12-03 01:19:34,457 INFO     Training average positive_sample_loss at step 59900: 0.040438\n",
      "2023-12-03 01:19:34,458 INFO     Training average negative_sample_loss at step 59900: 0.016306\n",
      "2023-12-03 01:19:34,458 INFO     Training average loss at step 59900: 0.028372\n",
      "2023-12-03 01:19:50,017 INFO     Training average positive_sample_loss at step 60000: 0.040621\n",
      "2023-12-03 01:19:50,017 INFO     Training average negative_sample_loss at step 60000: 0.016302\n",
      "2023-12-03 01:19:50,017 INFO     Training average loss at step 60000: 0.028461\n",
      "2023-12-03 01:19:50,017 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 01:19:50,655 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 01:20:23,326 INFO     Valid MRR at step 60000: 0.479386\n",
      "2023-12-03 01:20:23,327 INFO     Valid MR at step 60000: 3325.590310\n",
      "2023-12-03 01:20:23,327 INFO     Valid HITS@1 at step 60000: 0.434575\n",
      "2023-12-03 01:20:23,327 INFO     Valid HITS@3 at step 60000: 0.492254\n",
      "2023-12-03 01:20:23,327 INFO     Valid HITS@10 at step 60000: 0.571523\n",
      "2023-12-03 01:20:29,478 INFO     Training average positive_sample_loss at step 60100: 0.040650\n",
      "2023-12-03 01:20:29,479 INFO     Training average negative_sample_loss at step 60100: 0.016287\n",
      "2023-12-03 01:20:29,479 INFO     Training average loss at step 60100: 0.028469\n",
      "2023-12-03 01:20:36,140 INFO     Training average positive_sample_loss at step 60200: 0.040896\n",
      "2023-12-03 01:20:36,140 INFO     Training average negative_sample_loss at step 60200: 0.016144\n",
      "2023-12-03 01:20:36,140 INFO     Training average loss at step 60200: 0.028520\n",
      "2023-12-03 01:20:41,818 INFO     Training average positive_sample_loss at step 60300: 0.040567\n",
      "2023-12-03 01:20:41,819 INFO     Training average negative_sample_loss at step 60300: 0.016348\n",
      "2023-12-03 01:20:41,819 INFO     Training average loss at step 60300: 0.028458\n",
      "2023-12-03 01:20:48,042 INFO     Training average positive_sample_loss at step 60400: 0.040579\n",
      "2023-12-03 01:20:48,043 INFO     Training average negative_sample_loss at step 60400: 0.016088\n",
      "2023-12-03 01:20:48,043 INFO     Training average loss at step 60400: 0.028334\n",
      "2023-12-03 01:20:54,159 INFO     Training average positive_sample_loss at step 60500: 0.040834\n",
      "2023-12-03 01:20:54,159 INFO     Training average negative_sample_loss at step 60500: 0.016272\n",
      "2023-12-03 01:20:54,159 INFO     Training average loss at step 60500: 0.028553\n",
      "2023-12-03 01:21:00,681 INFO     Training average positive_sample_loss at step 60600: 0.040406\n",
      "2023-12-03 01:21:00,682 INFO     Training average negative_sample_loss at step 60600: 0.016173\n",
      "2023-12-03 01:21:00,682 INFO     Training average loss at step 60600: 0.028290\n",
      "2023-12-03 01:21:06,785 INFO     Training average positive_sample_loss at step 60700: 0.040769\n",
      "2023-12-03 01:21:06,785 INFO     Training average negative_sample_loss at step 60700: 0.016299\n",
      "2023-12-03 01:21:06,785 INFO     Training average loss at step 60700: 0.028534\n",
      "2023-12-03 01:21:12,862 INFO     Training average positive_sample_loss at step 60800: 0.040882\n",
      "2023-12-03 01:21:12,862 INFO     Training average negative_sample_loss at step 60800: 0.016233\n",
      "2023-12-03 01:21:12,862 INFO     Training average loss at step 60800: 0.028557\n",
      "2023-12-03 01:21:18,982 INFO     Training average positive_sample_loss at step 60900: 0.040551\n",
      "2023-12-03 01:21:18,982 INFO     Training average negative_sample_loss at step 60900: 0.016258\n",
      "2023-12-03 01:21:18,982 INFO     Training average loss at step 60900: 0.028405\n",
      "2023-12-03 01:21:24,892 INFO     Training average positive_sample_loss at step 61000: 0.040656\n",
      "2023-12-03 01:21:24,893 INFO     Training average negative_sample_loss at step 61000: 0.016234\n",
      "2023-12-03 01:21:24,893 INFO     Training average loss at step 61000: 0.028445\n",
      "2023-12-03 01:21:30,979 INFO     Training average positive_sample_loss at step 61100: 0.040658\n",
      "2023-12-03 01:21:30,980 INFO     Training average negative_sample_loss at step 61100: 0.016299\n",
      "2023-12-03 01:21:30,980 INFO     Training average loss at step 61100: 0.028479\n",
      "2023-12-03 01:21:37,337 INFO     Training average positive_sample_loss at step 61200: 0.040753\n",
      "2023-12-03 01:21:37,337 INFO     Training average negative_sample_loss at step 61200: 0.016248\n",
      "2023-12-03 01:21:37,337 INFO     Training average loss at step 61200: 0.028501\n",
      "2023-12-03 01:21:43,400 INFO     Training average positive_sample_loss at step 61300: 0.040504\n",
      "2023-12-03 01:21:43,400 INFO     Training average negative_sample_loss at step 61300: 0.016180\n",
      "2023-12-03 01:21:43,400 INFO     Training average loss at step 61300: 0.028342\n",
      "2023-12-03 01:21:49,264 INFO     Training average positive_sample_loss at step 61400: 0.040607\n",
      "2023-12-03 01:21:49,264 INFO     Training average negative_sample_loss at step 61400: 0.016114\n",
      "2023-12-03 01:21:49,264 INFO     Training average loss at step 61400: 0.028361\n",
      "2023-12-03 01:21:55,333 INFO     Training average positive_sample_loss at step 61500: 0.040635\n",
      "2023-12-03 01:21:55,333 INFO     Training average negative_sample_loss at step 61500: 0.016116\n",
      "2023-12-03 01:21:55,333 INFO     Training average loss at step 61500: 0.028375\n",
      "2023-12-03 01:22:01,967 INFO     Training average positive_sample_loss at step 61600: 0.040787\n",
      "2023-12-03 01:22:01,968 INFO     Training average negative_sample_loss at step 61600: 0.016203\n",
      "2023-12-03 01:22:01,968 INFO     Training average loss at step 61600: 0.028495\n",
      "2023-12-03 01:22:08,051 INFO     Training average positive_sample_loss at step 61700: 0.040553\n",
      "2023-12-03 01:22:08,051 INFO     Training average negative_sample_loss at step 61700: 0.016264\n",
      "2023-12-03 01:22:08,051 INFO     Training average loss at step 61700: 0.028408\n",
      "2023-12-03 01:22:13,557 INFO     Training average positive_sample_loss at step 61800: 0.040728\n",
      "2023-12-03 01:22:13,558 INFO     Training average negative_sample_loss at step 61800: 0.016343\n",
      "2023-12-03 01:22:13,558 INFO     Training average loss at step 61800: 0.028535\n",
      "2023-12-03 01:22:20,189 INFO     Training average positive_sample_loss at step 61900: 0.040896\n",
      "2023-12-03 01:22:20,189 INFO     Training average negative_sample_loss at step 61900: 0.016415\n",
      "2023-12-03 01:22:20,189 INFO     Training average loss at step 61900: 0.028656\n",
      "2023-12-03 01:22:26,322 INFO     Training average positive_sample_loss at step 62000: 0.040365\n",
      "2023-12-03 01:22:26,323 INFO     Training average negative_sample_loss at step 62000: 0.016321\n",
      "2023-12-03 01:22:26,323 INFO     Training average loss at step 62000: 0.028343\n",
      "2023-12-03 01:22:32,470 INFO     Training average positive_sample_loss at step 62100: 0.040710\n",
      "2023-12-03 01:22:32,471 INFO     Training average negative_sample_loss at step 62100: 0.016398\n",
      "2023-12-03 01:22:32,471 INFO     Training average loss at step 62100: 0.028554\n",
      "2023-12-03 01:22:38,594 INFO     Training average positive_sample_loss at step 62200: 0.040821\n",
      "2023-12-03 01:22:38,595 INFO     Training average negative_sample_loss at step 62200: 0.016259\n",
      "2023-12-03 01:22:38,595 INFO     Training average loss at step 62200: 0.028540\n",
      "2023-12-03 01:22:45,255 INFO     Training average positive_sample_loss at step 62300: 0.040533\n",
      "2023-12-03 01:22:45,255 INFO     Training average negative_sample_loss at step 62300: 0.016223\n",
      "2023-12-03 01:22:45,256 INFO     Training average loss at step 62300: 0.028378\n",
      "2023-12-03 01:22:50,716 INFO     Training average positive_sample_loss at step 62400: 0.040442\n",
      "2023-12-03 01:22:50,717 INFO     Training average negative_sample_loss at step 62400: 0.016193\n",
      "2023-12-03 01:22:50,717 INFO     Training average loss at step 62400: 0.028317\n",
      "2023-12-03 01:22:56,893 INFO     Training average positive_sample_loss at step 62500: 0.040786\n",
      "2023-12-03 01:22:56,893 INFO     Training average negative_sample_loss at step 62500: 0.016068\n",
      "2023-12-03 01:22:56,893 INFO     Training average loss at step 62500: 0.028427\n",
      "2023-12-03 01:23:03,674 INFO     Training average positive_sample_loss at step 62600: 0.040751\n",
      "2023-12-03 01:23:03,674 INFO     Training average negative_sample_loss at step 62600: 0.016359\n",
      "2023-12-03 01:23:03,674 INFO     Training average loss at step 62600: 0.028555\n",
      "2023-12-03 01:23:09,796 INFO     Training average positive_sample_loss at step 62700: 0.040387\n",
      "2023-12-03 01:23:09,796 INFO     Training average negative_sample_loss at step 62700: 0.016239\n",
      "2023-12-03 01:23:09,797 INFO     Training average loss at step 62700: 0.028313\n",
      "2023-12-03 01:23:15,940 INFO     Training average positive_sample_loss at step 62800: 0.040924\n",
      "2023-12-03 01:23:15,940 INFO     Training average negative_sample_loss at step 62800: 0.016241\n",
      "2023-12-03 01:23:15,940 INFO     Training average loss at step 62800: 0.028582\n",
      "2023-12-03 01:23:22,173 INFO     Training average positive_sample_loss at step 62900: 0.040661\n",
      "2023-12-03 01:23:22,174 INFO     Training average negative_sample_loss at step 62900: 0.016123\n",
      "2023-12-03 01:23:22,174 INFO     Training average loss at step 62900: 0.028392\n",
      "2023-12-03 01:23:27,915 INFO     Training average positive_sample_loss at step 63000: 0.040454\n",
      "2023-12-03 01:23:27,916 INFO     Training average negative_sample_loss at step 63000: 0.016171\n",
      "2023-12-03 01:23:27,916 INFO     Training average loss at step 63000: 0.028313\n",
      "2023-12-03 01:23:34,039 INFO     Training average positive_sample_loss at step 63100: 0.040639\n",
      "2023-12-03 01:23:34,040 INFO     Training average negative_sample_loss at step 63100: 0.016208\n",
      "2023-12-03 01:23:34,040 INFO     Training average loss at step 63100: 0.028424\n",
      "2023-12-03 01:23:40,319 INFO     Training average positive_sample_loss at step 63200: 0.040820\n",
      "2023-12-03 01:23:40,319 INFO     Training average negative_sample_loss at step 63200: 0.016306\n",
      "2023-12-03 01:23:40,319 INFO     Training average loss at step 63200: 0.028563\n",
      "2023-12-03 01:23:47,071 INFO     Training average positive_sample_loss at step 63300: 0.040396\n",
      "2023-12-03 01:23:47,071 INFO     Training average negative_sample_loss at step 63300: 0.016237\n",
      "2023-12-03 01:23:47,071 INFO     Training average loss at step 63300: 0.028316\n",
      "2023-12-03 01:23:53,194 INFO     Training average positive_sample_loss at step 63400: 0.040559\n",
      "2023-12-03 01:23:53,194 INFO     Training average negative_sample_loss at step 63400: 0.016351\n",
      "2023-12-03 01:23:53,194 INFO     Training average loss at step 63400: 0.028455\n",
      "2023-12-03 01:23:58,623 INFO     Training average positive_sample_loss at step 63500: 0.040777\n",
      "2023-12-03 01:23:58,623 INFO     Training average negative_sample_loss at step 63500: 0.016334\n",
      "2023-12-03 01:23:58,624 INFO     Training average loss at step 63500: 0.028556\n",
      "2023-12-03 01:24:05,304 INFO     Training average positive_sample_loss at step 63600: 0.040686\n",
      "2023-12-03 01:24:05,304 INFO     Training average negative_sample_loss at step 63600: 0.016168\n",
      "2023-12-03 01:24:05,304 INFO     Training average loss at step 63600: 0.028427\n",
      "2023-12-03 01:24:11,434 INFO     Training average positive_sample_loss at step 63700: 0.040537\n",
      "2023-12-03 01:24:11,435 INFO     Training average negative_sample_loss at step 63700: 0.016117\n",
      "2023-12-03 01:24:11,435 INFO     Training average loss at step 63700: 0.028327\n",
      "2023-12-03 01:24:17,639 INFO     Training average positive_sample_loss at step 63800: 0.040456\n",
      "2023-12-03 01:24:17,639 INFO     Training average negative_sample_loss at step 63800: 0.016215\n",
      "2023-12-03 01:24:17,639 INFO     Training average loss at step 63800: 0.028335\n",
      "2023-12-03 01:24:23,854 INFO     Training average positive_sample_loss at step 63900: 0.040934\n",
      "2023-12-03 01:24:23,855 INFO     Training average negative_sample_loss at step 63900: 0.016110\n",
      "2023-12-03 01:24:23,855 INFO     Training average loss at step 63900: 0.028522\n",
      "2023-12-03 01:24:30,455 INFO     Training average positive_sample_loss at step 64000: 0.040527\n",
      "2023-12-03 01:24:30,455 INFO     Training average negative_sample_loss at step 64000: 0.016055\n",
      "2023-12-03 01:24:30,455 INFO     Training average loss at step 64000: 0.028291\n",
      "2023-12-03 01:24:36,108 INFO     Training average positive_sample_loss at step 64100: 0.040504\n",
      "2023-12-03 01:24:36,108 INFO     Training average negative_sample_loss at step 64100: 0.016139\n",
      "2023-12-03 01:24:36,108 INFO     Training average loss at step 64100: 0.028321\n",
      "2023-12-03 01:24:41,996 INFO     Training average positive_sample_loss at step 64200: 0.040642\n",
      "2023-12-03 01:24:41,997 INFO     Training average negative_sample_loss at step 64200: 0.016176\n",
      "2023-12-03 01:24:41,997 INFO     Training average loss at step 64200: 0.028409\n",
      "2023-12-03 01:24:48,589 INFO     Training average positive_sample_loss at step 64300: 0.040737\n",
      "2023-12-03 01:24:48,589 INFO     Training average negative_sample_loss at step 64300: 0.016360\n",
      "2023-12-03 01:24:48,590 INFO     Training average loss at step 64300: 0.028548\n",
      "2023-12-03 01:24:54,714 INFO     Training average positive_sample_loss at step 64400: 0.040622\n",
      "2023-12-03 01:24:54,715 INFO     Training average negative_sample_loss at step 64400: 0.016255\n",
      "2023-12-03 01:24:54,715 INFO     Training average loss at step 64400: 0.028439\n",
      "2023-12-03 01:25:00,820 INFO     Training average positive_sample_loss at step 64500: 0.040604\n",
      "2023-12-03 01:25:00,821 INFO     Training average negative_sample_loss at step 64500: 0.016202\n",
      "2023-12-03 01:25:00,821 INFO     Training average loss at step 64500: 0.028403\n",
      "2023-12-03 01:25:07,221 INFO     Training average positive_sample_loss at step 64600: 0.040764\n",
      "2023-12-03 01:25:07,221 INFO     Training average negative_sample_loss at step 64600: 0.016208\n",
      "2023-12-03 01:25:07,221 INFO     Training average loss at step 64600: 0.028486\n",
      "2023-12-03 01:25:13,379 INFO     Training average positive_sample_loss at step 64700: 0.040128\n",
      "2023-12-03 01:25:13,379 INFO     Training average negative_sample_loss at step 64700: 0.016204\n",
      "2023-12-03 01:25:13,379 INFO     Training average loss at step 64700: 0.028166\n",
      "2023-12-03 01:25:19,166 INFO     Training average positive_sample_loss at step 64800: 0.040677\n",
      "2023-12-03 01:25:19,166 INFO     Training average negative_sample_loss at step 64800: 0.016193\n",
      "2023-12-03 01:25:19,166 INFO     Training average loss at step 64800: 0.028435\n",
      "2023-12-03 01:25:25,314 INFO     Training average positive_sample_loss at step 64900: 0.040793\n",
      "2023-12-03 01:25:25,314 INFO     Training average negative_sample_loss at step 64900: 0.016133\n",
      "2023-12-03 01:25:25,314 INFO     Training average loss at step 64900: 0.028463\n",
      "2023-12-03 01:25:31,558 INFO     Training average positive_sample_loss at step 65000: 0.040621\n",
      "2023-12-03 01:25:31,559 INFO     Training average negative_sample_loss at step 65000: 0.016110\n",
      "2023-12-03 01:25:31,559 INFO     Training average loss at step 65000: 0.028365\n",
      "2023-12-03 01:25:37,680 INFO     Training average positive_sample_loss at step 65100: 0.040717\n",
      "2023-12-03 01:25:37,681 INFO     Training average negative_sample_loss at step 65100: 0.016107\n",
      "2023-12-03 01:25:37,681 INFO     Training average loss at step 65100: 0.028412\n",
      "2023-12-03 01:25:43,800 INFO     Training average positive_sample_loss at step 65200: 0.040462\n",
      "2023-12-03 01:25:43,801 INFO     Training average negative_sample_loss at step 65200: 0.016049\n",
      "2023-12-03 01:25:43,801 INFO     Training average loss at step 65200: 0.028256\n",
      "2023-12-03 01:25:49,948 INFO     Training average positive_sample_loss at step 65300: 0.040918\n",
      "2023-12-03 01:25:49,948 INFO     Training average negative_sample_loss at step 65300: 0.016481\n",
      "2023-12-03 01:25:49,948 INFO     Training average loss at step 65300: 0.028699\n",
      "2023-12-03 01:25:55,875 INFO     Training average positive_sample_loss at step 65400: 0.040276\n",
      "2023-12-03 01:25:55,875 INFO     Training average negative_sample_loss at step 65400: 0.016322\n",
      "2023-12-03 01:25:55,875 INFO     Training average loss at step 65400: 0.028299\n",
      "2023-12-03 01:26:01,967 INFO     Training average positive_sample_loss at step 65500: 0.040733\n",
      "2023-12-03 01:26:01,968 INFO     Training average negative_sample_loss at step 65500: 0.016103\n",
      "2023-12-03 01:26:01,968 INFO     Training average loss at step 65500: 0.028418\n",
      "2023-12-03 01:26:08,082 INFO     Training average positive_sample_loss at step 65600: 0.040826\n",
      "2023-12-03 01:26:08,082 INFO     Training average negative_sample_loss at step 65600: 0.016151\n",
      "2023-12-03 01:26:08,082 INFO     Training average loss at step 65600: 0.028489\n",
      "2023-12-03 01:26:14,669 INFO     Training average positive_sample_loss at step 65700: 0.040464\n",
      "2023-12-03 01:26:14,670 INFO     Training average negative_sample_loss at step 65700: 0.016128\n",
      "2023-12-03 01:26:14,670 INFO     Training average loss at step 65700: 0.028296\n",
      "2023-12-03 01:26:20,336 INFO     Training average positive_sample_loss at step 65800: 0.040378\n",
      "2023-12-03 01:26:20,336 INFO     Training average negative_sample_loss at step 65800: 0.016194\n",
      "2023-12-03 01:26:20,336 INFO     Training average loss at step 65800: 0.028286\n",
      "2023-12-03 01:26:26,329 INFO     Training average positive_sample_loss at step 65900: 0.040707\n",
      "2023-12-03 01:26:26,329 INFO     Training average negative_sample_loss at step 65900: 0.016346\n",
      "2023-12-03 01:26:26,329 INFO     Training average loss at step 65900: 0.028527\n",
      "2023-12-03 01:26:33,012 INFO     Training average positive_sample_loss at step 66000: 0.040731\n",
      "2023-12-03 01:26:33,012 INFO     Training average negative_sample_loss at step 66000: 0.016286\n",
      "2023-12-03 01:26:33,012 INFO     Training average loss at step 66000: 0.028509\n",
      "2023-12-03 01:26:38,688 INFO     Training average positive_sample_loss at step 66100: 0.040469\n",
      "2023-12-03 01:26:38,688 INFO     Training average negative_sample_loss at step 66100: 0.016204\n",
      "2023-12-03 01:26:38,688 INFO     Training average loss at step 66100: 0.028336\n",
      "2023-12-03 01:26:44,331 INFO     Training average positive_sample_loss at step 66200: 0.040788\n",
      "2023-12-03 01:26:44,332 INFO     Training average negative_sample_loss at step 66200: 0.016107\n",
      "2023-12-03 01:26:44,332 INFO     Training average loss at step 66200: 0.028447\n",
      "2023-12-03 01:26:50,198 INFO     Training average positive_sample_loss at step 66300: 0.040627\n",
      "2023-12-03 01:26:50,199 INFO     Training average negative_sample_loss at step 66300: 0.016252\n",
      "2023-12-03 01:26:50,199 INFO     Training average loss at step 66300: 0.028440\n",
      "2023-12-03 01:26:56,640 INFO     Training average positive_sample_loss at step 66400: 0.040093\n",
      "2023-12-03 01:26:56,641 INFO     Training average negative_sample_loss at step 66400: 0.016044\n",
      "2023-12-03 01:26:56,641 INFO     Training average loss at step 66400: 0.028068\n",
      "2023-12-03 01:27:02,735 INFO     Training average positive_sample_loss at step 66500: 0.040742\n",
      "2023-12-03 01:27:02,736 INFO     Training average negative_sample_loss at step 66500: 0.016250\n",
      "2023-12-03 01:27:02,736 INFO     Training average loss at step 66500: 0.028496\n",
      "2023-12-03 01:27:08,834 INFO     Training average positive_sample_loss at step 66600: 0.040906\n",
      "2023-12-03 01:27:08,834 INFO     Training average negative_sample_loss at step 66600: 0.016230\n",
      "2023-12-03 01:27:08,834 INFO     Training average loss at step 66600: 0.028568\n",
      "2023-12-03 01:27:15,176 INFO     Training average positive_sample_loss at step 66700: 0.040356\n",
      "2023-12-03 01:27:15,176 INFO     Training average negative_sample_loss at step 66700: 0.016307\n",
      "2023-12-03 01:27:15,176 INFO     Training average loss at step 66700: 0.028331\n",
      "2023-12-03 01:27:20,869 INFO     Training average positive_sample_loss at step 66800: 0.040429\n",
      "2023-12-03 01:27:20,869 INFO     Training average negative_sample_loss at step 66800: 0.016182\n",
      "2023-12-03 01:27:20,869 INFO     Training average loss at step 66800: 0.028305\n",
      "2023-12-03 01:27:26,966 INFO     Training average positive_sample_loss at step 66900: 0.040805\n",
      "2023-12-03 01:27:26,966 INFO     Training average negative_sample_loss at step 66900: 0.016149\n",
      "2023-12-03 01:27:26,966 INFO     Training average loss at step 66900: 0.028477\n",
      "2023-12-03 01:27:33,540 INFO     Training average positive_sample_loss at step 67000: 0.040641\n",
      "2023-12-03 01:27:33,540 INFO     Training average negative_sample_loss at step 67000: 0.016213\n",
      "2023-12-03 01:27:33,540 INFO     Training average loss at step 67000: 0.028427\n",
      "2023-12-03 01:27:39,650 INFO     Training average positive_sample_loss at step 67100: 0.040395\n",
      "2023-12-03 01:27:39,650 INFO     Training average negative_sample_loss at step 67100: 0.016105\n",
      "2023-12-03 01:27:39,650 INFO     Training average loss at step 67100: 0.028250\n",
      "2023-12-03 01:27:45,750 INFO     Training average positive_sample_loss at step 67200: 0.040596\n",
      "2023-12-03 01:27:45,750 INFO     Training average negative_sample_loss at step 67200: 0.016321\n",
      "2023-12-03 01:27:45,750 INFO     Training average loss at step 67200: 0.028458\n",
      "2023-12-03 01:27:51,198 INFO     Training average positive_sample_loss at step 67300: 0.040844\n",
      "2023-12-03 01:27:51,199 INFO     Training average negative_sample_loss at step 67300: 0.016265\n",
      "2023-12-03 01:27:51,199 INFO     Training average loss at step 67300: 0.028555\n",
      "2023-12-03 01:27:57,904 INFO     Training average positive_sample_loss at step 67400: 0.040238\n",
      "2023-12-03 01:27:57,904 INFO     Training average negative_sample_loss at step 67400: 0.016200\n",
      "2023-12-03 01:27:57,904 INFO     Training average loss at step 67400: 0.028219\n",
      "2023-12-03 01:28:04,086 INFO     Training average positive_sample_loss at step 67500: 0.040570\n",
      "2023-12-03 01:28:04,087 INFO     Training average negative_sample_loss at step 67500: 0.016133\n",
      "2023-12-03 01:28:04,087 INFO     Training average loss at step 67500: 0.028351\n",
      "2023-12-03 01:28:10,235 INFO     Training average positive_sample_loss at step 67600: 0.040847\n",
      "2023-12-03 01:28:10,235 INFO     Training average negative_sample_loss at step 67600: 0.016230\n",
      "2023-12-03 01:28:10,235 INFO     Training average loss at step 67600: 0.028539\n",
      "2023-12-03 01:28:16,858 INFO     Training average positive_sample_loss at step 67700: 0.040463\n",
      "2023-12-03 01:28:16,858 INFO     Training average negative_sample_loss at step 67700: 0.016068\n",
      "2023-12-03 01:28:16,858 INFO     Training average loss at step 67700: 0.028266\n",
      "2023-12-03 01:28:22,874 INFO     Training average positive_sample_loss at step 67800: 0.040487\n",
      "2023-12-03 01:28:22,875 INFO     Training average negative_sample_loss at step 67800: 0.016191\n",
      "2023-12-03 01:28:22,875 INFO     Training average loss at step 67800: 0.028339\n",
      "2023-12-03 01:28:28,776 INFO     Training average positive_sample_loss at step 67900: 0.040454\n",
      "2023-12-03 01:28:28,776 INFO     Training average negative_sample_loss at step 67900: 0.016163\n",
      "2023-12-03 01:28:28,776 INFO     Training average loss at step 67900: 0.028309\n",
      "2023-12-03 01:28:34,885 INFO     Training average positive_sample_loss at step 68000: 0.041038\n",
      "2023-12-03 01:28:34,885 INFO     Training average negative_sample_loss at step 68000: 0.016155\n",
      "2023-12-03 01:28:34,885 INFO     Training average loss at step 68000: 0.028597\n",
      "2023-12-03 01:28:41,266 INFO     Training average positive_sample_loss at step 68100: 0.040489\n",
      "2023-12-03 01:28:41,266 INFO     Training average negative_sample_loss at step 68100: 0.016256\n",
      "2023-12-03 01:28:41,266 INFO     Training average loss at step 68100: 0.028373\n",
      "2023-12-03 01:28:47,409 INFO     Training average positive_sample_loss at step 68200: 0.040377\n",
      "2023-12-03 01:28:47,410 INFO     Training average negative_sample_loss at step 68200: 0.016115\n",
      "2023-12-03 01:28:47,410 INFO     Training average loss at step 68200: 0.028246\n",
      "2023-12-03 01:28:53,515 INFO     Training average positive_sample_loss at step 68300: 0.040769\n",
      "2023-12-03 01:28:53,515 INFO     Training average negative_sample_loss at step 68300: 0.016136\n",
      "2023-12-03 01:28:53,515 INFO     Training average loss at step 68300: 0.028452\n",
      "2023-12-03 01:28:59,731 INFO     Training average positive_sample_loss at step 68400: 0.040446\n",
      "2023-12-03 01:28:59,731 INFO     Training average negative_sample_loss at step 68400: 0.016246\n",
      "2023-12-03 01:28:59,731 INFO     Training average loss at step 68400: 0.028346\n",
      "2023-12-03 01:29:05,819 INFO     Training average positive_sample_loss at step 68500: 0.040605\n",
      "2023-12-03 01:29:05,819 INFO     Training average negative_sample_loss at step 68500: 0.016181\n",
      "2023-12-03 01:29:05,819 INFO     Training average loss at step 68500: 0.028393\n",
      "2023-12-03 01:29:11,648 INFO     Training average positive_sample_loss at step 68600: 0.040718\n",
      "2023-12-03 01:29:11,648 INFO     Training average negative_sample_loss at step 68600: 0.016105\n",
      "2023-12-03 01:29:11,648 INFO     Training average loss at step 68600: 0.028411\n",
      "2023-12-03 01:29:18,244 INFO     Training average positive_sample_loss at step 68700: 0.040492\n",
      "2023-12-03 01:29:18,244 INFO     Training average negative_sample_loss at step 68700: 0.016090\n",
      "2023-12-03 01:29:18,244 INFO     Training average loss at step 68700: 0.028291\n",
      "2023-12-03 01:29:24,367 INFO     Training average positive_sample_loss at step 68800: 0.040208\n",
      "2023-12-03 01:29:24,368 INFO     Training average negative_sample_loss at step 68800: 0.016290\n",
      "2023-12-03 01:29:24,368 INFO     Training average loss at step 68800: 0.028249\n",
      "2023-12-03 01:29:30,489 INFO     Training average positive_sample_loss at step 68900: 0.040737\n",
      "2023-12-03 01:29:30,489 INFO     Training average negative_sample_loss at step 68900: 0.016436\n",
      "2023-12-03 01:29:30,489 INFO     Training average loss at step 68900: 0.028587\n",
      "2023-12-03 01:29:36,191 INFO     Training average positive_sample_loss at step 69000: 0.040646\n",
      "2023-12-03 01:29:36,192 INFO     Training average negative_sample_loss at step 69000: 0.016219\n",
      "2023-12-03 01:29:36,192 INFO     Training average loss at step 69000: 0.028432\n",
      "2023-12-03 01:29:42,736 INFO     Training average positive_sample_loss at step 69100: 0.040484\n",
      "2023-12-03 01:29:42,737 INFO     Training average negative_sample_loss at step 69100: 0.016188\n",
      "2023-12-03 01:29:42,737 INFO     Training average loss at step 69100: 0.028336\n",
      "2023-12-03 01:29:48,542 INFO     Training average positive_sample_loss at step 69200: 0.040343\n",
      "2023-12-03 01:29:48,543 INFO     Training average negative_sample_loss at step 69200: 0.016233\n",
      "2023-12-03 01:29:48,543 INFO     Training average loss at step 69200: 0.028288\n",
      "2023-12-03 01:29:54,602 INFO     Training average positive_sample_loss at step 69300: 0.040721\n",
      "2023-12-03 01:29:54,602 INFO     Training average negative_sample_loss at step 69300: 0.016249\n",
      "2023-12-03 01:29:54,602 INFO     Training average loss at step 69300: 0.028485\n",
      "2023-12-03 01:30:00,875 INFO     Training average positive_sample_loss at step 69400: 0.040758\n",
      "2023-12-03 01:30:00,875 INFO     Training average negative_sample_loss at step 69400: 0.016233\n",
      "2023-12-03 01:30:00,875 INFO     Training average loss at step 69400: 0.028496\n",
      "2023-12-03 01:30:06,926 INFO     Training average positive_sample_loss at step 69500: 0.040325\n",
      "2023-12-03 01:30:06,926 INFO     Training average negative_sample_loss at step 69500: 0.016169\n",
      "2023-12-03 01:30:06,926 INFO     Training average loss at step 69500: 0.028247\n",
      "2023-12-03 01:30:12,831 INFO     Training average positive_sample_loss at step 69600: 0.040572\n",
      "2023-12-03 01:30:12,831 INFO     Training average negative_sample_loss at step 69600: 0.016161\n",
      "2023-12-03 01:30:12,831 INFO     Training average loss at step 69600: 0.028366\n",
      "2023-12-03 01:30:18,731 INFO     Training average positive_sample_loss at step 69700: 0.040866\n",
      "2023-12-03 01:30:18,731 INFO     Training average negative_sample_loss at step 69700: 0.016164\n",
      "2023-12-03 01:30:18,732 INFO     Training average loss at step 69700: 0.028515\n",
      "2023-12-03 01:30:25,154 INFO     Training average positive_sample_loss at step 69800: 0.040318\n",
      "2023-12-03 01:30:25,154 INFO     Training average negative_sample_loss at step 69800: 0.016291\n",
      "2023-12-03 01:30:25,154 INFO     Training average loss at step 69800: 0.028304\n",
      "2023-12-03 01:30:31,271 INFO     Training average positive_sample_loss at step 69900: 0.040593\n",
      "2023-12-03 01:30:31,271 INFO     Training average negative_sample_loss at step 69900: 0.016021\n",
      "2023-12-03 01:30:31,271 INFO     Training average loss at step 69900: 0.028307\n",
      "2023-12-03 01:30:48,968 INFO     Training average positive_sample_loss at step 70000: 0.040833\n",
      "2023-12-03 01:30:48,968 INFO     Training average negative_sample_loss at step 70000: 0.016105\n",
      "2023-12-03 01:30:48,968 INFO     Training average loss at step 70000: 0.028469\n",
      "2023-12-03 01:30:48,968 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 01:30:49,648 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 01:31:20,301 INFO     Valid MRR at step 70000: 0.478922\n",
      "2023-12-03 01:31:20,301 INFO     Valid MR at step 70000: 3314.547627\n",
      "2023-12-03 01:31:20,301 INFO     Valid HITS@1 at step 70000: 0.433916\n",
      "2023-12-03 01:31:20,301 INFO     Valid HITS@3 at step 70000: 0.492419\n",
      "2023-12-03 01:31:20,302 INFO     Valid HITS@10 at step 70000: 0.572017\n",
      "2023-12-03 01:31:26,971 INFO     Training average positive_sample_loss at step 70100: 0.040223\n",
      "2023-12-03 01:31:26,971 INFO     Training average negative_sample_loss at step 70100: 0.016232\n",
      "2023-12-03 01:31:26,971 INFO     Training average loss at step 70100: 0.028227\n",
      "2023-12-03 01:31:33,113 INFO     Training average positive_sample_loss at step 70200: 0.040358\n",
      "2023-12-03 01:31:33,113 INFO     Training average negative_sample_loss at step 70200: 0.016197\n",
      "2023-12-03 01:31:33,113 INFO     Training average loss at step 70200: 0.028278\n",
      "2023-12-03 01:31:39,249 INFO     Training average positive_sample_loss at step 70300: 0.040566\n",
      "2023-12-03 01:31:39,250 INFO     Training average negative_sample_loss at step 70300: 0.016145\n",
      "2023-12-03 01:31:39,250 INFO     Training average loss at step 70300: 0.028355\n",
      "2023-12-03 01:31:45,954 INFO     Training average positive_sample_loss at step 70400: 0.040901\n",
      "2023-12-03 01:31:45,955 INFO     Training average negative_sample_loss at step 70400: 0.016181\n",
      "2023-12-03 01:31:45,955 INFO     Training average loss at step 70400: 0.028541\n",
      "2023-12-03 01:31:52,013 INFO     Training average positive_sample_loss at step 70500: 0.040179\n",
      "2023-12-03 01:31:52,013 INFO     Training average negative_sample_loss at step 70500: 0.016127\n",
      "2023-12-03 01:31:52,013 INFO     Training average loss at step 70500: 0.028153\n",
      "2023-12-03 01:31:57,789 INFO     Training average positive_sample_loss at step 70600: 0.040564\n",
      "2023-12-03 01:31:57,789 INFO     Training average negative_sample_loss at step 70600: 0.016286\n",
      "2023-12-03 01:31:57,789 INFO     Training average loss at step 70600: 0.028425\n",
      "2023-12-03 01:32:03,681 INFO     Training average positive_sample_loss at step 70700: 0.040886\n",
      "2023-12-03 01:32:03,681 INFO     Training average negative_sample_loss at step 70700: 0.016223\n",
      "2023-12-03 01:32:03,681 INFO     Training average loss at step 70700: 0.028555\n",
      "2023-12-03 01:32:10,021 INFO     Training average positive_sample_loss at step 70800: 0.040314\n",
      "2023-12-03 01:32:10,022 INFO     Training average negative_sample_loss at step 70800: 0.016146\n",
      "2023-12-03 01:32:10,022 INFO     Training average loss at step 70800: 0.028230\n",
      "2023-12-03 01:32:16,017 INFO     Training average positive_sample_loss at step 70900: 0.040296\n",
      "2023-12-03 01:32:16,017 INFO     Training average negative_sample_loss at step 70900: 0.016073\n",
      "2023-12-03 01:32:16,017 INFO     Training average loss at step 70900: 0.028185\n",
      "2023-12-03 01:32:22,115 INFO     Training average positive_sample_loss at step 71000: 0.040825\n",
      "2023-12-03 01:32:22,115 INFO     Training average negative_sample_loss at step 71000: 0.016158\n",
      "2023-12-03 01:32:22,115 INFO     Training average loss at step 71000: 0.028491\n",
      "2023-12-03 01:32:28,635 INFO     Training average positive_sample_loss at step 71100: 0.040531\n",
      "2023-12-03 01:32:28,636 INFO     Training average negative_sample_loss at step 71100: 0.016130\n",
      "2023-12-03 01:32:28,636 INFO     Training average loss at step 71100: 0.028331\n",
      "2023-12-03 01:32:34,733 INFO     Training average positive_sample_loss at step 71200: 0.040462\n",
      "2023-12-03 01:32:34,734 INFO     Training average negative_sample_loss at step 71200: 0.016067\n",
      "2023-12-03 01:32:34,734 INFO     Training average loss at step 71200: 0.028264\n",
      "2023-12-03 01:32:40,323 INFO     Training average positive_sample_loss at step 71300: 0.040511\n",
      "2023-12-03 01:32:40,324 INFO     Training average negative_sample_loss at step 71300: 0.016087\n",
      "2023-12-03 01:32:40,324 INFO     Training average loss at step 71300: 0.028299\n",
      "2023-12-03 01:32:46,810 INFO     Training average positive_sample_loss at step 71400: 0.040729\n",
      "2023-12-03 01:32:46,810 INFO     Training average negative_sample_loss at step 71400: 0.016073\n",
      "2023-12-03 01:32:46,810 INFO     Training average loss at step 71400: 0.028401\n",
      "2023-12-03 01:32:53,202 INFO     Training average positive_sample_loss at step 71500: 0.040171\n",
      "2023-12-03 01:32:53,203 INFO     Training average negative_sample_loss at step 71500: 0.016123\n",
      "2023-12-03 01:32:53,203 INFO     Training average loss at step 71500: 0.028147\n",
      "2023-12-03 01:32:59,310 INFO     Training average positive_sample_loss at step 71600: 0.040408\n",
      "2023-12-03 01:32:59,310 INFO     Training average negative_sample_loss at step 71600: 0.016162\n",
      "2023-12-03 01:32:59,310 INFO     Training average loss at step 71600: 0.028285\n",
      "2023-12-03 01:33:05,482 INFO     Training average positive_sample_loss at step 71700: 0.040860\n",
      "2023-12-03 01:33:05,483 INFO     Training average negative_sample_loss at step 71700: 0.016430\n",
      "2023-12-03 01:33:05,483 INFO     Training average loss at step 71700: 0.028645\n",
      "2023-12-03 01:33:11,905 INFO     Training average positive_sample_loss at step 71800: 0.040403\n",
      "2023-12-03 01:33:11,905 INFO     Training average negative_sample_loss at step 71800: 0.016183\n",
      "2023-12-03 01:33:11,905 INFO     Training average loss at step 71800: 0.028293\n",
      "2023-12-03 01:33:17,919 INFO     Training average positive_sample_loss at step 71900: 0.040508\n",
      "2023-12-03 01:33:17,919 INFO     Training average negative_sample_loss at step 71900: 0.016100\n",
      "2023-12-03 01:33:17,920 INFO     Training average loss at step 71900: 0.028304\n",
      "2023-12-03 01:33:23,628 INFO     Training average positive_sample_loss at step 72000: 0.040815\n",
      "2023-12-03 01:33:23,628 INFO     Training average negative_sample_loss at step 72000: 0.016168\n",
      "2023-12-03 01:33:23,628 INFO     Training average loss at step 72000: 0.028491\n",
      "2023-12-03 01:33:30,096 INFO     Training average positive_sample_loss at step 72100: 0.040430\n",
      "2023-12-03 01:33:30,096 INFO     Training average negative_sample_loss at step 72100: 0.016100\n",
      "2023-12-03 01:33:30,096 INFO     Training average loss at step 72100: 0.028265\n",
      "2023-12-03 01:33:36,134 INFO     Training average positive_sample_loss at step 72200: 0.040390\n",
      "2023-12-03 01:33:36,134 INFO     Training average negative_sample_loss at step 72200: 0.016128\n",
      "2023-12-03 01:33:36,134 INFO     Training average loss at step 72200: 0.028259\n",
      "2023-12-03 01:33:42,252 INFO     Training average positive_sample_loss at step 72300: 0.040455\n",
      "2023-12-03 01:33:42,252 INFO     Training average negative_sample_loss at step 72300: 0.016329\n",
      "2023-12-03 01:33:42,252 INFO     Training average loss at step 72300: 0.028392\n",
      "2023-12-03 01:33:48,359 INFO     Training average positive_sample_loss at step 72400: 0.040785\n",
      "2023-12-03 01:33:48,359 INFO     Training average negative_sample_loss at step 72400: 0.016108\n",
      "2023-12-03 01:33:48,359 INFO     Training average loss at step 72400: 0.028447\n",
      "2023-12-03 01:33:54,457 INFO     Training average positive_sample_loss at step 72500: 0.040164\n",
      "2023-12-03 01:33:54,457 INFO     Training average negative_sample_loss at step 72500: 0.016080\n",
      "2023-12-03 01:33:54,457 INFO     Training average loss at step 72500: 0.028122\n",
      "2023-12-03 01:34:00,541 INFO     Training average positive_sample_loss at step 72600: 0.040545\n",
      "2023-12-03 01:34:00,541 INFO     Training average negative_sample_loss at step 72600: 0.016278\n",
      "2023-12-03 01:34:00,541 INFO     Training average loss at step 72600: 0.028412\n",
      "2023-12-03 01:34:06,411 INFO     Training average positive_sample_loss at step 72700: 0.040748\n",
      "2023-12-03 01:34:06,411 INFO     Training average negative_sample_loss at step 72700: 0.016258\n",
      "2023-12-03 01:34:06,412 INFO     Training average loss at step 72700: 0.028503\n",
      "2023-12-03 01:34:12,756 INFO     Training average positive_sample_loss at step 72800: 0.040338\n",
      "2023-12-03 01:34:12,756 INFO     Training average negative_sample_loss at step 72800: 0.016084\n",
      "2023-12-03 01:34:12,756 INFO     Training average loss at step 72800: 0.028211\n",
      "2023-12-03 01:34:18,892 INFO     Training average positive_sample_loss at step 72900: 0.040372\n",
      "2023-12-03 01:34:18,892 INFO     Training average negative_sample_loss at step 72900: 0.016201\n",
      "2023-12-03 01:34:18,892 INFO     Training average loss at step 72900: 0.028287\n",
      "2023-12-03 01:34:24,641 INFO     Training average positive_sample_loss at step 73000: 0.040598\n",
      "2023-12-03 01:34:24,641 INFO     Training average negative_sample_loss at step 73000: 0.016264\n",
      "2023-12-03 01:34:24,641 INFO     Training average loss at step 73000: 0.028431\n",
      "2023-12-03 01:34:30,710 INFO     Training average positive_sample_loss at step 73100: 0.040833\n",
      "2023-12-03 01:34:30,711 INFO     Training average negative_sample_loss at step 73100: 0.015953\n",
      "2023-12-03 01:34:30,711 INFO     Training average loss at step 73100: 0.028393\n",
      "2023-12-03 01:34:36,934 INFO     Training average positive_sample_loss at step 73200: 0.040278\n",
      "2023-12-03 01:34:36,935 INFO     Training average negative_sample_loss at step 73200: 0.016049\n",
      "2023-12-03 01:34:36,935 INFO     Training average loss at step 73200: 0.028163\n",
      "2023-12-03 01:34:43,155 INFO     Training average positive_sample_loss at step 73300: 0.040638\n",
      "2023-12-03 01:34:43,156 INFO     Training average negative_sample_loss at step 73300: 0.016082\n",
      "2023-12-03 01:34:43,156 INFO     Training average loss at step 73300: 0.028360\n",
      "2023-12-03 01:34:49,277 INFO     Training average positive_sample_loss at step 73400: 0.040778\n",
      "2023-12-03 01:34:49,278 INFO     Training average negative_sample_loss at step 73400: 0.016219\n",
      "2023-12-03 01:34:49,278 INFO     Training average loss at step 73400: 0.028499\n",
      "2023-12-03 01:34:55,779 INFO     Training average positive_sample_loss at step 73500: 0.040149\n",
      "2023-12-03 01:34:55,780 INFO     Training average negative_sample_loss at step 73500: 0.016132\n",
      "2023-12-03 01:34:55,780 INFO     Training average loss at step 73500: 0.028141\n",
      "2023-12-03 01:35:01,322 INFO     Training average positive_sample_loss at step 73600: 0.040234\n",
      "2023-12-03 01:35:01,323 INFO     Training average negative_sample_loss at step 73600: 0.016124\n",
      "2023-12-03 01:35:01,323 INFO     Training average loss at step 73600: 0.028179\n",
      "2023-12-03 01:35:07,447 INFO     Training average positive_sample_loss at step 73700: 0.040653\n",
      "2023-12-03 01:35:07,447 INFO     Training average negative_sample_loss at step 73700: 0.016077\n",
      "2023-12-03 01:35:07,447 INFO     Training average loss at step 73700: 0.028365\n",
      "2023-12-03 01:35:14,064 INFO     Training average positive_sample_loss at step 73800: 0.040565\n",
      "2023-12-03 01:35:14,065 INFO     Training average negative_sample_loss at step 73800: 0.016004\n",
      "2023-12-03 01:35:14,065 INFO     Training average loss at step 73800: 0.028285\n",
      "2023-12-03 01:35:20,218 INFO     Training average positive_sample_loss at step 73900: 0.040384\n",
      "2023-12-03 01:35:20,219 INFO     Training average negative_sample_loss at step 73900: 0.016117\n",
      "2023-12-03 01:35:20,219 INFO     Training average loss at step 73900: 0.028250\n",
      "2023-12-03 01:35:26,362 INFO     Training average positive_sample_loss at step 74000: 0.040546\n",
      "2023-12-03 01:35:26,362 INFO     Training average negative_sample_loss at step 74000: 0.016144\n",
      "2023-12-03 01:35:26,362 INFO     Training average loss at step 74000: 0.028345\n",
      "2023-12-03 01:35:32,453 INFO     Training average positive_sample_loss at step 74100: 0.040643\n",
      "2023-12-03 01:35:32,454 INFO     Training average negative_sample_loss at step 74100: 0.016112\n",
      "2023-12-03 01:35:32,454 INFO     Training average loss at step 74100: 0.028377\n",
      "2023-12-03 01:35:38,660 INFO     Training average positive_sample_loss at step 74200: 0.040306\n",
      "2023-12-03 01:35:38,661 INFO     Training average negative_sample_loss at step 74200: 0.016170\n",
      "2023-12-03 01:35:38,661 INFO     Training average loss at step 74200: 0.028238\n",
      "2023-12-03 01:35:44,541 INFO     Training average positive_sample_loss at step 74300: 0.040499\n",
      "2023-12-03 01:35:44,541 INFO     Training average negative_sample_loss at step 74300: 0.016194\n",
      "2023-12-03 01:35:44,541 INFO     Training average loss at step 74300: 0.028347\n",
      "2023-12-03 01:35:50,608 INFO     Training average positive_sample_loss at step 74400: 0.040604\n",
      "2023-12-03 01:35:50,608 INFO     Training average negative_sample_loss at step 74400: 0.016064\n",
      "2023-12-03 01:35:50,609 INFO     Training average loss at step 74400: 0.028334\n",
      "2023-12-03 01:35:56,809 INFO     Training average positive_sample_loss at step 74500: 0.040509\n",
      "2023-12-03 01:35:56,810 INFO     Training average negative_sample_loss at step 74500: 0.016192\n",
      "2023-12-03 01:35:56,810 INFO     Training average loss at step 74500: 0.028350\n",
      "2023-12-03 01:36:02,954 INFO     Training average positive_sample_loss at step 74600: 0.040382\n",
      "2023-12-03 01:36:02,954 INFO     Training average negative_sample_loss at step 74600: 0.016226\n",
      "2023-12-03 01:36:02,954 INFO     Training average loss at step 74600: 0.028304\n",
      "2023-12-03 01:36:08,539 INFO     Training average positive_sample_loss at step 74700: 0.040512\n",
      "2023-12-03 01:36:08,539 INFO     Training average negative_sample_loss at step 74700: 0.016001\n",
      "2023-12-03 01:36:08,539 INFO     Training average loss at step 74700: 0.028257\n",
      "2023-12-03 01:36:14,975 INFO     Training average positive_sample_loss at step 74800: 0.040590\n",
      "2023-12-03 01:36:14,975 INFO     Training average negative_sample_loss at step 74800: 0.015984\n",
      "2023-12-03 01:36:14,975 INFO     Training average loss at step 74800: 0.028287\n",
      "2023-12-03 01:36:21,409 INFO     Training average positive_sample_loss at step 74900: 0.040311\n",
      "2023-12-03 01:36:21,409 INFO     Training average negative_sample_loss at step 74900: 0.016088\n",
      "2023-12-03 01:36:21,409 INFO     Training average loss at step 74900: 0.028200\n",
      "2023-12-03 01:36:27,585 INFO     Training average positive_sample_loss at step 75000: 0.040425\n",
      "2023-12-03 01:36:27,585 INFO     Training average negative_sample_loss at step 75000: 0.016110\n",
      "2023-12-03 01:36:27,585 INFO     Training average loss at step 75000: 0.028268\n",
      "2023-12-03 01:36:33,775 INFO     Training average positive_sample_loss at step 75100: 0.040563\n",
      "2023-12-03 01:36:33,776 INFO     Training average negative_sample_loss at step 75100: 0.016084\n",
      "2023-12-03 01:36:33,776 INFO     Training average loss at step 75100: 0.028324\n",
      "2023-12-03 01:36:40,469 INFO     Training average positive_sample_loss at step 75200: 0.040594\n",
      "2023-12-03 01:36:40,469 INFO     Training average negative_sample_loss at step 75200: 0.016062\n",
      "2023-12-03 01:36:40,469 INFO     Training average loss at step 75200: 0.028328\n",
      "2023-12-03 01:36:45,979 INFO     Training average positive_sample_loss at step 75300: 0.040405\n",
      "2023-12-03 01:36:45,979 INFO     Training average negative_sample_loss at step 75300: 0.016090\n",
      "2023-12-03 01:36:45,979 INFO     Training average loss at step 75300: 0.028248\n",
      "2023-12-03 01:36:52,045 INFO     Training average positive_sample_loss at step 75400: 0.040622\n",
      "2023-12-03 01:36:52,047 INFO     Training average negative_sample_loss at step 75400: 0.016001\n",
      "2023-12-03 01:36:52,047 INFO     Training average loss at step 75400: 0.028312\n",
      "2023-12-03 01:36:58,584 INFO     Training average positive_sample_loss at step 75500: 0.040352\n",
      "2023-12-03 01:36:58,584 INFO     Training average negative_sample_loss at step 75500: 0.016103\n",
      "2023-12-03 01:36:58,584 INFO     Training average loss at step 75500: 0.028227\n",
      "2023-12-03 01:37:04,658 INFO     Training average positive_sample_loss at step 75600: 0.040352\n",
      "2023-12-03 01:37:04,658 INFO     Training average negative_sample_loss at step 75600: 0.016199\n",
      "2023-12-03 01:37:04,658 INFO     Training average loss at step 75600: 0.028275\n",
      "2023-12-03 01:37:10,072 INFO     Training average positive_sample_loss at step 75700: 0.040431\n",
      "2023-12-03 01:37:10,073 INFO     Training average negative_sample_loss at step 75700: 0.016128\n",
      "2023-12-03 01:37:10,073 INFO     Training average loss at step 75700: 0.028279\n",
      "2023-12-03 01:37:16,160 INFO     Training average positive_sample_loss at step 75800: 0.040511\n",
      "2023-12-03 01:37:16,160 INFO     Training average negative_sample_loss at step 75800: 0.016158\n",
      "2023-12-03 01:37:16,160 INFO     Training average loss at step 75800: 0.028334\n",
      "2023-12-03 01:37:22,811 INFO     Training average positive_sample_loss at step 75900: 0.040274\n",
      "2023-12-03 01:37:22,811 INFO     Training average negative_sample_loss at step 75900: 0.016022\n",
      "2023-12-03 01:37:22,811 INFO     Training average loss at step 75900: 0.028148\n",
      "2023-12-03 01:37:28,938 INFO     Training average positive_sample_loss at step 76000: 0.040394\n",
      "2023-12-03 01:37:28,938 INFO     Training average negative_sample_loss at step 76000: 0.016195\n",
      "2023-12-03 01:37:28,938 INFO     Training average loss at step 76000: 0.028294\n",
      "2023-12-03 01:37:35,094 INFO     Training average positive_sample_loss at step 76100: 0.040663\n",
      "2023-12-03 01:37:35,095 INFO     Training average negative_sample_loss at step 76100: 0.016100\n",
      "2023-12-03 01:37:35,095 INFO     Training average loss at step 76100: 0.028382\n",
      "2023-12-03 01:37:41,746 INFO     Training average positive_sample_loss at step 76200: 0.040553\n",
      "2023-12-03 01:37:41,746 INFO     Training average negative_sample_loss at step 76200: 0.016029\n",
      "2023-12-03 01:37:41,746 INFO     Training average loss at step 76200: 0.028291\n",
      "2023-12-03 01:37:47,155 INFO     Training average positive_sample_loss at step 76300: 0.040463\n",
      "2023-12-03 01:37:47,156 INFO     Training average negative_sample_loss at step 76300: 0.016055\n",
      "2023-12-03 01:37:47,156 INFO     Training average loss at step 76300: 0.028259\n",
      "2023-12-03 01:37:53,304 INFO     Training average positive_sample_loss at step 76400: 0.040314\n",
      "2023-12-03 01:37:53,305 INFO     Training average negative_sample_loss at step 76400: 0.015976\n",
      "2023-12-03 01:37:53,305 INFO     Training average loss at step 76400: 0.028145\n",
      "2023-12-03 01:37:59,724 INFO     Training average positive_sample_loss at step 76500: 0.040709\n",
      "2023-12-03 01:37:59,725 INFO     Training average negative_sample_loss at step 76500: 0.016140\n",
      "2023-12-03 01:37:59,725 INFO     Training average loss at step 76500: 0.028424\n",
      "2023-12-03 01:38:06,192 INFO     Training average positive_sample_loss at step 76600: 0.040351\n",
      "2023-12-03 01:38:06,193 INFO     Training average negative_sample_loss at step 76600: 0.016170\n",
      "2023-12-03 01:38:06,193 INFO     Training average loss at step 76600: 0.028260\n",
      "2023-12-03 01:38:12,319 INFO     Training average positive_sample_loss at step 76700: 0.040327\n",
      "2023-12-03 01:38:12,320 INFO     Training average negative_sample_loss at step 76700: 0.016146\n",
      "2023-12-03 01:38:12,320 INFO     Training average loss at step 76700: 0.028237\n",
      "2023-12-03 01:38:17,786 INFO     Training average positive_sample_loss at step 76800: 0.040522\n",
      "2023-12-03 01:38:17,786 INFO     Training average negative_sample_loss at step 76800: 0.016043\n",
      "2023-12-03 01:38:17,786 INFO     Training average loss at step 76800: 0.028282\n",
      "2023-12-03 01:38:24,484 INFO     Training average positive_sample_loss at step 76900: 0.040412\n",
      "2023-12-03 01:38:24,484 INFO     Training average negative_sample_loss at step 76900: 0.016020\n",
      "2023-12-03 01:38:24,485 INFO     Training average loss at step 76900: 0.028216\n",
      "2023-12-03 01:38:30,653 INFO     Training average positive_sample_loss at step 77000: 0.040244\n",
      "2023-12-03 01:38:30,654 INFO     Training average negative_sample_loss at step 77000: 0.016163\n",
      "2023-12-03 01:38:30,654 INFO     Training average loss at step 77000: 0.028203\n",
      "2023-12-03 01:38:36,634 INFO     Training average positive_sample_loss at step 77100: 0.040556\n",
      "2023-12-03 01:38:36,635 INFO     Training average negative_sample_loss at step 77100: 0.016057\n",
      "2023-12-03 01:38:36,635 INFO     Training average loss at step 77100: 0.028307\n",
      "2023-12-03 01:38:42,815 INFO     Training average positive_sample_loss at step 77200: 0.040668\n",
      "2023-12-03 01:38:42,815 INFO     Training average negative_sample_loss at step 77200: 0.016226\n",
      "2023-12-03 01:38:42,815 INFO     Training average loss at step 77200: 0.028447\n",
      "2023-12-03 01:38:48,306 INFO     Training average positive_sample_loss at step 77300: 0.040294\n",
      "2023-12-03 01:38:48,306 INFO     Training average negative_sample_loss at step 77300: 0.016120\n",
      "2023-12-03 01:38:48,306 INFO     Training average loss at step 77300: 0.028207\n",
      "2023-12-03 01:38:54,397 INFO     Training average positive_sample_loss at step 77400: 0.040351\n",
      "2023-12-03 01:38:54,397 INFO     Training average negative_sample_loss at step 77400: 0.016325\n",
      "2023-12-03 01:38:54,397 INFO     Training average loss at step 77400: 0.028338\n",
      "2023-12-03 01:39:00,490 INFO     Training average positive_sample_loss at step 77500: 0.040637\n",
      "2023-12-03 01:39:00,490 INFO     Training average negative_sample_loss at step 77500: 0.016003\n",
      "2023-12-03 01:39:00,490 INFO     Training average loss at step 77500: 0.028320\n",
      "2023-12-03 01:39:07,124 INFO     Training average positive_sample_loss at step 77600: 0.040388\n",
      "2023-12-03 01:39:07,124 INFO     Training average negative_sample_loss at step 77600: 0.016245\n",
      "2023-12-03 01:39:07,124 INFO     Training average loss at step 77600: 0.028316\n",
      "2023-12-03 01:39:12,571 INFO     Training average positive_sample_loss at step 77700: 0.040272\n",
      "2023-12-03 01:39:12,572 INFO     Training average negative_sample_loss at step 77700: 0.016125\n",
      "2023-12-03 01:39:12,572 INFO     Training average loss at step 77700: 0.028198\n",
      "2023-12-03 01:39:18,685 INFO     Training average positive_sample_loss at step 77800: 0.040599\n",
      "2023-12-03 01:39:18,686 INFO     Training average negative_sample_loss at step 77800: 0.016067\n",
      "2023-12-03 01:39:18,686 INFO     Training average loss at step 77800: 0.028333\n",
      "2023-12-03 01:39:25,183 INFO     Training average positive_sample_loss at step 77900: 0.040315\n",
      "2023-12-03 01:39:25,183 INFO     Training average negative_sample_loss at step 77900: 0.016141\n",
      "2023-12-03 01:39:25,183 INFO     Training average loss at step 77900: 0.028228\n",
      "2023-12-03 01:39:31,352 INFO     Training average positive_sample_loss at step 78000: 0.040393\n",
      "2023-12-03 01:39:31,353 INFO     Training average negative_sample_loss at step 78000: 0.016324\n",
      "2023-12-03 01:39:31,353 INFO     Training average loss at step 78000: 0.028359\n",
      "2023-12-03 01:39:36,888 INFO     Training average positive_sample_loss at step 78100: 0.040571\n",
      "2023-12-03 01:39:36,888 INFO     Training average negative_sample_loss at step 78100: 0.015853\n",
      "2023-12-03 01:39:36,888 INFO     Training average loss at step 78100: 0.028212\n",
      "2023-12-03 01:39:43,098 INFO     Training average positive_sample_loss at step 78200: 0.040524\n",
      "2023-12-03 01:39:43,098 INFO     Training average negative_sample_loss at step 78200: 0.016104\n",
      "2023-12-03 01:39:43,098 INFO     Training average loss at step 78200: 0.028314\n",
      "2023-12-03 01:39:49,416 INFO     Training average positive_sample_loss at step 78300: 0.040368\n",
      "2023-12-03 01:39:49,416 INFO     Training average negative_sample_loss at step 78300: 0.016069\n",
      "2023-12-03 01:39:49,416 INFO     Training average loss at step 78300: 0.028218\n",
      "2023-12-03 01:39:55,543 INFO     Training average positive_sample_loss at step 78400: 0.040400\n",
      "2023-12-03 01:39:55,543 INFO     Training average negative_sample_loss at step 78400: 0.016120\n",
      "2023-12-03 01:39:55,543 INFO     Training average loss at step 78400: 0.028260\n",
      "2023-12-03 01:40:01,654 INFO     Training average positive_sample_loss at step 78500: 0.040467\n",
      "2023-12-03 01:40:01,654 INFO     Training average negative_sample_loss at step 78500: 0.016074\n",
      "2023-12-03 01:40:01,654 INFO     Training average loss at step 78500: 0.028271\n",
      "2023-12-03 01:40:08,295 INFO     Training average positive_sample_loss at step 78600: 0.040191\n",
      "2023-12-03 01:40:08,295 INFO     Training average negative_sample_loss at step 78600: 0.016028\n",
      "2023-12-03 01:40:08,295 INFO     Training average loss at step 78600: 0.028109\n",
      "2023-12-03 01:40:13,861 INFO     Training average positive_sample_loss at step 78700: 0.040460\n",
      "2023-12-03 01:40:13,862 INFO     Training average negative_sample_loss at step 78700: 0.016155\n",
      "2023-12-03 01:40:13,862 INFO     Training average loss at step 78700: 0.028307\n",
      "2023-12-03 01:40:19,959 INFO     Training average positive_sample_loss at step 78800: 0.040455\n",
      "2023-12-03 01:40:19,960 INFO     Training average negative_sample_loss at step 78800: 0.015970\n",
      "2023-12-03 01:40:19,960 INFO     Training average loss at step 78800: 0.028212\n",
      "2023-12-03 01:40:26,578 INFO     Training average positive_sample_loss at step 78900: 0.040610\n",
      "2023-12-03 01:40:26,578 INFO     Training average negative_sample_loss at step 78900: 0.016116\n",
      "2023-12-03 01:40:26,578 INFO     Training average loss at step 78900: 0.028363\n",
      "2023-12-03 01:40:32,734 INFO     Training average positive_sample_loss at step 79000: 0.040328\n",
      "2023-12-03 01:40:32,735 INFO     Training average negative_sample_loss at step 79000: 0.016034\n",
      "2023-12-03 01:40:32,735 INFO     Training average loss at step 79000: 0.028181\n",
      "2023-12-03 01:40:38,885 INFO     Training average positive_sample_loss at step 79100: 0.040244\n",
      "2023-12-03 01:40:38,885 INFO     Training average negative_sample_loss at step 79100: 0.015944\n",
      "2023-12-03 01:40:38,885 INFO     Training average loss at step 79100: 0.028094\n",
      "2023-12-03 01:40:44,352 INFO     Training average positive_sample_loss at step 79200: 0.040666\n",
      "2023-12-03 01:40:44,353 INFO     Training average negative_sample_loss at step 79200: 0.016109\n",
      "2023-12-03 01:40:44,353 INFO     Training average loss at step 79200: 0.028388\n",
      "2023-12-03 01:40:50,872 INFO     Training average positive_sample_loss at step 79300: 0.040111\n",
      "2023-12-03 01:40:50,872 INFO     Training average negative_sample_loss at step 79300: 0.015940\n",
      "2023-12-03 01:40:50,872 INFO     Training average loss at step 79300: 0.028025\n",
      "2023-12-03 01:40:56,976 INFO     Training average positive_sample_loss at step 79400: 0.040415\n",
      "2023-12-03 01:40:56,976 INFO     Training average negative_sample_loss at step 79400: 0.016199\n",
      "2023-12-03 01:40:56,976 INFO     Training average loss at step 79400: 0.028307\n",
      "2023-12-03 01:41:03,100 INFO     Training average positive_sample_loss at step 79500: 0.040567\n",
      "2023-12-03 01:41:03,100 INFO     Training average negative_sample_loss at step 79500: 0.016283\n",
      "2023-12-03 01:41:03,100 INFO     Training average loss at step 79500: 0.028425\n",
      "2023-12-03 01:41:09,609 INFO     Training average positive_sample_loss at step 79600: 0.040485\n",
      "2023-12-03 01:41:09,610 INFO     Training average negative_sample_loss at step 79600: 0.016062\n",
      "2023-12-03 01:41:09,610 INFO     Training average loss at step 79600: 0.028274\n",
      "2023-12-03 01:41:15,182 INFO     Training average positive_sample_loss at step 79700: 0.040381\n",
      "2023-12-03 01:41:15,182 INFO     Training average negative_sample_loss at step 79700: 0.016079\n",
      "2023-12-03 01:41:15,182 INFO     Training average loss at step 79700: 0.028230\n",
      "2023-12-03 01:41:21,332 INFO     Training average positive_sample_loss at step 79800: 0.040464\n",
      "2023-12-03 01:41:21,332 INFO     Training average negative_sample_loss at step 79800: 0.016067\n",
      "2023-12-03 01:41:21,332 INFO     Training average loss at step 79800: 0.028265\n",
      "2023-12-03 01:41:27,736 INFO     Training average positive_sample_loss at step 79900: 0.040458\n",
      "2023-12-03 01:41:27,736 INFO     Training average negative_sample_loss at step 79900: 0.016083\n",
      "2023-12-03 01:41:27,736 INFO     Training average loss at step 79900: 0.028271\n",
      "2023-12-03 01:41:47,544 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 01:41:48,537 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 01:42:22,237 INFO     Valid MRR at step 79999: 0.478979\n",
      "2023-12-03 01:42:22,238 INFO     Valid MR at step 79999: 3301.097231\n",
      "2023-12-03 01:42:22,238 INFO     Valid HITS@1 at step 79999: 0.433916\n",
      "2023-12-03 01:42:22,238 INFO     Valid HITS@3 at step 79999: 0.492419\n",
      "2023-12-03 01:42:22,238 INFO     Valid HITS@10 at step 79999: 0.573006\n",
      "2023-12-03 01:42:22,238 INFO     Evaluating on Test Dataset...\n",
      "2023-12-03 01:42:22,693 INFO     Evaluating the model... (0/784)\n",
      "2023-12-03 01:42:52,728 INFO     Test MRR at step 79999: 0.475920\n",
      "2023-12-03 01:42:52,728 INFO     Test MR at step 79999: 3383.699745\n",
      "2023-12-03 01:42:52,729 INFO     Test HITS@1 at step 79999: 0.428047\n",
      "2023-12-03 01:42:52,729 INFO     Test HITS@3 at step 79999: 0.495214\n",
      "2023-12-03 01:42:52,729 INFO     Test HITS@10 at step 79999: 0.573070\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE wn18rr 0 0 512 1024 500 6.0 0.5 0.00005 80000 8 -de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento RotatE con variante NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd KnowledgeGraphEmbedding_variant_NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-09 18:40:20,574 INFO     Model: RotatE\n",
      "2023-12-09 18:40:20,577 INFO     Data Path: data/wn18rr\n",
      "2023-12-09 18:40:20,578 INFO     #entity: 40943\n",
      "2023-12-09 18:40:20,578 INFO     #relation: 11\n",
      "2023-12-09 18:40:20,749 INFO     #train: 86835\n",
      "2023-12-09 18:40:20,754 INFO     #valid: 3034\n",
      "2023-12-09 18:40:20,792 INFO     #test: 3134\n",
      "2023-12-09 18:40:21,023 INFO     Model Parameter Configuration:\n",
      "2023-12-09 18:40:21,024 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-09 18:40:21,024 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-09 18:40:21,024 INFO     Parameter entity_embedding: torch.Size([40943, 1000]), require_grad = True\n",
      "2023-12-09 18:40:21,024 INFO     Parameter relation_embedding: torch.Size([11, 500]), require_grad = True\n",
      "2023-12-09 18:40:22,558 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-09 18:40:22,558 INFO     Start Training...\n",
      "2023-12-09 18:40:22,558 INFO     init_step = 0\n",
      "2023-12-09 18:40:22,558 INFO     batch_size = 512\n",
      "2023-12-09 18:40:22,558 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-09 18:40:22,558 INFO     hidden_dim = 500\n",
      "2023-12-09 18:40:22,558 INFO     gamma = 6.000000\n",
      "2023-12-09 18:40:22,558 INFO     negative_adversarial_sampling = True\n",
      "2023-12-09 18:40:22,559 INFO     adversarial_temperature = 0.500000\n",
      "2023-12-09 18:40:22,559 INFO     learning_rate = 0\n",
      "2023-12-09 18:40:41,027 INFO     Training average positive_sample_loss at step 0: 2.453177\n",
      "2023-12-09 18:40:41,027 INFO     Training average negative_sample_loss at step 0: 0.093180\n",
      "2023-12-09 18:40:41,027 INFO     Training average loss at step 0: 1.273179\n",
      "2023-12-09 18:40:41,027 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 18:40:41,605 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 18:41:15,896 INFO     Valid MRR at step 0: 0.000462\n",
      "2023-12-09 18:41:15,896 INFO     Valid MR at step 0: 20411.480224\n",
      "2023-12-09 18:41:15,896 INFO     Valid HITS@1 at step 0: 0.000165\n",
      "2023-12-09 18:41:15,896 INFO     Valid HITS@3 at step 0: 0.000330\n",
      "2023-12-09 18:41:15,896 INFO     Valid HITS@10 at step 0: 0.000494\n",
      "2023-12-09 18:41:27,512 INFO     Training average positive_sample_loss at step 100: 2.872020\n",
      "2023-12-09 18:41:27,512 INFO     Training average negative_sample_loss at step 100: 0.071452\n",
      "2023-12-09 18:41:27,512 INFO     Training average loss at step 100: 1.471736\n",
      "2023-12-09 18:41:38,106 INFO     Training average positive_sample_loss at step 200: 2.710987\n",
      "2023-12-09 18:41:38,107 INFO     Training average negative_sample_loss at step 200: 0.100414\n",
      "2023-12-09 18:41:38,107 INFO     Training average loss at step 200: 1.405701\n",
      "2023-12-09 18:41:49,104 INFO     Training average positive_sample_loss at step 300: 2.317519\n",
      "2023-12-09 18:41:49,105 INFO     Training average negative_sample_loss at step 300: 0.145532\n",
      "2023-12-09 18:41:49,105 INFO     Training average loss at step 300: 1.231526\n",
      "2023-12-09 18:42:03,834 INFO     Training average positive_sample_loss at step 400: 1.793984\n",
      "2023-12-09 18:42:03,835 INFO     Training average negative_sample_loss at step 400: 0.200013\n",
      "2023-12-09 18:42:03,835 INFO     Training average loss at step 400: 0.996998\n",
      "2023-12-09 18:42:17,102 INFO     Training average positive_sample_loss at step 500: 1.455096\n",
      "2023-12-09 18:42:17,103 INFO     Training average negative_sample_loss at step 500: 0.245628\n",
      "2023-12-09 18:42:17,103 INFO     Training average loss at step 500: 0.850362\n",
      "2023-12-09 18:42:31,536 INFO     Training average positive_sample_loss at step 600: 1.268067\n",
      "2023-12-09 18:42:31,536 INFO     Training average negative_sample_loss at step 600: 0.285508\n",
      "2023-12-09 18:42:31,536 INFO     Training average loss at step 600: 0.776787\n",
      "2023-12-09 18:42:48,209 INFO     Training average positive_sample_loss at step 700: 1.077435\n",
      "2023-12-09 18:42:48,209 INFO     Training average negative_sample_loss at step 700: 0.319522\n",
      "2023-12-09 18:42:48,209 INFO     Training average loss at step 700: 0.698479\n",
      "2023-12-09 18:43:02,536 INFO     Training average positive_sample_loss at step 800: 0.853127\n",
      "2023-12-09 18:43:02,537 INFO     Training average negative_sample_loss at step 800: 0.343597\n",
      "2023-12-09 18:43:02,537 INFO     Training average loss at step 800: 0.598362\n",
      "2023-12-09 18:43:16,797 INFO     Training average positive_sample_loss at step 900: 0.791028\n",
      "2023-12-09 18:43:16,797 INFO     Training average negative_sample_loss at step 900: 0.354782\n",
      "2023-12-09 18:43:16,797 INFO     Training average loss at step 900: 0.572905\n",
      "2023-12-09 18:43:29,431 INFO     Training average positive_sample_loss at step 1000: 0.730899\n",
      "2023-12-09 18:43:29,431 INFO     Training average negative_sample_loss at step 1000: 0.363930\n",
      "2023-12-09 18:43:29,431 INFO     Training average loss at step 1000: 0.547415\n",
      "2023-12-09 18:43:45,585 INFO     Training average positive_sample_loss at step 1100: 0.605174\n",
      "2023-12-09 18:43:45,585 INFO     Training average negative_sample_loss at step 1100: 0.367942\n",
      "2023-12-09 18:43:45,585 INFO     Training average loss at step 1100: 0.486558\n",
      "2023-12-09 18:43:59,935 INFO     Training average positive_sample_loss at step 1200: 0.568385\n",
      "2023-12-09 18:43:59,936 INFO     Training average negative_sample_loss at step 1200: 0.362316\n",
      "2023-12-09 18:43:59,936 INFO     Training average loss at step 1200: 0.465350\n",
      "2023-12-09 18:44:14,177 INFO     Training average positive_sample_loss at step 1300: 0.547553\n",
      "2023-12-09 18:44:14,177 INFO     Training average negative_sample_loss at step 1300: 0.357035\n",
      "2023-12-09 18:44:14,177 INFO     Training average loss at step 1300: 0.452294\n",
      "2023-12-09 18:44:30,266 INFO     Training average positive_sample_loss at step 1400: 0.500087\n",
      "2023-12-09 18:44:30,267 INFO     Training average negative_sample_loss at step 1400: 0.351031\n",
      "2023-12-09 18:44:30,267 INFO     Training average loss at step 1400: 0.425559\n",
      "2023-12-09 18:44:44,445 INFO     Training average positive_sample_loss at step 1500: 0.453538\n",
      "2023-12-09 18:44:44,445 INFO     Training average negative_sample_loss at step 1500: 0.338254\n",
      "2023-12-09 18:44:44,445 INFO     Training average loss at step 1500: 0.395896\n",
      "2023-12-09 18:44:57,072 INFO     Training average positive_sample_loss at step 1600: 0.451022\n",
      "2023-12-09 18:44:57,072 INFO     Training average negative_sample_loss at step 1600: 0.327450\n",
      "2023-12-09 18:44:57,072 INFO     Training average loss at step 1600: 0.389236\n",
      "2023-12-09 18:45:12,419 INFO     Training average positive_sample_loss at step 1700: 0.441537\n",
      "2023-12-09 18:45:12,419 INFO     Training average negative_sample_loss at step 1700: 0.318937\n",
      "2023-12-09 18:45:12,420 INFO     Training average loss at step 1700: 0.380237\n",
      "2023-12-09 18:45:27,586 INFO     Training average positive_sample_loss at step 1800: 0.384435\n",
      "2023-12-09 18:45:27,586 INFO     Training average negative_sample_loss at step 1800: 0.305235\n",
      "2023-12-09 18:45:27,586 INFO     Training average loss at step 1800: 0.344835\n",
      "2023-12-09 18:45:41,881 INFO     Training average positive_sample_loss at step 1900: 0.386669\n",
      "2023-12-09 18:45:41,881 INFO     Training average negative_sample_loss at step 1900: 0.292473\n",
      "2023-12-09 18:45:41,881 INFO     Training average loss at step 1900: 0.339571\n",
      "2023-12-09 18:45:56,134 INFO     Training average positive_sample_loss at step 2000: 0.383980\n",
      "2023-12-09 18:45:56,135 INFO     Training average negative_sample_loss at step 2000: 0.282602\n",
      "2023-12-09 18:45:56,135 INFO     Training average loss at step 2000: 0.333291\n",
      "2023-12-09 18:46:10,912 INFO     Training average positive_sample_loss at step 2100: 0.352729\n",
      "2023-12-09 18:46:10,913 INFO     Training average negative_sample_loss at step 2100: 0.271883\n",
      "2023-12-09 18:46:10,913 INFO     Training average loss at step 2100: 0.312306\n",
      "2023-12-09 18:46:25,150 INFO     Training average positive_sample_loss at step 2200: 0.339280\n",
      "2023-12-09 18:46:25,150 INFO     Training average negative_sample_loss at step 2200: 0.258483\n",
      "2023-12-09 18:46:25,150 INFO     Training average loss at step 2200: 0.298881\n",
      "2023-12-09 18:46:39,554 INFO     Training average positive_sample_loss at step 2300: 0.340895\n",
      "2023-12-09 18:46:39,554 INFO     Training average negative_sample_loss at step 2300: 0.249500\n",
      "2023-12-09 18:46:39,554 INFO     Training average loss at step 2300: 0.295197\n",
      "2023-12-09 18:46:56,151 INFO     Training average positive_sample_loss at step 2400: 0.328977\n",
      "2023-12-09 18:46:56,152 INFO     Training average negative_sample_loss at step 2400: 0.240762\n",
      "2023-12-09 18:46:56,152 INFO     Training average loss at step 2400: 0.284869\n",
      "2023-12-09 18:47:10,560 INFO     Training average positive_sample_loss at step 2500: 0.300711\n",
      "2023-12-09 18:47:10,560 INFO     Training average negative_sample_loss at step 2500: 0.228947\n",
      "2023-12-09 18:47:10,561 INFO     Training average loss at step 2500: 0.264829\n",
      "2023-12-09 18:47:24,881 INFO     Training average positive_sample_loss at step 2600: 0.304827\n",
      "2023-12-09 18:47:24,881 INFO     Training average negative_sample_loss at step 2600: 0.220149\n",
      "2023-12-09 18:47:24,882 INFO     Training average loss at step 2600: 0.262488\n",
      "2023-12-09 18:47:37,667 INFO     Training average positive_sample_loss at step 2700: 0.305557\n",
      "2023-12-09 18:47:37,667 INFO     Training average negative_sample_loss at step 2700: 0.213011\n",
      "2023-12-09 18:47:37,668 INFO     Training average loss at step 2700: 0.259284\n",
      "2023-12-09 18:47:53,944 INFO     Training average positive_sample_loss at step 2800: 0.274911\n",
      "2023-12-09 18:47:53,944 INFO     Training average negative_sample_loss at step 2800: 0.204059\n",
      "2023-12-09 18:47:53,944 INFO     Training average loss at step 2800: 0.239485\n",
      "2023-12-09 18:48:08,288 INFO     Training average positive_sample_loss at step 2900: 0.274220\n",
      "2023-12-09 18:48:08,288 INFO     Training average negative_sample_loss at step 2900: 0.194951\n",
      "2023-12-09 18:48:08,288 INFO     Training average loss at step 2900: 0.234585\n",
      "2023-12-09 18:48:22,560 INFO     Training average positive_sample_loss at step 3000: 0.277190\n",
      "2023-12-09 18:48:22,560 INFO     Training average negative_sample_loss at step 3000: 0.188626\n",
      "2023-12-09 18:48:22,560 INFO     Training average loss at step 3000: 0.232908\n",
      "2023-12-09 18:48:39,329 INFO     Training average positive_sample_loss at step 3100: 0.262889\n",
      "2023-12-09 18:48:39,329 INFO     Training average negative_sample_loss at step 3100: 0.182572\n",
      "2023-12-09 18:48:39,329 INFO     Training average loss at step 3100: 0.222731\n",
      "2023-12-09 18:48:52,048 INFO     Training average positive_sample_loss at step 3200: 0.247398\n",
      "2023-12-09 18:48:52,048 INFO     Training average negative_sample_loss at step 3200: 0.173940\n",
      "2023-12-09 18:48:52,048 INFO     Training average loss at step 3200: 0.210669\n",
      "2023-12-09 18:49:06,188 INFO     Training average positive_sample_loss at step 3300: 0.251896\n",
      "2023-12-09 18:49:06,188 INFO     Training average negative_sample_loss at step 3300: 0.168179\n",
      "2023-12-09 18:49:06,188 INFO     Training average loss at step 3300: 0.210038\n",
      "2023-12-09 18:49:21,704 INFO     Training average positive_sample_loss at step 3400: 0.251895\n",
      "2023-12-09 18:49:21,704 INFO     Training average negative_sample_loss at step 3400: 0.163545\n",
      "2023-12-09 18:49:21,704 INFO     Training average loss at step 3400: 0.207720\n",
      "2023-12-09 18:49:36,914 INFO     Training average positive_sample_loss at step 3500: 0.224040\n",
      "2023-12-09 18:49:36,914 INFO     Training average negative_sample_loss at step 3500: 0.156394\n",
      "2023-12-09 18:49:36,914 INFO     Training average loss at step 3500: 0.190217\n",
      "2023-12-09 18:49:50,965 INFO     Training average positive_sample_loss at step 3600: 0.229285\n",
      "2023-12-09 18:49:50,965 INFO     Training average negative_sample_loss at step 3600: 0.150526\n",
      "2023-12-09 18:49:50,965 INFO     Training average loss at step 3600: 0.189905\n",
      "2023-12-09 18:50:05,317 INFO     Training average positive_sample_loss at step 3700: 0.232197\n",
      "2023-12-09 18:50:05,317 INFO     Training average negative_sample_loss at step 3700: 0.146583\n",
      "2023-12-09 18:50:05,317 INFO     Training average loss at step 3700: 0.189390\n",
      "2023-12-09 18:50:21,471 INFO     Training average positive_sample_loss at step 3800: 0.214200\n",
      "2023-12-09 18:50:21,471 INFO     Training average negative_sample_loss at step 3800: 0.141603\n",
      "2023-12-09 18:50:21,471 INFO     Training average loss at step 3800: 0.177901\n",
      "2023-12-09 18:50:35,735 INFO     Training average positive_sample_loss at step 3900: 0.209772\n",
      "2023-12-09 18:50:35,735 INFO     Training average negative_sample_loss at step 3900: 0.135639\n",
      "2023-12-09 18:50:35,735 INFO     Training average loss at step 3900: 0.172706\n",
      "2023-12-09 18:50:49,921 INFO     Training average positive_sample_loss at step 4000: 0.213659\n",
      "2023-12-09 18:50:49,921 INFO     Training average negative_sample_loss at step 4000: 0.131814\n",
      "2023-12-09 18:50:49,921 INFO     Training average loss at step 4000: 0.172736\n",
      "2023-12-09 18:51:06,326 INFO     Training average positive_sample_loss at step 4100: 0.208764\n",
      "2023-12-09 18:51:06,327 INFO     Training average negative_sample_loss at step 4100: 0.128617\n",
      "2023-12-09 18:51:06,327 INFO     Training average loss at step 4100: 0.168690\n",
      "2023-12-09 18:51:20,622 INFO     Training average positive_sample_loss at step 4200: 0.191936\n",
      "2023-12-09 18:51:20,622 INFO     Training average negative_sample_loss at step 4200: 0.123321\n",
      "2023-12-09 18:51:20,622 INFO     Training average loss at step 4200: 0.157629\n",
      "2023-12-09 18:51:34,041 INFO     Training average positive_sample_loss at step 4300: 0.196749\n",
      "2023-12-09 18:51:34,041 INFO     Training average negative_sample_loss at step 4300: 0.119372\n",
      "2023-12-09 18:51:34,041 INFO     Training average loss at step 4300: 0.158060\n",
      "2023-12-09 18:51:47,229 INFO     Training average positive_sample_loss at step 4400: 0.198696\n",
      "2023-12-09 18:51:47,230 INFO     Training average negative_sample_loss at step 4400: 0.116782\n",
      "2023-12-09 18:51:47,230 INFO     Training average loss at step 4400: 0.157739\n",
      "2023-12-09 18:52:03,295 INFO     Training average positive_sample_loss at step 4500: 0.181274\n",
      "2023-12-09 18:52:03,296 INFO     Training average negative_sample_loss at step 4500: 0.112945\n",
      "2023-12-09 18:52:03,296 INFO     Training average loss at step 4500: 0.147110\n",
      "2023-12-09 18:52:17,558 INFO     Training average positive_sample_loss at step 4600: 0.180858\n",
      "2023-12-09 18:52:17,559 INFO     Training average negative_sample_loss at step 4600: 0.108719\n",
      "2023-12-09 18:52:17,559 INFO     Training average loss at step 4600: 0.144788\n",
      "2023-12-09 18:52:31,894 INFO     Training average positive_sample_loss at step 4700: 0.184872\n",
      "2023-12-09 18:52:31,895 INFO     Training average negative_sample_loss at step 4700: 0.106083\n",
      "2023-12-09 18:52:31,895 INFO     Training average loss at step 4700: 0.145477\n",
      "2023-12-09 18:52:48,441 INFO     Training average positive_sample_loss at step 4800: 0.176778\n",
      "2023-12-09 18:52:48,442 INFO     Training average negative_sample_loss at step 4800: 0.103692\n",
      "2023-12-09 18:52:48,442 INFO     Training average loss at step 4800: 0.140235\n",
      "2023-12-09 18:53:01,040 INFO     Training average positive_sample_loss at step 4900: 0.167498\n",
      "2023-12-09 18:53:01,040 INFO     Training average negative_sample_loss at step 4900: 0.099850\n",
      "2023-12-09 18:53:01,040 INFO     Training average loss at step 4900: 0.133674\n",
      "2023-12-09 18:53:15,493 INFO     Training average positive_sample_loss at step 5000: 0.172256\n",
      "2023-12-09 18:53:15,493 INFO     Training average negative_sample_loss at step 5000: 0.097221\n",
      "2023-12-09 18:53:15,493 INFO     Training average loss at step 5000: 0.134738\n",
      "2023-12-09 18:53:30,808 INFO     Training average positive_sample_loss at step 5100: 0.172700\n",
      "2023-12-09 18:53:30,808 INFO     Training average negative_sample_loss at step 5100: 0.095254\n",
      "2023-12-09 18:53:30,808 INFO     Training average loss at step 5100: 0.133977\n",
      "2023-12-09 18:53:46,280 INFO     Training average positive_sample_loss at step 5200: 0.155461\n",
      "2023-12-09 18:53:46,281 INFO     Training average negative_sample_loss at step 5200: 0.091939\n",
      "2023-12-09 18:53:46,281 INFO     Training average loss at step 5200: 0.123700\n",
      "2023-12-09 18:54:00,647 INFO     Training average positive_sample_loss at step 5300: 0.160069\n",
      "2023-12-09 18:54:00,647 INFO     Training average negative_sample_loss at step 5300: 0.089337\n",
      "2023-12-09 18:54:00,647 INFO     Training average loss at step 5300: 0.124703\n",
      "2023-12-09 18:54:14,462 INFO     Training average positive_sample_loss at step 5400: 0.162699\n",
      "2023-12-09 18:54:14,462 INFO     Training average negative_sample_loss at step 5400: 0.087780\n",
      "2023-12-09 18:54:14,462 INFO     Training average loss at step 5400: 0.125240\n",
      "2023-12-09 18:54:29,961 INFO     Training average positive_sample_loss at step 5500: 0.151786\n",
      "2023-12-09 18:54:29,961 INFO     Training average negative_sample_loss at step 5500: 0.085482\n",
      "2023-12-09 18:54:29,961 INFO     Training average loss at step 5500: 0.118634\n",
      "2023-12-09 18:54:44,256 INFO     Training average positive_sample_loss at step 5600: 0.149364\n",
      "2023-12-09 18:54:44,257 INFO     Training average negative_sample_loss at step 5600: 0.082691\n",
      "2023-12-09 18:54:44,257 INFO     Training average loss at step 5600: 0.116027\n",
      "2023-12-09 18:54:58,603 INFO     Training average positive_sample_loss at step 5700: 0.152417\n",
      "2023-12-09 18:54:58,603 INFO     Training average negative_sample_loss at step 5700: 0.080649\n",
      "2023-12-09 18:54:58,603 INFO     Training average loss at step 5700: 0.116533\n",
      "2023-12-09 18:55:15,171 INFO     Training average positive_sample_loss at step 5800: 0.150039\n",
      "2023-12-09 18:55:15,171 INFO     Training average negative_sample_loss at step 5800: 0.079313\n",
      "2023-12-09 18:55:15,171 INFO     Training average loss at step 5800: 0.114676\n",
      "2023-12-09 18:55:29,470 INFO     Training average positive_sample_loss at step 5900: 0.139065\n",
      "2023-12-09 18:55:29,471 INFO     Training average negative_sample_loss at step 5900: 0.076906\n",
      "2023-12-09 18:55:29,471 INFO     Training average loss at step 5900: 0.107985\n",
      "2023-12-09 18:55:42,043 INFO     Training average positive_sample_loss at step 6000: 0.144385\n",
      "2023-12-09 18:55:42,043 INFO     Training average negative_sample_loss at step 6000: 0.075024\n",
      "2023-12-09 18:55:42,043 INFO     Training average loss at step 6000: 0.109704\n",
      "2023-12-09 18:55:56,204 INFO     Training average positive_sample_loss at step 6100: 0.144494\n",
      "2023-12-09 18:55:56,204 INFO     Training average negative_sample_loss at step 6100: 0.073817\n",
      "2023-12-09 18:55:56,204 INFO     Training average loss at step 6100: 0.109156\n",
      "2023-12-09 18:56:12,480 INFO     Training average positive_sample_loss at step 6200: 0.132796\n",
      "2023-12-09 18:56:12,480 INFO     Training average negative_sample_loss at step 6200: 0.071925\n",
      "2023-12-09 18:56:12,480 INFO     Training average loss at step 6200: 0.102361\n",
      "2023-12-09 18:56:26,809 INFO     Training average positive_sample_loss at step 6300: 0.134962\n",
      "2023-12-09 18:56:26,809 INFO     Training average negative_sample_loss at step 6300: 0.069886\n",
      "2023-12-09 18:56:26,809 INFO     Training average loss at step 6300: 0.102424\n",
      "2023-12-09 18:56:41,165 INFO     Training average positive_sample_loss at step 6400: 0.137255\n",
      "2023-12-09 18:56:41,165 INFO     Training average negative_sample_loss at step 6400: 0.068638\n",
      "2023-12-09 18:56:41,165 INFO     Training average loss at step 6400: 0.102947\n",
      "2023-12-09 18:56:57,807 INFO     Training average positive_sample_loss at step 6500: 0.132199\n",
      "2023-12-09 18:56:57,807 INFO     Training average negative_sample_loss at step 6500: 0.067588\n",
      "2023-12-09 18:56:57,807 INFO     Training average loss at step 6500: 0.099893\n",
      "2023-12-09 18:57:10,336 INFO     Training average positive_sample_loss at step 6600: 0.126583\n",
      "2023-12-09 18:57:10,337 INFO     Training average negative_sample_loss at step 6600: 0.065536\n",
      "2023-12-09 18:57:10,337 INFO     Training average loss at step 6600: 0.096059\n",
      "2023-12-09 18:57:24,696 INFO     Training average positive_sample_loss at step 6700: 0.129833\n",
      "2023-12-09 18:57:24,696 INFO     Training average negative_sample_loss at step 6700: 0.064198\n",
      "2023-12-09 18:57:24,696 INFO     Training average loss at step 6700: 0.097015\n",
      "2023-12-09 18:57:40,010 INFO     Training average positive_sample_loss at step 6800: 0.132043\n",
      "2023-12-09 18:57:40,011 INFO     Training average negative_sample_loss at step 6800: 0.063399\n",
      "2023-12-09 18:57:40,011 INFO     Training average loss at step 6800: 0.097721\n",
      "2023-12-09 18:57:55,406 INFO     Training average positive_sample_loss at step 6900: 0.118111\n",
      "2023-12-09 18:57:55,406 INFO     Training average negative_sample_loss at step 6900: 0.061640\n",
      "2023-12-09 18:57:55,406 INFO     Training average loss at step 6900: 0.089875\n",
      "2023-12-09 18:58:09,742 INFO     Training average positive_sample_loss at step 7000: 0.123209\n",
      "2023-12-09 18:58:09,743 INFO     Training average negative_sample_loss at step 7000: 0.060252\n",
      "2023-12-09 18:58:09,743 INFO     Training average loss at step 7000: 0.091730\n",
      "2023-12-09 18:58:23,299 INFO     Training average positive_sample_loss at step 7100: 0.126163\n",
      "2023-12-09 18:58:23,299 INFO     Training average negative_sample_loss at step 7100: 0.059600\n",
      "2023-12-09 18:58:23,299 INFO     Training average loss at step 7100: 0.092881\n",
      "2023-12-09 18:58:38,738 INFO     Training average positive_sample_loss at step 7200: 0.117358\n",
      "2023-12-09 18:58:38,738 INFO     Training average negative_sample_loss at step 7200: 0.058599\n",
      "2023-12-09 18:58:38,738 INFO     Training average loss at step 7200: 0.087979\n",
      "2023-12-09 18:58:53,001 INFO     Training average positive_sample_loss at step 7300: 0.116890\n",
      "2023-12-09 18:58:53,001 INFO     Training average negative_sample_loss at step 7300: 0.056916\n",
      "2023-12-09 18:58:53,001 INFO     Training average loss at step 7300: 0.086903\n",
      "2023-12-09 18:59:07,262 INFO     Training average positive_sample_loss at step 7400: 0.119505\n",
      "2023-12-09 18:59:07,262 INFO     Training average negative_sample_loss at step 7400: 0.056059\n",
      "2023-12-09 18:59:07,262 INFO     Training average loss at step 7400: 0.087782\n",
      "2023-12-09 18:59:21,945 INFO     Training average positive_sample_loss at step 7500: 0.118035\n",
      "2023-12-09 18:59:21,946 INFO     Training average negative_sample_loss at step 7500: 0.055567\n",
      "2023-12-09 18:59:21,946 INFO     Training average loss at step 7500: 0.086801\n",
      "2023-12-09 18:59:35,288 INFO     Training average positive_sample_loss at step 7600: 0.109422\n",
      "2023-12-09 18:59:35,289 INFO     Training average negative_sample_loss at step 7600: 0.053846\n",
      "2023-12-09 18:59:35,289 INFO     Training average loss at step 7600: 0.081634\n",
      "2023-12-09 18:59:46,245 INFO     Training average positive_sample_loss at step 7700: 0.113988\n",
      "2023-12-09 18:59:46,246 INFO     Training average negative_sample_loss at step 7700: 0.053126\n",
      "2023-12-09 18:59:46,246 INFO     Training average loss at step 7700: 0.083557\n",
      "2023-12-09 18:59:58,951 INFO     Training average positive_sample_loss at step 7800: 0.116037\n",
      "2023-12-09 18:59:58,952 INFO     Training average negative_sample_loss at step 7800: 0.052552\n",
      "2023-12-09 18:59:58,952 INFO     Training average loss at step 7800: 0.084294\n",
      "2023-12-09 19:00:13,044 INFO     Training average positive_sample_loss at step 7900: 0.106789\n",
      "2023-12-09 19:00:13,045 INFO     Training average negative_sample_loss at step 7900: 0.051605\n",
      "2023-12-09 19:00:13,045 INFO     Training average loss at step 7900: 0.079197\n",
      "2023-12-09 19:00:26,286 INFO     Training average positive_sample_loss at step 8000: 0.108033\n",
      "2023-12-09 19:00:26,286 INFO     Training average negative_sample_loss at step 8000: 0.050330\n",
      "2023-12-09 19:00:26,286 INFO     Training average loss at step 8000: 0.079181\n",
      "2023-12-09 19:00:39,167 INFO     Training average positive_sample_loss at step 8100: 0.110969\n",
      "2023-12-09 19:00:39,168 INFO     Training average negative_sample_loss at step 8100: 0.049831\n",
      "2023-12-09 19:00:39,168 INFO     Training average loss at step 8100: 0.080400\n",
      "2023-12-09 19:00:53,611 INFO     Training average positive_sample_loss at step 8200: 0.107101\n",
      "2023-12-09 19:00:53,611 INFO     Training average negative_sample_loss at step 8200: 0.049166\n",
      "2023-12-09 19:00:53,611 INFO     Training average loss at step 8200: 0.078134\n",
      "2023-12-09 19:01:05,021 INFO     Training average positive_sample_loss at step 8300: 0.102805\n",
      "2023-12-09 19:01:05,021 INFO     Training average negative_sample_loss at step 8300: 0.048094\n",
      "2023-12-09 19:01:05,021 INFO     Training average loss at step 8300: 0.075450\n",
      "2023-12-09 19:01:17,798 INFO     Training average positive_sample_loss at step 8400: 0.106052\n",
      "2023-12-09 19:01:17,798 INFO     Training average negative_sample_loss at step 8400: 0.047290\n",
      "2023-12-09 19:01:17,798 INFO     Training average loss at step 8400: 0.076671\n",
      "2023-12-09 19:01:31,010 INFO     Training average positive_sample_loss at step 8500: 0.107774\n",
      "2023-12-09 19:01:31,010 INFO     Training average negative_sample_loss at step 8500: 0.046990\n",
      "2023-12-09 19:01:31,010 INFO     Training average loss at step 8500: 0.077382\n",
      "2023-12-09 19:01:45,143 INFO     Training average positive_sample_loss at step 8600: 0.097277\n",
      "2023-12-09 19:01:45,144 INFO     Training average negative_sample_loss at step 8600: 0.046083\n",
      "2023-12-09 19:01:45,144 INFO     Training average loss at step 8600: 0.071680\n",
      "2023-12-09 19:01:58,262 INFO     Training average positive_sample_loss at step 8700: 0.101676\n",
      "2023-12-09 19:01:58,263 INFO     Training average negative_sample_loss at step 8700: 0.045168\n",
      "2023-12-09 19:01:58,263 INFO     Training average loss at step 8700: 0.073422\n",
      "2023-12-09 19:02:11,306 INFO     Training average positive_sample_loss at step 8800: 0.104458\n",
      "2023-12-09 19:02:11,306 INFO     Training average negative_sample_loss at step 8800: 0.044804\n",
      "2023-12-09 19:02:11,306 INFO     Training average loss at step 8800: 0.074631\n",
      "2023-12-09 19:02:25,203 INFO     Training average positive_sample_loss at step 8900: 0.097158\n",
      "2023-12-09 19:02:25,203 INFO     Training average negative_sample_loss at step 8900: 0.044425\n",
      "2023-12-09 19:02:25,203 INFO     Training average loss at step 8900: 0.070792\n",
      "2023-12-09 19:02:35,856 INFO     Training average positive_sample_loss at step 9000: 0.097039\n",
      "2023-12-09 19:02:35,857 INFO     Training average negative_sample_loss at step 9000: 0.043258\n",
      "2023-12-09 19:02:35,857 INFO     Training average loss at step 9000: 0.070149\n",
      "2023-12-09 19:02:48,796 INFO     Training average positive_sample_loss at step 9100: 0.100024\n",
      "2023-12-09 19:02:48,796 INFO     Training average negative_sample_loss at step 9100: 0.042867\n",
      "2023-12-09 19:02:48,796 INFO     Training average loss at step 9100: 0.071446\n",
      "2023-12-09 19:03:04,942 INFO     Training average positive_sample_loss at step 9200: 0.098352\n",
      "2023-12-09 19:03:04,942 INFO     Training average negative_sample_loss at step 9200: 0.042572\n",
      "2023-12-09 19:03:04,942 INFO     Training average loss at step 9200: 0.070462\n",
      "2023-12-09 19:03:18,136 INFO     Training average positive_sample_loss at step 9300: 0.092631\n",
      "2023-12-09 19:03:18,137 INFO     Training average negative_sample_loss at step 9300: 0.041775\n",
      "2023-12-09 19:03:18,137 INFO     Training average loss at step 9300: 0.067203\n",
      "2023-12-09 19:03:31,774 INFO     Training average positive_sample_loss at step 9400: 0.096360\n",
      "2023-12-09 19:03:31,774 INFO     Training average negative_sample_loss at step 9400: 0.041206\n",
      "2023-12-09 19:03:31,774 INFO     Training average loss at step 9400: 0.068783\n",
      "2023-12-09 19:03:44,396 INFO     Training average positive_sample_loss at step 9500: 0.097123\n",
      "2023-12-09 19:03:44,397 INFO     Training average negative_sample_loss at step 9500: 0.040872\n",
      "2023-12-09 19:03:44,397 INFO     Training average loss at step 9500: 0.068998\n",
      "2023-12-09 19:03:57,009 INFO     Training average positive_sample_loss at step 9600: 0.090444\n",
      "2023-12-09 19:03:57,009 INFO     Training average negative_sample_loss at step 9600: 0.040303\n",
      "2023-12-09 19:03:57,009 INFO     Training average loss at step 9600: 0.065373\n",
      "2023-12-09 19:04:08,129 INFO     Training average positive_sample_loss at step 9700: 0.091915\n",
      "2023-12-09 19:04:08,129 INFO     Training average negative_sample_loss at step 9700: 0.039611\n",
      "2023-12-09 19:04:08,129 INFO     Training average loss at step 9700: 0.065763\n",
      "2023-12-09 19:04:18,366 INFO     Training average positive_sample_loss at step 9800: 0.094560\n",
      "2023-12-09 19:04:18,367 INFO     Training average negative_sample_loss at step 9800: 0.039313\n",
      "2023-12-09 19:04:18,367 INFO     Training average loss at step 9800: 0.066937\n",
      "2023-12-09 19:04:30,577 INFO     Training average positive_sample_loss at step 9900: 0.091493\n",
      "2023-12-09 19:04:30,578 INFO     Training average negative_sample_loss at step 9900: 0.039009\n",
      "2023-12-09 19:04:30,578 INFO     Training average loss at step 9900: 0.065251\n",
      "2023-12-09 19:04:53,682 INFO     Training average positive_sample_loss at step 10000: 0.087937\n",
      "2023-12-09 19:04:53,682 INFO     Training average negative_sample_loss at step 10000: 0.038333\n",
      "2023-12-09 19:04:53,682 INFO     Training average loss at step 10000: 0.063135\n",
      "2023-12-09 19:04:53,682 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 19:04:54,222 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 19:05:30,643 INFO     Valid MRR at step 10000: 0.465683\n",
      "2023-12-09 19:05:30,644 INFO     Valid MR at step 10000: 4439.210613\n",
      "2023-12-09 19:05:30,644 INFO     Valid HITS@1 at step 10000: 0.434245\n",
      "2023-12-09 19:05:30,644 INFO     Valid HITS@3 at step 10000: 0.478411\n",
      "2023-12-09 19:05:30,644 INFO     Valid HITS@10 at step 10000: 0.524390\n",
      "2023-12-09 19:05:44,044 INFO     Training average positive_sample_loss at step 10100: 0.091045\n",
      "2023-12-09 19:05:44,044 INFO     Training average negative_sample_loss at step 10100: 0.037769\n",
      "2023-12-09 19:05:44,044 INFO     Training average loss at step 10100: 0.064407\n",
      "2023-12-09 19:05:58,346 INFO     Training average positive_sample_loss at step 10200: 0.092702\n",
      "2023-12-09 19:05:58,346 INFO     Training average negative_sample_loss at step 10200: 0.037765\n",
      "2023-12-09 19:05:58,346 INFO     Training average loss at step 10200: 0.065234\n",
      "2023-12-09 19:06:11,335 INFO     Training average positive_sample_loss at step 10300: 0.083688\n",
      "2023-12-09 19:06:11,335 INFO     Training average negative_sample_loss at step 10300: 0.037014\n",
      "2023-12-09 19:06:11,335 INFO     Training average loss at step 10300: 0.060351\n",
      "2023-12-09 19:06:22,718 INFO     Training average positive_sample_loss at step 10400: 0.088514\n",
      "2023-12-09 19:06:22,718 INFO     Training average negative_sample_loss at step 10400: 0.036680\n",
      "2023-12-09 19:06:22,718 INFO     Training average loss at step 10400: 0.062597\n",
      "2023-12-09 19:06:35,041 INFO     Training average positive_sample_loss at step 10500: 0.089774\n",
      "2023-12-09 19:06:35,041 INFO     Training average negative_sample_loss at step 10500: 0.036472\n",
      "2023-12-09 19:06:35,041 INFO     Training average loss at step 10500: 0.063123\n",
      "2023-12-09 19:06:49,227 INFO     Training average positive_sample_loss at step 10600: 0.084200\n",
      "2023-12-09 19:06:49,228 INFO     Training average negative_sample_loss at step 10600: 0.036048\n",
      "2023-12-09 19:06:49,228 INFO     Training average loss at step 10600: 0.060124\n",
      "2023-12-09 19:07:02,162 INFO     Training average positive_sample_loss at step 10700: 0.084770\n",
      "2023-12-09 19:07:02,162 INFO     Training average negative_sample_loss at step 10700: 0.035432\n",
      "2023-12-09 19:07:02,162 INFO     Training average loss at step 10700: 0.060101\n",
      "2023-12-09 19:07:15,613 INFO     Training average positive_sample_loss at step 10800: 0.087016\n",
      "2023-12-09 19:07:15,613 INFO     Training average negative_sample_loss at step 10800: 0.035198\n",
      "2023-12-09 19:07:15,613 INFO     Training average loss at step 10800: 0.061107\n",
      "2023-12-09 19:07:30,378 INFO     Training average positive_sample_loss at step 10900: 0.085944\n",
      "2023-12-09 19:07:30,379 INFO     Training average negative_sample_loss at step 10900: 0.035063\n",
      "2023-12-09 19:07:30,379 INFO     Training average loss at step 10900: 0.060504\n",
      "2023-12-09 19:07:41,152 INFO     Training average positive_sample_loss at step 11000: 0.080841\n",
      "2023-12-09 19:07:41,152 INFO     Training average negative_sample_loss at step 11000: 0.034400\n",
      "2023-12-09 19:07:41,152 INFO     Training average loss at step 11000: 0.057620\n",
      "2023-12-09 19:07:53,336 INFO     Training average positive_sample_loss at step 11100: 0.084349\n",
      "2023-12-09 19:07:53,337 INFO     Training average negative_sample_loss at step 11100: 0.034155\n",
      "2023-12-09 19:07:53,337 INFO     Training average loss at step 11100: 0.059252\n",
      "2023-12-09 19:08:06,479 INFO     Training average positive_sample_loss at step 11200: 0.085926\n",
      "2023-12-09 19:08:06,480 INFO     Training average negative_sample_loss at step 11200: 0.034108\n",
      "2023-12-09 19:08:06,480 INFO     Training average loss at step 11200: 0.060017\n",
      "2023-12-09 19:08:22,371 INFO     Training average positive_sample_loss at step 11300: 0.079746\n",
      "2023-12-09 19:08:22,372 INFO     Training average negative_sample_loss at step 11300: 0.033737\n",
      "2023-12-09 19:08:22,372 INFO     Training average loss at step 11300: 0.056741\n",
      "2023-12-09 19:08:35,579 INFO     Training average positive_sample_loss at step 11400: 0.081248\n",
      "2023-12-09 19:08:35,580 INFO     Training average negative_sample_loss at step 11400: 0.033186\n",
      "2023-12-09 19:08:35,580 INFO     Training average loss at step 11400: 0.057217\n",
      "2023-12-09 19:08:48,703 INFO     Training average positive_sample_loss at step 11500: 0.083450\n",
      "2023-12-09 19:08:48,703 INFO     Training average negative_sample_loss at step 11500: 0.032955\n",
      "2023-12-09 19:08:48,703 INFO     Training average loss at step 11500: 0.058203\n",
      "2023-12-09 19:09:02,327 INFO     Training average positive_sample_loss at step 11600: 0.080414\n",
      "2023-12-09 19:09:02,328 INFO     Training average negative_sample_loss at step 11600: 0.032898\n",
      "2023-12-09 19:09:02,328 INFO     Training average loss at step 11600: 0.056656\n",
      "2023-12-09 19:09:15,402 INFO     Training average positive_sample_loss at step 11700: 0.078242\n",
      "2023-12-09 19:09:15,402 INFO     Training average negative_sample_loss at step 11700: 0.032282\n",
      "2023-12-09 19:09:15,402 INFO     Training average loss at step 11700: 0.055262\n",
      "2023-12-09 19:09:28,761 INFO     Training average positive_sample_loss at step 11800: 0.080613\n",
      "2023-12-09 19:09:28,761 INFO     Training average negative_sample_loss at step 11800: 0.031962\n",
      "2023-12-09 19:09:28,761 INFO     Training average loss at step 11800: 0.056288\n",
      "2023-12-09 19:09:43,076 INFO     Training average positive_sample_loss at step 11900: 0.082720\n",
      "2023-12-09 19:09:43,076 INFO     Training average negative_sample_loss at step 11900: 0.032138\n",
      "2023-12-09 19:09:43,076 INFO     Training average loss at step 11900: 0.057429\n",
      "2023-12-09 19:09:55,406 INFO     Training average positive_sample_loss at step 12000: 0.074380\n",
      "2023-12-09 19:09:55,406 INFO     Training average negative_sample_loss at step 12000: 0.031603\n",
      "2023-12-09 19:09:55,406 INFO     Training average loss at step 12000: 0.052991\n",
      "2023-12-09 19:10:08,874 INFO     Training average positive_sample_loss at step 12100: 0.078720\n",
      "2023-12-09 19:10:08,874 INFO     Training average negative_sample_loss at step 12100: 0.031201\n",
      "2023-12-09 19:10:08,874 INFO     Training average loss at step 12100: 0.054961\n",
      "2023-12-09 19:10:20,318 INFO     Training average positive_sample_loss at step 12200: 0.080531\n",
      "2023-12-09 19:10:20,319 INFO     Training average negative_sample_loss at step 12200: 0.031175\n",
      "2023-12-09 19:10:20,319 INFO     Training average loss at step 12200: 0.055853\n",
      "2023-12-09 19:10:33,514 INFO     Training average positive_sample_loss at step 12300: 0.076151\n",
      "2023-12-09 19:10:33,514 INFO     Training average negative_sample_loss at step 12300: 0.031088\n",
      "2023-12-09 19:10:33,514 INFO     Training average loss at step 12300: 0.053619\n",
      "2023-12-09 19:10:47,047 INFO     Training average positive_sample_loss at step 12400: 0.075807\n",
      "2023-12-09 19:10:47,048 INFO     Training average negative_sample_loss at step 12400: 0.030558\n",
      "2023-12-09 19:10:47,048 INFO     Training average loss at step 12400: 0.053183\n",
      "2023-12-09 19:10:59,884 INFO     Training average positive_sample_loss at step 12500: 0.078059\n",
      "2023-12-09 19:10:59,885 INFO     Training average negative_sample_loss at step 12500: 0.030323\n",
      "2023-12-09 19:10:59,885 INFO     Training average loss at step 12500: 0.054191\n",
      "2023-12-09 19:11:13,730 INFO     Training average positive_sample_loss at step 12600: 0.077254\n",
      "2023-12-09 19:11:13,730 INFO     Training average negative_sample_loss at step 12600: 0.030454\n",
      "2023-12-09 19:11:13,730 INFO     Training average loss at step 12600: 0.053854\n",
      "2023-12-09 19:11:24,990 INFO     Training average positive_sample_loss at step 12700: 0.073236\n",
      "2023-12-09 19:11:24,990 INFO     Training average negative_sample_loss at step 12700: 0.029952\n",
      "2023-12-09 19:11:24,990 INFO     Training average loss at step 12700: 0.051594\n",
      "2023-12-09 19:11:36,103 INFO     Training average positive_sample_loss at step 12800: 0.075717\n",
      "2023-12-09 19:11:36,104 INFO     Training average negative_sample_loss at step 12800: 0.029612\n",
      "2023-12-09 19:11:36,104 INFO     Training average loss at step 12800: 0.052665\n",
      "2023-12-09 19:11:45,925 INFO     Training average positive_sample_loss at step 12900: 0.077345\n",
      "2023-12-09 19:11:45,925 INFO     Training average negative_sample_loss at step 12900: 0.029565\n",
      "2023-12-09 19:11:45,925 INFO     Training average loss at step 12900: 0.053455\n",
      "2023-12-09 19:12:00,418 INFO     Training average positive_sample_loss at step 13000: 0.072364\n",
      "2023-12-09 19:12:00,419 INFO     Training average negative_sample_loss at step 13000: 0.029429\n",
      "2023-12-09 19:12:00,419 INFO     Training average loss at step 13000: 0.050897\n",
      "2023-12-09 19:12:13,556 INFO     Training average positive_sample_loss at step 13100: 0.073294\n",
      "2023-12-09 19:12:13,556 INFO     Training average negative_sample_loss at step 13100: 0.029030\n",
      "2023-12-09 19:12:13,556 INFO     Training average loss at step 13100: 0.051162\n",
      "2023-12-09 19:12:26,521 INFO     Training average positive_sample_loss at step 13200: 0.075754\n",
      "2023-12-09 19:12:26,521 INFO     Training average negative_sample_loss at step 13200: 0.028909\n",
      "2023-12-09 19:12:26,521 INFO     Training average loss at step 13200: 0.052331\n",
      "2023-12-09 19:12:40,769 INFO     Training average positive_sample_loss at step 13300: 0.072889\n",
      "2023-12-09 19:12:40,769 INFO     Training average negative_sample_loss at step 13300: 0.028851\n",
      "2023-12-09 19:12:40,769 INFO     Training average loss at step 13300: 0.050870\n",
      "2023-12-09 19:12:54,280 INFO     Training average positive_sample_loss at step 13400: 0.070948\n",
      "2023-12-09 19:12:54,280 INFO     Training average negative_sample_loss at step 13400: 0.028422\n",
      "2023-12-09 19:12:54,280 INFO     Training average loss at step 13400: 0.049685\n",
      "2023-12-09 19:13:05,108 INFO     Training average positive_sample_loss at step 13500: 0.073847\n",
      "2023-12-09 19:13:05,109 INFO     Training average negative_sample_loss at step 13500: 0.028332\n",
      "2023-12-09 19:13:05,109 INFO     Training average loss at step 13500: 0.051090\n",
      "2023-12-09 19:13:19,214 INFO     Training average positive_sample_loss at step 13600: 0.075089\n",
      "2023-12-09 19:13:19,214 INFO     Training average negative_sample_loss at step 13600: 0.028326\n",
      "2023-12-09 19:13:19,214 INFO     Training average loss at step 13600: 0.051708\n",
      "2023-12-09 19:13:32,621 INFO     Training average positive_sample_loss at step 13700: 0.068849\n",
      "2023-12-09 19:13:32,622 INFO     Training average negative_sample_loss at step 13700: 0.028029\n",
      "2023-12-09 19:13:32,622 INFO     Training average loss at step 13700: 0.048439\n",
      "2023-12-09 19:13:46,052 INFO     Training average positive_sample_loss at step 13800: 0.071192\n",
      "2023-12-09 19:13:46,052 INFO     Training average negative_sample_loss at step 13800: 0.027692\n",
      "2023-12-09 19:13:46,052 INFO     Training average loss at step 13800: 0.049442\n",
      "2023-12-09 19:13:59,096 INFO     Training average positive_sample_loss at step 13900: 0.073478\n",
      "2023-12-09 19:13:59,096 INFO     Training average negative_sample_loss at step 13900: 0.027804\n",
      "2023-12-09 19:13:59,096 INFO     Training average loss at step 13900: 0.050641\n",
      "2023-12-09 19:14:14,379 INFO     Training average positive_sample_loss at step 14000: 0.069542\n",
      "2023-12-09 19:14:14,379 INFO     Training average negative_sample_loss at step 14000: 0.027584\n",
      "2023-12-09 19:14:14,379 INFO     Training average loss at step 14000: 0.048563\n",
      "2023-12-09 19:14:25,034 INFO     Training average positive_sample_loss at step 14100: 0.069674\n",
      "2023-12-09 19:14:25,034 INFO     Training average negative_sample_loss at step 14100: 0.027222\n",
      "2023-12-09 19:14:25,035 INFO     Training average loss at step 14100: 0.048448\n",
      "2023-12-09 19:14:37,329 INFO     Training average positive_sample_loss at step 14200: 0.071619\n",
      "2023-12-09 19:14:37,330 INFO     Training average negative_sample_loss at step 14200: 0.027126\n",
      "2023-12-09 19:14:37,330 INFO     Training average loss at step 14200: 0.049373\n",
      "2023-12-09 19:14:51,148 INFO     Training average positive_sample_loss at step 14300: 0.070981\n",
      "2023-12-09 19:14:51,149 INFO     Training average negative_sample_loss at step 14300: 0.027156\n",
      "2023-12-09 19:14:51,149 INFO     Training average loss at step 14300: 0.049068\n",
      "2023-12-09 19:15:04,678 INFO     Training average positive_sample_loss at step 14400: 0.067086\n",
      "2023-12-09 19:15:04,678 INFO     Training average negative_sample_loss at step 14400: 0.026851\n",
      "2023-12-09 19:15:04,678 INFO     Training average loss at step 14400: 0.046968\n",
      "2023-12-09 19:15:17,501 INFO     Training average positive_sample_loss at step 14500: 0.069767\n",
      "2023-12-09 19:15:17,501 INFO     Training average negative_sample_loss at step 14500: 0.026662\n",
      "2023-12-09 19:15:17,501 INFO     Training average loss at step 14500: 0.048215\n",
      "2023-12-09 19:15:31,107 INFO     Training average positive_sample_loss at step 14600: 0.071687\n",
      "2023-12-09 19:15:31,108 INFO     Training average negative_sample_loss at step 14600: 0.026613\n",
      "2023-12-09 19:15:31,108 INFO     Training average loss at step 14600: 0.049150\n",
      "2023-12-09 19:15:43,211 INFO     Training average positive_sample_loss at step 14700: 0.065984\n",
      "2023-12-09 19:15:43,211 INFO     Training average negative_sample_loss at step 14700: 0.026496\n",
      "2023-12-09 19:15:43,211 INFO     Training average loss at step 14700: 0.046240\n",
      "2023-12-09 19:15:55,687 INFO     Training average positive_sample_loss at step 14800: 0.068077\n",
      "2023-12-09 19:15:55,687 INFO     Training average negative_sample_loss at step 14800: 0.026170\n",
      "2023-12-09 19:15:55,687 INFO     Training average loss at step 14800: 0.047123\n",
      "2023-12-09 19:16:08,910 INFO     Training average positive_sample_loss at step 14900: 0.069771\n",
      "2023-12-09 19:16:08,910 INFO     Training average negative_sample_loss at step 14900: 0.026119\n",
      "2023-12-09 19:16:08,911 INFO     Training average loss at step 14900: 0.047945\n",
      "2023-12-09 19:16:23,680 INFO     Training average positive_sample_loss at step 15000: 0.067640\n",
      "2023-12-09 19:16:23,680 INFO     Training average negative_sample_loss at step 15000: 0.026210\n",
      "2023-12-09 19:16:23,680 INFO     Training average loss at step 15000: 0.046925\n",
      "2023-12-09 19:16:37,163 INFO     Training average positive_sample_loss at step 15100: 0.065609\n",
      "2023-12-09 19:16:37,164 INFO     Training average negative_sample_loss at step 15100: 0.025701\n",
      "2023-12-09 19:16:37,164 INFO     Training average loss at step 15100: 0.045655\n",
      "2023-12-09 19:16:50,024 INFO     Training average positive_sample_loss at step 15200: 0.068366\n",
      "2023-12-09 19:16:50,024 INFO     Training average negative_sample_loss at step 15200: 0.025710\n",
      "2023-12-09 19:16:50,024 INFO     Training average loss at step 15200: 0.047038\n",
      "2023-12-09 19:17:03,233 INFO     Training average positive_sample_loss at step 15300: 0.069972\n",
      "2023-12-09 19:17:03,234 INFO     Training average negative_sample_loss at step 15300: 0.025847\n",
      "2023-12-09 19:17:03,234 INFO     Training average loss at step 15300: 0.047910\n",
      "2023-12-09 19:17:17,486 INFO     Training average positive_sample_loss at step 15400: 0.063594\n",
      "2023-12-09 19:17:17,486 INFO     Training average negative_sample_loss at step 15400: 0.025572\n",
      "2023-12-09 19:17:17,487 INFO     Training average loss at step 15400: 0.044583\n",
      "2023-12-09 19:17:30,968 INFO     Training average positive_sample_loss at step 15500: 0.066760\n",
      "2023-12-09 19:17:30,968 INFO     Training average negative_sample_loss at step 15500: 0.025317\n",
      "2023-12-09 19:17:30,968 INFO     Training average loss at step 15500: 0.046039\n",
      "2023-12-09 19:17:44,419 INFO     Training average positive_sample_loss at step 15600: 0.068440\n",
      "2023-12-09 19:17:44,419 INFO     Training average negative_sample_loss at step 15600: 0.025363\n",
      "2023-12-09 19:17:44,419 INFO     Training average loss at step 15600: 0.046901\n",
      "2023-12-09 19:17:58,283 INFO     Training average positive_sample_loss at step 15700: 0.064299\n",
      "2023-12-09 19:17:58,283 INFO     Training average negative_sample_loss at step 15700: 0.025175\n",
      "2023-12-09 19:17:58,283 INFO     Training average loss at step 15700: 0.044737\n",
      "2023-12-09 19:18:11,211 INFO     Training average positive_sample_loss at step 15800: 0.064839\n",
      "2023-12-09 19:18:11,211 INFO     Training average negative_sample_loss at step 15800: 0.024892\n",
      "2023-12-09 19:18:11,211 INFO     Training average loss at step 15800: 0.044865\n",
      "2023-12-09 19:18:22,876 INFO     Training average positive_sample_loss at step 15900: 0.066938\n",
      "2023-12-09 19:18:22,876 INFO     Training average negative_sample_loss at step 15900: 0.024913\n",
      "2023-12-09 19:18:22,876 INFO     Training average loss at step 15900: 0.045925\n",
      "2023-12-09 19:18:37,456 INFO     Training average positive_sample_loss at step 16000: 0.066174\n",
      "2023-12-09 19:18:37,456 INFO     Training average negative_sample_loss at step 16000: 0.024972\n",
      "2023-12-09 19:18:37,456 INFO     Training average loss at step 16000: 0.045573\n",
      "2023-12-09 19:18:49,504 INFO     Training average positive_sample_loss at step 16100: 0.062687\n",
      "2023-12-09 19:18:49,504 INFO     Training average negative_sample_loss at step 16100: 0.024718\n",
      "2023-12-09 19:18:49,504 INFO     Training average loss at step 16100: 0.043703\n",
      "2023-12-09 19:19:03,087 INFO     Training average positive_sample_loss at step 16200: 0.065295\n",
      "2023-12-09 19:19:03,087 INFO     Training average negative_sample_loss at step 16200: 0.024499\n",
      "2023-12-09 19:19:03,087 INFO     Training average loss at step 16200: 0.044897\n",
      "2023-12-09 19:19:16,516 INFO     Training average positive_sample_loss at step 16300: 0.066903\n",
      "2023-12-09 19:19:16,516 INFO     Training average negative_sample_loss at step 16300: 0.024606\n",
      "2023-12-09 19:19:16,516 INFO     Training average loss at step 16300: 0.045755\n",
      "2023-12-09 19:19:31,495 INFO     Training average positive_sample_loss at step 16400: 0.061867\n",
      "2023-12-09 19:19:31,496 INFO     Training average negative_sample_loss at step 16400: 0.024439\n",
      "2023-12-09 19:19:31,496 INFO     Training average loss at step 16400: 0.043153\n",
      "2023-12-09 19:19:42,191 INFO     Training average positive_sample_loss at step 16500: 0.063548\n",
      "2023-12-09 19:19:42,191 INFO     Training average negative_sample_loss at step 16500: 0.024168\n",
      "2023-12-09 19:19:42,191 INFO     Training average loss at step 16500: 0.043858\n",
      "2023-12-09 19:19:54,951 INFO     Training average positive_sample_loss at step 16600: 0.065605\n",
      "2023-12-09 19:19:54,952 INFO     Training average negative_sample_loss at step 16600: 0.024113\n",
      "2023-12-09 19:19:54,952 INFO     Training average loss at step 16600: 0.044859\n",
      "2023-12-09 19:20:10,324 INFO     Training average positive_sample_loss at step 16700: 0.063820\n",
      "2023-12-09 19:20:10,324 INFO     Training average negative_sample_loss at step 16700: 0.024224\n",
      "2023-12-09 19:20:10,324 INFO     Training average loss at step 16700: 0.044022\n",
      "2023-12-09 19:20:23,609 INFO     Training average positive_sample_loss at step 16800: 0.061643\n",
      "2023-12-09 19:20:23,609 INFO     Training average negative_sample_loss at step 16800: 0.023839\n",
      "2023-12-09 19:20:23,609 INFO     Training average loss at step 16800: 0.042741\n",
      "2023-12-09 19:20:36,527 INFO     Training average positive_sample_loss at step 16900: 0.064184\n",
      "2023-12-09 19:20:36,528 INFO     Training average negative_sample_loss at step 16900: 0.023850\n",
      "2023-12-09 19:20:36,528 INFO     Training average loss at step 16900: 0.044017\n",
      "2023-12-09 19:20:50,753 INFO     Training average positive_sample_loss at step 17000: 0.065487\n",
      "2023-12-09 19:20:50,753 INFO     Training average negative_sample_loss at step 17000: 0.023938\n",
      "2023-12-09 19:20:50,753 INFO     Training average loss at step 17000: 0.044713\n",
      "2023-12-09 19:21:02,218 INFO     Training average positive_sample_loss at step 17100: 0.060132\n",
      "2023-12-09 19:21:02,218 INFO     Training average negative_sample_loss at step 17100: 0.023803\n",
      "2023-12-09 19:21:02,218 INFO     Training average loss at step 17100: 0.041967\n",
      "2023-12-09 19:21:14,820 INFO     Training average positive_sample_loss at step 17200: 0.062634\n",
      "2023-12-09 19:21:14,820 INFO     Training average negative_sample_loss at step 17200: 0.023599\n",
      "2023-12-09 19:21:14,820 INFO     Training average loss at step 17200: 0.043117\n",
      "2023-12-09 19:21:27,666 INFO     Training average positive_sample_loss at step 17300: 0.064093\n",
      "2023-12-09 19:21:27,667 INFO     Training average negative_sample_loss at step 17300: 0.023564\n",
      "2023-12-09 19:21:27,667 INFO     Training average loss at step 17300: 0.043829\n",
      "2023-12-09 19:21:43,192 INFO     Training average positive_sample_loss at step 17400: 0.061191\n",
      "2023-12-09 19:21:43,193 INFO     Training average negative_sample_loss at step 17400: 0.023575\n",
      "2023-12-09 19:21:43,193 INFO     Training average loss at step 17400: 0.042383\n",
      "2023-12-09 19:21:56,679 INFO     Training average positive_sample_loss at step 17500: 0.061480\n",
      "2023-12-09 19:21:56,679 INFO     Training average negative_sample_loss at step 17500: 0.023346\n",
      "2023-12-09 19:21:56,679 INFO     Training average loss at step 17500: 0.042413\n",
      "2023-12-09 19:22:10,347 INFO     Training average positive_sample_loss at step 17600: 0.062686\n",
      "2023-12-09 19:22:10,347 INFO     Training average negative_sample_loss at step 17600: 0.023203\n",
      "2023-12-09 19:22:10,347 INFO     Training average loss at step 17600: 0.042945\n",
      "2023-12-09 19:22:24,781 INFO     Training average positive_sample_loss at step 17700: 0.062287\n",
      "2023-12-09 19:22:24,781 INFO     Training average negative_sample_loss at step 17700: 0.023287\n",
      "2023-12-09 19:22:24,781 INFO     Training average loss at step 17700: 0.042787\n",
      "2023-12-09 19:22:37,036 INFO     Training average positive_sample_loss at step 17800: 0.059447\n",
      "2023-12-09 19:22:37,037 INFO     Training average negative_sample_loss at step 17800: 0.023173\n",
      "2023-12-09 19:22:37,037 INFO     Training average loss at step 17800: 0.041310\n",
      "2023-12-09 19:22:50,251 INFO     Training average positive_sample_loss at step 17900: 0.061929\n",
      "2023-12-09 19:22:50,252 INFO     Training average negative_sample_loss at step 17900: 0.022899\n",
      "2023-12-09 19:22:50,252 INFO     Training average loss at step 17900: 0.042414\n",
      "2023-12-09 19:23:03,136 INFO     Training average positive_sample_loss at step 18000: 0.063165\n",
      "2023-12-09 19:23:03,137 INFO     Training average negative_sample_loss at step 18000: 0.023045\n",
      "2023-12-09 19:23:03,137 INFO     Training average loss at step 18000: 0.043105\n",
      "2023-12-09 19:23:18,094 INFO     Training average positive_sample_loss at step 18100: 0.059046\n",
      "2023-12-09 19:23:18,094 INFO     Training average negative_sample_loss at step 18100: 0.022950\n",
      "2023-12-09 19:23:18,094 INFO     Training average loss at step 18100: 0.040998\n",
      "2023-12-09 19:23:31,058 INFO     Training average positive_sample_loss at step 18200: 0.060469\n",
      "2023-12-09 19:23:31,058 INFO     Training average negative_sample_loss at step 18200: 0.022791\n",
      "2023-12-09 19:23:31,058 INFO     Training average loss at step 18200: 0.041630\n",
      "2023-12-09 19:23:41,593 INFO     Training average positive_sample_loss at step 18300: 0.061929\n",
      "2023-12-09 19:23:41,594 INFO     Training average negative_sample_loss at step 18300: 0.022729\n",
      "2023-12-09 19:23:41,594 INFO     Training average loss at step 18300: 0.042329\n",
      "2023-12-09 19:23:55,369 INFO     Training average positive_sample_loss at step 18400: 0.060021\n",
      "2023-12-09 19:23:55,369 INFO     Training average negative_sample_loss at step 18400: 0.022734\n",
      "2023-12-09 19:23:55,369 INFO     Training average loss at step 18400: 0.041378\n",
      "2023-12-09 19:24:07,187 INFO     Training average positive_sample_loss at step 18500: 0.059078\n",
      "2023-12-09 19:24:07,187 INFO     Training average negative_sample_loss at step 18500: 0.022533\n",
      "2023-12-09 19:24:07,187 INFO     Training average loss at step 18500: 0.040806\n",
      "2023-12-09 19:24:20,159 INFO     Training average positive_sample_loss at step 18600: 0.060945\n",
      "2023-12-09 19:24:20,159 INFO     Training average negative_sample_loss at step 18600: 0.022576\n",
      "2023-12-09 19:24:20,159 INFO     Training average loss at step 18600: 0.041760\n",
      "2023-12-09 19:24:33,433 INFO     Training average positive_sample_loss at step 18700: 0.061759\n",
      "2023-12-09 19:24:33,434 INFO     Training average negative_sample_loss at step 18700: 0.022543\n",
      "2023-12-09 19:24:33,434 INFO     Training average loss at step 18700: 0.042151\n",
      "2023-12-09 19:24:46,280 INFO     Training average positive_sample_loss at step 18800: 0.056869\n",
      "2023-12-09 19:24:46,280 INFO     Training average negative_sample_loss at step 18800: 0.022319\n",
      "2023-12-09 19:24:46,281 INFO     Training average loss at step 18800: 0.039594\n",
      "2023-12-09 19:24:58,919 INFO     Training average positive_sample_loss at step 18900: 0.059738\n",
      "2023-12-09 19:24:58,919 INFO     Training average negative_sample_loss at step 18900: 0.022188\n",
      "2023-12-09 19:24:58,919 INFO     Training average loss at step 18900: 0.040963\n",
      "2023-12-09 19:25:08,827 INFO     Training average positive_sample_loss at step 19000: 0.061252\n",
      "2023-12-09 19:25:08,827 INFO     Training average negative_sample_loss at step 19000: 0.022224\n",
      "2023-12-09 19:25:08,827 INFO     Training average loss at step 19000: 0.041738\n",
      "2023-12-09 19:25:24,327 INFO     Training average positive_sample_loss at step 19100: 0.057915\n",
      "2023-12-09 19:25:24,327 INFO     Training average negative_sample_loss at step 19100: 0.022308\n",
      "2023-12-09 19:25:24,327 INFO     Training average loss at step 19100: 0.040111\n",
      "2023-12-09 19:25:37,841 INFO     Training average positive_sample_loss at step 19200: 0.058062\n",
      "2023-12-09 19:25:37,841 INFO     Training average negative_sample_loss at step 19200: 0.021956\n",
      "2023-12-09 19:25:37,841 INFO     Training average loss at step 19200: 0.040009\n",
      "2023-12-09 19:25:51,040 INFO     Training average positive_sample_loss at step 19300: 0.060489\n",
      "2023-12-09 19:25:51,040 INFO     Training average negative_sample_loss at step 19300: 0.021979\n",
      "2023-12-09 19:25:51,041 INFO     Training average loss at step 19300: 0.041234\n",
      "2023-12-09 19:26:05,777 INFO     Training average positive_sample_loss at step 19400: 0.059835\n",
      "2023-12-09 19:26:05,778 INFO     Training average negative_sample_loss at step 19400: 0.022202\n",
      "2023-12-09 19:26:05,778 INFO     Training average loss at step 19400: 0.041019\n",
      "2023-12-09 19:26:18,742 INFO     Training average positive_sample_loss at step 19500: 0.056712\n",
      "2023-12-09 19:26:18,743 INFO     Training average negative_sample_loss at step 19500: 0.021922\n",
      "2023-12-09 19:26:18,743 INFO     Training average loss at step 19500: 0.039317\n",
      "2023-12-09 19:26:30,030 INFO     Training average positive_sample_loss at step 19600: 0.058589\n",
      "2023-12-09 19:26:30,031 INFO     Training average negative_sample_loss at step 19600: 0.021738\n",
      "2023-12-09 19:26:30,031 INFO     Training average loss at step 19600: 0.040164\n",
      "2023-12-09 19:26:42,753 INFO     Training average positive_sample_loss at step 19700: 0.060411\n",
      "2023-12-09 19:26:42,753 INFO     Training average negative_sample_loss at step 19700: 0.021843\n",
      "2023-12-09 19:26:42,753 INFO     Training average loss at step 19700: 0.041127\n",
      "2023-12-09 19:26:58,073 INFO     Training average positive_sample_loss at step 19800: 0.056130\n",
      "2023-12-09 19:26:58,074 INFO     Training average negative_sample_loss at step 19800: 0.021733\n",
      "2023-12-09 19:26:58,074 INFO     Training average loss at step 19800: 0.038931\n",
      "2023-12-09 19:27:11,215 INFO     Training average positive_sample_loss at step 19900: 0.057712\n",
      "2023-12-09 19:27:11,216 INFO     Training average negative_sample_loss at step 19900: 0.021517\n",
      "2023-12-09 19:27:11,216 INFO     Training average loss at step 19900: 0.039615\n",
      "2023-12-09 19:27:43,723 INFO     Training average positive_sample_loss at step 20000: 0.059790\n",
      "2023-12-09 19:27:43,723 INFO     Training average negative_sample_loss at step 20000: 0.021701\n",
      "2023-12-09 19:27:43,723 INFO     Training average loss at step 20000: 0.040745\n",
      "2023-12-09 19:27:43,723 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 19:27:44,244 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 19:28:22,918 INFO     Valid MRR at step 20000: 0.481296\n",
      "2023-12-09 19:28:22,919 INFO     Valid MR at step 20000: 2701.463909\n",
      "2023-12-09 19:28:22,919 INFO     Valid HITS@1 at step 20000: 0.443144\n",
      "2023-12-09 19:28:22,919 INFO     Valid HITS@3 at step 20000: 0.491925\n",
      "2023-12-09 19:28:22,919 INFO     Valid HITS@10 at step 20000: 0.555867\n",
      "2023-12-09 19:28:37,814 INFO     Training average positive_sample_loss at step 20100: 0.057470\n",
      "2023-12-09 19:28:37,814 INFO     Training average negative_sample_loss at step 20100: 0.021701\n",
      "2023-12-09 19:28:37,814 INFO     Training average loss at step 20100: 0.039586\n",
      "2023-12-09 19:28:49,920 INFO     Training average positive_sample_loss at step 20200: 0.056298\n",
      "2023-12-09 19:28:49,921 INFO     Training average negative_sample_loss at step 20200: 0.021408\n",
      "2023-12-09 19:28:49,921 INFO     Training average loss at step 20200: 0.038853\n",
      "2023-12-09 19:29:02,952 INFO     Training average positive_sample_loss at step 20300: 0.058451\n",
      "2023-12-09 19:29:02,952 INFO     Training average negative_sample_loss at step 20300: 0.021443\n",
      "2023-12-09 19:29:02,952 INFO     Training average loss at step 20300: 0.039947\n",
      "2023-12-09 19:29:13,574 INFO     Training average positive_sample_loss at step 20400: 0.059023\n",
      "2023-12-09 19:29:13,575 INFO     Training average negative_sample_loss at step 20400: 0.021558\n",
      "2023-12-09 19:29:13,575 INFO     Training average loss at step 20400: 0.040290\n",
      "2023-12-09 19:29:25,666 INFO     Training average positive_sample_loss at step 20500: 0.054442\n",
      "2023-12-09 19:29:25,666 INFO     Training average negative_sample_loss at step 20500: 0.021253\n",
      "2023-12-09 19:29:25,667 INFO     Training average loss at step 20500: 0.037847\n",
      "2023-12-09 19:29:36,838 INFO     Training average positive_sample_loss at step 20600: 0.057380\n",
      "2023-12-09 19:29:36,839 INFO     Training average negative_sample_loss at step 20600: 0.021327\n",
      "2023-12-09 19:29:36,839 INFO     Training average loss at step 20600: 0.039354\n",
      "2023-12-09 19:29:47,162 INFO     Training average positive_sample_loss at step 20700: 0.058587\n",
      "2023-12-09 19:29:47,163 INFO     Training average negative_sample_loss at step 20700: 0.021155\n",
      "2023-12-09 19:29:47,163 INFO     Training average loss at step 20700: 0.039871\n",
      "2023-12-09 19:29:59,436 INFO     Training average positive_sample_loss at step 20800: 0.055956\n",
      "2023-12-09 19:29:59,437 INFO     Training average negative_sample_loss at step 20800: 0.021262\n",
      "2023-12-09 19:29:59,437 INFO     Training average loss at step 20800: 0.038609\n",
      "2023-12-09 19:30:09,389 INFO     Training average positive_sample_loss at step 20900: 0.055942\n",
      "2023-12-09 19:30:09,389 INFO     Training average negative_sample_loss at step 20900: 0.021027\n",
      "2023-12-09 19:30:09,389 INFO     Training average loss at step 20900: 0.038485\n",
      "2023-12-09 19:30:19,578 INFO     Training average positive_sample_loss at step 21000: 0.057701\n",
      "2023-12-09 19:30:19,578 INFO     Training average negative_sample_loss at step 21000: 0.021147\n",
      "2023-12-09 19:30:19,578 INFO     Training average loss at step 21000: 0.039424\n",
      "2023-12-09 19:30:32,072 INFO     Training average positive_sample_loss at step 21100: 0.056939\n",
      "2023-12-09 19:30:32,073 INFO     Training average negative_sample_loss at step 21100: 0.021145\n",
      "2023-12-09 19:30:32,073 INFO     Training average loss at step 21100: 0.039042\n",
      "2023-12-09 19:30:43,446 INFO     Training average positive_sample_loss at step 21200: 0.054394\n",
      "2023-12-09 19:30:43,447 INFO     Training average negative_sample_loss at step 21200: 0.020926\n",
      "2023-12-09 19:30:43,447 INFO     Training average loss at step 21200: 0.037660\n",
      "2023-12-09 19:30:56,567 INFO     Training average positive_sample_loss at step 21300: 0.056722\n",
      "2023-12-09 19:30:56,567 INFO     Training average negative_sample_loss at step 21300: 0.020871\n",
      "2023-12-09 19:30:56,567 INFO     Training average loss at step 21300: 0.038797\n",
      "2023-12-09 19:31:08,661 INFO     Training average positive_sample_loss at step 21400: 0.058137\n",
      "2023-12-09 19:31:08,662 INFO     Training average negative_sample_loss at step 21400: 0.021010\n",
      "2023-12-09 19:31:08,662 INFO     Training average loss at step 21400: 0.039573\n",
      "2023-12-09 19:31:23,466 INFO     Training average positive_sample_loss at step 21500: 0.054113\n",
      "2023-12-09 19:31:23,467 INFO     Training average negative_sample_loss at step 21500: 0.020886\n",
      "2023-12-09 19:31:23,467 INFO     Training average loss at step 21500: 0.037499\n",
      "2023-12-09 19:31:37,091 INFO     Training average positive_sample_loss at step 21600: 0.055412\n",
      "2023-12-09 19:31:37,091 INFO     Training average negative_sample_loss at step 21600: 0.020797\n",
      "2023-12-09 19:31:37,091 INFO     Training average loss at step 21600: 0.038104\n",
      "2023-12-09 19:31:49,554 INFO     Training average positive_sample_loss at step 21700: 0.057173\n",
      "2023-12-09 19:31:49,554 INFO     Training average negative_sample_loss at step 21700: 0.020857\n",
      "2023-12-09 19:31:49,554 INFO     Training average loss at step 21700: 0.039015\n",
      "2023-12-09 19:32:03,159 INFO     Training average positive_sample_loss at step 21800: 0.055342\n",
      "2023-12-09 19:32:03,159 INFO     Training average negative_sample_loss at step 21800: 0.020877\n",
      "2023-12-09 19:32:03,159 INFO     Training average loss at step 21800: 0.038109\n",
      "2023-12-09 19:32:16,109 INFO     Training average positive_sample_loss at step 21900: 0.054380\n",
      "2023-12-09 19:32:16,109 INFO     Training average negative_sample_loss at step 21900: 0.020571\n",
      "2023-12-09 19:32:16,109 INFO     Training average loss at step 21900: 0.037475\n",
      "2023-12-09 19:32:29,318 INFO     Training average positive_sample_loss at step 22000: 0.056275\n",
      "2023-12-09 19:32:29,318 INFO     Training average negative_sample_loss at step 22000: 0.020597\n",
      "2023-12-09 19:32:29,318 INFO     Training average loss at step 22000: 0.038436\n",
      "2023-12-09 19:32:43,253 INFO     Training average positive_sample_loss at step 22100: 0.057202\n",
      "2023-12-09 19:32:43,254 INFO     Training average negative_sample_loss at step 22100: 0.020692\n",
      "2023-12-09 19:32:43,254 INFO     Training average loss at step 22100: 0.038947\n",
      "2023-12-09 19:32:57,540 INFO     Training average positive_sample_loss at step 22200: 0.052504\n",
      "2023-12-09 19:32:57,540 INFO     Training average negative_sample_loss at step 22200: 0.020496\n",
      "2023-12-09 19:32:57,540 INFO     Training average loss at step 22200: 0.036500\n",
      "2023-12-09 19:33:09,375 INFO     Training average positive_sample_loss at step 22300: 0.055096\n",
      "2023-12-09 19:33:09,376 INFO     Training average negative_sample_loss at step 22300: 0.020377\n",
      "2023-12-09 19:33:09,376 INFO     Training average loss at step 22300: 0.037736\n",
      "2023-12-09 19:33:20,545 INFO     Training average positive_sample_loss at step 22400: 0.056702\n",
      "2023-12-09 19:33:20,546 INFO     Training average negative_sample_loss at step 22400: 0.020497\n",
      "2023-12-09 19:33:20,546 INFO     Training average loss at step 22400: 0.038599\n",
      "2023-12-09 19:33:34,361 INFO     Training average positive_sample_loss at step 22500: 0.053992\n",
      "2023-12-09 19:33:34,362 INFO     Training average negative_sample_loss at step 22500: 0.020477\n",
      "2023-12-09 19:33:34,362 INFO     Training average loss at step 22500: 0.037235\n",
      "2023-12-09 19:33:46,723 INFO     Training average positive_sample_loss at step 22600: 0.053884\n",
      "2023-12-09 19:33:46,723 INFO     Training average negative_sample_loss at step 22600: 0.020220\n",
      "2023-12-09 19:33:46,723 INFO     Training average loss at step 22600: 0.037052\n",
      "2023-12-09 19:34:00,390 INFO     Training average positive_sample_loss at step 22700: 0.055992\n",
      "2023-12-09 19:34:00,390 INFO     Training average negative_sample_loss at step 22700: 0.020409\n",
      "2023-12-09 19:34:00,390 INFO     Training average loss at step 22700: 0.038200\n",
      "2023-12-09 19:34:15,550 INFO     Training average positive_sample_loss at step 22800: 0.055265\n",
      "2023-12-09 19:34:15,550 INFO     Training average negative_sample_loss at step 22800: 0.020506\n",
      "2023-12-09 19:34:15,550 INFO     Training average loss at step 22800: 0.037885\n",
      "2023-12-09 19:34:28,844 INFO     Training average positive_sample_loss at step 22900: 0.052365\n",
      "2023-12-09 19:34:28,845 INFO     Training average negative_sample_loss at step 22900: 0.020179\n",
      "2023-12-09 19:34:28,845 INFO     Training average loss at step 22900: 0.036272\n",
      "2023-12-09 19:34:40,871 INFO     Training average positive_sample_loss at step 23000: 0.054729\n",
      "2023-12-09 19:34:40,871 INFO     Training average negative_sample_loss at step 23000: 0.020190\n",
      "2023-12-09 19:34:40,871 INFO     Training average loss at step 23000: 0.037460\n",
      "2023-12-09 19:34:53,872 INFO     Training average positive_sample_loss at step 23100: 0.056274\n",
      "2023-12-09 19:34:53,872 INFO     Training average negative_sample_loss at step 23100: 0.020390\n",
      "2023-12-09 19:34:53,872 INFO     Training average loss at step 23100: 0.038332\n",
      "2023-12-09 19:35:08,194 INFO     Training average positive_sample_loss at step 23200: 0.052298\n",
      "2023-12-09 19:35:08,194 INFO     Training average negative_sample_loss at step 23200: 0.020342\n",
      "2023-12-09 19:35:08,194 INFO     Training average loss at step 23200: 0.036320\n",
      "2023-12-09 19:35:20,344 INFO     Training average positive_sample_loss at step 23300: 0.053538\n",
      "2023-12-09 19:35:20,345 INFO     Training average negative_sample_loss at step 23300: 0.019903\n",
      "2023-12-09 19:35:20,345 INFO     Training average loss at step 23300: 0.036720\n",
      "2023-12-09 19:35:33,796 INFO     Training average positive_sample_loss at step 23400: 0.055613\n",
      "2023-12-09 19:35:33,796 INFO     Training average negative_sample_loss at step 23400: 0.020068\n",
      "2023-12-09 19:35:33,796 INFO     Training average loss at step 23400: 0.037841\n",
      "2023-12-09 19:35:48,027 INFO     Training average positive_sample_loss at step 23500: 0.053728\n",
      "2023-12-09 19:35:48,027 INFO     Training average negative_sample_loss at step 23500: 0.020124\n",
      "2023-12-09 19:35:48,027 INFO     Training average loss at step 23500: 0.036926\n",
      "2023-12-09 19:35:58,596 INFO     Training average positive_sample_loss at step 23600: 0.052529\n",
      "2023-12-09 19:35:58,596 INFO     Training average negative_sample_loss at step 23600: 0.020000\n",
      "2023-12-09 19:35:58,596 INFO     Training average loss at step 23600: 0.036264\n",
      "2023-12-09 19:36:11,632 INFO     Training average positive_sample_loss at step 23700: 0.054202\n",
      "2023-12-09 19:36:11,632 INFO     Training average negative_sample_loss at step 23700: 0.019868\n",
      "2023-12-09 19:36:11,633 INFO     Training average loss at step 23700: 0.037035\n",
      "2023-12-09 19:36:26,174 INFO     Training average positive_sample_loss at step 23800: 0.055628\n",
      "2023-12-09 19:36:26,174 INFO     Training average negative_sample_loss at step 23800: 0.020047\n",
      "2023-12-09 19:36:26,175 INFO     Training average loss at step 23800: 0.037837\n",
      "2023-12-09 19:36:40,081 INFO     Training average positive_sample_loss at step 23900: 0.051308\n",
      "2023-12-09 19:36:40,082 INFO     Training average negative_sample_loss at step 23900: 0.019867\n",
      "2023-12-09 19:36:40,082 INFO     Training average loss at step 23900: 0.035588\n",
      "2023-12-09 19:36:53,016 INFO     Training average positive_sample_loss at step 24000: 0.053378\n",
      "2023-12-09 19:36:53,016 INFO     Training average negative_sample_loss at step 24000: 0.019859\n",
      "2023-12-09 19:36:53,016 INFO     Training average loss at step 24000: 0.036618\n",
      "2023-12-09 19:37:05,630 INFO     Training average positive_sample_loss at step 24100: 0.054621\n",
      "2023-12-09 19:37:05,631 INFO     Training average negative_sample_loss at step 24100: 0.019871\n",
      "2023-12-09 19:37:05,631 INFO     Training average loss at step 24100: 0.037246\n",
      "2023-12-09 19:37:19,809 INFO     Training average positive_sample_loss at step 24200: 0.052437\n",
      "2023-12-09 19:37:19,810 INFO     Training average negative_sample_loss at step 24200: 0.019946\n",
      "2023-12-09 19:37:19,810 INFO     Training average loss at step 24200: 0.036191\n",
      "2023-12-09 19:37:32,518 INFO     Training average positive_sample_loss at step 24300: 0.052388\n",
      "2023-12-09 19:37:32,518 INFO     Training average negative_sample_loss at step 24300: 0.019681\n",
      "2023-12-09 19:37:32,518 INFO     Training average loss at step 24300: 0.036035\n",
      "2023-12-09 19:37:45,419 INFO     Training average positive_sample_loss at step 24400: 0.054054\n",
      "2023-12-09 19:37:45,420 INFO     Training average negative_sample_loss at step 24400: 0.019653\n",
      "2023-12-09 19:37:45,420 INFO     Training average loss at step 24400: 0.036854\n",
      "2023-12-09 19:38:00,570 INFO     Training average positive_sample_loss at step 24500: 0.053745\n",
      "2023-12-09 19:38:00,570 INFO     Training average negative_sample_loss at step 24500: 0.019885\n",
      "2023-12-09 19:38:00,571 INFO     Training average loss at step 24500: 0.036815\n",
      "2023-12-09 19:38:13,732 INFO     Training average positive_sample_loss at step 24600: 0.050834\n",
      "2023-12-09 19:38:13,733 INFO     Training average negative_sample_loss at step 24600: 0.019459\n",
      "2023-12-09 19:38:13,733 INFO     Training average loss at step 24600: 0.035146\n",
      "2023-12-09 19:38:26,972 INFO     Training average positive_sample_loss at step 24700: 0.053484\n",
      "2023-12-09 19:38:26,973 INFO     Training average negative_sample_loss at step 24700: 0.019667\n",
      "2023-12-09 19:38:26,973 INFO     Training average loss at step 24700: 0.036575\n",
      "2023-12-09 19:38:38,473 INFO     Training average positive_sample_loss at step 24800: 0.054475\n",
      "2023-12-09 19:38:38,473 INFO     Training average negative_sample_loss at step 24800: 0.019736\n",
      "2023-12-09 19:38:38,473 INFO     Training average loss at step 24800: 0.037105\n",
      "2023-12-09 19:38:52,641 INFO     Training average positive_sample_loss at step 24900: 0.050790\n",
      "2023-12-09 19:38:52,641 INFO     Training average negative_sample_loss at step 24900: 0.019665\n",
      "2023-12-09 19:38:52,641 INFO     Training average loss at step 24900: 0.035228\n",
      "2023-12-09 19:39:05,428 INFO     Training average positive_sample_loss at step 25000: 0.052405\n",
      "2023-12-09 19:39:05,428 INFO     Training average negative_sample_loss at step 25000: 0.019580\n",
      "2023-12-09 19:39:05,428 INFO     Training average loss at step 25000: 0.035993\n",
      "2023-12-09 19:39:17,550 INFO     Training average positive_sample_loss at step 25100: 0.053885\n",
      "2023-12-09 19:39:17,550 INFO     Training average negative_sample_loss at step 25100: 0.019477\n",
      "2023-12-09 19:39:17,550 INFO     Training average loss at step 25100: 0.036681\n",
      "2023-12-09 19:39:32,681 INFO     Training average positive_sample_loss at step 25200: 0.052047\n",
      "2023-12-09 19:39:32,681 INFO     Training average negative_sample_loss at step 25200: 0.019677\n",
      "2023-12-09 19:39:32,681 INFO     Training average loss at step 25200: 0.035862\n",
      "2023-12-09 19:39:45,617 INFO     Training average positive_sample_loss at step 25300: 0.051495\n",
      "2023-12-09 19:39:45,617 INFO     Training average negative_sample_loss at step 25300: 0.019389\n",
      "2023-12-09 19:39:45,618 INFO     Training average loss at step 25300: 0.035442\n",
      "2023-12-09 19:39:55,732 INFO     Training average positive_sample_loss at step 25400: 0.052743\n",
      "2023-12-09 19:39:55,732 INFO     Training average negative_sample_loss at step 25400: 0.019317\n",
      "2023-12-09 19:39:55,732 INFO     Training average loss at step 25400: 0.036030\n",
      "2023-12-09 19:40:10,116 INFO     Training average positive_sample_loss at step 25500: 0.053768\n",
      "2023-12-09 19:40:10,116 INFO     Training average negative_sample_loss at step 25500: 0.019577\n",
      "2023-12-09 19:40:10,116 INFO     Training average loss at step 25500: 0.036673\n",
      "2023-12-09 19:40:24,277 INFO     Training average positive_sample_loss at step 25600: 0.049833\n",
      "2023-12-09 19:40:24,277 INFO     Training average negative_sample_loss at step 25600: 0.019410\n",
      "2023-12-09 19:40:24,277 INFO     Training average loss at step 25600: 0.034622\n",
      "2023-12-09 19:40:37,178 INFO     Training average positive_sample_loss at step 25700: 0.051984\n",
      "2023-12-09 19:40:37,179 INFO     Training average negative_sample_loss at step 25700: 0.019424\n",
      "2023-12-09 19:40:37,179 INFO     Training average loss at step 25700: 0.035704\n",
      "2023-12-09 19:40:50,107 INFO     Training average positive_sample_loss at step 25800: 0.053563\n",
      "2023-12-09 19:40:50,107 INFO     Training average negative_sample_loss at step 25800: 0.019364\n",
      "2023-12-09 19:40:50,107 INFO     Training average loss at step 25800: 0.036463\n",
      "2023-12-09 19:41:05,206 INFO     Training average positive_sample_loss at step 25900: 0.050823\n",
      "2023-12-09 19:41:05,207 INFO     Training average negative_sample_loss at step 25900: 0.019356\n",
      "2023-12-09 19:41:05,207 INFO     Training average loss at step 25900: 0.035090\n",
      "2023-12-09 19:41:16,136 INFO     Training average positive_sample_loss at step 26000: 0.051093\n",
      "2023-12-09 19:41:16,136 INFO     Training average negative_sample_loss at step 26000: 0.019342\n",
      "2023-12-09 19:41:16,136 INFO     Training average loss at step 26000: 0.035217\n",
      "2023-12-09 19:41:29,013 INFO     Training average positive_sample_loss at step 26100: 0.052717\n",
      "2023-12-09 19:41:29,014 INFO     Training average negative_sample_loss at step 26100: 0.019255\n",
      "2023-12-09 19:41:29,014 INFO     Training average loss at step 26100: 0.035986\n",
      "2023-12-09 19:41:44,128 INFO     Training average positive_sample_loss at step 26200: 0.052385\n",
      "2023-12-09 19:41:44,128 INFO     Training average negative_sample_loss at step 26200: 0.019281\n",
      "2023-12-09 19:41:44,128 INFO     Training average loss at step 26200: 0.035833\n",
      "2023-12-09 19:41:57,250 INFO     Training average positive_sample_loss at step 26300: 0.049755\n",
      "2023-12-09 19:41:57,251 INFO     Training average negative_sample_loss at step 26300: 0.019163\n",
      "2023-12-09 19:41:57,251 INFO     Training average loss at step 26300: 0.034459\n",
      "2023-12-09 19:42:10,154 INFO     Training average positive_sample_loss at step 26400: 0.052103\n",
      "2023-12-09 19:42:10,154 INFO     Training average negative_sample_loss at step 26400: 0.019029\n",
      "2023-12-09 19:42:10,154 INFO     Training average loss at step 26400: 0.035566\n",
      "2023-12-09 19:42:22,457 INFO     Training average positive_sample_loss at step 26500: 0.053216\n",
      "2023-12-09 19:42:22,457 INFO     Training average negative_sample_loss at step 26500: 0.019216\n",
      "2023-12-09 19:42:22,457 INFO     Training average loss at step 26500: 0.036216\n",
      "2023-12-09 19:42:35,212 INFO     Training average positive_sample_loss at step 26600: 0.049343\n",
      "2023-12-09 19:42:35,213 INFO     Training average negative_sample_loss at step 26600: 0.019286\n",
      "2023-12-09 19:42:35,213 INFO     Training average loss at step 26600: 0.034314\n",
      "2023-12-09 19:42:48,249 INFO     Training average positive_sample_loss at step 26700: 0.051327\n",
      "2023-12-09 19:42:48,249 INFO     Training average negative_sample_loss at step 26700: 0.019158\n",
      "2023-12-09 19:42:48,249 INFO     Training average loss at step 26700: 0.035243\n",
      "2023-12-09 19:43:01,005 INFO     Training average positive_sample_loss at step 26800: 0.052476\n",
      "2023-12-09 19:43:01,005 INFO     Training average negative_sample_loss at step 26800: 0.019099\n",
      "2023-12-09 19:43:01,005 INFO     Training average loss at step 26800: 0.035787\n",
      "2023-12-09 19:43:14,723 INFO     Training average positive_sample_loss at step 26900: 0.050762\n",
      "2023-12-09 19:43:14,723 INFO     Training average negative_sample_loss at step 26900: 0.019180\n",
      "2023-12-09 19:43:14,723 INFO     Training average loss at step 26900: 0.034971\n",
      "2023-12-09 19:43:27,653 INFO     Training average positive_sample_loss at step 27000: 0.050312\n",
      "2023-12-09 19:43:27,653 INFO     Training average negative_sample_loss at step 27000: 0.019112\n",
      "2023-12-09 19:43:27,653 INFO     Training average loss at step 27000: 0.034712\n",
      "2023-12-09 19:43:40,751 INFO     Training average positive_sample_loss at step 27100: 0.051563\n",
      "2023-12-09 19:43:40,751 INFO     Training average negative_sample_loss at step 27100: 0.018888\n",
      "2023-12-09 19:43:40,751 INFO     Training average loss at step 27100: 0.035225\n",
      "2023-12-09 19:43:54,530 INFO     Training average positive_sample_loss at step 27200: 0.052625\n",
      "2023-12-09 19:43:54,531 INFO     Training average negative_sample_loss at step 27200: 0.019029\n",
      "2023-12-09 19:43:54,531 INFO     Training average loss at step 27200: 0.035827\n",
      "2023-12-09 19:44:07,797 INFO     Training average positive_sample_loss at step 27300: 0.048664\n",
      "2023-12-09 19:44:07,797 INFO     Training average negative_sample_loss at step 27300: 0.019010\n",
      "2023-12-09 19:44:07,797 INFO     Training average loss at step 27300: 0.033837\n",
      "2023-12-09 19:44:21,023 INFO     Training average positive_sample_loss at step 27400: 0.050879\n",
      "2023-12-09 19:44:21,024 INFO     Training average negative_sample_loss at step 27400: 0.018877\n",
      "2023-12-09 19:44:21,024 INFO     Training average loss at step 27400: 0.034878\n",
      "2023-12-09 19:44:33,878 INFO     Training average positive_sample_loss at step 27500: 0.052191\n",
      "2023-12-09 19:44:33,879 INFO     Training average negative_sample_loss at step 27500: 0.018965\n",
      "2023-12-09 19:44:33,879 INFO     Training average loss at step 27500: 0.035578\n",
      "2023-12-09 19:44:48,715 INFO     Training average positive_sample_loss at step 27600: 0.049769\n",
      "2023-12-09 19:44:48,716 INFO     Training average negative_sample_loss at step 27600: 0.018915\n",
      "2023-12-09 19:44:48,716 INFO     Training average loss at step 27600: 0.034342\n",
      "2023-12-09 19:45:02,375 INFO     Training average positive_sample_loss at step 27700: 0.049996\n",
      "2023-12-09 19:45:02,376 INFO     Training average negative_sample_loss at step 27700: 0.018871\n",
      "2023-12-09 19:45:02,376 INFO     Training average loss at step 27700: 0.034433\n",
      "2023-12-09 19:45:14,730 INFO     Training average positive_sample_loss at step 27800: 0.051707\n",
      "2023-12-09 19:45:14,730 INFO     Training average negative_sample_loss at step 27800: 0.018966\n",
      "2023-12-09 19:45:14,730 INFO     Training average loss at step 27800: 0.035336\n",
      "2023-12-09 19:45:28,027 INFO     Training average positive_sample_loss at step 27900: 0.051121\n",
      "2023-12-09 19:45:28,027 INFO     Training average negative_sample_loss at step 27900: 0.018990\n",
      "2023-12-09 19:45:28,027 INFO     Training average loss at step 27900: 0.035056\n",
      "2023-12-09 19:45:41,301 INFO     Training average positive_sample_loss at step 28000: 0.049012\n",
      "2023-12-09 19:45:41,301 INFO     Training average negative_sample_loss at step 28000: 0.018847\n",
      "2023-12-09 19:45:41,301 INFO     Training average loss at step 28000: 0.033929\n",
      "2023-12-09 19:45:54,662 INFO     Training average positive_sample_loss at step 28100: 0.050434\n",
      "2023-12-09 19:45:54,662 INFO     Training average negative_sample_loss at step 28100: 0.018713\n",
      "2023-12-09 19:45:54,662 INFO     Training average loss at step 28100: 0.034574\n",
      "2023-12-09 19:46:08,205 INFO     Training average positive_sample_loss at step 28200: 0.052315\n",
      "2023-12-09 19:46:08,205 INFO     Training average negative_sample_loss at step 28200: 0.018898\n",
      "2023-12-09 19:46:08,205 INFO     Training average loss at step 28200: 0.035607\n",
      "2023-12-09 19:46:23,248 INFO     Training average positive_sample_loss at step 28300: 0.048333\n",
      "2023-12-09 19:46:23,249 INFO     Training average negative_sample_loss at step 28300: 0.018860\n",
      "2023-12-09 19:46:23,249 INFO     Training average loss at step 28300: 0.033597\n",
      "2023-12-09 19:46:34,418 INFO     Training average positive_sample_loss at step 28400: 0.049865\n",
      "2023-12-09 19:46:34,418 INFO     Training average negative_sample_loss at step 28400: 0.018687\n",
      "2023-12-09 19:46:34,418 INFO     Training average loss at step 28400: 0.034276\n",
      "2023-12-09 19:46:45,886 INFO     Training average positive_sample_loss at step 28500: 0.051530\n",
      "2023-12-09 19:46:45,886 INFO     Training average negative_sample_loss at step 28500: 0.018838\n",
      "2023-12-09 19:46:45,886 INFO     Training average loss at step 28500: 0.035184\n",
      "2023-12-09 19:47:00,817 INFO     Training average positive_sample_loss at step 28600: 0.050354\n",
      "2023-12-09 19:47:00,817 INFO     Training average negative_sample_loss at step 28600: 0.018870\n",
      "2023-12-09 19:47:00,817 INFO     Training average loss at step 28600: 0.034612\n",
      "2023-12-09 19:47:13,496 INFO     Training average positive_sample_loss at step 28700: 0.048766\n",
      "2023-12-09 19:47:13,497 INFO     Training average negative_sample_loss at step 28700: 0.018780\n",
      "2023-12-09 19:47:13,497 INFO     Training average loss at step 28700: 0.033773\n",
      "2023-12-09 19:47:26,455 INFO     Training average positive_sample_loss at step 28800: 0.051001\n",
      "2023-12-09 19:47:26,456 INFO     Training average negative_sample_loss at step 28800: 0.018652\n",
      "2023-12-09 19:47:26,456 INFO     Training average loss at step 28800: 0.034826\n",
      "2023-12-09 19:47:41,017 INFO     Training average positive_sample_loss at step 28900: 0.051454\n",
      "2023-12-09 19:47:41,017 INFO     Training average negative_sample_loss at step 28900: 0.018704\n",
      "2023-12-09 19:47:41,017 INFO     Training average loss at step 28900: 0.035079\n",
      "2023-12-09 19:47:54,550 INFO     Training average positive_sample_loss at step 29000: 0.047470\n",
      "2023-12-09 19:47:54,551 INFO     Training average negative_sample_loss at step 29000: 0.018649\n",
      "2023-12-09 19:47:54,551 INFO     Training average loss at step 29000: 0.033060\n",
      "2023-12-09 19:48:04,381 INFO     Training average positive_sample_loss at step 29100: 0.050137\n",
      "2023-12-09 19:48:04,382 INFO     Training average negative_sample_loss at step 29100: 0.018623\n",
      "2023-12-09 19:48:04,382 INFO     Training average loss at step 29100: 0.034380\n",
      "2023-12-09 19:48:16,718 INFO     Training average positive_sample_loss at step 29200: 0.051468\n",
      "2023-12-09 19:48:16,719 INFO     Training average negative_sample_loss at step 29200: 0.018784\n",
      "2023-12-09 19:48:16,719 INFO     Training average loss at step 29200: 0.035126\n",
      "2023-12-09 19:48:32,587 INFO     Training average positive_sample_loss at step 29300: 0.048706\n",
      "2023-12-09 19:48:32,587 INFO     Training average negative_sample_loss at step 29300: 0.018686\n",
      "2023-12-09 19:48:32,587 INFO     Training average loss at step 29300: 0.033696\n",
      "2023-12-09 19:48:46,162 INFO     Training average positive_sample_loss at step 29400: 0.049087\n",
      "2023-12-09 19:48:46,163 INFO     Training average negative_sample_loss at step 29400: 0.018617\n",
      "2023-12-09 19:48:46,163 INFO     Training average loss at step 29400: 0.033852\n",
      "2023-12-09 19:48:59,951 INFO     Training average positive_sample_loss at step 29500: 0.050607\n",
      "2023-12-09 19:48:59,951 INFO     Training average negative_sample_loss at step 29500: 0.018565\n",
      "2023-12-09 19:48:59,951 INFO     Training average loss at step 29500: 0.034586\n",
      "2023-12-09 19:49:14,410 INFO     Training average positive_sample_loss at step 29600: 0.049985\n",
      "2023-12-09 19:49:14,411 INFO     Training average negative_sample_loss at step 29600: 0.018543\n",
      "2023-12-09 19:49:14,411 INFO     Training average loss at step 29600: 0.034264\n",
      "2023-12-09 19:49:26,525 INFO     Training average positive_sample_loss at step 29700: 0.048046\n",
      "2023-12-09 19:49:26,526 INFO     Training average negative_sample_loss at step 29700: 0.018388\n",
      "2023-12-09 19:49:26,526 INFO     Training average loss at step 29700: 0.033217\n",
      "2023-12-09 19:49:39,778 INFO     Training average positive_sample_loss at step 29800: 0.049924\n",
      "2023-12-09 19:49:39,778 INFO     Training average negative_sample_loss at step 29800: 0.018572\n",
      "2023-12-09 19:49:39,778 INFO     Training average loss at step 29800: 0.034248\n",
      "2023-12-09 19:49:53,329 INFO     Training average positive_sample_loss at step 29900: 0.051033\n",
      "2023-12-09 19:49:53,329 INFO     Training average negative_sample_loss at step 29900: 0.018704\n",
      "2023-12-09 19:49:53,330 INFO     Training average loss at step 29900: 0.034868\n",
      "2023-12-09 19:50:24,679 INFO     Training average positive_sample_loss at step 30000: 0.047694\n",
      "2023-12-09 19:50:24,679 INFO     Training average negative_sample_loss at step 30000: 0.018580\n",
      "2023-12-09 19:50:24,680 INFO     Training average loss at step 30000: 0.033137\n",
      "2023-12-09 19:50:24,680 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 19:50:25,261 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 19:51:02,709 INFO     Valid MRR at step 30000: 0.481186\n",
      "2023-12-09 19:51:02,710 INFO     Valid MR at step 30000: 2087.063612\n",
      "2023-12-09 19:51:02,710 INFO     Valid HITS@1 at step 30000: 0.438365\n",
      "2023-12-09 19:51:02,710 INFO     Valid HITS@3 at step 30000: 0.495715\n",
      "2023-12-09 19:51:02,710 INFO     Valid HITS@10 at step 30000: 0.564601\n",
      "2023-12-09 19:51:14,649 INFO     Training average positive_sample_loss at step 30100: 0.049042\n",
      "2023-12-09 19:51:14,650 INFO     Training average negative_sample_loss at step 30100: 0.018382\n",
      "2023-12-09 19:51:14,650 INFO     Training average loss at step 30100: 0.033712\n",
      "2023-12-09 19:51:27,850 INFO     Training average positive_sample_loss at step 30200: 0.050709\n",
      "2023-12-09 19:51:27,850 INFO     Training average negative_sample_loss at step 30200: 0.018535\n",
      "2023-12-09 19:51:27,850 INFO     Training average loss at step 30200: 0.034622\n",
      "2023-12-09 19:51:42,501 INFO     Training average positive_sample_loss at step 30300: 0.048825\n",
      "2023-12-09 19:51:42,502 INFO     Training average negative_sample_loss at step 30300: 0.018502\n",
      "2023-12-09 19:51:42,502 INFO     Training average loss at step 30300: 0.033663\n",
      "2023-12-09 19:51:55,811 INFO     Training average positive_sample_loss at step 30400: 0.048051\n",
      "2023-12-09 19:51:55,812 INFO     Training average negative_sample_loss at step 30400: 0.018410\n",
      "2023-12-09 19:51:55,812 INFO     Training average loss at step 30400: 0.033231\n",
      "2023-12-09 19:52:06,433 INFO     Training average positive_sample_loss at step 30500: 0.049935\n",
      "2023-12-09 19:52:06,433 INFO     Training average negative_sample_loss at step 30500: 0.018268\n",
      "2023-12-09 19:52:06,434 INFO     Training average loss at step 30500: 0.034102\n",
      "2023-12-09 19:52:20,047 INFO     Training average positive_sample_loss at step 30600: 0.050755\n",
      "2023-12-09 19:52:20,047 INFO     Training average negative_sample_loss at step 30600: 0.018624\n",
      "2023-12-09 19:52:20,047 INFO     Training average loss at step 30600: 0.034689\n",
      "2023-12-09 19:52:34,401 INFO     Training average positive_sample_loss at step 30700: 0.046969\n",
      "2023-12-09 19:52:34,402 INFO     Training average negative_sample_loss at step 30700: 0.018317\n",
      "2023-12-09 19:52:34,402 INFO     Training average loss at step 30700: 0.032643\n",
      "2023-12-09 19:52:47,406 INFO     Training average positive_sample_loss at step 30800: 0.048996\n",
      "2023-12-09 19:52:47,406 INFO     Training average negative_sample_loss at step 30800: 0.018299\n",
      "2023-12-09 19:52:47,407 INFO     Training average loss at step 30800: 0.033648\n",
      "2023-12-09 19:52:59,444 INFO     Training average positive_sample_loss at step 30900: 0.050360\n",
      "2023-12-09 19:52:59,445 INFO     Training average negative_sample_loss at step 30900: 0.018419\n",
      "2023-12-09 19:52:59,445 INFO     Training average loss at step 30900: 0.034390\n",
      "2023-12-09 19:53:15,439 INFO     Training average positive_sample_loss at step 31000: 0.047895\n",
      "2023-12-09 19:53:15,439 INFO     Training average negative_sample_loss at step 31000: 0.018512\n",
      "2023-12-09 19:53:15,439 INFO     Training average loss at step 31000: 0.033204\n",
      "2023-12-09 19:53:26,391 INFO     Training average positive_sample_loss at step 31100: 0.048375\n",
      "2023-12-09 19:53:26,391 INFO     Training average negative_sample_loss at step 31100: 0.018280\n",
      "2023-12-09 19:53:26,391 INFO     Training average loss at step 31100: 0.033328\n",
      "2023-12-09 19:53:39,735 INFO     Training average positive_sample_loss at step 31200: 0.050020\n",
      "2023-12-09 19:53:39,735 INFO     Training average negative_sample_loss at step 31200: 0.018370\n",
      "2023-12-09 19:53:39,735 INFO     Training average loss at step 31200: 0.034195\n",
      "2023-12-09 19:53:55,184 INFO     Training average positive_sample_loss at step 31300: 0.049155\n",
      "2023-12-09 19:53:55,185 INFO     Training average negative_sample_loss at step 31300: 0.018479\n",
      "2023-12-09 19:53:55,185 INFO     Training average loss at step 31300: 0.033817\n",
      "2023-12-09 19:54:07,704 INFO     Training average positive_sample_loss at step 31400: 0.047177\n",
      "2023-12-09 19:54:07,704 INFO     Training average negative_sample_loss at step 31400: 0.018311\n",
      "2023-12-09 19:54:07,704 INFO     Training average loss at step 31400: 0.032744\n",
      "2023-12-09 19:54:21,146 INFO     Training average positive_sample_loss at step 31500: 0.049198\n",
      "2023-12-09 19:54:21,146 INFO     Training average negative_sample_loss at step 31500: 0.018242\n",
      "2023-12-09 19:54:21,146 INFO     Training average loss at step 31500: 0.033720\n",
      "2023-12-09 19:54:34,261 INFO     Training average positive_sample_loss at step 31600: 0.050182\n",
      "2023-12-09 19:54:34,261 INFO     Training average negative_sample_loss at step 31600: 0.018492\n",
      "2023-12-09 19:54:34,261 INFO     Training average loss at step 31600: 0.034337\n",
      "2023-12-09 19:54:48,371 INFO     Training average positive_sample_loss at step 31700: 0.046993\n",
      "2023-12-09 19:54:48,371 INFO     Training average negative_sample_loss at step 31700: 0.018208\n",
      "2023-12-09 19:54:48,371 INFO     Training average loss at step 31700: 0.032600\n",
      "2023-12-09 19:54:58,349 INFO     Training average positive_sample_loss at step 31800: 0.048474\n",
      "2023-12-09 19:54:58,350 INFO     Training average negative_sample_loss at step 31800: 0.018229\n",
      "2023-12-09 19:54:58,350 INFO     Training average loss at step 31800: 0.033352\n",
      "2023-12-09 19:55:11,403 INFO     Training average positive_sample_loss at step 31900: 0.049714\n",
      "2023-12-09 19:55:11,404 INFO     Training average negative_sample_loss at step 31900: 0.018244\n",
      "2023-12-09 19:55:11,404 INFO     Training average loss at step 31900: 0.033979\n",
      "2023-12-09 19:55:25,018 INFO     Training average positive_sample_loss at step 32000: 0.048110\n",
      "2023-12-09 19:55:25,018 INFO     Training average negative_sample_loss at step 32000: 0.018426\n",
      "2023-12-09 19:55:25,018 INFO     Training average loss at step 32000: 0.033268\n",
      "2023-12-09 19:55:35,143 INFO     Training average positive_sample_loss at step 32100: 0.047423\n",
      "2023-12-09 19:55:35,144 INFO     Training average negative_sample_loss at step 32100: 0.018028\n",
      "2023-12-09 19:55:35,144 INFO     Training average loss at step 32100: 0.032725\n",
      "2023-12-09 19:55:45,702 INFO     Training average positive_sample_loss at step 32200: 0.049034\n",
      "2023-12-09 19:55:45,703 INFO     Training average negative_sample_loss at step 32200: 0.018124\n",
      "2023-12-09 19:55:45,703 INFO     Training average loss at step 32200: 0.033579\n",
      "2023-12-09 19:55:56,459 INFO     Training average positive_sample_loss at step 32300: 0.050014\n",
      "2023-12-09 19:55:56,460 INFO     Training average negative_sample_loss at step 32300: 0.018289\n",
      "2023-12-09 19:55:56,460 INFO     Training average loss at step 32300: 0.034151\n",
      "2023-12-09 19:56:08,175 INFO     Training average positive_sample_loss at step 32400: 0.046218\n",
      "2023-12-09 19:56:08,176 INFO     Training average negative_sample_loss at step 32400: 0.018101\n",
      "2023-12-09 19:56:08,176 INFO     Training average loss at step 32400: 0.032159\n",
      "2023-12-09 19:56:18,135 INFO     Training average positive_sample_loss at step 32500: 0.048453\n",
      "2023-12-09 19:56:18,135 INFO     Training average negative_sample_loss at step 32500: 0.018165\n",
      "2023-12-09 19:56:18,135 INFO     Training average loss at step 32500: 0.033309\n",
      "2023-12-09 19:56:31,556 INFO     Training average positive_sample_loss at step 32600: 0.049695\n",
      "2023-12-09 19:56:31,556 INFO     Training average negative_sample_loss at step 32600: 0.018201\n",
      "2023-12-09 19:56:31,556 INFO     Training average loss at step 32600: 0.033948\n",
      "2023-12-09 19:56:46,701 INFO     Training average positive_sample_loss at step 32700: 0.046973\n",
      "2023-12-09 19:56:46,701 INFO     Training average negative_sample_loss at step 32700: 0.018249\n",
      "2023-12-09 19:56:46,701 INFO     Training average loss at step 32700: 0.032611\n",
      "2023-12-09 19:56:59,408 INFO     Training average positive_sample_loss at step 32800: 0.047315\n",
      "2023-12-09 19:56:59,408 INFO     Training average negative_sample_loss at step 32800: 0.018052\n",
      "2023-12-09 19:56:59,408 INFO     Training average loss at step 32800: 0.032683\n",
      "2023-12-09 19:57:12,495 INFO     Training average positive_sample_loss at step 32900: 0.049321\n",
      "2023-12-09 19:57:12,495 INFO     Training average negative_sample_loss at step 32900: 0.018113\n",
      "2023-12-09 19:57:12,495 INFO     Training average loss at step 32900: 0.033717\n",
      "2023-12-09 19:57:26,772 INFO     Training average positive_sample_loss at step 33000: 0.048814\n",
      "2023-12-09 19:57:26,773 INFO     Training average negative_sample_loss at step 33000: 0.018166\n",
      "2023-12-09 19:57:26,773 INFO     Training average loss at step 33000: 0.033490\n",
      "2023-12-09 19:57:40,203 INFO     Training average positive_sample_loss at step 33100: 0.046572\n",
      "2023-12-09 19:57:40,203 INFO     Training average negative_sample_loss at step 33100: 0.018167\n",
      "2023-12-09 19:57:40,203 INFO     Training average loss at step 33100: 0.032369\n",
      "2023-12-09 19:57:53,799 INFO     Training average positive_sample_loss at step 33200: 0.048465\n",
      "2023-12-09 19:57:53,799 INFO     Training average negative_sample_loss at step 33200: 0.018040\n",
      "2023-12-09 19:57:53,799 INFO     Training average loss at step 33200: 0.033253\n",
      "2023-12-09 19:58:07,423 INFO     Training average positive_sample_loss at step 33300: 0.049445\n",
      "2023-12-09 19:58:07,423 INFO     Training average negative_sample_loss at step 33300: 0.018255\n",
      "2023-12-09 19:58:07,423 INFO     Training average loss at step 33300: 0.033850\n",
      "2023-12-09 19:58:22,239 INFO     Training average positive_sample_loss at step 33400: 0.046596\n",
      "2023-12-09 19:58:22,240 INFO     Training average negative_sample_loss at step 33400: 0.018065\n",
      "2023-12-09 19:58:22,240 INFO     Training average loss at step 33400: 0.032330\n",
      "2023-12-09 19:58:34,517 INFO     Training average positive_sample_loss at step 33500: 0.047798\n",
      "2023-12-09 19:58:34,517 INFO     Training average negative_sample_loss at step 33500: 0.018062\n",
      "2023-12-09 19:58:34,517 INFO     Training average loss at step 33500: 0.032930\n",
      "2023-12-09 19:58:45,666 INFO     Training average positive_sample_loss at step 33600: 0.048759\n",
      "2023-12-09 19:58:45,667 INFO     Training average negative_sample_loss at step 33600: 0.018036\n",
      "2023-12-09 19:58:45,667 INFO     Training average loss at step 33600: 0.033397\n",
      "2023-12-09 19:59:00,649 INFO     Training average positive_sample_loss at step 33700: 0.047422\n",
      "2023-12-09 19:59:00,649 INFO     Training average negative_sample_loss at step 33700: 0.017985\n",
      "2023-12-09 19:59:00,649 INFO     Training average loss at step 33700: 0.032704\n",
      "2023-12-09 19:59:14,202 INFO     Training average positive_sample_loss at step 33800: 0.046735\n",
      "2023-12-09 19:59:14,202 INFO     Training average negative_sample_loss at step 33800: 0.017883\n",
      "2023-12-09 19:59:14,202 INFO     Training average loss at step 33800: 0.032309\n",
      "2023-12-09 19:59:27,404 INFO     Training average positive_sample_loss at step 33900: 0.048548\n",
      "2023-12-09 19:59:27,405 INFO     Training average negative_sample_loss at step 33900: 0.017990\n",
      "2023-12-09 19:59:27,405 INFO     Training average loss at step 33900: 0.033269\n",
      "2023-12-09 19:59:41,508 INFO     Training average positive_sample_loss at step 34000: 0.049335\n",
      "2023-12-09 19:59:41,509 INFO     Training average negative_sample_loss at step 34000: 0.018104\n",
      "2023-12-09 19:59:41,509 INFO     Training average loss at step 34000: 0.033719\n",
      "2023-12-09 19:59:54,894 INFO     Training average positive_sample_loss at step 34100: 0.045461\n",
      "2023-12-09 19:59:54,895 INFO     Training average negative_sample_loss at step 34100: 0.018058\n",
      "2023-12-09 19:59:54,895 INFO     Training average loss at step 34100: 0.031760\n",
      "2023-12-09 20:00:05,649 INFO     Training average positive_sample_loss at step 34200: 0.047780\n",
      "2023-12-09 20:00:05,649 INFO     Training average negative_sample_loss at step 34200: 0.017991\n",
      "2023-12-09 20:00:05,649 INFO     Training average loss at step 34200: 0.032885\n",
      "2023-12-09 20:00:16,851 INFO     Training average positive_sample_loss at step 34300: 0.048852\n",
      "2023-12-09 20:00:16,852 INFO     Training average negative_sample_loss at step 34300: 0.017966\n",
      "2023-12-09 20:00:16,852 INFO     Training average loss at step 34300: 0.033409\n",
      "2023-12-09 20:00:31,466 INFO     Training average positive_sample_loss at step 34400: 0.046961\n",
      "2023-12-09 20:00:31,466 INFO     Training average negative_sample_loss at step 34400: 0.018094\n",
      "2023-12-09 20:00:31,466 INFO     Training average loss at step 34400: 0.032527\n",
      "2023-12-09 20:00:45,082 INFO     Training average positive_sample_loss at step 34500: 0.046906\n",
      "2023-12-09 20:00:45,082 INFO     Training average negative_sample_loss at step 34500: 0.017731\n",
      "2023-12-09 20:00:45,082 INFO     Training average loss at step 34500: 0.032319\n",
      "2023-12-09 20:00:58,650 INFO     Training average positive_sample_loss at step 34600: 0.048326\n",
      "2023-12-09 20:00:58,651 INFO     Training average negative_sample_loss at step 34600: 0.017967\n",
      "2023-12-09 20:00:58,651 INFO     Training average loss at step 34600: 0.033147\n",
      "2023-12-09 20:01:13,981 INFO     Training average positive_sample_loss at step 34700: 0.048173\n",
      "2023-12-09 20:01:13,981 INFO     Training average negative_sample_loss at step 34700: 0.018116\n",
      "2023-12-09 20:01:13,981 INFO     Training average loss at step 34700: 0.033145\n",
      "2023-12-09 20:01:25,300 INFO     Training average positive_sample_loss at step 34800: 0.046071\n",
      "2023-12-09 20:01:25,301 INFO     Training average negative_sample_loss at step 34800: 0.017969\n",
      "2023-12-09 20:01:25,301 INFO     Training average loss at step 34800: 0.032020\n",
      "2023-12-09 20:01:36,949 INFO     Training average positive_sample_loss at step 34900: 0.048044\n",
      "2023-12-09 20:01:36,949 INFO     Training average negative_sample_loss at step 34900: 0.017788\n",
      "2023-12-09 20:01:36,949 INFO     Training average loss at step 34900: 0.032916\n",
      "2023-12-09 20:01:49,716 INFO     Training average positive_sample_loss at step 35000: 0.048607\n",
      "2023-12-09 20:01:49,716 INFO     Training average negative_sample_loss at step 35000: 0.017963\n",
      "2023-12-09 20:01:49,717 INFO     Training average loss at step 35000: 0.033285\n",
      "2023-12-09 20:02:05,481 INFO     Training average positive_sample_loss at step 35100: 0.045751\n",
      "2023-12-09 20:02:05,481 INFO     Training average negative_sample_loss at step 35100: 0.018023\n",
      "2023-12-09 20:02:05,481 INFO     Training average loss at step 35100: 0.031887\n",
      "2023-12-09 20:02:18,878 INFO     Training average positive_sample_loss at step 35200: 0.047196\n",
      "2023-12-09 20:02:18,879 INFO     Training average negative_sample_loss at step 35200: 0.017766\n",
      "2023-12-09 20:02:18,879 INFO     Training average loss at step 35200: 0.032481\n",
      "2023-12-09 20:02:31,731 INFO     Training average positive_sample_loss at step 35300: 0.048511\n",
      "2023-12-09 20:02:31,731 INFO     Training average negative_sample_loss at step 35300: 0.017888\n",
      "2023-12-09 20:02:31,731 INFO     Training average loss at step 35300: 0.033199\n",
      "2023-12-09 20:02:44,807 INFO     Training average positive_sample_loss at step 35400: 0.046946\n",
      "2023-12-09 20:02:44,808 INFO     Training average negative_sample_loss at step 35400: 0.017868\n",
      "2023-12-09 20:02:44,808 INFO     Training average loss at step 35400: 0.032407\n",
      "2023-12-09 20:02:57,002 INFO     Training average positive_sample_loss at step 35500: 0.046181\n",
      "2023-12-09 20:02:57,003 INFO     Training average negative_sample_loss at step 35500: 0.017796\n",
      "2023-12-09 20:02:57,003 INFO     Training average loss at step 35500: 0.031988\n",
      "2023-12-09 20:03:09,746 INFO     Training average positive_sample_loss at step 35600: 0.047884\n",
      "2023-12-09 20:03:09,747 INFO     Training average negative_sample_loss at step 35600: 0.017739\n",
      "2023-12-09 20:03:09,747 INFO     Training average loss at step 35600: 0.032811\n",
      "2023-12-09 20:03:23,587 INFO     Training average positive_sample_loss at step 35700: 0.048643\n",
      "2023-12-09 20:03:23,587 INFO     Training average negative_sample_loss at step 35700: 0.018027\n",
      "2023-12-09 20:03:23,587 INFO     Training average loss at step 35700: 0.033335\n",
      "2023-12-09 20:03:37,849 INFO     Training average positive_sample_loss at step 35800: 0.045200\n",
      "2023-12-09 20:03:37,850 INFO     Training average negative_sample_loss at step 35800: 0.017822\n",
      "2023-12-09 20:03:37,850 INFO     Training average loss at step 35800: 0.031511\n",
      "2023-12-09 20:03:50,966 INFO     Training average positive_sample_loss at step 35900: 0.047057\n",
      "2023-12-09 20:03:50,966 INFO     Training average negative_sample_loss at step 35900: 0.017828\n",
      "2023-12-09 20:03:50,966 INFO     Training average loss at step 35900: 0.032442\n",
      "2023-12-09 20:04:03,655 INFO     Training average positive_sample_loss at step 36000: 0.048423\n",
      "2023-12-09 20:04:03,655 INFO     Training average negative_sample_loss at step 36000: 0.017992\n",
      "2023-12-09 20:04:03,656 INFO     Training average loss at step 36000: 0.033207\n",
      "2023-12-09 20:04:16,586 INFO     Training average positive_sample_loss at step 36100: 0.046311\n",
      "2023-12-09 20:04:16,587 INFO     Training average negative_sample_loss at step 36100: 0.017910\n",
      "2023-12-09 20:04:16,587 INFO     Training average loss at step 36100: 0.032110\n",
      "2023-12-09 20:04:29,684 INFO     Training average positive_sample_loss at step 36200: 0.046488\n",
      "2023-12-09 20:04:29,685 INFO     Training average negative_sample_loss at step 36200: 0.017839\n",
      "2023-12-09 20:04:29,685 INFO     Training average loss at step 36200: 0.032164\n",
      "2023-12-09 20:04:42,284 INFO     Training average positive_sample_loss at step 36300: 0.047682\n",
      "2023-12-09 20:04:42,285 INFO     Training average negative_sample_loss at step 36300: 0.017779\n",
      "2023-12-09 20:04:42,285 INFO     Training average loss at step 36300: 0.032731\n",
      "2023-12-09 20:04:57,268 INFO     Training average positive_sample_loss at step 36400: 0.047638\n",
      "2023-12-09 20:04:57,268 INFO     Training average negative_sample_loss at step 36400: 0.017857\n",
      "2023-12-09 20:04:57,268 INFO     Training average loss at step 36400: 0.032748\n",
      "2023-12-09 20:05:10,891 INFO     Training average positive_sample_loss at step 36500: 0.045597\n",
      "2023-12-09 20:05:10,892 INFO     Training average negative_sample_loss at step 36500: 0.017675\n",
      "2023-12-09 20:05:10,892 INFO     Training average loss at step 36500: 0.031636\n",
      "2023-12-09 20:05:23,647 INFO     Training average positive_sample_loss at step 36600: 0.047384\n",
      "2023-12-09 20:05:23,648 INFO     Training average negative_sample_loss at step 36600: 0.017740\n",
      "2023-12-09 20:05:23,648 INFO     Training average loss at step 36600: 0.032562\n",
      "2023-12-09 20:05:34,152 INFO     Training average positive_sample_loss at step 36700: 0.048199\n",
      "2023-12-09 20:05:34,152 INFO     Training average negative_sample_loss at step 36700: 0.017846\n",
      "2023-12-09 20:05:34,152 INFO     Training average loss at step 36700: 0.033022\n",
      "2023-12-09 20:05:48,693 INFO     Training average positive_sample_loss at step 36800: 0.045427\n",
      "2023-12-09 20:05:48,693 INFO     Training average negative_sample_loss at step 36800: 0.017838\n",
      "2023-12-09 20:05:48,693 INFO     Training average loss at step 36800: 0.031632\n",
      "2023-12-09 20:06:01,827 INFO     Training average positive_sample_loss at step 36900: 0.046762\n",
      "2023-12-09 20:06:01,827 INFO     Training average negative_sample_loss at step 36900: 0.017626\n",
      "2023-12-09 20:06:01,827 INFO     Training average loss at step 36900: 0.032194\n",
      "2023-12-09 20:06:14,926 INFO     Training average positive_sample_loss at step 37000: 0.047716\n",
      "2023-12-09 20:06:14,926 INFO     Training average negative_sample_loss at step 37000: 0.017861\n",
      "2023-12-09 20:06:14,926 INFO     Training average loss at step 37000: 0.032788\n",
      "2023-12-09 20:06:29,597 INFO     Training average positive_sample_loss at step 37100: 0.046382\n",
      "2023-12-09 20:06:29,597 INFO     Training average negative_sample_loss at step 37100: 0.017832\n",
      "2023-12-09 20:06:29,597 INFO     Training average loss at step 37100: 0.032107\n",
      "2023-12-09 20:06:42,619 INFO     Training average positive_sample_loss at step 37200: 0.045697\n",
      "2023-12-09 20:06:42,619 INFO     Training average negative_sample_loss at step 37200: 0.017743\n",
      "2023-12-09 20:06:42,619 INFO     Training average loss at step 37200: 0.031720\n",
      "2023-12-09 20:06:53,857 INFO     Training average positive_sample_loss at step 37300: 0.047519\n",
      "2023-12-09 20:06:53,858 INFO     Training average negative_sample_loss at step 37300: 0.017708\n",
      "2023-12-09 20:06:53,858 INFO     Training average loss at step 37300: 0.032614\n",
      "2023-12-09 20:07:07,845 INFO     Training average positive_sample_loss at step 37400: 0.048288\n",
      "2023-12-09 20:07:07,845 INFO     Training average negative_sample_loss at step 37400: 0.017744\n",
      "2023-12-09 20:07:07,845 INFO     Training average loss at step 37400: 0.033016\n",
      "2023-12-09 20:07:21,306 INFO     Training average positive_sample_loss at step 37500: 0.044726\n",
      "2023-12-09 20:07:21,306 INFO     Training average negative_sample_loss at step 37500: 0.017717\n",
      "2023-12-09 20:07:21,306 INFO     Training average loss at step 37500: 0.031221\n",
      "2023-12-09 20:07:34,492 INFO     Training average positive_sample_loss at step 37600: 0.046706\n",
      "2023-12-09 20:07:34,492 INFO     Training average negative_sample_loss at step 37600: 0.017600\n",
      "2023-12-09 20:07:34,492 INFO     Training average loss at step 37600: 0.032153\n",
      "2023-12-09 20:07:48,127 INFO     Training average positive_sample_loss at step 37700: 0.048020\n",
      "2023-12-09 20:07:48,127 INFO     Training average negative_sample_loss at step 37700: 0.017803\n",
      "2023-12-09 20:07:48,128 INFO     Training average loss at step 37700: 0.032912\n",
      "2023-12-09 20:08:03,732 INFO     Training average positive_sample_loss at step 37800: 0.045494\n",
      "2023-12-09 20:08:03,733 INFO     Training average negative_sample_loss at step 37800: 0.017461\n",
      "2023-12-09 20:08:03,733 INFO     Training average loss at step 37800: 0.031478\n",
      "2023-12-09 20:08:13,573 INFO     Training average positive_sample_loss at step 37900: 0.046001\n",
      "2023-12-09 20:08:13,574 INFO     Training average negative_sample_loss at step 37900: 0.017613\n",
      "2023-12-09 20:08:13,574 INFO     Training average loss at step 37900: 0.031807\n",
      "2023-12-09 20:08:27,093 INFO     Training average positive_sample_loss at step 38000: 0.047415\n",
      "2023-12-09 20:08:27,093 INFO     Training average negative_sample_loss at step 38000: 0.017842\n",
      "2023-12-09 20:08:27,093 INFO     Training average loss at step 38000: 0.032628\n",
      "2023-12-09 20:08:42,416 INFO     Training average positive_sample_loss at step 38100: 0.047252\n",
      "2023-12-09 20:08:42,417 INFO     Training average negative_sample_loss at step 38100: 0.017763\n",
      "2023-12-09 20:08:42,417 INFO     Training average loss at step 38100: 0.032507\n",
      "2023-12-09 20:08:56,050 INFO     Training average positive_sample_loss at step 38200: 0.044943\n",
      "2023-12-09 20:08:56,050 INFO     Training average negative_sample_loss at step 38200: 0.017651\n",
      "2023-12-09 20:08:56,051 INFO     Training average loss at step 38200: 0.031297\n",
      "2023-12-09 20:09:08,712 INFO     Training average positive_sample_loss at step 38300: 0.046988\n",
      "2023-12-09 20:09:08,712 INFO     Training average negative_sample_loss at step 38300: 0.017667\n",
      "2023-12-09 20:09:08,712 INFO     Training average loss at step 38300: 0.032327\n",
      "2023-12-09 20:09:21,695 INFO     Training average positive_sample_loss at step 38400: 0.047729\n",
      "2023-12-09 20:09:21,695 INFO     Training average negative_sample_loss at step 38400: 0.017553\n",
      "2023-12-09 20:09:21,695 INFO     Training average loss at step 38400: 0.032641\n",
      "2023-12-09 20:09:36,915 INFO     Training average positive_sample_loss at step 38500: 0.044752\n",
      "2023-12-09 20:09:36,915 INFO     Training average negative_sample_loss at step 38500: 0.017631\n",
      "2023-12-09 20:09:36,915 INFO     Training average loss at step 38500: 0.031191\n",
      "2023-12-09 20:09:50,050 INFO     Training average positive_sample_loss at step 38600: 0.046656\n",
      "2023-12-09 20:09:50,051 INFO     Training average negative_sample_loss at step 38600: 0.017800\n",
      "2023-12-09 20:09:50,051 INFO     Training average loss at step 38600: 0.032228\n",
      "2023-12-09 20:10:03,566 INFO     Training average positive_sample_loss at step 38700: 0.047353\n",
      "2023-12-09 20:10:03,567 INFO     Training average negative_sample_loss at step 38700: 0.017596\n",
      "2023-12-09 20:10:03,567 INFO     Training average loss at step 38700: 0.032474\n",
      "2023-12-09 20:10:19,065 INFO     Training average positive_sample_loss at step 38800: 0.046107\n",
      "2023-12-09 20:10:19,066 INFO     Training average negative_sample_loss at step 38800: 0.017656\n",
      "2023-12-09 20:10:19,066 INFO     Training average loss at step 38800: 0.031882\n",
      "2023-12-09 20:10:32,289 INFO     Training average positive_sample_loss at step 38900: 0.045447\n",
      "2023-12-09 20:10:32,289 INFO     Training average negative_sample_loss at step 38900: 0.017498\n",
      "2023-12-09 20:10:32,289 INFO     Training average loss at step 38900: 0.031472\n",
      "2023-12-09 20:10:44,013 INFO     Training average positive_sample_loss at step 39000: 0.046698\n",
      "2023-12-09 20:10:44,014 INFO     Training average negative_sample_loss at step 39000: 0.017605\n",
      "2023-12-09 20:10:44,014 INFO     Training average loss at step 39000: 0.032152\n",
      "2023-12-09 20:10:56,130 INFO     Training average positive_sample_loss at step 39100: 0.047865\n",
      "2023-12-09 20:10:56,131 INFO     Training average negative_sample_loss at step 39100: 0.017781\n",
      "2023-12-09 20:10:56,131 INFO     Training average loss at step 39100: 0.032823\n",
      "2023-12-09 20:11:10,127 INFO     Training average positive_sample_loss at step 39200: 0.044307\n",
      "2023-12-09 20:11:10,127 INFO     Training average negative_sample_loss at step 39200: 0.017522\n",
      "2023-12-09 20:11:10,128 INFO     Training average loss at step 39200: 0.030914\n",
      "2023-12-09 20:11:23,088 INFO     Training average positive_sample_loss at step 39300: 0.046182\n",
      "2023-12-09 20:11:23,089 INFO     Training average negative_sample_loss at step 39300: 0.017532\n",
      "2023-12-09 20:11:23,089 INFO     Training average loss at step 39300: 0.031857\n",
      "2023-12-09 20:11:36,451 INFO     Training average positive_sample_loss at step 39400: 0.047481\n",
      "2023-12-09 20:11:36,451 INFO     Training average negative_sample_loss at step 39400: 0.017539\n",
      "2023-12-09 20:11:36,451 INFO     Training average loss at step 39400: 0.032510\n",
      "2023-12-09 20:11:52,259 INFO     Training average positive_sample_loss at step 39500: 0.045632\n",
      "2023-12-09 20:11:52,260 INFO     Training average negative_sample_loss at step 39500: 0.017594\n",
      "2023-12-09 20:11:52,260 INFO     Training average loss at step 39500: 0.031613\n",
      "2023-12-09 20:12:05,544 INFO     Training average positive_sample_loss at step 39600: 0.045844\n",
      "2023-12-09 20:12:05,544 INFO     Training average negative_sample_loss at step 39600: 0.017581\n",
      "2023-12-09 20:12:05,544 INFO     Training average loss at step 39600: 0.031713\n",
      "2023-12-09 20:12:15,712 INFO     Training average positive_sample_loss at step 39700: 0.046702\n",
      "2023-12-09 20:12:15,712 INFO     Training average negative_sample_loss at step 39700: 0.017536\n",
      "2023-12-09 20:12:15,712 INFO     Training average loss at step 39700: 0.032119\n",
      "2023-12-09 20:12:28,572 INFO     Training average positive_sample_loss at step 39800: 0.046570\n",
      "2023-12-09 20:12:28,572 INFO     Training average negative_sample_loss at step 39800: 0.017623\n",
      "2023-12-09 20:12:28,572 INFO     Training average loss at step 39800: 0.032097\n",
      "2023-12-09 20:12:41,302 INFO     Training average positive_sample_loss at step 39900: 0.044693\n",
      "2023-12-09 20:12:41,303 INFO     Training average negative_sample_loss at step 39900: 0.017340\n",
      "2023-12-09 20:12:41,303 INFO     Training average loss at step 39900: 0.031016\n",
      "2023-12-09 20:12:54,262 INFO     Change learning_rate to 0.000005 at step 40000\n",
      "2023-12-09 20:13:01,661 INFO     Training average positive_sample_loss at step 40000: 0.046120\n",
      "2023-12-09 20:13:01,661 INFO     Training average negative_sample_loss at step 40000: 0.017557\n",
      "2023-12-09 20:13:01,662 INFO     Training average loss at step 40000: 0.031839\n",
      "2023-12-09 20:13:01,662 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 20:13:02,178 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 20:13:40,996 INFO     Valid MRR at step 40000: 0.483099\n",
      "2023-12-09 20:13:40,996 INFO     Valid MR at step 40000: 1833.713744\n",
      "2023-12-09 20:13:40,996 INFO     Valid HITS@1 at step 40000: 0.440837\n",
      "2023-12-09 20:13:40,996 INFO     Valid HITS@3 at step 40000: 0.492584\n",
      "2023-12-09 20:13:40,996 INFO     Valid HITS@10 at step 40000: 0.571028\n",
      "2023-12-09 20:13:54,209 INFO     Training average positive_sample_loss at step 40100: 0.047817\n",
      "2023-12-09 20:13:54,210 INFO     Training average negative_sample_loss at step 40100: 0.016941\n",
      "2023-12-09 20:13:54,210 INFO     Training average loss at step 40100: 0.032379\n",
      "2023-12-09 20:14:07,955 INFO     Training average positive_sample_loss at step 40200: 0.044087\n",
      "2023-12-09 20:14:07,955 INFO     Training average negative_sample_loss at step 40200: 0.016966\n",
      "2023-12-09 20:14:07,955 INFO     Training average loss at step 40200: 0.030527\n",
      "2023-12-09 20:14:20,070 INFO     Training average positive_sample_loss at step 40300: 0.043283\n",
      "2023-12-09 20:14:20,071 INFO     Training average negative_sample_loss at step 40300: 0.016745\n",
      "2023-12-09 20:14:20,071 INFO     Training average loss at step 40300: 0.030014\n",
      "2023-12-09 20:14:33,205 INFO     Training average positive_sample_loss at step 40400: 0.043322\n",
      "2023-12-09 20:14:33,205 INFO     Training average negative_sample_loss at step 40400: 0.016911\n",
      "2023-12-09 20:14:33,205 INFO     Training average loss at step 40400: 0.030116\n",
      "2023-12-09 20:14:48,204 INFO     Training average positive_sample_loss at step 40500: 0.042736\n",
      "2023-12-09 20:14:48,205 INFO     Training average negative_sample_loss at step 40500: 0.016692\n",
      "2023-12-09 20:14:48,205 INFO     Training average loss at step 40500: 0.029714\n",
      "2023-12-09 20:14:58,337 INFO     Training average positive_sample_loss at step 40600: 0.042337\n",
      "2023-12-09 20:14:58,337 INFO     Training average negative_sample_loss at step 40600: 0.016625\n",
      "2023-12-09 20:14:58,337 INFO     Training average loss at step 40600: 0.029481\n",
      "2023-12-09 20:15:11,399 INFO     Training average positive_sample_loss at step 40700: 0.042340\n",
      "2023-12-09 20:15:11,400 INFO     Training average negative_sample_loss at step 40700: 0.016744\n",
      "2023-12-09 20:15:11,400 INFO     Training average loss at step 40700: 0.029542\n",
      "2023-12-09 20:15:25,604 INFO     Training average positive_sample_loss at step 40800: 0.042452\n",
      "2023-12-09 20:15:25,605 INFO     Training average negative_sample_loss at step 40800: 0.016728\n",
      "2023-12-09 20:15:25,605 INFO     Training average loss at step 40800: 0.029590\n",
      "2023-12-09 20:15:40,225 INFO     Training average positive_sample_loss at step 40900: 0.041569\n",
      "2023-12-09 20:15:40,226 INFO     Training average negative_sample_loss at step 40900: 0.016776\n",
      "2023-12-09 20:15:40,226 INFO     Training average loss at step 40900: 0.029173\n",
      "2023-12-09 20:15:53,850 INFO     Training average positive_sample_loss at step 41000: 0.042114\n",
      "2023-12-09 20:15:53,850 INFO     Training average negative_sample_loss at step 41000: 0.016808\n",
      "2023-12-09 20:15:53,850 INFO     Training average loss at step 41000: 0.029461\n",
      "2023-12-09 20:16:07,005 INFO     Training average positive_sample_loss at step 41100: 0.042052\n",
      "2023-12-09 20:16:07,006 INFO     Training average negative_sample_loss at step 41100: 0.016856\n",
      "2023-12-09 20:16:07,006 INFO     Training average loss at step 41100: 0.029454\n",
      "2023-12-09 20:16:20,268 INFO     Training average positive_sample_loss at step 41200: 0.041797\n",
      "2023-12-09 20:16:20,268 INFO     Training average negative_sample_loss at step 41200: 0.016707\n",
      "2023-12-09 20:16:20,268 INFO     Training average loss at step 41200: 0.029252\n",
      "2023-12-09 20:16:33,591 INFO     Training average positive_sample_loss at step 41300: 0.041376\n",
      "2023-12-09 20:16:33,592 INFO     Training average negative_sample_loss at step 41300: 0.016696\n",
      "2023-12-09 20:16:33,592 INFO     Training average loss at step 41300: 0.029036\n",
      "2023-12-09 20:16:46,064 INFO     Training average positive_sample_loss at step 41400: 0.041766\n",
      "2023-12-09 20:16:46,064 INFO     Training average negative_sample_loss at step 41400: 0.016833\n",
      "2023-12-09 20:16:46,064 INFO     Training average loss at step 41400: 0.029300\n",
      "2023-12-09 20:17:01,281 INFO     Training average positive_sample_loss at step 41500: 0.041622\n",
      "2023-12-09 20:17:01,281 INFO     Training average negative_sample_loss at step 41500: 0.016836\n",
      "2023-12-09 20:17:01,281 INFO     Training average loss at step 41500: 0.029229\n",
      "2023-12-09 20:17:13,829 INFO     Training average positive_sample_loss at step 41600: 0.041095\n",
      "2023-12-09 20:17:13,829 INFO     Training average negative_sample_loss at step 41600: 0.016717\n",
      "2023-12-09 20:17:13,829 INFO     Training average loss at step 41600: 0.028906\n",
      "2023-12-09 20:17:27,046 INFO     Training average positive_sample_loss at step 41700: 0.041503\n",
      "2023-12-09 20:17:27,047 INFO     Training average negative_sample_loss at step 41700: 0.016855\n",
      "2023-12-09 20:17:27,047 INFO     Training average loss at step 41700: 0.029179\n",
      "2023-12-09 20:17:38,481 INFO     Training average positive_sample_loss at step 41800: 0.041675\n",
      "2023-12-09 20:17:38,482 INFO     Training average negative_sample_loss at step 41800: 0.016899\n",
      "2023-12-09 20:17:38,482 INFO     Training average loss at step 41800: 0.029287\n",
      "2023-12-09 20:17:53,437 INFO     Training average positive_sample_loss at step 41900: 0.041414\n",
      "2023-12-09 20:17:53,438 INFO     Training average negative_sample_loss at step 41900: 0.016714\n",
      "2023-12-09 20:17:53,438 INFO     Training average loss at step 41900: 0.029064\n",
      "2023-12-09 20:18:05,248 INFO     Training average positive_sample_loss at step 42000: 0.041419\n",
      "2023-12-09 20:18:05,249 INFO     Training average negative_sample_loss at step 42000: 0.016692\n",
      "2023-12-09 20:18:05,249 INFO     Training average loss at step 42000: 0.029055\n",
      "2023-12-09 20:18:18,560 INFO     Training average positive_sample_loss at step 42100: 0.041389\n",
      "2023-12-09 20:18:18,560 INFO     Training average negative_sample_loss at step 42100: 0.016777\n",
      "2023-12-09 20:18:18,560 INFO     Training average loss at step 42100: 0.029083\n",
      "2023-12-09 20:18:33,493 INFO     Training average positive_sample_loss at step 42200: 0.041230\n",
      "2023-12-09 20:18:33,494 INFO     Training average negative_sample_loss at step 42200: 0.016692\n",
      "2023-12-09 20:18:33,494 INFO     Training average loss at step 42200: 0.028961\n",
      "2023-12-09 20:18:45,155 INFO     Training average positive_sample_loss at step 42300: 0.041216\n",
      "2023-12-09 20:18:45,156 INFO     Training average negative_sample_loss at step 42300: 0.016705\n",
      "2023-12-09 20:18:45,156 INFO     Training average loss at step 42300: 0.028961\n",
      "2023-12-09 20:18:55,508 INFO     Training average positive_sample_loss at step 42400: 0.041118\n",
      "2023-12-09 20:18:55,509 INFO     Training average negative_sample_loss at step 42400: 0.016900\n",
      "2023-12-09 20:18:55,509 INFO     Training average loss at step 42400: 0.029009\n",
      "2023-12-09 20:19:08,304 INFO     Training average positive_sample_loss at step 42500: 0.041461\n",
      "2023-12-09 20:19:08,304 INFO     Training average negative_sample_loss at step 42500: 0.016787\n",
      "2023-12-09 20:19:08,304 INFO     Training average loss at step 42500: 0.029124\n",
      "2023-12-09 20:19:21,559 INFO     Training average positive_sample_loss at step 42600: 0.040724\n",
      "2023-12-09 20:19:21,560 INFO     Training average negative_sample_loss at step 42600: 0.016762\n",
      "2023-12-09 20:19:21,560 INFO     Training average loss at step 42600: 0.028743\n",
      "2023-12-09 20:19:35,168 INFO     Training average positive_sample_loss at step 42700: 0.041013\n",
      "2023-12-09 20:19:35,168 INFO     Training average negative_sample_loss at step 42700: 0.016799\n",
      "2023-12-09 20:19:35,169 INFO     Training average loss at step 42700: 0.028906\n",
      "2023-12-09 20:19:48,513 INFO     Training average positive_sample_loss at step 42800: 0.041367\n",
      "2023-12-09 20:19:48,513 INFO     Training average negative_sample_loss at step 42800: 0.016693\n",
      "2023-12-09 20:19:48,513 INFO     Training average loss at step 42800: 0.029030\n",
      "2023-12-09 20:20:03,604 INFO     Training average positive_sample_loss at step 42900: 0.041243\n",
      "2023-12-09 20:20:03,604 INFO     Training average negative_sample_loss at step 42900: 0.016838\n",
      "2023-12-09 20:20:03,604 INFO     Training average loss at step 42900: 0.029040\n",
      "2023-12-09 20:20:14,108 INFO     Training average positive_sample_loss at step 43000: 0.041060\n",
      "2023-12-09 20:20:14,108 INFO     Training average negative_sample_loss at step 43000: 0.017015\n",
      "2023-12-09 20:20:14,108 INFO     Training average loss at step 43000: 0.029038\n",
      "2023-12-09 20:20:26,688 INFO     Training average positive_sample_loss at step 43100: 0.041275\n",
      "2023-12-09 20:20:26,689 INFO     Training average negative_sample_loss at step 43100: 0.016664\n",
      "2023-12-09 20:20:26,689 INFO     Training average loss at step 43100: 0.028970\n",
      "2023-12-09 20:20:42,038 INFO     Training average positive_sample_loss at step 43200: 0.041098\n",
      "2023-12-09 20:20:42,038 INFO     Training average negative_sample_loss at step 43200: 0.016459\n",
      "2023-12-09 20:20:42,038 INFO     Training average loss at step 43200: 0.028779\n",
      "2023-12-09 20:20:53,890 INFO     Training average positive_sample_loss at step 43300: 0.040865\n",
      "2023-12-09 20:20:53,891 INFO     Training average negative_sample_loss at step 43300: 0.016708\n",
      "2023-12-09 20:20:53,891 INFO     Training average loss at step 43300: 0.028787\n",
      "2023-12-09 20:21:04,144 INFO     Training average positive_sample_loss at step 43400: 0.041287\n",
      "2023-12-09 20:21:04,144 INFO     Training average negative_sample_loss at step 43400: 0.016664\n",
      "2023-12-09 20:21:04,144 INFO     Training average loss at step 43400: 0.028975\n",
      "2023-12-09 20:21:14,133 INFO     Training average positive_sample_loss at step 43500: 0.041120\n",
      "2023-12-09 20:21:14,133 INFO     Training average negative_sample_loss at step 43500: 0.016739\n",
      "2023-12-09 20:21:14,133 INFO     Training average loss at step 43500: 0.028929\n",
      "2023-12-09 20:21:26,622 INFO     Training average positive_sample_loss at step 43600: 0.040766\n",
      "2023-12-09 20:21:26,623 INFO     Training average negative_sample_loss at step 43600: 0.016727\n",
      "2023-12-09 20:21:26,623 INFO     Training average loss at step 43600: 0.028747\n",
      "2023-12-09 20:21:36,623 INFO     Training average positive_sample_loss at step 43700: 0.040748\n",
      "2023-12-09 20:21:36,623 INFO     Training average negative_sample_loss at step 43700: 0.016896\n",
      "2023-12-09 20:21:36,623 INFO     Training average loss at step 43700: 0.028822\n",
      "2023-12-09 20:21:47,159 INFO     Training average positive_sample_loss at step 43800: 0.041286\n",
      "2023-12-09 20:21:47,160 INFO     Training average negative_sample_loss at step 43800: 0.016829\n",
      "2023-12-09 20:21:47,160 INFO     Training average loss at step 43800: 0.029058\n",
      "2023-12-09 20:22:00,313 INFO     Training average positive_sample_loss at step 43900: 0.041102\n",
      "2023-12-09 20:22:00,314 INFO     Training average negative_sample_loss at step 43900: 0.016576\n",
      "2023-12-09 20:22:00,314 INFO     Training average loss at step 43900: 0.028839\n",
      "2023-12-09 20:22:12,215 INFO     Training average positive_sample_loss at step 44000: 0.040836\n",
      "2023-12-09 20:22:12,215 INFO     Training average negative_sample_loss at step 44000: 0.016625\n",
      "2023-12-09 20:22:12,215 INFO     Training average loss at step 44000: 0.028731\n",
      "2023-12-09 20:22:25,017 INFO     Training average positive_sample_loss at step 44100: 0.041085\n",
      "2023-12-09 20:22:25,018 INFO     Training average negative_sample_loss at step 44100: 0.016615\n",
      "2023-12-09 20:22:25,018 INFO     Training average loss at step 44100: 0.028850\n",
      "2023-12-09 20:22:39,492 INFO     Training average positive_sample_loss at step 44200: 0.041172\n",
      "2023-12-09 20:22:39,493 INFO     Training average negative_sample_loss at step 44200: 0.016720\n",
      "2023-12-09 20:22:39,493 INFO     Training average loss at step 44200: 0.028946\n",
      "2023-12-09 20:22:51,575 INFO     Training average positive_sample_loss at step 44300: 0.040581\n",
      "2023-12-09 20:22:51,576 INFO     Training average negative_sample_loss at step 44300: 0.016688\n",
      "2023-12-09 20:22:51,576 INFO     Training average loss at step 44300: 0.028635\n",
      "2023-12-09 20:23:03,590 INFO     Training average positive_sample_loss at step 44400: 0.041079\n",
      "2023-12-09 20:23:03,590 INFO     Training average negative_sample_loss at step 44400: 0.016796\n",
      "2023-12-09 20:23:03,590 INFO     Training average loss at step 44400: 0.028937\n",
      "2023-12-09 20:23:16,981 INFO     Training average positive_sample_loss at step 44500: 0.041061\n",
      "2023-12-09 20:23:16,982 INFO     Training average negative_sample_loss at step 44500: 0.016647\n",
      "2023-12-09 20:23:16,982 INFO     Training average loss at step 44500: 0.028854\n",
      "2023-12-09 20:23:32,298 INFO     Training average positive_sample_loss at step 44600: 0.041008\n",
      "2023-12-09 20:23:32,299 INFO     Training average negative_sample_loss at step 44600: 0.016708\n",
      "2023-12-09 20:23:32,299 INFO     Training average loss at step 44600: 0.028858\n",
      "2023-12-09 20:23:45,894 INFO     Training average positive_sample_loss at step 44700: 0.040774\n",
      "2023-12-09 20:23:45,894 INFO     Training average negative_sample_loss at step 44700: 0.016671\n",
      "2023-12-09 20:23:45,894 INFO     Training average loss at step 44700: 0.028723\n",
      "2023-12-09 20:23:59,570 INFO     Training average positive_sample_loss at step 44800: 0.040982\n",
      "2023-12-09 20:23:59,570 INFO     Training average negative_sample_loss at step 44800: 0.016694\n",
      "2023-12-09 20:23:59,570 INFO     Training average loss at step 44800: 0.028838\n",
      "2023-12-09 20:24:14,119 INFO     Training average positive_sample_loss at step 44900: 0.041117\n",
      "2023-12-09 20:24:14,120 INFO     Training average negative_sample_loss at step 44900: 0.016795\n",
      "2023-12-09 20:24:14,120 INFO     Training average loss at step 44900: 0.028956\n",
      "2023-12-09 20:24:26,672 INFO     Training average positive_sample_loss at step 45000: 0.040652\n",
      "2023-12-09 20:24:26,673 INFO     Training average negative_sample_loss at step 45000: 0.016710\n",
      "2023-12-09 20:24:26,673 INFO     Training average loss at step 45000: 0.028681\n",
      "2023-12-09 20:24:38,490 INFO     Training average positive_sample_loss at step 45100: 0.041191\n",
      "2023-12-09 20:24:38,491 INFO     Training average negative_sample_loss at step 45100: 0.016736\n",
      "2023-12-09 20:24:38,491 INFO     Training average loss at step 45100: 0.028964\n",
      "2023-12-09 20:24:50,967 INFO     Training average positive_sample_loss at step 45200: 0.041116\n",
      "2023-12-09 20:24:50,967 INFO     Training average negative_sample_loss at step 45200: 0.016734\n",
      "2023-12-09 20:24:50,967 INFO     Training average loss at step 45200: 0.028925\n",
      "2023-12-09 20:25:06,103 INFO     Training average positive_sample_loss at step 45300: 0.040659\n",
      "2023-12-09 20:25:06,103 INFO     Training average negative_sample_loss at step 45300: 0.016705\n",
      "2023-12-09 20:25:06,103 INFO     Training average loss at step 45300: 0.028682\n",
      "2023-12-09 20:25:18,471 INFO     Training average positive_sample_loss at step 45400: 0.040821\n",
      "2023-12-09 20:25:18,472 INFO     Training average negative_sample_loss at step 45400: 0.016694\n",
      "2023-12-09 20:25:18,472 INFO     Training average loss at step 45400: 0.028758\n",
      "2023-12-09 20:25:29,762 INFO     Training average positive_sample_loss at step 45500: 0.040910\n",
      "2023-12-09 20:25:29,762 INFO     Training average negative_sample_loss at step 45500: 0.016670\n",
      "2023-12-09 20:25:29,762 INFO     Training average loss at step 45500: 0.028790\n",
      "2023-12-09 20:25:43,423 INFO     Training average positive_sample_loss at step 45600: 0.041087\n",
      "2023-12-09 20:25:43,424 INFO     Training average negative_sample_loss at step 45600: 0.016498\n",
      "2023-12-09 20:25:43,424 INFO     Training average loss at step 45600: 0.028793\n",
      "2023-12-09 20:25:55,877 INFO     Training average positive_sample_loss at step 45700: 0.040840\n",
      "2023-12-09 20:25:55,877 INFO     Training average negative_sample_loss at step 45700: 0.016682\n",
      "2023-12-09 20:25:55,877 INFO     Training average loss at step 45700: 0.028761\n",
      "2023-12-09 20:26:09,281 INFO     Training average positive_sample_loss at step 45800: 0.040881\n",
      "2023-12-09 20:26:09,281 INFO     Training average negative_sample_loss at step 45800: 0.016692\n",
      "2023-12-09 20:26:09,281 INFO     Training average loss at step 45800: 0.028787\n",
      "2023-12-09 20:26:23,551 INFO     Training average positive_sample_loss at step 45900: 0.041044\n",
      "2023-12-09 20:26:23,551 INFO     Training average negative_sample_loss at step 45900: 0.016630\n",
      "2023-12-09 20:26:23,551 INFO     Training average loss at step 45900: 0.028837\n",
      "2023-12-09 20:26:37,404 INFO     Training average positive_sample_loss at step 46000: 0.040373\n",
      "2023-12-09 20:26:37,405 INFO     Training average negative_sample_loss at step 46000: 0.016495\n",
      "2023-12-09 20:26:37,405 INFO     Training average loss at step 46000: 0.028434\n",
      "2023-12-09 20:26:49,517 INFO     Training average positive_sample_loss at step 46100: 0.040894\n",
      "2023-12-09 20:26:49,517 INFO     Training average negative_sample_loss at step 46100: 0.016616\n",
      "2023-12-09 20:26:49,517 INFO     Training average loss at step 46100: 0.028755\n",
      "2023-12-09 20:27:00,609 INFO     Training average positive_sample_loss at step 46200: 0.041382\n",
      "2023-12-09 20:27:00,609 INFO     Training average negative_sample_loss at step 46200: 0.016700\n",
      "2023-12-09 20:27:00,609 INFO     Training average loss at step 46200: 0.029041\n",
      "2023-12-09 20:27:15,112 INFO     Training average positive_sample_loss at step 46300: 0.040532\n",
      "2023-12-09 20:27:15,113 INFO     Training average negative_sample_loss at step 46300: 0.016598\n",
      "2023-12-09 20:27:15,113 INFO     Training average loss at step 46300: 0.028565\n",
      "2023-12-09 20:27:28,419 INFO     Training average positive_sample_loss at step 46400: 0.040819\n",
      "2023-12-09 20:27:28,419 INFO     Training average negative_sample_loss at step 46400: 0.016609\n",
      "2023-12-09 20:27:28,419 INFO     Training average loss at step 46400: 0.028714\n",
      "2023-12-09 20:27:41,407 INFO     Training average positive_sample_loss at step 46500: 0.041088\n",
      "2023-12-09 20:27:41,407 INFO     Training average negative_sample_loss at step 46500: 0.016585\n",
      "2023-12-09 20:27:41,407 INFO     Training average loss at step 46500: 0.028836\n",
      "2023-12-09 20:27:55,754 INFO     Training average positive_sample_loss at step 46600: 0.041023\n",
      "2023-12-09 20:27:55,754 INFO     Training average negative_sample_loss at step 46600: 0.016676\n",
      "2023-12-09 20:27:55,754 INFO     Training average loss at step 46600: 0.028850\n",
      "2023-12-09 20:28:08,925 INFO     Training average positive_sample_loss at step 46700: 0.040699\n",
      "2023-12-09 20:28:08,926 INFO     Training average negative_sample_loss at step 46700: 0.016569\n",
      "2023-12-09 20:28:08,926 INFO     Training average loss at step 46700: 0.028634\n",
      "2023-12-09 20:28:19,235 INFO     Training average positive_sample_loss at step 46800: 0.040673\n",
      "2023-12-09 20:28:19,236 INFO     Training average negative_sample_loss at step 46800: 0.016603\n",
      "2023-12-09 20:28:19,236 INFO     Training average loss at step 46800: 0.028638\n",
      "2023-12-09 20:28:31,678 INFO     Training average positive_sample_loss at step 46900: 0.041462\n",
      "2023-12-09 20:28:31,679 INFO     Training average negative_sample_loss at step 46900: 0.016479\n",
      "2023-12-09 20:28:31,679 INFO     Training average loss at step 46900: 0.028970\n",
      "2023-12-09 20:28:46,060 INFO     Training average positive_sample_loss at step 47000: 0.040470\n",
      "2023-12-09 20:28:46,060 INFO     Training average negative_sample_loss at step 47000: 0.016668\n",
      "2023-12-09 20:28:46,060 INFO     Training average loss at step 47000: 0.028569\n",
      "2023-12-09 20:28:59,652 INFO     Training average positive_sample_loss at step 47100: 0.040623\n",
      "2023-12-09 20:28:59,653 INFO     Training average negative_sample_loss at step 47100: 0.016715\n",
      "2023-12-09 20:28:59,653 INFO     Training average loss at step 47100: 0.028669\n",
      "2023-12-09 20:29:12,788 INFO     Training average positive_sample_loss at step 47200: 0.041243\n",
      "2023-12-09 20:29:12,788 INFO     Training average negative_sample_loss at step 47200: 0.016531\n",
      "2023-12-09 20:29:12,788 INFO     Training average loss at step 47200: 0.028887\n",
      "2023-12-09 20:29:28,095 INFO     Training average positive_sample_loss at step 47300: 0.040962\n",
      "2023-12-09 20:29:28,095 INFO     Training average negative_sample_loss at step 47300: 0.016380\n",
      "2023-12-09 20:29:28,095 INFO     Training average loss at step 47300: 0.028671\n",
      "2023-12-09 20:29:37,908 INFO     Training average positive_sample_loss at step 47400: 0.040604\n",
      "2023-12-09 20:29:37,909 INFO     Training average negative_sample_loss at step 47400: 0.016668\n",
      "2023-12-09 20:29:37,909 INFO     Training average loss at step 47400: 0.028636\n",
      "2023-12-09 20:29:50,438 INFO     Training average positive_sample_loss at step 47500: 0.040950\n",
      "2023-12-09 20:29:50,438 INFO     Training average negative_sample_loss at step 47500: 0.016377\n",
      "2023-12-09 20:29:50,438 INFO     Training average loss at step 47500: 0.028664\n",
      "2023-12-09 20:30:04,944 INFO     Training average positive_sample_loss at step 47600: 0.041158\n",
      "2023-12-09 20:30:04,945 INFO     Training average negative_sample_loss at step 47600: 0.016707\n",
      "2023-12-09 20:30:04,945 INFO     Training average loss at step 47600: 0.028932\n",
      "2023-12-09 20:30:19,339 INFO     Training average positive_sample_loss at step 47700: 0.040443\n",
      "2023-12-09 20:30:19,340 INFO     Training average negative_sample_loss at step 47700: 0.016414\n",
      "2023-12-09 20:30:19,340 INFO     Training average loss at step 47700: 0.028429\n",
      "2023-12-09 20:30:32,879 INFO     Training average positive_sample_loss at step 47800: 0.040932\n",
      "2023-12-09 20:30:32,880 INFO     Training average negative_sample_loss at step 47800: 0.016443\n",
      "2023-12-09 20:30:32,880 INFO     Training average loss at step 47800: 0.028688\n",
      "2023-12-09 20:30:45,278 INFO     Training average positive_sample_loss at step 47900: 0.040960\n",
      "2023-12-09 20:30:45,279 INFO     Training average negative_sample_loss at step 47900: 0.016502\n",
      "2023-12-09 20:30:45,279 INFO     Training average loss at step 47900: 0.028731\n",
      "2023-12-09 20:30:59,152 INFO     Training average positive_sample_loss at step 48000: 0.041008\n",
      "2023-12-09 20:30:59,152 INFO     Training average negative_sample_loss at step 48000: 0.016516\n",
      "2023-12-09 20:30:59,152 INFO     Training average loss at step 48000: 0.028762\n",
      "2023-12-09 20:31:12,473 INFO     Training average positive_sample_loss at step 48100: 0.040806\n",
      "2023-12-09 20:31:12,473 INFO     Training average negative_sample_loss at step 48100: 0.016389\n",
      "2023-12-09 20:31:12,474 INFO     Training average loss at step 48100: 0.028598\n",
      "2023-12-09 20:31:25,638 INFO     Training average positive_sample_loss at step 48200: 0.040809\n",
      "2023-12-09 20:31:25,639 INFO     Training average negative_sample_loss at step 48200: 0.016359\n",
      "2023-12-09 20:31:25,639 INFO     Training average loss at step 48200: 0.028584\n",
      "2023-12-09 20:31:40,633 INFO     Training average positive_sample_loss at step 48300: 0.040950\n",
      "2023-12-09 20:31:40,633 INFO     Training average negative_sample_loss at step 48300: 0.016571\n",
      "2023-12-09 20:31:40,633 INFO     Training average loss at step 48300: 0.028760\n",
      "2023-12-09 20:31:53,320 INFO     Training average positive_sample_loss at step 48400: 0.040420\n",
      "2023-12-09 20:31:53,320 INFO     Training average negative_sample_loss at step 48400: 0.016659\n",
      "2023-12-09 20:31:53,320 INFO     Training average loss at step 48400: 0.028540\n",
      "2023-12-09 20:32:05,933 INFO     Training average positive_sample_loss at step 48500: 0.041011\n",
      "2023-12-09 20:32:05,934 INFO     Training average negative_sample_loss at step 48500: 0.016397\n",
      "2023-12-09 20:32:05,934 INFO     Training average loss at step 48500: 0.028704\n",
      "2023-12-09 20:32:16,486 INFO     Training average positive_sample_loss at step 48600: 0.041259\n",
      "2023-12-09 20:32:16,486 INFO     Training average negative_sample_loss at step 48600: 0.016496\n",
      "2023-12-09 20:32:16,486 INFO     Training average loss at step 48600: 0.028878\n",
      "2023-12-09 20:32:31,276 INFO     Training average positive_sample_loss at step 48700: 0.040795\n",
      "2023-12-09 20:32:31,276 INFO     Training average negative_sample_loss at step 48700: 0.016547\n",
      "2023-12-09 20:32:31,276 INFO     Training average loss at step 48700: 0.028671\n",
      "2023-12-09 20:32:43,348 INFO     Training average positive_sample_loss at step 48800: 0.040758\n",
      "2023-12-09 20:32:43,349 INFO     Training average negative_sample_loss at step 48800: 0.016297\n",
      "2023-12-09 20:32:43,349 INFO     Training average loss at step 48800: 0.028527\n",
      "2023-12-09 20:32:56,515 INFO     Training average positive_sample_loss at step 48900: 0.040883\n",
      "2023-12-09 20:32:56,515 INFO     Training average negative_sample_loss at step 48900: 0.016469\n",
      "2023-12-09 20:32:56,515 INFO     Training average loss at step 48900: 0.028676\n",
      "2023-12-09 20:33:11,046 INFO     Training average positive_sample_loss at step 49000: 0.040826\n",
      "2023-12-09 20:33:11,047 INFO     Training average negative_sample_loss at step 49000: 0.016550\n",
      "2023-12-09 20:33:11,047 INFO     Training average loss at step 49000: 0.028688\n",
      "2023-12-09 20:33:23,887 INFO     Training average positive_sample_loss at step 49100: 0.040718\n",
      "2023-12-09 20:33:23,887 INFO     Training average negative_sample_loss at step 49100: 0.016525\n",
      "2023-12-09 20:33:23,887 INFO     Training average loss at step 49100: 0.028621\n",
      "2023-12-09 20:33:34,630 INFO     Training average positive_sample_loss at step 49200: 0.040935\n",
      "2023-12-09 20:33:34,630 INFO     Training average negative_sample_loss at step 49200: 0.016497\n",
      "2023-12-09 20:33:34,630 INFO     Training average loss at step 49200: 0.028716\n",
      "2023-12-09 20:33:47,210 INFO     Training average positive_sample_loss at step 49300: 0.041134\n",
      "2023-12-09 20:33:47,210 INFO     Training average negative_sample_loss at step 49300: 0.016376\n",
      "2023-12-09 20:33:47,210 INFO     Training average loss at step 49300: 0.028755\n",
      "2023-12-09 20:34:01,468 INFO     Training average positive_sample_loss at step 49400: 0.040774\n",
      "2023-12-09 20:34:01,468 INFO     Training average negative_sample_loss at step 49400: 0.016501\n",
      "2023-12-09 20:34:01,468 INFO     Training average loss at step 49400: 0.028637\n",
      "2023-12-09 20:34:14,671 INFO     Training average positive_sample_loss at step 49500: 0.040892\n",
      "2023-12-09 20:34:14,672 INFO     Training average negative_sample_loss at step 49500: 0.016552\n",
      "2023-12-09 20:34:14,672 INFO     Training average loss at step 49500: 0.028722\n",
      "2023-12-09 20:34:26,942 INFO     Training average positive_sample_loss at step 49600: 0.040693\n",
      "2023-12-09 20:34:26,943 INFO     Training average negative_sample_loss at step 49600: 0.016428\n",
      "2023-12-09 20:34:26,943 INFO     Training average loss at step 49600: 0.028561\n",
      "2023-12-09 20:34:42,222 INFO     Training average positive_sample_loss at step 49700: 0.040774\n",
      "2023-12-09 20:34:42,222 INFO     Training average negative_sample_loss at step 49700: 0.016467\n",
      "2023-12-09 20:34:42,222 INFO     Training average loss at step 49700: 0.028620\n",
      "2023-12-09 20:34:54,668 INFO     Training average positive_sample_loss at step 49800: 0.040631\n",
      "2023-12-09 20:34:54,668 INFO     Training average negative_sample_loss at step 49800: 0.016324\n",
      "2023-12-09 20:34:54,669 INFO     Training average loss at step 49800: 0.028478\n",
      "2023-12-09 20:35:06,754 INFO     Training average positive_sample_loss at step 49900: 0.041102\n",
      "2023-12-09 20:35:06,754 INFO     Training average negative_sample_loss at step 49900: 0.016520\n",
      "2023-12-09 20:35:06,754 INFO     Training average loss at step 49900: 0.028811\n",
      "2023-12-09 20:35:37,829 INFO     Training average positive_sample_loss at step 50000: 0.040931\n",
      "2023-12-09 20:35:37,829 INFO     Training average negative_sample_loss at step 50000: 0.016353\n",
      "2023-12-09 20:35:37,829 INFO     Training average loss at step 50000: 0.028642\n",
      "2023-12-09 20:35:37,829 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 20:35:38,442 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 20:36:16,139 INFO     Valid MRR at step 50000: 0.481775\n",
      "2023-12-09 20:36:16,139 INFO     Valid MR at step 50000: 1778.497528\n",
      "2023-12-09 20:36:16,139 INFO     Valid HITS@1 at step 50000: 0.438036\n",
      "2023-12-09 20:36:16,139 INFO     Valid HITS@3 at step 50000: 0.495221\n",
      "2023-12-09 20:36:16,139 INFO     Valid HITS@10 at step 50000: 0.569051\n",
      "2023-12-09 20:36:26,791 INFO     Training average positive_sample_loss at step 50100: 0.040690\n",
      "2023-12-09 20:36:26,792 INFO     Training average negative_sample_loss at step 50100: 0.016454\n",
      "2023-12-09 20:36:26,792 INFO     Training average loss at step 50100: 0.028572\n",
      "2023-12-09 20:36:39,766 INFO     Training average positive_sample_loss at step 50200: 0.040675\n",
      "2023-12-09 20:36:39,766 INFO     Training average negative_sample_loss at step 50200: 0.016301\n",
      "2023-12-09 20:36:39,766 INFO     Training average loss at step 50200: 0.028488\n",
      "2023-12-09 20:36:49,808 INFO     Training average positive_sample_loss at step 50300: 0.041226\n",
      "2023-12-09 20:36:49,808 INFO     Training average negative_sample_loss at step 50300: 0.016326\n",
      "2023-12-09 20:36:49,808 INFO     Training average loss at step 50300: 0.028776\n",
      "2023-12-09 20:37:05,180 INFO     Training average positive_sample_loss at step 50400: 0.040686\n",
      "2023-12-09 20:37:05,181 INFO     Training average negative_sample_loss at step 50400: 0.016451\n",
      "2023-12-09 20:37:05,181 INFO     Training average loss at step 50400: 0.028568\n",
      "2023-12-09 20:37:18,394 INFO     Training average positive_sample_loss at step 50500: 0.040769\n",
      "2023-12-09 20:37:18,394 INFO     Training average negative_sample_loss at step 50500: 0.016388\n",
      "2023-12-09 20:37:18,394 INFO     Training average loss at step 50500: 0.028579\n",
      "2023-12-09 20:37:31,580 INFO     Training average positive_sample_loss at step 50600: 0.041113\n",
      "2023-12-09 20:37:31,580 INFO     Training average negative_sample_loss at step 50600: 0.016509\n",
      "2023-12-09 20:37:31,581 INFO     Training average loss at step 50600: 0.028811\n",
      "2023-12-09 20:37:45,351 INFO     Training average positive_sample_loss at step 50700: 0.040917\n",
      "2023-12-09 20:37:45,351 INFO     Training average negative_sample_loss at step 50700: 0.016382\n",
      "2023-12-09 20:37:45,351 INFO     Training average loss at step 50700: 0.028649\n",
      "2023-12-09 20:37:58,553 INFO     Training average positive_sample_loss at step 50800: 0.040660\n",
      "2023-12-09 20:37:58,553 INFO     Training average negative_sample_loss at step 50800: 0.016454\n",
      "2023-12-09 20:37:58,553 INFO     Training average loss at step 50800: 0.028557\n",
      "2023-12-09 20:38:11,494 INFO     Training average positive_sample_loss at step 50900: 0.040840\n",
      "2023-12-09 20:38:11,494 INFO     Training average negative_sample_loss at step 50900: 0.016397\n",
      "2023-12-09 20:38:11,494 INFO     Training average loss at step 50900: 0.028619\n",
      "2023-12-09 20:38:25,943 INFO     Training average positive_sample_loss at step 51000: 0.041101\n",
      "2023-12-09 20:38:25,943 INFO     Training average negative_sample_loss at step 51000: 0.016420\n",
      "2023-12-09 20:38:25,943 INFO     Training average loss at step 51000: 0.028761\n",
      "2023-12-09 20:38:39,572 INFO     Training average positive_sample_loss at step 51100: 0.040457\n",
      "2023-12-09 20:38:39,573 INFO     Training average negative_sample_loss at step 51100: 0.016376\n",
      "2023-12-09 20:38:39,573 INFO     Training average loss at step 51100: 0.028417\n",
      "2023-12-09 20:38:53,197 INFO     Training average positive_sample_loss at step 51200: 0.040756\n",
      "2023-12-09 20:38:53,198 INFO     Training average negative_sample_loss at step 51200: 0.016547\n",
      "2023-12-09 20:38:53,198 INFO     Training average loss at step 51200: 0.028651\n",
      "2023-12-09 20:39:03,597 INFO     Training average positive_sample_loss at step 51300: 0.041393\n",
      "2023-12-09 20:39:03,597 INFO     Training average negative_sample_loss at step 51300: 0.016433\n",
      "2023-12-09 20:39:03,597 INFO     Training average loss at step 51300: 0.028913\n",
      "2023-12-09 20:39:18,841 INFO     Training average positive_sample_loss at step 51400: 0.040439\n",
      "2023-12-09 20:39:18,841 INFO     Training average negative_sample_loss at step 51400: 0.016468\n",
      "2023-12-09 20:39:18,841 INFO     Training average loss at step 51400: 0.028454\n",
      "2023-12-09 20:39:32,365 INFO     Training average positive_sample_loss at step 51500: 0.040518\n",
      "2023-12-09 20:39:32,366 INFO     Training average negative_sample_loss at step 51500: 0.016263\n",
      "2023-12-09 20:39:32,366 INFO     Training average loss at step 51500: 0.028390\n",
      "2023-12-09 20:39:43,414 INFO     Training average positive_sample_loss at step 51600: 0.040888\n",
      "2023-12-09 20:39:43,414 INFO     Training average negative_sample_loss at step 51600: 0.016310\n",
      "2023-12-09 20:39:43,414 INFO     Training average loss at step 51600: 0.028599\n",
      "2023-12-09 20:39:57,861 INFO     Training average positive_sample_loss at step 51700: 0.041324\n",
      "2023-12-09 20:39:57,861 INFO     Training average negative_sample_loss at step 51700: 0.016534\n",
      "2023-12-09 20:39:57,861 INFO     Training average loss at step 51700: 0.028929\n",
      "2023-12-09 20:40:11,088 INFO     Training average positive_sample_loss at step 51800: 0.040464\n",
      "2023-12-09 20:40:11,089 INFO     Training average negative_sample_loss at step 51800: 0.016335\n",
      "2023-12-09 20:40:11,089 INFO     Training average loss at step 51800: 0.028399\n",
      "2023-12-09 20:40:22,319 INFO     Training average positive_sample_loss at step 51900: 0.041094\n",
      "2023-12-09 20:40:22,319 INFO     Training average negative_sample_loss at step 51900: 0.016343\n",
      "2023-12-09 20:40:22,319 INFO     Training average loss at step 51900: 0.028718\n",
      "2023-12-09 20:40:34,097 INFO     Training average positive_sample_loss at step 52000: 0.041047\n",
      "2023-12-09 20:40:34,098 INFO     Training average negative_sample_loss at step 52000: 0.016407\n",
      "2023-12-09 20:40:34,098 INFO     Training average loss at step 52000: 0.028727\n",
      "2023-12-09 20:40:48,176 INFO     Training average positive_sample_loss at step 52100: 0.040501\n",
      "2023-12-09 20:40:48,176 INFO     Training average negative_sample_loss at step 52100: 0.016351\n",
      "2023-12-09 20:40:48,176 INFO     Training average loss at step 52100: 0.028426\n",
      "2023-12-09 20:41:01,713 INFO     Training average positive_sample_loss at step 52200: 0.040999\n",
      "2023-12-09 20:41:01,714 INFO     Training average negative_sample_loss at step 52200: 0.016326\n",
      "2023-12-09 20:41:01,714 INFO     Training average loss at step 52200: 0.028662\n",
      "2023-12-09 20:41:14,464 INFO     Training average positive_sample_loss at step 52300: 0.040842\n",
      "2023-12-09 20:41:14,465 INFO     Training average negative_sample_loss at step 52300: 0.016439\n",
      "2023-12-09 20:41:14,465 INFO     Training average loss at step 52300: 0.028641\n",
      "2023-12-09 20:41:29,021 INFO     Training average positive_sample_loss at step 52400: 0.040914\n",
      "2023-12-09 20:41:29,022 INFO     Training average negative_sample_loss at step 52400: 0.016283\n",
      "2023-12-09 20:41:29,022 INFO     Training average loss at step 52400: 0.028598\n",
      "2023-12-09 20:41:40,816 INFO     Training average positive_sample_loss at step 52500: 0.040684\n",
      "2023-12-09 20:41:40,817 INFO     Training average negative_sample_loss at step 52500: 0.016442\n",
      "2023-12-09 20:41:40,817 INFO     Training average loss at step 52500: 0.028563\n",
      "2023-12-09 20:41:52,179 INFO     Training average positive_sample_loss at step 52600: 0.041032\n",
      "2023-12-09 20:41:52,179 INFO     Training average negative_sample_loss at step 52600: 0.016303\n",
      "2023-12-09 20:41:52,179 INFO     Training average loss at step 52600: 0.028667\n",
      "2023-12-09 20:42:06,874 INFO     Training average positive_sample_loss at step 52700: 0.041000\n",
      "2023-12-09 20:42:06,875 INFO     Training average negative_sample_loss at step 52700: 0.016271\n",
      "2023-12-09 20:42:06,875 INFO     Training average loss at step 52700: 0.028635\n",
      "2023-12-09 20:42:20,825 INFO     Training average positive_sample_loss at step 52800: 0.040602\n",
      "2023-12-09 20:42:20,826 INFO     Training average negative_sample_loss at step 52800: 0.016358\n",
      "2023-12-09 20:42:20,826 INFO     Training average loss at step 52800: 0.028480\n",
      "2023-12-09 20:42:34,060 INFO     Training average positive_sample_loss at step 52900: 0.040697\n",
      "2023-12-09 20:42:34,060 INFO     Training average negative_sample_loss at step 52900: 0.016321\n",
      "2023-12-09 20:42:34,061 INFO     Training average loss at step 52900: 0.028509\n",
      "2023-12-09 20:42:47,546 INFO     Training average positive_sample_loss at step 53000: 0.041004\n",
      "2023-12-09 20:42:47,546 INFO     Training average negative_sample_loss at step 53000: 0.016294\n",
      "2023-12-09 20:42:47,546 INFO     Training average loss at step 53000: 0.028649\n",
      "2023-12-09 20:42:59,856 INFO     Training average positive_sample_loss at step 53100: 0.040818\n",
      "2023-12-09 20:42:59,856 INFO     Training average negative_sample_loss at step 53100: 0.016163\n",
      "2023-12-09 20:42:59,856 INFO     Training average loss at step 53100: 0.028490\n",
      "2023-12-09 20:43:12,128 INFO     Training average positive_sample_loss at step 53200: 0.040762\n",
      "2023-12-09 20:43:12,129 INFO     Training average negative_sample_loss at step 53200: 0.016276\n",
      "2023-12-09 20:43:12,129 INFO     Training average loss at step 53200: 0.028519\n",
      "2023-12-09 20:43:25,320 INFO     Training average positive_sample_loss at step 53300: 0.040806\n",
      "2023-12-09 20:43:25,320 INFO     Training average negative_sample_loss at step 53300: 0.016424\n",
      "2023-12-09 20:43:25,320 INFO     Training average loss at step 53300: 0.028615\n",
      "2023-12-09 20:43:38,498 INFO     Training average positive_sample_loss at step 53400: 0.040995\n",
      "2023-12-09 20:43:38,498 INFO     Training average negative_sample_loss at step 53400: 0.016251\n",
      "2023-12-09 20:43:38,498 INFO     Training average loss at step 53400: 0.028623\n",
      "2023-12-09 20:43:52,123 INFO     Training average positive_sample_loss at step 53500: 0.040665\n",
      "2023-12-09 20:43:52,124 INFO     Training average negative_sample_loss at step 53500: 0.016387\n",
      "2023-12-09 20:43:52,124 INFO     Training average loss at step 53500: 0.028526\n",
      "2023-12-09 20:44:05,792 INFO     Training average positive_sample_loss at step 53600: 0.040994\n",
      "2023-12-09 20:44:05,792 INFO     Training average negative_sample_loss at step 53600: 0.016302\n",
      "2023-12-09 20:44:05,792 INFO     Training average loss at step 53600: 0.028648\n",
      "2023-12-09 20:44:18,106 INFO     Training average positive_sample_loss at step 53700: 0.040875\n",
      "2023-12-09 20:44:18,107 INFO     Training average negative_sample_loss at step 53700: 0.016202\n",
      "2023-12-09 20:44:18,107 INFO     Training average loss at step 53700: 0.028538\n",
      "2023-12-09 20:44:32,218 INFO     Training average positive_sample_loss at step 53800: 0.040368\n",
      "2023-12-09 20:44:32,218 INFO     Training average negative_sample_loss at step 53800: 0.016394\n",
      "2023-12-09 20:44:32,218 INFO     Training average loss at step 53800: 0.028381\n",
      "2023-12-09 20:44:45,268 INFO     Training average positive_sample_loss at step 53900: 0.041025\n",
      "2023-12-09 20:44:45,269 INFO     Training average negative_sample_loss at step 53900: 0.016271\n",
      "2023-12-09 20:44:45,269 INFO     Training average loss at step 53900: 0.028648\n",
      "2023-12-09 20:44:58,609 INFO     Training average positive_sample_loss at step 54000: 0.041027\n",
      "2023-12-09 20:44:58,609 INFO     Training average negative_sample_loss at step 54000: 0.016271\n",
      "2023-12-09 20:44:58,609 INFO     Training average loss at step 54000: 0.028649\n",
      "2023-12-09 20:45:13,124 INFO     Training average positive_sample_loss at step 54100: 0.040669\n",
      "2023-12-09 20:45:13,124 INFO     Training average negative_sample_loss at step 54100: 0.016348\n",
      "2023-12-09 20:45:13,124 INFO     Training average loss at step 54100: 0.028509\n",
      "2023-12-09 20:45:25,444 INFO     Training average positive_sample_loss at step 54200: 0.040741\n",
      "2023-12-09 20:45:25,445 INFO     Training average negative_sample_loss at step 54200: 0.016148\n",
      "2023-12-09 20:45:25,445 INFO     Training average loss at step 54200: 0.028445\n",
      "2023-12-09 20:45:38,310 INFO     Training average positive_sample_loss at step 54300: 0.040986\n",
      "2023-12-09 20:45:38,310 INFO     Training average negative_sample_loss at step 54300: 0.016375\n",
      "2023-12-09 20:45:38,311 INFO     Training average loss at step 54300: 0.028680\n",
      "2023-12-09 20:45:49,289 INFO     Training average positive_sample_loss at step 54400: 0.040970\n",
      "2023-12-09 20:45:49,289 INFO     Training average negative_sample_loss at step 54400: 0.016389\n",
      "2023-12-09 20:45:49,290 INFO     Training average loss at step 54400: 0.028680\n",
      "2023-12-09 20:46:03,558 INFO     Training average positive_sample_loss at step 54500: 0.040598\n",
      "2023-12-09 20:46:03,558 INFO     Training average negative_sample_loss at step 54500: 0.016244\n",
      "2023-12-09 20:46:03,558 INFO     Training average loss at step 54500: 0.028421\n",
      "2023-12-09 20:46:15,384 INFO     Training average positive_sample_loss at step 54600: 0.040882\n",
      "2023-12-09 20:46:15,490 INFO     Training average negative_sample_loss at step 54600: 0.016323\n",
      "2023-12-09 20:46:15,490 INFO     Training average loss at step 54600: 0.028603\n",
      "2023-12-09 20:46:25,689 INFO     Training average positive_sample_loss at step 54700: 0.040923\n",
      "2023-12-09 20:46:25,689 INFO     Training average negative_sample_loss at step 54700: 0.016434\n",
      "2023-12-09 20:46:25,689 INFO     Training average loss at step 54700: 0.028679\n",
      "2023-12-09 20:46:38,567 INFO     Training average positive_sample_loss at step 54800: 0.040736\n",
      "2023-12-09 20:46:38,568 INFO     Training average negative_sample_loss at step 54800: 0.016207\n",
      "2023-12-09 20:46:38,568 INFO     Training average loss at step 54800: 0.028472\n",
      "2023-12-09 20:46:49,259 INFO     Training average positive_sample_loss at step 54900: 0.040752\n",
      "2023-12-09 20:46:49,259 INFO     Training average negative_sample_loss at step 54900: 0.016461\n",
      "2023-12-09 20:46:49,259 INFO     Training average loss at step 54900: 0.028606\n",
      "2023-12-09 20:46:59,124 INFO     Training average positive_sample_loss at step 55000: 0.040928\n",
      "2023-12-09 20:46:59,124 INFO     Training average negative_sample_loss at step 55000: 0.016299\n",
      "2023-12-09 20:46:59,124 INFO     Training average loss at step 55000: 0.028614\n",
      "2023-12-09 20:47:11,270 INFO     Training average positive_sample_loss at step 55100: 0.040900\n",
      "2023-12-09 20:47:11,271 INFO     Training average negative_sample_loss at step 55100: 0.016427\n",
      "2023-12-09 20:47:11,271 INFO     Training average loss at step 55100: 0.028664\n",
      "2023-12-09 20:47:21,255 INFO     Training average positive_sample_loss at step 55200: 0.040947\n",
      "2023-12-09 20:47:21,255 INFO     Training average negative_sample_loss at step 55200: 0.016232\n",
      "2023-12-09 20:47:21,255 INFO     Training average loss at step 55200: 0.028589\n",
      "2023-12-09 20:47:33,014 INFO     Training average positive_sample_loss at step 55300: 0.040614\n",
      "2023-12-09 20:47:33,015 INFO     Training average negative_sample_loss at step 55300: 0.016314\n",
      "2023-12-09 20:47:33,015 INFO     Training average loss at step 55300: 0.028464\n",
      "2023-12-09 20:47:45,946 INFO     Training average positive_sample_loss at step 55400: 0.040919\n",
      "2023-12-09 20:47:45,947 INFO     Training average negative_sample_loss at step 55400: 0.016278\n",
      "2023-12-09 20:47:45,947 INFO     Training average loss at step 55400: 0.028598\n",
      "2023-12-09 20:48:00,811 INFO     Training average positive_sample_loss at step 55500: 0.040555\n",
      "2023-12-09 20:48:00,812 INFO     Training average negative_sample_loss at step 55500: 0.016249\n",
      "2023-12-09 20:48:00,812 INFO     Training average loss at step 55500: 0.028402\n",
      "2023-12-09 20:48:14,292 INFO     Training average positive_sample_loss at step 55600: 0.040920\n",
      "2023-12-09 20:48:14,292 INFO     Training average negative_sample_loss at step 55600: 0.016360\n",
      "2023-12-09 20:48:14,293 INFO     Training average loss at step 55600: 0.028640\n",
      "2023-12-09 20:48:26,081 INFO     Training average positive_sample_loss at step 55700: 0.040910\n",
      "2023-12-09 20:48:26,082 INFO     Training average negative_sample_loss at step 55700: 0.016245\n",
      "2023-12-09 20:48:26,082 INFO     Training average loss at step 55700: 0.028577\n",
      "2023-12-09 20:48:38,303 INFO     Training average positive_sample_loss at step 55800: 0.040847\n",
      "2023-12-09 20:48:38,303 INFO     Training average negative_sample_loss at step 55800: 0.016316\n",
      "2023-12-09 20:48:38,304 INFO     Training average loss at step 55800: 0.028582\n",
      "2023-12-09 20:48:51,679 INFO     Training average positive_sample_loss at step 55900: 0.040738\n",
      "2023-12-09 20:48:51,679 INFO     Training average negative_sample_loss at step 55900: 0.016290\n",
      "2023-12-09 20:48:51,679 INFO     Training average loss at step 55900: 0.028514\n",
      "2023-12-09 20:49:02,626 INFO     Training average positive_sample_loss at step 56000: 0.040581\n",
      "2023-12-09 20:49:02,627 INFO     Training average negative_sample_loss at step 56000: 0.016120\n",
      "2023-12-09 20:49:02,627 INFO     Training average loss at step 56000: 0.028351\n",
      "2023-12-09 20:49:15,136 INFO     Training average positive_sample_loss at step 56100: 0.041188\n",
      "2023-12-09 20:49:15,136 INFO     Training average negative_sample_loss at step 56100: 0.016368\n",
      "2023-12-09 20:49:15,136 INFO     Training average loss at step 56100: 0.028778\n",
      "2023-12-09 20:49:28,339 INFO     Training average positive_sample_loss at step 56200: 0.040580\n",
      "2023-12-09 20:49:28,339 INFO     Training average negative_sample_loss at step 56200: 0.016302\n",
      "2023-12-09 20:49:28,340 INFO     Training average loss at step 56200: 0.028441\n",
      "2023-12-09 20:49:40,902 INFO     Training average positive_sample_loss at step 56300: 0.040865\n",
      "2023-12-09 20:49:40,902 INFO     Training average negative_sample_loss at step 56300: 0.016237\n",
      "2023-12-09 20:49:40,902 INFO     Training average loss at step 56300: 0.028551\n",
      "2023-12-09 20:49:51,662 INFO     Training average positive_sample_loss at step 56400: 0.041018\n",
      "2023-12-09 20:49:51,662 INFO     Training average negative_sample_loss at step 56400: 0.016286\n",
      "2023-12-09 20:49:51,662 INFO     Training average loss at step 56400: 0.028652\n",
      "2023-12-09 20:50:05,506 INFO     Training average positive_sample_loss at step 56500: 0.040493\n",
      "2023-12-09 20:50:05,506 INFO     Training average negative_sample_loss at step 56500: 0.016170\n",
      "2023-12-09 20:50:05,506 INFO     Training average loss at step 56500: 0.028331\n",
      "2023-12-09 20:50:17,873 INFO     Training average positive_sample_loss at step 56600: 0.040765\n",
      "2023-12-09 20:50:17,873 INFO     Training average negative_sample_loss at step 56600: 0.016302\n",
      "2023-12-09 20:50:17,873 INFO     Training average loss at step 56600: 0.028534\n",
      "2023-12-09 20:50:31,421 INFO     Training average positive_sample_loss at step 56700: 0.040848\n",
      "2023-12-09 20:50:31,421 INFO     Training average negative_sample_loss at step 56700: 0.016223\n",
      "2023-12-09 20:50:31,421 INFO     Training average loss at step 56700: 0.028536\n",
      "2023-12-09 20:50:45,651 INFO     Training average positive_sample_loss at step 56800: 0.041152\n",
      "2023-12-09 20:50:45,651 INFO     Training average negative_sample_loss at step 56800: 0.016236\n",
      "2023-12-09 20:50:45,651 INFO     Training average loss at step 56800: 0.028694\n",
      "2023-12-09 20:50:57,979 INFO     Training average positive_sample_loss at step 56900: 0.040637\n",
      "2023-12-09 20:50:57,979 INFO     Training average negative_sample_loss at step 56900: 0.016278\n",
      "2023-12-09 20:50:57,979 INFO     Training average loss at step 56900: 0.028458\n",
      "2023-12-09 20:51:09,356 INFO     Training average positive_sample_loss at step 57000: 0.040630\n",
      "2023-12-09 20:51:09,356 INFO     Training average negative_sample_loss at step 57000: 0.016183\n",
      "2023-12-09 20:51:09,356 INFO     Training average loss at step 57000: 0.028406\n",
      "2023-12-09 20:51:21,494 INFO     Training average positive_sample_loss at step 57100: 0.040896\n",
      "2023-12-09 20:51:21,495 INFO     Training average negative_sample_loss at step 57100: 0.016143\n",
      "2023-12-09 20:51:21,495 INFO     Training average loss at step 57100: 0.028520\n",
      "2023-12-09 20:51:37,093 INFO     Training average positive_sample_loss at step 57200: 0.040780\n",
      "2023-12-09 20:51:37,093 INFO     Training average negative_sample_loss at step 57200: 0.016437\n",
      "2023-12-09 20:51:37,093 INFO     Training average loss at step 57200: 0.028608\n",
      "2023-12-09 20:51:49,592 INFO     Training average positive_sample_loss at step 57300: 0.040828\n",
      "2023-12-09 20:51:49,592 INFO     Training average negative_sample_loss at step 57300: 0.016295\n",
      "2023-12-09 20:51:49,592 INFO     Training average loss at step 57300: 0.028562\n",
      "2023-12-09 20:52:03,162 INFO     Training average positive_sample_loss at step 57400: 0.041037\n",
      "2023-12-09 20:52:03,162 INFO     Training average negative_sample_loss at step 57400: 0.016349\n",
      "2023-12-09 20:52:03,162 INFO     Training average loss at step 57400: 0.028693\n",
      "2023-12-09 20:52:18,267 INFO     Training average positive_sample_loss at step 57500: 0.040615\n",
      "2023-12-09 20:52:18,267 INFO     Training average negative_sample_loss at step 57500: 0.016362\n",
      "2023-12-09 20:52:18,267 INFO     Training average loss at step 57500: 0.028488\n",
      "2023-12-09 20:52:30,187 INFO     Training average positive_sample_loss at step 57600: 0.040641\n",
      "2023-12-09 20:52:30,188 INFO     Training average negative_sample_loss at step 57600: 0.016026\n",
      "2023-12-09 20:52:30,188 INFO     Training average loss at step 57600: 0.028334\n",
      "2023-12-09 20:52:41,214 INFO     Training average positive_sample_loss at step 57700: 0.040811\n",
      "2023-12-09 20:52:41,215 INFO     Training average negative_sample_loss at step 57700: 0.016262\n",
      "2023-12-09 20:52:41,215 INFO     Training average loss at step 57700: 0.028536\n",
      "2023-12-09 20:52:55,697 INFO     Training average positive_sample_loss at step 57800: 0.041110\n",
      "2023-12-09 20:52:55,698 INFO     Training average negative_sample_loss at step 57800: 0.016175\n",
      "2023-12-09 20:52:55,698 INFO     Training average loss at step 57800: 0.028642\n",
      "2023-12-09 20:53:09,584 INFO     Training average positive_sample_loss at step 57900: 0.040516\n",
      "2023-12-09 20:53:09,585 INFO     Training average negative_sample_loss at step 57900: 0.016228\n",
      "2023-12-09 20:53:09,585 INFO     Training average loss at step 57900: 0.028372\n",
      "2023-12-09 20:53:22,384 INFO     Training average positive_sample_loss at step 58000: 0.040763\n",
      "2023-12-09 20:53:22,384 INFO     Training average negative_sample_loss at step 58000: 0.016197\n",
      "2023-12-09 20:53:22,385 INFO     Training average loss at step 58000: 0.028480\n",
      "2023-12-09 20:53:35,714 INFO     Training average positive_sample_loss at step 58100: 0.040941\n",
      "2023-12-09 20:53:35,714 INFO     Training average negative_sample_loss at step 58100: 0.016208\n",
      "2023-12-09 20:53:35,714 INFO     Training average loss at step 58100: 0.028574\n",
      "2023-12-09 20:53:50,089 INFO     Training average positive_sample_loss at step 58200: 0.040930\n",
      "2023-12-09 20:53:50,090 INFO     Training average negative_sample_loss at step 58200: 0.016243\n",
      "2023-12-09 20:53:50,090 INFO     Training average loss at step 58200: 0.028586\n",
      "2023-12-09 20:54:03,115 INFO     Training average positive_sample_loss at step 58300: 0.040693\n",
      "2023-12-09 20:54:03,115 INFO     Training average negative_sample_loss at step 58300: 0.016200\n",
      "2023-12-09 20:54:03,115 INFO     Training average loss at step 58300: 0.028447\n",
      "2023-12-09 20:54:15,891 INFO     Training average positive_sample_loss at step 58400: 0.040867\n",
      "2023-12-09 20:54:15,892 INFO     Training average negative_sample_loss at step 58400: 0.016329\n",
      "2023-12-09 20:54:15,892 INFO     Training average loss at step 58400: 0.028598\n",
      "2023-12-09 20:54:31,359 INFO     Training average positive_sample_loss at step 58500: 0.040741\n",
      "2023-12-09 20:54:31,360 INFO     Training average negative_sample_loss at step 58500: 0.016218\n",
      "2023-12-09 20:54:31,360 INFO     Training average loss at step 58500: 0.028480\n",
      "2023-12-09 20:54:44,186 INFO     Training average positive_sample_loss at step 58600: 0.040507\n",
      "2023-12-09 20:54:44,186 INFO     Training average negative_sample_loss at step 58600: 0.016237\n",
      "2023-12-09 20:54:44,186 INFO     Training average loss at step 58600: 0.028372\n",
      "2023-12-09 20:54:57,090 INFO     Training average positive_sample_loss at step 58700: 0.041055\n",
      "2023-12-09 20:54:57,090 INFO     Training average negative_sample_loss at step 58700: 0.016216\n",
      "2023-12-09 20:54:57,090 INFO     Training average loss at step 58700: 0.028636\n",
      "2023-12-09 20:55:09,925 INFO     Training average positive_sample_loss at step 58800: 0.040889\n",
      "2023-12-09 20:55:09,926 INFO     Training average negative_sample_loss at step 58800: 0.016124\n",
      "2023-12-09 20:55:09,926 INFO     Training average loss at step 58800: 0.028506\n",
      "2023-12-09 20:55:23,153 INFO     Training average positive_sample_loss at step 58900: 0.040750\n",
      "2023-12-09 20:55:23,153 INFO     Training average negative_sample_loss at step 58900: 0.016327\n",
      "2023-12-09 20:55:23,153 INFO     Training average loss at step 58900: 0.028538\n",
      "2023-12-09 20:55:36,686 INFO     Training average positive_sample_loss at step 59000: 0.040626\n",
      "2023-12-09 20:55:36,686 INFO     Training average negative_sample_loss at step 59000: 0.016148\n",
      "2023-12-09 20:55:36,686 INFO     Training average loss at step 59000: 0.028387\n",
      "2023-12-09 20:55:49,543 INFO     Training average positive_sample_loss at step 59100: 0.040919\n",
      "2023-12-09 20:55:49,544 INFO     Training average negative_sample_loss at step 59100: 0.016223\n",
      "2023-12-09 20:55:49,544 INFO     Training average loss at step 59100: 0.028571\n",
      "2023-12-09 20:56:05,006 INFO     Training average positive_sample_loss at step 59200: 0.040572\n",
      "2023-12-09 20:56:05,006 INFO     Training average negative_sample_loss at step 59200: 0.016245\n",
      "2023-12-09 20:56:05,006 INFO     Training average loss at step 59200: 0.028408\n",
      "2023-12-09 20:56:18,239 INFO     Training average positive_sample_loss at step 59300: 0.040848\n",
      "2023-12-09 20:56:18,239 INFO     Training average negative_sample_loss at step 59300: 0.016105\n",
      "2023-12-09 20:56:18,240 INFO     Training average loss at step 59300: 0.028477\n",
      "2023-12-09 20:56:30,755 INFO     Training average positive_sample_loss at step 59400: 0.040920\n",
      "2023-12-09 20:56:30,755 INFO     Training average negative_sample_loss at step 59400: 0.016189\n",
      "2023-12-09 20:56:30,755 INFO     Training average loss at step 59400: 0.028555\n",
      "2023-12-09 20:56:42,079 INFO     Training average positive_sample_loss at step 59500: 0.040905\n",
      "2023-12-09 20:56:42,079 INFO     Training average negative_sample_loss at step 59500: 0.016093\n",
      "2023-12-09 20:56:42,080 INFO     Training average loss at step 59500: 0.028499\n",
      "2023-12-09 20:56:54,047 INFO     Training average positive_sample_loss at step 59600: 0.040841\n",
      "2023-12-09 20:56:54,047 INFO     Training average negative_sample_loss at step 59600: 0.016186\n",
      "2023-12-09 20:56:54,047 INFO     Training average loss at step 59600: 0.028514\n",
      "2023-12-09 20:57:07,388 INFO     Training average positive_sample_loss at step 59700: 0.040712\n",
      "2023-12-09 20:57:07,389 INFO     Training average negative_sample_loss at step 59700: 0.016160\n",
      "2023-12-09 20:57:07,389 INFO     Training average loss at step 59700: 0.028436\n",
      "2023-12-09 20:57:20,903 INFO     Training average positive_sample_loss at step 59800: 0.040545\n",
      "2023-12-09 20:57:20,903 INFO     Training average negative_sample_loss at step 59800: 0.016119\n",
      "2023-12-09 20:57:20,903 INFO     Training average loss at step 59800: 0.028332\n",
      "2023-12-09 20:57:34,870 INFO     Training average positive_sample_loss at step 59900: 0.040849\n",
      "2023-12-09 20:57:34,870 INFO     Training average negative_sample_loss at step 59900: 0.016141\n",
      "2023-12-09 20:57:34,870 INFO     Training average loss at step 59900: 0.028495\n",
      "2023-12-09 20:58:01,379 INFO     Training average positive_sample_loss at step 60000: 0.040886\n",
      "2023-12-09 20:58:01,379 INFO     Training average negative_sample_loss at step 60000: 0.016137\n",
      "2023-12-09 20:58:01,379 INFO     Training average loss at step 60000: 0.028512\n",
      "2023-12-09 20:58:01,379 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 20:58:01,997 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 20:58:42,835 INFO     Valid MRR at step 60000: 0.482334\n",
      "2023-12-09 20:58:42,836 INFO     Valid MR at step 60000: 1767.399473\n",
      "2023-12-09 20:58:42,836 INFO     Valid HITS@1 at step 60000: 0.438365\n",
      "2023-12-09 20:58:42,836 INFO     Valid HITS@3 at step 60000: 0.495221\n",
      "2023-12-09 20:58:42,836 INFO     Valid HITS@10 at step 60000: 0.570369\n",
      "2023-12-09 20:58:55,539 INFO     Training average positive_sample_loss at step 60100: 0.040769\n",
      "2023-12-09 20:58:55,540 INFO     Training average negative_sample_loss at step 60100: 0.016270\n",
      "2023-12-09 20:58:55,540 INFO     Training average loss at step 60100: 0.028520\n",
      "2023-12-09 20:59:10,580 INFO     Training average positive_sample_loss at step 60200: 0.040722\n",
      "2023-12-09 20:59:10,580 INFO     Training average negative_sample_loss at step 60200: 0.016305\n",
      "2023-12-09 20:59:10,580 INFO     Training average loss at step 60200: 0.028514\n",
      "2023-12-09 20:59:21,568 INFO     Training average positive_sample_loss at step 60300: 0.040638\n",
      "2023-12-09 20:59:21,569 INFO     Training average negative_sample_loss at step 60300: 0.016190\n",
      "2023-12-09 20:59:21,569 INFO     Training average loss at step 60300: 0.028414\n",
      "2023-12-09 20:59:34,199 INFO     Training average positive_sample_loss at step 60400: 0.040822\n",
      "2023-12-09 20:59:34,199 INFO     Training average negative_sample_loss at step 60400: 0.016314\n",
      "2023-12-09 20:59:34,200 INFO     Training average loss at step 60400: 0.028568\n",
      "2023-12-09 20:59:47,524 INFO     Training average positive_sample_loss at step 60500: 0.040880\n",
      "2023-12-09 20:59:47,525 INFO     Training average negative_sample_loss at step 60500: 0.016155\n",
      "2023-12-09 20:59:47,525 INFO     Training average loss at step 60500: 0.028517\n",
      "2023-12-09 21:00:02,871 INFO     Training average positive_sample_loss at step 60600: 0.040575\n",
      "2023-12-09 21:00:02,871 INFO     Training average negative_sample_loss at step 60600: 0.016131\n",
      "2023-12-09 21:00:02,871 INFO     Training average loss at step 60600: 0.028353\n",
      "2023-12-09 21:00:15,845 INFO     Training average positive_sample_loss at step 60700: 0.040935\n",
      "2023-12-09 21:00:15,846 INFO     Training average negative_sample_loss at step 60700: 0.016143\n",
      "2023-12-09 21:00:15,846 INFO     Training average loss at step 60700: 0.028539\n",
      "2023-12-09 21:00:28,867 INFO     Training average positive_sample_loss at step 60800: 0.040733\n",
      "2023-12-09 21:00:28,867 INFO     Training average negative_sample_loss at step 60800: 0.016194\n",
      "2023-12-09 21:00:28,867 INFO     Training average loss at step 60800: 0.028463\n",
      "2023-12-09 21:00:42,678 INFO     Training average positive_sample_loss at step 60900: 0.040749\n",
      "2023-12-09 21:00:42,679 INFO     Training average negative_sample_loss at step 60900: 0.016194\n",
      "2023-12-09 21:00:42,679 INFO     Training average loss at step 60900: 0.028471\n",
      "2023-12-09 21:00:55,146 INFO     Training average positive_sample_loss at step 61000: 0.040810\n",
      "2023-12-09 21:00:55,147 INFO     Training average negative_sample_loss at step 61000: 0.016149\n",
      "2023-12-09 21:00:55,147 INFO     Training average loss at step 61000: 0.028480\n",
      "2023-12-09 21:01:07,956 INFO     Training average positive_sample_loss at step 61100: 0.040714\n",
      "2023-12-09 21:01:07,956 INFO     Training average negative_sample_loss at step 61100: 0.016006\n",
      "2023-12-09 21:01:07,956 INFO     Training average loss at step 61100: 0.028360\n",
      "2023-12-09 21:01:19,677 INFO     Training average positive_sample_loss at step 61200: 0.040949\n",
      "2023-12-09 21:01:19,678 INFO     Training average negative_sample_loss at step 61200: 0.016216\n",
      "2023-12-09 21:01:19,678 INFO     Training average loss at step 61200: 0.028582\n",
      "2023-12-09 21:01:32,196 INFO     Training average positive_sample_loss at step 61300: 0.040438\n",
      "2023-12-09 21:01:32,197 INFO     Training average negative_sample_loss at step 61300: 0.016031\n",
      "2023-12-09 21:01:32,197 INFO     Training average loss at step 61300: 0.028235\n",
      "2023-12-09 21:01:45,841 INFO     Training average positive_sample_loss at step 61400: 0.040994\n",
      "2023-12-09 21:01:45,841 INFO     Training average negative_sample_loss at step 61400: 0.016231\n",
      "2023-12-09 21:01:45,841 INFO     Training average loss at step 61400: 0.028612\n",
      "2023-12-09 21:01:58,477 INFO     Training average positive_sample_loss at step 61500: 0.040814\n",
      "2023-12-09 21:01:58,477 INFO     Training average negative_sample_loss at step 61500: 0.016238\n",
      "2023-12-09 21:01:58,477 INFO     Training average loss at step 61500: 0.028526\n",
      "2023-12-09 21:02:11,128 INFO     Training average positive_sample_loss at step 61600: 0.040486\n",
      "2023-12-09 21:02:11,129 INFO     Training average negative_sample_loss at step 61600: 0.016217\n",
      "2023-12-09 21:02:11,129 INFO     Training average loss at step 61600: 0.028351\n",
      "2023-12-09 21:02:24,470 INFO     Training average positive_sample_loss at step 61700: 0.040733\n",
      "2023-12-09 21:02:24,470 INFO     Training average negative_sample_loss at step 61700: 0.016169\n",
      "2023-12-09 21:02:24,470 INFO     Training average loss at step 61700: 0.028451\n",
      "2023-12-09 21:02:36,859 INFO     Training average positive_sample_loss at step 61800: 0.040957\n",
      "2023-12-09 21:02:36,860 INFO     Training average negative_sample_loss at step 61800: 0.016114\n",
      "2023-12-09 21:02:36,860 INFO     Training average loss at step 61800: 0.028535\n",
      "2023-12-09 21:02:50,634 INFO     Training average positive_sample_loss at step 61900: 0.040958\n",
      "2023-12-09 21:02:50,634 INFO     Training average negative_sample_loss at step 61900: 0.016110\n",
      "2023-12-09 21:02:50,635 INFO     Training average loss at step 61900: 0.028534\n",
      "2023-12-09 21:03:03,147 INFO     Training average positive_sample_loss at step 62000: 0.040544\n",
      "2023-12-09 21:03:03,147 INFO     Training average negative_sample_loss at step 62000: 0.016034\n",
      "2023-12-09 21:03:03,147 INFO     Training average loss at step 62000: 0.028289\n",
      "2023-12-09 21:03:16,282 INFO     Training average positive_sample_loss at step 62100: 0.040852\n",
      "2023-12-09 21:03:16,283 INFO     Training average negative_sample_loss at step 62100: 0.016248\n",
      "2023-12-09 21:03:16,283 INFO     Training average loss at step 62100: 0.028550\n",
      "2023-12-09 21:03:26,208 INFO     Training average positive_sample_loss at step 62200: 0.040744\n",
      "2023-12-09 21:03:26,208 INFO     Training average negative_sample_loss at step 62200: 0.016069\n",
      "2023-12-09 21:03:26,209 INFO     Training average loss at step 62200: 0.028407\n",
      "2023-12-09 21:03:40,106 INFO     Training average positive_sample_loss at step 62300: 0.040420\n",
      "2023-12-09 21:03:40,107 INFO     Training average negative_sample_loss at step 62300: 0.016143\n",
      "2023-12-09 21:03:40,107 INFO     Training average loss at step 62300: 0.028282\n",
      "2023-12-09 21:03:53,245 INFO     Training average positive_sample_loss at step 62400: 0.040851\n",
      "2023-12-09 21:03:53,245 INFO     Training average negative_sample_loss at step 62400: 0.016116\n",
      "2023-12-09 21:03:53,245 INFO     Training average loss at step 62400: 0.028484\n",
      "2023-12-09 21:04:04,904 INFO     Training average positive_sample_loss at step 62500: 0.041062\n",
      "2023-12-09 21:04:04,904 INFO     Training average negative_sample_loss at step 62500: 0.016156\n",
      "2023-12-09 21:04:04,904 INFO     Training average loss at step 62500: 0.028609\n",
      "2023-12-09 21:04:18,852 INFO     Training average positive_sample_loss at step 62600: 0.040543\n",
      "2023-12-09 21:04:18,853 INFO     Training average negative_sample_loss at step 62600: 0.016112\n",
      "2023-12-09 21:04:18,853 INFO     Training average loss at step 62600: 0.028328\n",
      "2023-12-09 21:04:32,097 INFO     Training average positive_sample_loss at step 62700: 0.040681\n",
      "2023-12-09 21:04:32,097 INFO     Training average negative_sample_loss at step 62700: 0.016235\n",
      "2023-12-09 21:04:32,097 INFO     Training average loss at step 62700: 0.028458\n",
      "2023-12-09 21:04:43,602 INFO     Training average positive_sample_loss at step 62800: 0.040769\n",
      "2023-12-09 21:04:43,602 INFO     Training average negative_sample_loss at step 62800: 0.016151\n",
      "2023-12-09 21:04:43,602 INFO     Training average loss at step 62800: 0.028460\n",
      "2023-12-09 21:04:55,807 INFO     Training average positive_sample_loss at step 62900: 0.040932\n",
      "2023-12-09 21:04:55,808 INFO     Training average negative_sample_loss at step 62900: 0.016187\n",
      "2023-12-09 21:04:55,808 INFO     Training average loss at step 62900: 0.028559\n",
      "2023-12-09 21:05:10,040 INFO     Training average positive_sample_loss at step 63000: 0.040322\n",
      "2023-12-09 21:05:10,041 INFO     Training average negative_sample_loss at step 63000: 0.016120\n",
      "2023-12-09 21:05:10,041 INFO     Training average loss at step 63000: 0.028221\n",
      "2023-12-09 21:05:23,244 INFO     Training average positive_sample_loss at step 63100: 0.040790\n",
      "2023-12-09 21:05:23,244 INFO     Training average negative_sample_loss at step 63100: 0.016158\n",
      "2023-12-09 21:05:23,244 INFO     Training average loss at step 63100: 0.028474\n",
      "2023-12-09 21:05:35,796 INFO     Training average positive_sample_loss at step 63200: 0.040988\n",
      "2023-12-09 21:05:35,796 INFO     Training average negative_sample_loss at step 63200: 0.016186\n",
      "2023-12-09 21:05:35,796 INFO     Training average loss at step 63200: 0.028587\n",
      "2023-12-09 21:05:51,061 INFO     Training average positive_sample_loss at step 63300: 0.040889\n",
      "2023-12-09 21:05:51,062 INFO     Training average negative_sample_loss at step 63300: 0.016048\n",
      "2023-12-09 21:05:51,062 INFO     Training average loss at step 63300: 0.028469\n",
      "2023-12-09 21:06:02,877 INFO     Training average positive_sample_loss at step 63400: 0.040539\n",
      "2023-12-09 21:06:02,877 INFO     Training average negative_sample_loss at step 63400: 0.016197\n",
      "2023-12-09 21:06:02,877 INFO     Training average loss at step 63400: 0.028368\n",
      "2023-12-09 21:06:12,483 INFO     Training average positive_sample_loss at step 63500: 0.040744\n",
      "2023-12-09 21:06:12,484 INFO     Training average negative_sample_loss at step 63500: 0.015990\n",
      "2023-12-09 21:06:12,484 INFO     Training average loss at step 63500: 0.028367\n",
      "2023-12-09 21:06:26,774 INFO     Training average positive_sample_loss at step 63600: 0.040835\n",
      "2023-12-09 21:06:26,774 INFO     Training average negative_sample_loss at step 63600: 0.016105\n",
      "2023-12-09 21:06:26,774 INFO     Training average loss at step 63600: 0.028470\n",
      "2023-12-09 21:06:39,526 INFO     Training average positive_sample_loss at step 63700: 0.040497\n",
      "2023-12-09 21:06:39,526 INFO     Training average negative_sample_loss at step 63700: 0.016056\n",
      "2023-12-09 21:06:39,526 INFO     Training average loss at step 63700: 0.028276\n",
      "2023-12-09 21:06:52,692 INFO     Training average positive_sample_loss at step 63800: 0.040691\n",
      "2023-12-09 21:06:52,692 INFO     Training average negative_sample_loss at step 63800: 0.015984\n",
      "2023-12-09 21:06:52,692 INFO     Training average loss at step 63800: 0.028338\n",
      "2023-12-09 21:07:05,904 INFO     Training average positive_sample_loss at step 63900: 0.040980\n",
      "2023-12-09 21:07:05,904 INFO     Training average negative_sample_loss at step 63900: 0.016274\n",
      "2023-12-09 21:07:05,904 INFO     Training average loss at step 63900: 0.028627\n",
      "2023-12-09 21:07:20,899 INFO     Training average positive_sample_loss at step 64000: 0.040790\n",
      "2023-12-09 21:07:20,900 INFO     Training average negative_sample_loss at step 64000: 0.016014\n",
      "2023-12-09 21:07:20,900 INFO     Training average loss at step 64000: 0.028402\n",
      "2023-12-09 21:07:31,485 INFO     Training average positive_sample_loss at step 64100: 0.040652\n",
      "2023-12-09 21:07:31,486 INFO     Training average negative_sample_loss at step 64100: 0.016293\n",
      "2023-12-09 21:07:31,486 INFO     Training average loss at step 64100: 0.028473\n",
      "2023-12-09 21:07:44,980 INFO     Training average positive_sample_loss at step 64200: 0.040712\n",
      "2023-12-09 21:07:44,981 INFO     Training average negative_sample_loss at step 64200: 0.016017\n",
      "2023-12-09 21:07:44,981 INFO     Training average loss at step 64200: 0.028365\n",
      "2023-12-09 21:08:00,420 INFO     Training average positive_sample_loss at step 64300: 0.040555\n",
      "2023-12-09 21:08:00,420 INFO     Training average negative_sample_loss at step 64300: 0.016028\n",
      "2023-12-09 21:08:00,420 INFO     Training average loss at step 64300: 0.028292\n",
      "2023-12-09 21:08:13,088 INFO     Training average positive_sample_loss at step 64400: 0.040664\n",
      "2023-12-09 21:08:13,089 INFO     Training average negative_sample_loss at step 64400: 0.016169\n",
      "2023-12-09 21:08:13,089 INFO     Training average loss at step 64400: 0.028417\n",
      "2023-12-09 21:08:26,202 INFO     Training average positive_sample_loss at step 64500: 0.040887\n",
      "2023-12-09 21:08:26,203 INFO     Training average negative_sample_loss at step 64500: 0.016139\n",
      "2023-12-09 21:08:26,203 INFO     Training average loss at step 64500: 0.028513\n",
      "2023-12-09 21:08:40,621 INFO     Training average positive_sample_loss at step 64600: 0.040837\n",
      "2023-12-09 21:08:40,622 INFO     Training average negative_sample_loss at step 64600: 0.016054\n",
      "2023-12-09 21:08:40,622 INFO     Training average loss at step 64600: 0.028445\n",
      "2023-12-09 21:08:54,997 INFO     Training average positive_sample_loss at step 64700: 0.040339\n",
      "2023-12-09 21:08:54,997 INFO     Training average negative_sample_loss at step 64700: 0.016065\n",
      "2023-12-09 21:08:54,997 INFO     Training average loss at step 64700: 0.028202\n",
      "2023-12-09 21:09:09,360 INFO     Training average positive_sample_loss at step 64800: 0.040555\n",
      "2023-12-09 21:09:09,361 INFO     Training average negative_sample_loss at step 64800: 0.016110\n",
      "2023-12-09 21:09:09,361 INFO     Training average loss at step 64800: 0.028333\n",
      "2023-12-09 21:09:23,748 INFO     Training average positive_sample_loss at step 64900: 0.041058\n",
      "2023-12-09 21:09:23,748 INFO     Training average negative_sample_loss at step 64900: 0.016008\n",
      "2023-12-09 21:09:23,749 INFO     Training average loss at step 64900: 0.028533\n",
      "2023-12-09 21:09:40,136 INFO     Training average positive_sample_loss at step 65000: 0.040672\n",
      "2023-12-09 21:09:40,137 INFO     Training average negative_sample_loss at step 65000: 0.016067\n",
      "2023-12-09 21:09:40,137 INFO     Training average loss at step 65000: 0.028370\n",
      "2023-12-09 21:09:54,517 INFO     Training average positive_sample_loss at step 65100: 0.040696\n",
      "2023-12-09 21:09:54,517 INFO     Training average negative_sample_loss at step 65100: 0.016194\n",
      "2023-12-09 21:09:54,517 INFO     Training average loss at step 65100: 0.028445\n",
      "2023-12-09 21:10:07,915 INFO     Training average positive_sample_loss at step 65200: 0.040852\n",
      "2023-12-09 21:10:07,915 INFO     Training average negative_sample_loss at step 65200: 0.016179\n",
      "2023-12-09 21:10:07,915 INFO     Training average loss at step 65200: 0.028516\n",
      "2023-12-09 21:10:23,209 INFO     Training average positive_sample_loss at step 65300: 0.040843\n",
      "2023-12-09 21:10:23,210 INFO     Training average negative_sample_loss at step 65300: 0.016085\n",
      "2023-12-09 21:10:23,210 INFO     Training average loss at step 65300: 0.028464\n",
      "2023-12-09 21:10:37,509 INFO     Training average positive_sample_loss at step 65400: 0.040409\n",
      "2023-12-09 21:10:37,509 INFO     Training average negative_sample_loss at step 65400: 0.016051\n",
      "2023-12-09 21:10:37,509 INFO     Training average loss at step 65400: 0.028230\n",
      "2023-12-09 21:10:51,892 INFO     Training average positive_sample_loss at step 65500: 0.040711\n",
      "2023-12-09 21:10:51,893 INFO     Training average negative_sample_loss at step 65500: 0.016108\n",
      "2023-12-09 21:10:51,893 INFO     Training average loss at step 65500: 0.028409\n",
      "2023-12-09 21:11:06,282 INFO     Training average positive_sample_loss at step 65600: 0.040957\n",
      "2023-12-09 21:11:06,282 INFO     Training average negative_sample_loss at step 65600: 0.016183\n",
      "2023-12-09 21:11:06,282 INFO     Training average loss at step 65600: 0.028570\n",
      "2023-12-09 21:11:22,741 INFO     Training average positive_sample_loss at step 65700: 0.040482\n",
      "2023-12-09 21:11:22,742 INFO     Training average negative_sample_loss at step 65700: 0.016080\n",
      "2023-12-09 21:11:22,742 INFO     Training average loss at step 65700: 0.028281\n",
      "2023-12-09 21:11:35,208 INFO     Training average positive_sample_loss at step 65800: 0.040947\n",
      "2023-12-09 21:11:35,209 INFO     Training average negative_sample_loss at step 65800: 0.016168\n",
      "2023-12-09 21:11:35,209 INFO     Training average loss at step 65800: 0.028557\n",
      "2023-12-09 21:11:49,511 INFO     Training average positive_sample_loss at step 65900: 0.040702\n",
      "2023-12-09 21:11:49,511 INFO     Training average negative_sample_loss at step 65900: 0.016087\n",
      "2023-12-09 21:11:49,511 INFO     Training average loss at step 65900: 0.028395\n",
      "2023-12-09 21:12:03,660 INFO     Training average positive_sample_loss at step 66000: 0.040578\n",
      "2023-12-09 21:12:03,660 INFO     Training average negative_sample_loss at step 66000: 0.016064\n",
      "2023-12-09 21:12:03,660 INFO     Training average loss at step 66000: 0.028321\n",
      "2023-12-09 21:12:14,772 INFO     Training average positive_sample_loss at step 66100: 0.040401\n",
      "2023-12-09 21:12:14,772 INFO     Training average negative_sample_loss at step 66100: 0.016044\n",
      "2023-12-09 21:12:14,772 INFO     Training average loss at step 66100: 0.028222\n",
      "2023-12-09 21:12:26,315 INFO     Training average positive_sample_loss at step 66200: 0.040933\n",
      "2023-12-09 21:12:26,315 INFO     Training average negative_sample_loss at step 66200: 0.016164\n",
      "2023-12-09 21:12:26,315 INFO     Training average loss at step 66200: 0.028549\n",
      "2023-12-09 21:12:38,452 INFO     Training average positive_sample_loss at step 66300: 0.040997\n",
      "2023-12-09 21:12:38,452 INFO     Training average negative_sample_loss at step 66300: 0.016113\n",
      "2023-12-09 21:12:38,452 INFO     Training average loss at step 66300: 0.028555\n",
      "2023-12-09 21:12:50,797 INFO     Training average positive_sample_loss at step 66400: 0.040395\n",
      "2023-12-09 21:12:50,798 INFO     Training average negative_sample_loss at step 66400: 0.016103\n",
      "2023-12-09 21:12:50,798 INFO     Training average loss at step 66400: 0.028249\n",
      "2023-12-09 21:13:01,947 INFO     Training average positive_sample_loss at step 66500: 0.040969\n",
      "2023-12-09 21:13:01,947 INFO     Training average negative_sample_loss at step 66500: 0.016123\n",
      "2023-12-09 21:13:01,947 INFO     Training average loss at step 66500: 0.028546\n",
      "2023-12-09 21:13:13,150 INFO     Training average positive_sample_loss at step 66600: 0.040828\n",
      "2023-12-09 21:13:13,150 INFO     Training average negative_sample_loss at step 66600: 0.015989\n",
      "2023-12-09 21:13:13,150 INFO     Training average loss at step 66600: 0.028408\n",
      "2023-12-09 21:13:26,730 INFO     Training average positive_sample_loss at step 66700: 0.040559\n",
      "2023-12-09 21:13:26,731 INFO     Training average negative_sample_loss at step 66700: 0.016222\n",
      "2023-12-09 21:13:26,731 INFO     Training average loss at step 66700: 0.028390\n",
      "2023-12-09 21:13:38,596 INFO     Training average positive_sample_loss at step 66800: 0.040756\n",
      "2023-12-09 21:13:38,597 INFO     Training average negative_sample_loss at step 66800: 0.016026\n",
      "2023-12-09 21:13:38,597 INFO     Training average loss at step 66800: 0.028391\n",
      "2023-12-09 21:13:53,056 INFO     Training average positive_sample_loss at step 66900: 0.040582\n",
      "2023-12-09 21:13:53,056 INFO     Training average negative_sample_loss at step 66900: 0.015964\n",
      "2023-12-09 21:13:53,056 INFO     Training average loss at step 66900: 0.028273\n",
      "2023-12-09 21:14:09,739 INFO     Training average positive_sample_loss at step 67000: 0.040700\n",
      "2023-12-09 21:14:09,739 INFO     Training average negative_sample_loss at step 67000: 0.016092\n",
      "2023-12-09 21:14:09,739 INFO     Training average loss at step 67000: 0.028396\n",
      "2023-12-09 21:14:24,052 INFO     Training average positive_sample_loss at step 67100: 0.040578\n",
      "2023-12-09 21:14:24,053 INFO     Training average negative_sample_loss at step 67100: 0.016029\n",
      "2023-12-09 21:14:24,053 INFO     Training average loss at step 67100: 0.028304\n",
      "2023-12-09 21:14:36,674 INFO     Training average positive_sample_loss at step 67200: 0.040565\n",
      "2023-12-09 21:14:36,675 INFO     Training average negative_sample_loss at step 67200: 0.015989\n",
      "2023-12-09 21:14:36,675 INFO     Training average loss at step 67200: 0.028277\n",
      "2023-12-09 21:14:51,069 INFO     Training average positive_sample_loss at step 67300: 0.040881\n",
      "2023-12-09 21:14:51,069 INFO     Training average negative_sample_loss at step 67300: 0.016229\n",
      "2023-12-09 21:14:51,069 INFO     Training average loss at step 67300: 0.028555\n",
      "2023-12-09 21:15:07,557 INFO     Training average positive_sample_loss at step 67400: 0.040720\n",
      "2023-12-09 21:15:07,557 INFO     Training average negative_sample_loss at step 67400: 0.016209\n",
      "2023-12-09 21:15:07,557 INFO     Training average loss at step 67400: 0.028465\n",
      "2023-12-09 21:15:21,901 INFO     Training average positive_sample_loss at step 67500: 0.040372\n",
      "2023-12-09 21:15:21,901 INFO     Training average negative_sample_loss at step 67500: 0.015918\n",
      "2023-12-09 21:15:21,901 INFO     Training average loss at step 67500: 0.028145\n",
      "2023-12-09 21:15:36,120 INFO     Training average positive_sample_loss at step 67600: 0.040796\n",
      "2023-12-09 21:15:36,120 INFO     Training average negative_sample_loss at step 67600: 0.016067\n",
      "2023-12-09 21:15:36,120 INFO     Training average loss at step 67600: 0.028431\n",
      "2023-12-09 21:15:51,731 INFO     Training average positive_sample_loss at step 67700: 0.040834\n",
      "2023-12-09 21:15:51,731 INFO     Training average negative_sample_loss at step 67700: 0.016268\n",
      "2023-12-09 21:15:51,731 INFO     Training average loss at step 67700: 0.028551\n",
      "2023-12-09 21:16:04,932 INFO     Training average positive_sample_loss at step 67800: 0.040399\n",
      "2023-12-09 21:16:04,932 INFO     Training average negative_sample_loss at step 67800: 0.016013\n",
      "2023-12-09 21:16:04,932 INFO     Training average loss at step 67800: 0.028206\n",
      "2023-12-09 21:16:19,169 INFO     Training average positive_sample_loss at step 67900: 0.040815\n",
      "2023-12-09 21:16:19,170 INFO     Training average negative_sample_loss at step 67900: 0.016172\n",
      "2023-12-09 21:16:19,170 INFO     Training average loss at step 67900: 0.028493\n",
      "2023-12-09 21:16:34,400 INFO     Training average positive_sample_loss at step 68000: 0.040931\n",
      "2023-12-09 21:16:34,400 INFO     Training average negative_sample_loss at step 68000: 0.016166\n",
      "2023-12-09 21:16:34,400 INFO     Training average loss at step 68000: 0.028548\n",
      "2023-12-09 21:16:49,799 INFO     Training average positive_sample_loss at step 68100: 0.040403\n",
      "2023-12-09 21:16:49,799 INFO     Training average negative_sample_loss at step 68100: 0.016185\n",
      "2023-12-09 21:16:49,799 INFO     Training average loss at step 68100: 0.028294\n",
      "2023-12-09 21:17:04,183 INFO     Training average positive_sample_loss at step 68200: 0.040708\n",
      "2023-12-09 21:17:04,184 INFO     Training average negative_sample_loss at step 68200: 0.015947\n",
      "2023-12-09 21:17:04,184 INFO     Training average loss at step 68200: 0.028327\n",
      "2023-12-09 21:17:16,741 INFO     Training average positive_sample_loss at step 68300: 0.040798\n",
      "2023-12-09 21:17:16,741 INFO     Training average negative_sample_loss at step 68300: 0.016214\n",
      "2023-12-09 21:17:16,741 INFO     Training average loss at step 68300: 0.028506\n",
      "2023-12-09 21:17:32,873 INFO     Training average positive_sample_loss at step 68400: 0.040804\n",
      "2023-12-09 21:17:32,873 INFO     Training average negative_sample_loss at step 68400: 0.016170\n",
      "2023-12-09 21:17:32,873 INFO     Training average loss at step 68400: 0.028487\n",
      "2023-12-09 21:17:46,958 INFO     Training average positive_sample_loss at step 68500: 0.040551\n",
      "2023-12-09 21:17:46,958 INFO     Training average negative_sample_loss at step 68500: 0.016187\n",
      "2023-12-09 21:17:46,958 INFO     Training average loss at step 68500: 0.028369\n",
      "2023-12-09 21:18:01,222 INFO     Training average positive_sample_loss at step 68600: 0.040613\n",
      "2023-12-09 21:18:01,222 INFO     Training average negative_sample_loss at step 68600: 0.016083\n",
      "2023-12-09 21:18:01,222 INFO     Training average loss at step 68600: 0.028348\n",
      "2023-12-09 21:18:17,558 INFO     Training average positive_sample_loss at step 68700: 0.040843\n",
      "2023-12-09 21:18:17,559 INFO     Training average negative_sample_loss at step 68700: 0.016203\n",
      "2023-12-09 21:18:17,559 INFO     Training average loss at step 68700: 0.028523\n",
      "2023-12-09 21:18:31,416 INFO     Training average positive_sample_loss at step 68800: 0.040529\n",
      "2023-12-09 21:18:31,417 INFO     Training average negative_sample_loss at step 68800: 0.016054\n",
      "2023-12-09 21:18:31,417 INFO     Training average loss at step 68800: 0.028292\n",
      "2023-12-09 21:18:44,005 INFO     Training average positive_sample_loss at step 68900: 0.040455\n",
      "2023-12-09 21:18:44,005 INFO     Training average negative_sample_loss at step 68900: 0.016144\n",
      "2023-12-09 21:18:44,006 INFO     Training average loss at step 68900: 0.028299\n",
      "2023-12-09 21:18:58,013 INFO     Training average positive_sample_loss at step 69000: 0.041019\n",
      "2023-12-09 21:18:58,013 INFO     Training average negative_sample_loss at step 69000: 0.016139\n",
      "2023-12-09 21:18:58,013 INFO     Training average loss at step 69000: 0.028579\n",
      "2023-12-09 21:19:14,404 INFO     Training average positive_sample_loss at step 69100: 0.040457\n",
      "2023-12-09 21:19:14,405 INFO     Training average negative_sample_loss at step 69100: 0.016098\n",
      "2023-12-09 21:19:14,405 INFO     Training average loss at step 69100: 0.028277\n",
      "2023-12-09 21:19:28,774 INFO     Training average positive_sample_loss at step 69200: 0.040773\n",
      "2023-12-09 21:19:28,775 INFO     Training average negative_sample_loss at step 69200: 0.016090\n",
      "2023-12-09 21:19:28,775 INFO     Training average loss at step 69200: 0.028431\n",
      "2023-12-09 21:19:43,143 INFO     Training average positive_sample_loss at step 69300: 0.040646\n",
      "2023-12-09 21:19:43,143 INFO     Training average negative_sample_loss at step 69300: 0.015951\n",
      "2023-12-09 21:19:43,144 INFO     Training average loss at step 69300: 0.028298\n",
      "2023-12-09 21:19:59,230 INFO     Training average positive_sample_loss at step 69400: 0.040379\n",
      "2023-12-09 21:19:59,230 INFO     Training average negative_sample_loss at step 69400: 0.016168\n",
      "2023-12-09 21:19:59,230 INFO     Training average loss at step 69400: 0.028273\n",
      "2023-12-09 21:20:12,102 INFO     Training average positive_sample_loss at step 69500: 0.040704\n",
      "2023-12-09 21:20:12,102 INFO     Training average negative_sample_loss at step 69500: 0.016199\n",
      "2023-12-09 21:20:12,102 INFO     Training average loss at step 69500: 0.028452\n",
      "2023-12-09 21:20:26,112 INFO     Training average positive_sample_loss at step 69600: 0.040750\n",
      "2023-12-09 21:20:26,113 INFO     Training average negative_sample_loss at step 69600: 0.016045\n",
      "2023-12-09 21:20:26,113 INFO     Training average loss at step 69600: 0.028398\n",
      "2023-12-09 21:20:41,630 INFO     Training average positive_sample_loss at step 69700: 0.040980\n",
      "2023-12-09 21:20:41,630 INFO     Training average negative_sample_loss at step 69700: 0.016135\n",
      "2023-12-09 21:20:41,631 INFO     Training average loss at step 69700: 0.028558\n",
      "2023-12-09 21:20:57,097 INFO     Training average positive_sample_loss at step 69800: 0.040432\n",
      "2023-12-09 21:20:57,097 INFO     Training average negative_sample_loss at step 69800: 0.016120\n",
      "2023-12-09 21:20:57,097 INFO     Training average loss at step 69800: 0.028276\n",
      "2023-12-09 21:21:11,402 INFO     Training average positive_sample_loss at step 69900: 0.040457\n",
      "2023-12-09 21:21:11,403 INFO     Training average negative_sample_loss at step 69900: 0.015978\n",
      "2023-12-09 21:21:11,403 INFO     Training average loss at step 69900: 0.028217\n",
      "2023-12-09 21:21:33,768 INFO     Training average positive_sample_loss at step 70000: 0.040949\n",
      "2023-12-09 21:21:33,769 INFO     Training average negative_sample_loss at step 70000: 0.016166\n",
      "2023-12-09 21:21:33,769 INFO     Training average loss at step 70000: 0.028558\n",
      "2023-12-09 21:21:33,769 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 21:21:34,445 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 21:22:22,402 INFO     Valid MRR at step 70000: 0.482767\n",
      "2023-12-09 21:22:22,403 INFO     Valid MR at step 70000: 1759.896836\n",
      "2023-12-09 21:22:22,403 INFO     Valid HITS@1 at step 70000: 0.439519\n",
      "2023-12-09 21:22:22,403 INFO     Valid HITS@3 at step 70000: 0.493243\n",
      "2023-12-09 21:22:22,403 INFO     Valid HITS@10 at step 70000: 0.570369\n",
      "2023-12-09 21:22:38,713 INFO     Training average positive_sample_loss at step 70100: 0.040550\n",
      "2023-12-09 21:22:38,713 INFO     Training average negative_sample_loss at step 70100: 0.016020\n",
      "2023-12-09 21:22:38,713 INFO     Training average loss at step 70100: 0.028285\n",
      "2023-12-09 21:22:51,289 INFO     Training average positive_sample_loss at step 70200: 0.040378\n",
      "2023-12-09 21:22:51,289 INFO     Training average negative_sample_loss at step 70200: 0.016011\n",
      "2023-12-09 21:22:51,290 INFO     Training average loss at step 70200: 0.028194\n",
      "2023-12-09 21:23:05,598 INFO     Training average positive_sample_loss at step 70300: 0.041022\n",
      "2023-12-09 21:23:05,598 INFO     Training average negative_sample_loss at step 70300: 0.016079\n",
      "2023-12-09 21:23:05,598 INFO     Training average loss at step 70300: 0.028550\n",
      "2023-12-09 21:23:21,987 INFO     Training average positive_sample_loss at step 70400: 0.040649\n",
      "2023-12-09 21:23:21,987 INFO     Training average negative_sample_loss at step 70400: 0.016070\n",
      "2023-12-09 21:23:21,987 INFO     Training average loss at step 70400: 0.028359\n",
      "2023-12-09 21:23:36,384 INFO     Training average positive_sample_loss at step 70500: 0.040528\n",
      "2023-12-09 21:23:36,384 INFO     Training average negative_sample_loss at step 70500: 0.016055\n",
      "2023-12-09 21:23:36,384 INFO     Training average loss at step 70500: 0.028292\n",
      "2023-12-09 21:23:51,770 INFO     Training average positive_sample_loss at step 70600: 0.040691\n",
      "2023-12-09 21:23:51,770 INFO     Training average negative_sample_loss at step 70600: 0.016046\n",
      "2023-12-09 21:23:51,770 INFO     Training average loss at step 70600: 0.028369\n",
      "2023-12-09 21:24:04,555 INFO     Training average positive_sample_loss at step 70700: 0.040793\n",
      "2023-12-09 21:24:04,556 INFO     Training average negative_sample_loss at step 70700: 0.016095\n",
      "2023-12-09 21:24:04,556 INFO     Training average loss at step 70700: 0.028444\n",
      "2023-12-09 21:24:19,065 INFO     Training average positive_sample_loss at step 70800: 0.040349\n",
      "2023-12-09 21:24:19,065 INFO     Training average negative_sample_loss at step 70800: 0.016178\n",
      "2023-12-09 21:24:19,065 INFO     Training average loss at step 70800: 0.028263\n",
      "2023-12-09 21:24:32,470 INFO     Training average positive_sample_loss at step 70900: 0.040602\n",
      "2023-12-09 21:24:32,470 INFO     Training average negative_sample_loss at step 70900: 0.016120\n",
      "2023-12-09 21:24:32,470 INFO     Training average loss at step 70900: 0.028361\n",
      "2023-12-09 21:24:45,530 INFO     Training average positive_sample_loss at step 71000: 0.040827\n",
      "2023-12-09 21:24:45,531 INFO     Training average negative_sample_loss at step 71000: 0.015989\n",
      "2023-12-09 21:24:45,531 INFO     Training average loss at step 71000: 0.028408\n",
      "2023-12-09 21:25:00,354 INFO     Training average positive_sample_loss at step 71100: 0.040581\n",
      "2023-12-09 21:25:00,355 INFO     Training average negative_sample_loss at step 71100: 0.016212\n",
      "2023-12-09 21:25:00,355 INFO     Training average loss at step 71100: 0.028397\n",
      "2023-12-09 21:25:13,613 INFO     Training average positive_sample_loss at step 71200: 0.040393\n",
      "2023-12-09 21:25:13,613 INFO     Training average negative_sample_loss at step 71200: 0.016039\n",
      "2023-12-09 21:25:13,613 INFO     Training average loss at step 71200: 0.028216\n",
      "2023-12-09 21:25:26,935 INFO     Training average positive_sample_loss at step 71300: 0.040809\n",
      "2023-12-09 21:25:26,935 INFO     Training average negative_sample_loss at step 71300: 0.015962\n",
      "2023-12-09 21:25:26,935 INFO     Training average loss at step 71300: 0.028385\n",
      "2023-12-09 21:25:38,489 INFO     Training average positive_sample_loss at step 71400: 0.041014\n",
      "2023-12-09 21:25:38,490 INFO     Training average negative_sample_loss at step 71400: 0.016190\n",
      "2023-12-09 21:25:38,490 INFO     Training average loss at step 71400: 0.028602\n",
      "2023-12-09 21:25:52,387 INFO     Training average positive_sample_loss at step 71500: 0.040523\n",
      "2023-12-09 21:25:52,388 INFO     Training average negative_sample_loss at step 71500: 0.016082\n",
      "2023-12-09 21:25:52,388 INFO     Training average loss at step 71500: 0.028303\n",
      "2023-12-09 21:26:05,767 INFO     Training average positive_sample_loss at step 71600: 0.040497\n",
      "2023-12-09 21:26:05,767 INFO     Training average negative_sample_loss at step 71600: 0.016049\n",
      "2023-12-09 21:26:05,767 INFO     Training average loss at step 71600: 0.028273\n",
      "2023-12-09 21:26:18,919 INFO     Training average positive_sample_loss at step 71700: 0.040809\n",
      "2023-12-09 21:26:18,919 INFO     Training average negative_sample_loss at step 71700: 0.016052\n",
      "2023-12-09 21:26:18,919 INFO     Training average loss at step 71700: 0.028430\n",
      "2023-12-09 21:26:33,935 INFO     Training average positive_sample_loss at step 71800: 0.040398\n",
      "2023-12-09 21:26:33,935 INFO     Training average negative_sample_loss at step 71800: 0.016112\n",
      "2023-12-09 21:26:33,935 INFO     Training average loss at step 71800: 0.028255\n",
      "2023-12-09 21:26:46,831 INFO     Training average positive_sample_loss at step 71900: 0.040708\n",
      "2023-12-09 21:26:46,831 INFO     Training average negative_sample_loss at step 71900: 0.016112\n",
      "2023-12-09 21:26:46,831 INFO     Training average loss at step 71900: 0.028410\n",
      "2023-12-09 21:26:57,946 INFO     Training average positive_sample_loss at step 72000: 0.040702\n",
      "2023-12-09 21:26:57,946 INFO     Training average negative_sample_loss at step 72000: 0.016038\n",
      "2023-12-09 21:26:57,946 INFO     Training average loss at step 72000: 0.028370\n",
      "2023-12-09 21:27:13,261 INFO     Training average positive_sample_loss at step 72100: 0.040663\n",
      "2023-12-09 21:27:13,262 INFO     Training average negative_sample_loss at step 72100: 0.015932\n",
      "2023-12-09 21:27:13,262 INFO     Training average loss at step 72100: 0.028298\n",
      "2023-12-09 21:27:25,742 INFO     Training average positive_sample_loss at step 72200: 0.040223\n",
      "2023-12-09 21:27:25,742 INFO     Training average negative_sample_loss at step 72200: 0.016065\n",
      "2023-12-09 21:27:25,742 INFO     Training average loss at step 72200: 0.028144\n",
      "2023-12-09 21:27:38,618 INFO     Training average positive_sample_loss at step 72300: 0.040831\n",
      "2023-12-09 21:27:38,619 INFO     Training average negative_sample_loss at step 72300: 0.015977\n",
      "2023-12-09 21:27:38,619 INFO     Training average loss at step 72300: 0.028404\n",
      "2023-12-09 21:27:50,892 INFO     Training average positive_sample_loss at step 72400: 0.040859\n",
      "2023-12-09 21:27:50,893 INFO     Training average negative_sample_loss at step 72400: 0.015977\n",
      "2023-12-09 21:27:50,893 INFO     Training average loss at step 72400: 0.028418\n",
      "2023-12-09 21:28:06,023 INFO     Training average positive_sample_loss at step 72500: 0.040658\n",
      "2023-12-09 21:28:06,023 INFO     Training average negative_sample_loss at step 72500: 0.016039\n",
      "2023-12-09 21:28:06,023 INFO     Training average loss at step 72500: 0.028348\n",
      "2023-12-09 21:28:16,624 INFO     Training average positive_sample_loss at step 72600: 0.040534\n",
      "2023-12-09 21:28:16,624 INFO     Training average negative_sample_loss at step 72600: 0.016053\n",
      "2023-12-09 21:28:16,624 INFO     Training average loss at step 72600: 0.028293\n",
      "2023-12-09 21:28:28,727 INFO     Training average positive_sample_loss at step 72700: 0.040566\n",
      "2023-12-09 21:28:28,727 INFO     Training average negative_sample_loss at step 72700: 0.016109\n",
      "2023-12-09 21:28:28,727 INFO     Training average loss at step 72700: 0.028337\n",
      "2023-12-09 21:28:42,616 INFO     Training average positive_sample_loss at step 72800: 0.040592\n",
      "2023-12-09 21:28:42,617 INFO     Training average negative_sample_loss at step 72800: 0.015908\n",
      "2023-12-09 21:28:42,617 INFO     Training average loss at step 72800: 0.028250\n",
      "2023-12-09 21:28:55,917 INFO     Training average positive_sample_loss at step 72900: 0.040547\n",
      "2023-12-09 21:28:55,917 INFO     Training average negative_sample_loss at step 72900: 0.016176\n",
      "2023-12-09 21:28:55,917 INFO     Training average loss at step 72900: 0.028362\n",
      "2023-12-09 21:29:09,096 INFO     Training average positive_sample_loss at step 73000: 0.040695\n",
      "2023-12-09 21:29:09,096 INFO     Training average negative_sample_loss at step 73000: 0.016038\n",
      "2023-12-09 21:29:09,096 INFO     Training average loss at step 73000: 0.028367\n",
      "2023-12-09 21:29:22,938 INFO     Training average positive_sample_loss at step 73100: 0.040854\n",
      "2023-12-09 21:29:22,938 INFO     Training average negative_sample_loss at step 73100: 0.016159\n",
      "2023-12-09 21:29:22,938 INFO     Training average loss at step 73100: 0.028507\n",
      "2023-12-09 21:29:35,868 INFO     Training average positive_sample_loss at step 73200: 0.040381\n",
      "2023-12-09 21:29:35,869 INFO     Training average negative_sample_loss at step 73200: 0.016032\n",
      "2023-12-09 21:29:35,869 INFO     Training average loss at step 73200: 0.028206\n",
      "2023-12-09 21:29:48,960 INFO     Training average positive_sample_loss at step 73300: 0.040629\n",
      "2023-12-09 21:29:48,960 INFO     Training average negative_sample_loss at step 73300: 0.016042\n",
      "2023-12-09 21:29:48,960 INFO     Training average loss at step 73300: 0.028335\n",
      "2023-12-09 21:30:01,669 INFO     Training average positive_sample_loss at step 73400: 0.040765\n",
      "2023-12-09 21:30:01,669 INFO     Training average negative_sample_loss at step 73400: 0.016028\n",
      "2023-12-09 21:30:01,669 INFO     Training average loss at step 73400: 0.028397\n",
      "2023-12-09 21:30:16,093 INFO     Training average positive_sample_loss at step 73500: 0.040484\n",
      "2023-12-09 21:30:16,093 INFO     Training average negative_sample_loss at step 73500: 0.016031\n",
      "2023-12-09 21:30:16,093 INFO     Training average loss at step 73500: 0.028258\n",
      "2023-12-09 21:30:28,890 INFO     Training average positive_sample_loss at step 73600: 0.040493\n",
      "2023-12-09 21:30:28,891 INFO     Training average negative_sample_loss at step 73600: 0.016128\n",
      "2023-12-09 21:30:28,891 INFO     Training average loss at step 73600: 0.028311\n",
      "2023-12-09 21:30:41,979 INFO     Training average positive_sample_loss at step 73700: 0.040683\n",
      "2023-12-09 21:30:41,980 INFO     Training average negative_sample_loss at step 73700: 0.016035\n",
      "2023-12-09 21:30:41,980 INFO     Training average loss at step 73700: 0.028359\n",
      "2023-12-09 21:30:54,825 INFO     Training average positive_sample_loss at step 73800: 0.040770\n",
      "2023-12-09 21:30:54,825 INFO     Training average negative_sample_loss at step 73800: 0.016025\n",
      "2023-12-09 21:30:54,825 INFO     Training average loss at step 73800: 0.028398\n",
      "2023-12-09 21:31:07,724 INFO     Training average positive_sample_loss at step 73900: 0.040454\n",
      "2023-12-09 21:31:07,725 INFO     Training average negative_sample_loss at step 73900: 0.015958\n",
      "2023-12-09 21:31:07,725 INFO     Training average loss at step 73900: 0.028206\n",
      "2023-12-09 21:31:20,110 INFO     Training average positive_sample_loss at step 74000: 0.040545\n",
      "2023-12-09 21:31:20,110 INFO     Training average negative_sample_loss at step 74000: 0.016035\n",
      "2023-12-09 21:31:20,110 INFO     Training average loss at step 74000: 0.028290\n",
      "2023-12-09 21:31:33,396 INFO     Training average positive_sample_loss at step 74100: 0.040723\n",
      "2023-12-09 21:31:33,396 INFO     Training average negative_sample_loss at step 74100: 0.016032\n",
      "2023-12-09 21:31:33,396 INFO     Training average loss at step 74100: 0.028378\n",
      "2023-12-09 21:31:47,746 INFO     Training average positive_sample_loss at step 74200: 0.040464\n",
      "2023-12-09 21:31:47,747 INFO     Training average negative_sample_loss at step 74200: 0.016019\n",
      "2023-12-09 21:31:47,747 INFO     Training average loss at step 74200: 0.028241\n",
      "2023-12-09 21:32:01,225 INFO     Training average positive_sample_loss at step 74300: 0.040408\n",
      "2023-12-09 21:32:01,225 INFO     Training average negative_sample_loss at step 74300: 0.016122\n",
      "2023-12-09 21:32:01,225 INFO     Training average loss at step 74300: 0.028265\n",
      "2023-12-09 21:32:12,075 INFO     Training average positive_sample_loss at step 74400: 0.040786\n",
      "2023-12-09 21:32:12,075 INFO     Training average negative_sample_loss at step 74400: 0.016095\n",
      "2023-12-09 21:32:12,075 INFO     Training average loss at step 74400: 0.028441\n",
      "2023-12-09 21:32:26,312 INFO     Training average positive_sample_loss at step 74500: 0.040683\n",
      "2023-12-09 21:32:26,313 INFO     Training average negative_sample_loss at step 74500: 0.016067\n",
      "2023-12-09 21:32:26,313 INFO     Training average loss at step 74500: 0.028375\n",
      "2023-12-09 21:32:39,599 INFO     Training average positive_sample_loss at step 74600: 0.040597\n",
      "2023-12-09 21:32:39,599 INFO     Training average negative_sample_loss at step 74600: 0.015992\n",
      "2023-12-09 21:32:39,599 INFO     Training average loss at step 74600: 0.028295\n",
      "2023-12-09 21:32:52,877 INFO     Training average positive_sample_loss at step 74700: 0.040366\n",
      "2023-12-09 21:32:52,878 INFO     Training average negative_sample_loss at step 74700: 0.016092\n",
      "2023-12-09 21:32:52,878 INFO     Training average loss at step 74700: 0.028229\n",
      "2023-12-09 21:33:06,224 INFO     Training average positive_sample_loss at step 74800: 0.040991\n",
      "2023-12-09 21:33:06,224 INFO     Training average negative_sample_loss at step 74800: 0.016024\n",
      "2023-12-09 21:33:06,224 INFO     Training average loss at step 74800: 0.028508\n",
      "2023-12-09 21:33:18,549 INFO     Training average positive_sample_loss at step 74900: 0.040341\n",
      "2023-12-09 21:33:18,550 INFO     Training average negative_sample_loss at step 74900: 0.015983\n",
      "2023-12-09 21:33:18,550 INFO     Training average loss at step 74900: 0.028162\n",
      "2023-12-09 21:33:31,730 INFO     Training average positive_sample_loss at step 75000: 0.040825\n",
      "2023-12-09 21:33:31,730 INFO     Training average negative_sample_loss at step 75000: 0.016022\n",
      "2023-12-09 21:33:31,731 INFO     Training average loss at step 75000: 0.028423\n",
      "2023-12-09 21:33:42,406 INFO     Training average positive_sample_loss at step 75100: 0.040620\n",
      "2023-12-09 21:33:42,407 INFO     Training average negative_sample_loss at step 75100: 0.015958\n",
      "2023-12-09 21:33:42,407 INFO     Training average loss at step 75100: 0.028289\n",
      "2023-12-09 21:33:57,095 INFO     Training average positive_sample_loss at step 75200: 0.040387\n",
      "2023-12-09 21:33:57,095 INFO     Training average negative_sample_loss at step 75200: 0.016032\n",
      "2023-12-09 21:33:57,095 INFO     Training average loss at step 75200: 0.028209\n",
      "2023-12-09 21:34:10,103 INFO     Training average positive_sample_loss at step 75300: 0.040379\n",
      "2023-12-09 21:34:10,104 INFO     Training average negative_sample_loss at step 75300: 0.016024\n",
      "2023-12-09 21:34:10,104 INFO     Training average loss at step 75300: 0.028201\n",
      "2023-12-09 21:34:23,247 INFO     Training average positive_sample_loss at step 75400: 0.040708\n",
      "2023-12-09 21:34:23,248 INFO     Training average negative_sample_loss at step 75400: 0.015990\n",
      "2023-12-09 21:34:23,248 INFO     Training average loss at step 75400: 0.028349\n",
      "2023-12-09 21:34:38,348 INFO     Training average positive_sample_loss at step 75500: 0.040802\n",
      "2023-12-09 21:34:38,348 INFO     Training average negative_sample_loss at step 75500: 0.015961\n",
      "2023-12-09 21:34:38,349 INFO     Training average loss at step 75500: 0.028381\n",
      "2023-12-09 21:34:51,800 INFO     Training average positive_sample_loss at step 75600: 0.040354\n",
      "2023-12-09 21:34:51,800 INFO     Training average negative_sample_loss at step 75600: 0.015989\n",
      "2023-12-09 21:34:51,800 INFO     Training average loss at step 75600: 0.028171\n",
      "2023-12-09 21:35:02,227 INFO     Training average positive_sample_loss at step 75700: 0.040617\n",
      "2023-12-09 21:35:02,227 INFO     Training average negative_sample_loss at step 75700: 0.016226\n",
      "2023-12-09 21:35:02,227 INFO     Training average loss at step 75700: 0.028421\n",
      "2023-12-09 21:35:15,692 INFO     Training average positive_sample_loss at step 75800: 0.040734\n",
      "2023-12-09 21:35:15,693 INFO     Training average negative_sample_loss at step 75800: 0.015946\n",
      "2023-12-09 21:35:15,693 INFO     Training average loss at step 75800: 0.028340\n",
      "2023-12-09 21:35:30,540 INFO     Training average positive_sample_loss at step 75900: 0.040350\n",
      "2023-12-09 21:35:30,540 INFO     Training average negative_sample_loss at step 75900: 0.016062\n",
      "2023-12-09 21:35:30,540 INFO     Training average loss at step 75900: 0.028206\n",
      "2023-12-09 21:35:43,434 INFO     Training average positive_sample_loss at step 76000: 0.040651\n",
      "2023-12-09 21:35:43,435 INFO     Training average negative_sample_loss at step 76000: 0.016058\n",
      "2023-12-09 21:35:43,435 INFO     Training average loss at step 76000: 0.028354\n",
      "2023-12-09 21:35:55,556 INFO     Training average positive_sample_loss at step 76100: 0.040625\n",
      "2023-12-09 21:35:55,557 INFO     Training average negative_sample_loss at step 76100: 0.015980\n",
      "2023-12-09 21:35:55,557 INFO     Training average loss at step 76100: 0.028302\n",
      "2023-12-09 21:36:11,169 INFO     Training average positive_sample_loss at step 76200: 0.040458\n",
      "2023-12-09 21:36:11,170 INFO     Training average negative_sample_loss at step 76200: 0.016088\n",
      "2023-12-09 21:36:11,170 INFO     Training average loss at step 76200: 0.028273\n",
      "2023-12-09 21:36:20,712 INFO     Training average positive_sample_loss at step 76300: 0.040468\n",
      "2023-12-09 21:36:20,712 INFO     Training average negative_sample_loss at step 76300: 0.016023\n",
      "2023-12-09 21:36:20,712 INFO     Training average loss at step 76300: 0.028245\n",
      "2023-12-09 21:36:33,810 INFO     Training average positive_sample_loss at step 76400: 0.040623\n",
      "2023-12-09 21:36:33,811 INFO     Training average negative_sample_loss at step 76400: 0.016096\n",
      "2023-12-09 21:36:33,811 INFO     Training average loss at step 76400: 0.028359\n",
      "2023-12-09 21:36:48,297 INFO     Training average positive_sample_loss at step 76500: 0.040924\n",
      "2023-12-09 21:36:48,297 INFO     Training average negative_sample_loss at step 76500: 0.015928\n",
      "2023-12-09 21:36:48,297 INFO     Training average loss at step 76500: 0.028426\n",
      "2023-12-09 21:37:01,709 INFO     Training average positive_sample_loss at step 76600: 0.040523\n",
      "2023-12-09 21:37:01,710 INFO     Training average negative_sample_loss at step 76600: 0.016015\n",
      "2023-12-09 21:37:01,710 INFO     Training average loss at step 76600: 0.028269\n",
      "2023-12-09 21:37:14,712 INFO     Training average positive_sample_loss at step 76700: 0.040387\n",
      "2023-12-09 21:37:14,712 INFO     Training average negative_sample_loss at step 76700: 0.015846\n",
      "2023-12-09 21:37:14,712 INFO     Training average loss at step 76700: 0.028116\n",
      "2023-12-09 21:37:28,331 INFO     Training average positive_sample_loss at step 76800: 0.040621\n",
      "2023-12-09 21:37:28,331 INFO     Training average negative_sample_loss at step 76800: 0.016037\n",
      "2023-12-09 21:37:28,331 INFO     Training average loss at step 76800: 0.028329\n",
      "2023-12-09 21:37:43,828 INFO     Training average positive_sample_loss at step 76900: 0.040562\n",
      "2023-12-09 21:37:43,828 INFO     Training average negative_sample_loss at step 76900: 0.016132\n",
      "2023-12-09 21:37:43,829 INFO     Training average loss at step 76900: 0.028347\n",
      "2023-12-09 21:37:57,440 INFO     Training average positive_sample_loss at step 77000: 0.040461\n",
      "2023-12-09 21:37:57,441 INFO     Training average negative_sample_loss at step 77000: 0.016058\n",
      "2023-12-09 21:37:57,441 INFO     Training average loss at step 77000: 0.028259\n",
      "2023-12-09 21:38:09,410 INFO     Training average positive_sample_loss at step 77100: 0.040741\n",
      "2023-12-09 21:38:09,411 INFO     Training average negative_sample_loss at step 77100: 0.016079\n",
      "2023-12-09 21:38:09,411 INFO     Training average loss at step 77100: 0.028410\n",
      "2023-12-09 21:38:22,516 INFO     Training average positive_sample_loss at step 77200: 0.040442\n",
      "2023-12-09 21:38:23,286 INFO     Training average negative_sample_loss at step 77200: 0.015907\n",
      "2023-12-09 21:38:23,286 INFO     Training average loss at step 77200: 0.028174\n",
      "2023-12-09 21:38:34,499 INFO     Training average positive_sample_loss at step 77300: 0.040383\n",
      "2023-12-09 21:38:34,500 INFO     Training average negative_sample_loss at step 77300: 0.015928\n",
      "2023-12-09 21:38:34,500 INFO     Training average loss at step 77300: 0.028156\n",
      "2023-12-09 21:38:44,464 INFO     Training average positive_sample_loss at step 77400: 0.040472\n",
      "2023-12-09 21:38:44,465 INFO     Training average negative_sample_loss at step 77400: 0.015961\n",
      "2023-12-09 21:38:44,465 INFO     Training average loss at step 77400: 0.028217\n",
      "2023-12-09 21:38:55,274 INFO     Training average positive_sample_loss at step 77500: 0.040948\n",
      "2023-12-09 21:38:55,274 INFO     Training average negative_sample_loss at step 77500: 0.016006\n",
      "2023-12-09 21:38:55,274 INFO     Training average loss at step 77500: 0.028477\n",
      "2023-12-09 21:39:07,394 INFO     Training average positive_sample_loss at step 77600: 0.040207\n",
      "2023-12-09 21:39:07,395 INFO     Training average negative_sample_loss at step 77600: 0.015971\n",
      "2023-12-09 21:39:07,395 INFO     Training average loss at step 77600: 0.028089\n",
      "2023-12-09 21:39:18,117 INFO     Training average positive_sample_loss at step 77700: 0.040729\n",
      "2023-12-09 21:39:18,117 INFO     Training average negative_sample_loss at step 77700: 0.016071\n",
      "2023-12-09 21:39:18,117 INFO     Training average loss at step 77700: 0.028400\n",
      "2023-12-09 21:39:28,764 INFO     Training average positive_sample_loss at step 77800: 0.040620\n",
      "2023-12-09 21:39:28,764 INFO     Training average negative_sample_loss at step 77800: 0.015993\n",
      "2023-12-09 21:39:28,764 INFO     Training average loss at step 77800: 0.028306\n",
      "2023-12-09 21:39:43,937 INFO     Training average positive_sample_loss at step 77900: 0.040637\n",
      "2023-12-09 21:39:43,938 INFO     Training average negative_sample_loss at step 77900: 0.016087\n",
      "2023-12-09 21:39:43,938 INFO     Training average loss at step 77900: 0.028362\n",
      "2023-12-09 21:39:57,065 INFO     Training average positive_sample_loss at step 78000: 0.040434\n",
      "2023-12-09 21:39:57,066 INFO     Training average negative_sample_loss at step 78000: 0.015895\n",
      "2023-12-09 21:39:57,066 INFO     Training average loss at step 78000: 0.028165\n",
      "2023-12-09 21:40:10,691 INFO     Training average positive_sample_loss at step 78100: 0.040568\n",
      "2023-12-09 21:40:10,691 INFO     Training average negative_sample_loss at step 78100: 0.015991\n",
      "2023-12-09 21:40:10,691 INFO     Training average loss at step 78100: 0.028280\n",
      "2023-12-09 21:40:21,770 INFO     Training average positive_sample_loss at step 78200: 0.040712\n",
      "2023-12-09 21:40:21,770 INFO     Training average negative_sample_loss at step 78200: 0.016093\n",
      "2023-12-09 21:40:21,770 INFO     Training average loss at step 78200: 0.028403\n",
      "2023-12-09 21:40:36,159 INFO     Training average positive_sample_loss at step 78300: 0.040269\n",
      "2023-12-09 21:40:36,159 INFO     Training average negative_sample_loss at step 78300: 0.016007\n",
      "2023-12-09 21:40:36,159 INFO     Training average loss at step 78300: 0.028138\n",
      "2023-12-09 21:40:46,453 INFO     Training average positive_sample_loss at step 78400: 0.040510\n",
      "2023-12-09 21:40:46,453 INFO     Training average negative_sample_loss at step 78400: 0.015813\n",
      "2023-12-09 21:40:46,453 INFO     Training average loss at step 78400: 0.028162\n",
      "2023-12-09 21:40:59,314 INFO     Training average positive_sample_loss at step 78500: 0.040768\n",
      "2023-12-09 21:40:59,315 INFO     Training average negative_sample_loss at step 78500: 0.016004\n",
      "2023-12-09 21:40:59,315 INFO     Training average loss at step 78500: 0.028386\n",
      "2023-12-09 21:41:12,856 INFO     Training average positive_sample_loss at step 78600: 0.040535\n",
      "2023-12-09 21:41:12,857 INFO     Training average negative_sample_loss at step 78600: 0.016078\n",
      "2023-12-09 21:41:12,857 INFO     Training average loss at step 78600: 0.028307\n",
      "2023-12-09 21:41:26,203 INFO     Training average positive_sample_loss at step 78700: 0.040669\n",
      "2023-12-09 21:41:26,203 INFO     Training average negative_sample_loss at step 78700: 0.016082\n",
      "2023-12-09 21:41:26,204 INFO     Training average loss at step 78700: 0.028375\n",
      "2023-12-09 21:41:37,862 INFO     Training average positive_sample_loss at step 78800: 0.040324\n",
      "2023-12-09 21:41:37,862 INFO     Training average negative_sample_loss at step 78800: 0.015839\n",
      "2023-12-09 21:41:37,862 INFO     Training average loss at step 78800: 0.028081\n",
      "2023-12-09 21:41:52,622 INFO     Training average positive_sample_loss at step 78900: 0.040699\n",
      "2023-12-09 21:41:52,623 INFO     Training average negative_sample_loss at step 78900: 0.016003\n",
      "2023-12-09 21:41:52,623 INFO     Training average loss at step 78900: 0.028351\n",
      "2023-12-09 21:42:05,452 INFO     Training average positive_sample_loss at step 79000: 0.040165\n",
      "2023-12-09 21:42:05,452 INFO     Training average negative_sample_loss at step 79000: 0.016018\n",
      "2023-12-09 21:42:05,452 INFO     Training average loss at step 79000: 0.028091\n",
      "2023-12-09 21:42:18,777 INFO     Training average positive_sample_loss at step 79100: 0.040679\n",
      "2023-12-09 21:42:18,777 INFO     Training average negative_sample_loss at step 79100: 0.016086\n",
      "2023-12-09 21:42:18,777 INFO     Training average loss at step 79100: 0.028383\n",
      "2023-12-09 21:42:32,337 INFO     Training average positive_sample_loss at step 79200: 0.040625\n",
      "2023-12-09 21:42:32,337 INFO     Training average negative_sample_loss at step 79200: 0.015864\n",
      "2023-12-09 21:42:32,337 INFO     Training average loss at step 79200: 0.028244\n",
      "2023-12-09 21:42:46,507 INFO     Training average positive_sample_loss at step 79300: 0.040601\n",
      "2023-12-09 21:42:46,507 INFO     Training average negative_sample_loss at step 79300: 0.015999\n",
      "2023-12-09 21:42:46,507 INFO     Training average loss at step 79300: 0.028300\n",
      "2023-12-09 21:42:57,215 INFO     Training average positive_sample_loss at step 79400: 0.040399\n",
      "2023-12-09 21:42:57,216 INFO     Training average negative_sample_loss at step 79400: 0.016028\n",
      "2023-12-09 21:42:57,216 INFO     Training average loss at step 79400: 0.028213\n",
      "2023-12-09 21:43:10,044 INFO     Training average positive_sample_loss at step 79500: 0.040721\n",
      "2023-12-09 21:43:10,044 INFO     Training average negative_sample_loss at step 79500: 0.016017\n",
      "2023-12-09 21:43:10,044 INFO     Training average loss at step 79500: 0.028369\n",
      "2023-12-09 21:43:25,134 INFO     Training average positive_sample_loss at step 79600: 0.040363\n",
      "2023-12-09 21:43:25,134 INFO     Training average negative_sample_loss at step 79600: 0.015998\n",
      "2023-12-09 21:43:25,134 INFO     Training average loss at step 79600: 0.028180\n",
      "2023-12-09 21:43:38,535 INFO     Training average positive_sample_loss at step 79700: 0.040523\n",
      "2023-12-09 21:43:38,536 INFO     Training average negative_sample_loss at step 79700: 0.016016\n",
      "2023-12-09 21:43:38,536 INFO     Training average loss at step 79700: 0.028269\n",
      "2023-12-09 21:43:51,197 INFO     Training average positive_sample_loss at step 79800: 0.040591\n",
      "2023-12-09 21:43:51,197 INFO     Training average negative_sample_loss at step 79800: 0.015967\n",
      "2023-12-09 21:43:51,197 INFO     Training average loss at step 79800: 0.028279\n",
      "2023-12-09 21:44:05,044 INFO     Training average positive_sample_loss at step 79900: 0.040633\n",
      "2023-12-09 21:44:05,044 INFO     Training average negative_sample_loss at step 79900: 0.016010\n",
      "2023-12-09 21:44:05,044 INFO     Training average loss at step 79900: 0.028321\n",
      "2023-12-09 21:44:32,254 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 21:44:32,840 INFO     Evaluating the model... (0/760)\n",
      "2023-12-09 21:45:13,839 INFO     Valid MRR at step 79999: 0.482817\n",
      "2023-12-09 21:45:13,839 INFO     Valid MR at step 79999: 1753.423863\n",
      "2023-12-09 21:45:13,839 INFO     Valid HITS@1 at step 79999: 0.439519\n",
      "2023-12-09 21:45:13,839 INFO     Valid HITS@3 at step 79999: 0.494067\n",
      "2023-12-09 21:45:13,839 INFO     Valid HITS@10 at step 79999: 0.570699\n",
      "2023-12-09 21:45:13,839 INFO     Evaluating on Test Dataset...\n",
      "2023-12-09 21:45:14,388 INFO     Evaluating the model... (0/784)\n",
      "2023-12-09 21:45:53,439 INFO     Test MRR at step 79999: 0.479526\n",
      "2023-12-09 21:45:53,440 INFO     Test MR at step 79999: 1859.770900\n",
      "2023-12-09 21:45:53,440 INFO     Test HITS@1 at step 79999: 0.432514\n",
      "2023-12-09 21:45:53,440 INFO     Test HITS@3 at step 79999: 0.496809\n",
      "2023-12-09 21:45:53,440 INFO     Test HITS@10 at step 79999: 0.573229\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE wn18rr 0 0 512 1024 500 6.0 0.5 0.00005 80000 8 -de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con il metodo NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd KnowledgeGraphEmbedding_NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu118\n",
      "Start Training......\n",
      "2024-02-28 17:51:14,819 INFO     Model: RotatE\n",
      "2024-02-28 17:51:14,819 INFO     Data Path: data/wn18rr\n",
      "2024-02-28 17:51:14,819 INFO     #entity: 40943\n",
      "2024-02-28 17:51:14,819 INFO     #relation: 11\n",
      "2024-02-28 17:51:15,030 INFO     #train: 86835\n",
      "2024-02-28 17:51:15,055 INFO     #valid: 3034\n",
      "2024-02-28 17:51:15,080 INFO     #test: 3134\n",
      "2024-02-28 17:51:15,291 INFO     Model Parameter Configuration:\n",
      "2024-02-28 17:51:15,291 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2024-02-28 17:51:15,291 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2024-02-28 17:51:15,292 INFO     Parameter entity_embedding: torch.Size([40943, 1000]), require_grad = True\n",
      "2024-02-28 17:51:15,292 INFO     Parameter relation_embedding: torch.Size([11, 500]), require_grad = True\n",
      "2024-02-28 17:51:17,906 INFO     Ramdomly Initializing RotatE Model...\n",
      "2024-02-28 17:51:17,906 INFO     Start Training...\n",
      "2024-02-28 17:51:17,906 INFO     init_step = 0\n",
      "2024-02-28 17:51:17,906 INFO     batch_size = 512\n",
      "2024-02-28 17:51:17,906 INFO     negative_adversarial_sampling = 1\n",
      "2024-02-28 17:51:17,906 INFO     hidden_dim = 500\n",
      "2024-02-28 17:51:17,906 INFO     gamma = 6.000000\n",
      "2024-02-28 17:51:17,906 INFO     negative_adversarial_sampling = True\n",
      "2024-02-28 17:51:17,906 INFO     adversarial_temperature = 0.500000\n",
      "2024-02-28 17:51:17,906 INFO     learning_rate = 0\n",
      "2024-02-28 17:51:36,916 INFO     Training average positive_sample_loss at step 0: 2.441333\n",
      "2024-02-28 17:51:36,917 INFO     Training average negative_sample_loss at step 0: 0.093519\n",
      "2024-02-28 17:51:36,917 INFO     Training average loss at step 0: 1.267426\n",
      "2024-02-28 17:51:36,917 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-28 17:51:37,495 INFO     Evaluating the model... (0/760)\n",
      "2024-02-28 17:52:05,823 INFO     Valid MRR at step 0: 0.000306\n",
      "2024-02-28 17:52:05,824 INFO     Valid MR at step 0: 20148.986981\n",
      "2024-02-28 17:52:05,824 INFO     Valid HITS@1 at step 0: 0.000000\n",
      "2024-02-28 17:52:05,824 INFO     Valid HITS@3 at step 0: 0.000165\n",
      "2024-02-28 17:52:05,824 INFO     Valid HITS@10 at step 0: 0.000330\n",
      "2024-02-28 17:55:09,110 INFO     Training average positive_sample_loss at step 100: 2.781000\n",
      "2024-02-28 17:55:09,111 INFO     Training average negative_sample_loss at step 100: 0.070490\n",
      "2024-02-28 17:55:09,111 INFO     Training average loss at step 100: 1.425745\n",
      "2024-02-28 17:58:26,779 INFO     Training average positive_sample_loss at step 200: 2.582683\n",
      "2024-02-28 17:58:26,779 INFO     Training average negative_sample_loss at step 200: 0.093677\n",
      "2024-02-28 17:58:26,779 INFO     Training average loss at step 200: 1.338180\n",
      "2024-02-28 18:01:26,890 INFO     Training average positive_sample_loss at step 300: 2.190332\n",
      "2024-02-28 18:01:26,891 INFO     Training average negative_sample_loss at step 300: 0.135914\n",
      "2024-02-28 18:01:26,891 INFO     Training average loss at step 300: 1.163123\n",
      "2024-02-28 18:07:37,777 INFO     Training average positive_sample_loss at step 500: 1.351067\n",
      "2024-02-28 18:07:37,778 INFO     Training average negative_sample_loss at step 500: 0.240157\n",
      "2024-02-28 18:07:37,778 INFO     Training average loss at step 500: 0.795612\n",
      "2024-02-28 18:10:53,163 INFO     Training average positive_sample_loss at step 600: 1.174538\n",
      "2024-02-28 18:10:53,163 INFO     Training average negative_sample_loss at step 600: 0.281774\n",
      "2024-02-28 18:10:53,163 INFO     Training average loss at step 600: 0.728156\n",
      "2024-02-28 18:14:33,234 INFO     Training average positive_sample_loss at step 700: 0.996239\n",
      "2024-02-28 18:14:33,234 INFO     Training average negative_sample_loss at step 700: 0.316436\n",
      "2024-02-28 18:14:33,234 INFO     Training average loss at step 700: 0.656338\n",
      "2024-02-28 18:17:30,162 INFO     Training average positive_sample_loss at step 800: 0.784428\n",
      "2024-02-28 18:17:30,163 INFO     Training average negative_sample_loss at step 800: 0.342429\n",
      "2024-02-28 18:17:30,163 INFO     Training average loss at step 800: 0.563429\n",
      "2024-02-28 18:20:51,184 INFO     Training average positive_sample_loss at step 900: 0.726653\n",
      "2024-02-28 18:20:51,185 INFO     Training average negative_sample_loss at step 900: 0.353326\n",
      "2024-02-28 18:20:51,185 INFO     Training average loss at step 900: 0.539990\n",
      "2024-02-28 18:24:31,940 INFO     Training average positive_sample_loss at step 1000: 0.672865\n",
      "2024-02-28 18:24:31,940 INFO     Training average negative_sample_loss at step 1000: 0.361647\n",
      "2024-02-28 18:24:31,940 INFO     Training average loss at step 1000: 0.517256\n",
      "2024-02-28 18:28:03,786 INFO     Training average positive_sample_loss at step 1100: 0.558268\n",
      "2024-02-28 18:28:03,787 INFO     Training average negative_sample_loss at step 1100: 0.362028\n",
      "2024-02-28 18:28:03,787 INFO     Training average loss at step 1100: 0.460148\n",
      "2024-02-28 18:31:03,405 INFO     Training average positive_sample_loss at step 1200: 0.525330\n",
      "2024-02-28 18:31:03,406 INFO     Training average negative_sample_loss at step 1200: 0.356185\n",
      "2024-02-28 18:31:03,406 INFO     Training average loss at step 1200: 0.440758\n",
      "2024-02-28 18:34:17,449 INFO     Training average positive_sample_loss at step 1300: 0.509313\n",
      "2024-02-28 18:34:17,449 INFO     Training average negative_sample_loss at step 1300: 0.350276\n",
      "2024-02-28 18:34:17,449 INFO     Training average loss at step 1300: 0.429795\n",
      "2024-02-28 18:37:43,717 INFO     Training average positive_sample_loss at step 1400: 0.465365\n",
      "2024-02-28 18:37:43,717 INFO     Training average negative_sample_loss at step 1400: 0.342054\n",
      "2024-02-28 18:37:43,717 INFO     Training average loss at step 1400: 0.403710\n",
      "2024-02-28 18:40:51,426 INFO     Training average positive_sample_loss at step 1500: 0.423565\n",
      "2024-02-28 18:40:51,427 INFO     Training average negative_sample_loss at step 1500: 0.328880\n",
      "2024-02-28 18:40:51,427 INFO     Training average loss at step 1500: 0.376223\n",
      "2024-02-28 18:44:13,407 INFO     Training average positive_sample_loss at step 1600: 0.423126\n",
      "2024-02-28 18:44:13,407 INFO     Training average negative_sample_loss at step 1600: 0.318223\n",
      "2024-02-28 18:44:13,407 INFO     Training average loss at step 1600: 0.370674\n",
      "2024-02-28 18:47:47,211 INFO     Training average positive_sample_loss at step 1700: 0.414413\n",
      "2024-02-28 18:47:47,212 INFO     Training average negative_sample_loss at step 1700: 0.309339\n",
      "2024-02-28 18:47:47,212 INFO     Training average loss at step 1700: 0.361876\n",
      "2024-02-28 18:51:02,135 INFO     Training average positive_sample_loss at step 1800: 0.361376\n",
      "2024-02-28 18:51:02,136 INFO     Training average negative_sample_loss at step 1800: 0.295458\n",
      "2024-02-28 18:51:02,136 INFO     Training average loss at step 1800: 0.328417\n",
      "2024-02-28 18:54:13,841 INFO     Training average positive_sample_loss at step 1900: 0.366001\n",
      "2024-02-28 18:54:13,841 INFO     Training average negative_sample_loss at step 1900: 0.284013\n",
      "2024-02-28 18:54:13,841 INFO     Training average loss at step 1900: 0.325007\n",
      "2024-02-28 18:57:16,381 INFO     Training average positive_sample_loss at step 2000: 0.365086\n",
      "2024-02-28 18:57:16,382 INFO     Training average negative_sample_loss at step 2000: 0.274762\n",
      "2024-02-28 18:57:16,382 INFO     Training average loss at step 2000: 0.319924\n",
      "2024-02-28 19:00:17,830 INFO     Training average positive_sample_loss at step 2100: 0.334776\n",
      "2024-02-28 19:00:17,830 INFO     Training average negative_sample_loss at step 2100: 0.263768\n",
      "2024-02-28 19:00:17,830 INFO     Training average loss at step 2100: 0.299272\n",
      "2024-02-28 19:03:28,162 INFO     Training average positive_sample_loss at step 2200: 0.324140\n",
      "2024-02-28 19:03:28,162 INFO     Training average negative_sample_loss at step 2200: 0.252143\n",
      "2024-02-28 19:03:28,162 INFO     Training average loss at step 2200: 0.288141\n",
      "2024-02-28 19:06:42,656 INFO     Training average positive_sample_loss at step 2300: 0.327169\n",
      "2024-02-28 19:06:42,656 INFO     Training average negative_sample_loss at step 2300: 0.244050\n",
      "2024-02-28 19:06:42,656 INFO     Training average loss at step 2300: 0.285609\n",
      "2024-02-28 19:10:14,308 INFO     Training average positive_sample_loss at step 2400: 0.317610\n",
      "2024-02-28 19:10:14,309 INFO     Training average negative_sample_loss at step 2400: 0.236199\n",
      "2024-02-28 19:10:14,309 INFO     Training average loss at step 2400: 0.276904\n",
      "2024-02-28 19:13:11,823 INFO     Training average positive_sample_loss at step 2500: 0.290659\n",
      "2024-02-28 19:13:11,823 INFO     Training average negative_sample_loss at step 2500: 0.225223\n",
      "2024-02-28 19:13:11,823 INFO     Training average loss at step 2500: 0.257941\n",
      "2024-02-28 19:16:23,625 INFO     Training average positive_sample_loss at step 2600: 0.296808\n",
      "2024-02-28 19:16:23,625 INFO     Training average negative_sample_loss at step 2600: 0.217048\n",
      "2024-02-28 19:16:23,625 INFO     Training average loss at step 2600: 0.256928\n",
      "2024-02-28 19:19:35,542 INFO     Training average positive_sample_loss at step 2700: 0.297352\n",
      "2024-02-28 19:19:35,543 INFO     Training average negative_sample_loss at step 2700: 0.210960\n",
      "2024-02-28 19:19:35,543 INFO     Training average loss at step 2700: 0.254156\n",
      "2024-02-28 19:23:06,538 INFO     Training average positive_sample_loss at step 2800: 0.268709\n",
      "2024-02-28 19:23:06,539 INFO     Training average negative_sample_loss at step 2800: 0.202957\n",
      "2024-02-28 19:23:06,539 INFO     Training average loss at step 2800: 0.235833\n",
      "2024-02-28 19:26:12,559 INFO     Training average positive_sample_loss at step 2900: 0.269747\n",
      "2024-02-28 19:26:12,560 INFO     Training average negative_sample_loss at step 2900: 0.194863\n",
      "2024-02-28 19:26:12,560 INFO     Training average loss at step 2900: 0.232305\n",
      "2024-02-28 19:29:18,677 INFO     Training average positive_sample_loss at step 3000: 0.273019\n",
      "2024-02-28 19:29:18,678 INFO     Training average negative_sample_loss at step 3000: 0.188832\n",
      "2024-02-28 19:29:18,678 INFO     Training average loss at step 3000: 0.230925\n",
      "2024-02-28 19:32:36,976 INFO     Training average positive_sample_loss at step 3100: 0.260734\n",
      "2024-02-28 19:32:36,977 INFO     Training average negative_sample_loss at step 3100: 0.183316\n",
      "2024-02-28 19:32:36,977 INFO     Training average loss at step 3100: 0.222025\n",
      "2024-02-28 19:35:36,811 INFO     Training average positive_sample_loss at step 3200: 0.246389\n",
      "2024-02-28 19:35:36,811 INFO     Training average negative_sample_loss at step 3200: 0.176394\n",
      "2024-02-28 19:35:36,811 INFO     Training average loss at step 3200: 0.211392\n",
      "2024-02-28 19:38:56,667 INFO     Training average positive_sample_loss at step 3300: 0.251448\n",
      "2024-02-28 19:38:56,668 INFO     Training average negative_sample_loss at step 3300: 0.170776\n",
      "2024-02-28 19:38:56,668 INFO     Training average loss at step 3300: 0.211112\n",
      "2024-02-28 19:42:39,142 INFO     Training average positive_sample_loss at step 3400: 0.253535\n",
      "2024-02-28 19:42:39,143 INFO     Training average negative_sample_loss at step 3400: 0.167020\n",
      "2024-02-28 19:42:39,143 INFO     Training average loss at step 3400: 0.210277\n",
      "2024-02-28 19:45:53,925 INFO     Training average positive_sample_loss at step 3500: 0.225460\n",
      "2024-02-28 19:45:53,926 INFO     Training average negative_sample_loss at step 3500: 0.160401\n",
      "2024-02-28 19:45:53,926 INFO     Training average loss at step 3500: 0.192930\n",
      "2024-02-28 19:49:03,260 INFO     Training average positive_sample_loss at step 3600: 0.233321\n",
      "2024-02-28 19:49:03,261 INFO     Training average negative_sample_loss at step 3600: 0.155346\n",
      "2024-02-28 19:49:03,261 INFO     Training average loss at step 3600: 0.194334\n",
      "2024-02-28 19:52:48,329 INFO     Training average positive_sample_loss at step 3700: 0.235986\n",
      "2024-02-28 19:52:48,330 INFO     Training average negative_sample_loss at step 3700: 0.151977\n",
      "2024-02-28 19:52:48,330 INFO     Training average loss at step 3700: 0.193981\n",
      "2024-02-28 19:56:14,716 INFO     Training average positive_sample_loss at step 3800: 0.219551\n",
      "2024-02-28 19:56:14,717 INFO     Training average negative_sample_loss at step 3800: 0.147510\n",
      "2024-02-28 19:56:14,717 INFO     Training average loss at step 3800: 0.183531\n",
      "2024-02-28 19:59:28,745 INFO     Training average positive_sample_loss at step 3900: 0.217067\n",
      "2024-02-28 19:59:28,745 INFO     Training average negative_sample_loss at step 3900: 0.142741\n",
      "2024-02-28 19:59:28,746 INFO     Training average loss at step 3900: 0.179904\n",
      "2024-02-28 20:02:56,003 INFO     Training average positive_sample_loss at step 4000: 0.220277\n",
      "2024-02-28 20:02:56,003 INFO     Training average negative_sample_loss at step 4000: 0.138988\n",
      "2024-02-28 20:02:56,004 INFO     Training average loss at step 4000: 0.179633\n",
      "2024-02-28 20:06:24,883 INFO     Training average positive_sample_loss at step 4100: 0.214835\n",
      "2024-02-28 20:06:24,883 INFO     Training average negative_sample_loss at step 4100: 0.136575\n",
      "2024-02-28 20:06:24,883 INFO     Training average loss at step 4100: 0.175705\n",
      "2024-02-28 20:09:35,856 INFO     Training average positive_sample_loss at step 4200: 0.200406\n",
      "2024-02-28 20:09:35,856 INFO     Training average negative_sample_loss at step 4200: 0.130768\n",
      "2024-02-28 20:09:35,856 INFO     Training average loss at step 4200: 0.165587\n",
      "2024-02-28 20:12:32,875 INFO     Training average positive_sample_loss at step 4300: 0.205375\n",
      "2024-02-28 20:12:32,875 INFO     Training average negative_sample_loss at step 4300: 0.127938\n",
      "2024-02-28 20:12:32,875 INFO     Training average loss at step 4300: 0.166657\n",
      "2024-02-28 20:16:09,747 INFO     Training average positive_sample_loss at step 4400: 0.209890\n",
      "2024-02-28 20:16:09,747 INFO     Training average negative_sample_loss at step 4400: 0.126115\n",
      "2024-02-28 20:16:09,747 INFO     Training average loss at step 4400: 0.168003\n",
      "2024-02-28 20:19:34,482 INFO     Training average positive_sample_loss at step 4500: 0.190162\n",
      "2024-02-28 20:19:34,482 INFO     Training average negative_sample_loss at step 4500: 0.122571\n",
      "2024-02-28 20:19:34,482 INFO     Training average loss at step 4500: 0.156366\n",
      "2024-02-28 20:22:41,775 INFO     Training average positive_sample_loss at step 4600: 0.193447\n",
      "2024-02-28 20:22:41,776 INFO     Training average negative_sample_loss at step 4600: 0.118580\n",
      "2024-02-28 20:22:41,776 INFO     Training average loss at step 4600: 0.156014\n",
      "2024-02-28 20:25:36,272 INFO     Training average positive_sample_loss at step 4700: 0.197426\n",
      "2024-02-28 20:25:36,272 INFO     Training average negative_sample_loss at step 4700: 0.116803\n",
      "2024-02-28 20:25:36,272 INFO     Training average loss at step 4700: 0.157114\n",
      "2024-02-28 20:29:08,079 INFO     Training average positive_sample_loss at step 4800: 0.188697\n",
      "2024-02-28 20:29:08,079 INFO     Training average negative_sample_loss at step 4800: 0.114422\n",
      "2024-02-28 20:29:08,079 INFO     Training average loss at step 4800: 0.151560\n",
      "2024-02-28 20:32:16,518 INFO     Training average positive_sample_loss at step 4900: 0.180386\n",
      "2024-02-28 20:32:16,518 INFO     Training average negative_sample_loss at step 4900: 0.110476\n",
      "2024-02-28 20:32:16,518 INFO     Training average loss at step 4900: 0.145431\n",
      "2024-02-28 20:35:33,990 INFO     Training average positive_sample_loss at step 5000: 0.185808\n",
      "2024-02-28 20:35:33,990 INFO     Training average negative_sample_loss at step 5000: 0.108721\n",
      "2024-02-28 20:35:33,990 INFO     Training average loss at step 5000: 0.147265\n",
      "2024-02-28 20:38:49,524 INFO     Training average positive_sample_loss at step 5100: 0.187608\n",
      "2024-02-28 20:38:49,524 INFO     Training average negative_sample_loss at step 5100: 0.107243\n",
      "2024-02-28 20:38:49,524 INFO     Training average loss at step 5100: 0.147426\n",
      "2024-02-28 20:41:58,294 INFO     Training average positive_sample_loss at step 5200: 0.169227\n",
      "2024-02-28 20:41:58,295 INFO     Training average negative_sample_loss at step 5200: 0.103716\n",
      "2024-02-28 20:41:58,295 INFO     Training average loss at step 5200: 0.136471\n",
      "2024-02-28 20:45:16,002 INFO     Training average positive_sample_loss at step 5300: 0.175673\n",
      "2024-02-28 20:45:16,003 INFO     Training average negative_sample_loss at step 5300: 0.101666\n",
      "2024-02-28 20:45:16,003 INFO     Training average loss at step 5300: 0.138669\n",
      "2024-02-28 20:48:40,229 INFO     Training average positive_sample_loss at step 5400: 0.178609\n",
      "2024-02-28 20:48:40,229 INFO     Training average negative_sample_loss at step 5400: 0.100059\n",
      "2024-02-28 20:48:40,230 INFO     Training average loss at step 5400: 0.139334\n",
      "2024-02-28 20:51:42,279 INFO     Training average positive_sample_loss at step 5500: 0.167309\n",
      "2024-02-28 20:51:42,279 INFO     Training average negative_sample_loss at step 5500: 0.098714\n",
      "2024-02-28 20:51:42,279 INFO     Training average loss at step 5500: 0.133011\n",
      "2024-02-28 20:54:54,116 INFO     Training average positive_sample_loss at step 5600: 0.165728\n",
      "2024-02-28 20:54:54,117 INFO     Training average negative_sample_loss at step 5600: 0.095192\n",
      "2024-02-28 20:54:54,117 INFO     Training average loss at step 5600: 0.130460\n",
      "2024-02-28 20:58:33,576 INFO     Training average positive_sample_loss at step 5700: 0.169779\n",
      "2024-02-28 20:58:33,577 INFO     Training average negative_sample_loss at step 5700: 0.094466\n",
      "2024-02-28 20:58:33,577 INFO     Training average loss at step 5700: 0.132122\n",
      "2024-02-28 21:02:20,668 INFO     Training average positive_sample_loss at step 5800: 0.167833\n",
      "2024-02-28 21:02:20,668 INFO     Training average negative_sample_loss at step 5800: 0.093191\n",
      "2024-02-28 21:02:20,668 INFO     Training average loss at step 5800: 0.130512\n",
      "2024-02-28 21:05:34,928 INFO     Training average positive_sample_loss at step 5900: 0.156328\n",
      "2024-02-28 21:05:34,928 INFO     Training average negative_sample_loss at step 5900: 0.090503\n",
      "2024-02-28 21:05:34,928 INFO     Training average loss at step 5900: 0.123416\n",
      "2024-02-28 21:08:48,684 INFO     Training average positive_sample_loss at step 6000: 0.162166\n",
      "2024-02-28 21:08:48,685 INFO     Training average negative_sample_loss at step 6000: 0.088890\n",
      "2024-02-28 21:08:48,685 INFO     Training average loss at step 6000: 0.125528\n",
      "2024-02-28 21:12:05,467 INFO     Training average positive_sample_loss at step 6100: 0.164282\n",
      "2024-02-28 21:12:05,468 INFO     Training average negative_sample_loss at step 6100: 0.088381\n",
      "2024-02-28 21:12:05,468 INFO     Training average loss at step 6100: 0.126331\n",
      "2024-02-28 21:14:59,817 INFO     Training average positive_sample_loss at step 6200: 0.150416\n",
      "2024-02-28 21:14:59,818 INFO     Training average negative_sample_loss at step 6200: 0.085826\n",
      "2024-02-28 21:14:59,818 INFO     Training average loss at step 6200: 0.118121\n",
      "2024-02-28 21:17:53,284 INFO     Training average positive_sample_loss at step 6300: 0.154947\n",
      "2024-02-28 21:17:53,285 INFO     Training average negative_sample_loss at step 6300: 0.084196\n",
      "2024-02-28 21:17:53,285 INFO     Training average loss at step 6300: 0.119572\n",
      "2024-02-28 21:21:07,032 INFO     Training average positive_sample_loss at step 6400: 0.157622\n",
      "2024-02-28 21:21:07,033 INFO     Training average negative_sample_loss at step 6400: 0.083793\n",
      "2024-02-28 21:21:07,033 INFO     Training average loss at step 6400: 0.120708\n",
      "2024-02-28 21:24:34,067 INFO     Training average positive_sample_loss at step 6500: 0.150948\n",
      "2024-02-28 21:24:34,068 INFO     Training average negative_sample_loss at step 6500: 0.082152\n",
      "2024-02-28 21:24:34,068 INFO     Training average loss at step 6500: 0.116550\n",
      "2024-02-28 21:27:43,842 INFO     Training average positive_sample_loss at step 6600: 0.146585\n",
      "2024-02-28 21:27:43,843 INFO     Training average negative_sample_loss at step 6600: 0.080291\n",
      "2024-02-28 21:27:43,843 INFO     Training average loss at step 6600: 0.113438\n",
      "2024-02-28 21:31:02,096 INFO     Training average positive_sample_loss at step 6700: 0.151066\n",
      "2024-02-28 21:31:02,096 INFO     Training average negative_sample_loss at step 6700: 0.079287\n",
      "2024-02-28 21:31:02,096 INFO     Training average loss at step 6700: 0.115177\n",
      "2024-02-28 21:34:44,502 INFO     Training average positive_sample_loss at step 6800: 0.152615\n",
      "2024-02-28 21:34:44,503 INFO     Training average negative_sample_loss at step 6800: 0.079248\n",
      "2024-02-28 21:34:44,503 INFO     Training average loss at step 6800: 0.115932\n",
      "2024-02-28 21:37:49,710 INFO     Training average positive_sample_loss at step 6900: 0.138368\n",
      "2024-02-28 21:37:49,711 INFO     Training average negative_sample_loss at step 6900: 0.076590\n",
      "2024-02-28 21:37:49,711 INFO     Training average loss at step 6900: 0.107479\n",
      "2024-02-28 21:40:55,653 INFO     Training average positive_sample_loss at step 7000: 0.144919\n",
      "2024-02-28 21:40:55,658 INFO     Training average negative_sample_loss at step 7000: 0.075631\n",
      "2024-02-28 21:40:55,658 INFO     Training average loss at step 7000: 0.110275\n",
      "2024-02-28 21:43:48,739 INFO     Training average positive_sample_loss at step 7100: 0.147074\n",
      "2024-02-28 21:43:48,739 INFO     Training average negative_sample_loss at step 7100: 0.075410\n",
      "2024-02-28 21:43:48,739 INFO     Training average loss at step 7100: 0.111242\n",
      "2024-02-28 21:47:12,087 INFO     Training average positive_sample_loss at step 7200: 0.139228\n",
      "2024-02-28 21:47:12,088 INFO     Training average negative_sample_loss at step 7200: 0.074452\n",
      "2024-02-28 21:47:12,088 INFO     Training average loss at step 7200: 0.106840\n",
      "2024-02-28 21:50:16,629 INFO     Training average positive_sample_loss at step 7300: 0.138228\n",
      "2024-02-28 21:50:16,629 INFO     Training average negative_sample_loss at step 7300: 0.072521\n",
      "2024-02-28 21:50:16,629 INFO     Training average loss at step 7300: 0.105374\n",
      "2024-02-28 21:53:16,929 INFO     Training average positive_sample_loss at step 7400: 0.142232\n",
      "2024-02-28 21:53:16,930 INFO     Training average negative_sample_loss at step 7400: 0.072139\n",
      "2024-02-28 21:53:16,930 INFO     Training average loss at step 7400: 0.107185\n",
      "2024-02-28 21:56:35,947 INFO     Training average positive_sample_loss at step 7500: 0.140738\n",
      "2024-02-28 21:56:35,948 INFO     Training average negative_sample_loss at step 7500: 0.071831\n",
      "2024-02-28 21:56:35,948 INFO     Training average loss at step 7500: 0.106284\n",
      "2024-02-28 21:59:26,342 INFO     Training average positive_sample_loss at step 7600: 0.131763\n",
      "2024-02-28 21:59:26,343 INFO     Training average negative_sample_loss at step 7600: 0.069914\n",
      "2024-02-28 21:59:26,343 INFO     Training average loss at step 7600: 0.100838\n",
      "2024-02-28 22:02:50,201 INFO     Training average positive_sample_loss at step 7700: 0.136478\n",
      "2024-02-28 22:02:50,202 INFO     Training average negative_sample_loss at step 7700: 0.069410\n",
      "2024-02-28 22:02:50,202 INFO     Training average loss at step 7700: 0.102944\n",
      "2024-02-28 22:05:53,555 INFO     Training average positive_sample_loss at step 7800: 0.139552\n",
      "2024-02-28 22:05:53,555 INFO     Training average negative_sample_loss at step 7800: 0.068976\n",
      "2024-02-28 22:05:53,555 INFO     Training average loss at step 7800: 0.104264\n",
      "2024-02-28 22:09:17,733 INFO     Training average positive_sample_loss at step 7900: 0.128801\n",
      "2024-02-28 22:09:17,734 INFO     Training average negative_sample_loss at step 7900: 0.067261\n",
      "2024-02-28 22:09:17,734 INFO     Training average loss at step 7900: 0.098031\n",
      "2024-02-28 22:12:11,548 INFO     Training average positive_sample_loss at step 8000: 0.131442\n",
      "2024-02-28 22:12:11,548 INFO     Training average negative_sample_loss at step 8000: 0.066363\n",
      "2024-02-28 22:12:11,548 INFO     Training average loss at step 8000: 0.098903\n",
      "2024-02-28 22:15:31,530 INFO     Training average positive_sample_loss at step 8100: 0.135760\n",
      "2024-02-28 22:15:31,530 INFO     Training average negative_sample_loss at step 8100: 0.066902\n",
      "2024-02-28 22:15:31,530 INFO     Training average loss at step 8100: 0.101331\n",
      "2024-02-28 22:19:04,328 INFO     Training average positive_sample_loss at step 8200: 0.130354\n",
      "2024-02-28 22:19:04,328 INFO     Training average negative_sample_loss at step 8200: 0.066189\n",
      "2024-02-28 22:19:04,328 INFO     Training average loss at step 8200: 0.098271\n",
      "2024-02-28 22:22:10,235 INFO     Training average positive_sample_loss at step 8300: 0.126541\n",
      "2024-02-28 22:22:10,235 INFO     Training average negative_sample_loss at step 8300: 0.064408\n",
      "2024-02-28 22:22:10,235 INFO     Training average loss at step 8300: 0.095475\n",
      "2024-02-28 22:25:19,875 INFO     Training average positive_sample_loss at step 8400: 0.130525\n",
      "2024-02-28 22:25:19,875 INFO     Training average negative_sample_loss at step 8400: 0.064305\n",
      "2024-02-28 22:25:19,876 INFO     Training average loss at step 8400: 0.097415\n",
      "2024-02-28 22:28:56,209 INFO     Training average positive_sample_loss at step 8500: 0.132309\n",
      "2024-02-28 22:28:56,209 INFO     Training average negative_sample_loss at step 8500: 0.064153\n",
      "2024-02-28 22:28:56,209 INFO     Training average loss at step 8500: 0.098231\n",
      "2024-02-28 22:31:49,868 INFO     Training average positive_sample_loss at step 8600: 0.121154\n",
      "2024-02-28 22:31:49,868 INFO     Training average negative_sample_loss at step 8600: 0.062459\n",
      "2024-02-28 22:31:49,868 INFO     Training average loss at step 8600: 0.091806\n",
      "2024-02-28 22:34:57,004 INFO     Training average positive_sample_loss at step 8700: 0.126544\n",
      "2024-02-28 22:34:57,004 INFO     Training average negative_sample_loss at step 8700: 0.062092\n",
      "2024-02-28 22:34:57,004 INFO     Training average loss at step 8700: 0.094318\n",
      "2024-02-28 22:38:32,382 INFO     Training average positive_sample_loss at step 8800: 0.128641\n",
      "2024-02-28 22:38:32,382 INFO     Training average negative_sample_loss at step 8800: 0.062012\n",
      "2024-02-28 22:38:32,382 INFO     Training average loss at step 8800: 0.095327\n",
      "2024-02-28 22:41:44,881 INFO     Training average positive_sample_loss at step 8900: 0.122417\n",
      "2024-02-28 22:41:44,882 INFO     Training average negative_sample_loss at step 8900: 0.061109\n",
      "2024-02-28 22:41:44,882 INFO     Training average loss at step 8900: 0.091763\n",
      "2024-02-28 22:44:52,024 INFO     Training average positive_sample_loss at step 9000: 0.122118\n",
      "2024-02-28 22:44:52,024 INFO     Training average negative_sample_loss at step 9000: 0.060729\n",
      "2024-02-28 22:44:52,024 INFO     Training average loss at step 9000: 0.091424\n",
      "2024-02-28 22:47:54,152 INFO     Training average positive_sample_loss at step 9100: 0.125663\n",
      "2024-02-28 22:47:54,153 INFO     Training average negative_sample_loss at step 9100: 0.060196\n",
      "2024-02-28 22:47:54,153 INFO     Training average loss at step 9100: 0.092929\n",
      "2024-02-28 22:51:10,938 INFO     Training average positive_sample_loss at step 9200: 0.124159\n",
      "2024-02-28 22:51:10,938 INFO     Training average negative_sample_loss at step 9200: 0.059926\n",
      "2024-02-28 22:51:10,938 INFO     Training average loss at step 9200: 0.092043\n",
      "2024-02-28 22:54:06,588 INFO     Training average positive_sample_loss at step 9300: 0.117644\n",
      "2024-02-28 22:54:06,589 INFO     Training average negative_sample_loss at step 9300: 0.058588\n",
      "2024-02-28 22:54:06,589 INFO     Training average loss at step 9300: 0.088116\n",
      "2024-02-28 22:57:27,402 INFO     Training average positive_sample_loss at step 9400: 0.121310\n",
      "2024-02-28 22:57:27,403 INFO     Training average negative_sample_loss at step 9400: 0.058545\n",
      "2024-02-28 22:57:27,403 INFO     Training average loss at step 9400: 0.089927\n",
      "2024-02-28 23:00:24,491 INFO     Training average positive_sample_loss at step 9500: 0.124633\n",
      "2024-02-28 23:00:24,491 INFO     Training average negative_sample_loss at step 9500: 0.058815\n",
      "2024-02-28 23:00:24,491 INFO     Training average loss at step 9500: 0.091724\n",
      "2024-02-28 23:03:26,812 INFO     Training average positive_sample_loss at step 9600: 0.115428\n",
      "2024-02-28 23:03:26,812 INFO     Training average negative_sample_loss at step 9600: 0.057447\n",
      "2024-02-28 23:03:26,812 INFO     Training average loss at step 9600: 0.086437\n",
      "2024-02-28 23:06:48,470 INFO     Training average positive_sample_loss at step 9700: 0.118120\n",
      "2024-02-28 23:06:48,471 INFO     Training average negative_sample_loss at step 9700: 0.057277\n",
      "2024-02-28 23:06:48,471 INFO     Training average loss at step 9700: 0.087698\n",
      "2024-02-28 23:10:06,569 INFO     Training average positive_sample_loss at step 9800: 0.121248\n",
      "2024-02-28 23:10:06,570 INFO     Training average negative_sample_loss at step 9800: 0.057149\n",
      "2024-02-28 23:10:06,570 INFO     Training average loss at step 9800: 0.089199\n",
      "2024-02-28 23:13:10,314 INFO     Training average positive_sample_loss at step 9900: 0.117091\n",
      "2024-02-28 23:13:10,315 INFO     Training average negative_sample_loss at step 9900: 0.056252\n",
      "2024-02-28 23:13:10,315 INFO     Training average loss at step 9900: 0.086672\n",
      "2024-02-28 23:16:09,368 INFO     Training average positive_sample_loss at step 10000: 0.113421\n",
      "2024-02-28 23:16:09,369 INFO     Training average negative_sample_loss at step 10000: 0.055629\n",
      "2024-02-28 23:16:09,369 INFO     Training average loss at step 10000: 0.084525\n",
      "2024-02-28 23:16:09,369 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-28 23:16:09,853 INFO     Evaluating the model... (0/760)\n",
      "2024-02-28 23:16:37,392 INFO     Valid MRR at step 10000: 0.424878\n",
      "2024-02-28 23:16:37,392 INFO     Valid MR at step 10000: 7190.672874\n",
      "2024-02-28 23:16:37,392 INFO     Valid HITS@1 at step 10000: 0.403593\n",
      "2024-02-28 23:16:37,392 INFO     Valid HITS@3 at step 10000: 0.432103\n",
      "2024-02-28 23:16:37,392 INFO     Valid HITS@10 at step 10000: 0.461602\n",
      "2024-02-28 23:19:20,438 INFO     Training average positive_sample_loss at step 10100: 0.118702\n",
      "2024-02-28 23:19:20,438 INFO     Training average negative_sample_loss at step 10100: 0.055622\n",
      "2024-02-28 23:19:20,438 INFO     Training average loss at step 10100: 0.087162\n",
      "2024-02-28 23:22:49,628 INFO     Training average positive_sample_loss at step 10200: 0.120491\n",
      "2024-02-28 23:22:49,629 INFO     Training average negative_sample_loss at step 10200: 0.056392\n",
      "2024-02-28 23:22:49,629 INFO     Training average loss at step 10200: 0.088441\n",
      "2024-02-28 23:25:44,271 INFO     Training average positive_sample_loss at step 10300: 0.110083\n",
      "2024-02-28 23:25:44,272 INFO     Training average negative_sample_loss at step 10300: 0.054691\n",
      "2024-02-28 23:25:44,272 INFO     Training average loss at step 10300: 0.082387\n",
      "2024-02-28 23:28:59,728 INFO     Training average positive_sample_loss at step 10400: 0.114364\n",
      "2024-02-28 23:28:59,728 INFO     Training average negative_sample_loss at step 10400: 0.053871\n",
      "2024-02-28 23:28:59,728 INFO     Training average loss at step 10400: 0.084118\n",
      "2024-02-28 23:32:12,374 INFO     Training average positive_sample_loss at step 10500: 0.118155\n",
      "2024-02-28 23:32:12,375 INFO     Training average negative_sample_loss at step 10500: 0.054367\n",
      "2024-02-28 23:32:12,375 INFO     Training average loss at step 10500: 0.086261\n",
      "2024-02-28 23:35:14,730 INFO     Training average positive_sample_loss at step 10600: 0.112110\n",
      "2024-02-28 23:35:14,731 INFO     Training average negative_sample_loss at step 10600: 0.054486\n",
      "2024-02-28 23:35:14,731 INFO     Training average loss at step 10600: 0.083298\n",
      "2024-02-28 23:38:26,888 INFO     Training average positive_sample_loss at step 10700: 0.111167\n",
      "2024-02-28 23:38:26,889 INFO     Training average negative_sample_loss at step 10700: 0.053108\n",
      "2024-02-28 23:38:26,889 INFO     Training average loss at step 10700: 0.082137\n",
      "2024-02-28 23:41:39,528 INFO     Training average positive_sample_loss at step 10800: 0.114992\n",
      "2024-02-28 23:41:39,529 INFO     Training average negative_sample_loss at step 10800: 0.053318\n",
      "2024-02-28 23:41:39,529 INFO     Training average loss at step 10800: 0.084155\n",
      "2024-02-28 23:44:55,007 INFO     Training average positive_sample_loss at step 10900: 0.114052\n",
      "2024-02-28 23:44:55,007 INFO     Training average negative_sample_loss at step 10900: 0.053210\n",
      "2024-02-28 23:44:55,008 INFO     Training average loss at step 10900: 0.083631\n",
      "2024-02-28 23:48:09,130 INFO     Training average positive_sample_loss at step 11000: 0.108029\n",
      "2024-02-28 23:48:09,131 INFO     Training average negative_sample_loss at step 11000: 0.052307\n",
      "2024-02-28 23:48:09,131 INFO     Training average loss at step 11000: 0.080168\n",
      "2024-02-28 23:51:27,195 INFO     Training average positive_sample_loss at step 11100: 0.111851\n",
      "2024-02-28 23:51:27,195 INFO     Training average negative_sample_loss at step 11100: 0.052147\n",
      "2024-02-28 23:51:27,195 INFO     Training average loss at step 11100: 0.081999\n",
      "2024-02-28 23:54:41,726 INFO     Training average positive_sample_loss at step 11200: 0.114419\n",
      "2024-02-28 23:54:41,727 INFO     Training average negative_sample_loss at step 11200: 0.052455\n",
      "2024-02-28 23:54:41,727 INFO     Training average loss at step 11200: 0.083437\n",
      "2024-02-28 23:57:54,847 INFO     Training average positive_sample_loss at step 11300: 0.106982\n",
      "2024-02-28 23:57:54,848 INFO     Training average negative_sample_loss at step 11300: 0.051774\n",
      "2024-02-28 23:57:54,848 INFO     Training average loss at step 11300: 0.079378\n",
      "2024-02-29 00:01:01,953 INFO     Training average positive_sample_loss at step 11400: 0.109536\n",
      "2024-02-29 00:01:01,953 INFO     Training average negative_sample_loss at step 11400: 0.051197\n",
      "2024-02-29 00:01:01,953 INFO     Training average loss at step 11400: 0.080366\n",
      "2024-02-29 00:04:15,002 INFO     Training average positive_sample_loss at step 11500: 0.112128\n",
      "2024-02-29 00:04:15,003 INFO     Training average negative_sample_loss at step 11500: 0.051480\n",
      "2024-02-29 00:04:15,003 INFO     Training average loss at step 11500: 0.081804\n",
      "2024-02-29 00:07:29,894 INFO     Training average positive_sample_loss at step 11600: 0.108714\n",
      "2024-02-29 00:07:29,895 INFO     Training average negative_sample_loss at step 11600: 0.051127\n",
      "2024-02-29 00:07:29,895 INFO     Training average loss at step 11600: 0.079921\n",
      "2024-02-29 00:11:07,847 INFO     Training average positive_sample_loss at step 11700: 0.106663\n",
      "2024-02-29 00:11:07,848 INFO     Training average negative_sample_loss at step 11700: 0.050265\n",
      "2024-02-29 00:11:07,848 INFO     Training average loss at step 11700: 0.078464\n",
      "2024-02-29 00:14:18,119 INFO     Training average positive_sample_loss at step 11800: 0.109640\n",
      "2024-02-29 00:14:18,120 INFO     Training average negative_sample_loss at step 11800: 0.050170\n",
      "2024-02-29 00:14:18,120 INFO     Training average loss at step 11800: 0.079905\n",
      "2024-02-29 00:17:36,265 INFO     Training average positive_sample_loss at step 11900: 0.111287\n",
      "2024-02-29 00:17:36,266 INFO     Training average negative_sample_loss at step 11900: 0.050795\n",
      "2024-02-29 00:17:36,266 INFO     Training average loss at step 11900: 0.081041\n",
      "2024-02-29 00:20:26,297 INFO     Training average positive_sample_loss at step 12000: 0.102832\n",
      "2024-02-29 00:20:26,298 INFO     Training average negative_sample_loss at step 12000: 0.049666\n",
      "2024-02-29 00:20:26,298 INFO     Training average loss at step 12000: 0.076249\n",
      "2024-02-29 00:23:35,145 INFO     Training average positive_sample_loss at step 12100: 0.107462\n",
      "2024-02-29 00:23:35,145 INFO     Training average negative_sample_loss at step 12100: 0.049562\n",
      "2024-02-29 00:23:35,145 INFO     Training average loss at step 12100: 0.078512\n",
      "2024-02-29 00:27:14,554 INFO     Training average positive_sample_loss at step 12200: 0.109539\n",
      "2024-02-29 00:27:14,554 INFO     Training average negative_sample_loss at step 12200: 0.049739\n",
      "2024-02-29 00:27:14,554 INFO     Training average loss at step 12200: 0.079639\n",
      "2024-02-29 00:30:23,013 INFO     Training average positive_sample_loss at step 12300: 0.104143\n",
      "2024-02-29 00:30:23,014 INFO     Training average negative_sample_loss at step 12300: 0.048876\n",
      "2024-02-29 00:30:23,014 INFO     Training average loss at step 12300: 0.076509\n",
      "2024-02-29 00:33:25,717 INFO     Training average positive_sample_loss at step 12400: 0.104808\n",
      "2024-02-29 00:33:25,718 INFO     Training average negative_sample_loss at step 12400: 0.048871\n",
      "2024-02-29 00:33:25,718 INFO     Training average loss at step 12400: 0.076840\n",
      "2024-02-29 00:36:34,416 INFO     Training average positive_sample_loss at step 12500: 0.108069\n",
      "2024-02-29 00:36:34,416 INFO     Training average negative_sample_loss at step 12500: 0.048836\n",
      "2024-02-29 00:36:34,416 INFO     Training average loss at step 12500: 0.078452\n",
      "2024-02-29 00:39:50,771 INFO     Training average positive_sample_loss at step 12600: 0.107191\n",
      "2024-02-29 00:39:50,771 INFO     Training average negative_sample_loss at step 12600: 0.049239\n",
      "2024-02-29 00:39:50,771 INFO     Training average loss at step 12600: 0.078215\n",
      "2024-02-29 00:43:18,562 INFO     Training average positive_sample_loss at step 12700: 0.101413\n",
      "2024-02-29 00:43:18,562 INFO     Training average negative_sample_loss at step 12700: 0.047726\n",
      "2024-02-29 00:43:18,562 INFO     Training average loss at step 12700: 0.074570\n",
      "2024-02-29 00:47:00,460 INFO     Training average positive_sample_loss at step 12800: 0.105592\n",
      "2024-02-29 00:47:00,460 INFO     Training average negative_sample_loss at step 12800: 0.048152\n",
      "2024-02-29 00:47:00,460 INFO     Training average loss at step 12800: 0.076872\n",
      "2024-02-29 00:50:29,417 INFO     Training average positive_sample_loss at step 12900: 0.107376\n",
      "2024-02-29 00:50:29,418 INFO     Training average negative_sample_loss at step 12900: 0.048793\n",
      "2024-02-29 00:50:29,418 INFO     Training average loss at step 12900: 0.078084\n",
      "2024-02-29 00:53:38,549 INFO     Training average positive_sample_loss at step 13000: 0.100959\n",
      "2024-02-29 00:53:38,550 INFO     Training average negative_sample_loss at step 13000: 0.047282\n",
      "2024-02-29 00:53:38,550 INFO     Training average loss at step 13000: 0.074120\n",
      "2024-02-29 00:57:08,944 INFO     Training average positive_sample_loss at step 13100: 0.103064\n",
      "2024-02-29 00:57:08,945 INFO     Training average negative_sample_loss at step 13100: 0.047265\n",
      "2024-02-29 00:57:08,945 INFO     Training average loss at step 13100: 0.075165\n",
      "2024-02-29 01:00:34,398 INFO     Training average positive_sample_loss at step 13200: 0.105403\n",
      "2024-02-29 01:00:34,399 INFO     Training average negative_sample_loss at step 13200: 0.047937\n",
      "2024-02-29 01:00:34,399 INFO     Training average loss at step 13200: 0.076670\n",
      "2024-02-29 01:03:37,477 INFO     Training average positive_sample_loss at step 13300: 0.103399\n",
      "2024-02-29 01:03:37,478 INFO     Training average negative_sample_loss at step 13300: 0.047739\n",
      "2024-02-29 01:03:37,478 INFO     Training average loss at step 13300: 0.075569\n",
      "2024-02-29 01:06:28,223 INFO     Training average positive_sample_loss at step 13400: 0.100583\n",
      "2024-02-29 01:06:28,223 INFO     Training average negative_sample_loss at step 13400: 0.046538\n",
      "2024-02-29 01:06:28,224 INFO     Training average loss at step 13400: 0.073560\n",
      "2024-02-29 01:09:30,793 INFO     Training average positive_sample_loss at step 13500: 0.103892\n",
      "2024-02-29 01:09:30,793 INFO     Training average negative_sample_loss at step 13500: 0.047031\n",
      "2024-02-29 01:09:30,793 INFO     Training average loss at step 13500: 0.075461\n",
      "2024-02-29 01:12:40,459 INFO     Training average positive_sample_loss at step 13600: 0.105696\n",
      "2024-02-29 01:12:40,459 INFO     Training average negative_sample_loss at step 13600: 0.047504\n",
      "2024-02-29 01:12:40,459 INFO     Training average loss at step 13600: 0.076600\n",
      "2024-02-29 01:15:26,855 INFO     Training average positive_sample_loss at step 13700: 0.097410\n",
      "2024-02-29 01:15:26,856 INFO     Training average negative_sample_loss at step 13700: 0.045943\n",
      "2024-02-29 01:15:26,856 INFO     Training average loss at step 13700: 0.071676\n",
      "2024-02-29 01:18:47,036 INFO     Training average positive_sample_loss at step 13800: 0.102054\n",
      "2024-02-29 01:18:47,037 INFO     Training average negative_sample_loss at step 13800: 0.046452\n",
      "2024-02-29 01:18:47,037 INFO     Training average loss at step 13800: 0.074253\n",
      "2024-02-29 01:21:49,080 INFO     Training average positive_sample_loss at step 13900: 0.104441\n",
      "2024-02-29 01:21:49,080 INFO     Training average negative_sample_loss at step 13900: 0.046425\n",
      "2024-02-29 01:21:49,080 INFO     Training average loss at step 13900: 0.075433\n",
      "2024-02-29 01:25:10,703 INFO     Training average positive_sample_loss at step 14000: 0.098904\n",
      "2024-02-29 01:25:10,703 INFO     Training average negative_sample_loss at step 14000: 0.046059\n",
      "2024-02-29 01:25:10,703 INFO     Training average loss at step 14000: 0.072482\n",
      "2024-02-29 01:28:09,900 INFO     Training average positive_sample_loss at step 14100: 0.099812\n",
      "2024-02-29 01:28:09,901 INFO     Training average negative_sample_loss at step 14100: 0.045600\n",
      "2024-02-29 01:28:09,901 INFO     Training average loss at step 14100: 0.072706\n",
      "2024-02-29 01:31:20,125 INFO     Training average positive_sample_loss at step 14200: 0.103106\n",
      "2024-02-29 01:31:20,125 INFO     Training average negative_sample_loss at step 14200: 0.045926\n",
      "2024-02-29 01:31:20,125 INFO     Training average loss at step 14200: 0.074516\n",
      "2024-02-29 01:34:55,981 INFO     Training average positive_sample_loss at step 14300: 0.101621\n",
      "2024-02-29 01:34:55,982 INFO     Training average negative_sample_loss at step 14300: 0.046143\n",
      "2024-02-29 01:34:55,982 INFO     Training average loss at step 14300: 0.073882\n",
      "2024-02-29 01:37:54,660 INFO     Training average positive_sample_loss at step 14400: 0.096908\n",
      "2024-02-29 01:37:54,660 INFO     Training average negative_sample_loss at step 14400: 0.044895\n",
      "2024-02-29 01:37:54,660 INFO     Training average loss at step 14400: 0.070902\n",
      "2024-02-29 01:41:09,099 INFO     Training average positive_sample_loss at step 14500: 0.100893\n",
      "2024-02-29 01:41:09,099 INFO     Training average negative_sample_loss at step 14500: 0.045650\n",
      "2024-02-29 01:41:09,099 INFO     Training average loss at step 14500: 0.073272\n",
      "2024-02-29 01:44:47,677 INFO     Training average positive_sample_loss at step 14600: 0.102774\n",
      "2024-02-29 01:44:47,677 INFO     Training average negative_sample_loss at step 14600: 0.045555\n",
      "2024-02-29 01:44:47,677 INFO     Training average loss at step 14600: 0.074164\n",
      "2024-02-29 01:48:14,016 INFO     Training average positive_sample_loss at step 14700: 0.095938\n",
      "2024-02-29 01:48:14,017 INFO     Training average negative_sample_loss at step 14700: 0.044843\n",
      "2024-02-29 01:48:14,017 INFO     Training average loss at step 14700: 0.070391\n",
      "2024-02-29 01:51:20,860 INFO     Training average positive_sample_loss at step 14800: 0.098285\n",
      "2024-02-29 01:51:20,861 INFO     Training average negative_sample_loss at step 14800: 0.044592\n",
      "2024-02-29 01:51:20,861 INFO     Training average loss at step 14800: 0.071439\n",
      "2024-02-29 01:54:50,368 INFO     Training average positive_sample_loss at step 14900: 0.101969\n",
      "2024-02-29 01:54:50,368 INFO     Training average negative_sample_loss at step 14900: 0.044941\n",
      "2024-02-29 01:54:50,368 INFO     Training average loss at step 14900: 0.073455\n",
      "2024-02-29 01:57:58,842 INFO     Training average positive_sample_loss at step 15000: 0.098418\n",
      "2024-02-29 01:57:58,843 INFO     Training average negative_sample_loss at step 15000: 0.045020\n",
      "2024-02-29 01:57:58,843 INFO     Training average loss at step 15000: 0.071719\n",
      "2024-02-29 02:01:15,665 INFO     Training average positive_sample_loss at step 15100: 0.096435\n",
      "2024-02-29 02:01:15,665 INFO     Training average negative_sample_loss at step 15100: 0.044177\n",
      "2024-02-29 02:01:15,665 INFO     Training average loss at step 15100: 0.070306\n",
      "2024-02-29 02:04:34,736 INFO     Training average positive_sample_loss at step 15200: 0.100134\n",
      "2024-02-29 02:04:34,737 INFO     Training average negative_sample_loss at step 15200: 0.044382\n",
      "2024-02-29 02:04:34,737 INFO     Training average loss at step 15200: 0.072258\n",
      "2024-02-29 02:08:08,275 INFO     Training average positive_sample_loss at step 15300: 0.101137\n",
      "2024-02-29 02:08:08,276 INFO     Training average negative_sample_loss at step 15300: 0.045046\n",
      "2024-02-29 02:08:08,276 INFO     Training average loss at step 15300: 0.073092\n",
      "2024-02-29 02:11:10,854 INFO     Training average positive_sample_loss at step 15400: 0.094028\n",
      "2024-02-29 02:11:10,855 INFO     Training average negative_sample_loss at step 15400: 0.043449\n",
      "2024-02-29 02:11:10,855 INFO     Training average loss at step 15400: 0.068739\n",
      "2024-02-29 02:14:16,202 INFO     Training average positive_sample_loss at step 15500: 0.097852\n",
      "2024-02-29 02:14:16,203 INFO     Training average negative_sample_loss at step 15500: 0.044090\n",
      "2024-02-29 02:14:16,203 INFO     Training average loss at step 15500: 0.070971\n",
      "2024-02-29 02:17:24,718 INFO     Training average positive_sample_loss at step 15600: 0.100195\n",
      "2024-02-29 02:17:24,719 INFO     Training average negative_sample_loss at step 15600: 0.044590\n",
      "2024-02-29 02:17:24,719 INFO     Training average loss at step 15600: 0.072393\n",
      "2024-02-29 02:20:42,660 INFO     Training average positive_sample_loss at step 15700: 0.095110\n",
      "2024-02-29 02:20:42,661 INFO     Training average negative_sample_loss at step 15700: 0.043608\n",
      "2024-02-29 02:20:42,661 INFO     Training average loss at step 15700: 0.069359\n",
      "2024-02-29 02:23:50,107 INFO     Training average positive_sample_loss at step 15800: 0.095609\n",
      "2024-02-29 02:23:50,107 INFO     Training average negative_sample_loss at step 15800: 0.043345\n",
      "2024-02-29 02:23:50,107 INFO     Training average loss at step 15800: 0.069477\n",
      "2024-02-29 02:26:59,932 INFO     Training average positive_sample_loss at step 15900: 0.099339\n",
      "2024-02-29 02:26:59,932 INFO     Training average negative_sample_loss at step 15900: 0.043921\n",
      "2024-02-29 02:26:59,932 INFO     Training average loss at step 15900: 0.071630\n",
      "2024-02-29 02:30:33,256 INFO     Training average positive_sample_loss at step 16000: 0.097809\n",
      "2024-02-29 02:30:33,257 INFO     Training average negative_sample_loss at step 16000: 0.043585\n",
      "2024-02-29 02:30:33,257 INFO     Training average loss at step 16000: 0.070697\n",
      "2024-02-29 02:33:37,215 INFO     Training average positive_sample_loss at step 16100: 0.093441\n",
      "2024-02-29 02:33:37,216 INFO     Training average negative_sample_loss at step 16100: 0.043169\n",
      "2024-02-29 02:33:37,216 INFO     Training average loss at step 16100: 0.068305\n",
      "2024-02-29 02:36:41,358 INFO     Training average positive_sample_loss at step 16200: 0.096881\n",
      "2024-02-29 02:36:41,359 INFO     Training average negative_sample_loss at step 16200: 0.042862\n",
      "2024-02-29 02:36:41,359 INFO     Training average loss at step 16200: 0.069871\n",
      "2024-02-29 02:40:00,233 INFO     Training average positive_sample_loss at step 16300: 0.099583\n",
      "2024-02-29 02:40:00,233 INFO     Training average negative_sample_loss at step 16300: 0.043614\n",
      "2024-02-29 02:40:00,233 INFO     Training average loss at step 16300: 0.071598\n",
      "2024-02-29 02:43:13,743 INFO     Training average positive_sample_loss at step 16400: 0.093060\n",
      "2024-02-29 02:43:13,744 INFO     Training average negative_sample_loss at step 16400: 0.042747\n",
      "2024-02-29 02:43:13,744 INFO     Training average loss at step 16400: 0.067903\n",
      "2024-02-29 02:46:32,783 INFO     Training average positive_sample_loss at step 16500: 0.095491\n",
      "2024-02-29 02:46:32,784 INFO     Training average negative_sample_loss at step 16500: 0.042810\n",
      "2024-02-29 02:46:32,784 INFO     Training average loss at step 16500: 0.069150\n",
      "2024-02-29 02:49:46,139 INFO     Training average positive_sample_loss at step 16600: 0.097735\n",
      "2024-02-29 02:49:46,140 INFO     Training average negative_sample_loss at step 16600: 0.043318\n",
      "2024-02-29 02:49:46,140 INFO     Training average loss at step 16600: 0.070527\n",
      "2024-02-29 02:53:21,895 INFO     Training average positive_sample_loss at step 16700: 0.094925\n",
      "2024-02-29 02:53:21,895 INFO     Training average negative_sample_loss at step 16700: 0.042920\n",
      "2024-02-29 02:53:21,895 INFO     Training average loss at step 16700: 0.068923\n",
      "2024-02-29 02:56:45,631 INFO     Training average positive_sample_loss at step 16800: 0.093194\n",
      "2024-02-29 02:56:45,632 INFO     Training average negative_sample_loss at step 16800: 0.042141\n",
      "2024-02-29 02:56:45,632 INFO     Training average loss at step 16800: 0.067667\n",
      "2024-02-29 02:59:57,657 INFO     Training average positive_sample_loss at step 16900: 0.096247\n",
      "2024-02-29 02:59:57,658 INFO     Training average negative_sample_loss at step 16900: 0.042460\n",
      "2024-02-29 02:59:57,658 INFO     Training average loss at step 16900: 0.069354\n",
      "2024-02-29 03:03:34,448 INFO     Training average positive_sample_loss at step 17000: 0.098326\n",
      "2024-02-29 03:03:34,448 INFO     Training average negative_sample_loss at step 17000: 0.043123\n",
      "2024-02-29 03:03:34,448 INFO     Training average loss at step 17000: 0.070725\n",
      "2024-02-29 03:06:37,969 INFO     Training average positive_sample_loss at step 17100: 0.090620\n",
      "2024-02-29 03:06:37,970 INFO     Training average negative_sample_loss at step 17100: 0.041740\n",
      "2024-02-29 03:06:37,970 INFO     Training average loss at step 17100: 0.066180\n",
      "2024-02-29 03:09:42,165 INFO     Training average positive_sample_loss at step 17200: 0.094729\n",
      "2024-02-29 03:09:42,166 INFO     Training average negative_sample_loss at step 17200: 0.042152\n",
      "2024-02-29 03:09:42,166 INFO     Training average loss at step 17200: 0.068441\n",
      "2024-02-29 03:13:03,284 INFO     Training average positive_sample_loss at step 17300: 0.097332\n",
      "2024-02-29 03:13:03,284 INFO     Training average negative_sample_loss at step 17300: 0.042531\n",
      "2024-02-29 03:13:03,284 INFO     Training average loss at step 17300: 0.069931\n",
      "2024-02-29 03:16:08,012 INFO     Training average positive_sample_loss at step 17400: 0.092640\n",
      "2024-02-29 03:16:08,012 INFO     Training average negative_sample_loss at step 17400: 0.042224\n",
      "2024-02-29 03:16:08,012 INFO     Training average loss at step 17400: 0.067432\n",
      "2024-02-29 03:19:37,289 INFO     Training average positive_sample_loss at step 17500: 0.092316\n",
      "2024-02-29 03:19:37,289 INFO     Training average negative_sample_loss at step 17500: 0.041474\n",
      "2024-02-29 03:19:37,289 INFO     Training average loss at step 17500: 0.066895\n",
      "2024-02-29 03:22:52,425 INFO     Training average positive_sample_loss at step 17600: 0.095533\n",
      "2024-02-29 03:22:52,426 INFO     Training average negative_sample_loss at step 17600: 0.042493\n",
      "2024-02-29 03:22:52,426 INFO     Training average loss at step 17600: 0.069013\n",
      "2024-02-29 03:27:05,692 INFO     Training average positive_sample_loss at step 17700: 0.095965\n",
      "2024-02-29 03:27:05,692 INFO     Training average negative_sample_loss at step 17700: 0.041853\n",
      "2024-02-29 03:27:05,692 INFO     Training average loss at step 17700: 0.068909\n",
      "2024-02-29 03:29:58,950 INFO     Training average positive_sample_loss at step 17800: 0.090457\n",
      "2024-02-29 03:29:58,951 INFO     Training average negative_sample_loss at step 17800: 0.041152\n",
      "2024-02-29 03:29:58,951 INFO     Training average loss at step 17800: 0.065804\n",
      "2024-02-29 03:33:00,887 INFO     Training average positive_sample_loss at step 17900: 0.093960\n",
      "2024-02-29 03:33:00,888 INFO     Training average negative_sample_loss at step 17900: 0.041377\n",
      "2024-02-29 03:33:00,888 INFO     Training average loss at step 17900: 0.067669\n",
      "2024-02-29 03:36:08,986 INFO     Training average positive_sample_loss at step 18000: 0.096475\n",
      "2024-02-29 03:36:08,986 INFO     Training average negative_sample_loss at step 18000: 0.042300\n",
      "2024-02-29 03:36:08,986 INFO     Training average loss at step 18000: 0.069387\n",
      "2024-02-29 03:39:31,704 INFO     Training average positive_sample_loss at step 18100: 0.090087\n",
      "2024-02-29 03:39:31,704 INFO     Training average negative_sample_loss at step 18100: 0.041092\n",
      "2024-02-29 03:39:31,704 INFO     Training average loss at step 18100: 0.065589\n",
      "2024-02-29 03:42:58,789 INFO     Training average positive_sample_loss at step 18200: 0.092729\n",
      "2024-02-29 03:42:58,789 INFO     Training average negative_sample_loss at step 18200: 0.041301\n",
      "2024-02-29 03:42:58,790 INFO     Training average loss at step 18200: 0.067015\n",
      "2024-02-29 03:46:07,133 INFO     Training average positive_sample_loss at step 18300: 0.095501\n",
      "2024-02-29 03:46:07,133 INFO     Training average negative_sample_loss at step 18300: 0.041503\n",
      "2024-02-29 03:46:07,133 INFO     Training average loss at step 18300: 0.068502\n",
      "2024-02-29 03:49:17,460 INFO     Training average positive_sample_loss at step 18400: 0.092270\n",
      "2024-02-29 03:49:17,461 INFO     Training average negative_sample_loss at step 18400: 0.041529\n",
      "2024-02-29 03:49:17,461 INFO     Training average loss at step 18400: 0.066900\n",
      "2024-02-29 03:52:29,700 INFO     Training average positive_sample_loss at step 18500: 0.090555\n",
      "2024-02-29 03:52:29,701 INFO     Training average negative_sample_loss at step 18500: 0.040599\n",
      "2024-02-29 03:52:29,701 INFO     Training average loss at step 18500: 0.065577\n",
      "2024-02-29 03:55:52,453 INFO     Training average positive_sample_loss at step 18600: 0.093682\n",
      "2024-02-29 03:55:52,453 INFO     Training average negative_sample_loss at step 18600: 0.041093\n",
      "2024-02-29 03:55:52,453 INFO     Training average loss at step 18600: 0.067387\n",
      "2024-02-29 03:59:29,551 INFO     Training average positive_sample_loss at step 18700: 0.095648\n",
      "2024-02-29 03:59:29,552 INFO     Training average negative_sample_loss at step 18700: 0.041907\n",
      "2024-02-29 03:59:29,552 INFO     Training average loss at step 18700: 0.068777\n",
      "2024-02-29 04:02:53,888 INFO     Training average positive_sample_loss at step 18800: 0.088770\n",
      "2024-02-29 04:02:53,889 INFO     Training average negative_sample_loss at step 18800: 0.040627\n",
      "2024-02-29 04:02:53,889 INFO     Training average loss at step 18800: 0.064698\n",
      "2024-02-29 04:06:04,261 INFO     Training average positive_sample_loss at step 18900: 0.092471\n",
      "2024-02-29 04:06:04,262 INFO     Training average negative_sample_loss at step 18900: 0.040891\n",
      "2024-02-29 04:06:04,262 INFO     Training average loss at step 18900: 0.066681\n",
      "2024-02-29 04:09:33,533 INFO     Training average positive_sample_loss at step 19000: 0.094027\n",
      "2024-02-29 04:09:33,534 INFO     Training average negative_sample_loss at step 19000: 0.040911\n",
      "2024-02-29 04:09:33,534 INFO     Training average loss at step 19000: 0.067469\n",
      "2024-02-29 04:12:55,944 INFO     Training average positive_sample_loss at step 19100: 0.089869\n",
      "2024-02-29 04:12:55,945 INFO     Training average negative_sample_loss at step 19100: 0.040452\n",
      "2024-02-29 04:12:55,945 INFO     Training average loss at step 19100: 0.065160\n",
      "2024-02-29 04:16:13,106 INFO     Training average positive_sample_loss at step 19200: 0.090509\n",
      "2024-02-29 04:16:13,107 INFO     Training average negative_sample_loss at step 19200: 0.040712\n",
      "2024-02-29 04:16:13,107 INFO     Training average loss at step 19200: 0.065611\n",
      "2024-02-29 04:19:17,570 INFO     Training average positive_sample_loss at step 19300: 0.093445\n",
      "2024-02-29 04:19:17,570 INFO     Training average negative_sample_loss at step 19300: 0.040598\n",
      "2024-02-29 04:19:17,570 INFO     Training average loss at step 19300: 0.067022\n",
      "2024-02-29 04:22:26,982 INFO     Training average positive_sample_loss at step 19400: 0.092977\n",
      "2024-02-29 04:22:26,982 INFO     Training average negative_sample_loss at step 19400: 0.040486\n",
      "2024-02-29 04:22:26,982 INFO     Training average loss at step 19400: 0.066731\n",
      "2024-02-29 04:25:35,087 INFO     Training average positive_sample_loss at step 19500: 0.088495\n",
      "2024-02-29 04:25:35,088 INFO     Training average negative_sample_loss at step 19500: 0.040190\n",
      "2024-02-29 04:25:35,088 INFO     Training average loss at step 19500: 0.064342\n",
      "2024-02-29 04:28:39,366 INFO     Training average positive_sample_loss at step 19600: 0.092361\n",
      "2024-02-29 04:28:39,367 INFO     Training average negative_sample_loss at step 19600: 0.040218\n",
      "2024-02-29 04:28:39,367 INFO     Training average loss at step 19600: 0.066289\n",
      "2024-02-29 04:31:44,550 INFO     Training average positive_sample_loss at step 19700: 0.093430\n",
      "2024-02-29 04:31:44,550 INFO     Training average negative_sample_loss at step 19700: 0.040905\n",
      "2024-02-29 04:31:44,550 INFO     Training average loss at step 19700: 0.067168\n",
      "2024-02-29 04:35:14,122 INFO     Training average positive_sample_loss at step 19800: 0.088119\n",
      "2024-02-29 04:35:14,123 INFO     Training average negative_sample_loss at step 19800: 0.040112\n",
      "2024-02-29 04:35:14,123 INFO     Training average loss at step 19800: 0.064116\n",
      "2024-02-29 04:38:13,429 INFO     Training average positive_sample_loss at step 19900: 0.090467\n",
      "2024-02-29 04:38:13,430 INFO     Training average negative_sample_loss at step 19900: 0.040014\n",
      "2024-02-29 04:38:13,430 INFO     Training average loss at step 19900: 0.065240\n",
      "2024-02-29 04:41:28,845 INFO     Training average positive_sample_loss at step 20000: 0.092989\n",
      "2024-02-29 04:41:28,845 INFO     Training average negative_sample_loss at step 20000: 0.039828\n",
      "2024-02-29 04:41:28,845 INFO     Training average loss at step 20000: 0.066408\n",
      "2024-02-29 04:41:28,845 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 04:41:29,333 INFO     Evaluating the model... (0/760)\n",
      "2024-02-29 04:41:58,391 INFO     Valid MRR at step 20000: 0.457067\n",
      "2024-02-29 04:41:58,391 INFO     Valid MR at step 20000: 5857.570040\n",
      "2024-02-29 04:41:58,391 INFO     Valid HITS@1 at step 20000: 0.425676\n",
      "2024-02-29 04:41:58,391 INFO     Valid HITS@3 at step 20000: 0.470171\n",
      "2024-02-29 04:41:58,391 INFO     Valid HITS@10 at step 20000: 0.517139\n",
      "2024-02-29 04:44:39,189 INFO     Training average positive_sample_loss at step 20100: 0.090682\n",
      "2024-02-29 04:44:39,190 INFO     Training average negative_sample_loss at step 20100: 0.040172\n",
      "2024-02-29 04:44:39,190 INFO     Training average loss at step 20100: 0.065427\n",
      "2024-02-29 04:48:42,358 INFO     Training average positive_sample_loss at step 20200: 0.088832\n",
      "2024-02-29 04:48:42,359 INFO     Training average negative_sample_loss at step 20200: 0.039963\n",
      "2024-02-29 04:48:42,359 INFO     Training average loss at step 20200: 0.064398\n",
      "2024-02-29 04:52:16,848 INFO     Training average positive_sample_loss at step 20300: 0.091177\n",
      "2024-02-29 04:52:16,848 INFO     Training average negative_sample_loss at step 20300: 0.040199\n",
      "2024-02-29 04:52:16,849 INFO     Training average loss at step 20300: 0.065688\n",
      "2024-02-29 04:55:26,415 INFO     Training average positive_sample_loss at step 20400: 0.093151\n",
      "2024-02-29 04:55:26,415 INFO     Training average negative_sample_loss at step 20400: 0.040217\n",
      "2024-02-29 04:55:26,416 INFO     Training average loss at step 20400: 0.066684\n",
      "2024-02-29 04:58:49,195 INFO     Training average positive_sample_loss at step 20500: 0.086131\n",
      "2024-02-29 04:58:49,195 INFO     Training average negative_sample_loss at step 20500: 0.039059\n",
      "2024-02-29 04:58:49,195 INFO     Training average loss at step 20500: 0.062595\n",
      "2024-02-29 05:01:57,620 INFO     Training average positive_sample_loss at step 20600: 0.090160\n",
      "2024-02-29 05:01:57,620 INFO     Training average negative_sample_loss at step 20600: 0.039227\n",
      "2024-02-29 05:01:57,620 INFO     Training average loss at step 20600: 0.064694\n",
      "2024-02-29 05:05:35,585 INFO     Training average positive_sample_loss at step 20700: 0.092751\n",
      "2024-02-29 05:05:35,586 INFO     Training average negative_sample_loss at step 20700: 0.040327\n",
      "2024-02-29 05:05:35,586 INFO     Training average loss at step 20700: 0.066539\n",
      "2024-02-29 05:08:35,735 INFO     Training average positive_sample_loss at step 20800: 0.088310\n",
      "2024-02-29 05:08:35,735 INFO     Training average negative_sample_loss at step 20800: 0.040049\n",
      "2024-02-29 05:08:35,735 INFO     Training average loss at step 20800: 0.064179\n",
      "2024-02-29 05:11:53,441 INFO     Training average positive_sample_loss at step 20900: 0.088710\n",
      "2024-02-29 05:11:53,441 INFO     Training average negative_sample_loss at step 20900: 0.039327\n",
      "2024-02-29 05:11:53,441 INFO     Training average loss at step 20900: 0.064019\n",
      "2024-02-29 05:15:16,171 INFO     Training average positive_sample_loss at step 21000: 0.092287\n",
      "2024-02-29 05:15:16,171 INFO     Training average negative_sample_loss at step 21000: 0.039453\n",
      "2024-02-29 05:15:16,171 INFO     Training average loss at step 21000: 0.065870\n",
      "2024-02-29 05:18:55,906 INFO     Training average positive_sample_loss at step 21100: 0.090012\n",
      "2024-02-29 05:18:55,907 INFO     Training average negative_sample_loss at step 21100: 0.039347\n",
      "2024-02-29 05:18:55,907 INFO     Training average loss at step 21100: 0.064680\n",
      "2024-02-29 05:21:41,158 INFO     Training average positive_sample_loss at step 21200: 0.086329\n",
      "2024-02-29 05:21:41,159 INFO     Training average negative_sample_loss at step 21200: 0.038866\n",
      "2024-02-29 05:21:41,159 INFO     Training average loss at step 21200: 0.062598\n",
      "2024-02-29 05:24:53,999 INFO     Training average positive_sample_loss at step 21300: 0.089991\n",
      "2024-02-29 05:24:53,999 INFO     Training average negative_sample_loss at step 21300: 0.039386\n",
      "2024-02-29 05:24:53,999 INFO     Training average loss at step 21300: 0.064688\n",
      "2024-02-29 05:28:11,755 INFO     Training average positive_sample_loss at step 21400: 0.092231\n",
      "2024-02-29 05:28:11,756 INFO     Training average negative_sample_loss at step 21400: 0.040000\n",
      "2024-02-29 05:28:11,756 INFO     Training average loss at step 21400: 0.066116\n",
      "2024-02-29 05:30:56,357 INFO     Training average positive_sample_loss at step 21500: 0.086628\n",
      "2024-02-29 05:30:56,358 INFO     Training average negative_sample_loss at step 21500: 0.038866\n",
      "2024-02-29 05:30:56,358 INFO     Training average loss at step 21500: 0.062747\n",
      "2024-02-29 05:33:39,266 INFO     Training average positive_sample_loss at step 21600: 0.088819\n",
      "2024-02-29 05:33:39,267 INFO     Training average negative_sample_loss at step 21600: 0.039191\n",
      "2024-02-29 05:33:39,267 INFO     Training average loss at step 21600: 0.064005\n",
      "2024-02-29 05:36:30,791 INFO     Training average positive_sample_loss at step 21700: 0.090903\n",
      "2024-02-29 05:36:30,791 INFO     Training average negative_sample_loss at step 21700: 0.039188\n",
      "2024-02-29 05:36:30,791 INFO     Training average loss at step 21700: 0.065045\n",
      "2024-02-29 05:39:46,889 INFO     Training average positive_sample_loss at step 21800: 0.088348\n",
      "2024-02-29 05:39:46,889 INFO     Training average negative_sample_loss at step 21800: 0.039286\n",
      "2024-02-29 05:39:46,889 INFO     Training average loss at step 21800: 0.063817\n",
      "2024-02-29 05:43:09,249 INFO     Training average positive_sample_loss at step 21900: 0.087123\n",
      "2024-02-29 05:43:09,250 INFO     Training average negative_sample_loss at step 21900: 0.038458\n",
      "2024-02-29 05:43:09,250 INFO     Training average loss at step 21900: 0.062791\n",
      "2024-02-29 05:46:42,704 INFO     Training average positive_sample_loss at step 22000: 0.089914\n",
      "2024-02-29 05:46:42,704 INFO     Training average negative_sample_loss at step 22000: 0.038868\n",
      "2024-02-29 05:46:42,704 INFO     Training average loss at step 22000: 0.064391\n",
      "2024-02-29 05:50:14,781 INFO     Training average positive_sample_loss at step 22100: 0.090936\n",
      "2024-02-29 05:50:14,781 INFO     Training average negative_sample_loss at step 22100: 0.039588\n",
      "2024-02-29 05:50:14,781 INFO     Training average loss at step 22100: 0.065262\n",
      "2024-02-29 05:53:02,538 INFO     Training average positive_sample_loss at step 22200: 0.085151\n",
      "2024-02-29 05:53:02,538 INFO     Training average negative_sample_loss at step 22200: 0.038669\n",
      "2024-02-29 05:53:02,538 INFO     Training average loss at step 22200: 0.061910\n",
      "2024-02-29 05:55:49,191 INFO     Training average positive_sample_loss at step 22300: 0.089021\n",
      "2024-02-29 05:55:49,192 INFO     Training average negative_sample_loss at step 22300: 0.038734\n",
      "2024-02-29 05:55:49,192 INFO     Training average loss at step 22300: 0.063878\n",
      "2024-02-29 05:58:57,798 INFO     Training average positive_sample_loss at step 22400: 0.090087\n",
      "2024-02-29 05:58:57,799 INFO     Training average negative_sample_loss at step 22400: 0.038708\n",
      "2024-02-29 05:58:57,799 INFO     Training average loss at step 22400: 0.064397\n",
      "2024-02-29 06:02:15,356 INFO     Training average positive_sample_loss at step 22500: 0.086816\n",
      "2024-02-29 06:02:15,356 INFO     Training average negative_sample_loss at step 22500: 0.038816\n",
      "2024-02-29 06:02:15,356 INFO     Training average loss at step 22500: 0.062816\n",
      "2024-02-29 06:04:59,526 INFO     Training average positive_sample_loss at step 22600: 0.087238\n",
      "2024-02-29 06:04:59,526 INFO     Training average negative_sample_loss at step 22600: 0.038424\n",
      "2024-02-29 06:04:59,526 INFO     Training average loss at step 22600: 0.062831\n",
      "2024-02-29 06:07:50,384 INFO     Training average positive_sample_loss at step 22700: 0.089535\n",
      "2024-02-29 06:07:50,385 INFO     Training average negative_sample_loss at step 22700: 0.038439\n",
      "2024-02-29 06:07:50,385 INFO     Training average loss at step 22700: 0.063987\n",
      "2024-02-29 06:11:28,104 INFO     Training average positive_sample_loss at step 22800: 0.088613\n",
      "2024-02-29 06:11:28,104 INFO     Training average negative_sample_loss at step 22800: 0.038882\n",
      "2024-02-29 06:11:28,105 INFO     Training average loss at step 22800: 0.063748\n",
      "2024-02-29 06:14:22,281 INFO     Training average positive_sample_loss at step 22900: 0.085196\n",
      "2024-02-29 06:14:22,282 INFO     Training average negative_sample_loss at step 22900: 0.037965\n",
      "2024-02-29 06:14:22,282 INFO     Training average loss at step 22900: 0.061581\n",
      "2024-02-29 06:17:17,632 INFO     Training average positive_sample_loss at step 23000: 0.088707\n",
      "2024-02-29 06:17:17,633 INFO     Training average negative_sample_loss at step 23000: 0.038449\n",
      "2024-02-29 06:17:17,633 INFO     Training average loss at step 23000: 0.063578\n",
      "2024-02-29 06:20:33,010 INFO     Training average positive_sample_loss at step 23100: 0.089940\n",
      "2024-02-29 06:20:33,010 INFO     Training average negative_sample_loss at step 23100: 0.038887\n",
      "2024-02-29 06:20:33,010 INFO     Training average loss at step 23100: 0.064413\n",
      "2024-02-29 06:24:02,001 INFO     Training average positive_sample_loss at step 23200: 0.085421\n",
      "2024-02-29 06:24:02,001 INFO     Training average negative_sample_loss at step 23200: 0.037881\n",
      "2024-02-29 06:24:02,001 INFO     Training average loss at step 23200: 0.061651\n",
      "2024-02-29 06:27:08,270 INFO     Training average positive_sample_loss at step 23300: 0.086790\n",
      "2024-02-29 06:27:08,271 INFO     Training average negative_sample_loss at step 23300: 0.038149\n",
      "2024-02-29 06:27:08,271 INFO     Training average loss at step 23300: 0.062470\n",
      "2024-02-29 06:30:13,609 INFO     Training average positive_sample_loss at step 23400: 0.089495\n",
      "2024-02-29 06:30:13,610 INFO     Training average negative_sample_loss at step 23400: 0.038466\n",
      "2024-02-29 06:30:13,610 INFO     Training average loss at step 23400: 0.063980\n",
      "2024-02-29 06:33:36,675 INFO     Training average positive_sample_loss at step 23500: 0.086823\n",
      "2024-02-29 06:33:36,676 INFO     Training average negative_sample_loss at step 23500: 0.038363\n",
      "2024-02-29 06:33:36,676 INFO     Training average loss at step 23500: 0.062593\n",
      "2024-02-29 06:36:26,867 INFO     Training average positive_sample_loss at step 23600: 0.085784\n",
      "2024-02-29 06:36:26,868 INFO     Training average negative_sample_loss at step 23600: 0.038103\n",
      "2024-02-29 06:36:26,868 INFO     Training average loss at step 23600: 0.061943\n",
      "2024-02-29 06:39:19,031 INFO     Training average positive_sample_loss at step 23700: 0.088800\n",
      "2024-02-29 06:39:19,031 INFO     Training average negative_sample_loss at step 23700: 0.038232\n",
      "2024-02-29 06:39:19,031 INFO     Training average loss at step 23700: 0.063516\n",
      "2024-02-29 06:42:42,790 INFO     Training average positive_sample_loss at step 23800: 0.089135\n",
      "2024-02-29 06:42:42,791 INFO     Training average negative_sample_loss at step 23800: 0.038478\n",
      "2024-02-29 06:42:42,791 INFO     Training average loss at step 23800: 0.063807\n",
      "2024-02-29 06:45:54,307 INFO     Training average positive_sample_loss at step 23900: 0.083622\n",
      "2024-02-29 06:45:54,308 INFO     Training average negative_sample_loss at step 23900: 0.037377\n",
      "2024-02-29 06:45:54,308 INFO     Training average loss at step 23900: 0.060500\n",
      "2024-02-29 06:48:55,338 INFO     Training average positive_sample_loss at step 24000: 0.087459\n",
      "2024-02-29 06:48:55,338 INFO     Training average negative_sample_loss at step 24000: 0.037824\n",
      "2024-02-29 06:48:55,338 INFO     Training average loss at step 24000: 0.062641\n",
      "2024-02-29 06:52:13,336 INFO     Training average positive_sample_loss at step 24100: 0.088779\n",
      "2024-02-29 06:52:13,337 INFO     Training average negative_sample_loss at step 24100: 0.038756\n",
      "2024-02-29 06:52:13,337 INFO     Training average loss at step 24100: 0.063768\n",
      "2024-02-29 06:55:47,146 INFO     Training average positive_sample_loss at step 24200: 0.085159\n",
      "2024-02-29 06:55:47,147 INFO     Training average negative_sample_loss at step 24200: 0.037904\n",
      "2024-02-29 06:55:47,147 INFO     Training average loss at step 24200: 0.061532\n",
      "2024-02-29 06:59:03,914 INFO     Training average positive_sample_loss at step 24300: 0.085480\n",
      "2024-02-29 06:59:03,915 INFO     Training average negative_sample_loss at step 24300: 0.037515\n",
      "2024-02-29 06:59:03,915 INFO     Training average loss at step 24300: 0.061497\n",
      "2024-02-29 07:01:54,002 INFO     Training average positive_sample_loss at step 24400: 0.088231\n",
      "2024-02-29 07:01:54,002 INFO     Training average negative_sample_loss at step 24400: 0.038059\n",
      "2024-02-29 07:01:54,002 INFO     Training average loss at step 24400: 0.063145\n",
      "2024-02-29 07:05:18,087 INFO     Training average positive_sample_loss at step 24500: 0.087398\n",
      "2024-02-29 07:05:18,087 INFO     Training average negative_sample_loss at step 24500: 0.037799\n",
      "2024-02-29 07:05:18,087 INFO     Training average loss at step 24500: 0.062599\n",
      "2024-02-29 07:08:36,927 INFO     Training average positive_sample_loss at step 24600: 0.083627\n",
      "2024-02-29 07:08:36,927 INFO     Training average negative_sample_loss at step 24600: 0.037131\n",
      "2024-02-29 07:08:36,927 INFO     Training average loss at step 24600: 0.060379\n",
      "2024-02-29 07:11:52,162 INFO     Training average positive_sample_loss at step 24700: 0.087536\n",
      "2024-02-29 07:11:52,163 INFO     Training average negative_sample_loss at step 24700: 0.037762\n",
      "2024-02-29 07:11:52,163 INFO     Training average loss at step 24700: 0.062649\n",
      "2024-02-29 07:15:11,390 INFO     Training average positive_sample_loss at step 24800: 0.089201\n",
      "2024-02-29 07:15:11,390 INFO     Training average negative_sample_loss at step 24800: 0.038061\n",
      "2024-02-29 07:15:11,390 INFO     Training average loss at step 24800: 0.063631\n",
      "2024-02-29 07:18:46,250 INFO     Training average positive_sample_loss at step 24900: 0.083701\n",
      "2024-02-29 07:18:46,250 INFO     Training average negative_sample_loss at step 24900: 0.037177\n",
      "2024-02-29 07:18:46,250 INFO     Training average loss at step 24900: 0.060439\n",
      "2024-02-29 07:22:06,282 INFO     Training average positive_sample_loss at step 25000: 0.085863\n",
      "2024-02-29 07:22:06,282 INFO     Training average negative_sample_loss at step 25000: 0.037767\n",
      "2024-02-29 07:22:06,282 INFO     Training average loss at step 25000: 0.061815\n",
      "2024-02-29 07:25:13,403 INFO     Training average positive_sample_loss at step 25100: 0.088018\n",
      "2024-02-29 07:25:13,404 INFO     Training average negative_sample_loss at step 25100: 0.037852\n",
      "2024-02-29 07:25:13,404 INFO     Training average loss at step 25100: 0.062935\n",
      "2024-02-29 07:28:24,573 INFO     Training average positive_sample_loss at step 25200: 0.085640\n",
      "2024-02-29 07:28:24,574 INFO     Training average negative_sample_loss at step 25200: 0.037643\n",
      "2024-02-29 07:28:24,574 INFO     Training average loss at step 25200: 0.061641\n",
      "2024-02-29 07:32:23,866 INFO     Training average positive_sample_loss at step 25300: 0.084151\n",
      "2024-02-29 07:32:23,867 INFO     Training average negative_sample_loss at step 25300: 0.036887\n",
      "2024-02-29 07:32:23,867 INFO     Training average loss at step 25300: 0.060519\n",
      "2024-02-29 07:35:58,856 INFO     Training average positive_sample_loss at step 25400: 0.087221\n",
      "2024-02-29 07:35:58,857 INFO     Training average negative_sample_loss at step 25400: 0.037392\n",
      "2024-02-29 07:35:58,857 INFO     Training average loss at step 25400: 0.062307\n",
      "2024-02-29 07:39:32,063 INFO     Training average positive_sample_loss at step 25500: 0.088379\n",
      "2024-02-29 07:39:32,063 INFO     Training average negative_sample_loss at step 25500: 0.038082\n",
      "2024-02-29 07:39:32,063 INFO     Training average loss at step 25500: 0.063231\n",
      "2024-02-29 07:42:37,961 INFO     Training average positive_sample_loss at step 25600: 0.082488\n",
      "2024-02-29 07:42:37,961 INFO     Training average negative_sample_loss at step 25600: 0.037204\n",
      "2024-02-29 07:42:37,962 INFO     Training average loss at step 25600: 0.059846\n",
      "2024-02-29 07:46:03,740 INFO     Training average positive_sample_loss at step 25700: 0.085547\n",
      "2024-02-29 07:46:03,740 INFO     Training average negative_sample_loss at step 25700: 0.036687\n",
      "2024-02-29 07:46:03,740 INFO     Training average loss at step 25700: 0.061117\n",
      "2024-02-29 07:49:26,759 INFO     Training average positive_sample_loss at step 25800: 0.088004\n",
      "2024-02-29 07:49:26,760 INFO     Training average negative_sample_loss at step 25800: 0.037718\n",
      "2024-02-29 07:49:26,760 INFO     Training average loss at step 25800: 0.062861\n",
      "2024-02-29 07:53:17,141 INFO     Training average positive_sample_loss at step 25900: 0.083977\n",
      "2024-02-29 07:53:17,141 INFO     Training average negative_sample_loss at step 25900: 0.037318\n",
      "2024-02-29 07:53:17,141 INFO     Training average loss at step 25900: 0.060648\n",
      "2024-02-29 07:56:36,774 INFO     Training average positive_sample_loss at step 26000: 0.084447\n",
      "2024-02-29 07:56:36,774 INFO     Training average negative_sample_loss at step 26000: 0.036686\n",
      "2024-02-29 07:56:36,774 INFO     Training average loss at step 26000: 0.060567\n",
      "2024-02-29 07:59:56,476 INFO     Training average positive_sample_loss at step 26100: 0.087310\n",
      "2024-02-29 07:59:56,477 INFO     Training average negative_sample_loss at step 26100: 0.037681\n",
      "2024-02-29 07:59:56,477 INFO     Training average loss at step 26100: 0.062496\n",
      "2024-02-29 08:03:34,827 INFO     Training average positive_sample_loss at step 26200: 0.086039\n",
      "2024-02-29 08:03:34,827 INFO     Training average negative_sample_loss at step 26200: 0.037401\n",
      "2024-02-29 08:03:34,827 INFO     Training average loss at step 26200: 0.061720\n",
      "2024-02-29 08:07:03,812 INFO     Training average positive_sample_loss at step 26300: 0.083016\n",
      "2024-02-29 08:07:03,812 INFO     Training average negative_sample_loss at step 26300: 0.036526\n",
      "2024-02-29 08:07:03,812 INFO     Training average loss at step 26300: 0.059771\n",
      "2024-02-29 08:10:33,362 INFO     Training average positive_sample_loss at step 26400: 0.085781\n",
      "2024-02-29 08:10:33,363 INFO     Training average negative_sample_loss at step 26400: 0.037081\n",
      "2024-02-29 08:10:33,363 INFO     Training average loss at step 26400: 0.061431\n",
      "2024-02-29 08:13:35,337 INFO     Training average positive_sample_loss at step 26500: 0.087719\n",
      "2024-02-29 08:13:35,338 INFO     Training average negative_sample_loss at step 26500: 0.037608\n",
      "2024-02-29 08:13:35,338 INFO     Training average loss at step 26500: 0.062664\n",
      "2024-02-29 08:16:34,052 INFO     Training average positive_sample_loss at step 26600: 0.082574\n",
      "2024-02-29 08:16:34,053 INFO     Training average negative_sample_loss at step 26600: 0.036636\n",
      "2024-02-29 08:16:34,053 INFO     Training average loss at step 26600: 0.059605\n",
      "2024-02-29 08:19:32,418 INFO     Training average positive_sample_loss at step 26700: 0.084677\n",
      "2024-02-29 08:19:32,418 INFO     Training average negative_sample_loss at step 26700: 0.037014\n",
      "2024-02-29 08:19:32,418 INFO     Training average loss at step 26700: 0.060846\n",
      "2024-02-29 08:23:05,965 INFO     Training average positive_sample_loss at step 26800: 0.086534\n",
      "2024-02-29 08:23:05,966 INFO     Training average negative_sample_loss at step 26800: 0.036902\n",
      "2024-02-29 08:23:05,966 INFO     Training average loss at step 26800: 0.061718\n",
      "2024-02-29 08:26:26,113 INFO     Training average positive_sample_loss at step 26900: 0.084968\n",
      "2024-02-29 08:26:26,114 INFO     Training average negative_sample_loss at step 26900: 0.037233\n",
      "2024-02-29 08:26:26,114 INFO     Training average loss at step 26900: 0.061101\n",
      "2024-02-29 08:29:32,840 INFO     Training average positive_sample_loss at step 27000: 0.083135\n",
      "2024-02-29 08:29:32,840 INFO     Training average negative_sample_loss at step 27000: 0.036280\n",
      "2024-02-29 08:29:32,840 INFO     Training average loss at step 27000: 0.059707\n",
      "2024-02-29 08:32:59,260 INFO     Training average positive_sample_loss at step 27100: 0.086110\n",
      "2024-02-29 08:32:59,261 INFO     Training average negative_sample_loss at step 27100: 0.036646\n",
      "2024-02-29 08:32:59,261 INFO     Training average loss at step 27100: 0.061378\n",
      "2024-02-29 08:36:51,948 INFO     Training average positive_sample_loss at step 27200: 0.087294\n",
      "2024-02-29 08:36:51,949 INFO     Training average negative_sample_loss at step 27200: 0.037702\n",
      "2024-02-29 08:36:51,949 INFO     Training average loss at step 27200: 0.062498\n",
      "2024-02-29 08:39:43,053 INFO     Training average positive_sample_loss at step 27300: 0.081486\n",
      "2024-02-29 08:39:43,054 INFO     Training average negative_sample_loss at step 27300: 0.036360\n",
      "2024-02-29 08:39:43,054 INFO     Training average loss at step 27300: 0.058923\n",
      "2024-02-29 08:42:58,245 INFO     Training average positive_sample_loss at step 27400: 0.084053\n",
      "2024-02-29 08:42:58,245 INFO     Training average negative_sample_loss at step 27400: 0.036533\n",
      "2024-02-29 08:42:58,245 INFO     Training average loss at step 27400: 0.060293\n",
      "2024-02-29 08:46:22,286 INFO     Training average positive_sample_loss at step 27500: 0.087158\n",
      "2024-02-29 08:46:22,286 INFO     Training average negative_sample_loss at step 27500: 0.037101\n",
      "2024-02-29 08:46:22,286 INFO     Training average loss at step 27500: 0.062130\n",
      "2024-02-29 08:49:39,902 INFO     Training average positive_sample_loss at step 27600: 0.083258\n",
      "2024-02-29 08:49:39,902 INFO     Training average negative_sample_loss at step 27600: 0.036725\n",
      "2024-02-29 08:49:39,902 INFO     Training average loss at step 27600: 0.059991\n",
      "2024-02-29 08:52:40,806 INFO     Training average positive_sample_loss at step 27700: 0.082811\n",
      "2024-02-29 08:52:40,806 INFO     Training average negative_sample_loss at step 27700: 0.036384\n",
      "2024-02-29 08:52:40,806 INFO     Training average loss at step 27700: 0.059598\n",
      "2024-02-29 08:56:33,166 INFO     Training average positive_sample_loss at step 27800: 0.086295\n",
      "2024-02-29 08:56:33,167 INFO     Training average negative_sample_loss at step 27800: 0.036775\n",
      "2024-02-29 08:56:33,167 INFO     Training average loss at step 27800: 0.061535\n",
      "2024-02-29 08:59:44,942 INFO     Training average positive_sample_loss at step 27900: 0.085395\n",
      "2024-02-29 08:59:44,943 INFO     Training average negative_sample_loss at step 27900: 0.036835\n",
      "2024-02-29 08:59:44,943 INFO     Training average loss at step 27900: 0.061115\n",
      "2024-02-29 09:03:14,398 INFO     Training average positive_sample_loss at step 28000: 0.082135\n",
      "2024-02-29 09:03:14,399 INFO     Training average negative_sample_loss at step 28000: 0.035974\n",
      "2024-02-29 09:03:14,399 INFO     Training average loss at step 28000: 0.059054\n",
      "2024-02-29 09:06:44,215 INFO     Training average positive_sample_loss at step 28100: 0.085132\n",
      "2024-02-29 09:06:44,215 INFO     Training average negative_sample_loss at step 28100: 0.036909\n",
      "2024-02-29 09:06:44,215 INFO     Training average loss at step 28100: 0.061020\n",
      "2024-02-29 09:10:02,931 INFO     Training average positive_sample_loss at step 28200: 0.085833\n",
      "2024-02-29 09:10:02,932 INFO     Training average negative_sample_loss at step 28200: 0.037095\n",
      "2024-02-29 09:10:02,932 INFO     Training average loss at step 28200: 0.061464\n",
      "2024-02-29 09:13:25,556 INFO     Training average positive_sample_loss at step 28300: 0.081422\n",
      "2024-02-29 09:13:25,556 INFO     Training average negative_sample_loss at step 28300: 0.036087\n",
      "2024-02-29 09:13:25,556 INFO     Training average loss at step 28300: 0.058755\n",
      "2024-02-29 09:16:36,486 INFO     Training average positive_sample_loss at step 28400: 0.083956\n",
      "2024-02-29 09:16:36,487 INFO     Training average negative_sample_loss at step 28400: 0.036117\n",
      "2024-02-29 09:16:36,487 INFO     Training average loss at step 28400: 0.060037\n",
      "2024-02-29 09:19:37,130 INFO     Training average positive_sample_loss at step 28500: 0.085811\n",
      "2024-02-29 09:19:37,131 INFO     Training average negative_sample_loss at step 28500: 0.036722\n",
      "2024-02-29 09:19:37,131 INFO     Training average loss at step 28500: 0.061266\n",
      "2024-02-29 09:22:58,814 INFO     Training average positive_sample_loss at step 28600: 0.083728\n",
      "2024-02-29 09:22:58,814 INFO     Training average negative_sample_loss at step 28600: 0.036503\n",
      "2024-02-29 09:22:58,814 INFO     Training average loss at step 28600: 0.060116\n",
      "2024-02-29 09:26:24,420 INFO     Training average positive_sample_loss at step 28700: 0.082534\n",
      "2024-02-29 09:26:24,421 INFO     Training average negative_sample_loss at step 28700: 0.036195\n",
      "2024-02-29 09:26:24,421 INFO     Training average loss at step 28700: 0.059364\n",
      "2024-02-29 09:30:08,073 INFO     Training average positive_sample_loss at step 28800: 0.084432\n",
      "2024-02-29 09:30:08,073 INFO     Training average negative_sample_loss at step 28800: 0.035800\n",
      "2024-02-29 09:30:08,073 INFO     Training average loss at step 28800: 0.060116\n",
      "2024-02-29 09:33:35,493 INFO     Training average positive_sample_loss at step 28900: 0.086171\n",
      "2024-02-29 09:33:35,493 INFO     Training average negative_sample_loss at step 28900: 0.037007\n",
      "2024-02-29 09:33:35,494 INFO     Training average loss at step 28900: 0.061589\n",
      "2024-02-29 09:36:30,902 INFO     Training average positive_sample_loss at step 29000: 0.080550\n",
      "2024-02-29 09:36:30,902 INFO     Training average negative_sample_loss at step 29000: 0.035711\n",
      "2024-02-29 09:36:30,902 INFO     Training average loss at step 29000: 0.058130\n",
      "2024-02-29 09:40:02,982 INFO     Training average positive_sample_loss at step 29100: 0.083474\n",
      "2024-02-29 09:40:02,982 INFO     Training average negative_sample_loss at step 29100: 0.035977\n",
      "2024-02-29 09:40:02,983 INFO     Training average loss at step 29100: 0.059725\n",
      "2024-02-29 09:43:24,626 INFO     Training average positive_sample_loss at step 29200: 0.085410\n",
      "2024-02-29 09:43:24,627 INFO     Training average negative_sample_loss at step 29200: 0.036554\n",
      "2024-02-29 09:43:24,627 INFO     Training average loss at step 29200: 0.060982\n",
      "2024-02-29 09:46:42,427 INFO     Training average positive_sample_loss at step 29300: 0.082403\n",
      "2024-02-29 09:46:42,427 INFO     Training average negative_sample_loss at step 29300: 0.036368\n",
      "2024-02-29 09:46:42,427 INFO     Training average loss at step 29300: 0.059386\n",
      "2024-02-29 09:50:11,057 INFO     Training average positive_sample_loss at step 29400: 0.082777\n",
      "2024-02-29 09:50:11,057 INFO     Training average negative_sample_loss at step 29400: 0.035913\n",
      "2024-02-29 09:50:11,057 INFO     Training average loss at step 29400: 0.059345\n",
      "2024-02-29 09:53:19,974 INFO     Training average positive_sample_loss at step 29500: 0.085119\n",
      "2024-02-29 09:53:19,975 INFO     Training average negative_sample_loss at step 29500: 0.036233\n",
      "2024-02-29 09:53:19,975 INFO     Training average loss at step 29500: 0.060676\n",
      "2024-02-29 09:56:36,281 INFO     Training average positive_sample_loss at step 29600: 0.084580\n",
      "2024-02-29 09:56:36,282 INFO     Training average negative_sample_loss at step 29600: 0.036305\n",
      "2024-02-29 09:56:36,282 INFO     Training average loss at step 29600: 0.060443\n",
      "2024-02-29 09:59:33,300 INFO     Training average positive_sample_loss at step 29700: 0.080379\n",
      "2024-02-29 09:59:33,300 INFO     Training average negative_sample_loss at step 29700: 0.035443\n",
      "2024-02-29 09:59:33,301 INFO     Training average loss at step 29700: 0.057911\n",
      "2024-02-29 10:02:42,150 INFO     Training average positive_sample_loss at step 29800: 0.084331\n",
      "2024-02-29 10:02:42,151 INFO     Training average negative_sample_loss at step 29800: 0.036112\n",
      "2024-02-29 10:02:42,151 INFO     Training average loss at step 29800: 0.060221\n",
      "2024-02-29 10:05:42,838 INFO     Training average positive_sample_loss at step 29900: 0.085801\n",
      "2024-02-29 10:05:42,838 INFO     Training average negative_sample_loss at step 29900: 0.036467\n",
      "2024-02-29 10:05:42,839 INFO     Training average loss at step 29900: 0.061134\n",
      "2024-02-29 10:08:36,226 INFO     Training average positive_sample_loss at step 30000: 0.080594\n",
      "2024-02-29 10:08:36,226 INFO     Training average negative_sample_loss at step 30000: 0.035682\n",
      "2024-02-29 10:08:36,226 INFO     Training average loss at step 30000: 0.058138\n",
      "2024-02-29 10:08:36,226 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 10:08:36,857 INFO     Evaluating the model... (0/760)\n",
      "2024-02-29 10:09:06,163 INFO     Valid MRR at step 30000: 0.461080\n",
      "2024-02-29 10:09:06,164 INFO     Valid MR at step 30000: 5251.142221\n",
      "2024-02-29 10:09:06,164 INFO     Valid HITS@1 at step 30000: 0.423698\n",
      "2024-02-29 10:09:06,164 INFO     Valid HITS@3 at step 30000: 0.476599\n",
      "2024-02-29 10:09:06,164 INFO     Valid HITS@10 at step 30000: 0.532136\n",
      "2024-02-29 10:11:44,439 INFO     Training average positive_sample_loss at step 30100: 0.082325\n",
      "2024-02-29 10:11:44,439 INFO     Training average negative_sample_loss at step 30100: 0.035407\n",
      "2024-02-29 10:11:44,439 INFO     Training average loss at step 30100: 0.058866\n",
      "2024-02-29 10:14:48,332 INFO     Training average positive_sample_loss at step 30200: 0.084913\n",
      "2024-02-29 10:14:48,333 INFO     Training average negative_sample_loss at step 30200: 0.036323\n",
      "2024-02-29 10:14:48,333 INFO     Training average loss at step 30200: 0.060618\n",
      "2024-02-29 10:17:55,118 INFO     Training average positive_sample_loss at step 30300: 0.083118\n",
      "2024-02-29 10:17:55,119 INFO     Training average negative_sample_loss at step 30300: 0.036125\n",
      "2024-02-29 10:17:55,119 INFO     Training average loss at step 30300: 0.059622\n",
      "2024-02-29 10:21:01,878 INFO     Training average positive_sample_loss at step 30400: 0.081393\n",
      "2024-02-29 10:21:01,879 INFO     Training average negative_sample_loss at step 30400: 0.035503\n",
      "2024-02-29 10:21:01,879 INFO     Training average loss at step 30400: 0.058448\n",
      "2024-02-29 10:24:14,424 INFO     Training average positive_sample_loss at step 30500: 0.083937\n",
      "2024-02-29 10:24:14,424 INFO     Training average negative_sample_loss at step 30500: 0.036207\n",
      "2024-02-29 10:24:14,424 INFO     Training average loss at step 30500: 0.060072\n",
      "2024-02-29 10:27:43,013 INFO     Training average positive_sample_loss at step 30600: 0.085594\n",
      "2024-02-29 10:27:43,013 INFO     Training average negative_sample_loss at step 30600: 0.036137\n",
      "2024-02-29 10:27:43,013 INFO     Training average loss at step 30600: 0.060866\n",
      "2024-02-29 10:30:51,086 INFO     Training average positive_sample_loss at step 30700: 0.079657\n",
      "2024-02-29 10:30:51,086 INFO     Training average negative_sample_loss at step 30700: 0.035304\n",
      "2024-02-29 10:30:51,086 INFO     Training average loss at step 30700: 0.057480\n",
      "2024-02-29 10:34:14,150 INFO     Training average positive_sample_loss at step 30800: 0.083095\n",
      "2024-02-29 10:34:14,150 INFO     Training average negative_sample_loss at step 30800: 0.035723\n",
      "2024-02-29 10:34:14,151 INFO     Training average loss at step 30800: 0.059409\n",
      "2024-02-29 10:37:22,897 INFO     Training average positive_sample_loss at step 30900: 0.084438\n",
      "2024-02-29 10:37:22,898 INFO     Training average negative_sample_loss at step 30900: 0.035921\n",
      "2024-02-29 10:37:22,898 INFO     Training average loss at step 30900: 0.060180\n",
      "2024-02-29 10:40:54,469 INFO     Training average positive_sample_loss at step 31000: 0.080967\n",
      "2024-02-29 10:40:54,470 INFO     Training average negative_sample_loss at step 31000: 0.035562\n",
      "2024-02-29 10:40:54,470 INFO     Training average loss at step 31000: 0.058264\n",
      "2024-02-29 10:44:01,938 INFO     Training average positive_sample_loss at step 31100: 0.081862\n",
      "2024-02-29 10:44:01,938 INFO     Training average negative_sample_loss at step 31100: 0.035616\n",
      "2024-02-29 10:44:01,938 INFO     Training average loss at step 31100: 0.058739\n",
      "2024-02-29 10:47:20,349 INFO     Training average positive_sample_loss at step 31200: 0.084440\n",
      "2024-02-29 10:47:20,350 INFO     Training average negative_sample_loss at step 31200: 0.036034\n",
      "2024-02-29 10:47:20,350 INFO     Training average loss at step 31200: 0.060237\n",
      "2024-02-29 10:51:04,524 INFO     Training average positive_sample_loss at step 31300: 0.083272\n",
      "2024-02-29 10:51:04,525 INFO     Training average negative_sample_loss at step 31300: 0.035928\n",
      "2024-02-29 10:51:04,525 INFO     Training average loss at step 31300: 0.059600\n",
      "2024-02-29 10:54:26,146 INFO     Training average positive_sample_loss at step 31400: 0.080090\n",
      "2024-02-29 10:54:26,147 INFO     Training average negative_sample_loss at step 31400: 0.035148\n",
      "2024-02-29 10:54:26,147 INFO     Training average loss at step 31400: 0.057619\n",
      "2024-02-29 10:57:42,791 INFO     Training average positive_sample_loss at step 31500: 0.083379\n",
      "2024-02-29 10:57:42,792 INFO     Training average negative_sample_loss at step 31500: 0.035588\n",
      "2024-02-29 10:57:42,792 INFO     Training average loss at step 31500: 0.059484\n",
      "2024-02-29 11:00:37,776 INFO     Training average positive_sample_loss at step 31600: 0.084623\n",
      "2024-02-29 11:00:37,776 INFO     Training average negative_sample_loss at step 31600: 0.036059\n",
      "2024-02-29 11:00:37,777 INFO     Training average loss at step 31600: 0.060341\n",
      "2024-02-29 11:04:06,777 INFO     Training average positive_sample_loss at step 31700: 0.079341\n",
      "2024-02-29 11:04:06,778 INFO     Training average negative_sample_loss at step 31700: 0.035110\n",
      "2024-02-29 11:04:06,778 INFO     Training average loss at step 31700: 0.057225\n",
      "2024-02-29 11:07:30,487 INFO     Training average positive_sample_loss at step 31800: 0.082702\n",
      "2024-02-29 11:07:30,488 INFO     Training average negative_sample_loss at step 31800: 0.035304\n",
      "2024-02-29 11:07:30,488 INFO     Training average loss at step 31800: 0.059003\n",
      "2024-02-29 11:10:51,997 INFO     Training average positive_sample_loss at step 31900: 0.084236\n",
      "2024-02-29 11:10:51,997 INFO     Training average negative_sample_loss at step 31900: 0.035757\n",
      "2024-02-29 11:10:51,997 INFO     Training average loss at step 31900: 0.059997\n",
      "2024-02-29 11:14:00,044 INFO     Training average positive_sample_loss at step 32000: 0.081739\n",
      "2024-02-29 11:14:00,045 INFO     Training average negative_sample_loss at step 32000: 0.035736\n",
      "2024-02-29 11:14:00,045 INFO     Training average loss at step 32000: 0.058738\n",
      "2024-02-29 11:17:13,249 INFO     Training average positive_sample_loss at step 32100: 0.080812\n",
      "2024-02-29 11:17:13,249 INFO     Training average negative_sample_loss at step 32100: 0.035303\n",
      "2024-02-29 11:17:13,249 INFO     Training average loss at step 32100: 0.058058\n",
      "2024-02-29 11:21:01,090 INFO     Training average positive_sample_loss at step 32200: 0.083675\n",
      "2024-02-29 11:21:01,091 INFO     Training average negative_sample_loss at step 32200: 0.035375\n",
      "2024-02-29 11:21:01,091 INFO     Training average loss at step 32200: 0.059525\n",
      "2024-02-29 11:24:55,525 INFO     Training average positive_sample_loss at step 32300: 0.083771\n",
      "2024-02-29 11:24:55,525 INFO     Training average negative_sample_loss at step 32300: 0.035884\n",
      "2024-02-29 11:24:55,525 INFO     Training average loss at step 32300: 0.059827\n",
      "2024-02-29 11:28:02,481 INFO     Training average positive_sample_loss at step 32400: 0.078966\n",
      "2024-02-29 11:28:02,482 INFO     Training average negative_sample_loss at step 32400: 0.035134\n",
      "2024-02-29 11:28:02,482 INFO     Training average loss at step 32400: 0.057050\n",
      "2024-02-29 11:31:16,185 INFO     Training average positive_sample_loss at step 32500: 0.082481\n",
      "2024-02-29 11:31:16,186 INFO     Training average negative_sample_loss at step 32500: 0.035442\n",
      "2024-02-29 11:31:16,186 INFO     Training average loss at step 32500: 0.058962\n",
      "2024-02-29 11:34:40,001 INFO     Training average positive_sample_loss at step 32600: 0.083922\n",
      "2024-02-29 11:34:40,001 INFO     Training average negative_sample_loss at step 32600: 0.035226\n",
      "2024-02-29 11:34:40,001 INFO     Training average loss at step 32600: 0.059574\n",
      "2024-02-29 11:38:21,180 INFO     Training average positive_sample_loss at step 32700: 0.080214\n",
      "2024-02-29 11:38:21,181 INFO     Training average negative_sample_loss at step 32700: 0.035192\n",
      "2024-02-29 11:38:21,181 INFO     Training average loss at step 32700: 0.057703\n",
      "2024-02-29 11:41:58,154 INFO     Training average positive_sample_loss at step 32800: 0.080858\n",
      "2024-02-29 11:41:58,155 INFO     Training average negative_sample_loss at step 32800: 0.035035\n",
      "2024-02-29 11:41:58,155 INFO     Training average loss at step 32800: 0.057947\n",
      "2024-02-29 11:45:25,423 INFO     Training average positive_sample_loss at step 32900: 0.083381\n",
      "2024-02-29 11:45:25,424 INFO     Training average negative_sample_loss at step 32900: 0.035285\n",
      "2024-02-29 11:45:25,424 INFO     Training average loss at step 32900: 0.059333\n",
      "2024-02-29 11:48:41,115 INFO     Training average positive_sample_loss at step 33000: 0.082826\n",
      "2024-02-29 11:48:41,115 INFO     Training average negative_sample_loss at step 33000: 0.035610\n",
      "2024-02-29 11:48:41,115 INFO     Training average loss at step 33000: 0.059218\n",
      "2024-02-29 11:51:39,853 INFO     Training average positive_sample_loss at step 33100: 0.079250\n",
      "2024-02-29 11:51:39,854 INFO     Training average negative_sample_loss at step 33100: 0.034934\n",
      "2024-02-29 11:51:39,854 INFO     Training average loss at step 33100: 0.057092\n",
      "2024-02-29 11:54:51,687 INFO     Training average positive_sample_loss at step 33200: 0.082709\n",
      "2024-02-29 11:54:51,688 INFO     Training average negative_sample_loss at step 33200: 0.035143\n",
      "2024-02-29 11:54:51,688 INFO     Training average loss at step 33200: 0.058926\n",
      "2024-02-29 11:57:55,512 INFO     Training average positive_sample_loss at step 33300: 0.084054\n",
      "2024-02-29 11:57:55,512 INFO     Training average negative_sample_loss at step 33300: 0.035645\n",
      "2024-02-29 11:57:55,512 INFO     Training average loss at step 33300: 0.059850\n",
      "2024-02-29 12:01:31,814 INFO     Training average positive_sample_loss at step 33400: 0.079242\n",
      "2024-02-29 12:01:31,815 INFO     Training average negative_sample_loss at step 33400: 0.034499\n",
      "2024-02-29 12:01:31,815 INFO     Training average loss at step 33400: 0.056871\n",
      "2024-02-29 12:05:16,136 INFO     Training average positive_sample_loss at step 33500: 0.081025\n",
      "2024-02-29 12:05:16,137 INFO     Training average negative_sample_loss at step 33500: 0.035045\n",
      "2024-02-29 12:05:16,137 INFO     Training average loss at step 33500: 0.058035\n",
      "2024-02-29 12:08:37,910 INFO     Training average positive_sample_loss at step 33600: 0.083296\n",
      "2024-02-29 12:08:37,910 INFO     Training average negative_sample_loss at step 33600: 0.035415\n",
      "2024-02-29 12:08:37,910 INFO     Training average loss at step 33600: 0.059355\n",
      "2024-02-29 12:11:41,461 INFO     Training average positive_sample_loss at step 33700: 0.081164\n",
      "2024-02-29 12:11:41,461 INFO     Training average negative_sample_loss at step 33700: 0.035347\n",
      "2024-02-29 12:11:41,461 INFO     Training average loss at step 33700: 0.058255\n",
      "2024-02-29 12:14:31,059 INFO     Training average positive_sample_loss at step 33800: 0.079660\n",
      "2024-02-29 12:14:31,060 INFO     Training average negative_sample_loss at step 33800: 0.034656\n",
      "2024-02-29 12:14:31,060 INFO     Training average loss at step 33800: 0.057158\n",
      "2024-02-29 12:17:47,893 INFO     Training average positive_sample_loss at step 33900: 0.082748\n",
      "2024-02-29 12:17:47,893 INFO     Training average negative_sample_loss at step 33900: 0.035220\n",
      "2024-02-29 12:17:47,893 INFO     Training average loss at step 33900: 0.058984\n",
      "2024-02-29 12:21:25,010 INFO     Training average positive_sample_loss at step 34000: 0.084257\n",
      "2024-02-29 12:21:25,011 INFO     Training average negative_sample_loss at step 34000: 0.035473\n",
      "2024-02-29 12:21:25,011 INFO     Training average loss at step 34000: 0.059865\n",
      "2024-02-29 12:27:49,347 INFO     Training average positive_sample_loss at step 34200: 0.081500\n",
      "2024-02-29 12:27:49,347 INFO     Training average negative_sample_loss at step 34200: 0.034863\n",
      "2024-02-29 12:27:49,347 INFO     Training average loss at step 34200: 0.058182\n",
      "2024-02-29 12:31:12,128 INFO     Training average positive_sample_loss at step 34300: 0.083554\n",
      "2024-02-29 12:31:12,128 INFO     Training average negative_sample_loss at step 34300: 0.035281\n",
      "2024-02-29 12:31:12,129 INFO     Training average loss at step 34300: 0.059418\n",
      "2024-02-29 12:34:47,035 INFO     Training average positive_sample_loss at step 34400: 0.080258\n",
      "2024-02-29 12:34:47,035 INFO     Training average negative_sample_loss at step 34400: 0.035046\n",
      "2024-02-29 12:34:47,035 INFO     Training average loss at step 34400: 0.057652\n",
      "2024-02-29 12:37:26,077 INFO     Training average positive_sample_loss at step 34500: 0.080875\n",
      "2024-02-29 12:37:26,078 INFO     Training average negative_sample_loss at step 34500: 0.034788\n",
      "2024-02-29 12:37:26,078 INFO     Training average loss at step 34500: 0.057831\n",
      "2024-02-29 12:40:42,778 INFO     Training average positive_sample_loss at step 34600: 0.082251\n",
      "2024-02-29 12:40:42,778 INFO     Training average negative_sample_loss at step 34600: 0.035017\n",
      "2024-02-29 12:40:42,778 INFO     Training average loss at step 34600: 0.058634\n",
      "2024-02-29 12:44:08,447 INFO     Training average positive_sample_loss at step 34700: 0.081600\n",
      "2024-02-29 12:44:08,447 INFO     Training average negative_sample_loss at step 34700: 0.035261\n",
      "2024-02-29 12:44:08,447 INFO     Training average loss at step 34700: 0.058430\n",
      "2024-02-29 12:47:02,328 INFO     Training average positive_sample_loss at step 34800: 0.078868\n",
      "2024-02-29 12:47:02,328 INFO     Training average negative_sample_loss at step 34800: 0.034489\n",
      "2024-02-29 12:47:02,328 INFO     Training average loss at step 34800: 0.056679\n",
      "2024-02-29 12:50:03,531 INFO     Training average positive_sample_loss at step 34900: 0.081543\n",
      "2024-02-29 12:50:03,531 INFO     Training average negative_sample_loss at step 34900: 0.035006\n",
      "2024-02-29 12:50:03,531 INFO     Training average loss at step 34900: 0.058274\n",
      "2024-02-29 12:53:30,202 INFO     Training average positive_sample_loss at step 35000: 0.083633\n",
      "2024-02-29 12:53:30,203 INFO     Training average negative_sample_loss at step 35000: 0.035067\n",
      "2024-02-29 12:53:30,203 INFO     Training average loss at step 35000: 0.059350\n",
      "2024-02-29 12:56:45,874 INFO     Training average positive_sample_loss at step 35100: 0.078314\n",
      "2024-02-29 12:56:45,874 INFO     Training average negative_sample_loss at step 35100: 0.034003\n",
      "2024-02-29 12:56:45,875 INFO     Training average loss at step 35100: 0.056158\n",
      "2024-02-29 12:59:41,077 INFO     Training average positive_sample_loss at step 35200: 0.080879\n",
      "2024-02-29 12:59:41,078 INFO     Training average negative_sample_loss at step 35200: 0.034832\n",
      "2024-02-29 12:59:41,078 INFO     Training average loss at step 35200: 0.057855\n",
      "2024-02-29 13:03:15,646 INFO     Training average positive_sample_loss at step 35300: 0.082654\n",
      "2024-02-29 13:03:15,647 INFO     Training average negative_sample_loss at step 35300: 0.035207\n",
      "2024-02-29 13:03:15,647 INFO     Training average loss at step 35300: 0.058931\n",
      "2024-02-29 13:06:44,597 INFO     Training average positive_sample_loss at step 35400: 0.080274\n",
      "2024-02-29 13:06:44,598 INFO     Training average negative_sample_loss at step 35400: 0.034786\n",
      "2024-02-29 13:06:44,598 INFO     Training average loss at step 35400: 0.057530\n",
      "2024-02-29 13:09:48,439 INFO     Training average positive_sample_loss at step 35500: 0.079412\n",
      "2024-02-29 13:09:48,440 INFO     Training average negative_sample_loss at step 35500: 0.034408\n",
      "2024-02-29 13:09:48,440 INFO     Training average loss at step 35500: 0.056910\n",
      "2024-02-29 13:12:53,064 INFO     Training average positive_sample_loss at step 35600: 0.081918\n",
      "2024-02-29 13:12:53,064 INFO     Training average negative_sample_loss at step 35600: 0.034936\n",
      "2024-02-29 13:12:53,064 INFO     Training average loss at step 35600: 0.058427\n",
      "2024-02-29 13:16:09,899 INFO     Training average positive_sample_loss at step 35700: 0.083158\n",
      "2024-02-29 13:16:09,900 INFO     Training average negative_sample_loss at step 35700: 0.035197\n",
      "2024-02-29 13:16:09,900 INFO     Training average loss at step 35700: 0.059178\n",
      "2024-02-29 13:19:11,757 INFO     Training average positive_sample_loss at step 35800: 0.077726\n",
      "2024-02-29 13:19:11,758 INFO     Training average negative_sample_loss at step 35800: 0.034220\n",
      "2024-02-29 13:19:11,758 INFO     Training average loss at step 35800: 0.055973\n",
      "2024-02-29 13:22:13,951 INFO     Training average positive_sample_loss at step 35900: 0.080749\n",
      "2024-02-29 13:22:13,951 INFO     Training average negative_sample_loss at step 35900: 0.034351\n",
      "2024-02-29 13:22:13,951 INFO     Training average loss at step 35900: 0.057550\n",
      "2024-02-29 13:25:13,862 INFO     Training average positive_sample_loss at step 36000: 0.082949\n",
      "2024-02-29 13:25:13,863 INFO     Training average negative_sample_loss at step 36000: 0.035152\n",
      "2024-02-29 13:25:13,863 INFO     Training average loss at step 36000: 0.059051\n",
      "2024-02-29 13:28:33,843 INFO     Training average positive_sample_loss at step 36100: 0.078954\n",
      "2024-02-29 13:28:33,844 INFO     Training average negative_sample_loss at step 36100: 0.034452\n",
      "2024-02-29 13:28:33,844 INFO     Training average loss at step 36100: 0.056703\n",
      "2024-02-29 13:31:23,492 INFO     Training average positive_sample_loss at step 36200: 0.079847\n",
      "2024-02-29 13:31:23,493 INFO     Training average negative_sample_loss at step 36200: 0.034278\n",
      "2024-02-29 13:31:23,493 INFO     Training average loss at step 36200: 0.057063\n",
      "2024-02-29 13:34:06,171 INFO     Training average positive_sample_loss at step 36300: 0.081856\n",
      "2024-02-29 13:34:06,171 INFO     Training average negative_sample_loss at step 36300: 0.034984\n",
      "2024-02-29 13:34:06,171 INFO     Training average loss at step 36300: 0.058420\n",
      "2024-02-29 13:37:00,390 INFO     Training average positive_sample_loss at step 36400: 0.081525\n",
      "2024-02-29 13:37:00,390 INFO     Training average negative_sample_loss at step 36400: 0.034895\n",
      "2024-02-29 13:37:00,390 INFO     Training average loss at step 36400: 0.058210\n",
      "2024-02-29 13:40:10,778 INFO     Training average positive_sample_loss at step 36500: 0.078537\n",
      "2024-02-29 13:40:10,778 INFO     Training average negative_sample_loss at step 36500: 0.034224\n",
      "2024-02-29 13:40:10,778 INFO     Training average loss at step 36500: 0.056380\n",
      "2024-02-29 13:42:48,844 INFO     Training average positive_sample_loss at step 36600: 0.080938\n",
      "2024-02-29 13:42:48,845 INFO     Training average negative_sample_loss at step 36600: 0.034092\n",
      "2024-02-29 13:42:48,845 INFO     Training average loss at step 36600: 0.057515\n",
      "2024-02-29 13:45:43,349 INFO     Training average positive_sample_loss at step 36700: 0.082698\n",
      "2024-02-29 13:45:43,350 INFO     Training average negative_sample_loss at step 36700: 0.035087\n",
      "2024-02-29 13:45:43,350 INFO     Training average loss at step 36700: 0.058892\n",
      "2024-02-29 13:49:00,492 INFO     Training average positive_sample_loss at step 36800: 0.078230\n",
      "2024-02-29 13:49:00,492 INFO     Training average negative_sample_loss at step 36800: 0.034248\n",
      "2024-02-29 13:49:00,493 INFO     Training average loss at step 36800: 0.056239\n",
      "2024-02-29 13:52:05,206 INFO     Training average positive_sample_loss at step 36900: 0.080372\n",
      "2024-02-29 13:52:05,206 INFO     Training average negative_sample_loss at step 36900: 0.034363\n",
      "2024-02-29 13:52:05,206 INFO     Training average loss at step 36900: 0.057368\n",
      "2024-02-29 13:55:15,762 INFO     Training average positive_sample_loss at step 37000: 0.081708\n",
      "2024-02-29 13:55:15,763 INFO     Training average negative_sample_loss at step 37000: 0.034840\n",
      "2024-02-29 13:55:15,763 INFO     Training average loss at step 37000: 0.058274\n",
      "2024-02-29 13:58:40,461 INFO     Training average positive_sample_loss at step 37100: 0.079848\n",
      "2024-02-29 13:58:40,461 INFO     Training average negative_sample_loss at step 37100: 0.034244\n",
      "2024-02-29 13:58:40,461 INFO     Training average loss at step 37100: 0.057046\n",
      "2024-02-29 14:01:36,083 INFO     Training average positive_sample_loss at step 37200: 0.078886\n",
      "2024-02-29 14:01:36,083 INFO     Training average negative_sample_loss at step 37200: 0.034144\n",
      "2024-02-29 14:01:36,083 INFO     Training average loss at step 37200: 0.056515\n",
      "2024-02-29 14:05:03,153 INFO     Training average positive_sample_loss at step 37300: 0.080750\n",
      "2024-02-29 14:05:03,153 INFO     Training average negative_sample_loss at step 37300: 0.034375\n",
      "2024-02-29 14:05:03,153 INFO     Training average loss at step 37300: 0.057562\n",
      "2024-02-29 14:08:05,487 INFO     Training average positive_sample_loss at step 37400: 0.082741\n",
      "2024-02-29 14:08:05,488 INFO     Training average negative_sample_loss at step 37400: 0.035106\n",
      "2024-02-29 14:08:05,488 INFO     Training average loss at step 37400: 0.058924\n",
      "2024-02-29 14:11:08,748 INFO     Training average positive_sample_loss at step 37500: 0.077463\n",
      "2024-02-29 14:11:08,748 INFO     Training average negative_sample_loss at step 37500: 0.033827\n",
      "2024-02-29 14:11:08,749 INFO     Training average loss at step 37500: 0.055645\n",
      "2024-02-29 14:14:01,340 INFO     Training average positive_sample_loss at step 37600: 0.080373\n",
      "2024-02-29 14:14:01,340 INFO     Training average negative_sample_loss at step 37600: 0.034165\n",
      "2024-02-29 14:14:01,340 INFO     Training average loss at step 37600: 0.057269\n",
      "2024-02-29 14:17:04,049 INFO     Training average positive_sample_loss at step 37700: 0.081747\n",
      "2024-02-29 14:17:04,049 INFO     Training average negative_sample_loss at step 37700: 0.034828\n",
      "2024-02-29 14:17:04,049 INFO     Training average loss at step 37700: 0.058288\n",
      "2024-02-29 14:20:24,406 INFO     Training average positive_sample_loss at step 37800: 0.079041\n",
      "2024-02-29 14:20:24,407 INFO     Training average negative_sample_loss at step 37800: 0.034305\n",
      "2024-02-29 14:20:24,407 INFO     Training average loss at step 37800: 0.056673\n",
      "2024-02-29 14:23:33,706 INFO     Training average positive_sample_loss at step 37900: 0.078889\n",
      "2024-02-29 14:23:33,706 INFO     Training average negative_sample_loss at step 37900: 0.034191\n",
      "2024-02-29 14:23:33,706 INFO     Training average loss at step 37900: 0.056540\n",
      "2024-02-29 14:26:54,191 INFO     Training average positive_sample_loss at step 38000: 0.081702\n",
      "2024-02-29 14:26:54,191 INFO     Training average negative_sample_loss at step 38000: 0.034364\n",
      "2024-02-29 14:26:54,191 INFO     Training average loss at step 38000: 0.058033\n",
      "2024-02-29 14:30:23,121 INFO     Training average positive_sample_loss at step 38100: 0.080378\n",
      "2024-02-29 14:30:23,121 INFO     Training average negative_sample_loss at step 38100: 0.034330\n",
      "2024-02-29 14:30:23,121 INFO     Training average loss at step 38100: 0.057354\n",
      "2024-02-29 14:33:45,615 INFO     Training average positive_sample_loss at step 38200: 0.077903\n",
      "2024-02-29 14:33:45,615 INFO     Training average negative_sample_loss at step 38200: 0.033731\n",
      "2024-02-29 14:33:45,615 INFO     Training average loss at step 38200: 0.055817\n",
      "2024-02-29 14:36:54,066 INFO     Training average positive_sample_loss at step 38300: 0.080000\n",
      "2024-02-29 14:36:54,067 INFO     Training average negative_sample_loss at step 38300: 0.034013\n",
      "2024-02-29 14:36:54,067 INFO     Training average loss at step 38300: 0.057007\n",
      "2024-02-29 14:40:02,137 INFO     Training average positive_sample_loss at step 38400: 0.082625\n",
      "2024-02-29 14:40:02,137 INFO     Training average negative_sample_loss at step 38400: 0.034898\n",
      "2024-02-29 14:40:02,137 INFO     Training average loss at step 38400: 0.058761\n",
      "2024-02-29 14:43:13,882 INFO     Training average positive_sample_loss at step 38500: 0.077712\n",
      "2024-02-29 14:43:13,883 INFO     Training average negative_sample_loss at step 38500: 0.033622\n",
      "2024-02-29 14:43:13,883 INFO     Training average loss at step 38500: 0.055667\n",
      "2024-02-29 14:46:20,260 INFO     Training average positive_sample_loss at step 38600: 0.079071\n",
      "2024-02-29 14:46:20,260 INFO     Training average negative_sample_loss at step 38600: 0.034179\n",
      "2024-02-29 14:46:20,260 INFO     Training average loss at step 38600: 0.056625\n",
      "2024-02-29 14:49:19,587 INFO     Training average positive_sample_loss at step 38700: 0.081491\n",
      "2024-02-29 14:49:19,587 INFO     Training average negative_sample_loss at step 38700: 0.034608\n",
      "2024-02-29 14:49:19,587 INFO     Training average loss at step 38700: 0.058049\n",
      "2024-02-29 14:52:15,102 INFO     Training average positive_sample_loss at step 38800: 0.079433\n",
      "2024-02-29 14:52:15,103 INFO     Training average negative_sample_loss at step 38800: 0.034297\n",
      "2024-02-29 14:52:15,103 INFO     Training average loss at step 38800: 0.056865\n",
      "2024-02-29 14:55:34,941 INFO     Training average positive_sample_loss at step 38900: 0.077992\n",
      "2024-02-29 14:55:34,942 INFO     Training average negative_sample_loss at step 38900: 0.033637\n",
      "2024-02-29 14:55:34,942 INFO     Training average loss at step 38900: 0.055814\n",
      "2024-02-29 14:59:05,281 INFO     Training average positive_sample_loss at step 39000: 0.080849\n",
      "2024-02-29 14:59:05,282 INFO     Training average negative_sample_loss at step 39000: 0.034226\n",
      "2024-02-29 14:59:05,282 INFO     Training average loss at step 39000: 0.057537\n",
      "2024-02-29 15:02:26,876 INFO     Training average positive_sample_loss at step 39100: 0.082386\n",
      "2024-02-29 15:02:26,877 INFO     Training average negative_sample_loss at step 39100: 0.034781\n",
      "2024-02-29 15:02:26,877 INFO     Training average loss at step 39100: 0.058584\n",
      "2024-02-29 15:05:25,229 INFO     Training average positive_sample_loss at step 39200: 0.076996\n",
      "2024-02-29 15:05:25,229 INFO     Training average negative_sample_loss at step 39200: 0.033728\n",
      "2024-02-29 15:05:25,229 INFO     Training average loss at step 39200: 0.055362\n",
      "2024-02-29 15:08:30,920 INFO     Training average positive_sample_loss at step 39300: 0.079367\n",
      "2024-02-29 15:08:30,920 INFO     Training average negative_sample_loss at step 39300: 0.033793\n",
      "2024-02-29 15:08:30,920 INFO     Training average loss at step 39300: 0.056580\n",
      "2024-02-29 15:11:33,759 INFO     Training average positive_sample_loss at step 39400: 0.081495\n",
      "2024-02-29 15:11:33,759 INFO     Training average negative_sample_loss at step 39400: 0.034295\n",
      "2024-02-29 15:11:33,759 INFO     Training average loss at step 39400: 0.057895\n",
      "2024-02-29 15:14:50,266 INFO     Training average positive_sample_loss at step 39500: 0.078076\n",
      "2024-02-29 15:14:50,266 INFO     Training average negative_sample_loss at step 39500: 0.034096\n",
      "2024-02-29 15:14:50,267 INFO     Training average loss at step 39500: 0.056086\n",
      "2024-02-29 15:18:23,604 INFO     Training average positive_sample_loss at step 39600: 0.079077\n",
      "2024-02-29 15:18:23,604 INFO     Training average negative_sample_loss at step 39600: 0.033914\n",
      "2024-02-29 15:18:23,604 INFO     Training average loss at step 39600: 0.056496\n",
      "2024-02-29 15:21:54,916 INFO     Training average positive_sample_loss at step 39700: 0.080678\n",
      "2024-02-29 15:21:54,916 INFO     Training average negative_sample_loss at step 39700: 0.033909\n",
      "2024-02-29 15:21:54,917 INFO     Training average loss at step 39700: 0.057294\n",
      "2024-02-29 15:25:20,263 INFO     Training average positive_sample_loss at step 39800: 0.080714\n",
      "2024-02-29 15:25:20,264 INFO     Training average negative_sample_loss at step 39800: 0.034380\n",
      "2024-02-29 15:25:20,264 INFO     Training average loss at step 39800: 0.057547\n",
      "2024-02-29 15:28:12,466 INFO     Training average positive_sample_loss at step 39900: 0.076907\n",
      "2024-02-29 15:28:12,467 INFO     Training average negative_sample_loss at step 39900: 0.033766\n",
      "2024-02-29 15:28:12,467 INFO     Training average loss at step 39900: 0.055336\n",
      "2024-02-29 15:31:14,893 INFO     Change learning_rate to 0.000005 at step 40000\n",
      "2024-02-29 15:31:16,110 INFO     Training average positive_sample_loss at step 40000: 0.080296\n",
      "2024-02-29 15:31:16,110 INFO     Training average negative_sample_loss at step 40000: 0.034247\n",
      "2024-02-29 15:31:16,110 INFO     Training average loss at step 40000: 0.057272\n",
      "2024-02-29 15:31:16,110 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 15:31:16,664 INFO     Evaluating the model... (0/760)\n",
      "2024-02-29 15:31:46,313 INFO     Valid MRR at step 40000: 0.460638\n",
      "2024-02-29 15:31:46,314 INFO     Valid MR at step 40000: 4898.660844\n",
      "2024-02-29 15:31:46,314 INFO     Valid HITS@1 at step 40000: 0.419413\n",
      "2024-02-29 15:31:46,314 INFO     Valid HITS@3 at step 40000: 0.476763\n",
      "2024-02-29 15:31:46,314 INFO     Valid HITS@10 at step 40000: 0.542189\n",
      "2024-02-29 15:34:37,398 INFO     Training average positive_sample_loss at step 40100: 0.081837\n",
      "2024-02-29 15:34:37,398 INFO     Training average negative_sample_loss at step 40100: 0.032719\n",
      "2024-02-29 15:34:37,398 INFO     Training average loss at step 40100: 0.057278\n",
      "2024-02-29 15:37:48,126 INFO     Training average positive_sample_loss at step 40200: 0.076137\n",
      "2024-02-29 15:37:48,127 INFO     Training average negative_sample_loss at step 40200: 0.032398\n",
      "2024-02-29 15:37:48,127 INFO     Training average loss at step 40200: 0.054268\n",
      "2024-02-29 15:40:57,373 INFO     Training average positive_sample_loss at step 40300: 0.074367\n",
      "2024-02-29 15:40:57,374 INFO     Training average negative_sample_loss at step 40300: 0.031557\n",
      "2024-02-29 15:40:57,374 INFO     Training average loss at step 40300: 0.052962\n",
      "2024-02-29 15:43:59,252 INFO     Training average positive_sample_loss at step 40400: 0.075641\n",
      "2024-02-29 15:43:59,253 INFO     Training average negative_sample_loss at step 40400: 0.031817\n",
      "2024-02-29 15:43:59,253 INFO     Training average loss at step 40400: 0.053729\n",
      "2024-02-29 15:47:02,204 INFO     Training average positive_sample_loss at step 40500: 0.074050\n",
      "2024-02-29 15:47:02,205 INFO     Training average negative_sample_loss at step 40500: 0.031782\n",
      "2024-02-29 15:47:02,205 INFO     Training average loss at step 40500: 0.052916\n",
      "2024-02-29 15:49:47,357 INFO     Training average positive_sample_loss at step 40600: 0.073259\n",
      "2024-02-29 15:49:47,358 INFO     Training average negative_sample_loss at step 40600: 0.031996\n",
      "2024-02-29 15:49:47,358 INFO     Training average loss at step 40600: 0.052627\n",
      "2024-02-29 15:52:40,959 INFO     Training average positive_sample_loss at step 40700: 0.073649\n",
      "2024-02-29 15:52:40,960 INFO     Training average negative_sample_loss at step 40700: 0.031626\n",
      "2024-02-29 15:52:40,960 INFO     Training average loss at step 40700: 0.052637\n",
      "2024-02-29 15:56:13,877 INFO     Training average positive_sample_loss at step 40800: 0.073849\n",
      "2024-02-29 15:56:13,878 INFO     Training average negative_sample_loss at step 40800: 0.031910\n",
      "2024-02-29 15:56:13,878 INFO     Training average loss at step 40800: 0.052880\n",
      "2024-02-29 15:59:01,804 INFO     Training average positive_sample_loss at step 40900: 0.072565\n",
      "2024-02-29 15:59:01,805 INFO     Training average negative_sample_loss at step 40900: 0.031606\n",
      "2024-02-29 15:59:01,805 INFO     Training average loss at step 40900: 0.052085\n",
      "2024-02-29 16:02:17,257 INFO     Training average positive_sample_loss at step 41000: 0.072221\n",
      "2024-02-29 16:02:17,257 INFO     Training average negative_sample_loss at step 41000: 0.031845\n",
      "2024-02-29 16:02:17,258 INFO     Training average loss at step 41000: 0.052033\n",
      "2024-02-29 16:05:10,246 INFO     Training average positive_sample_loss at step 41100: 0.073115\n",
      "2024-02-29 16:05:10,246 INFO     Training average negative_sample_loss at step 41100: 0.032077\n",
      "2024-02-29 16:05:10,246 INFO     Training average loss at step 41100: 0.052596\n",
      "2024-02-29 16:08:14,383 INFO     Training average positive_sample_loss at step 41200: 0.071945\n",
      "2024-02-29 16:08:14,384 INFO     Training average negative_sample_loss at step 41200: 0.032010\n",
      "2024-02-29 16:08:14,384 INFO     Training average loss at step 41200: 0.051977\n",
      "2024-02-29 16:11:09,553 INFO     Training average positive_sample_loss at step 41300: 0.071995\n",
      "2024-02-29 16:11:09,553 INFO     Training average negative_sample_loss at step 41300: 0.031765\n",
      "2024-02-29 16:11:09,553 INFO     Training average loss at step 41300: 0.051880\n",
      "2024-02-29 16:14:02,390 INFO     Training average positive_sample_loss at step 41400: 0.072564\n",
      "2024-02-29 16:14:02,390 INFO     Training average negative_sample_loss at step 41400: 0.031801\n",
      "2024-02-29 16:14:02,390 INFO     Training average loss at step 41400: 0.052182\n",
      "2024-02-29 16:17:19,644 INFO     Training average positive_sample_loss at step 41500: 0.072441\n",
      "2024-02-29 16:17:19,644 INFO     Training average negative_sample_loss at step 41500: 0.031812\n",
      "2024-02-29 16:17:19,644 INFO     Training average loss at step 41500: 0.052126\n",
      "2024-02-29 16:20:20,413 INFO     Training average positive_sample_loss at step 41600: 0.071564\n",
      "2024-02-29 16:20:20,414 INFO     Training average negative_sample_loss at step 41600: 0.031654\n",
      "2024-02-29 16:20:20,414 INFO     Training average loss at step 41600: 0.051609\n",
      "2024-02-29 16:23:16,063 INFO     Training average positive_sample_loss at step 41700: 0.071994\n",
      "2024-02-29 16:23:16,063 INFO     Training average negative_sample_loss at step 41700: 0.031889\n",
      "2024-02-29 16:23:16,063 INFO     Training average loss at step 41700: 0.051942\n",
      "2024-02-29 16:26:53,807 INFO     Training average positive_sample_loss at step 41800: 0.072429\n",
      "2024-02-29 16:26:53,808 INFO     Training average negative_sample_loss at step 41800: 0.032167\n",
      "2024-02-29 16:26:53,808 INFO     Training average loss at step 41800: 0.052298\n",
      "2024-02-29 16:30:29,412 INFO     Training average positive_sample_loss at step 41900: 0.071395\n",
      "2024-02-29 16:30:29,413 INFO     Training average negative_sample_loss at step 41900: 0.031893\n",
      "2024-02-29 16:30:29,413 INFO     Training average loss at step 41900: 0.051644\n",
      "2024-02-29 16:34:18,785 INFO     Training average positive_sample_loss at step 42000: 0.071404\n",
      "2024-02-29 16:34:18,786 INFO     Training average negative_sample_loss at step 42000: 0.031894\n",
      "2024-02-29 16:34:18,786 INFO     Training average loss at step 42000: 0.051649\n",
      "2024-02-29 16:37:42,859 INFO     Training average positive_sample_loss at step 42100: 0.072075\n",
      "2024-02-29 16:37:42,860 INFO     Training average negative_sample_loss at step 42100: 0.031754\n",
      "2024-02-29 16:37:42,860 INFO     Training average loss at step 42100: 0.051915\n",
      "2024-02-29 16:40:55,528 INFO     Training average positive_sample_loss at step 42200: 0.071996\n",
      "2024-02-29 16:40:55,528 INFO     Training average negative_sample_loss at step 42200: 0.032030\n",
      "2024-02-29 16:40:55,528 INFO     Training average loss at step 42200: 0.052013\n",
      "2024-02-29 16:44:16,616 INFO     Training average positive_sample_loss at step 42300: 0.071079\n",
      "2024-02-29 16:44:16,617 INFO     Training average negative_sample_loss at step 42300: 0.031926\n",
      "2024-02-29 16:44:16,617 INFO     Training average loss at step 42300: 0.051503\n",
      "2024-02-29 16:47:30,206 INFO     Training average positive_sample_loss at step 42400: 0.071378\n",
      "2024-02-29 16:47:30,206 INFO     Training average negative_sample_loss at step 42400: 0.031586\n",
      "2024-02-29 16:47:30,206 INFO     Training average loss at step 42400: 0.051482\n",
      "2024-02-29 16:50:59,752 INFO     Training average positive_sample_loss at step 42500: 0.071938\n",
      "2024-02-29 16:50:59,753 INFO     Training average negative_sample_loss at step 42500: 0.031957\n",
      "2024-02-29 16:50:59,753 INFO     Training average loss at step 42500: 0.051948\n",
      "2024-02-29 16:53:57,994 INFO     Training average positive_sample_loss at step 42600: 0.071178\n",
      "2024-02-29 16:53:57,994 INFO     Training average negative_sample_loss at step 42600: 0.031957\n",
      "2024-02-29 16:53:57,995 INFO     Training average loss at step 42600: 0.051568\n",
      "2024-02-29 16:57:15,278 INFO     Training average positive_sample_loss at step 42700: 0.071246\n",
      "2024-02-29 16:57:15,278 INFO     Training average negative_sample_loss at step 42700: 0.031701\n",
      "2024-02-29 16:57:15,278 INFO     Training average loss at step 42700: 0.051474\n",
      "2024-02-29 17:00:42,362 INFO     Training average positive_sample_loss at step 42800: 0.071755\n",
      "2024-02-29 17:00:42,363 INFO     Training average negative_sample_loss at step 42800: 0.031785\n",
      "2024-02-29 17:00:42,363 INFO     Training average loss at step 42800: 0.051770\n",
      "2024-02-29 17:04:09,658 INFO     Training average positive_sample_loss at step 42900: 0.071321\n",
      "2024-02-29 17:04:09,659 INFO     Training average negative_sample_loss at step 42900: 0.031788\n",
      "2024-02-29 17:04:09,659 INFO     Training average loss at step 42900: 0.051555\n",
      "2024-02-29 17:07:26,077 INFO     Training average positive_sample_loss at step 43000: 0.071005\n",
      "2024-02-29 17:07:26,077 INFO     Training average negative_sample_loss at step 43000: 0.031756\n",
      "2024-02-29 17:07:26,077 INFO     Training average loss at step 43000: 0.051380\n",
      "2024-02-29 17:10:22,049 INFO     Training average positive_sample_loss at step 43100: 0.071315\n",
      "2024-02-29 17:10:22,050 INFO     Training average negative_sample_loss at step 43100: 0.031760\n",
      "2024-02-29 17:10:22,050 INFO     Training average loss at step 43100: 0.051538\n",
      "2024-02-29 17:13:39,928 INFO     Training average positive_sample_loss at step 43200: 0.071403\n",
      "2024-02-29 17:13:39,928 INFO     Training average negative_sample_loss at step 43200: 0.031878\n",
      "2024-02-29 17:13:39,928 INFO     Training average loss at step 43200: 0.051641\n",
      "2024-02-29 17:16:46,000 INFO     Training average positive_sample_loss at step 43300: 0.070606\n",
      "2024-02-29 17:16:46,001 INFO     Training average negative_sample_loss at step 43300: 0.031582\n",
      "2024-02-29 17:16:46,001 INFO     Training average loss at step 43300: 0.051094\n",
      "2024-02-29 17:19:52,881 INFO     Training average positive_sample_loss at step 43400: 0.071419\n",
      "2024-02-29 17:19:52,882 INFO     Training average negative_sample_loss at step 43400: 0.031764\n",
      "2024-02-29 17:19:52,882 INFO     Training average loss at step 43400: 0.051591\n",
      "2024-02-29 17:22:54,733 INFO     Training average positive_sample_loss at step 43500: 0.071590\n",
      "2024-02-29 17:22:54,733 INFO     Training average negative_sample_loss at step 43500: 0.031920\n",
      "2024-02-29 17:22:54,733 INFO     Training average loss at step 43500: 0.051755\n",
      "2024-02-29 17:26:16,843 INFO     Training average positive_sample_loss at step 43600: 0.071326\n",
      "2024-02-29 17:26:16,843 INFO     Training average negative_sample_loss at step 43600: 0.031757\n",
      "2024-02-29 17:26:16,843 INFO     Training average loss at step 43600: 0.051542\n",
      "2024-02-29 17:29:15,469 INFO     Training average positive_sample_loss at step 43700: 0.070697\n",
      "2024-02-29 17:29:15,469 INFO     Training average negative_sample_loss at step 43700: 0.031567\n",
      "2024-02-29 17:29:15,470 INFO     Training average loss at step 43700: 0.051132\n",
      "2024-02-29 17:32:44,940 INFO     Training average positive_sample_loss at step 43800: 0.071518\n",
      "2024-02-29 17:32:44,940 INFO     Training average negative_sample_loss at step 43800: 0.031774\n",
      "2024-02-29 17:32:44,940 INFO     Training average loss at step 43800: 0.051646\n",
      "2024-02-29 17:35:52,340 INFO     Training average positive_sample_loss at step 43900: 0.071017\n",
      "2024-02-29 17:35:52,340 INFO     Training average negative_sample_loss at step 43900: 0.031842\n",
      "2024-02-29 17:35:52,340 INFO     Training average loss at step 43900: 0.051430\n",
      "2024-02-29 17:39:11,654 INFO     Training average positive_sample_loss at step 44000: 0.071094\n",
      "2024-02-29 17:39:11,654 INFO     Training average negative_sample_loss at step 44000: 0.031479\n",
      "2024-02-29 17:39:11,654 INFO     Training average loss at step 44000: 0.051287\n",
      "2024-02-29 17:42:24,396 INFO     Training average positive_sample_loss at step 44100: 0.071021\n",
      "2024-02-29 17:42:24,396 INFO     Training average negative_sample_loss at step 44100: 0.031682\n",
      "2024-02-29 17:42:24,396 INFO     Training average loss at step 44100: 0.051351\n",
      "2024-02-29 17:45:59,399 INFO     Training average positive_sample_loss at step 44200: 0.071785\n",
      "2024-02-29 17:45:59,400 INFO     Training average negative_sample_loss at step 44200: 0.031856\n",
      "2024-02-29 17:45:59,400 INFO     Training average loss at step 44200: 0.051821\n",
      "2024-02-29 17:49:06,220 INFO     Training average positive_sample_loss at step 44300: 0.070559\n",
      "2024-02-29 17:49:06,221 INFO     Training average negative_sample_loss at step 44300: 0.031766\n",
      "2024-02-29 17:49:06,221 INFO     Training average loss at step 44300: 0.051163\n",
      "2024-02-29 17:52:03,931 INFO     Training average positive_sample_loss at step 44400: 0.071344\n",
      "2024-02-29 17:52:03,932 INFO     Training average negative_sample_loss at step 44400: 0.031531\n",
      "2024-02-29 17:52:03,932 INFO     Training average loss at step 44400: 0.051437\n",
      "2024-02-29 17:55:22,365 INFO     Training average positive_sample_loss at step 44500: 0.071403\n",
      "2024-02-29 17:55:22,366 INFO     Training average negative_sample_loss at step 44500: 0.031663\n",
      "2024-02-29 17:55:22,366 INFO     Training average loss at step 44500: 0.051533\n",
      "2024-02-29 17:58:38,759 INFO     Training average positive_sample_loss at step 44600: 0.070787\n",
      "2024-02-29 17:58:38,759 INFO     Training average negative_sample_loss at step 44600: 0.031523\n",
      "2024-02-29 17:58:38,759 INFO     Training average loss at step 44600: 0.051155\n",
      "2024-02-29 18:01:34,870 INFO     Training average positive_sample_loss at step 44700: 0.071077\n",
      "2024-02-29 18:01:34,871 INFO     Training average negative_sample_loss at step 44700: 0.031579\n",
      "2024-02-29 18:01:34,871 INFO     Training average loss at step 44700: 0.051328\n",
      "2024-02-29 18:04:49,462 INFO     Training average positive_sample_loss at step 44800: 0.071150\n",
      "2024-02-29 18:04:49,463 INFO     Training average negative_sample_loss at step 44800: 0.031639\n",
      "2024-02-29 18:04:49,463 INFO     Training average loss at step 44800: 0.051395\n",
      "2024-02-29 18:08:39,459 INFO     Training average positive_sample_loss at step 44900: 0.071454\n",
      "2024-02-29 18:08:39,459 INFO     Training average negative_sample_loss at step 44900: 0.031802\n",
      "2024-02-29 18:08:39,459 INFO     Training average loss at step 44900: 0.051628\n",
      "2024-02-29 18:12:10,574 INFO     Training average positive_sample_loss at step 45000: 0.070302\n",
      "2024-02-29 18:12:10,575 INFO     Training average negative_sample_loss at step 45000: 0.031102\n",
      "2024-02-29 18:12:10,575 INFO     Training average loss at step 45000: 0.050702\n",
      "2024-02-29 18:15:12,282 INFO     Training average positive_sample_loss at step 45100: 0.071110\n",
      "2024-02-29 18:15:12,282 INFO     Training average negative_sample_loss at step 45100: 0.031710\n",
      "2024-02-29 18:15:12,282 INFO     Training average loss at step 45100: 0.051410\n",
      "2024-02-29 18:18:43,172 INFO     Training average positive_sample_loss at step 45200: 0.071767\n",
      "2024-02-29 18:18:43,173 INFO     Training average negative_sample_loss at step 45200: 0.031808\n",
      "2024-02-29 18:18:43,173 INFO     Training average loss at step 45200: 0.051788\n",
      "2024-02-29 18:22:00,300 INFO     Training average positive_sample_loss at step 45300: 0.071001\n",
      "2024-02-29 18:22:00,301 INFO     Training average negative_sample_loss at step 45300: 0.031601\n",
      "2024-02-29 18:22:00,301 INFO     Training average loss at step 45300: 0.051301\n",
      "2024-02-29 18:24:41,688 INFO     Training average positive_sample_loss at step 45400: 0.070728\n",
      "2024-02-29 18:24:41,689 INFO     Training average negative_sample_loss at step 45400: 0.031278\n",
      "2024-02-29 18:24:41,689 INFO     Training average loss at step 45400: 0.051003\n",
      "2024-02-29 18:27:21,873 INFO     Training average positive_sample_loss at step 45500: 0.071136\n",
      "2024-02-29 18:27:21,874 INFO     Training average negative_sample_loss at step 45500: 0.031611\n",
      "2024-02-29 18:27:21,874 INFO     Training average loss at step 45500: 0.051374\n",
      "2024-02-29 18:30:23,555 INFO     Training average positive_sample_loss at step 45600: 0.070945\n",
      "2024-02-29 18:30:23,556 INFO     Training average negative_sample_loss at step 45600: 0.031567\n",
      "2024-02-29 18:30:23,556 INFO     Training average loss at step 45600: 0.051256\n",
      "2024-02-29 18:33:20,966 INFO     Training average positive_sample_loss at step 45700: 0.071077\n",
      "2024-02-29 18:33:20,967 INFO     Training average negative_sample_loss at step 45700: 0.031491\n",
      "2024-02-29 18:33:20,967 INFO     Training average loss at step 45700: 0.051284\n",
      "2024-02-29 18:36:14,827 INFO     Training average positive_sample_loss at step 45800: 0.071109\n",
      "2024-02-29 18:36:14,827 INFO     Training average negative_sample_loss at step 45800: 0.031454\n",
      "2024-02-29 18:36:14,827 INFO     Training average loss at step 45800: 0.051281\n",
      "2024-02-29 18:39:23,974 INFO     Training average positive_sample_loss at step 45900: 0.071361\n",
      "2024-02-29 18:39:23,974 INFO     Training average negative_sample_loss at step 45900: 0.031523\n",
      "2024-02-29 18:39:23,974 INFO     Training average loss at step 45900: 0.051442\n",
      "2024-02-29 18:42:25,040 INFO     Training average positive_sample_loss at step 46000: 0.070286\n",
      "2024-02-29 18:42:25,041 INFO     Training average negative_sample_loss at step 46000: 0.031015\n",
      "2024-02-29 18:42:25,041 INFO     Training average loss at step 46000: 0.050651\n",
      "2024-02-29 18:45:54,169 INFO     Training average positive_sample_loss at step 46100: 0.071347\n",
      "2024-02-29 18:45:54,169 INFO     Training average negative_sample_loss at step 46100: 0.031611\n",
      "2024-02-29 18:45:54,169 INFO     Training average loss at step 46100: 0.051479\n",
      "2024-02-29 18:48:55,842 INFO     Training average positive_sample_loss at step 46200: 0.071339\n",
      "2024-02-29 18:48:55,843 INFO     Training average negative_sample_loss at step 46200: 0.031622\n",
      "2024-02-29 18:48:55,843 INFO     Training average loss at step 46200: 0.051480\n",
      "2024-02-29 18:52:09,012 INFO     Training average positive_sample_loss at step 46300: 0.070867\n",
      "2024-02-29 18:52:09,012 INFO     Training average negative_sample_loss at step 46300: 0.031722\n",
      "2024-02-29 18:52:09,012 INFO     Training average loss at step 46300: 0.051295\n",
      "2024-02-29 18:55:19,678 INFO     Training average positive_sample_loss at step 46400: 0.070845\n",
      "2024-02-29 18:55:19,679 INFO     Training average negative_sample_loss at step 46400: 0.031374\n",
      "2024-02-29 18:55:19,679 INFO     Training average loss at step 46400: 0.051110\n",
      "2024-02-29 18:58:23,664 INFO     Training average positive_sample_loss at step 46500: 0.070855\n",
      "2024-02-29 18:58:23,665 INFO     Training average negative_sample_loss at step 46500: 0.031289\n",
      "2024-02-29 18:58:23,665 INFO     Training average loss at step 46500: 0.051072\n",
      "2024-02-29 19:02:15,817 INFO     Training average positive_sample_loss at step 46600: 0.071560\n",
      "2024-02-29 19:02:15,817 INFO     Training average negative_sample_loss at step 46600: 0.031570\n",
      "2024-02-29 19:02:15,817 INFO     Training average loss at step 46600: 0.051565\n",
      "2024-02-29 19:05:28,316 INFO     Training average positive_sample_loss at step 46700: 0.070646\n",
      "2024-02-29 19:05:28,316 INFO     Training average negative_sample_loss at step 46700: 0.031316\n",
      "2024-02-29 19:05:28,316 INFO     Training average loss at step 46700: 0.050981\n",
      "2024-02-29 19:08:39,199 INFO     Training average positive_sample_loss at step 46800: 0.070974\n",
      "2024-02-29 19:08:39,200 INFO     Training average negative_sample_loss at step 46800: 0.031292\n",
      "2024-02-29 19:08:39,200 INFO     Training average loss at step 46800: 0.051133\n",
      "2024-02-29 19:11:57,066 INFO     Training average positive_sample_loss at step 46900: 0.071609\n",
      "2024-02-29 19:11:57,067 INFO     Training average negative_sample_loss at step 46900: 0.031364\n",
      "2024-02-29 19:11:57,067 INFO     Training average loss at step 46900: 0.051486\n",
      "2024-02-29 19:15:26,117 INFO     Training average positive_sample_loss at step 47000: 0.070771\n",
      "2024-02-29 19:15:26,118 INFO     Training average negative_sample_loss at step 47000: 0.031692\n",
      "2024-02-29 19:15:26,118 INFO     Training average loss at step 47000: 0.051232\n",
      "2024-02-29 19:18:23,973 INFO     Training average positive_sample_loss at step 47100: 0.070688\n",
      "2024-02-29 19:18:23,973 INFO     Training average negative_sample_loss at step 47100: 0.031366\n",
      "2024-02-29 19:18:23,973 INFO     Training average loss at step 47100: 0.051027\n",
      "2024-02-29 19:21:43,279 INFO     Training average positive_sample_loss at step 47200: 0.071412\n",
      "2024-02-29 19:21:43,279 INFO     Training average negative_sample_loss at step 47200: 0.031292\n",
      "2024-02-29 19:21:43,279 INFO     Training average loss at step 47200: 0.051352\n",
      "2024-02-29 19:25:17,948 INFO     Training average positive_sample_loss at step 47300: 0.071301\n",
      "2024-02-29 19:25:17,948 INFO     Training average negative_sample_loss at step 47300: 0.031279\n",
      "2024-02-29 19:25:17,948 INFO     Training average loss at step 47300: 0.051290\n",
      "2024-02-29 19:28:37,275 INFO     Training average positive_sample_loss at step 47400: 0.070619\n",
      "2024-02-29 19:28:37,276 INFO     Training average negative_sample_loss at step 47400: 0.031395\n",
      "2024-02-29 19:28:37,276 INFO     Training average loss at step 47400: 0.051007\n",
      "2024-02-29 19:32:07,265 INFO     Training average positive_sample_loss at step 47500: 0.070986\n",
      "2024-02-29 19:32:07,266 INFO     Training average negative_sample_loss at step 47500: 0.031291\n",
      "2024-02-29 19:32:07,266 INFO     Training average loss at step 47500: 0.051138\n",
      "2024-02-29 19:35:37,266 INFO     Training average positive_sample_loss at step 47600: 0.071455\n",
      "2024-02-29 19:35:37,266 INFO     Training average negative_sample_loss at step 47600: 0.031539\n",
      "2024-02-29 19:35:37,266 INFO     Training average loss at step 47600: 0.051497\n",
      "2024-02-29 19:38:57,523 INFO     Training average positive_sample_loss at step 47700: 0.070319\n",
      "2024-02-29 19:38:57,524 INFO     Training average negative_sample_loss at step 47700: 0.031394\n",
      "2024-02-29 19:38:57,524 INFO     Training average loss at step 47700: 0.050857\n",
      "2024-02-29 19:42:33,920 INFO     Training average positive_sample_loss at step 47800: 0.071594\n",
      "2024-02-29 19:42:33,920 INFO     Training average negative_sample_loss at step 47800: 0.031516\n",
      "2024-02-29 19:42:33,921 INFO     Training average loss at step 47800: 0.051555\n",
      "2024-02-29 19:45:58,700 INFO     Training average positive_sample_loss at step 47900: 0.070910\n",
      "2024-02-29 19:45:58,701 INFO     Training average negative_sample_loss at step 47900: 0.031068\n",
      "2024-02-29 19:45:58,701 INFO     Training average loss at step 47900: 0.050989\n",
      "2024-02-29 19:49:29,587 INFO     Training average positive_sample_loss at step 48000: 0.071006\n",
      "2024-02-29 19:49:29,588 INFO     Training average negative_sample_loss at step 48000: 0.031259\n",
      "2024-02-29 19:49:29,588 INFO     Training average loss at step 48000: 0.051133\n",
      "2024-02-29 19:52:27,903 INFO     Training average positive_sample_loss at step 48100: 0.070621\n",
      "2024-02-29 19:52:27,903 INFO     Training average negative_sample_loss at step 48100: 0.031094\n",
      "2024-02-29 19:52:27,904 INFO     Training average loss at step 48100: 0.050857\n",
      "2024-02-29 19:55:24,155 INFO     Training average positive_sample_loss at step 48200: 0.071189\n",
      "2024-02-29 19:55:24,156 INFO     Training average negative_sample_loss at step 48200: 0.031363\n",
      "2024-02-29 19:55:24,156 INFO     Training average loss at step 48200: 0.051276\n",
      "2024-02-29 19:58:41,409 INFO     Training average positive_sample_loss at step 48300: 0.071608\n",
      "2024-02-29 19:58:41,409 INFO     Training average negative_sample_loss at step 48300: 0.031324\n",
      "2024-02-29 19:58:41,409 INFO     Training average loss at step 48300: 0.051466\n",
      "2024-02-29 20:01:25,288 INFO     Training average positive_sample_loss at step 48400: 0.070647\n",
      "2024-02-29 20:01:25,289 INFO     Training average negative_sample_loss at step 48400: 0.031521\n",
      "2024-02-29 20:01:25,289 INFO     Training average loss at step 48400: 0.051084\n",
      "2024-02-29 20:04:52,808 INFO     Training average positive_sample_loss at step 48500: 0.071158\n",
      "2024-02-29 20:04:52,809 INFO     Training average negative_sample_loss at step 48500: 0.031007\n",
      "2024-02-29 20:04:52,809 INFO     Training average loss at step 48500: 0.051082\n",
      "2024-02-29 20:07:57,811 INFO     Training average positive_sample_loss at step 48600: 0.070884\n",
      "2024-02-29 20:07:57,811 INFO     Training average negative_sample_loss at step 48600: 0.031257\n",
      "2024-02-29 20:07:57,811 INFO     Training average loss at step 48600: 0.051071\n",
      "2024-02-29 20:11:03,805 INFO     Training average positive_sample_loss at step 48700: 0.070848\n",
      "2024-02-29 20:11:03,805 INFO     Training average negative_sample_loss at step 48700: 0.031286\n",
      "2024-02-29 20:11:03,805 INFO     Training average loss at step 48700: 0.051067\n",
      "2024-02-29 20:14:46,070 INFO     Training average positive_sample_loss at step 48800: 0.070890\n",
      "2024-02-29 20:14:46,071 INFO     Training average negative_sample_loss at step 48800: 0.031159\n",
      "2024-02-29 20:14:46,071 INFO     Training average loss at step 48800: 0.051025\n",
      "2024-02-29 20:18:08,258 INFO     Training average positive_sample_loss at step 48900: 0.071342\n",
      "2024-02-29 20:18:08,258 INFO     Training average negative_sample_loss at step 48900: 0.031321\n",
      "2024-02-29 20:18:08,258 INFO     Training average loss at step 48900: 0.051332\n",
      "2024-02-29 20:21:44,103 INFO     Training average positive_sample_loss at step 49000: 0.071255\n",
      "2024-02-29 20:21:44,104 INFO     Training average negative_sample_loss at step 49000: 0.031346\n",
      "2024-02-29 20:21:44,104 INFO     Training average loss at step 49000: 0.051301\n",
      "2024-02-29 20:24:46,789 INFO     Training average positive_sample_loss at step 49100: 0.070763\n",
      "2024-02-29 20:24:46,790 INFO     Training average negative_sample_loss at step 49100: 0.031160\n",
      "2024-02-29 20:24:46,790 INFO     Training average loss at step 49100: 0.050961\n",
      "2024-02-29 20:27:33,706 INFO     Training average positive_sample_loss at step 49200: 0.071124\n",
      "2024-02-29 20:27:33,707 INFO     Training average negative_sample_loss at step 49200: 0.031060\n",
      "2024-02-29 20:27:33,707 INFO     Training average loss at step 49200: 0.051092\n",
      "2024-02-29 20:31:02,330 INFO     Training average positive_sample_loss at step 49300: 0.071080\n",
      "2024-02-29 20:31:02,330 INFO     Training average negative_sample_loss at step 49300: 0.031340\n",
      "2024-02-29 20:31:02,331 INFO     Training average loss at step 49300: 0.051210\n",
      "2024-02-29 20:34:10,135 INFO     Training average positive_sample_loss at step 49400: 0.070423\n",
      "2024-02-29 20:34:10,135 INFO     Training average negative_sample_loss at step 49400: 0.030962\n",
      "2024-02-29 20:34:10,135 INFO     Training average loss at step 49400: 0.050693\n",
      "2024-02-29 20:37:21,946 INFO     Training average positive_sample_loss at step 49500: 0.071163\n",
      "2024-02-29 20:37:21,947 INFO     Training average negative_sample_loss at step 49500: 0.031201\n",
      "2024-02-29 20:37:21,947 INFO     Training average loss at step 49500: 0.051182\n",
      "2024-02-29 20:40:49,214 INFO     Training average positive_sample_loss at step 49600: 0.071403\n",
      "2024-02-29 20:40:49,215 INFO     Training average negative_sample_loss at step 49600: 0.031423\n",
      "2024-02-29 20:40:49,215 INFO     Training average loss at step 49600: 0.051413\n",
      "2024-02-29 20:44:09,200 INFO     Training average positive_sample_loss at step 49700: 0.070504\n",
      "2024-02-29 20:44:09,201 INFO     Training average negative_sample_loss at step 49700: 0.031300\n",
      "2024-02-29 20:44:09,201 INFO     Training average loss at step 49700: 0.050902\n",
      "2024-02-29 20:47:16,564 INFO     Training average positive_sample_loss at step 49800: 0.070861\n",
      "2024-02-29 20:47:16,564 INFO     Training average negative_sample_loss at step 49800: 0.031032\n",
      "2024-02-29 20:47:16,564 INFO     Training average loss at step 49800: 0.050946\n",
      "2024-02-29 20:50:44,795 INFO     Training average positive_sample_loss at step 49900: 0.071447\n",
      "2024-02-29 20:50:44,795 INFO     Training average negative_sample_loss at step 49900: 0.031349\n",
      "2024-02-29 20:50:44,795 INFO     Training average loss at step 49900: 0.051398\n",
      "2024-02-29 20:54:02,595 INFO     Training average positive_sample_loss at step 50000: 0.071053\n",
      "2024-02-29 20:54:02,596 INFO     Training average negative_sample_loss at step 50000: 0.031105\n",
      "2024-02-29 20:54:02,596 INFO     Training average loss at step 50000: 0.051079\n",
      "2024-02-29 20:54:02,596 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 20:54:03,217 INFO     Evaluating the model... (0/760)\n",
      "2024-02-29 20:54:31,534 INFO     Valid MRR at step 50000: 0.463215\n",
      "2024-02-29 20:54:31,535 INFO     Valid MR at step 50000: 4844.970995\n",
      "2024-02-29 20:54:31,535 INFO     Valid HITS@1 at step 50000: 0.422544\n",
      "2024-02-29 20:54:31,535 INFO     Valid HITS@3 at step 50000: 0.480059\n",
      "2024-02-29 20:54:31,535 INFO     Valid HITS@10 at step 50000: 0.543672\n",
      "2024-02-29 20:57:03,051 INFO     Training average positive_sample_loss at step 50100: 0.070285\n",
      "2024-02-29 20:57:03,052 INFO     Training average negative_sample_loss at step 50100: 0.030670\n",
      "2024-02-29 20:57:03,052 INFO     Training average loss at step 50100: 0.050477\n",
      "2024-02-29 21:00:26,093 INFO     Training average positive_sample_loss at step 50200: 0.071400\n",
      "2024-02-29 21:00:26,093 INFO     Training average negative_sample_loss at step 50200: 0.031346\n",
      "2024-02-29 21:00:26,094 INFO     Training average loss at step 50200: 0.051373\n",
      "2024-02-29 21:03:25,140 INFO     Training average positive_sample_loss at step 50300: 0.071481\n",
      "2024-02-29 21:03:25,141 INFO     Training average negative_sample_loss at step 50300: 0.031469\n",
      "2024-02-29 21:03:25,141 INFO     Training average loss at step 50300: 0.051475\n",
      "2024-02-29 21:06:32,516 INFO     Training average positive_sample_loss at step 50400: 0.070653\n",
      "2024-02-29 21:06:32,517 INFO     Training average negative_sample_loss at step 50400: 0.031025\n",
      "2024-02-29 21:06:32,517 INFO     Training average loss at step 50400: 0.050839\n",
      "2024-02-29 21:09:47,943 INFO     Training average positive_sample_loss at step 50500: 0.070587\n",
      "2024-02-29 21:09:47,944 INFO     Training average negative_sample_loss at step 50500: 0.031205\n",
      "2024-02-29 21:09:47,944 INFO     Training average loss at step 50500: 0.050896\n",
      "2024-02-29 21:13:00,788 INFO     Training average positive_sample_loss at step 50600: 0.071714\n",
      "2024-02-29 21:13:00,791 INFO     Training average negative_sample_loss at step 50600: 0.031161\n",
      "2024-02-29 21:13:00,791 INFO     Training average loss at step 50600: 0.051437\n",
      "2024-02-29 21:16:11,421 INFO     Training average positive_sample_loss at step 50700: 0.070630\n",
      "2024-02-29 21:16:11,422 INFO     Training average negative_sample_loss at step 50700: 0.031203\n",
      "2024-02-29 21:16:11,422 INFO     Training average loss at step 50700: 0.050917\n",
      "2024-02-29 21:19:09,301 INFO     Training average positive_sample_loss at step 50800: 0.070775\n",
      "2024-02-29 21:19:09,301 INFO     Training average negative_sample_loss at step 50800: 0.030826\n",
      "2024-02-29 21:19:09,301 INFO     Training average loss at step 50800: 0.050801\n",
      "2024-02-29 21:22:18,868 INFO     Training average positive_sample_loss at step 50900: 0.071130\n",
      "2024-02-29 21:22:18,869 INFO     Training average negative_sample_loss at step 50900: 0.031322\n",
      "2024-02-29 21:22:18,869 INFO     Training average loss at step 50900: 0.051226\n",
      "2024-02-29 21:25:31,080 INFO     Training average positive_sample_loss at step 51000: 0.071533\n",
      "2024-02-29 21:25:31,080 INFO     Training average negative_sample_loss at step 51000: 0.031197\n",
      "2024-02-29 21:25:31,080 INFO     Training average loss at step 51000: 0.051365\n",
      "2024-02-29 21:28:30,607 INFO     Training average positive_sample_loss at step 51100: 0.070526\n",
      "2024-02-29 21:28:30,608 INFO     Training average negative_sample_loss at step 51100: 0.030916\n",
      "2024-02-29 21:28:30,608 INFO     Training average loss at step 51100: 0.050721\n",
      "2024-02-29 21:31:59,458 INFO     Training average positive_sample_loss at step 51200: 0.071329\n",
      "2024-02-29 21:31:59,459 INFO     Training average negative_sample_loss at step 51200: 0.031077\n",
      "2024-02-29 21:31:59,459 INFO     Training average loss at step 51200: 0.051203\n",
      "2024-02-29 21:35:22,170 INFO     Training average positive_sample_loss at step 51300: 0.071222\n",
      "2024-02-29 21:35:22,171 INFO     Training average negative_sample_loss at step 51300: 0.031416\n",
      "2024-02-29 21:35:22,171 INFO     Training average loss at step 51300: 0.051319\n",
      "2024-02-29 21:38:27,412 INFO     Training average positive_sample_loss at step 51400: 0.070445\n",
      "2024-02-29 21:38:27,412 INFO     Training average negative_sample_loss at step 51400: 0.030862\n",
      "2024-02-29 21:38:27,413 INFO     Training average loss at step 51400: 0.050653\n",
      "2024-02-29 21:41:44,886 INFO     Training average positive_sample_loss at step 51500: 0.070881\n",
      "2024-02-29 21:41:44,886 INFO     Training average negative_sample_loss at step 51500: 0.030971\n",
      "2024-02-29 21:41:44,886 INFO     Training average loss at step 51500: 0.050926\n",
      "2024-02-29 21:44:37,440 INFO     Training average positive_sample_loss at step 51600: 0.071160\n",
      "2024-02-29 21:44:37,440 INFO     Training average negative_sample_loss at step 51600: 0.030937\n",
      "2024-02-29 21:44:37,440 INFO     Training average loss at step 51600: 0.051048\n",
      "2024-02-29 21:48:03,823 INFO     Training average positive_sample_loss at step 51700: 0.071554\n",
      "2024-02-29 21:48:03,824 INFO     Training average negative_sample_loss at step 51700: 0.031370\n",
      "2024-02-29 21:48:03,824 INFO     Training average loss at step 51700: 0.051462\n",
      "2024-02-29 21:51:15,401 INFO     Training average positive_sample_loss at step 51800: 0.070233\n",
      "2024-02-29 21:51:15,406 INFO     Training average negative_sample_loss at step 51800: 0.030980\n",
      "2024-02-29 21:51:15,406 INFO     Training average loss at step 51800: 0.050607\n",
      "2024-02-29 21:54:21,769 INFO     Training average positive_sample_loss at step 51900: 0.071292\n",
      "2024-02-29 21:54:21,770 INFO     Training average negative_sample_loss at step 51900: 0.031206\n",
      "2024-02-29 21:54:21,770 INFO     Training average loss at step 51900: 0.051249\n",
      "2024-02-29 21:57:20,793 INFO     Training average positive_sample_loss at step 52000: 0.071338\n",
      "2024-02-29 21:57:20,793 INFO     Training average negative_sample_loss at step 52000: 0.030980\n",
      "2024-02-29 21:57:20,794 INFO     Training average loss at step 52000: 0.051159\n",
      "2024-02-29 22:00:42,269 INFO     Training average positive_sample_loss at step 52100: 0.071096\n",
      "2024-02-29 22:00:42,270 INFO     Training average negative_sample_loss at step 52100: 0.031137\n",
      "2024-02-29 22:00:42,270 INFO     Training average loss at step 52100: 0.051116\n",
      "2024-02-29 22:04:01,151 INFO     Training average positive_sample_loss at step 52200: 0.071048\n",
      "2024-02-29 22:04:01,152 INFO     Training average negative_sample_loss at step 52200: 0.031304\n",
      "2024-02-29 22:04:01,152 INFO     Training average loss at step 52200: 0.051176\n",
      "2024-02-29 22:07:07,559 INFO     Training average positive_sample_loss at step 52300: 0.070873\n",
      "2024-02-29 22:07:07,560 INFO     Training average negative_sample_loss at step 52300: 0.030928\n",
      "2024-02-29 22:07:07,560 INFO     Training average loss at step 52300: 0.050900\n",
      "2024-02-29 22:10:41,841 INFO     Training average positive_sample_loss at step 52400: 0.070666\n",
      "2024-02-29 22:10:41,842 INFO     Training average negative_sample_loss at step 52400: 0.030897\n",
      "2024-02-29 22:10:41,842 INFO     Training average loss at step 52400: 0.050782\n",
      "2024-02-29 22:13:31,878 INFO     Training average positive_sample_loss at step 52500: 0.070957\n",
      "2024-02-29 22:13:31,878 INFO     Training average negative_sample_loss at step 52500: 0.031238\n",
      "2024-02-29 22:13:31,878 INFO     Training average loss at step 52500: 0.051097\n",
      "2024-02-29 22:16:53,233 INFO     Training average positive_sample_loss at step 52600: 0.071091\n",
      "2024-02-29 22:16:53,233 INFO     Training average negative_sample_loss at step 52600: 0.031006\n",
      "2024-02-29 22:16:53,233 INFO     Training average loss at step 52600: 0.051048\n",
      "2024-02-29 22:19:44,015 INFO     Training average positive_sample_loss at step 52700: 0.071249\n",
      "2024-02-29 22:19:44,016 INFO     Training average negative_sample_loss at step 52700: 0.030755\n",
      "2024-02-29 22:19:44,016 INFO     Training average loss at step 52700: 0.051002\n",
      "2024-02-29 22:22:21,379 INFO     Training average positive_sample_loss at step 52800: 0.070757\n",
      "2024-02-29 22:22:21,380 INFO     Training average negative_sample_loss at step 52800: 0.030694\n",
      "2024-02-29 22:22:21,380 INFO     Training average loss at step 52800: 0.050726\n",
      "2024-02-29 22:25:12,402 INFO     Training average positive_sample_loss at step 52900: 0.070895\n",
      "2024-02-29 22:25:12,403 INFO     Training average negative_sample_loss at step 52900: 0.031376\n",
      "2024-02-29 22:25:12,403 INFO     Training average loss at step 52900: 0.051135\n",
      "2024-02-29 22:27:44,680 INFO     Training average positive_sample_loss at step 53000: 0.071512\n",
      "2024-02-29 22:27:44,681 INFO     Training average negative_sample_loss at step 53000: 0.030950\n",
      "2024-02-29 22:27:44,681 INFO     Training average loss at step 53000: 0.051231\n",
      "2024-02-29 22:30:48,484 INFO     Training average positive_sample_loss at step 53100: 0.070381\n",
      "2024-02-29 22:30:48,485 INFO     Training average negative_sample_loss at step 53100: 0.031069\n",
      "2024-02-29 22:30:48,485 INFO     Training average loss at step 53100: 0.050725\n",
      "2024-02-29 22:33:51,863 INFO     Training average positive_sample_loss at step 53200: 0.071053\n",
      "2024-02-29 22:33:51,864 INFO     Training average negative_sample_loss at step 53200: 0.031146\n",
      "2024-02-29 22:33:51,864 INFO     Training average loss at step 53200: 0.051100\n",
      "2024-02-29 22:36:57,992 INFO     Training average positive_sample_loss at step 53300: 0.071185\n",
      "2024-02-29 22:36:57,992 INFO     Training average negative_sample_loss at step 53300: 0.030828\n",
      "2024-02-29 22:36:57,992 INFO     Training average loss at step 53300: 0.051006\n",
      "2024-02-29 22:40:33,635 INFO     Training average positive_sample_loss at step 53400: 0.070977\n",
      "2024-02-29 22:40:33,636 INFO     Training average negative_sample_loss at step 53400: 0.030894\n",
      "2024-02-29 22:40:33,636 INFO     Training average loss at step 53400: 0.050935\n",
      "2024-02-29 22:43:44,625 INFO     Training average positive_sample_loss at step 53500: 0.070965\n",
      "2024-02-29 22:43:44,626 INFO     Training average negative_sample_loss at step 53500: 0.031032\n",
      "2024-02-29 22:43:44,626 INFO     Training average loss at step 53500: 0.050998\n",
      "2024-02-29 22:47:34,533 INFO     Training average positive_sample_loss at step 53600: 0.070956\n",
      "2024-02-29 22:47:34,534 INFO     Training average negative_sample_loss at step 53600: 0.031111\n",
      "2024-02-29 22:47:34,534 INFO     Training average loss at step 53600: 0.051033\n",
      "2024-02-29 22:50:45,766 INFO     Training average positive_sample_loss at step 53700: 0.071207\n",
      "2024-02-29 22:50:45,766 INFO     Training average negative_sample_loss at step 53700: 0.030879\n",
      "2024-02-29 22:50:45,766 INFO     Training average loss at step 53700: 0.051043\n",
      "2024-02-29 22:54:21,861 INFO     Training average positive_sample_loss at step 53800: 0.070445\n",
      "2024-02-29 22:54:21,862 INFO     Training average negative_sample_loss at step 53800: 0.030697\n",
      "2024-02-29 22:54:21,862 INFO     Training average loss at step 53800: 0.050571\n",
      "2024-02-29 22:57:44,232 INFO     Training average positive_sample_loss at step 53900: 0.070675\n",
      "2024-02-29 22:57:44,233 INFO     Training average negative_sample_loss at step 53900: 0.030888\n",
      "2024-02-29 22:57:44,233 INFO     Training average loss at step 53900: 0.050781\n",
      "2024-02-29 23:01:16,512 INFO     Training average positive_sample_loss at step 54000: 0.071491\n",
      "2024-02-29 23:01:16,512 INFO     Training average negative_sample_loss at step 54000: 0.031074\n",
      "2024-02-29 23:01:16,512 INFO     Training average loss at step 54000: 0.051283\n",
      "2024-02-29 23:04:24,744 INFO     Training average positive_sample_loss at step 54100: 0.070837\n",
      "2024-02-29 23:04:24,745 INFO     Training average negative_sample_loss at step 54100: 0.031027\n",
      "2024-02-29 23:04:24,745 INFO     Training average loss at step 54100: 0.050932\n",
      "2024-02-29 23:07:42,749 INFO     Training average positive_sample_loss at step 54200: 0.071031\n",
      "2024-02-29 23:07:42,749 INFO     Training average negative_sample_loss at step 54200: 0.030849\n",
      "2024-02-29 23:07:42,749 INFO     Training average loss at step 54200: 0.050940\n",
      "2024-02-29 23:10:57,487 INFO     Training average positive_sample_loss at step 54300: 0.071484\n",
      "2024-02-29 23:10:57,487 INFO     Training average negative_sample_loss at step 54300: 0.031012\n",
      "2024-02-29 23:10:57,487 INFO     Training average loss at step 54300: 0.051248\n",
      "2024-02-29 23:14:23,386 INFO     Training average positive_sample_loss at step 54400: 0.070670\n",
      "2024-02-29 23:14:23,386 INFO     Training average negative_sample_loss at step 54400: 0.031002\n",
      "2024-02-29 23:14:23,387 INFO     Training average loss at step 54400: 0.050836\n",
      "2024-02-29 23:17:40,190 INFO     Training average positive_sample_loss at step 54500: 0.070522\n",
      "2024-02-29 23:17:40,190 INFO     Training average negative_sample_loss at step 54500: 0.031117\n",
      "2024-02-29 23:17:40,190 INFO     Training average loss at step 54500: 0.050820\n",
      "2024-02-29 23:21:00,732 INFO     Training average positive_sample_loss at step 54600: 0.070853\n",
      "2024-02-29 23:21:00,732 INFO     Training average negative_sample_loss at step 54600: 0.030687\n",
      "2024-02-29 23:21:00,733 INFO     Training average loss at step 54600: 0.050770\n",
      "2024-02-29 23:24:00,605 INFO     Training average positive_sample_loss at step 54700: 0.071280\n",
      "2024-02-29 23:24:00,606 INFO     Training average negative_sample_loss at step 54700: 0.030968\n",
      "2024-02-29 23:24:00,606 INFO     Training average loss at step 54700: 0.051124\n",
      "2024-02-29 23:27:40,582 INFO     Training average positive_sample_loss at step 54800: 0.070865\n",
      "2024-02-29 23:27:40,582 INFO     Training average negative_sample_loss at step 54800: 0.030840\n",
      "2024-02-29 23:27:40,582 INFO     Training average loss at step 54800: 0.050853\n",
      "2024-02-29 23:31:03,097 INFO     Training average positive_sample_loss at step 54900: 0.071001\n",
      "2024-02-29 23:31:03,097 INFO     Training average negative_sample_loss at step 54900: 0.030929\n",
      "2024-02-29 23:31:03,097 INFO     Training average loss at step 54900: 0.050965\n",
      "2024-02-29 23:34:19,957 INFO     Training average positive_sample_loss at step 55000: 0.071288\n",
      "2024-02-29 23:34:19,958 INFO     Training average negative_sample_loss at step 55000: 0.030917\n",
      "2024-02-29 23:34:19,958 INFO     Training average loss at step 55000: 0.051103\n",
      "2024-02-29 23:37:36,488 INFO     Training average positive_sample_loss at step 55100: 0.070776\n",
      "2024-02-29 23:37:36,488 INFO     Training average negative_sample_loss at step 55100: 0.031232\n",
      "2024-02-29 23:37:36,488 INFO     Training average loss at step 55100: 0.051004\n",
      "2024-02-29 23:40:58,073 INFO     Training average positive_sample_loss at step 55200: 0.070521\n",
      "2024-02-29 23:40:58,073 INFO     Training average negative_sample_loss at step 55200: 0.030610\n",
      "2024-02-29 23:40:58,073 INFO     Training average loss at step 55200: 0.050566\n",
      "2024-02-29 23:44:01,088 INFO     Training average positive_sample_loss at step 55300: 0.071079\n",
      "2024-02-29 23:44:01,089 INFO     Training average negative_sample_loss at step 55300: 0.031045\n",
      "2024-02-29 23:44:01,089 INFO     Training average loss at step 55300: 0.051062\n",
      "2024-02-29 23:46:46,003 INFO     Training average positive_sample_loss at step 55400: 0.071586\n",
      "2024-02-29 23:46:46,003 INFO     Training average negative_sample_loss at step 55400: 0.030735\n",
      "2024-02-29 23:46:46,003 INFO     Training average loss at step 55400: 0.051160\n",
      "2024-02-29 23:50:15,594 INFO     Training average positive_sample_loss at step 55500: 0.070138\n",
      "2024-02-29 23:50:15,595 INFO     Training average negative_sample_loss at step 55500: 0.030831\n",
      "2024-02-29 23:50:15,595 INFO     Training average loss at step 55500: 0.050484\n",
      "2024-02-29 23:53:42,899 INFO     Training average positive_sample_loss at step 55600: 0.071262\n",
      "2024-02-29 23:53:42,899 INFO     Training average negative_sample_loss at step 55600: 0.030990\n",
      "2024-02-29 23:53:42,899 INFO     Training average loss at step 55600: 0.051126\n",
      "2024-02-29 23:56:53,411 INFO     Training average positive_sample_loss at step 55700: 0.071101\n",
      "2024-02-29 23:56:53,411 INFO     Training average negative_sample_loss at step 55700: 0.030871\n",
      "2024-02-29 23:56:53,411 INFO     Training average loss at step 55700: 0.050986\n",
      "2024-03-01 00:00:29,961 INFO     Training average positive_sample_loss at step 55800: 0.070755\n",
      "2024-03-01 00:00:29,961 INFO     Training average negative_sample_loss at step 55800: 0.030901\n",
      "2024-03-01 00:00:29,961 INFO     Training average loss at step 55800: 0.050828\n",
      "2024-03-01 00:03:48,049 INFO     Training average positive_sample_loss at step 55900: 0.071001\n",
      "2024-03-01 00:03:48,050 INFO     Training average negative_sample_loss at step 55900: 0.030370\n",
      "2024-03-01 00:03:48,050 INFO     Training average loss at step 55900: 0.050686\n",
      "2024-03-01 00:06:46,657 INFO     Training average positive_sample_loss at step 56000: 0.070727\n",
      "2024-03-01 00:06:46,658 INFO     Training average negative_sample_loss at step 56000: 0.031030\n",
      "2024-03-01 00:06:46,658 INFO     Training average loss at step 56000: 0.050879\n",
      "2024-03-01 00:10:12,542 INFO     Training average positive_sample_loss at step 56100: 0.071562\n",
      "2024-03-01 00:10:12,543 INFO     Training average negative_sample_loss at step 56100: 0.031128\n",
      "2024-03-01 00:10:12,543 INFO     Training average loss at step 56100: 0.051345\n",
      "2024-03-01 00:13:06,388 INFO     Training average positive_sample_loss at step 56200: 0.070422\n",
      "2024-03-01 00:13:06,389 INFO     Training average negative_sample_loss at step 56200: 0.030834\n",
      "2024-03-01 00:13:06,389 INFO     Training average loss at step 56200: 0.050628\n",
      "2024-03-01 00:16:22,352 INFO     Training average positive_sample_loss at step 56300: 0.070968\n",
      "2024-03-01 00:16:22,353 INFO     Training average negative_sample_loss at step 56300: 0.030718\n",
      "2024-03-01 00:16:22,353 INFO     Training average loss at step 56300: 0.050843\n",
      "2024-03-01 00:19:40,175 INFO     Training average positive_sample_loss at step 56400: 0.071196\n",
      "2024-03-01 00:19:40,175 INFO     Training average negative_sample_loss at step 56400: 0.030853\n",
      "2024-03-01 00:19:40,175 INFO     Training average loss at step 56400: 0.051025\n",
      "2024-03-01 00:23:02,522 INFO     Training average positive_sample_loss at step 56500: 0.071068\n",
      "2024-03-01 00:23:02,523 INFO     Training average negative_sample_loss at step 56500: 0.031179\n",
      "2024-03-01 00:23:02,523 INFO     Training average loss at step 56500: 0.051123\n",
      "2024-03-01 00:26:16,018 INFO     Training average positive_sample_loss at step 56600: 0.070794\n",
      "2024-03-01 00:26:16,019 INFO     Training average negative_sample_loss at step 56600: 0.030818\n",
      "2024-03-01 00:26:16,019 INFO     Training average loss at step 56600: 0.050806\n",
      "2024-03-01 00:29:20,111 INFO     Training average positive_sample_loss at step 56700: 0.070765\n",
      "2024-03-01 00:29:20,112 INFO     Training average negative_sample_loss at step 56700: 0.030788\n",
      "2024-03-01 00:29:20,112 INFO     Training average loss at step 56700: 0.050776\n",
      "2024-03-01 00:32:42,656 INFO     Training average positive_sample_loss at step 56800: 0.071272\n",
      "2024-03-01 00:32:42,656 INFO     Training average negative_sample_loss at step 56800: 0.030883\n",
      "2024-03-01 00:32:42,656 INFO     Training average loss at step 56800: 0.051078\n",
      "2024-03-01 00:35:49,748 INFO     Training average positive_sample_loss at step 56900: 0.070546\n",
      "2024-03-01 00:35:49,749 INFO     Training average negative_sample_loss at step 56900: 0.031037\n",
      "2024-03-01 00:35:49,749 INFO     Training average loss at step 56900: 0.050791\n",
      "2024-03-01 00:39:26,512 INFO     Training average positive_sample_loss at step 57000: 0.071254\n",
      "2024-03-01 00:39:26,513 INFO     Training average negative_sample_loss at step 57000: 0.030776\n",
      "2024-03-01 00:39:26,513 INFO     Training average loss at step 57000: 0.051015\n",
      "2024-03-01 00:43:03,408 INFO     Training average positive_sample_loss at step 57100: 0.071189\n",
      "2024-03-01 00:43:03,408 INFO     Training average negative_sample_loss at step 57100: 0.030942\n",
      "2024-03-01 00:43:03,408 INFO     Training average loss at step 57100: 0.051066\n",
      "2024-03-01 00:46:13,800 INFO     Training average positive_sample_loss at step 57200: 0.070576\n",
      "2024-03-01 00:46:13,801 INFO     Training average negative_sample_loss at step 57200: 0.030681\n",
      "2024-03-01 00:46:13,801 INFO     Training average loss at step 57200: 0.050629\n",
      "2024-03-01 00:49:23,588 INFO     Training average positive_sample_loss at step 57300: 0.070733\n",
      "2024-03-01 00:49:23,589 INFO     Training average negative_sample_loss at step 57300: 0.030820\n",
      "2024-03-01 00:49:23,589 INFO     Training average loss at step 57300: 0.050776\n",
      "2024-03-01 00:53:18,785 INFO     Training average positive_sample_loss at step 57400: 0.070980\n",
      "2024-03-01 00:53:18,786 INFO     Training average negative_sample_loss at step 57400: 0.030651\n",
      "2024-03-01 00:53:18,786 INFO     Training average loss at step 57400: 0.050815\n",
      "2024-03-01 00:57:11,872 INFO     Training average positive_sample_loss at step 57500: 0.071155\n",
      "2024-03-01 00:57:11,873 INFO     Training average negative_sample_loss at step 57500: 0.031017\n",
      "2024-03-01 00:57:11,873 INFO     Training average loss at step 57500: 0.051086\n",
      "2024-03-01 01:00:20,911 INFO     Training average positive_sample_loss at step 57600: 0.070600\n",
      "2024-03-01 01:00:20,912 INFO     Training average negative_sample_loss at step 57600: 0.030760\n",
      "2024-03-01 01:00:20,912 INFO     Training average loss at step 57600: 0.050680\n",
      "2024-03-01 01:03:44,127 INFO     Training average positive_sample_loss at step 57700: 0.071222\n",
      "2024-03-01 01:03:44,128 INFO     Training average negative_sample_loss at step 57700: 0.030781\n",
      "2024-03-01 01:03:44,128 INFO     Training average loss at step 57700: 0.051002\n",
      "2024-03-01 01:07:06,884 INFO     Training average positive_sample_loss at step 57800: 0.071230\n",
      "2024-03-01 01:07:06,884 INFO     Training average negative_sample_loss at step 57800: 0.030999\n",
      "2024-03-01 01:07:06,884 INFO     Training average loss at step 57800: 0.051114\n",
      "2024-03-01 01:10:06,191 INFO     Training average positive_sample_loss at step 57900: 0.070496\n",
      "2024-03-01 01:10:06,191 INFO     Training average negative_sample_loss at step 57900: 0.030855\n",
      "2024-03-01 01:10:06,191 INFO     Training average loss at step 57900: 0.050675\n",
      "2024-03-01 01:13:25,484 INFO     Training average positive_sample_loss at step 58000: 0.070959\n",
      "2024-03-01 01:13:25,484 INFO     Training average negative_sample_loss at step 58000: 0.030685\n",
      "2024-03-01 01:13:25,484 INFO     Training average loss at step 58000: 0.050822\n",
      "2024-03-01 01:16:22,153 INFO     Training average positive_sample_loss at step 58100: 0.071017\n",
      "2024-03-01 01:16:22,153 INFO     Training average negative_sample_loss at step 58100: 0.030867\n",
      "2024-03-01 01:16:22,153 INFO     Training average loss at step 58100: 0.050942\n",
      "2024-03-01 01:19:30,812 INFO     Training average positive_sample_loss at step 58200: 0.071175\n",
      "2024-03-01 01:19:30,812 INFO     Training average negative_sample_loss at step 58200: 0.030993\n",
      "2024-03-01 01:19:30,812 INFO     Training average loss at step 58200: 0.051084\n",
      "2024-03-01 01:22:50,801 INFO     Training average positive_sample_loss at step 58300: 0.070505\n",
      "2024-03-01 01:22:50,801 INFO     Training average negative_sample_loss at step 58300: 0.030950\n",
      "2024-03-01 01:22:50,801 INFO     Training average loss at step 58300: 0.050727\n",
      "2024-03-01 01:25:44,724 INFO     Training average positive_sample_loss at step 58400: 0.070987\n",
      "2024-03-01 01:25:44,724 INFO     Training average negative_sample_loss at step 58400: 0.030333\n",
      "2024-03-01 01:25:44,724 INFO     Training average loss at step 58400: 0.050660\n",
      "2024-03-01 01:29:00,311 INFO     Training average positive_sample_loss at step 58500: 0.070979\n",
      "2024-03-01 01:29:00,311 INFO     Training average negative_sample_loss at step 58500: 0.030871\n",
      "2024-03-01 01:29:00,311 INFO     Training average loss at step 58500: 0.050925\n",
      "2024-03-01 01:32:11,651 INFO     Training average positive_sample_loss at step 58600: 0.070929\n",
      "2024-03-01 01:32:11,652 INFO     Training average negative_sample_loss at step 58600: 0.030757\n",
      "2024-03-01 01:32:11,652 INFO     Training average loss at step 58600: 0.050843\n",
      "2024-03-01 01:35:19,581 INFO     Training average positive_sample_loss at step 58700: 0.071124\n",
      "2024-03-01 01:35:19,582 INFO     Training average negative_sample_loss at step 58700: 0.030790\n",
      "2024-03-01 01:35:19,582 INFO     Training average loss at step 58700: 0.050957\n",
      "2024-03-01 01:38:44,962 INFO     Training average positive_sample_loss at step 58800: 0.070913\n",
      "2024-03-01 01:38:44,963 INFO     Training average negative_sample_loss at step 58800: 0.030900\n",
      "2024-03-01 01:38:44,963 INFO     Training average loss at step 58800: 0.050907\n",
      "2024-03-01 01:41:50,320 INFO     Training average positive_sample_loss at step 58900: 0.070521\n",
      "2024-03-01 01:41:50,321 INFO     Training average negative_sample_loss at step 58900: 0.030678\n",
      "2024-03-01 01:41:50,321 INFO     Training average loss at step 58900: 0.050600\n",
      "2024-03-01 01:44:48,682 INFO     Training average positive_sample_loss at step 59000: 0.070755\n",
      "2024-03-01 01:44:48,683 INFO     Training average negative_sample_loss at step 59000: 0.030701\n",
      "2024-03-01 01:44:48,683 INFO     Training average loss at step 59000: 0.050728\n",
      "2024-03-01 01:48:36,007 INFO     Training average positive_sample_loss at step 59100: 0.071245\n",
      "2024-03-01 01:48:36,007 INFO     Training average negative_sample_loss at step 59100: 0.031074\n",
      "2024-03-01 01:48:36,007 INFO     Training average loss at step 59100: 0.051160\n",
      "2024-03-01 01:51:56,745 INFO     Training average positive_sample_loss at step 59200: 0.070782\n",
      "2024-03-01 01:51:56,746 INFO     Training average negative_sample_loss at step 59200: 0.030708\n",
      "2024-03-01 01:51:56,746 INFO     Training average loss at step 59200: 0.050745\n",
      "2024-03-01 01:55:05,230 INFO     Training average positive_sample_loss at step 59300: 0.070257\n",
      "2024-03-01 01:55:05,231 INFO     Training average negative_sample_loss at step 59300: 0.030893\n",
      "2024-03-01 01:55:05,231 INFO     Training average loss at step 59300: 0.050575\n",
      "2024-03-01 01:58:31,073 INFO     Training average positive_sample_loss at step 59400: 0.071257\n",
      "2024-03-01 01:58:31,074 INFO     Training average negative_sample_loss at step 59400: 0.030699\n",
      "2024-03-01 01:58:31,074 INFO     Training average loss at step 59400: 0.050978\n",
      "2024-03-01 02:01:51,925 INFO     Training average positive_sample_loss at step 59500: 0.071459\n",
      "2024-03-01 02:01:51,925 INFO     Training average negative_sample_loss at step 59500: 0.030647\n",
      "2024-03-01 02:01:51,925 INFO     Training average loss at step 59500: 0.051053\n",
      "2024-03-01 02:04:50,350 INFO     Training average positive_sample_loss at step 59600: 0.070574\n",
      "2024-03-01 02:04:50,351 INFO     Training average negative_sample_loss at step 59600: 0.030621\n",
      "2024-03-01 02:04:50,351 INFO     Training average loss at step 59600: 0.050597\n",
      "2024-03-01 02:07:52,135 INFO     Training average positive_sample_loss at step 59700: 0.071256\n",
      "2024-03-01 02:07:52,135 INFO     Training average negative_sample_loss at step 59700: 0.030732\n",
      "2024-03-01 02:07:52,135 INFO     Training average loss at step 59700: 0.050994\n",
      "2024-03-01 02:10:48,609 INFO     Training average positive_sample_loss at step 59800: 0.071022\n",
      "2024-03-01 02:10:48,609 INFO     Training average negative_sample_loss at step 59800: 0.031041\n",
      "2024-03-01 02:10:48,609 INFO     Training average loss at step 59800: 0.051031\n",
      "2024-03-01 02:13:49,383 INFO     Training average positive_sample_loss at step 59900: 0.070335\n",
      "2024-03-01 02:13:49,383 INFO     Training average negative_sample_loss at step 59900: 0.030663\n",
      "2024-03-01 02:13:49,383 INFO     Training average loss at step 59900: 0.050499\n",
      "2024-03-01 02:16:44,055 INFO     Training average positive_sample_loss at step 60000: 0.070606\n",
      "2024-03-01 02:16:44,056 INFO     Training average negative_sample_loss at step 60000: 0.030575\n",
      "2024-03-01 02:16:44,056 INFO     Training average loss at step 60000: 0.050591\n",
      "2024-03-01 02:16:44,056 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 02:16:44,615 INFO     Evaluating the model... (0/760)\n",
      "2024-03-01 02:17:13,455 INFO     Valid MRR at step 60000: 0.463163\n",
      "2024-03-01 02:17:13,456 INFO     Valid MR at step 60000: 4827.945946\n",
      "2024-03-01 02:17:13,456 INFO     Valid HITS@1 at step 60000: 0.422215\n",
      "2024-03-01 02:17:13,456 INFO     Valid HITS@3 at step 60000: 0.479895\n",
      "2024-03-01 02:17:13,456 INFO     Valid HITS@10 at step 60000: 0.543342\n",
      "2024-03-01 02:19:43,299 INFO     Training average positive_sample_loss at step 60100: 0.070879\n",
      "2024-03-01 02:19:43,299 INFO     Training average negative_sample_loss at step 60100: 0.030874\n",
      "2024-03-01 02:19:43,299 INFO     Training average loss at step 60100: 0.050877\n",
      "2024-03-01 02:22:58,996 INFO     Training average positive_sample_loss at step 60200: 0.071329\n",
      "2024-03-01 02:22:58,997 INFO     Training average negative_sample_loss at step 60200: 0.030686\n",
      "2024-03-01 02:22:58,997 INFO     Training average loss at step 60200: 0.051008\n",
      "2024-03-01 02:26:03,734 INFO     Training average positive_sample_loss at step 60300: 0.070367\n",
      "2024-03-01 02:26:03,734 INFO     Training average negative_sample_loss at step 60300: 0.030713\n",
      "2024-03-01 02:26:03,734 INFO     Training average loss at step 60300: 0.050540\n",
      "2024-03-01 02:29:25,044 INFO     Training average positive_sample_loss at step 60400: 0.070919\n",
      "2024-03-01 02:29:25,045 INFO     Training average negative_sample_loss at step 60400: 0.030712\n",
      "2024-03-01 02:29:25,045 INFO     Training average loss at step 60400: 0.050816\n",
      "2024-03-01 02:32:48,451 INFO     Training average positive_sample_loss at step 60500: 0.071551\n",
      "2024-03-01 02:32:48,451 INFO     Training average negative_sample_loss at step 60500: 0.030825\n",
      "2024-03-01 02:32:48,451 INFO     Training average loss at step 60500: 0.051188\n",
      "2024-03-01 02:36:14,964 INFO     Training average positive_sample_loss at step 60600: 0.070459\n",
      "2024-03-01 02:36:14,965 INFO     Training average negative_sample_loss at step 60600: 0.030638\n",
      "2024-03-01 02:36:14,965 INFO     Training average loss at step 60600: 0.050548\n",
      "2024-03-01 02:39:16,576 INFO     Training average positive_sample_loss at step 60700: 0.070665\n",
      "2024-03-01 02:39:16,577 INFO     Training average negative_sample_loss at step 60700: 0.030494\n",
      "2024-03-01 02:39:16,577 INFO     Training average loss at step 60700: 0.050579\n",
      "2024-03-01 02:42:04,434 INFO     Training average positive_sample_loss at step 60800: 0.070920\n",
      "2024-03-01 02:42:04,434 INFO     Training average negative_sample_loss at step 60800: 0.030758\n",
      "2024-03-01 02:42:04,434 INFO     Training average loss at step 60800: 0.050839\n",
      "2024-03-01 02:44:59,862 INFO     Training average positive_sample_loss at step 60900: 0.070985\n",
      "2024-03-01 02:44:59,863 INFO     Training average negative_sample_loss at step 60900: 0.031258\n",
      "2024-03-01 02:44:59,863 INFO     Training average loss at step 60900: 0.051122\n",
      "2024-03-01 02:47:58,628 INFO     Training average positive_sample_loss at step 61000: 0.070575\n",
      "2024-03-01 02:47:58,629 INFO     Training average negative_sample_loss at step 61000: 0.030256\n",
      "2024-03-01 02:47:58,629 INFO     Training average loss at step 61000: 0.050415\n",
      "2024-03-01 02:50:51,364 INFO     Training average positive_sample_loss at step 61100: 0.070900\n",
      "2024-03-01 02:50:51,364 INFO     Training average negative_sample_loss at step 61100: 0.030647\n",
      "2024-03-01 02:50:51,365 INFO     Training average loss at step 61100: 0.050774\n",
      "2024-03-01 02:54:05,275 INFO     Training average positive_sample_loss at step 61200: 0.071539\n",
      "2024-03-01 02:54:05,275 INFO     Training average negative_sample_loss at step 61200: 0.031068\n",
      "2024-03-01 02:54:05,275 INFO     Training average loss at step 61200: 0.051303\n",
      "2024-03-01 02:56:56,580 INFO     Training average positive_sample_loss at step 61300: 0.070405\n",
      "2024-03-01 02:56:56,581 INFO     Training average negative_sample_loss at step 61300: 0.030541\n",
      "2024-03-01 02:56:56,581 INFO     Training average loss at step 61300: 0.050473\n",
      "2024-03-01 02:59:56,151 INFO     Training average positive_sample_loss at step 61400: 0.071262\n",
      "2024-03-01 02:59:56,151 INFO     Training average negative_sample_loss at step 61400: 0.030661\n",
      "2024-03-01 02:59:56,151 INFO     Training average loss at step 61400: 0.050962\n",
      "2024-03-01 03:02:48,400 INFO     Training average positive_sample_loss at step 61500: 0.070586\n",
      "2024-03-01 03:02:48,401 INFO     Training average negative_sample_loss at step 61500: 0.030816\n",
      "2024-03-01 03:02:48,401 INFO     Training average loss at step 61500: 0.050701\n",
      "2024-03-01 03:06:08,929 INFO     Training average positive_sample_loss at step 61600: 0.070823\n",
      "2024-03-01 03:06:08,930 INFO     Training average negative_sample_loss at step 61600: 0.030794\n",
      "2024-03-01 03:06:08,930 INFO     Training average loss at step 61600: 0.050809\n",
      "2024-03-01 03:09:05,660 INFO     Training average positive_sample_loss at step 61700: 0.070573\n",
      "2024-03-01 03:09:05,661 INFO     Training average negative_sample_loss at step 61700: 0.030525\n",
      "2024-03-01 03:09:05,661 INFO     Training average loss at step 61700: 0.050549\n",
      "2024-03-01 03:12:18,802 INFO     Training average positive_sample_loss at step 61800: 0.071402\n",
      "2024-03-01 03:12:18,803 INFO     Training average negative_sample_loss at step 61800: 0.030685\n",
      "2024-03-01 03:12:18,803 INFO     Training average loss at step 61800: 0.051044\n",
      "2024-03-01 03:15:22,458 INFO     Training average positive_sample_loss at step 61900: 0.070694\n",
      "2024-03-01 03:15:22,458 INFO     Training average negative_sample_loss at step 61900: 0.030915\n",
      "2024-03-01 03:15:22,458 INFO     Training average loss at step 61900: 0.050805\n",
      "2024-03-01 03:18:20,205 INFO     Training average positive_sample_loss at step 62000: 0.070188\n",
      "2024-03-01 03:18:20,206 INFO     Training average negative_sample_loss at step 62000: 0.030470\n",
      "2024-03-01 03:18:20,206 INFO     Training average loss at step 62000: 0.050329\n",
      "2024-03-01 03:21:21,469 INFO     Training average positive_sample_loss at step 62100: 0.071392\n",
      "2024-03-01 03:21:21,470 INFO     Training average negative_sample_loss at step 62100: 0.030913\n",
      "2024-03-01 03:21:21,470 INFO     Training average loss at step 62100: 0.051153\n",
      "2024-03-01 03:24:17,940 INFO     Training average positive_sample_loss at step 62200: 0.071107\n",
      "2024-03-01 03:24:17,940 INFO     Training average negative_sample_loss at step 62200: 0.030623\n",
      "2024-03-01 03:24:17,940 INFO     Training average loss at step 62200: 0.050865\n",
      "2024-03-01 03:27:28,049 INFO     Training average positive_sample_loss at step 62300: 0.070228\n",
      "2024-03-01 03:27:28,050 INFO     Training average negative_sample_loss at step 62300: 0.030542\n",
      "2024-03-01 03:27:28,050 INFO     Training average loss at step 62300: 0.050385\n",
      "2024-03-01 03:30:45,758 INFO     Training average positive_sample_loss at step 62400: 0.070944\n",
      "2024-03-01 03:30:45,758 INFO     Training average negative_sample_loss at step 62400: 0.030484\n",
      "2024-03-01 03:30:45,758 INFO     Training average loss at step 62400: 0.050714\n",
      "2024-03-01 03:33:52,419 INFO     Training average positive_sample_loss at step 62500: 0.070894\n",
      "2024-03-01 03:33:52,419 INFO     Training average negative_sample_loss at step 62500: 0.030838\n",
      "2024-03-01 03:33:52,419 INFO     Training average loss at step 62500: 0.050866\n",
      "2024-03-01 03:37:07,543 INFO     Training average positive_sample_loss at step 62600: 0.071254\n",
      "2024-03-01 03:37:07,543 INFO     Training average negative_sample_loss at step 62600: 0.030726\n",
      "2024-03-01 03:37:07,543 INFO     Training average loss at step 62600: 0.050990\n",
      "2024-03-01 03:40:16,601 INFO     Training average positive_sample_loss at step 62700: 0.070456\n",
      "2024-03-01 03:40:16,602 INFO     Training average negative_sample_loss at step 62700: 0.030823\n",
      "2024-03-01 03:40:16,602 INFO     Training average loss at step 62700: 0.050640\n",
      "2024-03-01 03:43:24,594 INFO     Training average positive_sample_loss at step 62800: 0.071142\n",
      "2024-03-01 03:43:24,595 INFO     Training average negative_sample_loss at step 62800: 0.030842\n",
      "2024-03-01 03:43:24,595 INFO     Training average loss at step 62800: 0.050992\n",
      "2024-03-01 03:47:12,766 INFO     Training average positive_sample_loss at step 62900: 0.070944\n",
      "2024-03-01 03:47:12,767 INFO     Training average negative_sample_loss at step 62900: 0.030490\n",
      "2024-03-01 03:47:12,767 INFO     Training average loss at step 62900: 0.050717\n",
      "2024-03-01 03:50:15,067 INFO     Training average positive_sample_loss at step 63000: 0.070617\n",
      "2024-03-01 03:50:15,067 INFO     Training average negative_sample_loss at step 63000: 0.030849\n",
      "2024-03-01 03:50:15,068 INFO     Training average loss at step 63000: 0.050733\n",
      "2024-03-01 03:53:45,841 INFO     Training average positive_sample_loss at step 63100: 0.070786\n",
      "2024-03-01 03:53:45,841 INFO     Training average negative_sample_loss at step 63100: 0.030964\n",
      "2024-03-01 03:53:45,841 INFO     Training average loss at step 63100: 0.050875\n",
      "2024-03-01 03:57:01,940 INFO     Training average positive_sample_loss at step 63200: 0.070970\n",
      "2024-03-01 03:57:01,940 INFO     Training average negative_sample_loss at step 63200: 0.030369\n",
      "2024-03-01 03:57:01,940 INFO     Training average loss at step 63200: 0.050669\n",
      "2024-03-01 04:00:17,039 INFO     Training average positive_sample_loss at step 63300: 0.070777\n",
      "2024-03-01 04:00:17,039 INFO     Training average negative_sample_loss at step 63300: 0.030715\n",
      "2024-03-01 04:00:17,039 INFO     Training average loss at step 63300: 0.050746\n",
      "2024-03-01 04:03:15,489 INFO     Training average positive_sample_loss at step 63400: 0.070770\n",
      "2024-03-01 04:03:15,489 INFO     Training average negative_sample_loss at step 63400: 0.030563\n",
      "2024-03-01 04:03:15,489 INFO     Training average loss at step 63400: 0.050666\n",
      "2024-03-01 04:06:44,793 INFO     Training average positive_sample_loss at step 63500: 0.070795\n",
      "2024-03-01 04:06:44,794 INFO     Training average negative_sample_loss at step 63500: 0.030486\n",
      "2024-03-01 04:06:44,794 INFO     Training average loss at step 63500: 0.050640\n",
      "2024-03-01 04:10:12,148 INFO     Training average positive_sample_loss at step 63600: 0.070629\n",
      "2024-03-01 04:10:12,148 INFO     Training average negative_sample_loss at step 63600: 0.030576\n",
      "2024-03-01 04:10:12,148 INFO     Training average loss at step 63600: 0.050603\n",
      "2024-03-01 04:13:04,619 INFO     Training average positive_sample_loss at step 63700: 0.070454\n",
      "2024-03-01 04:13:04,620 INFO     Training average negative_sample_loss at step 63700: 0.030567\n",
      "2024-03-01 04:13:04,620 INFO     Training average loss at step 63700: 0.050511\n",
      "2024-03-01 04:16:11,998 INFO     Training average positive_sample_loss at step 63800: 0.071437\n",
      "2024-03-01 04:16:11,999 INFO     Training average negative_sample_loss at step 63800: 0.030844\n",
      "2024-03-01 04:16:11,999 INFO     Training average loss at step 63800: 0.051140\n",
      "2024-03-01 04:19:01,934 INFO     Training average positive_sample_loss at step 63900: 0.070937\n",
      "2024-03-01 04:19:01,935 INFO     Training average negative_sample_loss at step 63900: 0.030613\n",
      "2024-03-01 04:19:01,935 INFO     Training average loss at step 63900: 0.050775\n",
      "2024-03-01 04:22:31,236 INFO     Training average positive_sample_loss at step 64000: 0.070863\n",
      "2024-03-01 04:22:31,236 INFO     Training average negative_sample_loss at step 64000: 0.030547\n",
      "2024-03-01 04:22:31,236 INFO     Training average loss at step 64000: 0.050705\n",
      "2024-03-01 04:25:28,863 INFO     Training average positive_sample_loss at step 64100: 0.070515\n",
      "2024-03-01 04:25:28,863 INFO     Training average negative_sample_loss at step 64100: 0.030572\n",
      "2024-03-01 04:25:28,864 INFO     Training average loss at step 64100: 0.050543\n",
      "2024-03-01 04:28:35,754 INFO     Training average positive_sample_loss at step 64200: 0.070644\n",
      "2024-03-01 04:28:35,755 INFO     Training average negative_sample_loss at step 64200: 0.030680\n",
      "2024-03-01 04:28:35,755 INFO     Training average loss at step 64200: 0.050662\n",
      "2024-03-01 04:31:49,821 INFO     Training average positive_sample_loss at step 64300: 0.070597\n",
      "2024-03-01 04:31:49,822 INFO     Training average negative_sample_loss at step 64300: 0.030926\n",
      "2024-03-01 04:31:49,822 INFO     Training average loss at step 64300: 0.050761\n",
      "2024-03-01 04:34:44,619 INFO     Training average positive_sample_loss at step 64400: 0.070275\n",
      "2024-03-01 04:34:44,619 INFO     Training average negative_sample_loss at step 64400: 0.030925\n",
      "2024-03-01 04:34:44,619 INFO     Training average loss at step 64400: 0.050600\n",
      "2024-03-01 04:37:57,271 INFO     Training average positive_sample_loss at step 64500: 0.070885\n",
      "2024-03-01 04:37:57,271 INFO     Training average negative_sample_loss at step 64500: 0.030516\n",
      "2024-03-01 04:37:57,271 INFO     Training average loss at step 64500: 0.050701\n",
      "2024-03-01 04:41:53,621 INFO     Training average positive_sample_loss at step 64600: 0.071772\n",
      "2024-03-01 04:41:53,621 INFO     Training average negative_sample_loss at step 64600: 0.030603\n",
      "2024-03-01 04:41:53,622 INFO     Training average loss at step 64600: 0.051187\n",
      "2024-03-01 04:45:08,284 INFO     Training average positive_sample_loss at step 64700: 0.070549\n",
      "2024-03-01 04:45:08,284 INFO     Training average negative_sample_loss at step 64700: 0.030775\n",
      "2024-03-01 04:45:08,284 INFO     Training average loss at step 64700: 0.050662\n",
      "2024-03-01 04:48:17,158 INFO     Training average positive_sample_loss at step 64800: 0.070736\n",
      "2024-03-01 04:48:17,158 INFO     Training average negative_sample_loss at step 64800: 0.030488\n",
      "2024-03-01 04:48:17,158 INFO     Training average loss at step 64800: 0.050612\n",
      "2024-03-01 04:51:26,250 INFO     Training average positive_sample_loss at step 64900: 0.070947\n",
      "2024-03-01 04:51:26,251 INFO     Training average negative_sample_loss at step 64900: 0.030758\n",
      "2024-03-01 04:51:26,251 INFO     Training average loss at step 64900: 0.050852\n",
      "2024-03-01 04:54:34,644 INFO     Training average positive_sample_loss at step 65000: 0.070735\n",
      "2024-03-01 04:54:34,645 INFO     Training average negative_sample_loss at step 65000: 0.030336\n",
      "2024-03-01 04:54:34,645 INFO     Training average loss at step 65000: 0.050536\n",
      "2024-03-01 04:57:50,279 INFO     Training average positive_sample_loss at step 65100: 0.070932\n",
      "2024-03-01 04:57:50,279 INFO     Training average negative_sample_loss at step 65100: 0.030741\n",
      "2024-03-01 04:57:50,279 INFO     Training average loss at step 65100: 0.050836\n",
      "2024-03-01 05:01:41,080 INFO     Training average positive_sample_loss at step 65200: 0.070919\n",
      "2024-03-01 05:01:41,081 INFO     Training average negative_sample_loss at step 65200: 0.030647\n",
      "2024-03-01 05:01:41,081 INFO     Training average loss at step 65200: 0.050783\n",
      "2024-03-01 05:04:36,107 INFO     Training average positive_sample_loss at step 65300: 0.070611\n",
      "2024-03-01 05:04:36,108 INFO     Training average negative_sample_loss at step 65300: 0.030853\n",
      "2024-03-01 05:04:36,108 INFO     Training average loss at step 65300: 0.050732\n",
      "2024-03-01 05:07:37,534 INFO     Training average positive_sample_loss at step 65400: 0.070321\n",
      "2024-03-01 05:07:37,535 INFO     Training average negative_sample_loss at step 65400: 0.030375\n",
      "2024-03-01 05:07:37,535 INFO     Training average loss at step 65400: 0.050348\n",
      "2024-03-01 05:10:28,274 INFO     Training average positive_sample_loss at step 65500: 0.071167\n",
      "2024-03-01 05:10:28,275 INFO     Training average negative_sample_loss at step 65500: 0.030604\n",
      "2024-03-01 05:10:28,275 INFO     Training average loss at step 65500: 0.050886\n",
      "2024-03-01 05:13:47,320 INFO     Training average positive_sample_loss at step 65600: 0.070689\n",
      "2024-03-01 05:13:47,320 INFO     Training average negative_sample_loss at step 65600: 0.030838\n",
      "2024-03-01 05:13:47,320 INFO     Training average loss at step 65600: 0.050764\n",
      "2024-03-01 05:17:00,517 INFO     Training average positive_sample_loss at step 65700: 0.070053\n",
      "2024-03-01 05:17:00,518 INFO     Training average negative_sample_loss at step 65700: 0.030522\n",
      "2024-03-01 05:17:00,518 INFO     Training average loss at step 65700: 0.050287\n",
      "2024-03-01 05:19:59,516 INFO     Training average positive_sample_loss at step 65800: 0.070984\n",
      "2024-03-01 05:19:59,517 INFO     Training average negative_sample_loss at step 65800: 0.030771\n",
      "2024-03-01 05:19:59,517 INFO     Training average loss at step 65800: 0.050878\n",
      "2024-03-01 05:23:17,063 INFO     Training average positive_sample_loss at step 65900: 0.071137\n",
      "2024-03-01 05:23:17,063 INFO     Training average negative_sample_loss at step 65900: 0.030714\n",
      "2024-03-01 05:23:17,063 INFO     Training average loss at step 65900: 0.050925\n",
      "2024-03-01 05:26:27,012 INFO     Training average positive_sample_loss at step 66000: 0.070801\n",
      "2024-03-01 05:26:27,013 INFO     Training average negative_sample_loss at step 66000: 0.030363\n",
      "2024-03-01 05:26:27,013 INFO     Training average loss at step 66000: 0.050582\n",
      "2024-03-01 05:29:30,543 INFO     Training average positive_sample_loss at step 66100: 0.070537\n",
      "2024-03-01 05:29:30,544 INFO     Training average negative_sample_loss at step 66100: 0.030648\n",
      "2024-03-01 05:29:30,544 INFO     Training average loss at step 66100: 0.050592\n",
      "2024-03-01 05:32:25,829 INFO     Training average positive_sample_loss at step 66200: 0.070952\n",
      "2024-03-01 05:32:25,829 INFO     Training average negative_sample_loss at step 66200: 0.030470\n",
      "2024-03-01 05:32:25,829 INFO     Training average loss at step 66200: 0.050711\n",
      "2024-03-01 05:35:34,022 INFO     Training average positive_sample_loss at step 66300: 0.071069\n",
      "2024-03-01 05:35:34,022 INFO     Training average negative_sample_loss at step 66300: 0.030809\n",
      "2024-03-01 05:35:34,022 INFO     Training average loss at step 66300: 0.050939\n",
      "2024-03-01 05:38:39,330 INFO     Training average positive_sample_loss at step 66400: 0.070022\n",
      "2024-03-01 05:38:39,331 INFO     Training average negative_sample_loss at step 66400: 0.030639\n",
      "2024-03-01 05:38:39,331 INFO     Training average loss at step 66400: 0.050330\n",
      "2024-03-01 05:41:40,949 INFO     Training average positive_sample_loss at step 66500: 0.070699\n",
      "2024-03-01 05:41:40,950 INFO     Training average negative_sample_loss at step 66500: 0.030143\n",
      "2024-03-01 05:41:40,950 INFO     Training average loss at step 66500: 0.050421\n",
      "2024-03-01 05:44:23,403 INFO     Training average positive_sample_loss at step 66600: 0.071548\n",
      "2024-03-01 05:44:23,404 INFO     Training average negative_sample_loss at step 66600: 0.031137\n",
      "2024-03-01 05:44:23,404 INFO     Training average loss at step 66600: 0.051343\n",
      "2024-03-01 05:47:37,444 INFO     Training average positive_sample_loss at step 66700: 0.070640\n",
      "2024-03-01 05:47:37,444 INFO     Training average negative_sample_loss at step 66700: 0.030396\n",
      "2024-03-01 05:47:37,444 INFO     Training average loss at step 66700: 0.050518\n",
      "2024-03-01 05:50:42,442 INFO     Training average positive_sample_loss at step 66800: 0.070322\n",
      "2024-03-01 05:50:42,443 INFO     Training average negative_sample_loss at step 66800: 0.030640\n",
      "2024-03-01 05:50:42,443 INFO     Training average loss at step 66800: 0.050481\n",
      "2024-03-01 05:53:53,211 INFO     Training average positive_sample_loss at step 66900: 0.070842\n",
      "2024-03-01 05:53:53,212 INFO     Training average negative_sample_loss at step 66900: 0.030470\n",
      "2024-03-01 05:53:53,212 INFO     Training average loss at step 66900: 0.050656\n",
      "2024-03-01 05:56:54,110 INFO     Training average positive_sample_loss at step 67000: 0.071119\n",
      "2024-03-01 05:56:54,111 INFO     Training average negative_sample_loss at step 67000: 0.030613\n",
      "2024-03-01 05:56:54,111 INFO     Training average loss at step 67000: 0.050866\n",
      "2024-03-01 05:59:52,285 INFO     Training average positive_sample_loss at step 67100: 0.070659\n",
      "2024-03-01 05:59:52,286 INFO     Training average negative_sample_loss at step 67100: 0.030385\n",
      "2024-03-01 05:59:52,286 INFO     Training average loss at step 67100: 0.050522\n",
      "2024-03-01 06:02:54,010 INFO     Training average positive_sample_loss at step 67200: 0.070479\n",
      "2024-03-01 06:02:54,011 INFO     Training average negative_sample_loss at step 67200: 0.030653\n",
      "2024-03-01 06:02:54,011 INFO     Training average loss at step 67200: 0.050566\n",
      "2024-03-01 06:05:53,251 INFO     Training average positive_sample_loss at step 67300: 0.071100\n",
      "2024-03-01 06:05:53,251 INFO     Training average negative_sample_loss at step 67300: 0.031059\n",
      "2024-03-01 06:05:53,251 INFO     Training average loss at step 67300: 0.051079\n",
      "2024-03-01 06:09:30,249 INFO     Training average positive_sample_loss at step 67400: 0.070454\n",
      "2024-03-01 06:09:30,249 INFO     Training average negative_sample_loss at step 67400: 0.030405\n",
      "2024-03-01 06:09:30,250 INFO     Training average loss at step 67400: 0.050430\n",
      "2024-03-01 06:12:58,264 INFO     Training average positive_sample_loss at step 67500: 0.070380\n",
      "2024-03-01 06:12:58,265 INFO     Training average negative_sample_loss at step 67500: 0.030517\n",
      "2024-03-01 06:12:58,265 INFO     Training average loss at step 67500: 0.050448\n",
      "2024-03-01 06:16:58,744 INFO     Training average positive_sample_loss at step 67600: 0.071212\n",
      "2024-03-01 06:16:58,744 INFO     Training average negative_sample_loss at step 67600: 0.030853\n",
      "2024-03-01 06:16:58,744 INFO     Training average loss at step 67600: 0.051033\n",
      "2024-03-01 06:20:09,156 INFO     Training average positive_sample_loss at step 67700: 0.070725\n",
      "2024-03-01 06:20:09,157 INFO     Training average negative_sample_loss at step 67700: 0.030531\n",
      "2024-03-01 06:20:09,157 INFO     Training average loss at step 67700: 0.050628\n",
      "2024-03-01 06:23:31,243 INFO     Training average positive_sample_loss at step 67800: 0.070597\n",
      "2024-03-01 06:23:31,244 INFO     Training average negative_sample_loss at step 67800: 0.030472\n",
      "2024-03-01 06:23:31,244 INFO     Training average loss at step 67800: 0.050535\n",
      "2024-03-01 06:26:52,220 INFO     Training average positive_sample_loss at step 67900: 0.071109\n",
      "2024-03-01 06:26:52,220 INFO     Training average negative_sample_loss at step 67900: 0.030691\n",
      "2024-03-01 06:26:52,220 INFO     Training average loss at step 67900: 0.050900\n",
      "2024-03-01 06:30:16,581 INFO     Training average positive_sample_loss at step 68000: 0.070610\n",
      "2024-03-01 06:30:16,581 INFO     Training average negative_sample_loss at step 68000: 0.030583\n",
      "2024-03-01 06:30:16,581 INFO     Training average loss at step 68000: 0.050597\n",
      "2024-03-01 06:32:53,591 INFO     Training average positive_sample_loss at step 68100: 0.070091\n",
      "2024-03-01 06:32:53,592 INFO     Training average negative_sample_loss at step 68100: 0.029943\n",
      "2024-03-01 06:32:53,592 INFO     Training average loss at step 68100: 0.050017\n",
      "2024-03-01 06:35:42,695 INFO     Training average positive_sample_loss at step 68200: 0.071124\n",
      "2024-03-01 06:35:42,696 INFO     Training average negative_sample_loss at step 68200: 0.030785\n",
      "2024-03-01 06:35:42,696 INFO     Training average loss at step 68200: 0.050955\n",
      "2024-03-01 06:38:25,309 INFO     Training average positive_sample_loss at step 68300: 0.071013\n",
      "2024-03-01 06:38:25,310 INFO     Training average negative_sample_loss at step 68300: 0.030913\n",
      "2024-03-01 06:38:25,310 INFO     Training average loss at step 68300: 0.050963\n",
      "2024-03-01 06:41:46,012 INFO     Training average positive_sample_loss at step 68400: 0.070778\n",
      "2024-03-01 06:41:46,012 INFO     Training average negative_sample_loss at step 68400: 0.030807\n",
      "2024-03-01 06:41:46,012 INFO     Training average loss at step 68400: 0.050792\n",
      "2024-03-01 06:45:00,349 INFO     Training average positive_sample_loss at step 68500: 0.070127\n",
      "2024-03-01 06:45:00,349 INFO     Training average negative_sample_loss at step 68500: 0.030683\n",
      "2024-03-01 06:45:00,349 INFO     Training average loss at step 68500: 0.050405\n",
      "2024-03-01 06:47:54,083 INFO     Training average positive_sample_loss at step 68600: 0.070768\n",
      "2024-03-01 06:47:54,084 INFO     Training average negative_sample_loss at step 68600: 0.030312\n",
      "2024-03-01 06:47:54,084 INFO     Training average loss at step 68600: 0.050540\n",
      "2024-03-01 06:50:42,946 INFO     Training average positive_sample_loss at step 68700: 0.071130\n",
      "2024-03-01 06:50:42,947 INFO     Training average negative_sample_loss at step 68700: 0.030564\n",
      "2024-03-01 06:50:42,947 INFO     Training average loss at step 68700: 0.050847\n",
      "2024-03-01 06:53:32,888 INFO     Training average positive_sample_loss at step 68800: 0.069878\n",
      "2024-03-01 06:53:32,888 INFO     Training average negative_sample_loss at step 68800: 0.030676\n",
      "2024-03-01 06:53:32,888 INFO     Training average loss at step 68800: 0.050277\n",
      "2024-03-01 06:56:17,853 INFO     Training average positive_sample_loss at step 68900: 0.070845\n",
      "2024-03-01 06:56:17,853 INFO     Training average negative_sample_loss at step 68900: 0.030365\n",
      "2024-03-01 06:56:17,853 INFO     Training average loss at step 68900: 0.050605\n",
      "2024-03-01 06:59:23,415 INFO     Training average positive_sample_loss at step 69000: 0.070988\n",
      "2024-03-01 06:59:23,415 INFO     Training average negative_sample_loss at step 69000: 0.030643\n",
      "2024-03-01 06:59:23,415 INFO     Training average loss at step 69000: 0.050815\n",
      "2024-03-01 07:02:20,928 INFO     Training average positive_sample_loss at step 69100: 0.070558\n",
      "2024-03-01 07:02:20,929 INFO     Training average negative_sample_loss at step 69100: 0.030720\n",
      "2024-03-01 07:02:20,929 INFO     Training average loss at step 69100: 0.050639\n",
      "2024-03-01 07:05:36,885 INFO     Training average positive_sample_loss at step 69200: 0.070499\n",
      "2024-03-01 07:05:36,886 INFO     Training average negative_sample_loss at step 69200: 0.030693\n",
      "2024-03-01 07:05:36,886 INFO     Training average loss at step 69200: 0.050596\n",
      "2024-03-01 07:08:36,167 INFO     Training average positive_sample_loss at step 69300: 0.070694\n",
      "2024-03-01 07:08:36,167 INFO     Training average negative_sample_loss at step 69300: 0.030281\n",
      "2024-03-01 07:08:36,167 INFO     Training average loss at step 69300: 0.050487\n",
      "2024-03-01 07:11:48,240 INFO     Training average positive_sample_loss at step 69400: 0.071399\n",
      "2024-03-01 07:11:48,241 INFO     Training average negative_sample_loss at step 69400: 0.030675\n",
      "2024-03-01 07:11:48,241 INFO     Training average loss at step 69400: 0.051037\n",
      "2024-03-01 07:14:41,437 INFO     Training average positive_sample_loss at step 69500: 0.070462\n",
      "2024-03-01 07:14:41,437 INFO     Training average negative_sample_loss at step 69500: 0.030311\n",
      "2024-03-01 07:14:41,437 INFO     Training average loss at step 69500: 0.050387\n",
      "2024-03-01 07:17:25,232 INFO     Training average positive_sample_loss at step 69600: 0.071127\n",
      "2024-03-01 07:17:25,232 INFO     Training average negative_sample_loss at step 69600: 0.030493\n",
      "2024-03-01 07:17:25,232 INFO     Training average loss at step 69600: 0.050810\n",
      "2024-03-01 07:20:30,340 INFO     Training average positive_sample_loss at step 69700: 0.070438\n",
      "2024-03-01 07:20:30,340 INFO     Training average negative_sample_loss at step 69700: 0.030673\n",
      "2024-03-01 07:20:30,340 INFO     Training average loss at step 69700: 0.050556\n",
      "2024-03-01 07:23:26,362 INFO     Training average positive_sample_loss at step 69800: 0.070507\n",
      "2024-03-01 07:23:26,363 INFO     Training average negative_sample_loss at step 69800: 0.030379\n",
      "2024-03-01 07:23:26,363 INFO     Training average loss at step 69800: 0.050443\n",
      "2024-03-01 07:26:38,483 INFO     Training average positive_sample_loss at step 69900: 0.070710\n",
      "2024-03-01 07:26:38,484 INFO     Training average negative_sample_loss at step 69900: 0.030644\n",
      "2024-03-01 07:26:38,484 INFO     Training average loss at step 69900: 0.050677\n",
      "2024-03-01 07:29:53,429 INFO     Training average positive_sample_loss at step 70000: 0.070772\n",
      "2024-03-01 07:29:53,429 INFO     Training average negative_sample_loss at step 70000: 0.030766\n",
      "2024-03-01 07:29:53,429 INFO     Training average loss at step 70000: 0.050769\n",
      "2024-03-01 07:29:53,429 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 07:29:54,101 INFO     Evaluating the model... (0/760)\n",
      "2024-03-01 07:30:23,583 INFO     Valid MRR at step 70000: 0.463170\n",
      "2024-03-01 07:30:23,584 INFO     Valid MR at step 70000: 4808.854153\n",
      "2024-03-01 07:30:23,584 INFO     Valid HITS@1 at step 70000: 0.422380\n",
      "2024-03-01 07:30:23,584 INFO     Valid HITS@3 at step 70000: 0.480224\n",
      "2024-03-01 07:30:23,584 INFO     Valid HITS@10 at step 70000: 0.542683\n",
      "2024-03-01 07:33:03,258 INFO     Training average positive_sample_loss at step 70100: 0.070390\n",
      "2024-03-01 07:33:03,259 INFO     Training average negative_sample_loss at step 70100: 0.030393\n",
      "2024-03-01 07:33:03,259 INFO     Training average loss at step 70100: 0.050391\n",
      "2024-03-01 07:36:14,795 INFO     Training average positive_sample_loss at step 70200: 0.070815\n",
      "2024-03-01 07:36:14,796 INFO     Training average negative_sample_loss at step 70200: 0.030979\n",
      "2024-03-01 07:36:14,796 INFO     Training average loss at step 70200: 0.050897\n",
      "2024-03-01 07:39:29,851 INFO     Training average positive_sample_loss at step 70300: 0.070522\n",
      "2024-03-01 07:39:29,852 INFO     Training average negative_sample_loss at step 70300: 0.030229\n",
      "2024-03-01 07:39:29,852 INFO     Training average loss at step 70300: 0.050375\n",
      "2024-03-01 07:42:51,022 INFO     Training average positive_sample_loss at step 70400: 0.070798\n",
      "2024-03-01 07:42:51,023 INFO     Training average negative_sample_loss at step 70400: 0.030489\n",
      "2024-03-01 07:42:51,023 INFO     Training average loss at step 70400: 0.050644\n",
      "2024-03-01 07:45:57,933 INFO     Training average positive_sample_loss at step 70500: 0.070604\n",
      "2024-03-01 07:45:57,934 INFO     Training average negative_sample_loss at step 70500: 0.030451\n",
      "2024-03-01 07:45:57,934 INFO     Training average loss at step 70500: 0.050528\n",
      "2024-03-01 07:49:12,397 INFO     Training average positive_sample_loss at step 70600: 0.070649\n",
      "2024-03-01 07:49:12,397 INFO     Training average negative_sample_loss at step 70600: 0.030598\n",
      "2024-03-01 07:49:12,397 INFO     Training average loss at step 70600: 0.050624\n",
      "2024-03-01 07:52:27,424 INFO     Training average positive_sample_loss at step 70700: 0.070802\n",
      "2024-03-01 07:52:27,424 INFO     Training average negative_sample_loss at step 70700: 0.030483\n",
      "2024-03-01 07:52:27,424 INFO     Training average loss at step 70700: 0.050642\n",
      "2024-03-01 07:55:55,503 INFO     Training average positive_sample_loss at step 70800: 0.070315\n",
      "2024-03-01 07:55:55,504 INFO     Training average negative_sample_loss at step 70800: 0.030529\n",
      "2024-03-01 07:55:55,504 INFO     Training average loss at step 70800: 0.050422\n",
      "2024-03-01 07:59:36,972 INFO     Training average positive_sample_loss at step 70900: 0.070820\n",
      "2024-03-01 07:59:36,972 INFO     Training average negative_sample_loss at step 70900: 0.030761\n",
      "2024-03-01 07:59:36,972 INFO     Training average loss at step 70900: 0.050790\n",
      "2024-03-01 08:03:09,970 INFO     Training average positive_sample_loss at step 71000: 0.071006\n",
      "2024-03-01 08:03:09,970 INFO     Training average negative_sample_loss at step 71000: 0.030658\n",
      "2024-03-01 08:03:09,970 INFO     Training average loss at step 71000: 0.050832\n",
      "2024-03-01 08:06:34,128 INFO     Training average positive_sample_loss at step 71100: 0.070258\n",
      "2024-03-01 08:06:34,128 INFO     Training average negative_sample_loss at step 71100: 0.030075\n",
      "2024-03-01 08:06:34,128 INFO     Training average loss at step 71100: 0.050167\n",
      "2024-03-01 08:09:50,096 INFO     Training average positive_sample_loss at step 71200: 0.070571\n",
      "2024-03-01 08:09:50,097 INFO     Training average negative_sample_loss at step 71200: 0.030866\n",
      "2024-03-01 08:09:50,097 INFO     Training average loss at step 71200: 0.050719\n",
      "2024-03-01 08:13:17,366 INFO     Training average positive_sample_loss at step 71300: 0.070808\n",
      "2024-03-01 08:13:17,366 INFO     Training average negative_sample_loss at step 71300: 0.030481\n",
      "2024-03-01 08:13:17,366 INFO     Training average loss at step 71300: 0.050644\n",
      "2024-03-01 08:16:47,135 INFO     Training average positive_sample_loss at step 71400: 0.071007\n",
      "2024-03-01 08:16:47,136 INFO     Training average negative_sample_loss at step 71400: 0.030415\n",
      "2024-03-01 08:16:47,136 INFO     Training average loss at step 71400: 0.050711\n",
      "2024-03-01 08:19:41,748 INFO     Training average positive_sample_loss at step 71500: 0.069954\n",
      "2024-03-01 08:19:41,749 INFO     Training average negative_sample_loss at step 71500: 0.030261\n",
      "2024-03-01 08:19:41,749 INFO     Training average loss at step 71500: 0.050107\n",
      "2024-03-01 08:23:06,130 INFO     Training average positive_sample_loss at step 71600: 0.071158\n",
      "2024-03-01 08:23:06,130 INFO     Training average negative_sample_loss at step 71600: 0.030733\n",
      "2024-03-01 08:23:06,130 INFO     Training average loss at step 71600: 0.050945\n",
      "2024-03-01 08:26:16,586 INFO     Training average positive_sample_loss at step 71700: 0.070619\n",
      "2024-03-01 08:26:16,587 INFO     Training average negative_sample_loss at step 71700: 0.030441\n",
      "2024-03-01 08:26:16,587 INFO     Training average loss at step 71700: 0.050530\n",
      "2024-03-01 08:29:57,097 INFO     Training average positive_sample_loss at step 71800: 0.070353\n",
      "2024-03-01 08:29:57,097 INFO     Training average negative_sample_loss at step 71800: 0.030417\n",
      "2024-03-01 08:29:57,097 INFO     Training average loss at step 71800: 0.050385\n",
      "2024-03-01 08:33:19,302 INFO     Training average positive_sample_loss at step 71900: 0.070763\n",
      "2024-03-01 08:33:19,302 INFO     Training average negative_sample_loss at step 71900: 0.030422\n",
      "2024-03-01 08:33:19,302 INFO     Training average loss at step 71900: 0.050593\n",
      "2024-03-01 08:36:08,750 INFO     Training average positive_sample_loss at step 72000: 0.070701\n",
      "2024-03-01 08:36:08,751 INFO     Training average negative_sample_loss at step 72000: 0.030840\n",
      "2024-03-01 08:36:08,751 INFO     Training average loss at step 72000: 0.050771\n",
      "2024-03-01 08:39:25,597 INFO     Training average positive_sample_loss at step 72100: 0.070841\n",
      "2024-03-01 08:39:25,597 INFO     Training average negative_sample_loss at step 72100: 0.030453\n",
      "2024-03-01 08:39:25,597 INFO     Training average loss at step 72100: 0.050647\n",
      "2024-03-01 08:42:16,926 INFO     Training average positive_sample_loss at step 72200: 0.070588\n",
      "2024-03-01 08:42:16,926 INFO     Training average negative_sample_loss at step 72200: 0.030336\n",
      "2024-03-01 08:42:16,926 INFO     Training average loss at step 72200: 0.050462\n",
      "2024-03-01 08:45:19,346 INFO     Training average positive_sample_loss at step 72300: 0.070565\n",
      "2024-03-01 08:45:19,347 INFO     Training average negative_sample_loss at step 72300: 0.030626\n",
      "2024-03-01 08:45:19,347 INFO     Training average loss at step 72300: 0.050595\n",
      "2024-03-01 08:48:47,531 INFO     Training average positive_sample_loss at step 72400: 0.070853\n",
      "2024-03-01 08:48:47,532 INFO     Training average negative_sample_loss at step 72400: 0.030433\n",
      "2024-03-01 08:48:47,532 INFO     Training average loss at step 72400: 0.050643\n",
      "2024-03-01 08:52:02,890 INFO     Training average positive_sample_loss at step 72500: 0.069953\n",
      "2024-03-01 08:52:02,890 INFO     Training average negative_sample_loss at step 72500: 0.030509\n",
      "2024-03-01 08:52:02,890 INFO     Training average loss at step 72500: 0.050231\n",
      "2024-03-01 08:55:25,338 INFO     Training average positive_sample_loss at step 72600: 0.071064\n",
      "2024-03-01 08:55:25,338 INFO     Training average negative_sample_loss at step 72600: 0.030563\n",
      "2024-03-01 08:55:25,338 INFO     Training average loss at step 72600: 0.050814\n",
      "2024-03-01 08:58:50,890 INFO     Training average positive_sample_loss at step 72700: 0.070731\n",
      "2024-03-01 08:58:50,890 INFO     Training average negative_sample_loss at step 72700: 0.030599\n",
      "2024-03-01 08:58:50,890 INFO     Training average loss at step 72700: 0.050665\n",
      "2024-03-01 09:02:26,442 INFO     Training average positive_sample_loss at step 72800: 0.070647\n",
      "2024-03-01 09:02:26,442 INFO     Training average negative_sample_loss at step 72800: 0.030723\n",
      "2024-03-01 09:02:26,443 INFO     Training average loss at step 72800: 0.050685\n",
      "2024-03-01 09:06:13,085 INFO     Training average positive_sample_loss at step 72900: 0.070464\n",
      "2024-03-01 09:06:13,086 INFO     Training average negative_sample_loss at step 72900: 0.030285\n",
      "2024-03-01 09:06:13,086 INFO     Training average loss at step 72900: 0.050375\n",
      "2024-03-01 09:09:32,790 INFO     Training average positive_sample_loss at step 73000: 0.070414\n",
      "2024-03-01 09:09:32,791 INFO     Training average negative_sample_loss at step 73000: 0.030798\n",
      "2024-03-01 09:09:32,791 INFO     Training average loss at step 73000: 0.050606\n",
      "2024-03-01 09:12:57,590 INFO     Training average positive_sample_loss at step 73100: 0.071086\n",
      "2024-03-01 09:12:57,591 INFO     Training average negative_sample_loss at step 73100: 0.030255\n",
      "2024-03-01 09:12:57,591 INFO     Training average loss at step 73100: 0.050670\n",
      "2024-03-01 09:16:05,402 INFO     Training average positive_sample_loss at step 73200: 0.070049\n",
      "2024-03-01 09:16:05,403 INFO     Training average negative_sample_loss at step 73200: 0.030389\n",
      "2024-03-01 09:16:05,403 INFO     Training average loss at step 73200: 0.050219\n",
      "2024-03-01 09:19:27,580 INFO     Training average positive_sample_loss at step 73300: 0.070553\n",
      "2024-03-01 09:19:27,580 INFO     Training average negative_sample_loss at step 73300: 0.030345\n",
      "2024-03-01 09:19:27,580 INFO     Training average loss at step 73300: 0.050449\n",
      "2024-03-01 09:22:43,549 INFO     Training average positive_sample_loss at step 73400: 0.071140\n",
      "2024-03-01 09:22:43,549 INFO     Training average negative_sample_loss at step 73400: 0.030502\n",
      "2024-03-01 09:22:43,549 INFO     Training average loss at step 73400: 0.050821\n",
      "2024-03-01 09:26:12,647 INFO     Training average positive_sample_loss at step 73500: 0.070218\n",
      "2024-03-01 09:26:12,648 INFO     Training average negative_sample_loss at step 73500: 0.030651\n",
      "2024-03-01 09:26:12,648 INFO     Training average loss at step 73500: 0.050434\n",
      "2024-03-01 09:29:25,236 INFO     Training average positive_sample_loss at step 73600: 0.070817\n",
      "2024-03-01 09:29:25,237 INFO     Training average negative_sample_loss at step 73600: 0.030631\n",
      "2024-03-01 09:29:25,237 INFO     Training average loss at step 73600: 0.050724\n",
      "2024-03-01 09:32:51,903 INFO     Training average positive_sample_loss at step 73700: 0.070502\n",
      "2024-03-01 09:32:51,903 INFO     Training average negative_sample_loss at step 73700: 0.030213\n",
      "2024-03-01 09:32:51,903 INFO     Training average loss at step 73700: 0.050358\n",
      "2024-03-01 09:36:17,873 INFO     Training average positive_sample_loss at step 73800: 0.070822\n",
      "2024-03-01 09:36:17,873 INFO     Training average negative_sample_loss at step 73800: 0.030408\n",
      "2024-03-01 09:36:17,874 INFO     Training average loss at step 73800: 0.050615\n",
      "2024-03-01 09:39:36,821 INFO     Training average positive_sample_loss at step 73900: 0.070256\n",
      "2024-03-01 09:39:36,821 INFO     Training average negative_sample_loss at step 73900: 0.030426\n",
      "2024-03-01 09:39:36,822 INFO     Training average loss at step 73900: 0.050341\n",
      "2024-03-01 09:43:09,716 INFO     Training average positive_sample_loss at step 74000: 0.070743\n",
      "2024-03-01 09:43:09,717 INFO     Training average negative_sample_loss at step 74000: 0.030479\n",
      "2024-03-01 09:43:09,717 INFO     Training average loss at step 74000: 0.050611\n",
      "2024-03-01 09:46:36,508 INFO     Training average positive_sample_loss at step 74100: 0.070974\n",
      "2024-03-01 09:46:36,509 INFO     Training average negative_sample_loss at step 74100: 0.030723\n",
      "2024-03-01 09:46:36,509 INFO     Training average loss at step 74100: 0.050848\n",
      "2024-03-01 09:50:05,715 INFO     Training average positive_sample_loss at step 74200: 0.070266\n",
      "2024-03-01 09:50:05,716 INFO     Training average negative_sample_loss at step 74200: 0.030521\n",
      "2024-03-01 09:50:05,716 INFO     Training average loss at step 74200: 0.050393\n",
      "2024-03-01 09:53:03,262 INFO     Training average positive_sample_loss at step 74300: 0.070623\n",
      "2024-03-01 09:53:03,262 INFO     Training average negative_sample_loss at step 74300: 0.030720\n",
      "2024-03-01 09:53:03,262 INFO     Training average loss at step 74300: 0.050671\n",
      "2024-03-01 09:56:22,861 INFO     Training average positive_sample_loss at step 74400: 0.070914\n",
      "2024-03-01 09:56:22,861 INFO     Training average negative_sample_loss at step 74400: 0.030590\n",
      "2024-03-01 09:56:22,861 INFO     Training average loss at step 74400: 0.050752\n",
      "2024-03-01 09:59:59,421 INFO     Training average positive_sample_loss at step 74500: 0.070571\n",
      "2024-03-01 09:59:59,421 INFO     Training average negative_sample_loss at step 74500: 0.030281\n",
      "2024-03-01 09:59:59,421 INFO     Training average loss at step 74500: 0.050426\n",
      "2024-03-01 10:03:27,038 INFO     Training average positive_sample_loss at step 74600: 0.070138\n",
      "2024-03-01 10:03:27,039 INFO     Training average negative_sample_loss at step 74600: 0.030131\n",
      "2024-03-01 10:03:27,039 INFO     Training average loss at step 74600: 0.050135\n",
      "2024-03-01 10:06:38,130 INFO     Training average positive_sample_loss at step 74700: 0.070603\n",
      "2024-03-01 10:06:38,131 INFO     Training average negative_sample_loss at step 74700: 0.030595\n",
      "2024-03-01 10:06:38,131 INFO     Training average loss at step 74700: 0.050599\n",
      "2024-03-01 10:10:02,623 INFO     Training average positive_sample_loss at step 74800: 0.070947\n",
      "2024-03-01 10:10:02,624 INFO     Training average negative_sample_loss at step 74800: 0.030560\n",
      "2024-03-01 10:10:02,624 INFO     Training average loss at step 74800: 0.050753\n",
      "2024-03-01 10:13:01,128 INFO     Training average positive_sample_loss at step 74900: 0.070423\n",
      "2024-03-01 10:13:01,129 INFO     Training average negative_sample_loss at step 74900: 0.030613\n",
      "2024-03-01 10:13:01,129 INFO     Training average loss at step 74900: 0.050518\n",
      "2024-03-01 10:16:27,144 INFO     Training average positive_sample_loss at step 75000: 0.070523\n",
      "2024-03-01 10:16:27,145 INFO     Training average negative_sample_loss at step 75000: 0.030289\n",
      "2024-03-01 10:16:27,145 INFO     Training average loss at step 75000: 0.050406\n",
      "2024-03-01 10:19:37,646 INFO     Training average positive_sample_loss at step 75100: 0.070666\n",
      "2024-03-01 10:19:37,646 INFO     Training average negative_sample_loss at step 75100: 0.030338\n",
      "2024-03-01 10:19:37,646 INFO     Training average loss at step 75100: 0.050502\n",
      "2024-03-01 10:23:10,802 INFO     Training average positive_sample_loss at step 75200: 0.070317\n",
      "2024-03-01 10:23:10,803 INFO     Training average negative_sample_loss at step 75200: 0.030243\n",
      "2024-03-01 10:23:10,803 INFO     Training average loss at step 75200: 0.050280\n",
      "2024-03-01 10:26:26,051 INFO     Training average positive_sample_loss at step 75300: 0.070677\n",
      "2024-03-01 10:26:26,052 INFO     Training average negative_sample_loss at step 75300: 0.030298\n",
      "2024-03-01 10:26:26,052 INFO     Training average loss at step 75300: 0.050487\n",
      "2024-03-01 10:29:54,928 INFO     Training average positive_sample_loss at step 75400: 0.070659\n",
      "2024-03-01 10:29:54,928 INFO     Training average negative_sample_loss at step 75400: 0.030712\n",
      "2024-03-01 10:29:54,928 INFO     Training average loss at step 75400: 0.050686\n",
      "2024-03-01 10:32:54,821 INFO     Training average positive_sample_loss at step 75500: 0.070667\n",
      "2024-03-01 10:32:54,821 INFO     Training average negative_sample_loss at step 75500: 0.030713\n",
      "2024-03-01 10:32:54,821 INFO     Training average loss at step 75500: 0.050690\n",
      "2024-03-01 10:35:55,782 INFO     Training average positive_sample_loss at step 75600: 0.070128\n",
      "2024-03-01 10:35:55,782 INFO     Training average negative_sample_loss at step 75600: 0.030465\n",
      "2024-03-01 10:35:55,782 INFO     Training average loss at step 75600: 0.050297\n",
      "2024-03-01 10:38:41,274 INFO     Training average positive_sample_loss at step 75700: 0.070611\n",
      "2024-03-01 10:38:41,274 INFO     Training average negative_sample_loss at step 75700: 0.030392\n",
      "2024-03-01 10:38:41,274 INFO     Training average loss at step 75700: 0.050502\n",
      "2024-03-01 10:41:44,440 INFO     Training average positive_sample_loss at step 75800: 0.070931\n",
      "2024-03-01 10:41:44,440 INFO     Training average negative_sample_loss at step 75800: 0.030389\n",
      "2024-03-01 10:41:44,440 INFO     Training average loss at step 75800: 0.050660\n",
      "2024-03-01 10:44:32,685 INFO     Training average positive_sample_loss at step 75900: 0.070590\n",
      "2024-03-01 10:44:32,686 INFO     Training average negative_sample_loss at step 75900: 0.030385\n",
      "2024-03-01 10:44:32,686 INFO     Training average loss at step 75900: 0.050487\n",
      "2024-03-01 10:48:08,798 INFO     Training average positive_sample_loss at step 76000: 0.070400\n",
      "2024-03-01 10:48:08,799 INFO     Training average negative_sample_loss at step 76000: 0.030401\n",
      "2024-03-01 10:48:08,799 INFO     Training average loss at step 76000: 0.050401\n",
      "2024-03-01 10:51:00,464 INFO     Training average positive_sample_loss at step 76100: 0.070852\n",
      "2024-03-01 10:51:00,465 INFO     Training average negative_sample_loss at step 76100: 0.030602\n",
      "2024-03-01 10:51:00,465 INFO     Training average loss at step 76100: 0.050727\n",
      "2024-03-01 10:54:06,948 INFO     Training average positive_sample_loss at step 76200: 0.070247\n",
      "2024-03-01 10:54:06,948 INFO     Training average negative_sample_loss at step 76200: 0.030311\n",
      "2024-03-01 10:54:06,948 INFO     Training average loss at step 76200: 0.050279\n",
      "2024-03-01 10:57:06,520 INFO     Training average positive_sample_loss at step 76300: 0.070669\n",
      "2024-03-01 10:57:06,521 INFO     Training average negative_sample_loss at step 76300: 0.030519\n",
      "2024-03-01 10:57:06,521 INFO     Training average loss at step 76300: 0.050594\n",
      "2024-03-01 11:00:15,904 INFO     Training average positive_sample_loss at step 76400: 0.070663\n",
      "2024-03-01 11:00:15,905 INFO     Training average negative_sample_loss at step 76400: 0.030338\n",
      "2024-03-01 11:00:15,905 INFO     Training average loss at step 76400: 0.050500\n",
      "2024-03-01 11:03:47,465 INFO     Training average positive_sample_loss at step 76500: 0.070462\n",
      "2024-03-01 11:03:47,465 INFO     Training average negative_sample_loss at step 76500: 0.030654\n",
      "2024-03-01 11:03:47,465 INFO     Training average loss at step 76500: 0.050558\n",
      "2024-03-01 11:06:58,681 INFO     Training average positive_sample_loss at step 76600: 0.070024\n",
      "2024-03-01 11:06:58,682 INFO     Training average negative_sample_loss at step 76600: 0.030476\n",
      "2024-03-01 11:06:58,682 INFO     Training average loss at step 76600: 0.050250\n",
      "2024-03-01 11:09:45,428 INFO     Training average positive_sample_loss at step 76700: 0.071010\n",
      "2024-03-01 11:09:45,429 INFO     Training average negative_sample_loss at step 76700: 0.030433\n",
      "2024-03-01 11:09:45,429 INFO     Training average loss at step 76700: 0.050721\n",
      "2024-03-01 11:12:28,945 INFO     Training average positive_sample_loss at step 76800: 0.070334\n",
      "2024-03-01 11:12:28,945 INFO     Training average negative_sample_loss at step 76800: 0.030383\n",
      "2024-03-01 11:12:28,945 INFO     Training average loss at step 76800: 0.050359\n",
      "2024-03-01 11:16:14,665 INFO     Training average positive_sample_loss at step 76900: 0.070614\n",
      "2024-03-01 11:16:14,666 INFO     Training average negative_sample_loss at step 76900: 0.030272\n",
      "2024-03-01 11:16:14,666 INFO     Training average loss at step 76900: 0.050443\n",
      "2024-03-01 11:19:59,743 INFO     Training average positive_sample_loss at step 77000: 0.070508\n",
      "2024-03-01 11:19:59,743 INFO     Training average negative_sample_loss at step 77000: 0.030310\n",
      "2024-03-01 11:19:59,743 INFO     Training average loss at step 77000: 0.050409\n",
      "2024-03-01 11:22:56,170 INFO     Training average positive_sample_loss at step 77100: 0.070336\n",
      "2024-03-01 11:22:56,170 INFO     Training average negative_sample_loss at step 77100: 0.030692\n",
      "2024-03-01 11:22:56,170 INFO     Training average loss at step 77100: 0.050514\n",
      "2024-03-01 11:25:49,806 INFO     Training average positive_sample_loss at step 77200: 0.070618\n",
      "2024-03-01 11:25:49,806 INFO     Training average negative_sample_loss at step 77200: 0.030356\n",
      "2024-03-01 11:25:49,806 INFO     Training average loss at step 77200: 0.050487\n",
      "2024-03-01 11:28:51,809 INFO     Training average positive_sample_loss at step 77300: 0.070362\n",
      "2024-03-01 11:28:51,810 INFO     Training average negative_sample_loss at step 77300: 0.030559\n",
      "2024-03-01 11:28:51,810 INFO     Training average loss at step 77300: 0.050460\n",
      "2024-03-01 11:32:06,956 INFO     Training average positive_sample_loss at step 77400: 0.070348\n",
      "2024-03-01 11:32:06,956 INFO     Training average negative_sample_loss at step 77400: 0.030211\n",
      "2024-03-01 11:32:06,957 INFO     Training average loss at step 77400: 0.050280\n",
      "2024-03-01 11:35:29,333 INFO     Training average positive_sample_loss at step 77500: 0.071052\n",
      "2024-03-01 11:35:29,333 INFO     Training average negative_sample_loss at step 77500: 0.030514\n",
      "2024-03-01 11:35:29,333 INFO     Training average loss at step 77500: 0.050783\n",
      "2024-03-01 11:38:13,374 INFO     Training average positive_sample_loss at step 77600: 0.070282\n",
      "2024-03-01 11:38:13,375 INFO     Training average negative_sample_loss at step 77600: 0.030631\n",
      "2024-03-01 11:38:13,375 INFO     Training average loss at step 77600: 0.050456\n",
      "2024-03-01 11:41:07,634 INFO     Training average positive_sample_loss at step 77700: 0.070559\n",
      "2024-03-01 11:41:07,635 INFO     Training average negative_sample_loss at step 77700: 0.030291\n",
      "2024-03-01 11:41:07,636 INFO     Training average loss at step 77700: 0.050425\n",
      "2024-03-01 11:44:22,075 INFO     Training average positive_sample_loss at step 77800: 0.070898\n",
      "2024-03-01 11:44:22,076 INFO     Training average negative_sample_loss at step 77800: 0.030330\n",
      "2024-03-01 11:44:22,076 INFO     Training average loss at step 77800: 0.050614\n",
      "2024-03-01 11:48:02,081 INFO     Training average positive_sample_loss at step 77900: 0.070296\n",
      "2024-03-01 11:48:02,081 INFO     Training average negative_sample_loss at step 77900: 0.030433\n",
      "2024-03-01 11:48:02,081 INFO     Training average loss at step 77900: 0.050364\n",
      "2024-03-01 11:51:12,250 INFO     Training average positive_sample_loss at step 78000: 0.070619\n",
      "2024-03-01 11:51:12,251 INFO     Training average negative_sample_loss at step 78000: 0.030495\n",
      "2024-03-01 11:51:12,251 INFO     Training average loss at step 78000: 0.050557\n",
      "2024-03-01 11:54:25,265 INFO     Training average positive_sample_loss at step 78100: 0.070218\n",
      "2024-03-01 11:54:25,266 INFO     Training average negative_sample_loss at step 78100: 0.030392\n",
      "2024-03-01 11:54:25,266 INFO     Training average loss at step 78100: 0.050305\n",
      "2024-03-01 11:58:07,890 INFO     Training average positive_sample_loss at step 78200: 0.070851\n",
      "2024-03-01 11:58:07,891 INFO     Training average negative_sample_loss at step 78200: 0.030307\n",
      "2024-03-01 11:58:07,891 INFO     Training average loss at step 78200: 0.050579\n",
      "2024-03-01 12:01:14,233 INFO     Training average positive_sample_loss at step 78300: 0.070168\n",
      "2024-03-01 12:01:14,234 INFO     Training average negative_sample_loss at step 78300: 0.030299\n",
      "2024-03-01 12:01:14,234 INFO     Training average loss at step 78300: 0.050234\n",
      "2024-03-01 12:04:37,102 INFO     Training average positive_sample_loss at step 78400: 0.070465\n",
      "2024-03-01 12:04:37,103 INFO     Training average negative_sample_loss at step 78400: 0.030502\n",
      "2024-03-01 12:04:37,103 INFO     Training average loss at step 78400: 0.050483\n",
      "2024-03-01 12:07:35,343 INFO     Training average positive_sample_loss at step 78500: 0.070991\n",
      "2024-03-01 12:07:35,343 INFO     Training average negative_sample_loss at step 78500: 0.030538\n",
      "2024-03-01 12:07:35,343 INFO     Training average loss at step 78500: 0.050764\n",
      "2024-03-01 12:11:33,237 INFO     Training average positive_sample_loss at step 78600: 0.069944\n",
      "2024-03-01 12:11:33,237 INFO     Training average negative_sample_loss at step 78600: 0.030210\n",
      "2024-03-01 12:11:33,237 INFO     Training average loss at step 78600: 0.050077\n",
      "2024-03-01 12:15:06,343 INFO     Training average positive_sample_loss at step 78700: 0.070248\n",
      "2024-03-01 12:15:06,344 INFO     Training average negative_sample_loss at step 78700: 0.030135\n",
      "2024-03-01 12:15:06,344 INFO     Training average loss at step 78700: 0.050192\n",
      "2024-03-01 12:18:28,117 INFO     Training average positive_sample_loss at step 78800: 0.071100\n",
      "2024-03-01 12:18:28,117 INFO     Training average negative_sample_loss at step 78800: 0.030649\n",
      "2024-03-01 12:18:28,117 INFO     Training average loss at step 78800: 0.050874\n",
      "2024-03-01 12:21:24,100 INFO     Training average positive_sample_loss at step 78900: 0.070399\n",
      "2024-03-01 12:21:24,100 INFO     Training average negative_sample_loss at step 78900: 0.030367\n",
      "2024-03-01 12:21:24,100 INFO     Training average loss at step 78900: 0.050383\n",
      "2024-03-01 12:24:26,769 INFO     Training average positive_sample_loss at step 79000: 0.070523\n",
      "2024-03-01 12:24:26,769 INFO     Training average negative_sample_loss at step 79000: 0.030372\n",
      "2024-03-01 12:24:26,769 INFO     Training average loss at step 79000: 0.050447\n",
      "2024-03-01 12:27:48,053 INFO     Training average positive_sample_loss at step 79100: 0.070459\n",
      "2024-03-01 12:27:48,054 INFO     Training average negative_sample_loss at step 79100: 0.030225\n",
      "2024-03-01 12:27:48,054 INFO     Training average loss at step 79100: 0.050342\n",
      "2024-03-01 12:31:17,765 INFO     Training average positive_sample_loss at step 79200: 0.070613\n",
      "2024-03-01 12:31:17,766 INFO     Training average negative_sample_loss at step 79200: 0.030581\n",
      "2024-03-01 12:31:17,766 INFO     Training average loss at step 79200: 0.050597\n",
      "2024-03-01 12:34:17,741 INFO     Training average positive_sample_loss at step 79300: 0.070257\n",
      "2024-03-01 12:34:17,742 INFO     Training average negative_sample_loss at step 79300: 0.030407\n",
      "2024-03-01 12:34:17,742 INFO     Training average loss at step 79300: 0.050332\n",
      "2024-03-01 12:37:52,120 INFO     Training average positive_sample_loss at step 79400: 0.070632\n",
      "2024-03-01 12:37:52,120 INFO     Training average negative_sample_loss at step 79400: 0.030648\n",
      "2024-03-01 12:37:52,121 INFO     Training average loss at step 79400: 0.050640\n",
      "2024-03-01 12:41:01,429 INFO     Training average positive_sample_loss at step 79500: 0.070426\n",
      "2024-03-01 12:41:01,429 INFO     Training average negative_sample_loss at step 79500: 0.030264\n",
      "2024-03-01 12:41:01,429 INFO     Training average loss at step 79500: 0.050345\n",
      "2024-03-01 12:44:15,528 INFO     Training average positive_sample_loss at step 79600: 0.070248\n",
      "2024-03-01 12:44:15,529 INFO     Training average negative_sample_loss at step 79600: 0.030296\n",
      "2024-03-01 12:44:15,529 INFO     Training average loss at step 79600: 0.050272\n",
      "2024-03-01 12:47:21,867 INFO     Training average positive_sample_loss at step 79700: 0.070130\n",
      "2024-03-01 12:47:21,867 INFO     Training average negative_sample_loss at step 79700: 0.030678\n",
      "2024-03-01 12:47:21,868 INFO     Training average loss at step 79700: 0.050404\n",
      "2024-03-01 12:50:21,194 INFO     Training average positive_sample_loss at step 79800: 0.070605\n",
      "2024-03-01 12:50:21,195 INFO     Training average negative_sample_loss at step 79800: 0.030429\n",
      "2024-03-01 12:50:21,195 INFO     Training average loss at step 79800: 0.050517\n",
      "2024-03-01 12:53:21,917 INFO     Training average positive_sample_loss at step 79900: 0.071067\n",
      "2024-03-01 12:53:21,918 INFO     Training average negative_sample_loss at step 79900: 0.030398\n",
      "2024-03-01 12:53:21,918 INFO     Training average loss at step 79900: 0.050732\n",
      "2024-03-01 12:56:01,239 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 12:56:01,790 INFO     Evaluating the model... (0/760)\n",
      "2024-03-01 12:56:29,610 INFO     Valid MRR at step 79999: 0.462967\n",
      "2024-03-01 12:56:29,611 INFO     Valid MR at step 79999: 4789.266809\n",
      "2024-03-01 12:56:29,611 INFO     Valid HITS@1 at step 79999: 0.421721\n",
      "2024-03-01 12:56:29,611 INFO     Valid HITS@3 at step 79999: 0.480224\n",
      "2024-03-01 12:56:29,611 INFO     Valid HITS@10 at step 79999: 0.543177\n",
      "2024-03-01 12:56:29,611 INFO     Evaluating on Test Dataset...\n",
      "2024-03-01 12:56:30,117 INFO     Evaluating the model... (0/784)\n",
      "2024-03-01 12:56:56,271 INFO     Test MRR at step 79999: 0.459030\n",
      "2024-03-01 12:56:56,271 INFO     Test MR at step 79999: 4915.477505\n",
      "2024-03-01 12:56:56,271 INFO     Test HITS@1 at step 79999: 0.417358\n",
      "2024-03-01 12:56:56,271 INFO     Test HITS@3 at step 79999: 0.477505\n",
      "2024-03-01 12:56:56,271 INFO     Test HITS@10 at step 79999: 0.538768\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE wn18rr 0 0 512 1024 500 6.0 0.5 0.00005 80000 8 -de"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
