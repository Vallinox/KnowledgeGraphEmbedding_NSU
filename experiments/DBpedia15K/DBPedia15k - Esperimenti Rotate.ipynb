{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con Self. Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding\n"
     ]
    }
   ],
   "source": [
    "%cd vsegreto1/KnowledgeGraphEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-05 22:35:32,336 INFO     Model: RotatE\n",
      "2023-12-05 22:35:32,336 INFO     Data Path: data/DBpedia15K\n",
      "2023-12-05 22:35:32,337 INFO     #entity: 12863\n",
      "2023-12-05 22:35:32,337 INFO     #relation: 279\n",
      "2023-12-05 22:35:32,490 INFO     #train: 131918\n",
      "2023-12-05 22:35:32,524 INFO     #valid: 14659\n",
      "2023-12-05 22:35:32,574 INFO     #test: 36645\n",
      "2023-12-05 22:35:32,717 INFO     Model Parameter Configuration:\n",
      "2023-12-05 22:35:32,717 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-05 22:35:32,718 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-05 22:35:32,718 INFO     Parameter entity_embedding: torch.Size([12863, 2000]), require_grad = True\n",
      "2023-12-05 22:35:32,718 INFO     Parameter relation_embedding: torch.Size([279, 1000]), require_grad = True\n",
      "2023-12-05 22:35:34,093 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-05 22:35:34,093 INFO     Start Training...\n",
      "2023-12-05 22:35:34,093 INFO     init_step = 0\n",
      "2023-12-05 22:35:34,093 INFO     batch_size = 1024\n",
      "2023-12-05 22:35:34,093 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-05 22:35:34,093 INFO     hidden_dim = 1000\n",
      "2023-12-05 22:35:34,093 INFO     gamma = 9.000000\n",
      "2023-12-05 22:35:34,093 INFO     negative_adversarial_sampling = True\n",
      "2023-12-05 22:35:34,093 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-05 22:35:34,093 INFO     learning_rate = 0\n",
      "2023-12-05 22:35:45,833 INFO     Training average positive_sample_loss at step 0: 2.561013\n",
      "2023-12-05 22:35:45,834 INFO     Training average negative_sample_loss at step 0: 0.083559\n",
      "2023-12-05 22:35:45,834 INFO     Training average loss at step 0: 1.322286\n",
      "2023-12-05 22:35:45,834 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 22:35:46,277 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 22:36:11,827 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 22:36:33,160 INFO     Valid MRR at step 0: 0.007295\n",
      "2023-12-05 22:36:33,161 INFO     Valid MR at step 0: 4975.589058\n",
      "2023-12-05 22:36:33,161 INFO     Valid HITS@1 at step 0: 0.005901\n",
      "2023-12-05 22:36:33,161 INFO     Valid HITS@3 at step 0: 0.006310\n",
      "2023-12-05 22:36:33,161 INFO     Valid HITS@10 at step 0: 0.007879\n",
      "2023-12-05 22:36:38,870 INFO     Training average positive_sample_loss at step 100: 2.126610\n",
      "2023-12-05 22:36:38,870 INFO     Training average negative_sample_loss at step 100: 0.143372\n",
      "2023-12-05 22:36:38,870 INFO     Training average loss at step 100: 1.134991\n",
      "2023-12-05 22:36:44,612 INFO     Training average positive_sample_loss at step 200: 1.184917\n",
      "2023-12-05 22:36:44,612 INFO     Training average negative_sample_loss at step 200: 0.372907\n",
      "2023-12-05 22:36:44,612 INFO     Training average loss at step 200: 0.778912\n",
      "2023-12-05 22:36:50,479 INFO     Training average positive_sample_loss at step 300: 0.768311\n",
      "2023-12-05 22:36:50,479 INFO     Training average negative_sample_loss at step 300: 0.496963\n",
      "2023-12-05 22:36:50,479 INFO     Training average loss at step 300: 0.632637\n",
      "2023-12-05 22:36:55,956 INFO     Training average positive_sample_loss at step 400: 0.614033\n",
      "2023-12-05 22:36:55,956 INFO     Training average negative_sample_loss at step 400: 0.507076\n",
      "2023-12-05 22:36:55,956 INFO     Training average loss at step 400: 0.560555\n",
      "2023-12-05 22:37:01,702 INFO     Training average positive_sample_loss at step 500: 0.571255\n",
      "2023-12-05 22:37:01,703 INFO     Training average negative_sample_loss at step 500: 0.497428\n",
      "2023-12-05 22:37:01,703 INFO     Training average loss at step 500: 0.534341\n",
      "2023-12-05 22:37:07,744 INFO     Training average positive_sample_loss at step 600: 0.481322\n",
      "2023-12-05 22:37:07,744 INFO     Training average negative_sample_loss at step 600: 0.474121\n",
      "2023-12-05 22:37:07,745 INFO     Training average loss at step 600: 0.477721\n",
      "2023-12-05 22:37:13,168 INFO     Training average positive_sample_loss at step 700: 0.478496\n",
      "2023-12-05 22:37:13,169 INFO     Training average negative_sample_loss at step 700: 0.441923\n",
      "2023-12-05 22:37:13,169 INFO     Training average loss at step 700: 0.460209\n",
      "2023-12-05 22:37:19,287 INFO     Training average positive_sample_loss at step 800: 0.448237\n",
      "2023-12-05 22:37:19,287 INFO     Training average negative_sample_loss at step 800: 0.421845\n",
      "2023-12-05 22:37:19,288 INFO     Training average loss at step 800: 0.435041\n",
      "2023-12-05 22:37:24,543 INFO     Training average positive_sample_loss at step 900: 0.415873\n",
      "2023-12-05 22:37:24,543 INFO     Training average negative_sample_loss at step 900: 0.389326\n",
      "2023-12-05 22:37:24,543 INFO     Training average loss at step 900: 0.402599\n",
      "2023-12-05 22:37:29,845 INFO     Training average positive_sample_loss at step 1000: 0.417301\n",
      "2023-12-05 22:37:29,845 INFO     Training average negative_sample_loss at step 1000: 0.371586\n",
      "2023-12-05 22:37:29,845 INFO     Training average loss at step 1000: 0.394444\n",
      "2023-12-05 22:37:35,726 INFO     Training average positive_sample_loss at step 1100: 0.377896\n",
      "2023-12-05 22:37:35,726 INFO     Training average negative_sample_loss at step 1100: 0.351433\n",
      "2023-12-05 22:37:35,726 INFO     Training average loss at step 1100: 0.364665\n",
      "2023-12-05 22:37:41,021 INFO     Training average positive_sample_loss at step 1200: 0.375702\n",
      "2023-12-05 22:37:41,021 INFO     Training average negative_sample_loss at step 1200: 0.328938\n",
      "2023-12-05 22:37:41,021 INFO     Training average loss at step 1200: 0.352320\n",
      "2023-12-05 22:37:47,341 INFO     Training average positive_sample_loss at step 1300: 0.367446\n",
      "2023-12-05 22:37:47,341 INFO     Training average negative_sample_loss at step 1300: 0.318315\n",
      "2023-12-05 22:37:47,341 INFO     Training average loss at step 1300: 0.342880\n",
      "2023-12-05 22:37:52,646 INFO     Training average positive_sample_loss at step 1400: 0.335677\n",
      "2023-12-05 22:37:52,646 INFO     Training average negative_sample_loss at step 1400: 0.298117\n",
      "2023-12-05 22:37:52,647 INFO     Training average loss at step 1400: 0.316897\n",
      "2023-12-05 22:37:57,859 INFO     Training average positive_sample_loss at step 1500: 0.341731\n",
      "2023-12-05 22:37:57,860 INFO     Training average negative_sample_loss at step 1500: 0.285485\n",
      "2023-12-05 22:37:57,860 INFO     Training average loss at step 1500: 0.313608\n",
      "2023-12-05 22:38:03,648 INFO     Training average positive_sample_loss at step 1600: 0.319562\n",
      "2023-12-05 22:38:03,648 INFO     Training average negative_sample_loss at step 1600: 0.276641\n",
      "2023-12-05 22:38:03,648 INFO     Training average loss at step 1600: 0.298101\n",
      "2023-12-05 22:38:09,469 INFO     Training average positive_sample_loss at step 1700: 0.313469\n",
      "2023-12-05 22:38:09,470 INFO     Training average negative_sample_loss at step 1700: 0.259710\n",
      "2023-12-05 22:38:09,470 INFO     Training average loss at step 1700: 0.286590\n",
      "2023-12-05 22:38:14,639 INFO     Training average positive_sample_loss at step 1800: 0.313335\n",
      "2023-12-05 22:38:14,639 INFO     Training average negative_sample_loss at step 1800: 0.253152\n",
      "2023-12-05 22:38:14,639 INFO     Training average loss at step 1800: 0.283243\n",
      "2023-12-05 22:38:20,434 INFO     Training average positive_sample_loss at step 1900: 0.284479\n",
      "2023-12-05 22:38:20,434 INFO     Training average negative_sample_loss at step 1900: 0.241715\n",
      "2023-12-05 22:38:20,435 INFO     Training average loss at step 1900: 0.263097\n",
      "2023-12-05 22:38:25,609 INFO     Training average positive_sample_loss at step 2000: 0.292175\n",
      "2023-12-05 22:38:25,609 INFO     Training average negative_sample_loss at step 2000: 0.232624\n",
      "2023-12-05 22:38:25,609 INFO     Training average loss at step 2000: 0.262400\n",
      "2023-12-05 22:38:32,115 INFO     Training average positive_sample_loss at step 2100: 0.278425\n",
      "2023-12-05 22:38:32,115 INFO     Training average negative_sample_loss at step 2100: 0.227949\n",
      "2023-12-05 22:38:32,116 INFO     Training average loss at step 2100: 0.253187\n",
      "2023-12-05 22:38:37,373 INFO     Training average positive_sample_loss at step 2200: 0.269278\n",
      "2023-12-05 22:38:37,373 INFO     Training average negative_sample_loss at step 2200: 0.215940\n",
      "2023-12-05 22:38:37,373 INFO     Training average loss at step 2200: 0.242609\n",
      "2023-12-05 22:38:42,726 INFO     Training average positive_sample_loss at step 2300: 0.273558\n",
      "2023-12-05 22:38:42,726 INFO     Training average negative_sample_loss at step 2300: 0.212039\n",
      "2023-12-05 22:38:42,726 INFO     Training average loss at step 2300: 0.242798\n",
      "2023-12-05 22:38:48,502 INFO     Training average positive_sample_loss at step 2400: 0.252449\n",
      "2023-12-05 22:38:48,502 INFO     Training average negative_sample_loss at step 2400: 0.205715\n",
      "2023-12-05 22:38:48,502 INFO     Training average loss at step 2400: 0.229082\n",
      "2023-12-05 22:38:53,807 INFO     Training average positive_sample_loss at step 2500: 0.255653\n",
      "2023-12-05 22:38:53,807 INFO     Training average negative_sample_loss at step 2500: 0.197414\n",
      "2023-12-05 22:38:53,807 INFO     Training average loss at step 2500: 0.226534\n",
      "2023-12-05 22:39:00,243 INFO     Training average positive_sample_loss at step 2600: 0.249783\n",
      "2023-12-05 22:39:00,244 INFO     Training average negative_sample_loss at step 2600: 0.195173\n",
      "2023-12-05 22:39:00,244 INFO     Training average loss at step 2600: 0.222478\n",
      "2023-12-05 22:39:05,548 INFO     Training average positive_sample_loss at step 2700: 0.236976\n",
      "2023-12-05 22:39:05,548 INFO     Training average negative_sample_loss at step 2700: 0.185869\n",
      "2023-12-05 22:39:05,548 INFO     Training average loss at step 2700: 0.211422\n",
      "2023-12-05 22:39:10,813 INFO     Training average positive_sample_loss at step 2800: 0.243778\n",
      "2023-12-05 22:39:10,813 INFO     Training average negative_sample_loss at step 2800: 0.183626\n",
      "2023-12-05 22:39:10,813 INFO     Training average loss at step 2800: 0.213702\n",
      "2023-12-05 22:39:16,752 INFO     Training average positive_sample_loss at step 2900: 0.227616\n",
      "2023-12-05 22:39:16,753 INFO     Training average negative_sample_loss at step 2900: 0.179780\n",
      "2023-12-05 22:39:16,753 INFO     Training average loss at step 2900: 0.203698\n",
      "2023-12-05 22:39:22,171 INFO     Training average positive_sample_loss at step 3000: 0.228851\n",
      "2023-12-05 22:39:22,171 INFO     Training average negative_sample_loss at step 3000: 0.172716\n",
      "2023-12-05 22:39:22,171 INFO     Training average loss at step 3000: 0.200783\n",
      "2023-12-05 22:39:28,630 INFO     Training average positive_sample_loss at step 3100: 0.229147\n",
      "2023-12-05 22:39:28,631 INFO     Training average negative_sample_loss at step 3100: 0.172468\n",
      "2023-12-05 22:39:28,631 INFO     Training average loss at step 3100: 0.200808\n",
      "2023-12-05 22:39:33,830 INFO     Training average positive_sample_loss at step 3200: 0.212875\n",
      "2023-12-05 22:39:33,831 INFO     Training average negative_sample_loss at step 3200: 0.166506\n",
      "2023-12-05 22:39:33,831 INFO     Training average loss at step 3200: 0.189691\n",
      "2023-12-05 22:39:39,210 INFO     Training average positive_sample_loss at step 3300: 0.220310\n",
      "2023-12-05 22:39:39,210 INFO     Training average negative_sample_loss at step 3300: 0.163279\n",
      "2023-12-05 22:39:39,210 INFO     Training average loss at step 3300: 0.191795\n",
      "2023-12-05 22:39:45,191 INFO     Training average positive_sample_loss at step 3400: 0.208636\n",
      "2023-12-05 22:39:45,191 INFO     Training average negative_sample_loss at step 3400: 0.160933\n",
      "2023-12-05 22:39:45,191 INFO     Training average loss at step 3400: 0.184784\n",
      "2023-12-05 22:39:50,413 INFO     Training average positive_sample_loss at step 3500: 0.208455\n",
      "2023-12-05 22:39:50,414 INFO     Training average negative_sample_loss at step 3500: 0.155421\n",
      "2023-12-05 22:39:50,414 INFO     Training average loss at step 3500: 0.181938\n",
      "2023-12-05 22:39:55,693 INFO     Training average positive_sample_loss at step 3600: 0.211589\n",
      "2023-12-05 22:39:55,693 INFO     Training average negative_sample_loss at step 3600: 0.155412\n",
      "2023-12-05 22:39:55,693 INFO     Training average loss at step 3600: 0.183500\n",
      "2023-12-05 22:40:01,565 INFO     Training average positive_sample_loss at step 3700: 0.195138\n",
      "2023-12-05 22:40:01,566 INFO     Training average negative_sample_loss at step 3700: 0.151592\n",
      "2023-12-05 22:40:01,566 INFO     Training average loss at step 3700: 0.173365\n",
      "2023-12-05 22:40:06,942 INFO     Training average positive_sample_loss at step 3800: 0.202985\n",
      "2023-12-05 22:40:06,942 INFO     Training average negative_sample_loss at step 3800: 0.148514\n",
      "2023-12-05 22:40:06,943 INFO     Training average loss at step 3800: 0.175749\n",
      "2023-12-05 22:40:13,096 INFO     Training average positive_sample_loss at step 3900: 0.196677\n",
      "2023-12-05 22:40:13,096 INFO     Training average negative_sample_loss at step 3900: 0.149077\n",
      "2023-12-05 22:40:13,096 INFO     Training average loss at step 3900: 0.172877\n",
      "2023-12-05 22:40:18,572 INFO     Training average positive_sample_loss at step 4000: 0.191957\n",
      "2023-12-05 22:40:18,573 INFO     Training average negative_sample_loss at step 4000: 0.143379\n",
      "2023-12-05 22:40:18,573 INFO     Training average loss at step 4000: 0.167668\n",
      "2023-12-05 22:40:23,868 INFO     Training average positive_sample_loss at step 4100: 0.196762\n",
      "2023-12-05 22:40:23,868 INFO     Training average negative_sample_loss at step 4100: 0.143568\n",
      "2023-12-05 22:40:23,868 INFO     Training average loss at step 4100: 0.170165\n",
      "2023-12-05 22:40:29,979 INFO     Training average positive_sample_loss at step 4200: 0.184255\n",
      "2023-12-05 22:40:29,979 INFO     Training average negative_sample_loss at step 4200: 0.141696\n",
      "2023-12-05 22:40:29,979 INFO     Training average loss at step 4200: 0.162976\n",
      "2023-12-05 22:40:35,161 INFO     Training average positive_sample_loss at step 4300: 0.188696\n",
      "2023-12-05 22:40:35,161 INFO     Training average negative_sample_loss at step 4300: 0.138271\n",
      "2023-12-05 22:40:35,161 INFO     Training average loss at step 4300: 0.163484\n",
      "2023-12-05 22:40:41,379 INFO     Training average positive_sample_loss at step 4400: 0.187455\n",
      "2023-12-05 22:40:41,379 INFO     Training average negative_sample_loss at step 4400: 0.139183\n",
      "2023-12-05 22:40:41,379 INFO     Training average loss at step 4400: 0.163319\n",
      "2023-12-05 22:40:46,928 INFO     Training average positive_sample_loss at step 4500: 0.177732\n",
      "2023-12-05 22:40:46,929 INFO     Training average negative_sample_loss at step 4500: 0.134304\n",
      "2023-12-05 22:40:46,929 INFO     Training average loss at step 4500: 0.156018\n",
      "2023-12-05 22:40:52,213 INFO     Training average positive_sample_loss at step 4600: 0.185770\n",
      "2023-12-05 22:40:52,214 INFO     Training average negative_sample_loss at step 4600: 0.133843\n",
      "2023-12-05 22:40:52,214 INFO     Training average loss at step 4600: 0.159807\n",
      "2023-12-05 22:40:58,432 INFO     Training average positive_sample_loss at step 4700: 0.175656\n",
      "2023-12-05 22:40:58,433 INFO     Training average negative_sample_loss at step 4700: 0.134142\n",
      "2023-12-05 22:40:58,433 INFO     Training average loss at step 4700: 0.154899\n",
      "2023-12-05 22:41:03,905 INFO     Training average positive_sample_loss at step 4800: 0.177752\n",
      "2023-12-05 22:41:03,906 INFO     Training average negative_sample_loss at step 4800: 0.130224\n",
      "2023-12-05 22:41:03,906 INFO     Training average loss at step 4800: 0.153988\n",
      "2023-12-05 22:41:09,449 INFO     Training average positive_sample_loss at step 4900: 0.180688\n",
      "2023-12-05 22:41:09,449 INFO     Training average negative_sample_loss at step 4900: 0.130500\n",
      "2023-12-05 22:41:09,449 INFO     Training average loss at step 4900: 0.155594\n",
      "2023-12-05 22:41:15,376 INFO     Training average positive_sample_loss at step 5000: 0.168031\n",
      "2023-12-05 22:41:15,377 INFO     Training average negative_sample_loss at step 5000: 0.128710\n",
      "2023-12-05 22:41:15,377 INFO     Training average loss at step 5000: 0.148370\n",
      "2023-12-05 22:41:20,759 INFO     Training average positive_sample_loss at step 5100: 0.174820\n",
      "2023-12-05 22:41:20,760 INFO     Training average negative_sample_loss at step 5100: 0.126383\n",
      "2023-12-05 22:41:20,760 INFO     Training average loss at step 5100: 0.150601\n",
      "2023-12-05 22:41:27,377 INFO     Training average positive_sample_loss at step 5200: 0.169826\n",
      "2023-12-05 22:41:27,377 INFO     Training average negative_sample_loss at step 5200: 0.128408\n",
      "2023-12-05 22:41:27,377 INFO     Training average loss at step 5200: 0.149117\n",
      "2023-12-05 22:41:32,602 INFO     Training average positive_sample_loss at step 5300: 0.168626\n",
      "2023-12-05 22:41:32,602 INFO     Training average negative_sample_loss at step 5300: 0.124257\n",
      "2023-12-05 22:41:32,603 INFO     Training average loss at step 5300: 0.146442\n",
      "2023-12-05 22:41:37,937 INFO     Training average positive_sample_loss at step 5400: 0.172331\n",
      "2023-12-05 22:41:37,938 INFO     Training average negative_sample_loss at step 5400: 0.124868\n",
      "2023-12-05 22:41:37,938 INFO     Training average loss at step 5400: 0.148600\n",
      "2023-12-05 22:41:44,429 INFO     Training average positive_sample_loss at step 5500: 0.161771\n",
      "2023-12-05 22:41:44,429 INFO     Training average negative_sample_loss at step 5500: 0.123084\n",
      "2023-12-05 22:41:44,429 INFO     Training average loss at step 5500: 0.142428\n",
      "2023-12-05 22:41:49,658 INFO     Training average positive_sample_loss at step 5600: 0.167839\n",
      "2023-12-05 22:41:49,659 INFO     Training average negative_sample_loss at step 5600: 0.121698\n",
      "2023-12-05 22:41:49,659 INFO     Training average loss at step 5600: 0.144769\n",
      "2023-12-05 22:41:55,597 INFO     Training average positive_sample_loss at step 5700: 0.164632\n",
      "2023-12-05 22:41:55,597 INFO     Training average negative_sample_loss at step 5700: 0.122637\n",
      "2023-12-05 22:41:55,597 INFO     Training average loss at step 5700: 0.143634\n",
      "2023-12-05 22:42:01,158 INFO     Training average positive_sample_loss at step 5800: 0.161172\n",
      "2023-12-05 22:42:01,158 INFO     Training average negative_sample_loss at step 5800: 0.119731\n",
      "2023-12-05 22:42:01,158 INFO     Training average loss at step 5800: 0.140452\n",
      "2023-12-05 22:42:06,894 INFO     Training average positive_sample_loss at step 5900: 0.165882\n",
      "2023-12-05 22:42:06,895 INFO     Training average negative_sample_loss at step 5900: 0.120028\n",
      "2023-12-05 22:42:06,895 INFO     Training average loss at step 5900: 0.142955\n",
      "2023-12-05 22:42:12,920 INFO     Training average positive_sample_loss at step 6000: 0.156800\n",
      "2023-12-05 22:42:12,921 INFO     Training average negative_sample_loss at step 6000: 0.119728\n",
      "2023-12-05 22:42:12,921 INFO     Training average loss at step 6000: 0.138264\n",
      "2023-12-05 22:42:18,609 INFO     Training average positive_sample_loss at step 6100: 0.161528\n",
      "2023-12-05 22:42:18,610 INFO     Training average negative_sample_loss at step 6100: 0.117350\n",
      "2023-12-05 22:42:18,610 INFO     Training average loss at step 6100: 0.139439\n",
      "2023-12-05 22:42:24,398 INFO     Training average positive_sample_loss at step 6200: 0.161612\n",
      "2023-12-05 22:42:24,398 INFO     Training average negative_sample_loss at step 6200: 0.118799\n",
      "2023-12-05 22:42:24,398 INFO     Training average loss at step 6200: 0.140205\n",
      "2023-12-05 22:42:29,617 INFO     Training average positive_sample_loss at step 6300: 0.153234\n",
      "2023-12-05 22:42:29,617 INFO     Training average negative_sample_loss at step 6300: 0.115877\n",
      "2023-12-05 22:42:29,617 INFO     Training average loss at step 6300: 0.134555\n",
      "2023-12-05 22:42:34,871 INFO     Training average positive_sample_loss at step 6400: 0.160856\n",
      "2023-12-05 22:42:34,872 INFO     Training average negative_sample_loss at step 6400: 0.115968\n",
      "2023-12-05 22:42:34,872 INFO     Training average loss at step 6400: 0.138412\n",
      "2023-12-05 22:42:41,070 INFO     Training average positive_sample_loss at step 6500: 0.153685\n",
      "2023-12-05 22:42:41,070 INFO     Training average negative_sample_loss at step 6500: 0.116490\n",
      "2023-12-05 22:42:41,070 INFO     Training average loss at step 6500: 0.135087\n",
      "2023-12-05 22:42:46,505 INFO     Training average positive_sample_loss at step 6600: 0.155924\n",
      "2023-12-05 22:42:46,505 INFO     Training average negative_sample_loss at step 6600: 0.114039\n",
      "2023-12-05 22:42:46,505 INFO     Training average loss at step 6600: 0.134981\n",
      "2023-12-05 22:42:51,977 INFO     Training average positive_sample_loss at step 6700: 0.158011\n",
      "2023-12-05 22:42:51,977 INFO     Training average negative_sample_loss at step 6700: 0.115159\n",
      "2023-12-05 22:42:51,977 INFO     Training average loss at step 6700: 0.136585\n",
      "2023-12-05 22:42:58,081 INFO     Training average positive_sample_loss at step 6800: 0.148895\n",
      "2023-12-05 22:42:58,081 INFO     Training average negative_sample_loss at step 6800: 0.112940\n",
      "2023-12-05 22:42:58,081 INFO     Training average loss at step 6800: 0.130918\n",
      "2023-12-05 22:43:03,352 INFO     Training average positive_sample_loss at step 6900: 0.155168\n",
      "2023-12-05 22:43:03,353 INFO     Training average negative_sample_loss at step 6900: 0.112618\n",
      "2023-12-05 22:43:03,353 INFO     Training average loss at step 6900: 0.133893\n",
      "2023-12-05 22:43:09,057 INFO     Training average positive_sample_loss at step 7000: 0.151905\n",
      "2023-12-05 22:43:09,058 INFO     Training average negative_sample_loss at step 7000: 0.114096\n",
      "2023-12-05 22:43:09,058 INFO     Training average loss at step 7000: 0.133000\n",
      "2023-12-05 22:43:14,507 INFO     Training average positive_sample_loss at step 7100: 0.150738\n",
      "2023-12-05 22:43:14,507 INFO     Training average negative_sample_loss at step 7100: 0.111598\n",
      "2023-12-05 22:43:14,507 INFO     Training average loss at step 7100: 0.131168\n",
      "2023-12-05 22:43:19,671 INFO     Training average positive_sample_loss at step 7200: 0.153808\n",
      "2023-12-05 22:43:19,671 INFO     Training average negative_sample_loss at step 7200: 0.111763\n",
      "2023-12-05 22:43:19,671 INFO     Training average loss at step 7200: 0.132785\n",
      "2023-12-05 22:43:25,368 INFO     Training average positive_sample_loss at step 7300: 0.146832\n",
      "2023-12-05 22:43:25,368 INFO     Training average negative_sample_loss at step 7300: 0.112019\n",
      "2023-12-05 22:43:25,368 INFO     Training average loss at step 7300: 0.129425\n",
      "2023-12-05 22:43:30,969 INFO     Training average positive_sample_loss at step 7400: 0.150904\n",
      "2023-12-05 22:43:30,969 INFO     Training average negative_sample_loss at step 7400: 0.109933\n",
      "2023-12-05 22:43:30,969 INFO     Training average loss at step 7400: 0.130418\n",
      "2023-12-05 22:43:36,882 INFO     Training average positive_sample_loss at step 7500: 0.150278\n",
      "2023-12-05 22:43:36,883 INFO     Training average negative_sample_loss at step 7500: 0.111753\n",
      "2023-12-05 22:43:36,883 INFO     Training average loss at step 7500: 0.131016\n",
      "2023-12-05 22:43:42,102 INFO     Training average positive_sample_loss at step 7600: 0.145604\n",
      "2023-12-05 22:43:42,102 INFO     Training average negative_sample_loss at step 7600: 0.109631\n",
      "2023-12-05 22:43:42,102 INFO     Training average loss at step 7600: 0.127618\n",
      "2023-12-05 22:43:47,540 INFO     Training average positive_sample_loss at step 7700: 0.151115\n",
      "2023-12-05 22:43:47,540 INFO     Training average negative_sample_loss at step 7700: 0.109456\n",
      "2023-12-05 22:43:47,540 INFO     Training average loss at step 7700: 0.130285\n",
      "2023-12-05 22:43:53,614 INFO     Training average positive_sample_loss at step 7800: 0.143628\n",
      "2023-12-05 22:43:53,614 INFO     Training average negative_sample_loss at step 7800: 0.109958\n",
      "2023-12-05 22:43:53,614 INFO     Training average loss at step 7800: 0.126793\n",
      "2023-12-05 22:43:58,771 INFO     Training average positive_sample_loss at step 7900: 0.147855\n",
      "2023-12-05 22:43:58,771 INFO     Training average negative_sample_loss at step 7900: 0.107418\n",
      "2023-12-05 22:43:58,771 INFO     Training average loss at step 7900: 0.127636\n",
      "2023-12-05 22:44:04,690 INFO     Training average positive_sample_loss at step 8000: 0.149641\n",
      "2023-12-05 22:44:04,690 INFO     Training average negative_sample_loss at step 8000: 0.109936\n",
      "2023-12-05 22:44:04,691 INFO     Training average loss at step 8000: 0.129788\n",
      "2023-12-05 22:44:10,053 INFO     Training average positive_sample_loss at step 8100: 0.141556\n",
      "2023-12-05 22:44:10,053 INFO     Training average negative_sample_loss at step 8100: 0.107820\n",
      "2023-12-05 22:44:10,053 INFO     Training average loss at step 8100: 0.124688\n",
      "2023-12-05 22:44:15,510 INFO     Training average positive_sample_loss at step 8200: 0.147946\n",
      "2023-12-05 22:44:15,510 INFO     Training average negative_sample_loss at step 8200: 0.106781\n",
      "2023-12-05 22:44:15,510 INFO     Training average loss at step 8200: 0.127364\n",
      "2023-12-05 22:44:21,350 INFO     Training average positive_sample_loss at step 8300: 0.142551\n",
      "2023-12-05 22:44:21,350 INFO     Training average negative_sample_loss at step 8300: 0.108853\n",
      "2023-12-05 22:44:21,350 INFO     Training average loss at step 8300: 0.125702\n",
      "2023-12-05 22:44:26,787 INFO     Training average positive_sample_loss at step 8400: 0.144579\n",
      "2023-12-05 22:44:26,788 INFO     Training average negative_sample_loss at step 8400: 0.106531\n",
      "2023-12-05 22:44:26,788 INFO     Training average loss at step 8400: 0.125555\n",
      "2023-12-05 22:44:32,238 INFO     Training average positive_sample_loss at step 8500: 0.147301\n",
      "2023-12-05 22:44:32,238 INFO     Training average negative_sample_loss at step 8500: 0.107436\n",
      "2023-12-05 22:44:32,238 INFO     Training average loss at step 8500: 0.127368\n",
      "2023-12-05 22:44:38,000 INFO     Training average positive_sample_loss at step 8600: 0.138537\n",
      "2023-12-05 22:44:38,000 INFO     Training average negative_sample_loss at step 8600: 0.106311\n",
      "2023-12-05 22:44:38,000 INFO     Training average loss at step 8600: 0.122424\n",
      "2023-12-05 22:44:43,214 INFO     Training average positive_sample_loss at step 8700: 0.145693\n",
      "2023-12-05 22:44:43,214 INFO     Training average negative_sample_loss at step 8700: 0.106802\n",
      "2023-12-05 22:44:43,214 INFO     Training average loss at step 8700: 0.126247\n",
      "2023-12-05 22:44:49,512 INFO     Training average positive_sample_loss at step 8800: 0.142677\n",
      "2023-12-05 22:44:49,513 INFO     Training average negative_sample_loss at step 8800: 0.107970\n",
      "2023-12-05 22:44:49,513 INFO     Training average loss at step 8800: 0.125324\n",
      "2023-12-05 22:44:54,661 INFO     Training average positive_sample_loss at step 8900: 0.140854\n",
      "2023-12-05 22:44:54,662 INFO     Training average negative_sample_loss at step 8900: 0.104838\n",
      "2023-12-05 22:44:54,662 INFO     Training average loss at step 8900: 0.122846\n",
      "2023-12-05 22:44:59,884 INFO     Training average positive_sample_loss at step 9000: 0.145172\n",
      "2023-12-05 22:44:59,885 INFO     Training average negative_sample_loss at step 9000: 0.105351\n",
      "2023-12-05 22:44:59,885 INFO     Training average loss at step 9000: 0.125261\n",
      "2023-12-05 22:45:05,965 INFO     Training average positive_sample_loss at step 9100: 0.137546\n",
      "2023-12-05 22:45:05,966 INFO     Training average negative_sample_loss at step 9100: 0.105384\n",
      "2023-12-05 22:45:05,966 INFO     Training average loss at step 9100: 0.121465\n",
      "2023-12-05 22:45:11,177 INFO     Training average positive_sample_loss at step 9200: 0.143102\n",
      "2023-12-05 22:45:11,177 INFO     Training average negative_sample_loss at step 9200: 0.105106\n",
      "2023-12-05 22:45:11,177 INFO     Training average loss at step 9200: 0.124104\n",
      "2023-12-05 22:45:17,634 INFO     Training average positive_sample_loss at step 9300: 0.142492\n",
      "2023-12-05 22:45:17,634 INFO     Training average negative_sample_loss at step 9300: 0.106487\n",
      "2023-12-05 22:45:17,634 INFO     Training average loss at step 9300: 0.124489\n",
      "2023-12-05 22:45:22,943 INFO     Training average positive_sample_loss at step 9400: 0.138363\n",
      "2023-12-05 22:45:22,943 INFO     Training average negative_sample_loss at step 9400: 0.104194\n",
      "2023-12-05 22:45:22,943 INFO     Training average loss at step 9400: 0.121279\n",
      "2023-12-05 22:45:28,380 INFO     Training average positive_sample_loss at step 9500: 0.142745\n",
      "2023-12-05 22:45:28,380 INFO     Training average negative_sample_loss at step 9500: 0.104884\n",
      "2023-12-05 22:45:28,380 INFO     Training average loss at step 9500: 0.123814\n",
      "2023-12-05 22:45:34,603 INFO     Training average positive_sample_loss at step 9600: 0.136783\n",
      "2023-12-05 22:45:34,604 INFO     Training average negative_sample_loss at step 9600: 0.104739\n",
      "2023-12-05 22:45:34,604 INFO     Training average loss at step 9600: 0.120761\n",
      "2023-12-05 22:45:39,931 INFO     Training average positive_sample_loss at step 9700: 0.140405\n",
      "2023-12-05 22:45:39,932 INFO     Training average negative_sample_loss at step 9700: 0.102966\n",
      "2023-12-05 22:45:39,932 INFO     Training average loss at step 9700: 0.121686\n",
      "2023-12-05 22:45:45,358 INFO     Training average positive_sample_loss at step 9800: 0.143020\n",
      "2023-12-05 22:45:45,358 INFO     Training average negative_sample_loss at step 9800: 0.105441\n",
      "2023-12-05 22:45:45,358 INFO     Training average loss at step 9800: 0.124230\n",
      "2023-12-05 22:45:51,625 INFO     Training average positive_sample_loss at step 9900: 0.134242\n",
      "2023-12-05 22:45:51,625 INFO     Training average negative_sample_loss at step 9900: 0.103435\n",
      "2023-12-05 22:45:51,625 INFO     Training average loss at step 9900: 0.118839\n",
      "2023-12-05 22:46:11,863 INFO     Training average positive_sample_loss at step 10000: 0.141032\n",
      "2023-12-05 22:46:11,863 INFO     Training average negative_sample_loss at step 10000: 0.102837\n",
      "2023-12-05 22:46:11,864 INFO     Training average loss at step 10000: 0.121934\n",
      "2023-12-05 22:46:11,864 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 22:46:12,397 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 22:46:40,650 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 22:46:56,623 INFO     Valid MRR at step 10000: 0.480542\n",
      "2023-12-05 22:46:56,623 INFO     Valid MR at step 10000: 341.512791\n",
      "2023-12-05 22:46:56,623 INFO     Valid HITS@1 at step 10000: 0.429804\n",
      "2023-12-05 22:46:56,624 INFO     Valid HITS@3 at step 10000: 0.492871\n",
      "2023-12-05 22:46:56,624 INFO     Valid HITS@10 at step 10000: 0.573231\n",
      "2023-12-05 22:47:02,550 INFO     Training average positive_sample_loss at step 10100: 0.137007\n",
      "2023-12-05 22:47:02,551 INFO     Training average negative_sample_loss at step 10100: 0.104592\n",
      "2023-12-05 22:47:02,551 INFO     Training average loss at step 10100: 0.120799\n",
      "2023-12-05 22:47:08,358 INFO     Training average positive_sample_loss at step 10200: 0.137989\n",
      "2023-12-05 22:47:08,358 INFO     Training average negative_sample_loss at step 10200: 0.101992\n",
      "2023-12-05 22:47:08,358 INFO     Training average loss at step 10200: 0.119991\n",
      "2023-12-05 22:47:13,582 INFO     Training average positive_sample_loss at step 10300: 0.141516\n",
      "2023-12-05 22:47:13,582 INFO     Training average negative_sample_loss at step 10300: 0.103675\n",
      "2023-12-05 22:47:13,582 INFO     Training average loss at step 10300: 0.122595\n",
      "2023-12-05 22:47:19,444 INFO     Training average positive_sample_loss at step 10400: 0.133306\n",
      "2023-12-05 22:47:19,444 INFO     Training average negative_sample_loss at step 10400: 0.102773\n",
      "2023-12-05 22:47:19,444 INFO     Training average loss at step 10400: 0.118039\n",
      "2023-12-05 22:47:24,625 INFO     Training average positive_sample_loss at step 10500: 0.139484\n",
      "2023-12-05 22:47:24,625 INFO     Training average negative_sample_loss at step 10500: 0.102452\n",
      "2023-12-05 22:47:24,625 INFO     Training average loss at step 10500: 0.120968\n",
      "2023-12-05 22:47:30,947 INFO     Training average positive_sample_loss at step 10600: 0.137610\n",
      "2023-12-05 22:47:30,948 INFO     Training average negative_sample_loss at step 10600: 0.103533\n",
      "2023-12-05 22:47:30,948 INFO     Training average loss at step 10600: 0.120571\n",
      "2023-12-05 22:47:36,107 INFO     Training average positive_sample_loss at step 10700: 0.134834\n",
      "2023-12-05 22:47:36,107 INFO     Training average negative_sample_loss at step 10700: 0.101323\n",
      "2023-12-05 22:47:36,107 INFO     Training average loss at step 10700: 0.118079\n",
      "2023-12-05 22:47:41,244 INFO     Training average positive_sample_loss at step 10800: 0.140079\n",
      "2023-12-05 22:47:41,244 INFO     Training average negative_sample_loss at step 10800: 0.102551\n",
      "2023-12-05 22:47:41,244 INFO     Training average loss at step 10800: 0.121315\n",
      "2023-12-05 22:47:47,660 INFO     Training average positive_sample_loss at step 10900: 0.133817\n",
      "2023-12-05 22:47:47,660 INFO     Training average negative_sample_loss at step 10900: 0.102400\n",
      "2023-12-05 22:47:47,660 INFO     Training average loss at step 10900: 0.118108\n",
      "2023-12-05 22:47:52,806 INFO     Training average positive_sample_loss at step 11000: 0.137756\n",
      "2023-12-05 22:47:52,807 INFO     Training average negative_sample_loss at step 11000: 0.101316\n",
      "2023-12-05 22:47:52,807 INFO     Training average loss at step 11000: 0.119536\n",
      "2023-12-05 22:47:58,512 INFO     Training average positive_sample_loss at step 11100: 0.137367\n",
      "2023-12-05 22:47:58,513 INFO     Training average negative_sample_loss at step 11100: 0.102677\n",
      "2023-12-05 22:47:58,513 INFO     Training average loss at step 11100: 0.120022\n",
      "2023-12-05 22:48:03,693 INFO     Training average positive_sample_loss at step 11200: 0.131758\n",
      "2023-12-05 22:48:03,694 INFO     Training average negative_sample_loss at step 11200: 0.100401\n",
      "2023-12-05 22:48:03,694 INFO     Training average loss at step 11200: 0.116080\n",
      "2023-12-05 22:48:08,983 INFO     Training average positive_sample_loss at step 11300: 0.138662\n",
      "2023-12-05 22:48:08,983 INFO     Training average negative_sample_loss at step 11300: 0.101550\n",
      "2023-12-05 22:48:08,983 INFO     Training average loss at step 11300: 0.120106\n",
      "2023-12-05 22:48:15,245 INFO     Training average positive_sample_loss at step 11400: 0.133770\n",
      "2023-12-05 22:48:15,245 INFO     Training average negative_sample_loss at step 11400: 0.102340\n",
      "2023-12-05 22:48:15,246 INFO     Training average loss at step 11400: 0.118055\n",
      "2023-12-05 22:48:20,417 INFO     Training average positive_sample_loss at step 11500: 0.135771\n",
      "2023-12-05 22:48:20,417 INFO     Training average negative_sample_loss at step 11500: 0.100778\n",
      "2023-12-05 22:48:20,417 INFO     Training average loss at step 11500: 0.118275\n",
      "2023-12-05 22:48:25,587 INFO     Training average positive_sample_loss at step 11600: 0.138163\n",
      "2023-12-05 22:48:25,587 INFO     Training average negative_sample_loss at step 11600: 0.101526\n",
      "2023-12-05 22:48:25,587 INFO     Training average loss at step 11600: 0.119845\n",
      "2023-12-05 22:48:31,317 INFO     Training average positive_sample_loss at step 11700: 0.130317\n",
      "2023-12-05 22:48:31,317 INFO     Training average negative_sample_loss at step 11700: 0.100619\n",
      "2023-12-05 22:48:31,317 INFO     Training average loss at step 11700: 0.115468\n",
      "2023-12-05 22:48:36,474 INFO     Training average positive_sample_loss at step 11800: 0.136898\n",
      "2023-12-05 22:48:36,474 INFO     Training average negative_sample_loss at step 11800: 0.099846\n",
      "2023-12-05 22:48:36,474 INFO     Training average loss at step 11800: 0.118372\n",
      "2023-12-05 22:48:42,261 INFO     Training average positive_sample_loss at step 11900: 0.133570\n",
      "2023-12-05 22:48:42,262 INFO     Training average negative_sample_loss at step 11900: 0.101681\n",
      "2023-12-05 22:48:42,262 INFO     Training average loss at step 11900: 0.117626\n",
      "2023-12-05 22:48:48,105 INFO     Training average positive_sample_loss at step 12000: 0.133365\n",
      "2023-12-05 22:48:48,105 INFO     Training average negative_sample_loss at step 12000: 0.099542\n",
      "2023-12-05 22:48:48,105 INFO     Training average loss at step 12000: 0.116453\n",
      "2023-12-05 22:48:53,277 INFO     Training average positive_sample_loss at step 12100: 0.136836\n",
      "2023-12-05 22:48:53,277 INFO     Training average negative_sample_loss at step 12100: 0.100508\n",
      "2023-12-05 22:48:53,278 INFO     Training average loss at step 12100: 0.118672\n",
      "2023-12-05 22:48:59,128 INFO     Training average positive_sample_loss at step 12200: 0.130969\n",
      "2023-12-05 22:48:59,128 INFO     Training average negative_sample_loss at step 12200: 0.101132\n",
      "2023-12-05 22:48:59,128 INFO     Training average loss at step 12200: 0.116050\n",
      "2023-12-05 22:49:04,280 INFO     Training average positive_sample_loss at step 12300: 0.135215\n",
      "2023-12-05 22:49:04,281 INFO     Training average negative_sample_loss at step 12300: 0.100029\n",
      "2023-12-05 22:49:04,281 INFO     Training average loss at step 12300: 0.117622\n",
      "2023-12-05 22:49:10,125 INFO     Training average positive_sample_loss at step 12400: 0.134570\n",
      "2023-12-05 22:49:10,125 INFO     Training average negative_sample_loss at step 12400: 0.101489\n",
      "2023-12-05 22:49:10,125 INFO     Training average loss at step 12400: 0.118030\n",
      "2023-12-05 22:49:15,412 INFO     Training average positive_sample_loss at step 12500: 0.130854\n",
      "2023-12-05 22:49:15,413 INFO     Training average negative_sample_loss at step 12500: 0.098306\n",
      "2023-12-05 22:49:15,413 INFO     Training average loss at step 12500: 0.114580\n",
      "2023-12-05 22:49:21,208 INFO     Training average positive_sample_loss at step 12600: 0.135834\n",
      "2023-12-05 22:49:21,208 INFO     Training average negative_sample_loss at step 12600: 0.100016\n",
      "2023-12-05 22:49:21,208 INFO     Training average loss at step 12600: 0.117925\n",
      "2023-12-05 22:49:27,059 INFO     Training average positive_sample_loss at step 12700: 0.130908\n",
      "2023-12-05 22:49:27,060 INFO     Training average negative_sample_loss at step 12700: 0.100561\n",
      "2023-12-05 22:49:27,060 INFO     Training average loss at step 12700: 0.115734\n",
      "2023-12-05 22:49:32,240 INFO     Training average positive_sample_loss at step 12800: 0.133783\n",
      "2023-12-05 22:49:32,240 INFO     Training average negative_sample_loss at step 12800: 0.099392\n",
      "2023-12-05 22:49:32,240 INFO     Training average loss at step 12800: 0.116588\n",
      "2023-12-05 22:49:38,383 INFO     Training average positive_sample_loss at step 12900: 0.135528\n",
      "2023-12-05 22:49:38,383 INFO     Training average negative_sample_loss at step 12900: 0.100320\n",
      "2023-12-05 22:49:38,383 INFO     Training average loss at step 12900: 0.117924\n",
      "2023-12-05 22:49:43,920 INFO     Training average positive_sample_loss at step 13000: 0.128106\n",
      "2023-12-05 22:49:43,921 INFO     Training average negative_sample_loss at step 13000: 0.098366\n",
      "2023-12-05 22:49:43,921 INFO     Training average loss at step 13000: 0.113236\n",
      "2023-12-05 22:49:49,075 INFO     Training average positive_sample_loss at step 13100: 0.135405\n",
      "2023-12-05 22:49:49,075 INFO     Training average negative_sample_loss at step 13100: 0.099642\n",
      "2023-12-05 22:49:49,076 INFO     Training average loss at step 13100: 0.117524\n",
      "2023-12-05 22:49:54,928 INFO     Training average positive_sample_loss at step 13200: 0.130595\n",
      "2023-12-05 22:49:54,928 INFO     Training average negative_sample_loss at step 13200: 0.100326\n",
      "2023-12-05 22:49:54,928 INFO     Training average loss at step 13200: 0.115461\n",
      "2023-12-05 22:50:00,795 INFO     Training average positive_sample_loss at step 13300: 0.132274\n",
      "2023-12-05 22:50:00,795 INFO     Training average negative_sample_loss at step 13300: 0.098777\n",
      "2023-12-05 22:50:00,795 INFO     Training average loss at step 13300: 0.115525\n",
      "2023-12-05 22:50:06,022 INFO     Training average positive_sample_loss at step 13400: 0.135207\n",
      "2023-12-05 22:50:06,022 INFO     Training average negative_sample_loss at step 13400: 0.098917\n",
      "2023-12-05 22:50:06,022 INFO     Training average loss at step 13400: 0.117062\n",
      "2023-12-05 22:50:11,858 INFO     Training average positive_sample_loss at step 13500: 0.128117\n",
      "2023-12-05 22:50:11,859 INFO     Training average negative_sample_loss at step 13500: 0.099058\n",
      "2023-12-05 22:50:11,859 INFO     Training average loss at step 13500: 0.113588\n",
      "2023-12-05 22:50:17,702 INFO     Training average positive_sample_loss at step 13600: 0.133892\n",
      "2023-12-05 22:50:17,702 INFO     Training average negative_sample_loss at step 13600: 0.098076\n",
      "2023-12-05 22:50:17,702 INFO     Training average loss at step 13600: 0.115984\n",
      "2023-12-05 22:50:23,573 INFO     Training average positive_sample_loss at step 13700: 0.130906\n",
      "2023-12-05 22:50:23,574 INFO     Training average negative_sample_loss at step 13700: 0.100183\n",
      "2023-12-05 22:50:23,574 INFO     Training average loss at step 13700: 0.115545\n",
      "2023-12-05 22:50:28,821 INFO     Training average positive_sample_loss at step 13800: 0.130233\n",
      "2023-12-05 22:50:28,821 INFO     Training average negative_sample_loss at step 13800: 0.097337\n",
      "2023-12-05 22:50:28,821 INFO     Training average loss at step 13800: 0.113785\n",
      "2023-12-05 22:50:34,113 INFO     Training average positive_sample_loss at step 13900: 0.134029\n",
      "2023-12-05 22:50:34,113 INFO     Training average negative_sample_loss at step 13900: 0.098494\n",
      "2023-12-05 22:50:34,113 INFO     Training average loss at step 13900: 0.116261\n",
      "2023-12-05 22:50:40,622 INFO     Training average positive_sample_loss at step 14000: 0.128184\n",
      "2023-12-05 22:50:40,623 INFO     Training average negative_sample_loss at step 14000: 0.098650\n",
      "2023-12-05 22:50:40,623 INFO     Training average loss at step 14000: 0.113417\n",
      "2023-12-05 22:50:45,878 INFO     Training average positive_sample_loss at step 14100: 0.132593\n",
      "2023-12-05 22:50:45,878 INFO     Training average negative_sample_loss at step 14100: 0.097846\n",
      "2023-12-05 22:50:45,878 INFO     Training average loss at step 14100: 0.115220\n",
      "2023-12-05 22:50:51,789 INFO     Training average positive_sample_loss at step 14200: 0.132468\n",
      "2023-12-05 22:50:51,789 INFO     Training average negative_sample_loss at step 14200: 0.099360\n",
      "2023-12-05 22:50:51,789 INFO     Training average loss at step 14200: 0.115914\n",
      "2023-12-05 22:50:57,661 INFO     Training average positive_sample_loss at step 14300: 0.127559\n",
      "2023-12-05 22:50:57,661 INFO     Training average negative_sample_loss at step 14300: 0.096941\n",
      "2023-12-05 22:50:57,661 INFO     Training average loss at step 14300: 0.112250\n",
      "2023-12-05 22:51:02,893 INFO     Training average positive_sample_loss at step 14400: 0.132946\n",
      "2023-12-05 22:51:02,894 INFO     Training average negative_sample_loss at step 14400: 0.098072\n",
      "2023-12-05 22:51:02,894 INFO     Training average loss at step 14400: 0.115509\n",
      "2023-12-05 22:51:08,865 INFO     Training average positive_sample_loss at step 14500: 0.129719\n",
      "2023-12-05 22:51:08,865 INFO     Training average negative_sample_loss at step 14500: 0.099687\n",
      "2023-12-05 22:51:08,865 INFO     Training average loss at step 14500: 0.114703\n",
      "2023-12-05 22:51:14,167 INFO     Training average positive_sample_loss at step 14600: 0.130381\n",
      "2023-12-05 22:51:14,167 INFO     Training average negative_sample_loss at step 14600: 0.096745\n",
      "2023-12-05 22:51:14,167 INFO     Training average loss at step 14600: 0.113563\n",
      "2023-12-05 22:51:20,146 INFO     Training average positive_sample_loss at step 14700: 0.133655\n",
      "2023-12-05 22:51:20,147 INFO     Training average negative_sample_loss at step 14700: 0.098489\n",
      "2023-12-05 22:51:20,147 INFO     Training average loss at step 14700: 0.116072\n",
      "2023-12-05 22:51:26,113 INFO     Training average positive_sample_loss at step 14800: 0.126166\n",
      "2023-12-05 22:51:26,113 INFO     Training average negative_sample_loss at step 14800: 0.097302\n",
      "2023-12-05 22:51:26,113 INFO     Training average loss at step 14800: 0.111734\n",
      "2023-12-05 22:51:31,364 INFO     Training average positive_sample_loss at step 14900: 0.132543\n",
      "2023-12-05 22:51:31,364 INFO     Training average negative_sample_loss at step 14900: 0.097496\n",
      "2023-12-05 22:51:31,364 INFO     Training average loss at step 14900: 0.115020\n",
      "2023-12-05 22:51:37,320 INFO     Training average positive_sample_loss at step 15000: 0.128660\n",
      "2023-12-05 22:51:37,320 INFO     Training average negative_sample_loss at step 15000: 0.098853\n",
      "2023-12-05 22:51:37,320 INFO     Training average loss at step 15000: 0.113757\n",
      "2023-12-05 22:51:43,203 INFO     Training average positive_sample_loss at step 15100: 0.129371\n",
      "2023-12-05 22:51:43,204 INFO     Training average negative_sample_loss at step 15100: 0.096774\n",
      "2023-12-05 22:51:43,204 INFO     Training average loss at step 15100: 0.113073\n",
      "2023-12-05 22:51:48,438 INFO     Training average positive_sample_loss at step 15200: 0.132868\n",
      "2023-12-05 22:51:48,439 INFO     Training average negative_sample_loss at step 15200: 0.097871\n",
      "2023-12-05 22:51:48,439 INFO     Training average loss at step 15200: 0.115369\n",
      "2023-12-05 22:51:54,285 INFO     Training average positive_sample_loss at step 15300: 0.126257\n",
      "2023-12-05 22:51:54,285 INFO     Training average negative_sample_loss at step 15300: 0.097261\n",
      "2023-12-05 22:51:54,285 INFO     Training average loss at step 15300: 0.111759\n",
      "2023-12-05 22:51:59,919 INFO     Training average positive_sample_loss at step 15400: 0.131394\n",
      "2023-12-05 22:51:59,920 INFO     Training average negative_sample_loss at step 15400: 0.096763\n",
      "2023-12-05 22:51:59,920 INFO     Training average loss at step 15400: 0.114078\n",
      "2023-12-05 22:52:06,099 INFO     Training average positive_sample_loss at step 15500: 0.130323\n",
      "2023-12-05 22:52:06,099 INFO     Training average negative_sample_loss at step 15500: 0.098410\n",
      "2023-12-05 22:52:06,099 INFO     Training average loss at step 15500: 0.114367\n",
      "2023-12-05 22:52:11,310 INFO     Training average positive_sample_loss at step 15600: 0.127495\n",
      "2023-12-05 22:52:11,311 INFO     Training average negative_sample_loss at step 15600: 0.096236\n",
      "2023-12-05 22:52:11,311 INFO     Training average loss at step 15600: 0.111866\n",
      "2023-12-05 22:52:16,670 INFO     Training average positive_sample_loss at step 15700: 0.131624\n",
      "2023-12-05 22:52:16,671 INFO     Training average negative_sample_loss at step 15700: 0.096888\n",
      "2023-12-05 22:52:16,671 INFO     Training average loss at step 15700: 0.114256\n",
      "2023-12-05 22:52:22,756 INFO     Training average positive_sample_loss at step 15800: 0.126357\n",
      "2023-12-05 22:52:22,756 INFO     Training average negative_sample_loss at step 15800: 0.097280\n",
      "2023-12-05 22:52:22,757 INFO     Training average loss at step 15800: 0.111819\n",
      "2023-12-05 22:52:28,631 INFO     Training average positive_sample_loss at step 15900: 0.130008\n",
      "2023-12-05 22:52:28,631 INFO     Training average negative_sample_loss at step 15900: 0.095369\n",
      "2023-12-05 22:52:28,631 INFO     Training average loss at step 15900: 0.112688\n",
      "2023-12-05 22:52:34,468 INFO     Training average positive_sample_loss at step 16000: 0.131554\n",
      "2023-12-05 22:52:34,469 INFO     Training average negative_sample_loss at step 16000: 0.098361\n",
      "2023-12-05 22:52:34,469 INFO     Training average loss at step 16000: 0.114958\n",
      "2023-12-05 22:52:39,692 INFO     Training average positive_sample_loss at step 16100: 0.125369\n",
      "2023-12-05 22:52:39,693 INFO     Training average negative_sample_loss at step 16100: 0.096565\n",
      "2023-12-05 22:52:39,693 INFO     Training average loss at step 16100: 0.110967\n",
      "2023-12-05 22:52:44,912 INFO     Training average positive_sample_loss at step 16200: 0.131461\n",
      "2023-12-05 22:52:44,912 INFO     Training average negative_sample_loss at step 16200: 0.096442\n",
      "2023-12-05 22:52:44,912 INFO     Training average loss at step 16200: 0.113952\n",
      "2023-12-05 22:52:50,930 INFO     Training average positive_sample_loss at step 16300: 0.126453\n",
      "2023-12-05 22:52:50,931 INFO     Training average negative_sample_loss at step 16300: 0.096967\n",
      "2023-12-05 22:52:50,931 INFO     Training average loss at step 16300: 0.111710\n",
      "2023-12-05 22:52:56,173 INFO     Training average positive_sample_loss at step 16400: 0.129059\n",
      "2023-12-05 22:52:56,174 INFO     Training average negative_sample_loss at step 16400: 0.096328\n",
      "2023-12-05 22:52:56,174 INFO     Training average loss at step 16400: 0.112694\n",
      "2023-12-05 22:53:01,558 INFO     Training average positive_sample_loss at step 16500: 0.131821\n",
      "2023-12-05 22:53:01,558 INFO     Training average negative_sample_loss at step 16500: 0.097948\n",
      "2023-12-05 22:53:01,558 INFO     Training average loss at step 16500: 0.114884\n",
      "2023-12-05 22:53:08,148 INFO     Training average positive_sample_loss at step 16600: 0.125012\n",
      "2023-12-05 22:53:08,149 INFO     Training average negative_sample_loss at step 16600: 0.095949\n",
      "2023-12-05 22:53:08,149 INFO     Training average loss at step 16600: 0.110481\n",
      "2023-12-05 22:53:13,385 INFO     Training average positive_sample_loss at step 16700: 0.130277\n",
      "2023-12-05 22:53:13,385 INFO     Training average negative_sample_loss at step 16700: 0.096011\n",
      "2023-12-05 22:53:13,385 INFO     Training average loss at step 16700: 0.113144\n",
      "2023-12-05 22:53:19,433 INFO     Training average positive_sample_loss at step 16800: 0.127518\n",
      "2023-12-05 22:53:19,434 INFO     Training average negative_sample_loss at step 16800: 0.097218\n",
      "2023-12-05 22:53:19,434 INFO     Training average loss at step 16800: 0.112368\n",
      "2023-12-05 22:53:25,397 INFO     Training average positive_sample_loss at step 16900: 0.127521\n",
      "2023-12-05 22:53:25,398 INFO     Training average negative_sample_loss at step 16900: 0.095743\n",
      "2023-12-05 22:53:25,398 INFO     Training average loss at step 16900: 0.111632\n",
      "2023-12-05 22:53:30,707 INFO     Training average positive_sample_loss at step 17000: 0.130708\n",
      "2023-12-05 22:53:30,707 INFO     Training average negative_sample_loss at step 17000: 0.096557\n",
      "2023-12-05 22:53:30,707 INFO     Training average loss at step 17000: 0.113632\n",
      "2023-12-05 22:53:36,755 INFO     Training average positive_sample_loss at step 17100: 0.125097\n",
      "2023-12-05 22:53:36,756 INFO     Training average negative_sample_loss at step 17100: 0.096481\n",
      "2023-12-05 22:53:36,756 INFO     Training average loss at step 17100: 0.110789\n",
      "2023-12-05 22:53:41,946 INFO     Training average positive_sample_loss at step 17200: 0.129330\n",
      "2023-12-05 22:53:41,946 INFO     Training average negative_sample_loss at step 17200: 0.095548\n",
      "2023-12-05 22:53:41,946 INFO     Training average loss at step 17200: 0.112439\n",
      "2023-12-05 22:53:48,563 INFO     Training average positive_sample_loss at step 17300: 0.129023\n",
      "2023-12-05 22:53:48,564 INFO     Training average negative_sample_loss at step 17300: 0.097036\n",
      "2023-12-05 22:53:48,564 INFO     Training average loss at step 17300: 0.113029\n",
      "2023-12-05 22:53:53,760 INFO     Training average positive_sample_loss at step 17400: 0.124823\n",
      "2023-12-05 22:53:53,760 INFO     Training average negative_sample_loss at step 17400: 0.094884\n",
      "2023-12-05 22:53:53,760 INFO     Training average loss at step 17400: 0.109853\n",
      "2023-12-05 22:53:59,071 INFO     Training average positive_sample_loss at step 17500: 0.131269\n",
      "2023-12-05 22:53:59,071 INFO     Training average negative_sample_loss at step 17500: 0.097143\n",
      "2023-12-05 22:53:59,071 INFO     Training average loss at step 17500: 0.114206\n",
      "2023-12-05 22:54:05,047 INFO     Training average positive_sample_loss at step 17600: 0.124899\n",
      "2023-12-05 22:54:05,048 INFO     Training average negative_sample_loss at step 17600: 0.095524\n",
      "2023-12-05 22:54:05,048 INFO     Training average loss at step 17600: 0.110212\n",
      "2023-12-05 22:54:10,924 INFO     Training average positive_sample_loss at step 17700: 0.127630\n",
      "2023-12-05 22:54:10,925 INFO     Training average negative_sample_loss at step 17700: 0.095073\n",
      "2023-12-05 22:54:10,925 INFO     Training average loss at step 17700: 0.111351\n",
      "2023-12-05 22:54:16,215 INFO     Training average positive_sample_loss at step 17800: 0.131268\n",
      "2023-12-05 22:54:16,216 INFO     Training average negative_sample_loss at step 17800: 0.096472\n",
      "2023-12-05 22:54:16,216 INFO     Training average loss at step 17800: 0.113870\n",
      "2023-12-05 22:54:22,106 INFO     Training average positive_sample_loss at step 17900: 0.122678\n",
      "2023-12-05 22:54:22,107 INFO     Training average negative_sample_loss at step 17900: 0.094989\n",
      "2023-12-05 22:54:22,107 INFO     Training average loss at step 17900: 0.108833\n",
      "2023-12-05 22:54:27,441 INFO     Training average positive_sample_loss at step 18000: 0.130226\n",
      "2023-12-05 22:54:27,441 INFO     Training average negative_sample_loss at step 18000: 0.096332\n",
      "2023-12-05 22:54:27,441 INFO     Training average loss at step 18000: 0.113279\n",
      "2023-12-05 22:54:33,989 INFO     Training average positive_sample_loss at step 18100: 0.125977\n",
      "2023-12-05 22:54:33,989 INFO     Training average negative_sample_loss at step 18100: 0.096376\n",
      "2023-12-05 22:54:33,989 INFO     Training average loss at step 18100: 0.111177\n",
      "2023-12-05 22:54:39,233 INFO     Training average positive_sample_loss at step 18200: 0.127005\n",
      "2023-12-05 22:54:39,234 INFO     Training average negative_sample_loss at step 18200: 0.095200\n",
      "2023-12-05 22:54:39,234 INFO     Training average loss at step 18200: 0.111103\n",
      "2023-12-05 22:54:44,565 INFO     Training average positive_sample_loss at step 18300: 0.129974\n",
      "2023-12-05 22:54:44,565 INFO     Training average negative_sample_loss at step 18300: 0.096613\n",
      "2023-12-05 22:54:44,565 INFO     Training average loss at step 18300: 0.113293\n",
      "2023-12-05 22:54:50,469 INFO     Training average positive_sample_loss at step 18400: 0.123501\n",
      "2023-12-05 22:54:50,469 INFO     Training average negative_sample_loss at step 18400: 0.095263\n",
      "2023-12-05 22:54:50,469 INFO     Training average loss at step 18400: 0.109382\n",
      "2023-12-05 22:54:56,419 INFO     Training average positive_sample_loss at step 18500: 0.128396\n",
      "2023-12-05 22:54:56,419 INFO     Training average negative_sample_loss at step 18500: 0.094744\n",
      "2023-12-05 22:54:56,419 INFO     Training average loss at step 18500: 0.111570\n",
      "2023-12-05 22:55:02,566 INFO     Training average positive_sample_loss at step 18600: 0.127435\n",
      "2023-12-05 22:55:02,567 INFO     Training average negative_sample_loss at step 18600: 0.096112\n",
      "2023-12-05 22:55:02,567 INFO     Training average loss at step 18600: 0.111774\n",
      "2023-12-05 22:55:07,941 INFO     Training average positive_sample_loss at step 18700: 0.125460\n",
      "2023-12-05 22:55:07,942 INFO     Training average negative_sample_loss at step 18700: 0.094746\n",
      "2023-12-05 22:55:07,942 INFO     Training average loss at step 18700: 0.110103\n",
      "2023-12-05 22:55:13,837 INFO     Training average positive_sample_loss at step 18800: 0.129463\n",
      "2023-12-05 22:55:13,837 INFO     Training average negative_sample_loss at step 18800: 0.095811\n",
      "2023-12-05 22:55:13,837 INFO     Training average loss at step 18800: 0.112637\n",
      "2023-12-05 22:55:19,982 INFO     Training average positive_sample_loss at step 18900: 0.123428\n",
      "2023-12-05 22:55:19,983 INFO     Training average negative_sample_loss at step 18900: 0.095280\n",
      "2023-12-05 22:55:19,983 INFO     Training average loss at step 18900: 0.109354\n",
      "2023-12-05 22:55:25,316 INFO     Training average positive_sample_loss at step 19000: 0.127688\n",
      "2023-12-05 22:55:25,317 INFO     Training average negative_sample_loss at step 19000: 0.094837\n",
      "2023-12-05 22:55:25,317 INFO     Training average loss at step 19000: 0.111263\n",
      "2023-12-05 22:55:31,860 INFO     Training average positive_sample_loss at step 19100: 0.128508\n",
      "2023-12-05 22:55:31,861 INFO     Training average negative_sample_loss at step 19100: 0.095206\n",
      "2023-12-05 22:55:31,861 INFO     Training average loss at step 19100: 0.111857\n",
      "2023-12-05 22:55:37,101 INFO     Training average positive_sample_loss at step 19200: 0.123569\n",
      "2023-12-05 22:55:37,101 INFO     Training average negative_sample_loss at step 19200: 0.094682\n",
      "2023-12-05 22:55:37,101 INFO     Training average loss at step 19200: 0.109125\n",
      "2023-12-05 22:55:42,324 INFO     Training average positive_sample_loss at step 19300: 0.128730\n",
      "2023-12-05 22:55:42,325 INFO     Training average negative_sample_loss at step 19300: 0.094854\n",
      "2023-12-05 22:55:42,325 INFO     Training average loss at step 19300: 0.111792\n",
      "2023-12-05 22:55:48,428 INFO     Training average positive_sample_loss at step 19400: 0.123995\n",
      "2023-12-05 22:55:48,428 INFO     Training average negative_sample_loss at step 19400: 0.095057\n",
      "2023-12-05 22:55:48,428 INFO     Training average loss at step 19400: 0.109526\n",
      "2023-12-05 22:55:54,199 INFO     Training average positive_sample_loss at step 19500: 0.127161\n",
      "2023-12-05 22:55:54,200 INFO     Training average negative_sample_loss at step 19500: 0.094956\n",
      "2023-12-05 22:55:54,200 INFO     Training average loss at step 19500: 0.111059\n",
      "2023-12-05 22:55:59,602 INFO     Training average positive_sample_loss at step 19600: 0.129229\n",
      "2023-12-05 22:55:59,602 INFO     Training average negative_sample_loss at step 19600: 0.095746\n",
      "2023-12-05 22:55:59,602 INFO     Training average loss at step 19600: 0.112488\n",
      "2023-12-05 22:56:05,427 INFO     Training average positive_sample_loss at step 19700: 0.122235\n",
      "2023-12-05 22:56:05,427 INFO     Training average negative_sample_loss at step 19700: 0.094421\n",
      "2023-12-05 22:56:05,427 INFO     Training average loss at step 19700: 0.108328\n",
      "2023-12-05 22:56:11,291 INFO     Training average positive_sample_loss at step 19800: 0.128114\n",
      "2023-12-05 22:56:11,291 INFO     Training average negative_sample_loss at step 19800: 0.095347\n",
      "2023-12-05 22:56:11,291 INFO     Training average loss at step 19800: 0.111730\n",
      "2023-12-05 22:56:17,199 INFO     Training average positive_sample_loss at step 19900: 0.125645\n",
      "2023-12-05 22:56:17,199 INFO     Training average negative_sample_loss at step 19900: 0.095787\n",
      "2023-12-05 22:56:17,199 INFO     Training average loss at step 19900: 0.110716\n",
      "2023-12-05 22:56:35,017 INFO     Training average positive_sample_loss at step 20000: 0.125438\n",
      "2023-12-05 22:56:35,018 INFO     Training average negative_sample_loss at step 20000: 0.092954\n",
      "2023-12-05 22:56:35,018 INFO     Training average loss at step 20000: 0.109196\n",
      "2023-12-05 22:56:35,018 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 22:56:35,554 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 22:57:05,545 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 22:57:27,171 INFO     Valid MRR at step 20000: 0.541199\n",
      "2023-12-05 22:57:27,171 INFO     Valid MR at step 20000: 288.573880\n",
      "2023-12-05 22:57:27,171 INFO     Valid HITS@1 at step 20000: 0.487516\n",
      "2023-12-05 22:57:27,171 INFO     Valid HITS@3 at step 20000: 0.559724\n",
      "2023-12-05 22:57:27,171 INFO     Valid HITS@10 at step 20000: 0.627191\n",
      "2023-12-05 22:57:32,603 INFO     Training average positive_sample_loss at step 20100: 0.128461\n",
      "2023-12-05 22:57:32,604 INFO     Training average negative_sample_loss at step 20100: 0.095250\n",
      "2023-12-05 22:57:32,604 INFO     Training average loss at step 20100: 0.111855\n",
      "2023-12-05 22:57:38,564 INFO     Training average positive_sample_loss at step 20200: 0.122815\n",
      "2023-12-05 22:57:38,565 INFO     Training average negative_sample_loss at step 20200: 0.095425\n",
      "2023-12-05 22:57:38,565 INFO     Training average loss at step 20200: 0.109120\n",
      "2023-12-05 22:57:44,332 INFO     Training average positive_sample_loss at step 20300: 0.127539\n",
      "2023-12-05 22:57:44,332 INFO     Training average negative_sample_loss at step 20300: 0.094272\n",
      "2023-12-05 22:57:44,332 INFO     Training average loss at step 20300: 0.110905\n",
      "2023-12-05 22:57:50,175 INFO     Training average positive_sample_loss at step 20400: 0.126560\n",
      "2023-12-05 22:57:50,175 INFO     Training average negative_sample_loss at step 20400: 0.095492\n",
      "2023-12-05 22:57:50,176 INFO     Training average loss at step 20400: 0.111026\n",
      "2023-12-05 22:57:55,495 INFO     Training average positive_sample_loss at step 20500: 0.123482\n",
      "2023-12-05 22:57:55,495 INFO     Training average negative_sample_loss at step 20500: 0.093463\n",
      "2023-12-05 22:57:55,495 INFO     Training average loss at step 20500: 0.108472\n",
      "2023-12-05 22:58:00,805 INFO     Training average positive_sample_loss at step 20600: 0.128083\n",
      "2023-12-05 22:58:00,805 INFO     Training average negative_sample_loss at step 20600: 0.094505\n",
      "2023-12-05 22:58:00,805 INFO     Training average loss at step 20600: 0.111294\n",
      "2023-12-05 22:58:07,334 INFO     Training average positive_sample_loss at step 20700: 0.123170\n",
      "2023-12-05 22:58:07,334 INFO     Training average negative_sample_loss at step 20700: 0.095078\n",
      "2023-12-05 22:58:07,334 INFO     Training average loss at step 20700: 0.109124\n",
      "2023-12-05 22:58:12,573 INFO     Training average positive_sample_loss at step 20800: 0.126470\n",
      "2023-12-05 22:58:12,573 INFO     Training average negative_sample_loss at step 20800: 0.093648\n",
      "2023-12-05 22:58:12,573 INFO     Training average loss at step 20800: 0.110059\n",
      "2023-12-05 22:58:18,755 INFO     Training average positive_sample_loss at step 20900: 0.128143\n",
      "2023-12-05 22:58:18,755 INFO     Training average negative_sample_loss at step 20900: 0.095505\n",
      "2023-12-05 22:58:18,755 INFO     Training average loss at step 20900: 0.111824\n",
      "2023-12-05 22:58:23,997 INFO     Training average positive_sample_loss at step 21000: 0.121906\n",
      "2023-12-05 22:58:23,997 INFO     Training average negative_sample_loss at step 21000: 0.093768\n",
      "2023-12-05 22:58:23,997 INFO     Training average loss at step 21000: 0.107837\n",
      "2023-12-05 22:58:29,780 INFO     Training average positive_sample_loss at step 21100: 0.127718\n",
      "2023-12-05 22:58:29,781 INFO     Training average negative_sample_loss at step 21100: 0.094433\n",
      "2023-12-05 22:58:29,781 INFO     Training average loss at step 21100: 0.111076\n",
      "2023-12-05 22:58:35,629 INFO     Training average positive_sample_loss at step 21200: 0.123892\n",
      "2023-12-05 22:58:35,629 INFO     Training average negative_sample_loss at step 21200: 0.095116\n",
      "2023-12-05 22:58:35,629 INFO     Training average loss at step 21200: 0.109504\n",
      "2023-12-05 22:58:40,853 INFO     Training average positive_sample_loss at step 21300: 0.125252\n",
      "2023-12-05 22:58:40,853 INFO     Training average negative_sample_loss at step 21300: 0.093610\n",
      "2023-12-05 22:58:40,853 INFO     Training average loss at step 21300: 0.109431\n",
      "2023-12-05 22:58:46,341 INFO     Training average positive_sample_loss at step 21400: 0.127992\n",
      "2023-12-05 22:58:46,342 INFO     Training average negative_sample_loss at step 21400: 0.094656\n",
      "2023-12-05 22:58:46,342 INFO     Training average loss at step 21400: 0.111324\n",
      "2023-12-05 22:58:52,789 INFO     Training average positive_sample_loss at step 21500: 0.121741\n",
      "2023-12-05 22:58:52,790 INFO     Training average negative_sample_loss at step 21500: 0.094085\n",
      "2023-12-05 22:58:52,790 INFO     Training average loss at step 21500: 0.107913\n",
      "2023-12-05 22:58:58,064 INFO     Training average positive_sample_loss at step 21600: 0.126557\n",
      "2023-12-05 22:58:58,064 INFO     Training average negative_sample_loss at step 21600: 0.093379\n",
      "2023-12-05 22:58:58,064 INFO     Training average loss at step 21600: 0.109968\n",
      "2023-12-05 22:59:03,922 INFO     Training average positive_sample_loss at step 21700: 0.125187\n",
      "2023-12-05 22:59:03,923 INFO     Training average negative_sample_loss at step 21700: 0.095288\n",
      "2023-12-05 22:59:03,923 INFO     Training average loss at step 21700: 0.110238\n",
      "2023-12-05 22:59:09,257 INFO     Training average positive_sample_loss at step 21800: 0.123608\n",
      "2023-12-05 22:59:09,257 INFO     Training average negative_sample_loss at step 21800: 0.092603\n",
      "2023-12-05 22:59:09,257 INFO     Training average loss at step 21800: 0.108106\n",
      "2023-12-05 22:59:14,456 INFO     Training average positive_sample_loss at step 21900: 0.127591\n",
      "2023-12-05 22:59:14,456 INFO     Training average negative_sample_loss at step 21900: 0.094806\n",
      "2023-12-05 22:59:14,456 INFO     Training average loss at step 21900: 0.111199\n",
      "2023-12-05 22:59:20,961 INFO     Training average positive_sample_loss at step 22000: 0.122638\n",
      "2023-12-05 22:59:20,962 INFO     Training average negative_sample_loss at step 22000: 0.094757\n",
      "2023-12-05 22:59:20,962 INFO     Training average loss at step 22000: 0.108698\n",
      "2023-12-05 22:59:26,345 INFO     Training average positive_sample_loss at step 22100: 0.125542\n",
      "2023-12-05 22:59:26,346 INFO     Training average negative_sample_loss at step 22100: 0.093018\n",
      "2023-12-05 22:59:26,346 INFO     Training average loss at step 22100: 0.109280\n",
      "2023-12-05 22:59:32,251 INFO     Training average positive_sample_loss at step 22200: 0.126440\n",
      "2023-12-05 22:59:32,251 INFO     Training average negative_sample_loss at step 22200: 0.095002\n",
      "2023-12-05 22:59:32,251 INFO     Training average loss at step 22200: 0.110721\n",
      "2023-12-05 22:59:37,481 INFO     Training average positive_sample_loss at step 22300: 0.122901\n",
      "2023-12-05 22:59:37,481 INFO     Training average negative_sample_loss at step 22300: 0.093787\n",
      "2023-12-05 22:59:37,481 INFO     Training average loss at step 22300: 0.108344\n",
      "2023-12-05 22:59:42,682 INFO     Training average positive_sample_loss at step 22400: 0.126894\n",
      "2023-12-05 22:59:42,682 INFO     Training average negative_sample_loss at step 22400: 0.093711\n",
      "2023-12-05 22:59:42,682 INFO     Training average loss at step 22400: 0.110302\n",
      "2023-12-05 22:59:49,218 INFO     Training average positive_sample_loss at step 22500: 0.122273\n",
      "2023-12-05 22:59:49,219 INFO     Training average negative_sample_loss at step 22500: 0.094453\n",
      "2023-12-05 22:59:49,219 INFO     Training average loss at step 22500: 0.108363\n",
      "2023-12-05 22:59:54,408 INFO     Training average positive_sample_loss at step 22600: 0.125163\n",
      "2023-12-05 22:59:54,408 INFO     Training average negative_sample_loss at step 22600: 0.093428\n",
      "2023-12-05 22:59:54,408 INFO     Training average loss at step 22600: 0.109296\n",
      "2023-12-05 22:59:59,716 INFO     Training average positive_sample_loss at step 22700: 0.127988\n",
      "2023-12-05 22:59:59,717 INFO     Training average negative_sample_loss at step 22700: 0.094629\n",
      "2023-12-05 22:59:59,717 INFO     Training average loss at step 22700: 0.111309\n",
      "2023-12-05 23:00:05,839 INFO     Training average positive_sample_loss at step 22800: 0.120895\n",
      "2023-12-05 23:00:05,839 INFO     Training average negative_sample_loss at step 22800: 0.092949\n",
      "2023-12-05 23:00:05,839 INFO     Training average loss at step 22800: 0.106922\n",
      "2023-12-05 23:00:11,481 INFO     Training average positive_sample_loss at step 22900: 0.126229\n",
      "2023-12-05 23:00:11,481 INFO     Training average negative_sample_loss at step 22900: 0.093519\n",
      "2023-12-05 23:00:11,481 INFO     Training average loss at step 22900: 0.109874\n",
      "2023-12-05 23:00:17,264 INFO     Training average positive_sample_loss at step 23000: 0.123356\n",
      "2023-12-05 23:00:17,264 INFO     Training average negative_sample_loss at step 23000: 0.094540\n",
      "2023-12-05 23:00:17,264 INFO     Training average loss at step 23000: 0.108948\n",
      "2023-12-05 23:00:22,451 INFO     Training average positive_sample_loss at step 23100: 0.123965\n",
      "2023-12-05 23:00:22,452 INFO     Training average negative_sample_loss at step 23100: 0.092205\n",
      "2023-12-05 23:00:22,452 INFO     Training average loss at step 23100: 0.108085\n",
      "2023-12-05 23:00:28,371 INFO     Training average positive_sample_loss at step 23200: 0.127071\n",
      "2023-12-05 23:00:28,371 INFO     Training average negative_sample_loss at step 23200: 0.094123\n",
      "2023-12-05 23:00:28,371 INFO     Training average loss at step 23200: 0.110597\n",
      "2023-12-05 23:00:34,163 INFO     Training average positive_sample_loss at step 23300: 0.121012\n",
      "2023-12-05 23:00:34,163 INFO     Training average negative_sample_loss at step 23300: 0.093606\n",
      "2023-12-05 23:00:34,163 INFO     Training average loss at step 23300: 0.107309\n",
      "2023-12-05 23:00:39,364 INFO     Training average positive_sample_loss at step 23400: 0.125566\n",
      "2023-12-05 23:00:39,364 INFO     Training average negative_sample_loss at step 23400: 0.092205\n",
      "2023-12-05 23:00:39,364 INFO     Training average loss at step 23400: 0.108886\n",
      "2023-12-05 23:00:45,182 INFO     Training average positive_sample_loss at step 23500: 0.124589\n",
      "2023-12-05 23:00:45,183 INFO     Training average negative_sample_loss at step 23500: 0.094564\n",
      "2023-12-05 23:00:45,183 INFO     Training average loss at step 23500: 0.109576\n",
      "2023-12-05 23:00:51,036 INFO     Training average positive_sample_loss at step 23600: 0.122313\n",
      "2023-12-05 23:00:51,037 INFO     Training average negative_sample_loss at step 23600: 0.092634\n",
      "2023-12-05 23:00:51,037 INFO     Training average loss at step 23600: 0.107473\n",
      "2023-12-05 23:00:56,307 INFO     Training average positive_sample_loss at step 23700: 0.127171\n",
      "2023-12-05 23:00:56,308 INFO     Training average negative_sample_loss at step 23700: 0.094120\n",
      "2023-12-05 23:00:56,308 INFO     Training average loss at step 23700: 0.110645\n",
      "2023-12-05 23:01:02,210 INFO     Training average positive_sample_loss at step 23800: 0.121072\n",
      "2023-12-05 23:01:02,211 INFO     Training average negative_sample_loss at step 23800: 0.093305\n",
      "2023-12-05 23:01:02,211 INFO     Training average loss at step 23800: 0.107189\n",
      "2023-12-05 23:01:07,377 INFO     Training average positive_sample_loss at step 23900: 0.125033\n",
      "2023-12-05 23:01:07,377 INFO     Training average negative_sample_loss at step 23900: 0.092912\n",
      "2023-12-05 23:01:07,377 INFO     Training average loss at step 23900: 0.108973\n",
      "2023-12-05 23:01:13,846 INFO     Training average positive_sample_loss at step 24000: 0.126508\n",
      "2023-12-05 23:01:13,846 INFO     Training average negative_sample_loss at step 24000: 0.095160\n",
      "2023-12-05 23:01:13,846 INFO     Training average loss at step 24000: 0.110834\n",
      "2023-12-05 23:01:19,001 INFO     Training average positive_sample_loss at step 24100: 0.120661\n",
      "2023-12-05 23:01:19,001 INFO     Training average negative_sample_loss at step 24100: 0.092240\n",
      "2023-12-05 23:01:19,001 INFO     Training average loss at step 24100: 0.106450\n",
      "2023-12-05 23:01:24,172 INFO     Training average positive_sample_loss at step 24200: 0.126226\n",
      "2023-12-05 23:01:24,172 INFO     Training average negative_sample_loss at step 24200: 0.093125\n",
      "2023-12-05 23:01:24,172 INFO     Training average loss at step 24200: 0.109675\n",
      "2023-12-05 23:01:30,681 INFO     Training average positive_sample_loss at step 24300: 0.122054\n",
      "2023-12-05 23:01:30,682 INFO     Training average negative_sample_loss at step 24300: 0.093201\n",
      "2023-12-05 23:01:30,682 INFO     Training average loss at step 24300: 0.107627\n",
      "2023-12-05 23:01:36,023 INFO     Training average positive_sample_loss at step 24400: 0.123822\n",
      "2023-12-05 23:01:36,024 INFO     Training average negative_sample_loss at step 24400: 0.092339\n",
      "2023-12-05 23:01:36,024 INFO     Training average loss at step 24400: 0.108081\n",
      "2023-12-05 23:01:41,295 INFO     Training average positive_sample_loss at step 24500: 0.126930\n",
      "2023-12-05 23:01:41,296 INFO     Training average negative_sample_loss at step 24500: 0.095057\n",
      "2023-12-05 23:01:41,296 INFO     Training average loss at step 24500: 0.110993\n",
      "2023-12-05 23:01:47,158 INFO     Training average positive_sample_loss at step 24600: 0.120065\n",
      "2023-12-05 23:01:47,158 INFO     Training average negative_sample_loss at step 24600: 0.092036\n",
      "2023-12-05 23:01:47,159 INFO     Training average loss at step 24600: 0.106051\n",
      "2023-12-05 23:01:52,993 INFO     Training average positive_sample_loss at step 24700: 0.125775\n",
      "2023-12-05 23:01:52,993 INFO     Training average negative_sample_loss at step 24700: 0.092775\n",
      "2023-12-05 23:01:52,993 INFO     Training average loss at step 24700: 0.109275\n",
      "2023-12-05 23:01:58,855 INFO     Training average positive_sample_loss at step 24800: 0.122993\n",
      "2023-12-05 23:01:58,855 INFO     Training average negative_sample_loss at step 24800: 0.093732\n",
      "2023-12-05 23:01:58,855 INFO     Training average loss at step 24800: 0.108362\n",
      "2023-12-05 23:02:04,128 INFO     Training average positive_sample_loss at step 24900: 0.122900\n",
      "2023-12-05 23:02:04,129 INFO     Training average negative_sample_loss at step 24900: 0.091926\n",
      "2023-12-05 23:02:04,129 INFO     Training average loss at step 24900: 0.107413\n",
      "2023-12-05 23:02:09,809 INFO     Training average positive_sample_loss at step 25000: 0.126255\n",
      "2023-12-05 23:02:09,809 INFO     Training average negative_sample_loss at step 25000: 0.093922\n",
      "2023-12-05 23:02:09,809 INFO     Training average loss at step 25000: 0.110089\n",
      "2023-12-05 23:02:15,840 INFO     Training average positive_sample_loss at step 25100: 0.120515\n",
      "2023-12-05 23:02:15,841 INFO     Training average negative_sample_loss at step 25100: 0.093397\n",
      "2023-12-05 23:02:15,841 INFO     Training average loss at step 25100: 0.106956\n",
      "2023-12-05 23:02:21,051 INFO     Training average positive_sample_loss at step 25200: 0.124785\n",
      "2023-12-05 23:02:21,051 INFO     Training average negative_sample_loss at step 25200: 0.092553\n",
      "2023-12-05 23:02:21,051 INFO     Training average loss at step 25200: 0.108669\n",
      "2023-12-05 23:02:26,896 INFO     Training average positive_sample_loss at step 25300: 0.124681\n",
      "2023-12-05 23:02:26,896 INFO     Training average negative_sample_loss at step 25300: 0.094493\n",
      "2023-12-05 23:02:26,896 INFO     Training average loss at step 25300: 0.109587\n",
      "2023-12-05 23:02:32,730 INFO     Training average positive_sample_loss at step 25400: 0.121532\n",
      "2023-12-05 23:02:32,730 INFO     Training average negative_sample_loss at step 25400: 0.092136\n",
      "2023-12-05 23:02:32,730 INFO     Training average loss at step 25400: 0.106834\n",
      "2023-12-05 23:02:37,908 INFO     Training average positive_sample_loss at step 25500: 0.126162\n",
      "2023-12-05 23:02:37,908 INFO     Training average negative_sample_loss at step 25500: 0.093141\n",
      "2023-12-05 23:02:37,908 INFO     Training average loss at step 25500: 0.109652\n",
      "2023-12-05 23:02:43,758 INFO     Training average positive_sample_loss at step 25600: 0.120929\n",
      "2023-12-05 23:02:43,758 INFO     Training average negative_sample_loss at step 25600: 0.092918\n",
      "2023-12-05 23:02:43,758 INFO     Training average loss at step 25600: 0.106924\n",
      "2023-12-05 23:02:49,025 INFO     Training average positive_sample_loss at step 25700: 0.124001\n",
      "2023-12-05 23:02:49,025 INFO     Training average negative_sample_loss at step 25700: 0.092448\n",
      "2023-12-05 23:02:49,026 INFO     Training average loss at step 25700: 0.108224\n",
      "2023-12-05 23:02:54,552 INFO     Training average positive_sample_loss at step 25800: 0.126338\n",
      "2023-12-05 23:02:54,553 INFO     Training average negative_sample_loss at step 25800: 0.093837\n",
      "2023-12-05 23:02:54,553 INFO     Training average loss at step 25800: 0.110087\n",
      "2023-12-05 23:03:00,747 INFO     Training average positive_sample_loss at step 25900: 0.119595\n",
      "2023-12-05 23:03:00,747 INFO     Training average negative_sample_loss at step 25900: 0.092304\n",
      "2023-12-05 23:03:00,747 INFO     Training average loss at step 25900: 0.105950\n",
      "2023-12-05 23:03:06,026 INFO     Training average positive_sample_loss at step 26000: 0.125739\n",
      "2023-12-05 23:03:06,027 INFO     Training average negative_sample_loss at step 26000: 0.093336\n",
      "2023-12-05 23:03:06,027 INFO     Training average loss at step 26000: 0.109537\n",
      "2023-12-05 23:03:11,917 INFO     Training average positive_sample_loss at step 26100: 0.121693\n",
      "2023-12-05 23:03:11,917 INFO     Training average negative_sample_loss at step 26100: 0.093102\n",
      "2023-12-05 23:03:11,917 INFO     Training average loss at step 26100: 0.107398\n",
      "2023-12-05 23:03:17,124 INFO     Training average positive_sample_loss at step 26200: 0.122965\n",
      "2023-12-05 23:03:17,125 INFO     Training average negative_sample_loss at step 26200: 0.091874\n",
      "2023-12-05 23:03:17,125 INFO     Training average loss at step 26200: 0.107419\n",
      "2023-12-05 23:03:23,135 INFO     Training average positive_sample_loss at step 26300: 0.126326\n",
      "2023-12-05 23:03:23,135 INFO     Training average negative_sample_loss at step 26300: 0.093192\n",
      "2023-12-05 23:03:23,135 INFO     Training average loss at step 26300: 0.109759\n",
      "2023-12-05 23:03:29,166 INFO     Training average positive_sample_loss at step 26400: 0.118869\n",
      "2023-12-05 23:03:29,166 INFO     Training average negative_sample_loss at step 26400: 0.091832\n",
      "2023-12-05 23:03:29,166 INFO     Training average loss at step 26400: 0.105350\n",
      "2023-12-05 23:03:34,591 INFO     Training average positive_sample_loss at step 26500: 0.124746\n",
      "2023-12-05 23:03:34,591 INFO     Training average negative_sample_loss at step 26500: 0.091517\n",
      "2023-12-05 23:03:34,591 INFO     Training average loss at step 26500: 0.108131\n",
      "2023-12-05 23:03:41,232 INFO     Training average positive_sample_loss at step 26600: 0.122944\n",
      "2023-12-05 23:03:41,232 INFO     Training average negative_sample_loss at step 26600: 0.093830\n",
      "2023-12-05 23:03:41,232 INFO     Training average loss at step 26600: 0.108387\n",
      "2023-12-05 23:03:46,492 INFO     Training average positive_sample_loss at step 26700: 0.121609\n",
      "2023-12-05 23:03:46,493 INFO     Training average negative_sample_loss at step 26700: 0.091245\n",
      "2023-12-05 23:03:46,493 INFO     Training average loss at step 26700: 0.106427\n",
      "2023-12-05 23:03:51,710 INFO     Training average positive_sample_loss at step 26800: 0.125345\n",
      "2023-12-05 23:03:51,711 INFO     Training average negative_sample_loss at step 26800: 0.092124\n",
      "2023-12-05 23:03:51,711 INFO     Training average loss at step 26800: 0.108735\n",
      "2023-12-05 23:03:58,035 INFO     Training average positive_sample_loss at step 26900: 0.120375\n",
      "2023-12-05 23:03:58,036 INFO     Training average negative_sample_loss at step 26900: 0.093757\n",
      "2023-12-05 23:03:58,036 INFO     Training average loss at step 26900: 0.107066\n",
      "2023-12-05 23:04:03,276 INFO     Training average positive_sample_loss at step 27000: 0.124231\n",
      "2023-12-05 23:04:03,277 INFO     Training average negative_sample_loss at step 27000: 0.092600\n",
      "2023-12-05 23:04:03,277 INFO     Training average loss at step 27000: 0.108416\n",
      "2023-12-05 23:04:09,160 INFO     Training average positive_sample_loss at step 27100: 0.124680\n",
      "2023-12-05 23:04:09,161 INFO     Training average negative_sample_loss at step 27100: 0.093442\n",
      "2023-12-05 23:04:09,161 INFO     Training average loss at step 27100: 0.109061\n",
      "2023-12-05 23:04:14,616 INFO     Training average positive_sample_loss at step 27200: 0.120372\n",
      "2023-12-05 23:04:14,617 INFO     Training average negative_sample_loss at step 27200: 0.092172\n",
      "2023-12-05 23:04:14,617 INFO     Training average loss at step 27200: 0.106272\n",
      "2023-12-05 23:04:19,946 INFO     Training average positive_sample_loss at step 27300: 0.124991\n",
      "2023-12-05 23:04:19,946 INFO     Training average negative_sample_loss at step 27300: 0.092431\n",
      "2023-12-05 23:04:19,946 INFO     Training average loss at step 27300: 0.108711\n",
      "2023-12-05 23:04:26,355 INFO     Training average positive_sample_loss at step 27400: 0.120610\n",
      "2023-12-05 23:04:26,355 INFO     Training average negative_sample_loss at step 27400: 0.092791\n",
      "2023-12-05 23:04:26,355 INFO     Training average loss at step 27400: 0.106701\n",
      "2023-12-05 23:04:31,845 INFO     Training average positive_sample_loss at step 27500: 0.123027\n",
      "2023-12-05 23:04:31,845 INFO     Training average negative_sample_loss at step 27500: 0.091760\n",
      "2023-12-05 23:04:31,845 INFO     Training average loss at step 27500: 0.107394\n",
      "2023-12-05 23:04:37,086 INFO     Training average positive_sample_loss at step 27600: 0.125578\n",
      "2023-12-05 23:04:37,086 INFO     Training average negative_sample_loss at step 27600: 0.092844\n",
      "2023-12-05 23:04:37,086 INFO     Training average loss at step 27600: 0.109211\n",
      "2023-12-05 23:04:42,829 INFO     Training average positive_sample_loss at step 27700: 0.119060\n",
      "2023-12-05 23:04:42,829 INFO     Training average negative_sample_loss at step 27700: 0.092195\n",
      "2023-12-05 23:04:42,829 INFO     Training average loss at step 27700: 0.105627\n",
      "2023-12-05 23:04:48,602 INFO     Training average positive_sample_loss at step 27800: 0.124555\n",
      "2023-12-05 23:04:48,602 INFO     Training average negative_sample_loss at step 27800: 0.092618\n",
      "2023-12-05 23:04:48,602 INFO     Training average loss at step 27800: 0.108586\n",
      "2023-12-05 23:04:54,435 INFO     Training average positive_sample_loss at step 27900: 0.122319\n",
      "2023-12-05 23:04:54,435 INFO     Training average negative_sample_loss at step 27900: 0.093043\n",
      "2023-12-05 23:04:54,435 INFO     Training average loss at step 27900: 0.107681\n",
      "2023-12-05 23:04:59,738 INFO     Training average positive_sample_loss at step 28000: 0.122109\n",
      "2023-12-05 23:04:59,739 INFO     Training average negative_sample_loss at step 28000: 0.091863\n",
      "2023-12-05 23:04:59,739 INFO     Training average loss at step 28000: 0.106986\n",
      "2023-12-05 23:05:04,985 INFO     Training average positive_sample_loss at step 28100: 0.125065\n",
      "2023-12-05 23:05:04,985 INFO     Training average negative_sample_loss at step 28100: 0.092826\n",
      "2023-12-05 23:05:04,985 INFO     Training average loss at step 28100: 0.108945\n",
      "2023-12-05 23:05:10,934 INFO     Training average positive_sample_loss at step 28200: 0.119727\n",
      "2023-12-05 23:05:10,935 INFO     Training average negative_sample_loss at step 28200: 0.092720\n",
      "2023-12-05 23:05:10,935 INFO     Training average loss at step 28200: 0.106223\n",
      "2023-12-05 23:05:16,263 INFO     Training average positive_sample_loss at step 28300: 0.123932\n",
      "2023-12-05 23:05:16,264 INFO     Training average negative_sample_loss at step 28300: 0.091386\n",
      "2023-12-05 23:05:16,264 INFO     Training average loss at step 28300: 0.107659\n",
      "2023-12-05 23:05:22,146 INFO     Training average positive_sample_loss at step 28400: 0.123064\n",
      "2023-12-05 23:05:22,147 INFO     Training average negative_sample_loss at step 28400: 0.093813\n",
      "2023-12-05 23:05:22,147 INFO     Training average loss at step 28400: 0.108439\n",
      "2023-12-05 23:05:27,529 INFO     Training average positive_sample_loss at step 28500: 0.120673\n",
      "2023-12-05 23:05:27,529 INFO     Training average negative_sample_loss at step 28500: 0.091323\n",
      "2023-12-05 23:05:27,530 INFO     Training average loss at step 28500: 0.105998\n",
      "2023-12-05 23:05:33,326 INFO     Training average positive_sample_loss at step 28600: 0.125359\n",
      "2023-12-05 23:05:33,326 INFO     Training average negative_sample_loss at step 28600: 0.093099\n",
      "2023-12-05 23:05:33,327 INFO     Training average loss at step 28600: 0.109229\n",
      "2023-12-05 23:05:39,226 INFO     Training average positive_sample_loss at step 28700: 0.119492\n",
      "2023-12-05 23:05:39,227 INFO     Training average negative_sample_loss at step 28700: 0.091946\n",
      "2023-12-05 23:05:39,227 INFO     Training average loss at step 28700: 0.105719\n",
      "2023-12-05 23:05:44,406 INFO     Training average positive_sample_loss at step 28800: 0.123463\n",
      "2023-12-05 23:05:44,406 INFO     Training average negative_sample_loss at step 28800: 0.091795\n",
      "2023-12-05 23:05:44,406 INFO     Training average loss at step 28800: 0.107629\n",
      "2023-12-05 23:05:50,527 INFO     Training average positive_sample_loss at step 28900: 0.124616\n",
      "2023-12-05 23:05:50,527 INFO     Training average negative_sample_loss at step 28900: 0.093174\n",
      "2023-12-05 23:05:50,527 INFO     Training average loss at step 28900: 0.108895\n",
      "2023-12-05 23:05:56,182 INFO     Training average positive_sample_loss at step 29000: 0.118993\n",
      "2023-12-05 23:05:56,182 INFO     Training average negative_sample_loss at step 29000: 0.091946\n",
      "2023-12-05 23:05:56,182 INFO     Training average loss at step 29000: 0.105469\n",
      "2023-12-05 23:06:01,392 INFO     Training average positive_sample_loss at step 29100: 0.124757\n",
      "2023-12-05 23:06:01,393 INFO     Training average negative_sample_loss at step 29100: 0.092356\n",
      "2023-12-05 23:06:01,393 INFO     Training average loss at step 29100: 0.108557\n",
      "2023-12-05 23:06:07,386 INFO     Training average positive_sample_loss at step 29200: 0.120812\n",
      "2023-12-05 23:06:07,386 INFO     Training average negative_sample_loss at step 29200: 0.092117\n",
      "2023-12-05 23:06:07,386 INFO     Training average loss at step 29200: 0.106465\n",
      "2023-12-05 23:06:13,215 INFO     Training average positive_sample_loss at step 29300: 0.122326\n",
      "2023-12-05 23:06:13,215 INFO     Training average negative_sample_loss at step 29300: 0.091164\n",
      "2023-12-05 23:06:13,215 INFO     Training average loss at step 29300: 0.106745\n",
      "2023-12-05 23:06:18,610 INFO     Training average positive_sample_loss at step 29400: 0.124852\n",
      "2023-12-05 23:06:18,610 INFO     Training average negative_sample_loss at step 29400: 0.092098\n",
      "2023-12-05 23:06:18,610 INFO     Training average loss at step 29400: 0.108475\n",
      "2023-12-05 23:06:24,649 INFO     Training average positive_sample_loss at step 29500: 0.118913\n",
      "2023-12-05 23:06:24,649 INFO     Training average negative_sample_loss at step 29500: 0.091932\n",
      "2023-12-05 23:06:24,649 INFO     Training average loss at step 29500: 0.105423\n",
      "2023-12-05 23:06:30,375 INFO     Training average positive_sample_loss at step 29600: 0.123696\n",
      "2023-12-05 23:06:30,376 INFO     Training average negative_sample_loss at step 29600: 0.091533\n",
      "2023-12-05 23:06:30,376 INFO     Training average loss at step 29600: 0.107614\n",
      "2023-12-05 23:06:36,297 INFO     Training average positive_sample_loss at step 29700: 0.121613\n",
      "2023-12-05 23:06:36,297 INFO     Training average negative_sample_loss at step 29700: 0.092679\n",
      "2023-12-05 23:06:36,298 INFO     Training average loss at step 29700: 0.107146\n",
      "2023-12-05 23:06:41,648 INFO     Training average positive_sample_loss at step 29800: 0.120917\n",
      "2023-12-05 23:06:41,648 INFO     Training average negative_sample_loss at step 29800: 0.090875\n",
      "2023-12-05 23:06:41,648 INFO     Training average loss at step 29800: 0.105896\n",
      "2023-12-05 23:06:47,018 INFO     Training average positive_sample_loss at step 29900: 0.125008\n",
      "2023-12-05 23:06:47,019 INFO     Training average negative_sample_loss at step 29900: 0.092883\n",
      "2023-12-05 23:06:47,019 INFO     Training average loss at step 29900: 0.108946\n",
      "2023-12-05 23:07:05,866 INFO     Training average positive_sample_loss at step 30000: 0.119232\n",
      "2023-12-05 23:07:05,866 INFO     Training average negative_sample_loss at step 30000: 0.092537\n",
      "2023-12-05 23:07:05,866 INFO     Training average loss at step 30000: 0.105885\n",
      "2023-12-05 23:07:05,867 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 23:07:06,387 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 23:07:35,966 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 23:07:54,511 INFO     Valid MRR at step 30000: 0.563255\n",
      "2023-12-05 23:07:54,512 INFO     Valid MR at step 30000: 279.126407\n",
      "2023-12-05 23:07:54,512 INFO     Valid HITS@1 at step 30000: 0.504912\n",
      "2023-12-05 23:07:54,512 INFO     Valid HITS@3 at step 30000: 0.580872\n",
      "2023-12-05 23:07:54,512 INFO     Valid HITS@10 at step 30000: 0.668634\n",
      "2023-12-05 23:08:00,004 INFO     Training average positive_sample_loss at step 30100: 0.123066\n",
      "2023-12-05 23:08:00,004 INFO     Training average negative_sample_loss at step 30100: 0.091109\n",
      "2023-12-05 23:08:00,004 INFO     Training average loss at step 30100: 0.107087\n",
      "2023-12-05 23:08:05,953 INFO     Training average positive_sample_loss at step 30200: 0.123520\n",
      "2023-12-05 23:08:05,953 INFO     Training average negative_sample_loss at step 30200: 0.092902\n",
      "2023-12-05 23:08:05,954 INFO     Training average loss at step 30200: 0.108211\n",
      "2023-12-05 23:08:11,255 INFO     Training average positive_sample_loss at step 30300: 0.119263\n",
      "2023-12-05 23:08:11,255 INFO     Training average negative_sample_loss at step 30300: 0.090811\n",
      "2023-12-05 23:08:11,255 INFO     Training average loss at step 30300: 0.105037\n",
      "2023-12-05 23:08:17,180 INFO     Training average positive_sample_loss at step 30400: 0.124251\n",
      "2023-12-05 23:08:17,180 INFO     Training average negative_sample_loss at step 30400: 0.091687\n",
      "2023-12-05 23:08:17,180 INFO     Training average loss at step 30400: 0.107969\n",
      "2023-12-05 23:08:23,097 INFO     Training average positive_sample_loss at step 30500: 0.120023\n",
      "2023-12-05 23:08:23,098 INFO     Training average negative_sample_loss at step 30500: 0.092409\n",
      "2023-12-05 23:08:23,098 INFO     Training average loss at step 30500: 0.106216\n",
      "2023-12-05 23:08:28,267 INFO     Training average positive_sample_loss at step 30600: 0.122822\n",
      "2023-12-05 23:08:28,267 INFO     Training average negative_sample_loss at step 30600: 0.090528\n",
      "2023-12-05 23:08:28,267 INFO     Training average loss at step 30600: 0.106675\n",
      "2023-12-05 23:08:33,491 INFO     Training average positive_sample_loss at step 30700: 0.124144\n",
      "2023-12-05 23:08:33,491 INFO     Training average negative_sample_loss at step 30700: 0.092339\n",
      "2023-12-05 23:08:33,491 INFO     Training average loss at step 30700: 0.108242\n",
      "2023-12-05 23:08:39,876 INFO     Training average positive_sample_loss at step 30800: 0.118217\n",
      "2023-12-05 23:08:39,877 INFO     Training average negative_sample_loss at step 30800: 0.091344\n",
      "2023-12-05 23:08:39,877 INFO     Training average loss at step 30800: 0.104780\n",
      "2023-12-05 23:08:45,093 INFO     Training average positive_sample_loss at step 30900: 0.123866\n",
      "2023-12-05 23:08:45,093 INFO     Training average negative_sample_loss at step 30900: 0.091754\n",
      "2023-12-05 23:08:45,093 INFO     Training average loss at step 30900: 0.107810\n",
      "2023-12-05 23:08:50,906 INFO     Training average positive_sample_loss at step 31000: 0.120294\n",
      "2023-12-05 23:08:50,906 INFO     Training average negative_sample_loss at step 31000: 0.092334\n",
      "2023-12-05 23:08:50,906 INFO     Training average loss at step 31000: 0.106314\n",
      "2023-12-05 23:08:56,122 INFO     Training average positive_sample_loss at step 31100: 0.121901\n",
      "2023-12-05 23:08:56,122 INFO     Training average negative_sample_loss at step 31100: 0.091355\n",
      "2023-12-05 23:08:56,122 INFO     Training average loss at step 31100: 0.106628\n",
      "2023-12-05 23:09:02,027 INFO     Training average positive_sample_loss at step 31200: 0.124437\n",
      "2023-12-05 23:09:02,027 INFO     Training average negative_sample_loss at step 31200: 0.092371\n",
      "2023-12-05 23:09:02,027 INFO     Training average loss at step 31200: 0.108404\n",
      "2023-12-05 23:09:07,887 INFO     Training average positive_sample_loss at step 31300: 0.118877\n",
      "2023-12-05 23:09:07,887 INFO     Training average negative_sample_loss at step 31300: 0.091366\n",
      "2023-12-05 23:09:07,887 INFO     Training average loss at step 31300: 0.105122\n",
      "2023-12-05 23:09:13,120 INFO     Training average positive_sample_loss at step 31400: 0.122829\n",
      "2023-12-05 23:09:13,120 INFO     Training average negative_sample_loss at step 31400: 0.090342\n",
      "2023-12-05 23:09:13,120 INFO     Training average loss at step 31400: 0.106585\n",
      "2023-12-05 23:09:19,023 INFO     Training average positive_sample_loss at step 31500: 0.121467\n",
      "2023-12-05 23:09:19,023 INFO     Training average negative_sample_loss at step 31500: 0.092600\n",
      "2023-12-05 23:09:19,023 INFO     Training average loss at step 31500: 0.107034\n",
      "2023-12-05 23:09:24,899 INFO     Training average positive_sample_loss at step 31600: 0.120339\n",
      "2023-12-05 23:09:24,899 INFO     Training average negative_sample_loss at step 31600: 0.090790\n",
      "2023-12-05 23:09:24,899 INFO     Training average loss at step 31600: 0.105564\n",
      "2023-12-05 23:09:30,073 INFO     Training average positive_sample_loss at step 31700: 0.124506\n",
      "2023-12-05 23:09:30,074 INFO     Training average negative_sample_loss at step 31700: 0.092421\n",
      "2023-12-05 23:09:30,074 INFO     Training average loss at step 31700: 0.108463\n",
      "2023-12-05 23:09:35,973 INFO     Training average positive_sample_loss at step 31800: 0.119132\n",
      "2023-12-05 23:09:35,973 INFO     Training average negative_sample_loss at step 31800: 0.092209\n",
      "2023-12-05 23:09:35,973 INFO     Training average loss at step 31800: 0.105671\n",
      "2023-12-05 23:09:41,869 INFO     Training average positive_sample_loss at step 31900: 0.122235\n",
      "2023-12-05 23:09:41,869 INFO     Training average negative_sample_loss at step 31900: 0.090937\n",
      "2023-12-05 23:09:41,869 INFO     Training average loss at step 31900: 0.106586\n",
      "2023-12-05 23:09:47,765 INFO     Training average positive_sample_loss at step 32000: 0.123622\n",
      "2023-12-05 23:09:47,766 INFO     Training average negative_sample_loss at step 32000: 0.092360\n",
      "2023-12-05 23:09:47,766 INFO     Training average loss at step 32000: 0.107991\n",
      "2023-12-05 23:09:52,981 INFO     Training average positive_sample_loss at step 32100: 0.118470\n",
      "2023-12-05 23:09:52,982 INFO     Training average negative_sample_loss at step 32100: 0.090936\n",
      "2023-12-05 23:09:52,982 INFO     Training average loss at step 32100: 0.104703\n",
      "2023-12-05 23:09:58,196 INFO     Training average positive_sample_loss at step 32200: 0.123709\n",
      "2023-12-05 23:09:58,196 INFO     Training average negative_sample_loss at step 32200: 0.091156\n",
      "2023-12-05 23:09:58,196 INFO     Training average loss at step 32200: 0.107433\n",
      "2023-12-05 23:10:04,712 INFO     Training average positive_sample_loss at step 32300: 0.119798\n",
      "2023-12-05 23:10:04,712 INFO     Training average negative_sample_loss at step 32300: 0.092169\n",
      "2023-12-05 23:10:04,712 INFO     Training average loss at step 32300: 0.105984\n",
      "2023-12-05 23:10:09,914 INFO     Training average positive_sample_loss at step 32400: 0.121795\n",
      "2023-12-05 23:10:09,915 INFO     Training average negative_sample_loss at step 32400: 0.091207\n",
      "2023-12-05 23:10:09,915 INFO     Training average loss at step 32400: 0.106501\n",
      "2023-12-05 23:10:15,102 INFO     Training average positive_sample_loss at step 32500: 0.124351\n",
      "2023-12-05 23:10:15,102 INFO     Training average negative_sample_loss at step 32500: 0.091805\n",
      "2023-12-05 23:10:15,102 INFO     Training average loss at step 32500: 0.108078\n",
      "2023-12-05 23:10:21,370 INFO     Training average positive_sample_loss at step 32600: 0.117868\n",
      "2023-12-05 23:10:21,371 INFO     Training average negative_sample_loss at step 32600: 0.091396\n",
      "2023-12-05 23:10:21,371 INFO     Training average loss at step 32600: 0.104632\n",
      "2023-12-05 23:10:26,539 INFO     Training average positive_sample_loss at step 32700: 0.123036\n",
      "2023-12-05 23:10:26,539 INFO     Training average negative_sample_loss at step 32700: 0.090602\n",
      "2023-12-05 23:10:26,539 INFO     Training average loss at step 32700: 0.106819\n",
      "2023-12-05 23:10:32,605 INFO     Training average positive_sample_loss at step 32800: 0.120679\n",
      "2023-12-05 23:10:32,606 INFO     Training average negative_sample_loss at step 32800: 0.092539\n",
      "2023-12-05 23:10:32,606 INFO     Training average loss at step 32800: 0.106609\n",
      "2023-12-05 23:10:38,191 INFO     Training average positive_sample_loss at step 32900: 0.120845\n",
      "2023-12-05 23:10:38,191 INFO     Training average negative_sample_loss at step 32900: 0.090603\n",
      "2023-12-05 23:10:38,191 INFO     Training average loss at step 32900: 0.105724\n",
      "2023-12-05 23:10:43,497 INFO     Training average positive_sample_loss at step 33000: 0.123493\n",
      "2023-12-05 23:10:43,497 INFO     Training average negative_sample_loss at step 33000: 0.091238\n",
      "2023-12-05 23:10:43,497 INFO     Training average loss at step 33000: 0.107366\n",
      "2023-12-05 23:10:49,358 INFO     Training average positive_sample_loss at step 33100: 0.118082\n",
      "2023-12-05 23:10:49,358 INFO     Training average negative_sample_loss at step 33100: 0.090706\n",
      "2023-12-05 23:10:49,358 INFO     Training average loss at step 33100: 0.104394\n",
      "2023-12-05 23:10:54,492 INFO     Training average positive_sample_loss at step 33200: 0.122379\n",
      "2023-12-05 23:10:54,492 INFO     Training average negative_sample_loss at step 33200: 0.090917\n",
      "2023-12-05 23:10:54,492 INFO     Training average loss at step 33200: 0.106648\n",
      "2023-12-05 23:11:00,296 INFO     Training average positive_sample_loss at step 33300: 0.122523\n",
      "2023-12-05 23:11:00,297 INFO     Training average negative_sample_loss at step 33300: 0.092490\n",
      "2023-12-05 23:11:00,297 INFO     Training average loss at step 33300: 0.107507\n",
      "2023-12-05 23:11:06,123 INFO     Training average positive_sample_loss at step 33400: 0.118788\n",
      "2023-12-05 23:11:06,123 INFO     Training average negative_sample_loss at step 33400: 0.090510\n",
      "2023-12-05 23:11:06,123 INFO     Training average loss at step 33400: 0.104649\n",
      "2023-12-05 23:11:11,291 INFO     Training average positive_sample_loss at step 33500: 0.124032\n",
      "2023-12-05 23:11:11,292 INFO     Training average negative_sample_loss at step 33500: 0.091682\n",
      "2023-12-05 23:11:11,292 INFO     Training average loss at step 33500: 0.107857\n",
      "2023-12-05 23:11:17,008 INFO     Training average positive_sample_loss at step 33600: 0.118758\n",
      "2023-12-05 23:11:17,008 INFO     Training average negative_sample_loss at step 33600: 0.091956\n",
      "2023-12-05 23:11:17,008 INFO     Training average loss at step 33600: 0.105357\n",
      "2023-12-05 23:11:22,850 INFO     Training average positive_sample_loss at step 33700: 0.122443\n",
      "2023-12-05 23:11:22,850 INFO     Training average negative_sample_loss at step 33700: 0.090619\n",
      "2023-12-05 23:11:22,850 INFO     Training average loss at step 33700: 0.106531\n",
      "2023-12-05 23:11:28,582 INFO     Training average positive_sample_loss at step 33800: 0.123323\n",
      "2023-12-05 23:11:28,583 INFO     Training average negative_sample_loss at step 33800: 0.091514\n",
      "2023-12-05 23:11:28,583 INFO     Training average loss at step 33800: 0.107419\n",
      "2023-12-05 23:11:33,734 INFO     Training average positive_sample_loss at step 33900: 0.117210\n",
      "2023-12-05 23:11:33,734 INFO     Training average negative_sample_loss at step 33900: 0.090591\n",
      "2023-12-05 23:11:33,735 INFO     Training average loss at step 33900: 0.103901\n",
      "2023-12-05 23:11:38,883 INFO     Training average positive_sample_loss at step 34000: 0.123495\n",
      "2023-12-05 23:11:38,883 INFO     Training average negative_sample_loss at step 34000: 0.091248\n",
      "2023-12-05 23:11:38,883 INFO     Training average loss at step 34000: 0.107371\n",
      "2023-12-05 23:11:44,604 INFO     Training average positive_sample_loss at step 34100: 0.119439\n",
      "2023-12-05 23:11:44,605 INFO     Training average negative_sample_loss at step 34100: 0.091957\n",
      "2023-12-05 23:11:44,605 INFO     Training average loss at step 34100: 0.105698\n",
      "2023-12-05 23:11:49,754 INFO     Training average positive_sample_loss at step 34200: 0.120953\n",
      "2023-12-05 23:11:49,754 INFO     Training average negative_sample_loss at step 34200: 0.090309\n",
      "2023-12-05 23:11:49,755 INFO     Training average loss at step 34200: 0.105631\n",
      "2023-12-05 23:11:55,267 INFO     Training average positive_sample_loss at step 34300: 0.124138\n",
      "2023-12-05 23:11:55,268 INFO     Training average negative_sample_loss at step 34300: 0.091810\n",
      "2023-12-05 23:11:55,268 INFO     Training average loss at step 34300: 0.107974\n",
      "2023-12-05 23:12:01,046 INFO     Training average positive_sample_loss at step 34400: 0.117680\n",
      "2023-12-05 23:12:01,047 INFO     Training average negative_sample_loss at step 34400: 0.091005\n",
      "2023-12-05 23:12:01,047 INFO     Training average loss at step 34400: 0.104343\n",
      "2023-12-05 23:12:06,515 INFO     Training average positive_sample_loss at step 34500: 0.122706\n",
      "2023-12-05 23:12:06,515 INFO     Training average negative_sample_loss at step 34500: 0.090516\n",
      "2023-12-05 23:12:06,515 INFO     Training average loss at step 34500: 0.106611\n",
      "2023-12-05 23:12:12,660 INFO     Training average positive_sample_loss at step 34600: 0.120622\n",
      "2023-12-05 23:12:12,660 INFO     Training average negative_sample_loss at step 34600: 0.092417\n",
      "2023-12-05 23:12:12,660 INFO     Training average loss at step 34600: 0.106519\n",
      "2023-12-05 23:12:17,831 INFO     Training average positive_sample_loss at step 34700: 0.119743\n",
      "2023-12-05 23:12:17,831 INFO     Training average negative_sample_loss at step 34700: 0.090479\n",
      "2023-12-05 23:12:17,831 INFO     Training average loss at step 34700: 0.105111\n",
      "2023-12-05 23:12:22,993 INFO     Training average positive_sample_loss at step 34800: 0.123824\n",
      "2023-12-05 23:12:22,994 INFO     Training average negative_sample_loss at step 34800: 0.091591\n",
      "2023-12-05 23:12:22,994 INFO     Training average loss at step 34800: 0.107708\n",
      "2023-12-05 23:12:28,747 INFO     Training average positive_sample_loss at step 34900: 0.117869\n",
      "2023-12-05 23:12:28,747 INFO     Training average negative_sample_loss at step 34900: 0.091435\n",
      "2023-12-05 23:12:28,747 INFO     Training average loss at step 34900: 0.104652\n",
      "2023-12-05 23:12:33,912 INFO     Training average positive_sample_loss at step 35000: 0.122434\n",
      "2023-12-05 23:12:33,913 INFO     Training average negative_sample_loss at step 35000: 0.090935\n",
      "2023-12-05 23:12:33,913 INFO     Training average loss at step 35000: 0.106685\n",
      "2023-12-05 23:12:40,309 INFO     Training average positive_sample_loss at step 35100: 0.122176\n",
      "2023-12-05 23:12:40,310 INFO     Training average negative_sample_loss at step 35100: 0.091654\n",
      "2023-12-05 23:12:40,310 INFO     Training average loss at step 35100: 0.106915\n",
      "2023-12-05 23:12:45,474 INFO     Training average positive_sample_loss at step 35200: 0.118149\n",
      "2023-12-05 23:12:45,474 INFO     Training average negative_sample_loss at step 35200: 0.090097\n",
      "2023-12-05 23:12:45,474 INFO     Training average loss at step 35200: 0.104123\n",
      "2023-12-05 23:12:50,627 INFO     Training average positive_sample_loss at step 35300: 0.123069\n",
      "2023-12-05 23:12:50,628 INFO     Training average negative_sample_loss at step 35300: 0.091331\n",
      "2023-12-05 23:12:50,628 INFO     Training average loss at step 35300: 0.107200\n",
      "2023-12-05 23:12:57,024 INFO     Training average positive_sample_loss at step 35400: 0.119030\n",
      "2023-12-05 23:12:57,024 INFO     Training average negative_sample_loss at step 35400: 0.091593\n",
      "2023-12-05 23:12:57,024 INFO     Training average loss at step 35400: 0.105312\n",
      "2023-12-05 23:13:02,164 INFO     Training average positive_sample_loss at step 35500: 0.121127\n",
      "2023-12-05 23:13:02,164 INFO     Training average negative_sample_loss at step 35500: 0.089936\n",
      "2023-12-05 23:13:02,164 INFO     Training average loss at step 35500: 0.105532\n",
      "2023-12-05 23:13:07,309 INFO     Training average positive_sample_loss at step 35600: 0.123422\n",
      "2023-12-05 23:13:07,309 INFO     Training average negative_sample_loss at step 35600: 0.091287\n",
      "2023-12-05 23:13:07,309 INFO     Training average loss at step 35600: 0.107355\n",
      "2023-12-05 23:13:13,528 INFO     Training average positive_sample_loss at step 35700: 0.117176\n",
      "2023-12-05 23:13:13,529 INFO     Training average negative_sample_loss at step 35700: 0.090576\n",
      "2023-12-05 23:13:13,529 INFO     Training average loss at step 35700: 0.103876\n",
      "2023-12-05 23:13:18,893 INFO     Training average positive_sample_loss at step 35800: 0.122620\n",
      "2023-12-05 23:13:18,893 INFO     Training average negative_sample_loss at step 35800: 0.091243\n",
      "2023-12-05 23:13:18,893 INFO     Training average loss at step 35800: 0.106932\n",
      "2023-12-05 23:13:24,596 INFO     Training average positive_sample_loss at step 35900: 0.119854\n",
      "2023-12-05 23:13:24,597 INFO     Training average negative_sample_loss at step 35900: 0.091906\n",
      "2023-12-05 23:13:24,597 INFO     Training average loss at step 35900: 0.105880\n",
      "2023-12-05 23:13:30,202 INFO     Training average positive_sample_loss at step 36000: 0.119668\n",
      "2023-12-05 23:13:30,202 INFO     Training average negative_sample_loss at step 36000: 0.090481\n",
      "2023-12-05 23:13:30,202 INFO     Training average loss at step 36000: 0.105074\n",
      "2023-12-05 23:13:35,353 INFO     Training average positive_sample_loss at step 36100: 0.123610\n",
      "2023-12-05 23:13:35,353 INFO     Training average negative_sample_loss at step 36100: 0.090869\n",
      "2023-12-05 23:13:35,353 INFO     Training average loss at step 36100: 0.107239\n",
      "2023-12-05 23:13:41,202 INFO     Training average positive_sample_loss at step 36200: 0.117475\n",
      "2023-12-05 23:13:41,202 INFO     Training average negative_sample_loss at step 36200: 0.090902\n",
      "2023-12-05 23:13:41,202 INFO     Training average loss at step 36200: 0.104188\n",
      "2023-12-05 23:13:46,797 INFO     Training average positive_sample_loss at step 36300: 0.122906\n",
      "2023-12-05 23:13:46,797 INFO     Training average negative_sample_loss at step 36300: 0.091198\n",
      "2023-12-05 23:13:46,797 INFO     Training average loss at step 36300: 0.107052\n",
      "2023-12-05 23:13:52,606 INFO     Training average positive_sample_loss at step 36400: 0.120131\n",
      "2023-12-05 23:13:52,607 INFO     Training average negative_sample_loss at step 36400: 0.091199\n",
      "2023-12-05 23:13:52,607 INFO     Training average loss at step 36400: 0.105665\n",
      "2023-12-05 23:13:58,045 INFO     Training average positive_sample_loss at step 36500: 0.119080\n",
      "2023-12-05 23:13:58,045 INFO     Training average negative_sample_loss at step 36500: 0.089639\n",
      "2023-12-05 23:13:58,045 INFO     Training average loss at step 36500: 0.104359\n",
      "2023-12-05 23:14:03,188 INFO     Training average positive_sample_loss at step 36600: 0.122952\n",
      "2023-12-05 23:14:03,188 INFO     Training average negative_sample_loss at step 36600: 0.091138\n",
      "2023-12-05 23:14:03,188 INFO     Training average loss at step 36600: 0.107045\n",
      "2023-12-05 23:14:08,980 INFO     Training average positive_sample_loss at step 36700: 0.117894\n",
      "2023-12-05 23:14:08,980 INFO     Training average negative_sample_loss at step 36700: 0.091099\n",
      "2023-12-05 23:14:08,980 INFO     Training average loss at step 36700: 0.104496\n",
      "2023-12-05 23:14:14,120 INFO     Training average positive_sample_loss at step 36800: 0.121000\n",
      "2023-12-05 23:14:14,120 INFO     Training average negative_sample_loss at step 36800: 0.090390\n",
      "2023-12-05 23:14:14,120 INFO     Training average loss at step 36800: 0.105695\n",
      "2023-12-05 23:14:20,493 INFO     Training average positive_sample_loss at step 36900: 0.123099\n",
      "2023-12-05 23:14:20,493 INFO     Training average negative_sample_loss at step 36900: 0.091586\n",
      "2023-12-05 23:14:20,493 INFO     Training average loss at step 36900: 0.107343\n",
      "2023-12-05 23:14:25,632 INFO     Training average positive_sample_loss at step 37000: 0.117389\n",
      "2023-12-05 23:14:25,632 INFO     Training average negative_sample_loss at step 37000: 0.090118\n",
      "2023-12-05 23:14:25,632 INFO     Training average loss at step 37000: 0.103754\n",
      "2023-12-05 23:14:30,754 INFO     Training average positive_sample_loss at step 37100: 0.122761\n",
      "2023-12-05 23:14:30,754 INFO     Training average negative_sample_loss at step 37100: 0.090745\n",
      "2023-12-05 23:14:30,754 INFO     Training average loss at step 37100: 0.106753\n",
      "2023-12-05 23:14:36,557 INFO     Training average positive_sample_loss at step 37200: 0.118850\n",
      "2023-12-05 23:14:36,557 INFO     Training average negative_sample_loss at step 37200: 0.091447\n",
      "2023-12-05 23:14:36,557 INFO     Training average loss at step 37200: 0.105149\n",
      "2023-12-05 23:14:42,409 INFO     Training average positive_sample_loss at step 37300: 0.121295\n",
      "2023-12-05 23:14:42,409 INFO     Training average negative_sample_loss at step 37300: 0.091333\n",
      "2023-12-05 23:14:42,409 INFO     Training average loss at step 37300: 0.106314\n",
      "2023-12-05 23:14:47,618 INFO     Training average positive_sample_loss at step 37400: 0.123068\n",
      "2023-12-05 23:14:47,619 INFO     Training average negative_sample_loss at step 37400: 0.091026\n",
      "2023-12-05 23:14:47,619 INFO     Training average loss at step 37400: 0.107047\n",
      "2023-12-05 23:14:53,473 INFO     Training average positive_sample_loss at step 37500: 0.116887\n",
      "2023-12-05 23:14:53,473 INFO     Training average negative_sample_loss at step 37500: 0.090084\n",
      "2023-12-05 23:14:53,473 INFO     Training average loss at step 37500: 0.103485\n",
      "2023-12-05 23:14:58,673 INFO     Training average positive_sample_loss at step 37600: 0.121833\n",
      "2023-12-05 23:14:58,674 INFO     Training average negative_sample_loss at step 37600: 0.089913\n",
      "2023-12-05 23:14:58,674 INFO     Training average loss at step 37600: 0.105873\n",
      "2023-12-05 23:15:04,468 INFO     Training average positive_sample_loss at step 37700: 0.119836\n",
      "2023-12-05 23:15:04,469 INFO     Training average negative_sample_loss at step 37700: 0.092041\n",
      "2023-12-05 23:15:04,469 INFO     Training average loss at step 37700: 0.105939\n",
      "2023-12-05 23:15:09,657 INFO     Training average positive_sample_loss at step 37800: 0.119825\n",
      "2023-12-05 23:15:09,658 INFO     Training average negative_sample_loss at step 37800: 0.089540\n",
      "2023-12-05 23:15:09,658 INFO     Training average loss at step 37800: 0.104683\n",
      "2023-12-05 23:15:15,512 INFO     Training average positive_sample_loss at step 37900: 0.123145\n",
      "2023-12-05 23:15:15,512 INFO     Training average negative_sample_loss at step 37900: 0.090907\n",
      "2023-12-05 23:15:15,512 INFO     Training average loss at step 37900: 0.107026\n",
      "2023-12-05 23:15:21,334 INFO     Training average positive_sample_loss at step 38000: 0.117070\n",
      "2023-12-05 23:15:21,335 INFO     Training average negative_sample_loss at step 38000: 0.090531\n",
      "2023-12-05 23:15:21,335 INFO     Training average loss at step 38000: 0.103800\n",
      "2023-12-05 23:15:26,466 INFO     Training average positive_sample_loss at step 38100: 0.121821\n",
      "2023-12-05 23:15:26,467 INFO     Training average negative_sample_loss at step 38100: 0.090827\n",
      "2023-12-05 23:15:26,467 INFO     Training average loss at step 38100: 0.106324\n",
      "2023-12-05 23:15:32,226 INFO     Training average positive_sample_loss at step 38200: 0.121275\n",
      "2023-12-05 23:15:32,227 INFO     Training average negative_sample_loss at step 38200: 0.090813\n",
      "2023-12-05 23:15:32,227 INFO     Training average loss at step 38200: 0.106044\n",
      "2023-12-05 23:15:37,394 INFO     Training average positive_sample_loss at step 38300: 0.117773\n",
      "2023-12-05 23:15:37,394 INFO     Training average negative_sample_loss at step 38300: 0.089867\n",
      "2023-12-05 23:15:37,394 INFO     Training average loss at step 38300: 0.103820\n",
      "2023-12-05 23:15:42,561 INFO     Training average positive_sample_loss at step 38400: 0.122872\n",
      "2023-12-05 23:15:42,561 INFO     Training average negative_sample_loss at step 38400: 0.091068\n",
      "2023-12-05 23:15:42,561 INFO     Training average loss at step 38400: 0.106970\n",
      "2023-12-05 23:15:49,088 INFO     Training average positive_sample_loss at step 38500: 0.118155\n",
      "2023-12-05 23:15:49,088 INFO     Training average negative_sample_loss at step 38500: 0.091712\n",
      "2023-12-05 23:15:49,088 INFO     Training average loss at step 38500: 0.104933\n",
      "2023-12-05 23:15:54,233 INFO     Training average positive_sample_loss at step 38600: 0.120755\n",
      "2023-12-05 23:15:54,234 INFO     Training average negative_sample_loss at step 38600: 0.089394\n",
      "2023-12-05 23:15:54,234 INFO     Training average loss at step 38600: 0.105074\n",
      "2023-12-05 23:15:59,653 INFO     Training average positive_sample_loss at step 38700: 0.123239\n",
      "2023-12-05 23:15:59,653 INFO     Training average negative_sample_loss at step 38700: 0.090980\n",
      "2023-12-05 23:15:59,653 INFO     Training average loss at step 38700: 0.107109\n",
      "2023-12-05 23:16:05,796 INFO     Training average positive_sample_loss at step 38800: 0.116620\n",
      "2023-12-05 23:16:05,796 INFO     Training average negative_sample_loss at step 38800: 0.090326\n",
      "2023-12-05 23:16:05,797 INFO     Training average loss at step 38800: 0.103473\n",
      "2023-12-05 23:16:10,978 INFO     Training average positive_sample_loss at step 38900: 0.121946\n",
      "2023-12-05 23:16:10,978 INFO     Training average negative_sample_loss at step 38900: 0.089686\n",
      "2023-12-05 23:16:10,978 INFO     Training average loss at step 38900: 0.105816\n",
      "2023-12-05 23:16:16,762 INFO     Training average positive_sample_loss at step 39000: 0.117885\n",
      "2023-12-05 23:16:16,763 INFO     Training average negative_sample_loss at step 39000: 0.090853\n",
      "2023-12-05 23:16:16,763 INFO     Training average loss at step 39000: 0.104369\n",
      "2023-12-05 23:16:22,621 INFO     Training average positive_sample_loss at step 39100: 0.120018\n",
      "2023-12-05 23:16:22,621 INFO     Training average negative_sample_loss at step 39100: 0.089343\n",
      "2023-12-05 23:16:22,621 INFO     Training average loss at step 39100: 0.104681\n",
      "2023-12-05 23:16:27,829 INFO     Training average positive_sample_loss at step 39200: 0.123147\n",
      "2023-12-05 23:16:27,829 INFO     Training average negative_sample_loss at step 39200: 0.091669\n",
      "2023-12-05 23:16:27,829 INFO     Training average loss at step 39200: 0.107408\n",
      "2023-12-05 23:16:33,634 INFO     Training average positive_sample_loss at step 39300: 0.116795\n",
      "2023-12-05 23:16:33,635 INFO     Training average negative_sample_loss at step 39300: 0.090032\n",
      "2023-12-05 23:16:33,635 INFO     Training average loss at step 39300: 0.103414\n",
      "2023-12-05 23:16:38,908 INFO     Training average positive_sample_loss at step 39400: 0.121966\n",
      "2023-12-05 23:16:38,909 INFO     Training average negative_sample_loss at step 39400: 0.091128\n",
      "2023-12-05 23:16:38,909 INFO     Training average loss at step 39400: 0.106547\n",
      "2023-12-05 23:16:44,734 INFO     Training average positive_sample_loss at step 39500: 0.120139\n",
      "2023-12-05 23:16:44,734 INFO     Training average negative_sample_loss at step 39500: 0.091579\n",
      "2023-12-05 23:16:44,734 INFO     Training average loss at step 39500: 0.105859\n",
      "2023-12-05 23:16:49,879 INFO     Training average positive_sample_loss at step 39600: 0.118852\n",
      "2023-12-05 23:16:49,879 INFO     Training average negative_sample_loss at step 39600: 0.089043\n",
      "2023-12-05 23:16:49,879 INFO     Training average loss at step 39600: 0.103947\n",
      "2023-12-05 23:16:55,020 INFO     Training average positive_sample_loss at step 39700: 0.122125\n",
      "2023-12-05 23:16:55,020 INFO     Training average negative_sample_loss at step 39700: 0.090186\n",
      "2023-12-05 23:16:55,020 INFO     Training average loss at step 39700: 0.106156\n",
      "2023-12-05 23:17:01,196 INFO     Training average positive_sample_loss at step 39800: 0.117598\n",
      "2023-12-05 23:17:01,196 INFO     Training average negative_sample_loss at step 39800: 0.091039\n",
      "2023-12-05 23:17:01,196 INFO     Training average loss at step 39800: 0.104319\n",
      "2023-12-05 23:17:06,650 INFO     Training average positive_sample_loss at step 39900: 0.121484\n",
      "2023-12-05 23:17:06,651 INFO     Training average negative_sample_loss at step 39900: 0.090184\n",
      "2023-12-05 23:17:06,651 INFO     Training average loss at step 39900: 0.105834\n",
      "2023-12-05 23:17:21,754 INFO     Training average positive_sample_loss at step 40000: 0.121414\n",
      "2023-12-05 23:17:21,755 INFO     Training average negative_sample_loss at step 40000: 0.091466\n",
      "2023-12-05 23:17:21,755 INFO     Training average loss at step 40000: 0.106440\n",
      "2023-12-05 23:17:21,755 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 23:17:22,487 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 23:17:51,930 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 23:18:11,585 INFO     Valid MRR at step 40000: 0.565312\n",
      "2023-12-05 23:18:11,586 INFO     Valid MR at step 40000: 274.678355\n",
      "2023-12-05 23:18:11,586 INFO     Valid HITS@1 at step 40000: 0.498295\n",
      "2023-12-05 23:18:11,586 INFO     Valid HITS@3 at step 40000: 0.595368\n",
      "2023-12-05 23:18:11,586 INFO     Valid HITS@10 at step 40000: 0.693226\n",
      "2023-12-05 23:18:16,837 INFO     Training average positive_sample_loss at step 40100: 0.117682\n",
      "2023-12-05 23:18:16,838 INFO     Training average negative_sample_loss at step 40100: 0.089891\n",
      "2023-12-05 23:18:16,838 INFO     Training average loss at step 40100: 0.103787\n",
      "2023-12-05 23:18:22,678 INFO     Training average positive_sample_loss at step 40200: 0.121958\n",
      "2023-12-05 23:18:22,678 INFO     Training average negative_sample_loss at step 40200: 0.089957\n",
      "2023-12-05 23:18:22,678 INFO     Training average loss at step 40200: 0.105957\n",
      "2023-12-05 23:18:28,798 INFO     Training average positive_sample_loss at step 40300: 0.117769\n",
      "2023-12-05 23:18:28,798 INFO     Training average negative_sample_loss at step 40300: 0.091319\n",
      "2023-12-05 23:18:28,798 INFO     Training average loss at step 40300: 0.104544\n",
      "2023-12-05 23:18:34,151 INFO     Training average positive_sample_loss at step 40400: 0.120101\n",
      "2023-12-05 23:18:34,151 INFO     Training average negative_sample_loss at step 40400: 0.089331\n",
      "2023-12-05 23:18:34,151 INFO     Training average loss at step 40400: 0.104716\n",
      "2023-12-05 23:18:39,468 INFO     Training average positive_sample_loss at step 40500: 0.122998\n",
      "2023-12-05 23:18:39,469 INFO     Training average negative_sample_loss at step 40500: 0.090980\n",
      "2023-12-05 23:18:39,469 INFO     Training average loss at step 40500: 0.106989\n",
      "2023-12-05 23:18:45,988 INFO     Training average positive_sample_loss at step 40600: 0.116456\n",
      "2023-12-05 23:18:45,988 INFO     Training average negative_sample_loss at step 40600: 0.090189\n",
      "2023-12-05 23:18:45,988 INFO     Training average loss at step 40600: 0.103323\n",
      "2023-12-05 23:18:51,200 INFO     Training average positive_sample_loss at step 40700: 0.121465\n",
      "2023-12-05 23:18:51,201 INFO     Training average negative_sample_loss at step 40700: 0.089696\n",
      "2023-12-05 23:18:51,201 INFO     Training average loss at step 40700: 0.105580\n",
      "2023-12-05 23:18:57,037 INFO     Training average positive_sample_loss at step 40800: 0.119149\n",
      "2023-12-05 23:18:57,037 INFO     Training average negative_sample_loss at step 40800: 0.091896\n",
      "2023-12-05 23:18:57,037 INFO     Training average loss at step 40800: 0.105522\n",
      "2023-12-05 23:19:02,215 INFO     Training average positive_sample_loss at step 40900: 0.119559\n",
      "2023-12-05 23:19:02,215 INFO     Training average negative_sample_loss at step 40900: 0.089728\n",
      "2023-12-05 23:19:02,215 INFO     Training average loss at step 40900: 0.104643\n",
      "2023-12-05 23:19:08,117 INFO     Training average positive_sample_loss at step 41000: 0.122648\n",
      "2023-12-05 23:19:08,118 INFO     Training average negative_sample_loss at step 41000: 0.090775\n",
      "2023-12-05 23:19:08,118 INFO     Training average loss at step 41000: 0.106712\n",
      "2023-12-05 23:19:13,982 INFO     Training average positive_sample_loss at step 41100: 0.116216\n",
      "2023-12-05 23:19:13,982 INFO     Training average negative_sample_loss at step 41100: 0.090126\n",
      "2023-12-05 23:19:13,982 INFO     Training average loss at step 41100: 0.103171\n",
      "2023-12-05 23:19:19,289 INFO     Training average positive_sample_loss at step 41200: 0.121804\n",
      "2023-12-05 23:19:19,290 INFO     Training average negative_sample_loss at step 41200: 0.090363\n",
      "2023-12-05 23:19:19,290 INFO     Training average loss at step 41200: 0.106084\n",
      "2023-12-05 23:19:25,178 INFO     Training average positive_sample_loss at step 41300: 0.120423\n",
      "2023-12-05 23:19:25,179 INFO     Training average negative_sample_loss at step 41300: 0.091220\n",
      "2023-12-05 23:19:25,179 INFO     Training average loss at step 41300: 0.105821\n",
      "2023-12-05 23:19:31,054 INFO     Training average positive_sample_loss at step 41400: 0.118021\n",
      "2023-12-05 23:19:31,054 INFO     Training average negative_sample_loss at step 41400: 0.088861\n",
      "2023-12-05 23:19:31,055 INFO     Training average loss at step 41400: 0.103441\n",
      "2023-12-05 23:19:36,363 INFO     Training average positive_sample_loss at step 41500: 0.122137\n",
      "2023-12-05 23:19:36,364 INFO     Training average negative_sample_loss at step 41500: 0.090385\n",
      "2023-12-05 23:19:36,364 INFO     Training average loss at step 41500: 0.106261\n",
      "2023-12-05 23:19:42,242 INFO     Training average positive_sample_loss at step 41600: 0.117348\n",
      "2023-12-05 23:19:42,243 INFO     Training average negative_sample_loss at step 41600: 0.090517\n",
      "2023-12-05 23:19:42,243 INFO     Training average loss at step 41600: 0.103933\n",
      "2023-12-05 23:19:48,065 INFO     Training average positive_sample_loss at step 41700: 0.120449\n",
      "2023-12-05 23:19:48,066 INFO     Training average negative_sample_loss at step 41700: 0.088941\n",
      "2023-12-05 23:19:48,066 INFO     Training average loss at step 41700: 0.104695\n",
      "2023-12-05 23:19:54,024 INFO     Training average positive_sample_loss at step 41800: 0.121729\n",
      "2023-12-05 23:19:54,025 INFO     Training average negative_sample_loss at step 41800: 0.091249\n",
      "2023-12-05 23:19:54,025 INFO     Training average loss at step 41800: 0.106489\n",
      "2023-12-05 23:19:59,232 INFO     Training average positive_sample_loss at step 41900: 0.116633\n",
      "2023-12-05 23:19:59,232 INFO     Training average negative_sample_loss at step 41900: 0.089319\n",
      "2023-12-05 23:19:59,232 INFO     Training average loss at step 41900: 0.102976\n",
      "2023-12-05 23:20:04,484 INFO     Training average positive_sample_loss at step 42000: 0.121741\n",
      "2023-12-05 23:20:04,484 INFO     Training average negative_sample_loss at step 42000: 0.090508\n",
      "2023-12-05 23:20:04,484 INFO     Training average loss at step 42000: 0.106125\n",
      "2023-12-05 23:20:11,016 INFO     Training average positive_sample_loss at step 42100: 0.118216\n",
      "2023-12-05 23:20:11,017 INFO     Training average negative_sample_loss at step 42100: 0.090413\n",
      "2023-12-05 23:20:11,017 INFO     Training average loss at step 42100: 0.104314\n",
      "2023-12-05 23:20:16,323 INFO     Training average positive_sample_loss at step 42200: 0.119726\n",
      "2023-12-05 23:20:16,324 INFO     Training average negative_sample_loss at step 42200: 0.089537\n",
      "2023-12-05 23:20:16,324 INFO     Training average loss at step 42200: 0.104631\n",
      "2023-12-05 23:20:21,636 INFO     Training average positive_sample_loss at step 42300: 0.122210\n",
      "2023-12-05 23:20:21,637 INFO     Training average negative_sample_loss at step 42300: 0.090609\n",
      "2023-12-05 23:20:21,637 INFO     Training average loss at step 42300: 0.106410\n",
      "2023-12-05 23:20:27,389 INFO     Training average positive_sample_loss at step 42400: 0.116147\n",
      "2023-12-05 23:20:27,390 INFO     Training average negative_sample_loss at step 42400: 0.089758\n",
      "2023-12-05 23:20:27,390 INFO     Training average loss at step 42400: 0.102952\n",
      "2023-12-05 23:20:33,238 INFO     Training average positive_sample_loss at step 42500: 0.121270\n",
      "2023-12-05 23:20:33,239 INFO     Training average negative_sample_loss at step 42500: 0.090025\n",
      "2023-12-05 23:20:33,239 INFO     Training average loss at step 42500: 0.105648\n",
      "2023-12-05 23:20:39,062 INFO     Training average positive_sample_loss at step 42600: 0.119645\n",
      "2023-12-05 23:20:39,062 INFO     Training average negative_sample_loss at step 42600: 0.091534\n",
      "2023-12-05 23:20:39,062 INFO     Training average loss at step 42600: 0.105590\n",
      "2023-12-05 23:20:44,243 INFO     Training average positive_sample_loss at step 42700: 0.118815\n",
      "2023-12-05 23:20:44,243 INFO     Training average negative_sample_loss at step 42700: 0.089021\n",
      "2023-12-05 23:20:44,243 INFO     Training average loss at step 42700: 0.103918\n",
      "2023-12-05 23:20:49,441 INFO     Training average positive_sample_loss at step 42800: 0.121880\n",
      "2023-12-05 23:20:49,442 INFO     Training average negative_sample_loss at step 42800: 0.090038\n",
      "2023-12-05 23:20:49,442 INFO     Training average loss at step 42800: 0.105959\n",
      "2023-12-05 23:20:56,130 INFO     Training average positive_sample_loss at step 42900: 0.116629\n",
      "2023-12-05 23:20:56,131 INFO     Training average negative_sample_loss at step 42900: 0.090079\n",
      "2023-12-05 23:20:56,131 INFO     Training average loss at step 42900: 0.103354\n",
      "2023-12-05 23:21:01,526 INFO     Training average positive_sample_loss at step 43000: 0.120756\n",
      "2023-12-05 23:21:01,526 INFO     Training average negative_sample_loss at step 43000: 0.089183\n",
      "2023-12-05 23:21:01,527 INFO     Training average loss at step 43000: 0.104969\n",
      "2023-12-05 23:21:07,626 INFO     Training average positive_sample_loss at step 43100: 0.120686\n",
      "2023-12-05 23:21:07,627 INFO     Training average negative_sample_loss at step 43100: 0.091149\n",
      "2023-12-05 23:21:07,627 INFO     Training average loss at step 43100: 0.105918\n",
      "2023-12-05 23:21:12,930 INFO     Training average positive_sample_loss at step 43200: 0.117748\n",
      "2023-12-05 23:21:12,930 INFO     Training average negative_sample_loss at step 43200: 0.089337\n",
      "2023-12-05 23:21:12,930 INFO     Training average loss at step 43200: 0.103542\n",
      "2023-12-05 23:21:18,869 INFO     Training average positive_sample_loss at step 43300: 0.121481\n",
      "2023-12-05 23:21:18,869 INFO     Training average negative_sample_loss at step 43300: 0.090780\n",
      "2023-12-05 23:21:18,869 INFO     Training average loss at step 43300: 0.106130\n",
      "2023-12-05 23:21:24,748 INFO     Training average positive_sample_loss at step 43400: 0.117680\n",
      "2023-12-05 23:21:24,749 INFO     Training average negative_sample_loss at step 43400: 0.090301\n",
      "2023-12-05 23:21:24,749 INFO     Training average loss at step 43400: 0.103991\n",
      "2023-12-05 23:21:30,109 INFO     Training average positive_sample_loss at step 43500: 0.120139\n",
      "2023-12-05 23:21:30,109 INFO     Training average negative_sample_loss at step 43500: 0.089611\n",
      "2023-12-05 23:21:30,109 INFO     Training average loss at step 43500: 0.104875\n",
      "2023-12-05 23:21:35,493 INFO     Training average positive_sample_loss at step 43600: 0.122171\n",
      "2023-12-05 23:21:35,494 INFO     Training average negative_sample_loss at step 43600: 0.091099\n",
      "2023-12-05 23:21:35,494 INFO     Training average loss at step 43600: 0.106635\n",
      "2023-12-05 23:21:41,936 INFO     Training average positive_sample_loss at step 43700: 0.116202\n",
      "2023-12-05 23:21:41,936 INFO     Training average negative_sample_loss at step 43700: 0.089588\n",
      "2023-12-05 23:21:41,936 INFO     Training average loss at step 43700: 0.102895\n",
      "2023-12-05 23:21:47,188 INFO     Training average positive_sample_loss at step 43800: 0.121227\n",
      "2023-12-05 23:21:47,188 INFO     Training average negative_sample_loss at step 43800: 0.090004\n",
      "2023-12-05 23:21:47,188 INFO     Training average loss at step 43800: 0.105615\n",
      "2023-12-05 23:21:53,090 INFO     Training average positive_sample_loss at step 43900: 0.118341\n",
      "2023-12-05 23:21:53,091 INFO     Training average negative_sample_loss at step 43900: 0.090384\n",
      "2023-12-05 23:21:53,091 INFO     Training average loss at step 43900: 0.104363\n",
      "2023-12-05 23:21:58,327 INFO     Training average positive_sample_loss at step 44000: 0.119294\n",
      "2023-12-05 23:21:58,328 INFO     Training average negative_sample_loss at step 44000: 0.089259\n",
      "2023-12-05 23:21:58,328 INFO     Training average loss at step 44000: 0.104276\n",
      "2023-12-05 23:22:03,562 INFO     Training average positive_sample_loss at step 44100: 0.121794\n",
      "2023-12-05 23:22:03,563 INFO     Training average negative_sample_loss at step 44100: 0.089757\n",
      "2023-12-05 23:22:03,563 INFO     Training average loss at step 44100: 0.105776\n",
      "2023-12-05 23:22:10,038 INFO     Training average positive_sample_loss at step 44200: 0.116599\n",
      "2023-12-05 23:22:10,038 INFO     Training average negative_sample_loss at step 44200: 0.090769\n",
      "2023-12-05 23:22:10,038 INFO     Training average loss at step 44200: 0.103684\n",
      "2023-12-05 23:22:15,252 INFO     Training average positive_sample_loss at step 44300: 0.120978\n",
      "2023-12-05 23:22:15,252 INFO     Training average negative_sample_loss at step 44300: 0.089726\n",
      "2023-12-05 23:22:15,252 INFO     Training average loss at step 44300: 0.105352\n",
      "2023-12-05 23:22:21,266 INFO     Training average positive_sample_loss at step 44400: 0.119559\n",
      "2023-12-05 23:22:21,267 INFO     Training average negative_sample_loss at step 44400: 0.090909\n",
      "2023-12-05 23:22:21,267 INFO     Training average loss at step 44400: 0.105234\n",
      "2023-12-05 23:22:26,537 INFO     Training average positive_sample_loss at step 44500: 0.117847\n",
      "2023-12-05 23:22:26,538 INFO     Training average negative_sample_loss at step 44500: 0.088118\n",
      "2023-12-05 23:22:26,538 INFO     Training average loss at step 44500: 0.102983\n",
      "2023-12-05 23:22:32,394 INFO     Training average positive_sample_loss at step 44600: 0.121436\n",
      "2023-12-05 23:22:32,395 INFO     Training average negative_sample_loss at step 44600: 0.089500\n",
      "2023-12-05 23:22:32,395 INFO     Training average loss at step 44600: 0.105468\n",
      "2023-12-05 23:22:38,194 INFO     Training average positive_sample_loss at step 44700: 0.116612\n",
      "2023-12-05 23:22:38,194 INFO     Training average negative_sample_loss at step 44700: 0.089883\n",
      "2023-12-05 23:22:38,194 INFO     Training average loss at step 44700: 0.103248\n",
      "2023-12-05 23:22:43,501 INFO     Training average positive_sample_loss at step 44800: 0.119969\n",
      "2023-12-05 23:22:43,501 INFO     Training average negative_sample_loss at step 44800: 0.088989\n",
      "2023-12-05 23:22:43,501 INFO     Training average loss at step 44800: 0.104479\n",
      "2023-12-05 23:22:49,566 INFO     Training average positive_sample_loss at step 44900: 0.121138\n",
      "2023-12-05 23:22:49,566 INFO     Training average negative_sample_loss at step 44900: 0.090280\n",
      "2023-12-05 23:22:49,566 INFO     Training average loss at step 44900: 0.105709\n",
      "2023-12-05 23:22:54,751 INFO     Training average positive_sample_loss at step 45000: 0.116411\n",
      "2023-12-05 23:22:54,751 INFO     Training average negative_sample_loss at step 45000: 0.090018\n",
      "2023-12-05 23:22:54,751 INFO     Training average loss at step 45000: 0.103215\n",
      "2023-12-05 23:23:00,602 INFO     Training average positive_sample_loss at step 45100: 0.121540\n",
      "2023-12-05 23:23:00,602 INFO     Training average negative_sample_loss at step 45100: 0.089422\n",
      "2023-12-05 23:23:00,602 INFO     Training average loss at step 45100: 0.105481\n",
      "2023-12-05 23:23:06,394 INFO     Training average positive_sample_loss at step 45200: 0.117565\n",
      "2023-12-05 23:23:06,394 INFO     Training average negative_sample_loss at step 45200: 0.090779\n",
      "2023-12-05 23:23:06,394 INFO     Training average loss at step 45200: 0.104172\n",
      "2023-12-05 23:23:11,643 INFO     Training average positive_sample_loss at step 45300: 0.120060\n",
      "2023-12-05 23:23:11,643 INFO     Training average negative_sample_loss at step 45300: 0.089400\n",
      "2023-12-05 23:23:11,643 INFO     Training average loss at step 45300: 0.104730\n",
      "2023-12-05 23:23:16,856 INFO     Training average positive_sample_loss at step 45400: 0.121434\n",
      "2023-12-05 23:23:16,856 INFO     Training average negative_sample_loss at step 45400: 0.090091\n",
      "2023-12-05 23:23:16,856 INFO     Training average loss at step 45400: 0.105762\n",
      "2023-12-05 23:23:22,671 INFO     Training average positive_sample_loss at step 45500: 0.116687\n",
      "2023-12-05 23:23:22,671 INFO     Training average negative_sample_loss at step 45500: 0.090816\n",
      "2023-12-05 23:23:22,671 INFO     Training average loss at step 45500: 0.103751\n",
      "2023-12-05 23:23:28,525 INFO     Training average positive_sample_loss at step 45600: 0.120439\n",
      "2023-12-05 23:23:28,525 INFO     Training average negative_sample_loss at step 45600: 0.089010\n",
      "2023-12-05 23:23:28,525 INFO     Training average loss at step 45600: 0.104724\n",
      "2023-12-05 23:23:34,529 INFO     Training average positive_sample_loss at step 45700: 0.118321\n",
      "2023-12-05 23:23:34,529 INFO     Training average negative_sample_loss at step 45700: 0.090235\n",
      "2023-12-05 23:23:34,529 INFO     Training average loss at step 45700: 0.104278\n",
      "2023-12-05 23:23:39,738 INFO     Training average positive_sample_loss at step 45800: 0.118703\n",
      "2023-12-05 23:23:39,739 INFO     Training average negative_sample_loss at step 45800: 0.089057\n",
      "2023-12-05 23:23:39,739 INFO     Training average loss at step 45800: 0.103880\n",
      "2023-12-05 23:23:44,973 INFO     Training average positive_sample_loss at step 45900: 0.121783\n",
      "2023-12-05 23:23:44,973 INFO     Training average negative_sample_loss at step 45900: 0.089886\n",
      "2023-12-05 23:23:44,973 INFO     Training average loss at step 45900: 0.105834\n",
      "2023-12-05 23:23:50,886 INFO     Training average positive_sample_loss at step 46000: 0.116540\n",
      "2023-12-05 23:23:50,886 INFO     Training average negative_sample_loss at step 46000: 0.091168\n",
      "2023-12-05 23:23:50,886 INFO     Training average loss at step 46000: 0.103854\n",
      "2023-12-05 23:23:56,064 INFO     Training average positive_sample_loss at step 46100: 0.120330\n",
      "2023-12-05 23:23:56,065 INFO     Training average negative_sample_loss at step 46100: 0.088675\n",
      "2023-12-05 23:23:56,065 INFO     Training average loss at step 46100: 0.104502\n",
      "2023-12-05 23:24:02,607 INFO     Training average positive_sample_loss at step 46200: 0.119839\n",
      "2023-12-05 23:24:02,607 INFO     Training average negative_sample_loss at step 46200: 0.091087\n",
      "2023-12-05 23:24:02,607 INFO     Training average loss at step 46200: 0.105463\n",
      "2023-12-05 23:24:07,849 INFO     Training average positive_sample_loss at step 46300: 0.117007\n",
      "2023-12-05 23:24:07,849 INFO     Training average negative_sample_loss at step 46300: 0.088277\n",
      "2023-12-05 23:24:07,849 INFO     Training average loss at step 46300: 0.102642\n",
      "2023-12-05 23:24:13,064 INFO     Training average positive_sample_loss at step 46400: 0.121479\n",
      "2023-12-05 23:24:13,064 INFO     Training average negative_sample_loss at step 46400: 0.089687\n",
      "2023-12-05 23:24:13,064 INFO     Training average loss at step 46400: 0.105583\n",
      "2023-12-05 23:24:18,903 INFO     Training average positive_sample_loss at step 46500: 0.116851\n",
      "2023-12-05 23:24:18,904 INFO     Training average negative_sample_loss at step 46500: 0.089936\n",
      "2023-12-05 23:24:18,904 INFO     Training average loss at step 46500: 0.103394\n",
      "2023-12-05 23:24:24,094 INFO     Training average positive_sample_loss at step 46600: 0.119684\n",
      "2023-12-05 23:24:24,095 INFO     Training average negative_sample_loss at step 46600: 0.089607\n",
      "2023-12-05 23:24:24,095 INFO     Training average loss at step 46600: 0.104646\n",
      "2023-12-05 23:24:30,616 INFO     Training average positive_sample_loss at step 46700: 0.121573\n",
      "2023-12-05 23:24:30,617 INFO     Training average negative_sample_loss at step 46700: 0.090744\n",
      "2023-12-05 23:24:30,617 INFO     Training average loss at step 46700: 0.106158\n",
      "2023-12-05 23:24:35,831 INFO     Training average positive_sample_loss at step 46800: 0.115976\n",
      "2023-12-05 23:24:35,832 INFO     Training average negative_sample_loss at step 46800: 0.089222\n",
      "2023-12-05 23:24:35,832 INFO     Training average loss at step 46800: 0.102599\n",
      "2023-12-05 23:24:41,046 INFO     Training average positive_sample_loss at step 46900: 0.121390\n",
      "2023-12-05 23:24:41,046 INFO     Training average negative_sample_loss at step 46900: 0.089479\n",
      "2023-12-05 23:24:41,046 INFO     Training average loss at step 46900: 0.105434\n",
      "2023-12-05 23:24:47,029 INFO     Training average positive_sample_loss at step 47000: 0.117268\n",
      "2023-12-05 23:24:47,030 INFO     Training average negative_sample_loss at step 47000: 0.090027\n",
      "2023-12-05 23:24:47,030 INFO     Training average loss at step 47000: 0.103647\n",
      "2023-12-05 23:24:52,227 INFO     Training average positive_sample_loss at step 47100: 0.119142\n",
      "2023-12-05 23:24:52,228 INFO     Training average negative_sample_loss at step 47100: 0.089071\n",
      "2023-12-05 23:24:52,228 INFO     Training average loss at step 47100: 0.104107\n",
      "2023-12-05 23:24:57,442 INFO     Training average positive_sample_loss at step 47200: 0.121487\n",
      "2023-12-05 23:24:57,442 INFO     Training average negative_sample_loss at step 47200: 0.089867\n",
      "2023-12-05 23:24:57,442 INFO     Training average loss at step 47200: 0.105677\n",
      "2023-12-05 23:25:04,126 INFO     Training average positive_sample_loss at step 47300: 0.115754\n",
      "2023-12-05 23:25:04,126 INFO     Training average negative_sample_loss at step 47300: 0.089213\n",
      "2023-12-05 23:25:04,127 INFO     Training average loss at step 47300: 0.102483\n",
      "2023-12-05 23:25:09,481 INFO     Training average positive_sample_loss at step 47400: 0.120526\n",
      "2023-12-05 23:25:09,481 INFO     Training average negative_sample_loss at step 47400: 0.089372\n",
      "2023-12-05 23:25:09,481 INFO     Training average loss at step 47400: 0.104949\n",
      "2023-12-05 23:25:15,506 INFO     Training average positive_sample_loss at step 47500: 0.118710\n",
      "2023-12-05 23:25:15,507 INFO     Training average negative_sample_loss at step 47500: 0.090275\n",
      "2023-12-05 23:25:15,507 INFO     Training average loss at step 47500: 0.104492\n",
      "2023-12-05 23:25:20,749 INFO     Training average positive_sample_loss at step 47600: 0.118139\n",
      "2023-12-05 23:25:20,750 INFO     Training average negative_sample_loss at step 47600: 0.089393\n",
      "2023-12-05 23:25:20,750 INFO     Training average loss at step 47600: 0.103766\n",
      "2023-12-05 23:25:26,720 INFO     Training average positive_sample_loss at step 47700: 0.121240\n",
      "2023-12-05 23:25:26,721 INFO     Training average negative_sample_loss at step 47700: 0.090323\n",
      "2023-12-05 23:25:26,721 INFO     Training average loss at step 47700: 0.105781\n",
      "2023-12-05 23:25:32,573 INFO     Training average positive_sample_loss at step 47800: 0.116526\n",
      "2023-12-05 23:25:32,573 INFO     Training average negative_sample_loss at step 47800: 0.089625\n",
      "2023-12-05 23:25:32,573 INFO     Training average loss at step 47800: 0.103075\n",
      "2023-12-05 23:25:37,964 INFO     Training average positive_sample_loss at step 47900: 0.119719\n",
      "2023-12-05 23:25:37,965 INFO     Training average negative_sample_loss at step 47900: 0.088522\n",
      "2023-12-05 23:25:37,965 INFO     Training average loss at step 47900: 0.104121\n",
      "2023-12-05 23:25:44,196 INFO     Training average positive_sample_loss at step 48000: 0.119805\n",
      "2023-12-05 23:25:44,197 INFO     Training average negative_sample_loss at step 48000: 0.089913\n",
      "2023-12-05 23:25:44,197 INFO     Training average loss at step 48000: 0.104859\n",
      "2023-12-05 23:25:49,421 INFO     Training average positive_sample_loss at step 48100: 0.116839\n",
      "2023-12-05 23:25:49,421 INFO     Training average negative_sample_loss at step 48100: 0.088799\n",
      "2023-12-05 23:25:49,422 INFO     Training average loss at step 48100: 0.102819\n",
      "2023-12-05 23:25:54,675 INFO     Training average positive_sample_loss at step 48200: 0.120891\n",
      "2023-12-05 23:25:54,675 INFO     Training average negative_sample_loss at step 48200: 0.090010\n",
      "2023-12-05 23:25:54,675 INFO     Training average loss at step 48200: 0.105450\n",
      "2023-12-05 23:26:00,572 INFO     Training average positive_sample_loss at step 48300: 0.116818\n",
      "2023-12-05 23:26:00,573 INFO     Training average negative_sample_loss at step 48300: 0.090035\n",
      "2023-12-05 23:26:00,573 INFO     Training average loss at step 48300: 0.103427\n",
      "2023-12-05 23:26:06,515 INFO     Training average positive_sample_loss at step 48400: 0.119532\n",
      "2023-12-05 23:26:06,515 INFO     Training average negative_sample_loss at step 48400: 0.089220\n",
      "2023-12-05 23:26:06,515 INFO     Training average loss at step 48400: 0.104376\n",
      "2023-12-05 23:26:11,760 INFO     Training average positive_sample_loss at step 48500: 0.121433\n",
      "2023-12-05 23:26:11,760 INFO     Training average negative_sample_loss at step 48500: 0.090176\n",
      "2023-12-05 23:26:11,760 INFO     Training average loss at step 48500: 0.105805\n",
      "2023-12-05 23:26:17,632 INFO     Training average positive_sample_loss at step 48600: 0.115234\n",
      "2023-12-05 23:26:17,633 INFO     Training average negative_sample_loss at step 48600: 0.089312\n",
      "2023-12-05 23:26:17,633 INFO     Training average loss at step 48600: 0.102273\n",
      "2023-12-05 23:26:23,476 INFO     Training average positive_sample_loss at step 48700: 0.121251\n",
      "2023-12-05 23:26:23,476 INFO     Training average negative_sample_loss at step 48700: 0.088864\n",
      "2023-12-05 23:26:23,476 INFO     Training average loss at step 48700: 0.105057\n",
      "2023-12-05 23:26:29,480 INFO     Training average positive_sample_loss at step 48800: 0.117616\n",
      "2023-12-05 23:26:29,481 INFO     Training average negative_sample_loss at step 48800: 0.090525\n",
      "2023-12-05 23:26:29,481 INFO     Training average loss at step 48800: 0.104070\n",
      "2023-12-05 23:26:34,690 INFO     Training average positive_sample_loss at step 48900: 0.118601\n",
      "2023-12-05 23:26:34,690 INFO     Training average negative_sample_loss at step 48900: 0.088070\n",
      "2023-12-05 23:26:34,690 INFO     Training average loss at step 48900: 0.103335\n",
      "2023-12-05 23:26:40,661 INFO     Training average positive_sample_loss at step 49000: 0.121367\n",
      "2023-12-05 23:26:40,661 INFO     Training average negative_sample_loss at step 49000: 0.090079\n",
      "2023-12-05 23:26:40,661 INFO     Training average loss at step 49000: 0.105723\n",
      "2023-12-05 23:26:46,478 INFO     Training average positive_sample_loss at step 49100: 0.115480\n",
      "2023-12-05 23:26:46,478 INFO     Training average negative_sample_loss at step 49100: 0.089439\n",
      "2023-12-05 23:26:46,478 INFO     Training average loss at step 49100: 0.102460\n",
      "2023-12-05 23:26:51,719 INFO     Training average positive_sample_loss at step 49200: 0.120494\n",
      "2023-12-05 23:26:51,719 INFO     Training average negative_sample_loss at step 49200: 0.089475\n",
      "2023-12-05 23:26:51,719 INFO     Training average loss at step 49200: 0.104985\n",
      "2023-12-05 23:26:58,137 INFO     Training average positive_sample_loss at step 49300: 0.118795\n",
      "2023-12-05 23:26:58,137 INFO     Training average negative_sample_loss at step 49300: 0.089907\n",
      "2023-12-05 23:26:58,137 INFO     Training average loss at step 49300: 0.104351\n",
      "2023-12-05 23:27:03,323 INFO     Training average positive_sample_loss at step 49400: 0.117144\n",
      "2023-12-05 23:27:03,323 INFO     Training average negative_sample_loss at step 49400: 0.088762\n",
      "2023-12-05 23:27:03,324 INFO     Training average loss at step 49400: 0.102953\n",
      "2023-12-05 23:27:08,481 INFO     Training average positive_sample_loss at step 49500: 0.120762\n",
      "2023-12-05 23:27:08,481 INFO     Training average negative_sample_loss at step 49500: 0.089815\n",
      "2023-12-05 23:27:08,481 INFO     Training average loss at step 49500: 0.105288\n",
      "2023-12-05 23:27:14,338 INFO     Training average positive_sample_loss at step 49600: 0.116569\n",
      "2023-12-05 23:27:14,339 INFO     Training average negative_sample_loss at step 49600: 0.090242\n",
      "2023-12-05 23:27:14,339 INFO     Training average loss at step 49600: 0.103405\n",
      "2023-12-05 23:27:20,175 INFO     Training average positive_sample_loss at step 49700: 0.119780\n",
      "2023-12-05 23:27:20,176 INFO     Training average negative_sample_loss at step 49700: 0.088366\n",
      "2023-12-05 23:27:20,176 INFO     Training average loss at step 49700: 0.104073\n",
      "2023-12-05 23:27:25,988 INFO     Training average positive_sample_loss at step 49800: 0.120723\n",
      "2023-12-05 23:27:25,988 INFO     Training average negative_sample_loss at step 49800: 0.090398\n",
      "2023-12-05 23:27:25,988 INFO     Training average loss at step 49800: 0.105561\n",
      "2023-12-05 23:27:31,215 INFO     Training average positive_sample_loss at step 49900: 0.115939\n",
      "2023-12-05 23:27:31,215 INFO     Training average negative_sample_loss at step 49900: 0.089592\n",
      "2023-12-05 23:27:31,215 INFO     Training average loss at step 49900: 0.102765\n",
      "2023-12-05 23:27:37,102 INFO     Change learning_rate to 0.000005 at step 50000\n",
      "2023-12-05 23:27:43,383 INFO     Training average positive_sample_loss at step 50000: 0.120880\n",
      "2023-12-05 23:27:43,383 INFO     Training average negative_sample_loss at step 50000: 0.089520\n",
      "2023-12-05 23:27:43,383 INFO     Training average loss at step 50000: 0.105200\n",
      "2023-12-05 23:27:43,383 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 23:27:43,956 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 23:28:13,218 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 23:28:31,259 INFO     Valid MRR at step 50000: 0.570828\n",
      "2023-12-05 23:28:31,260 INFO     Valid MR at step 50000: 270.987516\n",
      "2023-12-05 23:28:31,260 INFO     Valid HITS@1 at step 50000: 0.505764\n",
      "2023-12-05 23:28:31,260 INFO     Valid HITS@3 at step 50000: 0.601542\n",
      "2023-12-05 23:28:31,260 INFO     Valid HITS@10 at step 50000: 0.696159\n",
      "2023-12-05 23:28:37,106 INFO     Training average positive_sample_loss at step 50100: 0.117703\n",
      "2023-12-05 23:28:37,107 INFO     Training average negative_sample_loss at step 50100: 0.088410\n",
      "2023-12-05 23:28:37,107 INFO     Training average loss at step 50100: 0.103056\n",
      "2023-12-05 23:28:42,898 INFO     Training average positive_sample_loss at step 50200: 0.111806\n",
      "2023-12-05 23:28:42,899 INFO     Training average negative_sample_loss at step 50200: 0.088068\n",
      "2023-12-05 23:28:42,899 INFO     Training average loss at step 50200: 0.099937\n",
      "2023-12-05 23:28:48,082 INFO     Training average positive_sample_loss at step 50300: 0.112342\n",
      "2023-12-05 23:28:48,082 INFO     Training average negative_sample_loss at step 50300: 0.087253\n",
      "2023-12-05 23:28:48,082 INFO     Training average loss at step 50300: 0.099798\n",
      "2023-12-05 23:28:53,839 INFO     Training average positive_sample_loss at step 50400: 0.110294\n",
      "2023-12-05 23:28:53,839 INFO     Training average negative_sample_loss at step 50400: 0.087041\n",
      "2023-12-05 23:28:53,839 INFO     Training average loss at step 50400: 0.098667\n",
      "2023-12-05 23:28:59,004 INFO     Training average positive_sample_loss at step 50500: 0.111127\n",
      "2023-12-05 23:28:59,004 INFO     Training average negative_sample_loss at step 50500: 0.086367\n",
      "2023-12-05 23:28:59,004 INFO     Training average loss at step 50500: 0.098747\n",
      "2023-12-05 23:29:05,444 INFO     Training average positive_sample_loss at step 50600: 0.111593\n",
      "2023-12-05 23:29:05,445 INFO     Training average negative_sample_loss at step 50600: 0.086504\n",
      "2023-12-05 23:29:05,445 INFO     Training average loss at step 50600: 0.099049\n",
      "2023-12-05 23:29:10,579 INFO     Training average positive_sample_loss at step 50700: 0.110082\n",
      "2023-12-05 23:29:10,579 INFO     Training average negative_sample_loss at step 50700: 0.085924\n",
      "2023-12-05 23:29:10,580 INFO     Training average loss at step 50700: 0.098003\n",
      "2023-12-05 23:29:15,746 INFO     Training average positive_sample_loss at step 50800: 0.110950\n",
      "2023-12-05 23:29:15,746 INFO     Training average negative_sample_loss at step 50800: 0.086129\n",
      "2023-12-05 23:29:15,746 INFO     Training average loss at step 50800: 0.098539\n",
      "2023-12-05 23:29:22,139 INFO     Training average positive_sample_loss at step 50900: 0.110280\n",
      "2023-12-05 23:29:22,139 INFO     Training average negative_sample_loss at step 50900: 0.086300\n",
      "2023-12-05 23:29:22,139 INFO     Training average loss at step 50900: 0.098290\n",
      "2023-12-05 23:29:27,292 INFO     Training average positive_sample_loss at step 51000: 0.109969\n",
      "2023-12-05 23:29:27,292 INFO     Training average negative_sample_loss at step 51000: 0.085429\n",
      "2023-12-05 23:29:27,293 INFO     Training average loss at step 51000: 0.097699\n",
      "2023-12-05 23:29:33,009 INFO     Training average positive_sample_loss at step 51100: 0.110993\n",
      "2023-12-05 23:29:33,010 INFO     Training average negative_sample_loss at step 51100: 0.085805\n",
      "2023-12-05 23:29:33,010 INFO     Training average loss at step 51100: 0.098399\n",
      "2023-12-05 23:29:38,164 INFO     Training average positive_sample_loss at step 51200: 0.109950\n",
      "2023-12-05 23:29:38,164 INFO     Training average negative_sample_loss at step 51200: 0.085888\n",
      "2023-12-05 23:29:38,164 INFO     Training average loss at step 51200: 0.097919\n",
      "2023-12-05 23:29:44,000 INFO     Training average positive_sample_loss at step 51300: 0.110836\n",
      "2023-12-05 23:29:44,000 INFO     Training average negative_sample_loss at step 51300: 0.085327\n",
      "2023-12-05 23:29:44,000 INFO     Training average loss at step 51300: 0.098081\n",
      "2023-12-05 23:29:49,796 INFO     Training average positive_sample_loss at step 51400: 0.109854\n",
      "2023-12-05 23:29:49,797 INFO     Training average negative_sample_loss at step 51400: 0.085523\n",
      "2023-12-05 23:29:49,797 INFO     Training average loss at step 51400: 0.097688\n",
      "2023-12-05 23:29:54,941 INFO     Training average positive_sample_loss at step 51500: 0.110076\n",
      "2023-12-05 23:29:54,941 INFO     Training average negative_sample_loss at step 51500: 0.084996\n",
      "2023-12-05 23:29:54,941 INFO     Training average loss at step 51500: 0.097536\n",
      "2023-12-05 23:30:00,428 INFO     Training average positive_sample_loss at step 51600: 0.110922\n",
      "2023-12-05 23:30:00,429 INFO     Training average negative_sample_loss at step 51600: 0.085072\n",
      "2023-12-05 23:30:00,429 INFO     Training average loss at step 51600: 0.097997\n",
      "2023-12-05 23:30:06,643 INFO     Training average positive_sample_loss at step 51700: 0.109665\n",
      "2023-12-05 23:30:06,643 INFO     Training average negative_sample_loss at step 51700: 0.085272\n",
      "2023-12-05 23:30:06,643 INFO     Training average loss at step 51700: 0.097469\n",
      "2023-12-05 23:30:11,844 INFO     Training average positive_sample_loss at step 51800: 0.110384\n",
      "2023-12-05 23:30:11,844 INFO     Training average negative_sample_loss at step 51800: 0.085475\n",
      "2023-12-05 23:30:11,844 INFO     Training average loss at step 51800: 0.097930\n",
      "2023-12-05 23:30:17,633 INFO     Training average positive_sample_loss at step 51900: 0.110372\n",
      "2023-12-05 23:30:17,634 INFO     Training average negative_sample_loss at step 51900: 0.086309\n",
      "2023-12-05 23:30:17,634 INFO     Training average loss at step 51900: 0.098340\n",
      "2023-12-05 23:30:22,779 INFO     Training average positive_sample_loss at step 52000: 0.109588\n",
      "2023-12-05 23:30:22,779 INFO     Training average negative_sample_loss at step 52000: 0.085160\n",
      "2023-12-05 23:30:22,779 INFO     Training average loss at step 52000: 0.097374\n",
      "2023-12-05 23:30:28,605 INFO     Training average positive_sample_loss at step 52100: 0.110951\n",
      "2023-12-05 23:30:28,605 INFO     Training average negative_sample_loss at step 52100: 0.084788\n",
      "2023-12-05 23:30:28,605 INFO     Training average loss at step 52100: 0.097870\n",
      "2023-12-05 23:32:03,199 INFO     Training average positive_sample_loss at step 53800: 0.109503\n",
      "2023-12-05 23:32:03,200 INFO     Training average negative_sample_loss at step 53800: 0.084394\n",
      "2023-12-05 23:32:03,200 INFO     Training average loss at step 53800: 0.096949\n",
      "2023-12-05 23:32:08,410 INFO     Training average positive_sample_loss at step 53900: 0.111091\n",
      "2023-12-05 23:32:08,411 INFO     Training average negative_sample_loss at step 53900: 0.084767\n",
      "2023-12-05 23:32:08,411 INFO     Training average loss at step 53900: 0.097929\n",
      "2023-12-05 23:32:14,318 INFO     Training average positive_sample_loss at step 54000: 0.109865\n",
      "2023-12-05 23:32:14,319 INFO     Training average negative_sample_loss at step 54000: 0.084091\n",
      "2023-12-05 23:32:14,319 INFO     Training average loss at step 54000: 0.096978\n",
      "2023-12-05 23:32:20,152 INFO     Training average positive_sample_loss at step 54100: 0.110091\n",
      "2023-12-05 23:32:20,153 INFO     Training average negative_sample_loss at step 54100: 0.084304\n",
      "2023-12-05 23:32:20,153 INFO     Training average loss at step 54100: 0.097197\n",
      "2023-12-05 23:32:25,890 INFO     Training average positive_sample_loss at step 54200: 0.110456\n",
      "2023-12-05 23:32:25,890 INFO     Training average negative_sample_loss at step 54200: 0.084557\n",
      "2023-12-05 23:32:25,890 INFO     Training average loss at step 54200: 0.097506\n",
      "2023-12-05 23:32:31,048 INFO     Training average positive_sample_loss at step 54300: 0.110209\n",
      "2023-12-05 23:32:31,048 INFO     Training average negative_sample_loss at step 54300: 0.084491\n",
      "2023-12-05 23:32:31,048 INFO     Training average loss at step 54300: 0.097350\n",
      "2023-12-05 23:32:36,205 INFO     Training average positive_sample_loss at step 54400: 0.110454\n",
      "2023-12-05 23:32:36,205 INFO     Training average negative_sample_loss at step 54400: 0.084332\n",
      "2023-12-05 23:32:36,205 INFO     Training average loss at step 54400: 0.097393\n",
      "2023-12-05 23:32:42,713 INFO     Training average positive_sample_loss at step 54500: 0.109526\n",
      "2023-12-05 23:32:42,713 INFO     Training average negative_sample_loss at step 54500: 0.084111\n",
      "2023-12-05 23:32:42,713 INFO     Training average loss at step 54500: 0.096819\n",
      "2023-12-05 23:32:47,898 INFO     Training average positive_sample_loss at step 54600: 0.109971\n",
      "2023-12-05 23:32:47,899 INFO     Training average negative_sample_loss at step 54600: 0.084166\n",
      "2023-12-05 23:32:47,899 INFO     Training average loss at step 54600: 0.097069\n",
      "2023-12-05 23:32:53,789 INFO     Training average positive_sample_loss at step 54700: 0.110944\n",
      "2023-12-05 23:32:53,789 INFO     Training average negative_sample_loss at step 54700: 0.084543\n",
      "2023-12-05 23:32:53,789 INFO     Training average loss at step 54700: 0.097744\n",
      "2023-12-05 23:32:59,577 INFO     Training average positive_sample_loss at step 54800: 0.109816\n",
      "2023-12-05 23:32:59,577 INFO     Training average negative_sample_loss at step 54800: 0.084579\n",
      "2023-12-05 23:32:59,577 INFO     Training average loss at step 54800: 0.097197\n",
      "2023-12-05 23:33:04,697 INFO     Training average positive_sample_loss at step 54900: 0.110276\n",
      "2023-12-05 23:33:04,697 INFO     Training average negative_sample_loss at step 54900: 0.084170\n",
      "2023-12-05 23:33:04,698 INFO     Training average loss at step 54900: 0.097223\n",
      "2023-12-05 23:33:10,476 INFO     Training average positive_sample_loss at step 55000: 0.110258\n",
      "2023-12-05 23:33:10,477 INFO     Training average negative_sample_loss at step 55000: 0.084780\n",
      "2023-12-05 23:33:10,477 INFO     Training average loss at step 55000: 0.097519\n",
      "2023-12-05 23:33:15,643 INFO     Training average positive_sample_loss at step 55100: 0.109860\n",
      "2023-12-05 23:33:15,643 INFO     Training average negative_sample_loss at step 55100: 0.084667\n",
      "2023-12-05 23:33:15,643 INFO     Training average loss at step 55100: 0.097263\n",
      "2023-12-05 23:33:21,488 INFO     Training average positive_sample_loss at step 55200: 0.110854\n",
      "2023-12-05 23:33:21,488 INFO     Training average negative_sample_loss at step 55200: 0.084635\n",
      "2023-12-05 23:33:21,488 INFO     Training average loss at step 55200: 0.097745\n",
      "2023-12-05 23:33:27,224 INFO     Training average positive_sample_loss at step 55300: 0.109441\n",
      "2023-12-05 23:33:27,225 INFO     Training average negative_sample_loss at step 55300: 0.084290\n",
      "2023-12-05 23:33:27,225 INFO     Training average loss at step 55300: 0.096865\n",
      "2023-12-05 23:33:32,374 INFO     Training average positive_sample_loss at step 55400: 0.110448\n",
      "2023-12-05 23:33:32,375 INFO     Training average negative_sample_loss at step 55400: 0.084374\n",
      "2023-12-05 23:33:32,375 INFO     Training average loss at step 55400: 0.097411\n",
      "2023-12-05 23:33:38,780 INFO     Training average positive_sample_loss at step 55500: 0.110542\n",
      "2023-12-05 23:33:38,780 INFO     Training average negative_sample_loss at step 55500: 0.084189\n",
      "2023-12-05 23:33:38,780 INFO     Training average loss at step 55500: 0.097366\n",
      "2023-12-05 23:33:43,947 INFO     Training average positive_sample_loss at step 55600: 0.109732\n",
      "2023-12-05 23:33:43,948 INFO     Training average negative_sample_loss at step 55600: 0.083661\n",
      "2023-12-05 23:33:43,948 INFO     Training average loss at step 55600: 0.096697\n",
      "2023-12-05 23:33:49,134 INFO     Training average positive_sample_loss at step 55700: 0.110370\n",
      "2023-12-05 23:33:49,134 INFO     Training average negative_sample_loss at step 55700: 0.084726\n",
      "2023-12-05 23:33:49,134 INFO     Training average loss at step 55700: 0.097548\n",
      "2023-12-05 23:33:55,035 INFO     Training average positive_sample_loss at step 55800: 0.109811\n",
      "2023-12-05 23:33:55,035 INFO     Training average negative_sample_loss at step 55800: 0.084107\n",
      "2023-12-05 23:33:55,035 INFO     Training average loss at step 55800: 0.096959\n",
      "2023-12-05 23:34:00,723 INFO     Training average positive_sample_loss at step 55900: 0.110201\n",
      "2023-12-05 23:34:00,723 INFO     Training average negative_sample_loss at step 55900: 0.084672\n",
      "2023-12-05 23:34:00,723 INFO     Training average loss at step 55900: 0.097436\n",
      "2023-12-05 23:34:06,566 INFO     Training average positive_sample_loss at step 56000: 0.110488\n",
      "2023-12-05 23:34:06,567 INFO     Training average negative_sample_loss at step 56000: 0.083808\n",
      "2023-12-05 23:34:06,567 INFO     Training average loss at step 56000: 0.097148\n",
      "2023-12-05 23:34:11,722 INFO     Training average positive_sample_loss at step 56100: 0.109168\n",
      "2023-12-05 23:34:11,722 INFO     Training average negative_sample_loss at step 56100: 0.084187\n",
      "2023-12-05 23:34:11,722 INFO     Training average loss at step 56100: 0.096677\n",
      "2023-12-05 23:34:17,014 INFO     Training average positive_sample_loss at step 56200: 0.110828\n",
      "2023-12-05 23:34:17,014 INFO     Training average negative_sample_loss at step 56200: 0.085278\n",
      "2023-12-05 23:34:17,014 INFO     Training average loss at step 56200: 0.098053\n",
      "2023-12-05 23:34:22,855 INFO     Training average positive_sample_loss at step 56300: 0.109954\n",
      "2023-12-05 23:34:22,855 INFO     Training average negative_sample_loss at step 56300: 0.084318\n",
      "2023-12-05 23:34:22,855 INFO     Training average loss at step 56300: 0.097136\n",
      "2023-12-05 23:34:28,547 INFO     Training average positive_sample_loss at step 56400: 0.109371\n",
      "2023-12-05 23:34:28,548 INFO     Training average negative_sample_loss at step 56400: 0.083655\n",
      "2023-12-05 23:34:28,548 INFO     Training average loss at step 56400: 0.096513\n",
      "2023-12-05 23:34:33,875 INFO     Training average positive_sample_loss at step 56500: 0.111362\n",
      "2023-12-05 23:34:33,876 INFO     Training average negative_sample_loss at step 56500: 0.084916\n",
      "2023-12-05 23:34:33,876 INFO     Training average loss at step 56500: 0.098139\n",
      "2023-12-05 23:34:39,671 INFO     Training average positive_sample_loss at step 56600: 0.109282\n",
      "2023-12-05 23:34:39,672 INFO     Training average negative_sample_loss at step 56600: 0.083869\n",
      "2023-12-05 23:34:39,672 INFO     Training average loss at step 56600: 0.096576\n",
      "2023-12-05 23:34:44,840 INFO     Training average positive_sample_loss at step 56700: 0.110673\n",
      "2023-12-05 23:34:44,841 INFO     Training average negative_sample_loss at step 56700: 0.084024\n",
      "2023-12-05 23:34:44,841 INFO     Training average loss at step 56700: 0.097348\n",
      "2023-12-05 23:34:51,139 INFO     Training average positive_sample_loss at step 56800: 0.109854\n",
      "2023-12-05 23:34:51,140 INFO     Training average negative_sample_loss at step 56800: 0.084894\n",
      "2023-12-05 23:34:51,140 INFO     Training average loss at step 56800: 0.097374\n",
      "2023-12-05 23:34:56,439 INFO     Training average positive_sample_loss at step 56900: 0.110282\n",
      "2023-12-05 23:34:56,439 INFO     Training average negative_sample_loss at step 56900: 0.083840\n",
      "2023-12-05 23:34:56,439 INFO     Training average loss at step 56900: 0.097061\n",
      "2023-12-05 23:35:01,613 INFO     Training average positive_sample_loss at step 57000: 0.110201\n",
      "2023-12-05 23:35:01,614 INFO     Training average negative_sample_loss at step 57000: 0.084053\n",
      "2023-12-05 23:35:01,614 INFO     Training average loss at step 57000: 0.097127\n",
      "2023-12-05 23:35:07,884 INFO     Training average positive_sample_loss at step 57100: 0.109388\n",
      "2023-12-05 23:35:07,884 INFO     Training average negative_sample_loss at step 57100: 0.084099\n",
      "2023-12-05 23:35:07,884 INFO     Training average loss at step 57100: 0.096744\n",
      "2023-12-05 23:35:13,176 INFO     Training average positive_sample_loss at step 57200: 0.109940\n",
      "2023-12-05 23:35:13,177 INFO     Training average negative_sample_loss at step 57200: 0.084741\n",
      "2023-12-05 23:35:13,177 INFO     Training average loss at step 57200: 0.097341\n",
      "2023-12-05 23:35:18,960 INFO     Training average positive_sample_loss at step 57300: 0.110659\n",
      "2023-12-05 23:35:18,960 INFO     Training average negative_sample_loss at step 57300: 0.084610\n",
      "2023-12-05 23:35:18,960 INFO     Training average loss at step 57300: 0.097635\n",
      "2023-12-05 23:35:24,636 INFO     Training average positive_sample_loss at step 57400: 0.109188\n",
      "2023-12-05 23:35:24,636 INFO     Training average negative_sample_loss at step 57400: 0.083803\n",
      "2023-12-05 23:35:24,636 INFO     Training average loss at step 57400: 0.096495\n",
      "2023-12-05 23:35:29,779 INFO     Training average positive_sample_loss at step 57500: 0.111007\n",
      "2023-12-05 23:35:29,780 INFO     Training average negative_sample_loss at step 57500: 0.084261\n",
      "2023-12-05 23:35:29,780 INFO     Training average loss at step 57500: 0.097634\n",
      "2023-12-05 23:35:35,660 INFO     Training average positive_sample_loss at step 57600: 0.109941\n",
      "2023-12-05 23:35:35,660 INFO     Training average negative_sample_loss at step 57600: 0.084334\n",
      "2023-12-05 23:35:35,660 INFO     Training average loss at step 57600: 0.097138\n",
      "2023-12-05 23:35:41,339 INFO     Training average positive_sample_loss at step 57700: 0.110231\n",
      "2023-12-05 23:35:41,339 INFO     Training average negative_sample_loss at step 57700: 0.083895\n",
      "2023-12-05 23:35:41,339 INFO     Training average loss at step 57700: 0.097063\n",
      "2023-12-05 23:35:47,050 INFO     Training average positive_sample_loss at step 57800: 0.110586\n",
      "2023-12-05 23:35:47,050 INFO     Training average negative_sample_loss at step 57800: 0.084459\n",
      "2023-12-05 23:35:47,050 INFO     Training average loss at step 57800: 0.097522\n",
      "2023-12-05 23:35:52,190 INFO     Training average positive_sample_loss at step 57900: 0.109973\n",
      "2023-12-05 23:35:52,190 INFO     Training average negative_sample_loss at step 57900: 0.083820\n",
      "2023-12-05 23:35:52,191 INFO     Training average loss at step 57900: 0.096897\n",
      "2023-12-05 23:35:57,447 INFO     Training average positive_sample_loss at step 58000: 0.110199\n",
      "2023-12-05 23:35:57,447 INFO     Training average negative_sample_loss at step 58000: 0.083720\n",
      "2023-12-05 23:35:57,447 INFO     Training average loss at step 58000: 0.096959\n",
      "2023-12-05 23:36:03,768 INFO     Training average positive_sample_loss at step 58100: 0.109476\n",
      "2023-12-05 23:36:03,769 INFO     Training average negative_sample_loss at step 58100: 0.083956\n",
      "2023-12-05 23:36:03,769 INFO     Training average loss at step 58100: 0.096716\n",
      "2023-12-05 23:36:08,900 INFO     Training average positive_sample_loss at step 58200: 0.109931\n",
      "2023-12-05 23:36:08,900 INFO     Training average negative_sample_loss at step 58200: 0.083956\n",
      "2023-12-05 23:36:08,900 INFO     Training average loss at step 58200: 0.096943\n",
      "2023-12-05 23:36:14,066 INFO     Training average positive_sample_loss at step 58300: 0.110752\n",
      "2023-12-05 23:36:14,066 INFO     Training average negative_sample_loss at step 58300: 0.084282\n",
      "2023-12-05 23:36:14,066 INFO     Training average loss at step 58300: 0.097517\n",
      "2023-12-05 23:36:20,489 INFO     Training average positive_sample_loss at step 58400: 0.109568\n",
      "2023-12-05 23:36:20,490 INFO     Training average negative_sample_loss at step 58400: 0.084480\n",
      "2023-12-05 23:36:20,490 INFO     Training average loss at step 58400: 0.097024\n",
      "2023-12-05 23:36:25,623 INFO     Training average positive_sample_loss at step 58500: 0.110596\n",
      "2023-12-05 23:36:25,623 INFO     Training average negative_sample_loss at step 58500: 0.084283\n",
      "2023-12-05 23:36:25,623 INFO     Training average loss at step 58500: 0.097440\n",
      "2023-12-05 23:36:31,413 INFO     Training average positive_sample_loss at step 58600: 0.109801\n",
      "2023-12-05 23:36:31,413 INFO     Training average negative_sample_loss at step 58600: 0.083543\n",
      "2023-12-05 23:36:31,413 INFO     Training average loss at step 58600: 0.096672\n",
      "2023-12-05 23:36:36,626 INFO     Training average positive_sample_loss at step 58700: 0.109634\n",
      "2023-12-05 23:36:36,627 INFO     Training average negative_sample_loss at step 58700: 0.084275\n",
      "2023-12-05 23:36:36,627 INFO     Training average loss at step 58700: 0.096955\n",
      "2023-12-05 23:36:42,514 INFO     Training average positive_sample_loss at step 58800: 0.110400\n",
      "2023-12-05 23:36:42,514 INFO     Training average negative_sample_loss at step 58800: 0.084167\n",
      "2023-12-05 23:36:42,514 INFO     Training average loss at step 58800: 0.097283\n",
      "2023-12-05 23:36:48,341 INFO     Training average positive_sample_loss at step 58900: 0.109909\n",
      "2023-12-05 23:36:48,341 INFO     Training average negative_sample_loss at step 58900: 0.084057\n",
      "2023-12-05 23:36:48,341 INFO     Training average loss at step 58900: 0.096983\n",
      "2023-12-05 23:36:53,495 INFO     Training average positive_sample_loss at step 59000: 0.110034\n",
      "2023-12-05 23:36:53,495 INFO     Training average negative_sample_loss at step 59000: 0.083785\n",
      "2023-12-05 23:36:53,495 INFO     Training average loss at step 59000: 0.096909\n",
      "2023-12-05 23:36:59,184 INFO     Training average positive_sample_loss at step 59100: 0.110187\n",
      "2023-12-05 23:36:59,184 INFO     Training average negative_sample_loss at step 59100: 0.084086\n",
      "2023-12-05 23:36:59,184 INFO     Training average loss at step 59100: 0.097137\n",
      "2023-12-05 23:37:04,543 INFO     Training average positive_sample_loss at step 59200: 0.109518\n",
      "2023-12-05 23:37:04,544 INFO     Training average negative_sample_loss at step 59200: 0.084108\n",
      "2023-12-05 23:37:04,544 INFO     Training average loss at step 59200: 0.096813\n",
      "2023-12-05 23:37:10,261 INFO     Training average positive_sample_loss at step 59300: 0.110327\n",
      "2023-12-05 23:37:10,261 INFO     Training average negative_sample_loss at step 59300: 0.084372\n",
      "2023-12-05 23:37:10,261 INFO     Training average loss at step 59300: 0.097349\n",
      "2023-12-05 23:37:16,128 INFO     Training average positive_sample_loss at step 59400: 0.110185\n",
      "2023-12-05 23:37:16,128 INFO     Training average negative_sample_loss at step 59400: 0.084457\n",
      "2023-12-05 23:37:16,128 INFO     Training average loss at step 59400: 0.097321\n",
      "2023-12-05 23:37:21,282 INFO     Training average positive_sample_loss at step 59500: 0.110051\n",
      "2023-12-05 23:37:21,282 INFO     Training average negative_sample_loss at step 59500: 0.084157\n",
      "2023-12-05 23:37:21,282 INFO     Training average loss at step 59500: 0.097104\n",
      "2023-12-05 23:37:27,225 INFO     Training average positive_sample_loss at step 59600: 0.110665\n",
      "2023-12-05 23:37:27,225 INFO     Training average negative_sample_loss at step 59600: 0.083918\n",
      "2023-12-05 23:37:27,225 INFO     Training average loss at step 59600: 0.097291\n",
      "2023-12-05 23:37:32,934 INFO     Training average positive_sample_loss at step 59700: 0.109711\n",
      "2023-12-05 23:37:32,934 INFO     Training average negative_sample_loss at step 59700: 0.084373\n",
      "2023-12-05 23:37:32,934 INFO     Training average loss at step 59700: 0.097042\n",
      "2023-12-05 23:37:38,079 INFO     Training average positive_sample_loss at step 59800: 0.110114\n",
      "2023-12-05 23:37:38,080 INFO     Training average negative_sample_loss at step 59800: 0.084219\n",
      "2023-12-05 23:37:38,080 INFO     Training average loss at step 59800: 0.097167\n",
      "2023-12-05 23:37:43,910 INFO     Training average positive_sample_loss at step 59900: 0.109855\n",
      "2023-12-05 23:37:43,910 INFO     Training average negative_sample_loss at step 59900: 0.084299\n",
      "2023-12-05 23:37:43,910 INFO     Training average loss at step 59900: 0.097077\n",
      "2023-12-05 23:38:00,967 INFO     Training average positive_sample_loss at step 60000: 0.109753\n",
      "2023-12-05 23:38:00,968 INFO     Training average negative_sample_loss at step 60000: 0.083771\n",
      "2023-12-05 23:38:00,968 INFO     Training average loss at step 60000: 0.096762\n",
      "2023-12-05 23:38:00,968 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 23:38:01,436 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 23:38:26,825 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 23:38:43,509 INFO     Valid MRR at step 60000: 0.574870\n",
      "2023-12-05 23:38:43,509 INFO     Valid MR at step 60000: 265.504809\n",
      "2023-12-05 23:38:43,509 INFO     Valid HITS@1 at step 60000: 0.507811\n",
      "2023-12-05 23:38:43,509 INFO     Valid HITS@3 at step 60000: 0.599939\n",
      "2023-12-05 23:38:43,510 INFO     Valid HITS@10 at step 60000: 0.706904\n",
      "2023-12-05 23:38:48,687 INFO     Training average positive_sample_loss at step 60100: 0.110612\n",
      "2023-12-05 23:38:48,687 INFO     Training average negative_sample_loss at step 60100: 0.084535\n",
      "2023-12-05 23:38:48,687 INFO     Training average loss at step 60100: 0.097573\n",
      "2023-12-05 23:38:54,520 INFO     Training average positive_sample_loss at step 60200: 0.109472\n",
      "2023-12-05 23:38:54,520 INFO     Training average negative_sample_loss at step 60200: 0.084286\n",
      "2023-12-05 23:38:54,520 INFO     Training average loss at step 60200: 0.096879\n",
      "2023-12-05 23:38:59,708 INFO     Training average positive_sample_loss at step 60300: 0.110394\n",
      "2023-12-05 23:38:59,708 INFO     Training average negative_sample_loss at step 60300: 0.083822\n",
      "2023-12-05 23:38:59,709 INFO     Training average loss at step 60300: 0.097108\n",
      "2023-12-05 23:39:05,501 INFO     Training average positive_sample_loss at step 60400: 0.110163\n",
      "2023-12-05 23:39:05,502 INFO     Training average negative_sample_loss at step 60400: 0.084054\n",
      "2023-12-05 23:39:05,502 INFO     Training average loss at step 60400: 0.097109\n",
      "2023-12-05 23:39:10,744 INFO     Training average positive_sample_loss at step 60500: 0.109551\n",
      "2023-12-05 23:39:10,744 INFO     Training average negative_sample_loss at step 60500: 0.083548\n",
      "2023-12-05 23:39:10,744 INFO     Training average loss at step 60500: 0.096549\n",
      "2023-12-05 23:39:16,493 INFO     Training average positive_sample_loss at step 60600: 0.110317\n",
      "2023-12-05 23:39:16,493 INFO     Training average negative_sample_loss at step 60600: 0.084909\n",
      "2023-12-05 23:39:16,493 INFO     Training average loss at step 60600: 0.097613\n",
      "2023-12-05 23:39:22,328 INFO     Training average positive_sample_loss at step 60700: 0.109932\n",
      "2023-12-05 23:39:22,328 INFO     Training average negative_sample_loss at step 60700: 0.084321\n",
      "2023-12-05 23:39:22,328 INFO     Training average loss at step 60700: 0.097126\n",
      "2023-12-05 23:39:27,495 INFO     Training average positive_sample_loss at step 60800: 0.109954\n",
      "2023-12-05 23:39:27,495 INFO     Training average negative_sample_loss at step 60800: 0.084885\n",
      "2023-12-05 23:39:27,495 INFO     Training average loss at step 60800: 0.097419\n",
      "2023-12-05 23:39:33,304 INFO     Training average positive_sample_loss at step 60900: 0.110533\n",
      "2023-12-05 23:39:33,304 INFO     Training average negative_sample_loss at step 60900: 0.084558\n",
      "2023-12-05 23:39:33,304 INFO     Training average loss at step 60900: 0.097546\n",
      "2023-12-05 23:39:38,461 INFO     Training average positive_sample_loss at step 61000: 0.109859\n",
      "2023-12-05 23:39:38,461 INFO     Training average negative_sample_loss at step 61000: 0.083971\n",
      "2023-12-05 23:39:38,461 INFO     Training average loss at step 61000: 0.096915\n",
      "2023-12-05 23:39:43,620 INFO     Training average positive_sample_loss at step 61100: 0.110236\n",
      "2023-12-05 23:39:43,620 INFO     Training average negative_sample_loss at step 61100: 0.083669\n",
      "2023-12-05 23:39:43,620 INFO     Training average loss at step 61100: 0.096952\n",
      "2023-12-05 23:39:49,537 INFO     Training average positive_sample_loss at step 61200: 0.109732\n",
      "2023-12-05 23:39:49,537 INFO     Training average negative_sample_loss at step 61200: 0.084017\n",
      "2023-12-05 23:39:49,537 INFO     Training average loss at step 61200: 0.096874\n",
      "2023-12-05 23:39:54,687 INFO     Training average positive_sample_loss at step 61300: 0.109777\n",
      "2023-12-05 23:39:54,687 INFO     Training average negative_sample_loss at step 61300: 0.084404\n",
      "2023-12-05 23:39:54,687 INFO     Training average loss at step 61300: 0.097091\n",
      "2023-12-05 23:39:59,851 INFO     Training average positive_sample_loss at step 61400: 0.110802\n",
      "2023-12-05 23:39:59,851 INFO     Training average negative_sample_loss at step 61400: 0.084038\n",
      "2023-12-05 23:39:59,851 INFO     Training average loss at step 61400: 0.097420\n",
      "2023-12-05 23:40:05,612 INFO     Training average positive_sample_loss at step 61500: 0.109176\n",
      "2023-12-05 23:40:05,612 INFO     Training average negative_sample_loss at step 61500: 0.083891\n",
      "2023-12-05 23:40:05,612 INFO     Training average loss at step 61500: 0.096533\n",
      "2023-12-05 23:40:11,333 INFO     Training average positive_sample_loss at step 61600: 0.110318\n",
      "2023-12-05 23:40:11,333 INFO     Training average negative_sample_loss at step 61600: 0.083995\n",
      "2023-12-05 23:40:11,333 INFO     Training average loss at step 61600: 0.097157\n",
      "2023-12-05 23:40:17,212 INFO     Training average positive_sample_loss at step 61700: 0.109938\n",
      "2023-12-05 23:40:17,212 INFO     Training average negative_sample_loss at step 61700: 0.083519\n",
      "2023-12-05 23:40:17,212 INFO     Training average loss at step 61700: 0.096729\n",
      "2023-12-05 23:40:22,348 INFO     Training average positive_sample_loss at step 61800: 0.109136\n",
      "2023-12-05 23:40:22,348 INFO     Training average negative_sample_loss at step 61800: 0.083599\n",
      "2023-12-05 23:40:22,348 INFO     Training average loss at step 61800: 0.096368\n",
      "2023-12-05 23:40:27,502 INFO     Training average positive_sample_loss at step 61900: 0.111036\n",
      "2023-12-05 23:40:27,503 INFO     Training average negative_sample_loss at step 61900: 0.084097\n",
      "2023-12-05 23:40:27,503 INFO     Training average loss at step 61900: 0.097566\n",
      "2023-12-05 23:40:33,808 INFO     Training average positive_sample_loss at step 62000: 0.109319\n",
      "2023-12-05 23:40:33,808 INFO     Training average negative_sample_loss at step 62000: 0.083908\n",
      "2023-12-05 23:40:33,808 INFO     Training average loss at step 62000: 0.096614\n",
      "2023-12-05 23:40:39,092 INFO     Training average positive_sample_loss at step 62100: 0.110446\n",
      "2023-12-05 23:40:39,093 INFO     Training average negative_sample_loss at step 62100: 0.083588\n",
      "2023-12-05 23:40:39,093 INFO     Training average loss at step 62100: 0.097017\n",
      "2023-12-05 23:40:44,860 INFO     Training average positive_sample_loss at step 62200: 0.109917\n",
      "2023-12-05 23:40:44,861 INFO     Training average negative_sample_loss at step 62200: 0.084411\n",
      "2023-12-05 23:40:44,861 INFO     Training average loss at step 62200: 0.097164\n",
      "2023-12-05 23:40:49,973 INFO     Training average positive_sample_loss at step 62300: 0.109279\n",
      "2023-12-05 23:40:49,973 INFO     Training average negative_sample_loss at step 62300: 0.084064\n",
      "2023-12-05 23:40:49,973 INFO     Training average loss at step 62300: 0.096671\n",
      "2023-12-05 23:40:55,549 INFO     Training average positive_sample_loss at step 62400: 0.110834\n",
      "2023-12-05 23:40:55,550 INFO     Training average negative_sample_loss at step 62400: 0.084716\n",
      "2023-12-05 23:40:55,550 INFO     Training average loss at step 62400: 0.097775\n",
      "2023-12-05 23:41:01,496 INFO     Training average positive_sample_loss at step 62500: 0.109533\n",
      "2023-12-05 23:41:01,497 INFO     Training average negative_sample_loss at step 62500: 0.084029\n",
      "2023-12-05 23:41:01,497 INFO     Training average loss at step 62500: 0.096781\n",
      "2023-12-05 23:41:06,612 INFO     Training average positive_sample_loss at step 62600: 0.109657\n",
      "2023-12-05 23:41:06,612 INFO     Training average negative_sample_loss at step 62600: 0.083769\n",
      "2023-12-05 23:41:06,612 INFO     Training average loss at step 62600: 0.096713\n",
      "2023-12-05 23:41:12,461 INFO     Training average positive_sample_loss at step 62700: 0.110947\n",
      "2023-12-05 23:41:12,461 INFO     Training average negative_sample_loss at step 62700: 0.084205\n",
      "2023-12-05 23:41:12,462 INFO     Training average loss at step 62700: 0.097576\n",
      "2023-12-05 23:41:18,265 INFO     Training average positive_sample_loss at step 62800: 0.109086\n",
      "2023-12-05 23:41:18,265 INFO     Training average negative_sample_loss at step 62800: 0.083944\n",
      "2023-12-05 23:41:18,265 INFO     Training average loss at step 62800: 0.096515\n",
      "2023-12-05 23:41:23,357 INFO     Training average positive_sample_loss at step 62900: 0.110089\n",
      "2023-12-05 23:41:23,357 INFO     Training average negative_sample_loss at step 62900: 0.084088\n",
      "2023-12-05 23:41:23,357 INFO     Training average loss at step 62900: 0.097089\n",
      "2023-12-05 23:41:29,134 INFO     Training average positive_sample_loss at step 63000: 0.110043\n",
      "2023-12-05 23:41:29,134 INFO     Training average negative_sample_loss at step 63000: 0.083054\n",
      "2023-12-05 23:41:29,134 INFO     Training average loss at step 63000: 0.096549\n",
      "2023-12-05 23:41:34,956 INFO     Training average positive_sample_loss at step 63100: 0.109389\n",
      "2023-12-05 23:41:34,956 INFO     Training average negative_sample_loss at step 63100: 0.084668\n",
      "2023-12-05 23:41:34,957 INFO     Training average loss at step 63100: 0.097029\n",
      "2023-12-05 23:41:40,110 INFO     Training average positive_sample_loss at step 63200: 0.110980\n",
      "2023-12-05 23:41:40,110 INFO     Training average negative_sample_loss at step 63200: 0.084116\n",
      "2023-12-05 23:41:40,110 INFO     Training average loss at step 63200: 0.097548\n",
      "2023-12-05 23:41:45,774 INFO     Training average positive_sample_loss at step 63300: 0.109176\n",
      "2023-12-05 23:41:45,775 INFO     Training average negative_sample_loss at step 63300: 0.084376\n",
      "2023-12-05 23:41:45,775 INFO     Training average loss at step 63300: 0.096776\n",
      "2023-12-05 23:41:50,922 INFO     Training average positive_sample_loss at step 63400: 0.110472\n",
      "2023-12-05 23:41:50,922 INFO     Training average negative_sample_loss at step 63400: 0.083813\n",
      "2023-12-05 23:41:50,922 INFO     Training average loss at step 63400: 0.097142\n",
      "2023-12-05 23:41:57,349 INFO     Training average positive_sample_loss at step 63500: 0.110015\n",
      "2023-12-05 23:41:57,349 INFO     Training average negative_sample_loss at step 63500: 0.083785\n",
      "2023-12-05 23:41:57,349 INFO     Training average loss at step 63500: 0.096900\n",
      "2023-12-05 23:42:02,495 INFO     Training average positive_sample_loss at step 63600: 0.110159\n",
      "2023-12-05 23:42:02,495 INFO     Training average negative_sample_loss at step 63600: 0.084505\n",
      "2023-12-05 23:42:02,495 INFO     Training average loss at step 63600: 0.097332\n",
      "2023-12-05 23:42:07,634 INFO     Training average positive_sample_loss at step 63700: 0.109911\n",
      "2023-12-05 23:42:07,634 INFO     Training average negative_sample_loss at step 63700: 0.083399\n",
      "2023-12-05 23:42:07,634 INFO     Training average loss at step 63700: 0.096655\n",
      "2023-12-05 23:42:13,347 INFO     Training average positive_sample_loss at step 63800: 0.109606\n",
      "2023-12-05 23:42:13,348 INFO     Training average negative_sample_loss at step 63800: 0.083499\n",
      "2023-12-05 23:42:13,348 INFO     Training average loss at step 63800: 0.096553\n",
      "2023-12-05 23:42:19,175 INFO     Training average positive_sample_loss at step 63900: 0.109965\n",
      "2023-12-05 23:42:19,176 INFO     Training average negative_sample_loss at step 63900: 0.083860\n",
      "2023-12-05 23:42:19,176 INFO     Training average loss at step 63900: 0.096912\n",
      "2023-12-05 23:42:24,943 INFO     Training average positive_sample_loss at step 64000: 0.109792\n",
      "2023-12-05 23:42:24,944 INFO     Training average negative_sample_loss at step 64000: 0.084003\n",
      "2023-12-05 23:42:24,944 INFO     Training average loss at step 64000: 0.096897\n",
      "2023-12-05 23:42:30,074 INFO     Training average positive_sample_loss at step 64100: 0.109677\n",
      "2023-12-05 23:42:30,074 INFO     Training average negative_sample_loss at step 64100: 0.083628\n",
      "2023-12-05 23:42:30,074 INFO     Training average loss at step 64100: 0.096652\n",
      "2023-12-05 23:42:35,202 INFO     Training average positive_sample_loss at step 64200: 0.110298\n",
      "2023-12-05 23:42:35,202 INFO     Training average negative_sample_loss at step 64200: 0.083895\n",
      "2023-12-05 23:42:35,202 INFO     Training average loss at step 64200: 0.097096\n",
      "2023-12-05 23:42:41,719 INFO     Training average positive_sample_loss at step 64300: 0.109389\n",
      "2023-12-05 23:42:41,720 INFO     Training average negative_sample_loss at step 64300: 0.084023\n",
      "2023-12-05 23:42:41,720 INFO     Training average loss at step 64300: 0.096706\n",
      "2023-12-05 23:42:46,930 INFO     Training average positive_sample_loss at step 64400: 0.109525\n",
      "2023-12-05 23:42:46,930 INFO     Training average negative_sample_loss at step 64400: 0.084118\n",
      "2023-12-05 23:42:46,930 INFO     Training average loss at step 64400: 0.096822\n",
      "2023-12-05 23:42:52,403 INFO     Training average positive_sample_loss at step 64500: 0.110837\n",
      "2023-12-05 23:42:52,403 INFO     Training average negative_sample_loss at step 64500: 0.083808\n",
      "2023-12-05 23:42:52,403 INFO     Training average loss at step 64500: 0.097323\n",
      "2023-12-05 23:42:57,910 INFO     Training average positive_sample_loss at step 64600: 0.109151\n",
      "2023-12-05 23:42:57,910 INFO     Training average negative_sample_loss at step 64600: 0.083671\n",
      "2023-12-05 23:42:57,910 INFO     Training average loss at step 64600: 0.096411\n",
      "2023-12-05 23:43:03,746 INFO     Training average positive_sample_loss at step 64700: 0.110009\n",
      "2023-12-05 23:43:03,747 INFO     Training average negative_sample_loss at step 64700: 0.084148\n",
      "2023-12-05 23:43:03,747 INFO     Training average loss at step 64700: 0.097079\n",
      "2023-12-05 23:43:09,508 INFO     Training average positive_sample_loss at step 64800: 0.110330\n",
      "2023-12-05 23:43:09,508 INFO     Training average negative_sample_loss at step 64800: 0.084021\n",
      "2023-12-05 23:43:09,508 INFO     Training average loss at step 64800: 0.097175\n",
      "2023-12-05 23:43:14,679 INFO     Training average positive_sample_loss at step 64900: 0.109904\n",
      "2023-12-05 23:43:14,680 INFO     Training average negative_sample_loss at step 64900: 0.084267\n",
      "2023-12-05 23:43:14,680 INFO     Training average loss at step 64900: 0.097085\n",
      "2023-12-05 23:43:20,522 INFO     Training average positive_sample_loss at step 65000: 0.110212\n",
      "2023-12-05 23:43:20,522 INFO     Training average negative_sample_loss at step 65000: 0.083804\n",
      "2023-12-05 23:43:20,522 INFO     Training average loss at step 65000: 0.097008\n",
      "2023-12-05 23:43:26,353 INFO     Training average positive_sample_loss at step 65100: 0.109567\n",
      "2023-12-05 23:43:26,353 INFO     Training average negative_sample_loss at step 65100: 0.083485\n",
      "2023-12-05 23:43:26,353 INFO     Training average loss at step 65100: 0.096526\n",
      "2023-12-05 23:43:31,494 INFO     Training average positive_sample_loss at step 65200: 0.109910\n",
      "2023-12-05 23:43:31,494 INFO     Training average negative_sample_loss at step 65200: 0.084284\n",
      "2023-12-05 23:43:31,494 INFO     Training average loss at step 65200: 0.097097\n",
      "2023-12-05 23:43:37,639 INFO     Training average positive_sample_loss at step 65300: 0.110054\n",
      "2023-12-05 23:43:37,639 INFO     Training average negative_sample_loss at step 65300: 0.084715\n",
      "2023-12-05 23:43:37,639 INFO     Training average loss at step 65300: 0.097384\n",
      "2023-12-05 23:43:43,019 INFO     Training average positive_sample_loss at step 65400: 0.109313\n",
      "2023-12-05 23:43:43,020 INFO     Training average negative_sample_loss at step 65400: 0.083574\n",
      "2023-12-05 23:43:43,020 INFO     Training average loss at step 65400: 0.096444\n",
      "2023-12-05 23:43:48,185 INFO     Training average positive_sample_loss at step 65500: 0.110037\n",
      "2023-12-05 23:43:48,185 INFO     Training average negative_sample_loss at step 65500: 0.083679\n",
      "2023-12-05 23:43:48,185 INFO     Training average loss at step 65500: 0.096858\n",
      "2023-12-05 23:43:53,938 INFO     Training average positive_sample_loss at step 65600: 0.109784\n",
      "2023-12-05 23:43:53,938 INFO     Training average negative_sample_loss at step 65600: 0.083737\n",
      "2023-12-05 23:43:53,938 INFO     Training average loss at step 65600: 0.096761\n",
      "2023-12-05 23:43:59,800 INFO     Training average positive_sample_loss at step 65700: 0.110444\n",
      "2023-12-05 23:43:59,800 INFO     Training average negative_sample_loss at step 65700: 0.084335\n",
      "2023-12-05 23:43:59,800 INFO     Training average loss at step 65700: 0.097389\n",
      "2023-12-05 23:44:05,697 INFO     Training average positive_sample_loss at step 65800: 0.110227\n",
      "2023-12-05 23:44:05,697 INFO     Training average negative_sample_loss at step 65800: 0.083969\n",
      "2023-12-05 23:44:05,697 INFO     Training average loss at step 65800: 0.097098\n",
      "2023-12-05 23:44:10,854 INFO     Training average positive_sample_loss at step 65900: 0.109310\n",
      "2023-12-05 23:44:10,855 INFO     Training average negative_sample_loss at step 65900: 0.084212\n",
      "2023-12-05 23:44:10,855 INFO     Training average loss at step 65900: 0.096761\n",
      "2023-12-05 23:44:16,662 INFO     Training average positive_sample_loss at step 66000: 0.110161\n",
      "2023-12-05 23:44:16,663 INFO     Training average negative_sample_loss at step 66000: 0.083600\n",
      "2023-12-05 23:44:16,663 INFO     Training average loss at step 66000: 0.096881\n",
      "2023-12-05 23:44:22,452 INFO     Training average positive_sample_loss at step 66100: 0.109469\n",
      "2023-12-05 23:44:22,452 INFO     Training average negative_sample_loss at step 66100: 0.083978\n",
      "2023-12-05 23:44:22,452 INFO     Training average loss at step 66100: 0.096723\n",
      "2023-12-05 23:44:27,630 INFO     Training average positive_sample_loss at step 66200: 0.109750\n",
      "2023-12-05 23:44:27,631 INFO     Training average negative_sample_loss at step 66200: 0.084142\n",
      "2023-12-05 23:44:27,631 INFO     Training average loss at step 66200: 0.096946\n",
      "2023-12-05 23:44:33,451 INFO     Training average positive_sample_loss at step 66300: 0.110645\n",
      "2023-12-05 23:44:33,452 INFO     Training average negative_sample_loss at step 66300: 0.083578\n",
      "2023-12-05 23:44:33,452 INFO     Training average loss at step 66300: 0.097111\n",
      "2023-12-05 23:44:39,159 INFO     Training average positive_sample_loss at step 66400: 0.108982\n",
      "2023-12-05 23:44:39,159 INFO     Training average negative_sample_loss at step 66400: 0.083872\n",
      "2023-12-05 23:44:39,159 INFO     Training average loss at step 66400: 0.096427\n",
      "2023-12-05 23:44:44,290 INFO     Training average positive_sample_loss at step 66500: 0.110174\n",
      "2023-12-05 23:44:44,291 INFO     Training average negative_sample_loss at step 66500: 0.084599\n",
      "2023-12-05 23:44:44,291 INFO     Training average loss at step 66500: 0.097386\n",
      "2023-12-05 23:44:50,087 INFO     Training average positive_sample_loss at step 66600: 0.109885\n",
      "2023-12-05 23:44:50,088 INFO     Training average negative_sample_loss at step 66600: 0.084085\n",
      "2023-12-05 23:44:50,088 INFO     Training average loss at step 66600: 0.096985\n",
      "2023-12-05 23:44:55,822 INFO     Training average positive_sample_loss at step 66700: 0.109571\n",
      "2023-12-05 23:44:55,823 INFO     Training average negative_sample_loss at step 66700: 0.083109\n",
      "2023-12-05 23:44:55,823 INFO     Training average loss at step 66700: 0.096340\n",
      "2023-12-05 23:45:00,981 INFO     Training average positive_sample_loss at step 66800: 0.110678\n",
      "2023-12-05 23:45:00,981 INFO     Training average negative_sample_loss at step 66800: 0.084364\n",
      "2023-12-05 23:45:00,981 INFO     Training average loss at step 66800: 0.097521\n",
      "2023-12-05 23:45:06,811 INFO     Training average positive_sample_loss at step 66900: 0.109505\n",
      "2023-12-05 23:45:06,812 INFO     Training average negative_sample_loss at step 66900: 0.084126\n",
      "2023-12-05 23:45:06,812 INFO     Training average loss at step 66900: 0.096815\n",
      "2023-12-05 23:45:12,614 INFO     Training average positive_sample_loss at step 67000: 0.109968\n",
      "2023-12-05 23:45:12,614 INFO     Training average negative_sample_loss at step 67000: 0.083319\n",
      "2023-12-05 23:45:12,614 INFO     Training average loss at step 67000: 0.096644\n",
      "2023-12-05 23:45:18,346 INFO     Training average positive_sample_loss at step 67100: 0.110134\n",
      "2023-12-05 23:45:18,346 INFO     Training average negative_sample_loss at step 67100: 0.084678\n",
      "2023-12-05 23:45:18,346 INFO     Training average loss at step 67100: 0.097406\n",
      "2023-12-05 23:45:23,513 INFO     Training average positive_sample_loss at step 67200: 0.109123\n",
      "2023-12-05 23:45:23,513 INFO     Training average negative_sample_loss at step 67200: 0.083289\n",
      "2023-12-05 23:45:23,514 INFO     Training average loss at step 67200: 0.096206\n",
      "2023-12-05 23:45:29,349 INFO     Training average positive_sample_loss at step 67300: 0.110675\n",
      "2023-12-05 23:45:29,349 INFO     Training average negative_sample_loss at step 67300: 0.084357\n",
      "2023-12-05 23:45:29,349 INFO     Training average loss at step 67300: 0.097516\n",
      "2023-12-05 23:45:35,117 INFO     Training average positive_sample_loss at step 67400: 0.109152\n",
      "2023-12-05 23:45:35,117 INFO     Training average negative_sample_loss at step 67400: 0.083803\n",
      "2023-12-05 23:45:35,118 INFO     Training average loss at step 67400: 0.096477\n",
      "2023-12-05 23:45:40,265 INFO     Training average positive_sample_loss at step 67500: 0.110011\n",
      "2023-12-05 23:45:40,265 INFO     Training average negative_sample_loss at step 67500: 0.084701\n",
      "2023-12-05 23:45:40,266 INFO     Training average loss at step 67500: 0.097356\n",
      "2023-12-05 23:45:45,995 INFO     Training average positive_sample_loss at step 67600: 0.110395\n",
      "2023-12-05 23:45:45,995 INFO     Training average negative_sample_loss at step 67600: 0.083479\n",
      "2023-12-05 23:45:45,995 INFO     Training average loss at step 67600: 0.096937\n",
      "2023-12-05 23:45:51,826 INFO     Training average positive_sample_loss at step 67700: 0.109333\n",
      "2023-12-05 23:45:51,826 INFO     Training average negative_sample_loss at step 67700: 0.083536\n",
      "2023-12-05 23:45:51,826 INFO     Training average loss at step 67700: 0.096435\n",
      "2023-12-05 23:45:56,988 INFO     Training average positive_sample_loss at step 67800: 0.110190\n",
      "2023-12-05 23:45:56,989 INFO     Training average negative_sample_loss at step 67800: 0.083742\n",
      "2023-12-05 23:45:56,989 INFO     Training average loss at step 67800: 0.096966\n",
      "2023-12-05 23:46:02,785 INFO     Training average positive_sample_loss at step 67900: 0.109644\n",
      "2023-12-05 23:46:02,785 INFO     Training average negative_sample_loss at step 67900: 0.084225\n",
      "2023-12-05 23:46:02,785 INFO     Training average loss at step 67900: 0.096934\n",
      "2023-12-05 23:46:07,998 INFO     Training average positive_sample_loss at step 68000: 0.109887\n",
      "2023-12-05 23:46:07,998 INFO     Training average negative_sample_loss at step 68000: 0.083945\n",
      "2023-12-05 23:46:07,998 INFO     Training average loss at step 68000: 0.096916\n",
      "2023-12-05 23:46:13,871 INFO     Training average positive_sample_loss at step 68100: 0.110389\n",
      "2023-12-05 23:46:13,871 INFO     Training average negative_sample_loss at step 68100: 0.084828\n",
      "2023-12-05 23:46:13,871 INFO     Training average loss at step 68100: 0.097609\n",
      "2023-12-05 23:46:19,640 INFO     Training average positive_sample_loss at step 68200: 0.109547\n",
      "2023-12-05 23:46:19,640 INFO     Training average negative_sample_loss at step 68200: 0.083941\n",
      "2023-12-05 23:46:19,641 INFO     Training average loss at step 68200: 0.096744\n",
      "2023-12-05 23:46:24,851 INFO     Training average positive_sample_loss at step 68300: 0.109657\n",
      "2023-12-05 23:46:24,851 INFO     Training average negative_sample_loss at step 68300: 0.083709\n",
      "2023-12-05 23:46:24,851 INFO     Training average loss at step 68300: 0.096683\n",
      "2023-12-05 23:46:31,340 INFO     Training average positive_sample_loss at step 68400: 0.110059\n",
      "2023-12-05 23:46:31,340 INFO     Training average negative_sample_loss at step 68400: 0.083199\n",
      "2023-12-05 23:46:31,340 INFO     Training average loss at step 68400: 0.096629\n",
      "2023-12-05 23:46:36,505 INFO     Training average positive_sample_loss at step 68500: 0.109349\n",
      "2023-12-05 23:46:36,506 INFO     Training average negative_sample_loss at step 68500: 0.083870\n",
      "2023-12-05 23:46:36,506 INFO     Training average loss at step 68500: 0.096609\n",
      "2023-12-05 23:46:41,653 INFO     Training average positive_sample_loss at step 68600: 0.110262\n",
      "2023-12-05 23:46:41,653 INFO     Training average negative_sample_loss at step 68600: 0.083702\n",
      "2023-12-05 23:46:41,653 INFO     Training average loss at step 68600: 0.096982\n",
      "2023-12-05 23:46:47,943 INFO     Training average positive_sample_loss at step 68700: 0.109772\n",
      "2023-12-05 23:46:47,943 INFO     Training average negative_sample_loss at step 68700: 0.084342\n",
      "2023-12-05 23:46:47,943 INFO     Training average loss at step 68700: 0.097057\n",
      "2023-12-05 23:46:53,107 INFO     Training average positive_sample_loss at step 68800: 0.109971\n",
      "2023-12-05 23:46:53,107 INFO     Training average negative_sample_loss at step 68800: 0.084517\n",
      "2023-12-05 23:46:53,107 INFO     Training average loss at step 68800: 0.097244\n",
      "2023-12-05 23:46:58,857 INFO     Training average positive_sample_loss at step 68900: 0.109851\n",
      "2023-12-05 23:46:58,857 INFO     Training average negative_sample_loss at step 68900: 0.083303\n",
      "2023-12-05 23:46:58,857 INFO     Training average loss at step 68900: 0.096577\n",
      "2023-12-05 23:47:04,687 INFO     Training average positive_sample_loss at step 69000: 0.109158\n",
      "2023-12-05 23:47:04,687 INFO     Training average negative_sample_loss at step 69000: 0.083852\n",
      "2023-12-05 23:47:04,687 INFO     Training average loss at step 69000: 0.096505\n",
      "2023-12-05 23:47:09,843 INFO     Training average positive_sample_loss at step 69100: 0.110316\n",
      "2023-12-05 23:47:09,843 INFO     Training average negative_sample_loss at step 69100: 0.083223\n",
      "2023-12-05 23:47:09,843 INFO     Training average loss at step 69100: 0.096770\n",
      "2023-12-05 23:47:15,572 INFO     Training average positive_sample_loss at step 69200: 0.109744\n",
      "2023-12-05 23:47:15,573 INFO     Training average negative_sample_loss at step 69200: 0.084371\n",
      "2023-12-05 23:47:15,573 INFO     Training average loss at step 69200: 0.097057\n",
      "2023-12-05 23:47:21,292 INFO     Training average positive_sample_loss at step 69300: 0.109765\n",
      "2023-12-05 23:47:21,293 INFO     Training average negative_sample_loss at step 69300: 0.083742\n",
      "2023-12-05 23:47:21,293 INFO     Training average loss at step 69300: 0.096753\n",
      "2023-12-05 23:47:26,508 INFO     Training average positive_sample_loss at step 69400: 0.110516\n",
      "2023-12-05 23:47:26,508 INFO     Training average negative_sample_loss at step 69400: 0.084059\n",
      "2023-12-05 23:47:26,508 INFO     Training average loss at step 69400: 0.097287\n",
      "2023-12-05 23:47:32,229 INFO     Training average positive_sample_loss at step 69500: 0.109311\n",
      "2023-12-05 23:47:32,230 INFO     Training average negative_sample_loss at step 69500: 0.084631\n",
      "2023-12-05 23:47:32,230 INFO     Training average loss at step 69500: 0.096971\n",
      "2023-12-05 23:47:37,559 INFO     Training average positive_sample_loss at step 69600: 0.110055\n",
      "2023-12-05 23:47:37,560 INFO     Training average negative_sample_loss at step 69600: 0.083282\n",
      "2023-12-05 23:47:37,560 INFO     Training average loss at step 69600: 0.096668\n",
      "2023-12-05 23:47:43,945 INFO     Training average positive_sample_loss at step 69700: 0.109767\n",
      "2023-12-05 23:47:43,946 INFO     Training average negative_sample_loss at step 69700: 0.084473\n",
      "2023-12-05 23:47:43,946 INFO     Training average loss at step 69700: 0.097120\n",
      "2023-12-05 23:47:49,084 INFO     Training average positive_sample_loss at step 69800: 0.109738\n",
      "2023-12-05 23:47:49,085 INFO     Training average negative_sample_loss at step 69800: 0.083609\n",
      "2023-12-05 23:47:49,085 INFO     Training average loss at step 69800: 0.096673\n",
      "2023-12-05 23:47:54,212 INFO     Training average positive_sample_loss at step 69900: 0.110331\n",
      "2023-12-05 23:47:54,212 INFO     Training average negative_sample_loss at step 69900: 0.083962\n",
      "2023-12-05 23:47:54,212 INFO     Training average loss at step 69900: 0.097147\n",
      "2023-12-05 23:48:12,194 INFO     Training average positive_sample_loss at step 70000: 0.109039\n",
      "2023-12-05 23:48:12,194 INFO     Training average negative_sample_loss at step 70000: 0.083417\n",
      "2023-12-05 23:48:12,194 INFO     Training average loss at step 70000: 0.096228\n",
      "2023-12-05 23:48:12,194 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 23:48:12,609 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 23:48:44,400 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 23:49:03,813 INFO     Valid MRR at step 70000: 0.575816\n",
      "2023-12-05 23:49:03,813 INFO     Valid MR at step 70000: 266.027014\n",
      "2023-12-05 23:49:03,813 INFO     Valid HITS@1 at step 70000: 0.508902\n",
      "2023-12-05 23:49:03,813 INFO     Valid HITS@3 at step 70000: 0.602974\n",
      "2023-12-05 23:49:03,813 INFO     Valid HITS@10 at step 70000: 0.705642\n",
      "2023-12-05 23:49:09,100 INFO     Training average positive_sample_loss at step 70100: 0.110275\n",
      "2023-12-05 23:49:09,100 INFO     Training average negative_sample_loss at step 70100: 0.083581\n",
      "2023-12-05 23:49:09,100 INFO     Training average loss at step 70100: 0.096928\n",
      "2023-12-05 23:49:14,995 INFO     Training average positive_sample_loss at step 70200: 0.109924\n",
      "2023-12-05 23:49:14,995 INFO     Training average negative_sample_loss at step 70200: 0.084134\n",
      "2023-12-05 23:49:14,995 INFO     Training average loss at step 70200: 0.097029\n",
      "2023-12-05 23:49:20,329 INFO     Training average positive_sample_loss at step 70300: 0.109535\n",
      "2023-12-05 23:49:20,329 INFO     Training average negative_sample_loss at step 70300: 0.083955\n",
      "2023-12-05 23:49:20,330 INFO     Training average loss at step 70300: 0.096745\n",
      "2023-12-05 23:49:25,689 INFO     Training average positive_sample_loss at step 70400: 0.110437\n",
      "2023-12-05 23:49:25,689 INFO     Training average negative_sample_loss at step 70400: 0.084913\n",
      "2023-12-05 23:49:25,689 INFO     Training average loss at step 70400: 0.097675\n",
      "2023-12-05 23:49:31,489 INFO     Training average positive_sample_loss at step 70500: 0.109634\n",
      "2023-12-05 23:49:31,489 INFO     Training average negative_sample_loss at step 70500: 0.083565\n",
      "2023-12-05 23:49:31,489 INFO     Training average loss at step 70500: 0.096600\n",
      "2023-12-05 23:49:37,012 INFO     Training average positive_sample_loss at step 70600: 0.109746\n",
      "2023-12-05 23:49:37,012 INFO     Training average negative_sample_loss at step 70600: 0.083750\n",
      "2023-12-05 23:49:37,012 INFO     Training average loss at step 70600: 0.096748\n",
      "2023-12-05 23:49:42,707 INFO     Training average positive_sample_loss at step 70700: 0.110268\n",
      "2023-12-05 23:49:42,707 INFO     Training average negative_sample_loss at step 70700: 0.084126\n",
      "2023-12-05 23:49:42,707 INFO     Training average loss at step 70700: 0.097197\n",
      "2023-12-05 23:49:47,878 INFO     Training average positive_sample_loss at step 70800: 0.108842\n",
      "2023-12-05 23:49:47,878 INFO     Training average negative_sample_loss at step 70800: 0.083649\n",
      "2023-12-05 23:49:47,878 INFO     Training average loss at step 70800: 0.096246\n",
      "2023-12-05 23:49:53,299 INFO     Training average positive_sample_loss at step 70900: 0.110454\n",
      "2023-12-05 23:49:53,299 INFO     Training average negative_sample_loss at step 70900: 0.083758\n",
      "2023-12-05 23:49:53,299 INFO     Training average loss at step 70900: 0.097106\n",
      "2023-12-05 23:49:59,052 INFO     Training average positive_sample_loss at step 71000: 0.109705\n",
      "2023-12-05 23:49:59,053 INFO     Training average negative_sample_loss at step 71000: 0.083951\n",
      "2023-12-05 23:49:59,053 INFO     Training average loss at step 71000: 0.096828\n",
      "2023-12-05 23:50:04,603 INFO     Training average positive_sample_loss at step 71100: 0.109660\n",
      "2023-12-05 23:50:04,603 INFO     Training average negative_sample_loss at step 71100: 0.084312\n",
      "2023-12-05 23:50:04,603 INFO     Training average loss at step 71100: 0.096986\n",
      "2023-12-05 23:50:10,049 INFO     Training average positive_sample_loss at step 71200: 0.110768\n",
      "2023-12-05 23:50:10,049 INFO     Training average negative_sample_loss at step 71200: 0.083555\n",
      "2023-12-05 23:50:10,049 INFO     Training average loss at step 71200: 0.097162\n",
      "2023-12-05 23:50:15,842 INFO     Training average positive_sample_loss at step 71300: 0.109096\n",
      "2023-12-05 23:50:15,842 INFO     Training average negative_sample_loss at step 71300: 0.082729\n",
      "2023-12-05 23:50:15,842 INFO     Training average loss at step 71300: 0.095913\n",
      "2023-12-05 23:50:20,997 INFO     Training average positive_sample_loss at step 71400: 0.110082\n",
      "2023-12-05 23:50:20,997 INFO     Training average negative_sample_loss at step 71400: 0.082905\n",
      "2023-12-05 23:50:20,997 INFO     Training average loss at step 71400: 0.096493\n",
      "2023-12-05 23:50:26,740 INFO     Training average positive_sample_loss at step 71500: 0.109865\n",
      "2023-12-05 23:50:26,740 INFO     Training average negative_sample_loss at step 71500: 0.083601\n",
      "2023-12-05 23:50:26,740 INFO     Training average loss at step 71500: 0.096733\n",
      "2023-12-05 23:50:32,534 INFO     Training average positive_sample_loss at step 71600: 0.109013\n",
      "2023-12-05 23:50:32,534 INFO     Training average negative_sample_loss at step 71600: 0.083462\n",
      "2023-12-05 23:50:32,534 INFO     Training average loss at step 71600: 0.096238\n",
      "2023-12-05 23:50:37,676 INFO     Training average positive_sample_loss at step 71700: 0.110592\n",
      "2023-12-05 23:50:37,676 INFO     Training average negative_sample_loss at step 71700: 0.084078\n",
      "2023-12-05 23:50:37,676 INFO     Training average loss at step 71700: 0.097335\n",
      "2023-12-05 23:50:43,413 INFO     Training average positive_sample_loss at step 71800: 0.108915\n",
      "2023-12-05 23:50:43,414 INFO     Training average negative_sample_loss at step 71800: 0.083560\n",
      "2023-12-05 23:50:43,414 INFO     Training average loss at step 71800: 0.096238\n",
      "2023-12-05 23:50:48,570 INFO     Training average positive_sample_loss at step 71900: 0.110352\n",
      "2023-12-05 23:50:48,571 INFO     Training average negative_sample_loss at step 71900: 0.084699\n",
      "2023-12-05 23:50:48,571 INFO     Training average loss at step 71900: 0.097525\n",
      "2023-12-05 23:50:54,850 INFO     Training average positive_sample_loss at step 72000: 0.109701\n",
      "2023-12-05 23:50:54,850 INFO     Training average negative_sample_loss at step 72000: 0.084394\n",
      "2023-12-05 23:50:54,850 INFO     Training average loss at step 72000: 0.097048\n",
      "2023-12-05 23:51:00,021 INFO     Training average positive_sample_loss at step 72100: 0.109616\n",
      "2023-12-05 23:51:00,022 INFO     Training average negative_sample_loss at step 72100: 0.083465\n",
      "2023-12-05 23:51:00,022 INFO     Training average loss at step 72100: 0.096540\n",
      "2023-12-05 23:51:05,185 INFO     Training average positive_sample_loss at step 72200: 0.110067\n",
      "2023-12-05 23:51:05,186 INFO     Training average negative_sample_loss at step 72200: 0.084037\n",
      "2023-12-05 23:51:05,186 INFO     Training average loss at step 72200: 0.097052\n",
      "2023-12-05 23:51:10,912 INFO     Training average positive_sample_loss at step 72300: 0.109807\n",
      "2023-12-05 23:51:10,912 INFO     Training average negative_sample_loss at step 72300: 0.083852\n",
      "2023-12-05 23:51:10,912 INFO     Training average loss at step 72300: 0.096829\n",
      "2023-12-05 23:51:16,353 INFO     Training average positive_sample_loss at step 72400: 0.109915\n",
      "2023-12-05 23:51:16,353 INFO     Training average negative_sample_loss at step 72400: 0.083716\n",
      "2023-12-05 23:51:16,353 INFO     Training average loss at step 72400: 0.096815\n",
      "2023-12-05 23:51:22,487 INFO     Training average positive_sample_loss at step 72500: 0.109935\n",
      "2023-12-05 23:51:22,487 INFO     Training average negative_sample_loss at step 72500: 0.083430\n",
      "2023-12-05 23:51:22,487 INFO     Training average loss at step 72500: 0.096683\n",
      "2023-12-05 23:51:27,652 INFO     Training average positive_sample_loss at step 72600: 0.108623\n",
      "2023-12-05 23:51:27,652 INFO     Training average negative_sample_loss at step 72600: 0.083453\n",
      "2023-12-05 23:51:27,652 INFO     Training average loss at step 72600: 0.096038\n",
      "2023-12-05 23:51:32,796 INFO     Training average positive_sample_loss at step 72700: 0.110239\n",
      "2023-12-05 23:51:32,796 INFO     Training average negative_sample_loss at step 72700: 0.084598\n",
      "2023-12-05 23:51:32,796 INFO     Training average loss at step 72700: 0.097419\n",
      "2023-12-05 23:51:38,571 INFO     Training average positive_sample_loss at step 72800: 0.109860\n",
      "2023-12-05 23:51:38,571 INFO     Training average negative_sample_loss at step 72800: 0.084486\n",
      "2023-12-05 23:51:38,571 INFO     Training average loss at step 72800: 0.097173\n",
      "2023-12-05 23:51:44,392 INFO     Training average positive_sample_loss at step 72900: 0.110223\n",
      "2023-12-05 23:51:44,392 INFO     Training average negative_sample_loss at step 72900: 0.084683\n",
      "2023-12-05 23:51:44,392 INFO     Training average loss at step 72900: 0.097453\n",
      "2023-12-05 23:51:49,578 INFO     Training average positive_sample_loss at step 73000: 0.109966\n",
      "2023-12-05 23:51:49,579 INFO     Training average negative_sample_loss at step 73000: 0.082983\n",
      "2023-12-05 23:51:49,579 INFO     Training average loss at step 73000: 0.096475\n",
      "2023-12-05 23:51:55,409 INFO     Training average positive_sample_loss at step 73100: 0.109515\n",
      "2023-12-05 23:51:55,410 INFO     Training average negative_sample_loss at step 73100: 0.084370\n",
      "2023-12-05 23:51:55,410 INFO     Training average loss at step 73100: 0.096943\n",
      "2023-12-05 23:52:00,613 INFO     Training average positive_sample_loss at step 73200: 0.109498\n",
      "2023-12-05 23:52:00,613 INFO     Training average negative_sample_loss at step 73200: 0.083390\n",
      "2023-12-05 23:52:00,613 INFO     Training average loss at step 73200: 0.096444\n",
      "2023-12-05 23:52:06,486 INFO     Training average positive_sample_loss at step 73300: 0.110274\n",
      "2023-12-05 23:52:06,487 INFO     Training average negative_sample_loss at step 73300: 0.084087\n",
      "2023-12-05 23:52:06,487 INFO     Training average loss at step 73300: 0.097180\n",
      "2023-12-05 23:52:11,711 INFO     Training average positive_sample_loss at step 73400: 0.109359\n",
      "2023-12-05 23:52:11,712 INFO     Training average negative_sample_loss at step 73400: 0.083229\n",
      "2023-12-05 23:52:11,712 INFO     Training average loss at step 73400: 0.096294\n",
      "2023-12-05 23:52:17,610 INFO     Training average positive_sample_loss at step 73500: 0.109885\n",
      "2023-12-05 23:52:17,610 INFO     Training average negative_sample_loss at step 73500: 0.083818\n",
      "2023-12-05 23:52:17,611 INFO     Training average loss at step 73500: 0.096852\n",
      "2023-12-05 23:52:23,443 INFO     Training average positive_sample_loss at step 73600: 0.109962\n",
      "2023-12-05 23:52:23,444 INFO     Training average negative_sample_loss at step 73600: 0.084323\n",
      "2023-12-05 23:52:23,444 INFO     Training average loss at step 73600: 0.097142\n",
      "2023-12-05 23:52:28,663 INFO     Training average positive_sample_loss at step 73700: 0.110278\n",
      "2023-12-05 23:52:28,663 INFO     Training average negative_sample_loss at step 73700: 0.083950\n",
      "2023-12-05 23:52:28,663 INFO     Training average loss at step 73700: 0.097114\n",
      "2023-12-05 23:52:34,516 INFO     Training average positive_sample_loss at step 73800: 0.109706\n",
      "2023-12-05 23:52:34,516 INFO     Training average negative_sample_loss at step 73800: 0.083785\n",
      "2023-12-05 23:52:34,516 INFO     Training average loss at step 73800: 0.096745\n",
      "2023-12-05 23:52:39,730 INFO     Training average positive_sample_loss at step 73900: 0.109408\n",
      "2023-12-05 23:52:39,730 INFO     Training average negative_sample_loss at step 73900: 0.083618\n",
      "2023-12-05 23:52:39,730 INFO     Training average loss at step 73900: 0.096513\n",
      "2023-12-05 23:52:45,573 INFO     Training average positive_sample_loss at step 74000: 0.109938\n",
      "2023-12-05 23:52:45,573 INFO     Training average negative_sample_loss at step 74000: 0.083542\n",
      "2023-12-05 23:52:45,573 INFO     Training average loss at step 74000: 0.096740\n",
      "2023-12-05 23:52:51,415 INFO     Training average positive_sample_loss at step 74100: 0.109489\n",
      "2023-12-05 23:52:51,415 INFO     Training average negative_sample_loss at step 74100: 0.082590\n",
      "2023-12-05 23:52:51,416 INFO     Training average loss at step 74100: 0.096040\n",
      "2023-12-05 23:52:56,607 INFO     Training average positive_sample_loss at step 74200: 0.109158\n",
      "2023-12-05 23:52:56,608 INFO     Training average negative_sample_loss at step 74200: 0.083836\n",
      "2023-12-05 23:52:56,608 INFO     Training average loss at step 74200: 0.096497\n",
      "2023-12-05 23:53:01,836 INFO     Training average positive_sample_loss at step 74300: 0.110793\n",
      "2023-12-05 23:53:01,837 INFO     Training average negative_sample_loss at step 74300: 0.083813\n",
      "2023-12-05 23:53:01,837 INFO     Training average loss at step 74300: 0.097303\n",
      "2023-12-05 23:53:07,623 INFO     Training average positive_sample_loss at step 74400: 0.109495\n",
      "2023-12-05 23:53:07,624 INFO     Training average negative_sample_loss at step 74400: 0.084552\n",
      "2023-12-05 23:53:07,624 INFO     Training average loss at step 74400: 0.097024\n",
      "2023-12-05 23:53:13,443 INFO     Training average positive_sample_loss at step 74500: 0.109543\n",
      "2023-12-05 23:53:13,444 INFO     Training average negative_sample_loss at step 74500: 0.083695\n",
      "2023-12-05 23:53:13,444 INFO     Training average loss at step 74500: 0.096619\n",
      "2023-12-05 23:53:19,168 INFO     Training average positive_sample_loss at step 74600: 0.110073\n",
      "2023-12-05 23:53:19,168 INFO     Training average negative_sample_loss at step 74600: 0.084530\n",
      "2023-12-05 23:53:19,168 INFO     Training average loss at step 74600: 0.097302\n",
      "2023-12-05 23:53:24,356 INFO     Training average positive_sample_loss at step 74700: 0.109142\n",
      "2023-12-05 23:53:24,356 INFO     Training average negative_sample_loss at step 74700: 0.083616\n",
      "2023-12-05 23:53:24,356 INFO     Training average loss at step 74700: 0.096379\n",
      "2023-12-05 23:53:29,566 INFO     Training average positive_sample_loss at step 74800: 0.110489\n",
      "2023-12-05 23:53:29,566 INFO     Training average negative_sample_loss at step 74800: 0.084277\n",
      "2023-12-05 23:53:29,566 INFO     Training average loss at step 74800: 0.097383\n",
      "2023-12-05 23:53:35,597 INFO     Training average positive_sample_loss at step 74900: 0.109779\n",
      "2023-12-05 23:53:35,597 INFO     Training average negative_sample_loss at step 74900: 0.084253\n",
      "2023-12-05 23:53:35,597 INFO     Training average loss at step 74900: 0.097016\n",
      "2023-12-05 23:53:40,755 INFO     Training average positive_sample_loss at step 75000: 0.109506\n",
      "2023-12-05 23:53:40,755 INFO     Training average negative_sample_loss at step 75000: 0.083469\n",
      "2023-12-05 23:53:40,755 INFO     Training average loss at step 75000: 0.096487\n",
      "2023-12-05 23:53:46,578 INFO     Training average positive_sample_loss at step 75100: 0.109734\n",
      "2023-12-05 23:53:46,578 INFO     Training average negative_sample_loss at step 75100: 0.084114\n",
      "2023-12-05 23:53:46,578 INFO     Training average loss at step 75100: 0.096924\n",
      "2023-12-05 23:53:52,003 INFO     Training average positive_sample_loss at step 75200: 0.109710\n",
      "2023-12-05 23:53:52,003 INFO     Training average negative_sample_loss at step 75200: 0.083607\n",
      "2023-12-05 23:53:52,003 INFO     Training average loss at step 75200: 0.096659\n",
      "2023-12-05 23:53:57,600 INFO     Training average positive_sample_loss at step 75300: 0.110209\n",
      "2023-12-05 23:53:57,600 INFO     Training average negative_sample_loss at step 75300: 0.083893\n",
      "2023-12-05 23:53:57,600 INFO     Training average loss at step 75300: 0.097051\n",
      "2023-12-05 23:54:03,429 INFO     Training average positive_sample_loss at step 75400: 0.108983\n",
      "2023-12-05 23:54:03,430 INFO     Training average negative_sample_loss at step 75400: 0.083312\n",
      "2023-12-05 23:54:03,430 INFO     Training average loss at step 75400: 0.096148\n",
      "2023-12-05 23:54:08,611 INFO     Training average positive_sample_loss at step 75500: 0.110167\n",
      "2023-12-05 23:54:08,611 INFO     Training average negative_sample_loss at step 75500: 0.084473\n",
      "2023-12-05 23:54:08,611 INFO     Training average loss at step 75500: 0.097320\n",
      "2023-12-05 23:54:14,727 INFO     Training average positive_sample_loss at step 75600: 0.110037\n",
      "2023-12-05 23:54:14,728 INFO     Training average negative_sample_loss at step 75600: 0.083055\n",
      "2023-12-05 23:54:14,728 INFO     Training average loss at step 75600: 0.096546\n",
      "2023-12-05 23:54:20,333 INFO     Training average positive_sample_loss at step 75700: 0.109205\n",
      "2023-12-05 23:54:20,334 INFO     Training average negative_sample_loss at step 75700: 0.084394\n",
      "2023-12-05 23:54:20,334 INFO     Training average loss at step 75700: 0.096800\n",
      "2023-12-05 23:54:25,496 INFO     Training average positive_sample_loss at step 75800: 0.110075\n",
      "2023-12-05 23:54:25,497 INFO     Training average negative_sample_loss at step 75800: 0.084209\n",
      "2023-12-05 23:54:25,497 INFO     Training average loss at step 75800: 0.097142\n",
      "2023-12-05 23:54:31,530 INFO     Training average positive_sample_loss at step 75900: 0.109757\n",
      "2023-12-05 23:54:31,530 INFO     Training average negative_sample_loss at step 75900: 0.083716\n",
      "2023-12-05 23:54:31,530 INFO     Training average loss at step 75900: 0.096737\n",
      "2023-12-05 23:54:37,136 INFO     Training average positive_sample_loss at step 76000: 0.109481\n",
      "2023-12-05 23:54:37,136 INFO     Training average negative_sample_loss at step 76000: 0.083840\n",
      "2023-12-05 23:54:37,136 INFO     Training average loss at step 76000: 0.096660\n",
      "2023-12-05 23:54:42,344 INFO     Training average positive_sample_loss at step 76100: 0.110337\n",
      "2023-12-05 23:54:42,344 INFO     Training average negative_sample_loss at step 76100: 0.084602\n",
      "2023-12-05 23:54:42,344 INFO     Training average loss at step 76100: 0.097470\n",
      "2023-12-05 23:54:48,028 INFO     Training average positive_sample_loss at step 76200: 0.109589\n",
      "2023-12-05 23:54:48,028 INFO     Training average negative_sample_loss at step 76200: 0.084325\n",
      "2023-12-05 23:54:48,028 INFO     Training average loss at step 76200: 0.096957\n",
      "2023-12-05 23:54:53,445 INFO     Training average positive_sample_loss at step 76300: 0.109761\n",
      "2023-12-05 23:54:53,445 INFO     Training average negative_sample_loss at step 76300: 0.083649\n",
      "2023-12-05 23:54:53,445 INFO     Training average loss at step 76300: 0.096705\n",
      "2023-12-05 23:54:59,600 INFO     Training average positive_sample_loss at step 76400: 0.109934\n",
      "2023-12-05 23:54:59,600 INFO     Training average negative_sample_loss at step 76400: 0.084120\n",
      "2023-12-05 23:54:59,600 INFO     Training average loss at step 76400: 0.097027\n",
      "2023-12-05 23:55:04,757 INFO     Training average positive_sample_loss at step 76500: 0.109652\n",
      "2023-12-05 23:55:04,758 INFO     Training average negative_sample_loss at step 76500: 0.083632\n",
      "2023-12-05 23:55:04,758 INFO     Training average loss at step 76500: 0.096642\n",
      "2023-12-05 23:55:10,168 INFO     Training average positive_sample_loss at step 76600: 0.109930\n",
      "2023-12-05 23:55:10,168 INFO     Training average negative_sample_loss at step 76600: 0.083786\n",
      "2023-12-05 23:55:10,168 INFO     Training average loss at step 76600: 0.096858\n",
      "2023-12-05 23:55:16,297 INFO     Training average positive_sample_loss at step 76700: 0.109127\n",
      "2023-12-05 23:55:16,297 INFO     Training average negative_sample_loss at step 76700: 0.083100\n",
      "2023-12-05 23:55:16,297 INFO     Training average loss at step 76700: 0.096114\n",
      "2023-12-05 23:55:21,451 INFO     Training average positive_sample_loss at step 76800: 0.109869\n",
      "2023-12-05 23:55:21,451 INFO     Training average negative_sample_loss at step 76800: 0.083865\n",
      "2023-12-05 23:55:21,451 INFO     Training average loss at step 76800: 0.096867\n",
      "2023-12-05 23:55:27,241 INFO     Training average positive_sample_loss at step 76900: 0.110198\n",
      "2023-12-05 23:55:27,241 INFO     Training average negative_sample_loss at step 76900: 0.083863\n",
      "2023-12-05 23:55:27,241 INFO     Training average loss at step 76900: 0.097030\n",
      "2023-12-05 23:55:32,642 INFO     Training average positive_sample_loss at step 77000: 0.109226\n",
      "2023-12-05 23:55:32,642 INFO     Training average negative_sample_loss at step 77000: 0.083428\n",
      "2023-12-05 23:55:32,642 INFO     Training average loss at step 77000: 0.096327\n",
      "2023-12-05 23:55:38,184 INFO     Training average positive_sample_loss at step 77100: 0.110146\n",
      "2023-12-05 23:55:38,184 INFO     Training average negative_sample_loss at step 77100: 0.083676\n",
      "2023-12-05 23:55:38,184 INFO     Training average loss at step 77100: 0.096911\n",
      "2023-12-05 23:55:43,885 INFO     Training average positive_sample_loss at step 77200: 0.109507\n",
      "2023-12-05 23:55:43,885 INFO     Training average negative_sample_loss at step 77200: 0.083573\n",
      "2023-12-05 23:55:43,885 INFO     Training average loss at step 77200: 0.096540\n",
      "2023-12-05 23:55:49,029 INFO     Training average positive_sample_loss at step 77300: 0.109598\n",
      "2023-12-05 23:55:49,029 INFO     Training average negative_sample_loss at step 77300: 0.083487\n",
      "2023-12-05 23:55:49,029 INFO     Training average loss at step 77300: 0.096542\n",
      "2023-12-05 23:55:55,125 INFO     Training average positive_sample_loss at step 77400: 0.110294\n",
      "2023-12-05 23:55:55,126 INFO     Training average negative_sample_loss at step 77400: 0.084439\n",
      "2023-12-05 23:55:55,126 INFO     Training average loss at step 77400: 0.097366\n",
      "2023-12-05 23:56:00,659 INFO     Training average positive_sample_loss at step 77500: 0.108650\n",
      "2023-12-05 23:56:00,659 INFO     Training average negative_sample_loss at step 77500: 0.083286\n",
      "2023-12-05 23:56:00,659 INFO     Training average loss at step 77500: 0.095968\n",
      "2023-12-05 23:56:05,806 INFO     Training average positive_sample_loss at step 77600: 0.110235\n",
      "2023-12-05 23:56:05,807 INFO     Training average negative_sample_loss at step 77600: 0.084033\n",
      "2023-12-05 23:56:05,807 INFO     Training average loss at step 77600: 0.097134\n",
      "2023-12-05 23:56:11,513 INFO     Training average positive_sample_loss at step 77700: 0.110062\n",
      "2023-12-05 23:56:11,513 INFO     Training average negative_sample_loss at step 77700: 0.084382\n",
      "2023-12-05 23:56:11,514 INFO     Training average loss at step 77700: 0.097222\n",
      "2023-12-05 23:56:17,343 INFO     Training average positive_sample_loss at step 77800: 0.109476\n",
      "2023-12-05 23:56:17,343 INFO     Training average negative_sample_loss at step 77800: 0.083652\n",
      "2023-12-05 23:56:17,343 INFO     Training average loss at step 77800: 0.096564\n",
      "2023-12-05 23:56:22,510 INFO     Training average positive_sample_loss at step 77900: 0.110097\n",
      "2023-12-05 23:56:22,510 INFO     Training average negative_sample_loss at step 77900: 0.083563\n",
      "2023-12-05 23:56:22,510 INFO     Training average loss at step 77900: 0.096830\n",
      "2023-12-05 23:56:28,227 INFO     Training average positive_sample_loss at step 78000: 0.109470\n",
      "2023-12-05 23:56:28,227 INFO     Training average negative_sample_loss at step 78000: 0.084018\n",
      "2023-12-05 23:56:28,227 INFO     Training average loss at step 78000: 0.096744\n",
      "2023-12-05 23:56:34,055 INFO     Training average positive_sample_loss at step 78100: 0.109652\n",
      "2023-12-05 23:56:34,056 INFO     Training average negative_sample_loss at step 78100: 0.083736\n",
      "2023-12-05 23:56:34,056 INFO     Training average loss at step 78100: 0.096694\n",
      "2023-12-05 23:56:39,845 INFO     Training average positive_sample_loss at step 78200: 0.109374\n",
      "2023-12-05 23:56:39,845 INFO     Training average negative_sample_loss at step 78200: 0.084308\n",
      "2023-12-05 23:56:39,845 INFO     Training average loss at step 78200: 0.096841\n",
      "2023-12-05 23:56:45,005 INFO     Training average positive_sample_loss at step 78300: 0.109790\n",
      "2023-12-05 23:56:45,005 INFO     Training average negative_sample_loss at step 78300: 0.083731\n",
      "2023-12-05 23:56:45,005 INFO     Training average loss at step 78300: 0.096761\n",
      "2023-12-05 23:56:50,163 INFO     Training average positive_sample_loss at step 78400: 0.109917\n",
      "2023-12-05 23:56:50,163 INFO     Training average negative_sample_loss at step 78400: 0.084003\n",
      "2023-12-05 23:56:50,163 INFO     Training average loss at step 78400: 0.096960\n",
      "2023-12-05 23:56:56,618 INFO     Training average positive_sample_loss at step 78500: 0.109761\n",
      "2023-12-05 23:56:56,618 INFO     Training average negative_sample_loss at step 78500: 0.083487\n",
      "2023-12-05 23:56:56,618 INFO     Training average loss at step 78500: 0.096624\n",
      "2023-12-05 23:57:01,766 INFO     Training average positive_sample_loss at step 78600: 0.109671\n",
      "2023-12-05 23:57:01,766 INFO     Training average negative_sample_loss at step 78600: 0.083957\n",
      "2023-12-05 23:57:01,766 INFO     Training average loss at step 78600: 0.096814\n",
      "2023-12-05 23:57:07,546 INFO     Training average positive_sample_loss at step 78700: 0.109848\n",
      "2023-12-05 23:57:07,546 INFO     Training average negative_sample_loss at step 78700: 0.083125\n",
      "2023-12-05 23:57:07,546 INFO     Training average loss at step 78700: 0.096487\n",
      "2023-12-05 23:57:13,417 INFO     Training average positive_sample_loss at step 78800: 0.109357\n",
      "2023-12-05 23:57:13,417 INFO     Training average negative_sample_loss at step 78800: 0.084449\n",
      "2023-12-05 23:57:13,417 INFO     Training average loss at step 78800: 0.096903\n",
      "2023-12-05 23:57:18,579 INFO     Training average positive_sample_loss at step 78900: 0.110335\n",
      "2023-12-05 23:57:18,579 INFO     Training average negative_sample_loss at step 78900: 0.083744\n",
      "2023-12-05 23:57:18,579 INFO     Training average loss at step 78900: 0.097040\n",
      "2023-12-05 23:57:24,378 INFO     Training average positive_sample_loss at step 79000: 0.109462\n",
      "2023-12-05 23:57:24,378 INFO     Training average negative_sample_loss at step 79000: 0.083511\n",
      "2023-12-05 23:57:24,378 INFO     Training average loss at step 79000: 0.096487\n",
      "2023-12-05 23:57:29,631 INFO     Training average positive_sample_loss at step 79100: 0.109812\n",
      "2023-12-05 23:57:29,631 INFO     Training average negative_sample_loss at step 79100: 0.084092\n",
      "2023-12-05 23:57:29,631 INFO     Training average loss at step 79100: 0.096952\n",
      "2023-12-05 23:57:35,509 INFO     Training average positive_sample_loss at step 79200: 0.110160\n",
      "2023-12-05 23:57:35,509 INFO     Training average negative_sample_loss at step 79200: 0.083093\n",
      "2023-12-05 23:57:35,509 INFO     Training average loss at step 79200: 0.096626\n",
      "2023-12-05 23:57:41,287 INFO     Training average positive_sample_loss at step 79300: 0.108803\n",
      "2023-12-05 23:57:41,288 INFO     Training average negative_sample_loss at step 79300: 0.083069\n",
      "2023-12-05 23:57:41,288 INFO     Training average loss at step 79300: 0.095936\n",
      "2023-12-05 23:57:46,480 INFO     Training average positive_sample_loss at step 79400: 0.110149\n",
      "2023-12-05 23:57:46,480 INFO     Training average negative_sample_loss at step 79400: 0.084430\n",
      "2023-12-05 23:57:46,480 INFO     Training average loss at step 79400: 0.097289\n",
      "2023-12-05 23:57:52,269 INFO     Training average positive_sample_loss at step 79500: 0.109992\n",
      "2023-12-05 23:57:52,269 INFO     Training average negative_sample_loss at step 79500: 0.084366\n",
      "2023-12-05 23:57:52,269 INFO     Training average loss at step 79500: 0.097179\n",
      "2023-12-05 23:57:58,074 INFO     Training average positive_sample_loss at step 79600: 0.109266\n",
      "2023-12-05 23:57:58,074 INFO     Training average negative_sample_loss at step 79600: 0.083153\n",
      "2023-12-05 23:57:58,075 INFO     Training average loss at step 79600: 0.096210\n",
      "2023-12-05 23:58:03,230 INFO     Training average positive_sample_loss at step 79700: 0.110230\n",
      "2023-12-05 23:58:03,230 INFO     Training average negative_sample_loss at step 79700: 0.083474\n",
      "2023-12-05 23:58:03,230 INFO     Training average loss at step 79700: 0.096852\n",
      "2023-12-05 23:58:09,033 INFO     Training average positive_sample_loss at step 79800: 0.109358\n",
      "2023-12-05 23:58:09,033 INFO     Training average negative_sample_loss at step 79800: 0.083654\n",
      "2023-12-05 23:58:09,033 INFO     Training average loss at step 79800: 0.096506\n",
      "2023-12-05 23:58:14,190 INFO     Training average positive_sample_loss at step 79900: 0.109581\n",
      "2023-12-05 23:58:14,190 INFO     Training average negative_sample_loss at step 79900: 0.084078\n",
      "2023-12-05 23:58:14,190 INFO     Training average loss at step 79900: 0.096830\n",
      "2023-12-05 23:58:33,262 INFO     Training average positive_sample_loss at step 80000: 0.109724\n",
      "2023-12-05 23:58:33,263 INFO     Training average negative_sample_loss at step 80000: 0.084295\n",
      "2023-12-05 23:58:33,263 INFO     Training average loss at step 80000: 0.097009\n",
      "2023-12-05 23:58:33,263 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-05 23:58:33,688 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-05 23:59:01,554 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-05 23:59:16,463 INFO     Valid MRR at step 80000: 0.575833\n",
      "2023-12-05 23:59:16,463 INFO     Valid MR at step 80000: 266.572822\n",
      "2023-12-05 23:59:16,463 INFO     Valid HITS@1 at step 80000: 0.509516\n",
      "2023-12-05 23:59:16,463 INFO     Valid HITS@3 at step 80000: 0.602940\n",
      "2023-12-05 23:59:16,463 INFO     Valid HITS@10 at step 80000: 0.708132\n",
      "2023-12-05 23:59:22,297 INFO     Training average positive_sample_loss at step 80100: 0.109123\n",
      "2023-12-05 23:59:22,298 INFO     Training average negative_sample_loss at step 80100: 0.083662\n",
      "2023-12-05 23:59:22,298 INFO     Training average loss at step 80100: 0.096393\n",
      "2023-12-05 23:59:27,456 INFO     Training average positive_sample_loss at step 80200: 0.110557\n",
      "2023-12-05 23:59:27,457 INFO     Training average negative_sample_loss at step 80200: 0.083952\n",
      "2023-12-05 23:59:27,457 INFO     Training average loss at step 80200: 0.097255\n",
      "2023-12-05 23:59:33,348 INFO     Training average positive_sample_loss at step 80300: 0.109603\n",
      "2023-12-05 23:59:33,348 INFO     Training average negative_sample_loss at step 80300: 0.083434\n",
      "2023-12-05 23:59:33,348 INFO     Training average loss at step 80300: 0.096518\n",
      "2023-12-05 23:59:38,539 INFO     Training average positive_sample_loss at step 80400: 0.109508\n",
      "2023-12-05 23:59:38,539 INFO     Training average negative_sample_loss at step 80400: 0.084151\n",
      "2023-12-05 23:59:38,539 INFO     Training average loss at step 80400: 0.096829\n",
      "2023-12-05 23:59:44,534 INFO     Training average positive_sample_loss at step 80500: 0.110393\n",
      "2023-12-05 23:59:44,534 INFO     Training average negative_sample_loss at step 80500: 0.084041\n",
      "2023-12-05 23:59:44,534 INFO     Training average loss at step 80500: 0.097217\n",
      "2023-12-05 23:59:50,154 INFO     Training average positive_sample_loss at step 80600: 0.108936\n",
      "2023-12-05 23:59:50,154 INFO     Training average negative_sample_loss at step 80600: 0.083789\n",
      "2023-12-05 23:59:50,154 INFO     Training average loss at step 80600: 0.096362\n",
      "2023-12-05 23:59:55,348 INFO     Training average positive_sample_loss at step 80700: 0.110084\n",
      "2023-12-05 23:59:55,349 INFO     Training average negative_sample_loss at step 80700: 0.084086\n",
      "2023-12-05 23:59:55,349 INFO     Training average loss at step 80700: 0.097085\n",
      "2023-12-06 00:00:01,305 INFO     Training average positive_sample_loss at step 80800: 0.109921\n",
      "2023-12-06 00:00:01,306 INFO     Training average negative_sample_loss at step 80800: 0.083733\n",
      "2023-12-06 00:00:01,306 INFO     Training average loss at step 80800: 0.096827\n",
      "2023-12-06 00:00:07,117 INFO     Training average positive_sample_loss at step 80900: 0.109726\n",
      "2023-12-06 00:00:07,117 INFO     Training average negative_sample_loss at step 80900: 0.083811\n",
      "2023-12-06 00:00:07,117 INFO     Training average loss at step 80900: 0.096768\n",
      "2023-12-06 00:00:12,383 INFO     Training average positive_sample_loss at step 81000: 0.109924\n",
      "2023-12-06 00:00:12,383 INFO     Training average negative_sample_loss at step 81000: 0.083456\n",
      "2023-12-06 00:00:12,383 INFO     Training average loss at step 81000: 0.096690\n",
      "2023-12-06 00:00:18,213 INFO     Training average positive_sample_loss at step 81100: 0.109732\n",
      "2023-12-06 00:00:18,214 INFO     Training average negative_sample_loss at step 81100: 0.083672\n",
      "2023-12-06 00:00:18,214 INFO     Training average loss at step 81100: 0.096702\n",
      "2023-12-06 00:00:23,376 INFO     Training average positive_sample_loss at step 81200: 0.109669\n",
      "2023-12-06 00:00:23,376 INFO     Training average negative_sample_loss at step 81200: 0.083409\n",
      "2023-12-06 00:00:23,376 INFO     Training average loss at step 81200: 0.096539\n",
      "2023-12-06 00:00:29,253 INFO     Training average positive_sample_loss at step 81300: 0.109549\n",
      "2023-12-06 00:00:29,254 INFO     Training average negative_sample_loss at step 81300: 0.083085\n",
      "2023-12-06 00:00:29,254 INFO     Training average loss at step 81300: 0.096317\n",
      "2023-12-06 00:00:35,084 INFO     Training average positive_sample_loss at step 81400: 0.109007\n",
      "2023-12-06 00:00:35,084 INFO     Training average negative_sample_loss at step 81400: 0.083304\n",
      "2023-12-06 00:00:35,084 INFO     Training average loss at step 81400: 0.096155\n",
      "2023-12-06 00:00:40,245 INFO     Training average positive_sample_loss at step 81500: 0.109984\n",
      "2023-12-06 00:00:40,246 INFO     Training average negative_sample_loss at step 81500: 0.083757\n",
      "2023-12-06 00:00:40,246 INFO     Training average loss at step 81500: 0.096870\n",
      "2023-12-06 00:00:46,039 INFO     Training average positive_sample_loss at step 81600: 0.109515\n",
      "2023-12-06 00:00:46,039 INFO     Training average negative_sample_loss at step 81600: 0.083466\n",
      "2023-12-06 00:00:46,039 INFO     Training average loss at step 81600: 0.096491\n",
      "2023-12-06 00:00:51,197 INFO     Training average positive_sample_loss at step 81700: 0.109634\n",
      "2023-12-06 00:00:51,197 INFO     Training average negative_sample_loss at step 81700: 0.083515\n",
      "2023-12-06 00:00:51,197 INFO     Training average loss at step 81700: 0.096574\n",
      "2023-12-06 00:00:56,957 INFO     Training average positive_sample_loss at step 81800: 0.110198\n",
      "2023-12-06 00:00:56,957 INFO     Training average negative_sample_loss at step 81800: 0.083840\n",
      "2023-12-06 00:00:56,957 INFO     Training average loss at step 81800: 0.097019\n",
      "2023-12-06 00:01:02,654 INFO     Training average positive_sample_loss at step 81900: 0.109081\n",
      "2023-12-06 00:01:02,654 INFO     Training average negative_sample_loss at step 81900: 0.084544\n",
      "2023-12-06 00:01:02,654 INFO     Training average loss at step 81900: 0.096813\n",
      "2023-12-06 00:01:07,891 INFO     Training average positive_sample_loss at step 82000: 0.109854\n",
      "2023-12-06 00:01:07,892 INFO     Training average negative_sample_loss at step 82000: 0.083396\n",
      "2023-12-06 00:01:07,892 INFO     Training average loss at step 82000: 0.096625\n",
      "2023-12-06 00:01:13,730 INFO     Training average positive_sample_loss at step 82100: 0.109812\n",
      "2023-12-06 00:01:13,731 INFO     Training average negative_sample_loss at step 82100: 0.083986\n",
      "2023-12-06 00:01:13,731 INFO     Training average loss at step 82100: 0.096899\n",
      "2023-12-06 00:01:18,877 INFO     Training average positive_sample_loss at step 82200: 0.109267\n",
      "2023-12-06 00:01:18,877 INFO     Training average negative_sample_loss at step 82200: 0.083395\n",
      "2023-12-06 00:01:18,878 INFO     Training average loss at step 82200: 0.096331\n",
      "2023-12-06 00:01:24,703 INFO     Training average positive_sample_loss at step 82300: 0.110309\n",
      "2023-12-06 00:01:24,704 INFO     Training average negative_sample_loss at step 82300: 0.084374\n",
      "2023-12-06 00:01:24,704 INFO     Training average loss at step 82300: 0.097342\n",
      "2023-12-06 00:01:30,487 INFO     Training average positive_sample_loss at step 82400: 0.109066\n",
      "2023-12-06 00:01:30,487 INFO     Training average negative_sample_loss at step 82400: 0.083648\n",
      "2023-12-06 00:01:30,487 INFO     Training average loss at step 82400: 0.096357\n",
      "2023-12-06 00:01:35,641 INFO     Training average positive_sample_loss at step 82500: 0.109961\n",
      "2023-12-06 00:01:35,641 INFO     Training average negative_sample_loss at step 82500: 0.083644\n",
      "2023-12-06 00:01:35,641 INFO     Training average loss at step 82500: 0.096803\n",
      "2023-12-06 00:01:42,116 INFO     Training average positive_sample_loss at step 82600: 0.109639\n",
      "2023-12-06 00:01:42,116 INFO     Training average negative_sample_loss at step 82600: 0.083650\n",
      "2023-12-06 00:01:42,116 INFO     Training average loss at step 82600: 0.096645\n",
      "2023-12-06 00:01:47,271 INFO     Training average positive_sample_loss at step 82700: 0.109427\n",
      "2023-12-06 00:01:47,272 INFO     Training average negative_sample_loss at step 82700: 0.083763\n",
      "2023-12-06 00:01:47,272 INFO     Training average loss at step 82700: 0.096595\n",
      "2023-12-06 00:01:52,439 INFO     Training average positive_sample_loss at step 82800: 0.109934\n",
      "2023-12-06 00:01:52,439 INFO     Training average negative_sample_loss at step 82800: 0.083085\n",
      "2023-12-06 00:01:52,440 INFO     Training average loss at step 82800: 0.096509\n",
      "2023-12-06 00:01:58,237 INFO     Training average positive_sample_loss at step 82900: 0.109152\n",
      "2023-12-06 00:01:58,237 INFO     Training average negative_sample_loss at step 82900: 0.083501\n",
      "2023-12-06 00:01:58,237 INFO     Training average loss at step 82900: 0.096327\n",
      "2023-12-06 00:02:03,384 INFO     Training average positive_sample_loss at step 83000: 0.109807\n",
      "2023-12-06 00:02:03,384 INFO     Training average negative_sample_loss at step 83000: 0.083842\n",
      "2023-12-06 00:02:03,384 INFO     Training average loss at step 83000: 0.096825\n",
      "2023-12-06 00:02:09,903 INFO     Training average positive_sample_loss at step 83100: 0.109644\n",
      "2023-12-06 00:02:09,904 INFO     Training average negative_sample_loss at step 83100: 0.083312\n",
      "2023-12-06 00:02:09,904 INFO     Training average loss at step 83100: 0.096478\n",
      "2023-12-06 00:02:15,106 INFO     Training average positive_sample_loss at step 83200: 0.109769\n",
      "2023-12-06 00:02:15,106 INFO     Training average negative_sample_loss at step 83200: 0.083727\n",
      "2023-12-06 00:02:15,107 INFO     Training average loss at step 83200: 0.096748\n",
      "2023-12-06 00:02:20,298 INFO     Training average positive_sample_loss at step 83300: 0.109858\n",
      "2023-12-06 00:02:20,299 INFO     Training average negative_sample_loss at step 83300: 0.083775\n",
      "2023-12-06 00:02:20,299 INFO     Training average loss at step 83300: 0.096816\n",
      "2023-12-06 00:02:26,157 INFO     Training average positive_sample_loss at step 83400: 0.109025\n",
      "2023-12-06 00:02:26,157 INFO     Training average negative_sample_loss at step 83400: 0.084016\n",
      "2023-12-06 00:02:26,157 INFO     Training average loss at step 83400: 0.096520\n",
      "2023-12-06 00:02:31,975 INFO     Training average positive_sample_loss at step 83500: 0.109828\n",
      "2023-12-06 00:02:31,976 INFO     Training average negative_sample_loss at step 83500: 0.083217\n",
      "2023-12-06 00:02:31,976 INFO     Training average loss at step 83500: 0.096522\n",
      "2023-12-06 00:02:37,751 INFO     Training average positive_sample_loss at step 83600: 0.109869\n",
      "2023-12-06 00:02:37,752 INFO     Training average negative_sample_loss at step 83600: 0.083666\n",
      "2023-12-06 00:02:37,752 INFO     Training average loss at step 83600: 0.096767\n",
      "2023-12-06 00:02:42,954 INFO     Training average positive_sample_loss at step 83700: 0.109155\n",
      "2023-12-06 00:02:42,954 INFO     Training average negative_sample_loss at step 83700: 0.084007\n",
      "2023-12-06 00:02:42,954 INFO     Training average loss at step 83700: 0.096581\n",
      "2023-12-06 00:02:48,113 INFO     Training average positive_sample_loss at step 83800: 0.109778\n",
      "2023-12-06 00:02:48,113 INFO     Training average negative_sample_loss at step 83800: 0.083888\n",
      "2023-12-06 00:02:48,113 INFO     Training average loss at step 83800: 0.096833\n",
      "2023-12-06 00:02:53,991 INFO     Training average positive_sample_loss at step 83900: 0.109501\n",
      "2023-12-06 00:02:53,991 INFO     Training average negative_sample_loss at step 83900: 0.083142\n",
      "2023-12-06 00:02:53,991 INFO     Training average loss at step 83900: 0.096322\n",
      "2023-12-06 00:02:59,849 INFO     Training average positive_sample_loss at step 84000: 0.109195\n",
      "2023-12-06 00:02:59,850 INFO     Training average negative_sample_loss at step 84000: 0.083447\n",
      "2023-12-06 00:02:59,850 INFO     Training average loss at step 84000: 0.096321\n",
      "2023-12-06 00:03:05,082 INFO     Training average positive_sample_loss at step 84100: 0.110336\n",
      "2023-12-06 00:03:05,083 INFO     Training average negative_sample_loss at step 84100: 0.082999\n",
      "2023-12-06 00:03:05,083 INFO     Training average loss at step 84100: 0.096667\n",
      "2023-12-06 00:03:11,101 INFO     Training average positive_sample_loss at step 84200: 0.108824\n",
      "2023-12-06 00:03:11,102 INFO     Training average negative_sample_loss at step 84200: 0.083679\n",
      "2023-12-06 00:03:11,102 INFO     Training average loss at step 84200: 0.096252\n",
      "2023-12-06 00:03:16,323 INFO     Training average positive_sample_loss at step 84300: 0.109934\n",
      "2023-12-06 00:03:16,324 INFO     Training average negative_sample_loss at step 84300: 0.083723\n",
      "2023-12-06 00:03:16,324 INFO     Training average loss at step 84300: 0.096829\n",
      "2023-12-06 00:03:22,662 INFO     Training average positive_sample_loss at step 84400: 0.109768\n",
      "2023-12-06 00:03:22,662 INFO     Training average negative_sample_loss at step 84400: 0.083679\n",
      "2023-12-06 00:03:22,662 INFO     Training average loss at step 84400: 0.096723\n",
      "2023-12-06 00:03:27,835 INFO     Training average positive_sample_loss at step 84500: 0.109402\n",
      "2023-12-06 00:03:27,835 INFO     Training average negative_sample_loss at step 84500: 0.083449\n",
      "2023-12-06 00:03:27,835 INFO     Training average loss at step 84500: 0.096426\n",
      "2023-12-06 00:03:33,063 INFO     Training average positive_sample_loss at step 84600: 0.110078\n",
      "2023-12-06 00:03:33,063 INFO     Training average negative_sample_loss at step 84600: 0.083576\n",
      "2023-12-06 00:03:33,063 INFO     Training average loss at step 84600: 0.096827\n",
      "2023-12-06 00:03:39,244 INFO     Training average positive_sample_loss at step 84700: 0.108919\n",
      "2023-12-06 00:03:39,244 INFO     Training average negative_sample_loss at step 84700: 0.083885\n",
      "2023-12-06 00:03:39,244 INFO     Training average loss at step 84700: 0.096402\n",
      "2023-12-06 00:03:44,802 INFO     Training average positive_sample_loss at step 84800: 0.109936\n",
      "2023-12-06 00:03:44,802 INFO     Training average negative_sample_loss at step 84800: 0.083750\n",
      "2023-12-06 00:03:44,803 INFO     Training average loss at step 84800: 0.096843\n",
      "2023-12-06 00:03:50,707 INFO     Training average positive_sample_loss at step 84900: 0.109825\n",
      "2023-12-06 00:03:50,707 INFO     Training average negative_sample_loss at step 84900: 0.083268\n",
      "2023-12-06 00:03:50,707 INFO     Training average loss at step 84900: 0.096546\n",
      "2023-12-06 00:03:55,868 INFO     Training average positive_sample_loss at step 85000: 0.108941\n",
      "2023-12-06 00:03:55,868 INFO     Training average negative_sample_loss at step 85000: 0.083598\n",
      "2023-12-06 00:03:55,868 INFO     Training average loss at step 85000: 0.096270\n",
      "2023-12-06 00:04:01,714 INFO     Training average positive_sample_loss at step 85100: 0.110368\n",
      "2023-12-06 00:04:01,714 INFO     Training average negative_sample_loss at step 85100: 0.083438\n",
      "2023-12-06 00:04:01,714 INFO     Training average loss at step 85100: 0.096903\n",
      "2023-12-06 00:04:07,580 INFO     Training average positive_sample_loss at step 85200: 0.109108\n",
      "2023-12-06 00:04:07,580 INFO     Training average negative_sample_loss at step 85200: 0.083600\n",
      "2023-12-06 00:04:07,580 INFO     Training average loss at step 85200: 0.096354\n",
      "2023-12-06 00:04:12,727 INFO     Training average positive_sample_loss at step 85300: 0.109435\n",
      "2023-12-06 00:04:12,727 INFO     Training average negative_sample_loss at step 85300: 0.084486\n",
      "2023-12-06 00:04:12,727 INFO     Training average loss at step 85300: 0.096960\n",
      "2023-12-06 00:04:19,189 INFO     Training average positive_sample_loss at step 85400: 0.110505\n",
      "2023-12-06 00:04:19,189 INFO     Training average negative_sample_loss at step 85400: 0.084381\n",
      "2023-12-06 00:04:19,189 INFO     Training average loss at step 85400: 0.097443\n",
      "2023-12-06 00:04:24,475 INFO     Training average positive_sample_loss at step 85500: 0.108732\n",
      "2023-12-06 00:04:24,475 INFO     Training average negative_sample_loss at step 85500: 0.083461\n",
      "2023-12-06 00:04:24,475 INFO     Training average loss at step 85500: 0.096096\n",
      "2023-12-06 00:04:29,800 INFO     Training average positive_sample_loss at step 85600: 0.110042\n",
      "2023-12-06 00:04:29,800 INFO     Training average negative_sample_loss at step 85600: 0.083981\n",
      "2023-12-06 00:04:29,800 INFO     Training average loss at step 85600: 0.097011\n",
      "2023-12-06 00:04:36,265 INFO     Training average positive_sample_loss at step 85700: 0.109862\n",
      "2023-12-06 00:04:36,265 INFO     Training average negative_sample_loss at step 85700: 0.083392\n",
      "2023-12-06 00:04:36,265 INFO     Training average loss at step 85700: 0.096627\n",
      "2023-12-06 00:04:41,435 INFO     Training average positive_sample_loss at step 85800: 0.109630\n",
      "2023-12-06 00:04:41,435 INFO     Training average negative_sample_loss at step 85800: 0.083052\n",
      "2023-12-06 00:04:41,435 INFO     Training average loss at step 85800: 0.096341\n",
      "2023-12-06 00:04:46,768 INFO     Training average positive_sample_loss at step 85900: 0.109695\n",
      "2023-12-06 00:04:46,769 INFO     Training average negative_sample_loss at step 85900: 0.083593\n",
      "2023-12-06 00:04:46,769 INFO     Training average loss at step 85900: 0.096644\n",
      "2023-12-06 00:04:52,613 INFO     Training average positive_sample_loss at step 86000: 0.108698\n",
      "2023-12-06 00:04:52,613 INFO     Training average negative_sample_loss at step 86000: 0.083457\n",
      "2023-12-06 00:04:52,613 INFO     Training average loss at step 86000: 0.096078\n",
      "2023-12-06 00:04:58,332 INFO     Training average positive_sample_loss at step 86100: 0.110046\n",
      "2023-12-06 00:04:58,332 INFO     Training average negative_sample_loss at step 86100: 0.083456\n",
      "2023-12-06 00:04:58,332 INFO     Training average loss at step 86100: 0.096751\n",
      "2023-12-06 00:05:04,139 INFO     Training average positive_sample_loss at step 86200: 0.109974\n",
      "2023-12-06 00:05:04,139 INFO     Training average negative_sample_loss at step 86200: 0.084226\n",
      "2023-12-06 00:05:04,140 INFO     Training average loss at step 86200: 0.097100\n",
      "2023-12-06 00:05:09,318 INFO     Training average positive_sample_loss at step 86300: 0.109560\n",
      "2023-12-06 00:05:09,319 INFO     Training average negative_sample_loss at step 86300: 0.084018\n",
      "2023-12-06 00:05:09,319 INFO     Training average loss at step 86300: 0.096789\n",
      "2023-12-06 00:05:14,491 INFO     Training average positive_sample_loss at step 86400: 0.109783\n",
      "2023-12-06 00:05:14,491 INFO     Training average negative_sample_loss at step 86400: 0.083149\n",
      "2023-12-06 00:05:14,491 INFO     Training average loss at step 86400: 0.096466\n",
      "2023-12-06 00:05:20,536 INFO     Training average positive_sample_loss at step 86500: 0.108657\n",
      "2023-12-06 00:05:20,536 INFO     Training average negative_sample_loss at step 86500: 0.083767\n",
      "2023-12-06 00:05:20,536 INFO     Training average loss at step 86500: 0.096212\n",
      "2023-12-06 00:05:25,974 INFO     Training average positive_sample_loss at step 86600: 0.109850\n",
      "2023-12-06 00:05:25,974 INFO     Training average negative_sample_loss at step 86600: 0.082562\n",
      "2023-12-06 00:05:25,974 INFO     Training average loss at step 86600: 0.096206\n",
      "2023-12-06 00:05:31,781 INFO     Training average positive_sample_loss at step 86700: 0.110305\n",
      "2023-12-06 00:05:31,781 INFO     Training average negative_sample_loss at step 86700: 0.083485\n",
      "2023-12-06 00:05:31,781 INFO     Training average loss at step 86700: 0.096895\n",
      "2023-12-06 00:05:37,345 INFO     Training average positive_sample_loss at step 86800: 0.109322\n",
      "2023-12-06 00:05:37,345 INFO     Training average negative_sample_loss at step 86800: 0.084157\n",
      "2023-12-06 00:05:37,345 INFO     Training average loss at step 86800: 0.096739\n",
      "2023-12-06 00:05:42,508 INFO     Training average positive_sample_loss at step 86900: 0.109754\n",
      "2023-12-06 00:05:42,508 INFO     Training average negative_sample_loss at step 86900: 0.083434\n",
      "2023-12-06 00:05:42,508 INFO     Training average loss at step 86900: 0.096594\n",
      "2023-12-06 00:05:48,648 INFO     Training average positive_sample_loss at step 87000: 0.109467\n",
      "2023-12-06 00:05:48,648 INFO     Training average negative_sample_loss at step 87000: 0.084004\n",
      "2023-12-06 00:05:48,648 INFO     Training average loss at step 87000: 0.096736\n",
      "2023-12-06 00:05:53,824 INFO     Training average positive_sample_loss at step 87100: 0.109987\n",
      "2023-12-06 00:05:53,824 INFO     Training average negative_sample_loss at step 87100: 0.084496\n",
      "2023-12-06 00:05:53,824 INFO     Training average loss at step 87100: 0.097241\n",
      "2023-12-06 00:05:59,423 INFO     Training average positive_sample_loss at step 87200: 0.109636\n",
      "2023-12-06 00:05:59,424 INFO     Training average negative_sample_loss at step 87200: 0.083805\n",
      "2023-12-06 00:05:59,424 INFO     Training average loss at step 87200: 0.096720\n",
      "2023-12-06 00:06:05,244 INFO     Training average positive_sample_loss at step 87300: 0.109213\n",
      "2023-12-06 00:06:05,244 INFO     Training average negative_sample_loss at step 87300: 0.083615\n",
      "2023-12-06 00:06:05,244 INFO     Training average loss at step 87300: 0.096414\n",
      "2023-12-06 00:06:10,414 INFO     Training average positive_sample_loss at step 87400: 0.110027\n",
      "2023-12-06 00:06:10,414 INFO     Training average negative_sample_loss at step 87400: 0.084298\n",
      "2023-12-06 00:06:10,414 INFO     Training average loss at step 87400: 0.097162\n",
      "2023-12-06 00:06:16,874 INFO     Training average positive_sample_loss at step 87500: 0.109425\n",
      "2023-12-06 00:06:16,875 INFO     Training average negative_sample_loss at step 87500: 0.083337\n",
      "2023-12-06 00:06:16,875 INFO     Training average loss at step 87500: 0.096381\n",
      "2023-12-06 00:06:22,025 INFO     Training average positive_sample_loss at step 87600: 0.108903\n",
      "2023-12-06 00:06:22,025 INFO     Training average negative_sample_loss at step 87600: 0.083581\n",
      "2023-12-06 00:06:22,025 INFO     Training average loss at step 87600: 0.096242\n",
      "2023-12-06 00:06:27,211 INFO     Training average positive_sample_loss at step 87700: 0.110258\n",
      "2023-12-06 00:06:27,211 INFO     Training average negative_sample_loss at step 87700: 0.083666\n",
      "2023-12-06 00:06:27,211 INFO     Training average loss at step 87700: 0.096962\n",
      "2023-12-06 00:06:33,002 INFO     Training average positive_sample_loss at step 87800: 0.109114\n",
      "2023-12-06 00:06:33,002 INFO     Training average negative_sample_loss at step 87800: 0.083967\n",
      "2023-12-06 00:06:33,002 INFO     Training average loss at step 87800: 0.096540\n",
      "2023-12-06 00:06:38,138 INFO     Training average positive_sample_loss at step 87900: 0.109996\n",
      "2023-12-06 00:06:38,138 INFO     Training average negative_sample_loss at step 87900: 0.083645\n",
      "2023-12-06 00:06:38,138 INFO     Training average loss at step 87900: 0.096821\n",
      "2023-12-06 00:06:44,217 INFO     Training average positive_sample_loss at step 88000: 0.109400\n",
      "2023-12-06 00:06:44,217 INFO     Training average negative_sample_loss at step 88000: 0.083438\n",
      "2023-12-06 00:06:44,217 INFO     Training average loss at step 88000: 0.096419\n",
      "2023-12-06 00:06:49,369 INFO     Training average positive_sample_loss at step 88100: 0.109374\n",
      "2023-12-06 00:06:49,369 INFO     Training average negative_sample_loss at step 88100: 0.084295\n",
      "2023-12-06 00:06:49,369 INFO     Training average loss at step 88100: 0.096834\n",
      "2023-12-06 00:06:54,921 INFO     Training average positive_sample_loss at step 88200: 0.110480\n",
      "2023-12-06 00:06:54,921 INFO     Training average negative_sample_loss at step 88200: 0.083521\n",
      "2023-12-06 00:06:54,921 INFO     Training average loss at step 88200: 0.097000\n",
      "2023-12-06 00:07:00,850 INFO     Training average positive_sample_loss at step 88300: 0.108437\n",
      "2023-12-06 00:07:00,850 INFO     Training average negative_sample_loss at step 88300: 0.083834\n",
      "2023-12-06 00:07:00,850 INFO     Training average loss at step 88300: 0.096136\n",
      "2023-12-06 00:07:06,057 INFO     Training average positive_sample_loss at step 88400: 0.109889\n",
      "2023-12-06 00:07:06,058 INFO     Training average negative_sample_loss at step 88400: 0.083158\n",
      "2023-12-06 00:07:06,058 INFO     Training average loss at step 88400: 0.096524\n",
      "2023-12-06 00:07:11,928 INFO     Training average positive_sample_loss at step 88500: 0.110315\n",
      "2023-12-06 00:07:11,929 INFO     Training average negative_sample_loss at step 88500: 0.083816\n",
      "2023-12-06 00:07:11,929 INFO     Training average loss at step 88500: 0.097066\n",
      "2023-12-06 00:07:17,898 INFO     Training average positive_sample_loss at step 88600: 0.109278\n",
      "2023-12-06 00:07:17,898 INFO     Training average negative_sample_loss at step 88600: 0.083785\n",
      "2023-12-06 00:07:17,898 INFO     Training average loss at step 88600: 0.096531\n",
      "2023-12-06 00:07:23,096 INFO     Training average positive_sample_loss at step 88700: 0.109802\n",
      "2023-12-06 00:07:23,097 INFO     Training average negative_sample_loss at step 88700: 0.082939\n",
      "2023-12-06 00:07:23,097 INFO     Training average loss at step 88700: 0.096370\n",
      "2023-12-06 00:07:28,987 INFO     Training average positive_sample_loss at step 88800: 0.109379\n",
      "2023-12-06 00:07:28,987 INFO     Training average negative_sample_loss at step 88800: 0.083638\n",
      "2023-12-06 00:07:28,987 INFO     Training average loss at step 88800: 0.096508\n",
      "2023-12-06 00:07:34,231 INFO     Training average positive_sample_loss at step 88900: 0.109506\n",
      "2023-12-06 00:07:34,231 INFO     Training average negative_sample_loss at step 88900: 0.084185\n",
      "2023-12-06 00:07:34,232 INFO     Training average loss at step 88900: 0.096846\n",
      "2023-12-06 00:07:40,087 INFO     Training average positive_sample_loss at step 89000: 0.110108\n",
      "2023-12-06 00:07:40,088 INFO     Training average negative_sample_loss at step 89000: 0.083407\n",
      "2023-12-06 00:07:40,088 INFO     Training average loss at step 89000: 0.096758\n",
      "2023-12-06 00:07:45,921 INFO     Training average positive_sample_loss at step 89100: 0.109592\n",
      "2023-12-06 00:07:45,922 INFO     Training average negative_sample_loss at step 89100: 0.084078\n",
      "2023-12-06 00:07:45,922 INFO     Training average loss at step 89100: 0.096835\n",
      "2023-12-06 00:07:51,134 INFO     Training average positive_sample_loss at step 89200: 0.109211\n",
      "2023-12-06 00:07:51,134 INFO     Training average negative_sample_loss at step 89200: 0.083093\n",
      "2023-12-06 00:07:51,134 INFO     Training average loss at step 89200: 0.096152\n",
      "2023-12-06 00:07:56,860 INFO     Training average positive_sample_loss at step 89300: 0.109503\n",
      "2023-12-06 00:07:56,861 INFO     Training average negative_sample_loss at step 89300: 0.083453\n",
      "2023-12-06 00:07:56,861 INFO     Training average loss at step 89300: 0.096478\n",
      "2023-12-06 00:08:02,687 INFO     Training average positive_sample_loss at step 89400: 0.109297\n",
      "2023-12-06 00:08:02,687 INFO     Training average negative_sample_loss at step 89400: 0.083874\n",
      "2023-12-06 00:08:02,687 INFO     Training average loss at step 89400: 0.096586\n",
      "2023-12-06 00:08:07,866 INFO     Training average positive_sample_loss at step 89500: 0.110243\n",
      "2023-12-06 00:08:07,866 INFO     Training average negative_sample_loss at step 89500: 0.083973\n",
      "2023-12-06 00:08:07,866 INFO     Training average loss at step 89500: 0.097108\n",
      "2023-12-06 00:08:13,756 INFO     Training average positive_sample_loss at step 89600: 0.109300\n",
      "2023-12-06 00:08:13,756 INFO     Training average negative_sample_loss at step 89600: 0.083378\n",
      "2023-12-06 00:08:13,756 INFO     Training average loss at step 89600: 0.096339\n",
      "2023-12-06 00:08:19,571 INFO     Training average positive_sample_loss at step 89700: 0.109506\n",
      "2023-12-06 00:08:19,571 INFO     Training average negative_sample_loss at step 89700: 0.083877\n",
      "2023-12-06 00:08:19,571 INFO     Training average loss at step 89700: 0.096691\n",
      "2023-12-06 00:08:25,448 INFO     Training average positive_sample_loss at step 89800: 0.109869\n",
      "2023-12-06 00:08:25,448 INFO     Training average negative_sample_loss at step 89800: 0.082311\n",
      "2023-12-06 00:08:25,448 INFO     Training average loss at step 89800: 0.096090\n",
      "2023-12-06 00:08:30,615 INFO     Training average positive_sample_loss at step 89900: 0.108914\n",
      "2023-12-06 00:08:30,615 INFO     Training average negative_sample_loss at step 89900: 0.084023\n",
      "2023-12-06 00:08:30,615 INFO     Training average loss at step 89900: 0.096468\n",
      "2023-12-06 00:08:51,859 INFO     Training average positive_sample_loss at step 90000: 0.109955\n",
      "2023-12-06 00:08:51,860 INFO     Training average negative_sample_loss at step 90000: 0.083681\n",
      "2023-12-06 00:08:51,860 INFO     Training average loss at step 90000: 0.096818\n",
      "2023-12-06 00:08:51,860 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 00:08:52,314 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 00:09:19,574 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 00:09:39,528 INFO     Valid MRR at step 90000: 0.576240\n",
      "2023-12-06 00:09:39,528 INFO     Valid MR at step 90000: 266.473088\n",
      "2023-12-06 00:09:39,528 INFO     Valid HITS@1 at step 90000: 0.509823\n",
      "2023-12-06 00:09:39,528 INFO     Valid HITS@3 at step 90000: 0.603179\n",
      "2023-12-06 00:09:39,528 INFO     Valid HITS@10 at step 90000: 0.706631\n",
      "2023-12-06 00:09:46,067 INFO     Training average positive_sample_loss at step 90100: 0.109569\n",
      "2023-12-06 00:09:46,068 INFO     Training average negative_sample_loss at step 90100: 0.083616\n",
      "2023-12-06 00:09:46,068 INFO     Training average loss at step 90100: 0.096592\n",
      "2023-12-06 00:09:51,243 INFO     Training average positive_sample_loss at step 90200: 0.109767\n",
      "2023-12-06 00:09:51,243 INFO     Training average negative_sample_loss at step 90200: 0.083197\n",
      "2023-12-06 00:09:51,244 INFO     Training average loss at step 90200: 0.096482\n",
      "2023-12-06 00:09:56,753 INFO     Training average positive_sample_loss at step 90300: 0.110031\n",
      "2023-12-06 00:09:56,753 INFO     Training average negative_sample_loss at step 90300: 0.084056\n",
      "2023-12-06 00:09:56,753 INFO     Training average loss at step 90300: 0.097043\n",
      "2023-12-06 00:10:02,295 INFO     Training average positive_sample_loss at step 90400: 0.108479\n",
      "2023-12-06 00:10:02,295 INFO     Training average negative_sample_loss at step 90400: 0.083736\n",
      "2023-12-06 00:10:02,296 INFO     Training average loss at step 90400: 0.096108\n",
      "2023-12-06 00:10:08,117 INFO     Training average positive_sample_loss at step 90500: 0.109923\n",
      "2023-12-06 00:10:08,117 INFO     Training average negative_sample_loss at step 90500: 0.083863\n",
      "2023-12-06 00:10:08,117 INFO     Training average loss at step 90500: 0.096893\n",
      "2023-12-06 00:10:14,171 INFO     Training average positive_sample_loss at step 90600: 0.110256\n",
      "2023-12-06 00:10:14,172 INFO     Training average negative_sample_loss at step 90600: 0.084760\n",
      "2023-12-06 00:10:14,172 INFO     Training average loss at step 90600: 0.097508\n",
      "2023-12-06 00:10:19,356 INFO     Training average positive_sample_loss at step 90700: 0.109583\n",
      "2023-12-06 00:10:19,356 INFO     Training average negative_sample_loss at step 90700: 0.083536\n",
      "2023-12-06 00:10:19,356 INFO     Training average loss at step 90700: 0.096559\n",
      "2023-12-06 00:10:24,617 INFO     Training average positive_sample_loss at step 90800: 0.109881\n",
      "2023-12-06 00:10:24,617 INFO     Training average negative_sample_loss at step 90800: 0.083129\n",
      "2023-12-06 00:10:24,617 INFO     Training average loss at step 90800: 0.096505\n",
      "2023-12-06 00:10:30,848 INFO     Training average positive_sample_loss at step 90900: 0.109113\n",
      "2023-12-06 00:10:30,848 INFO     Training average negative_sample_loss at step 90900: 0.083790\n",
      "2023-12-06 00:10:30,848 INFO     Training average loss at step 90900: 0.096451\n",
      "2023-12-06 00:10:36,119 INFO     Training average positive_sample_loss at step 91000: 0.109352\n",
      "2023-12-06 00:10:36,120 INFO     Training average negative_sample_loss at step 91000: 0.083653\n",
      "2023-12-06 00:10:36,120 INFO     Training average loss at step 91000: 0.096503\n",
      "2023-12-06 00:10:42,119 INFO     Training average positive_sample_loss at step 91100: 0.109833\n",
      "2023-12-06 00:10:42,120 INFO     Training average negative_sample_loss at step 91100: 0.082661\n",
      "2023-12-06 00:10:42,120 INFO     Training average loss at step 91100: 0.096247\n",
      "2023-12-06 00:10:48,015 INFO     Training average positive_sample_loss at step 91200: 0.109324\n",
      "2023-12-06 00:10:48,015 INFO     Training average negative_sample_loss at step 91200: 0.083942\n",
      "2023-12-06 00:10:48,015 INFO     Training average loss at step 91200: 0.096633\n",
      "2023-12-06 00:10:53,420 INFO     Training average positive_sample_loss at step 91300: 0.109972\n",
      "2023-12-06 00:10:53,421 INFO     Training average negative_sample_loss at step 91300: 0.083518\n",
      "2023-12-06 00:10:53,421 INFO     Training average loss at step 91300: 0.096745\n",
      "2023-12-06 00:10:59,467 INFO     Training average positive_sample_loss at step 91400: 0.109237\n",
      "2023-12-06 00:10:59,468 INFO     Training average negative_sample_loss at step 91400: 0.083867\n",
      "2023-12-06 00:10:59,468 INFO     Training average loss at step 91400: 0.096552\n",
      "2023-12-06 00:11:05,472 INFO     Training average positive_sample_loss at step 91500: 0.109356\n",
      "2023-12-06 00:11:05,473 INFO     Training average negative_sample_loss at step 91500: 0.083645\n",
      "2023-12-06 00:11:05,473 INFO     Training average loss at step 91500: 0.096501\n",
      "2023-12-06 00:11:11,621 INFO     Training average positive_sample_loss at step 91600: 0.110028\n",
      "2023-12-06 00:11:11,622 INFO     Training average negative_sample_loss at step 91600: 0.083504\n",
      "2023-12-06 00:11:11,622 INFO     Training average loss at step 91600: 0.096766\n",
      "2023-12-06 00:11:16,964 INFO     Training average positive_sample_loss at step 91700: 0.108408\n",
      "2023-12-06 00:11:16,964 INFO     Training average negative_sample_loss at step 91700: 0.083188\n",
      "2023-12-06 00:11:16,964 INFO     Training average loss at step 91700: 0.095798\n",
      "2023-12-06 00:11:22,893 INFO     Training average positive_sample_loss at step 91800: 0.110530\n",
      "2023-12-06 00:11:22,893 INFO     Training average negative_sample_loss at step 91800: 0.082878\n",
      "2023-12-06 00:11:22,893 INFO     Training average loss at step 91800: 0.096704\n",
      "2023-12-06 00:11:28,737 INFO     Training average positive_sample_loss at step 91900: 0.109755\n",
      "2023-12-06 00:11:28,737 INFO     Training average negative_sample_loss at step 91900: 0.083523\n",
      "2023-12-06 00:11:28,737 INFO     Training average loss at step 91900: 0.096639\n",
      "2023-12-06 00:11:33,976 INFO     Training average positive_sample_loss at step 92000: 0.109461\n",
      "2023-12-06 00:11:33,976 INFO     Training average negative_sample_loss at step 92000: 0.083872\n",
      "2023-12-06 00:11:33,977 INFO     Training average loss at step 92000: 0.096667\n",
      "2023-12-06 00:11:39,889 INFO     Training average positive_sample_loss at step 92100: 0.109829\n",
      "2023-12-06 00:11:39,890 INFO     Training average negative_sample_loss at step 92100: 0.083672\n",
      "2023-12-06 00:11:39,890 INFO     Training average loss at step 92100: 0.096750\n",
      "2023-12-06 00:11:45,635 INFO     Training average positive_sample_loss at step 92200: 0.109304\n",
      "2023-12-06 00:11:45,635 INFO     Training average negative_sample_loss at step 92200: 0.083446\n",
      "2023-12-06 00:11:45,635 INFO     Training average loss at step 92200: 0.096375\n",
      "2023-12-06 00:11:50,808 INFO     Training average positive_sample_loss at step 92300: 0.109494\n",
      "2023-12-06 00:11:50,808 INFO     Training average negative_sample_loss at step 92300: 0.083368\n",
      "2023-12-06 00:11:50,808 INFO     Training average loss at step 92300: 0.096431\n",
      "2023-12-06 00:11:57,043 INFO     Training average positive_sample_loss at step 92400: 0.109512\n",
      "2023-12-06 00:11:57,043 INFO     Training average negative_sample_loss at step 92400: 0.082657\n",
      "2023-12-06 00:11:57,043 INFO     Training average loss at step 92400: 0.096084\n",
      "2023-12-06 00:12:02,669 INFO     Training average positive_sample_loss at step 92500: 0.109125\n",
      "2023-12-06 00:12:02,669 INFO     Training average negative_sample_loss at step 92500: 0.083120\n",
      "2023-12-06 00:12:02,669 INFO     Training average loss at step 92500: 0.096122\n",
      "2023-12-06 00:12:07,922 INFO     Training average positive_sample_loss at step 92600: 0.109780\n",
      "2023-12-06 00:12:07,923 INFO     Training average negative_sample_loss at step 92600: 0.084303\n",
      "2023-12-06 00:12:07,923 INFO     Training average loss at step 92600: 0.097041\n",
      "2023-12-06 00:12:13,775 INFO     Training average positive_sample_loss at step 92700: 0.109249\n",
      "2023-12-06 00:12:13,775 INFO     Training average negative_sample_loss at step 92700: 0.083932\n",
      "2023-12-06 00:12:13,776 INFO     Training average loss at step 92700: 0.096591\n",
      "2023-12-06 00:12:19,693 INFO     Training average positive_sample_loss at step 92800: 0.109738\n",
      "2023-12-06 00:12:19,694 INFO     Training average negative_sample_loss at step 92800: 0.083275\n",
      "2023-12-06 00:12:19,694 INFO     Training average loss at step 92800: 0.096506\n",
      "2023-12-06 00:12:25,657 INFO     Training average positive_sample_loss at step 92900: 0.109502\n",
      "2023-12-06 00:12:25,658 INFO     Training average negative_sample_loss at step 92900: 0.084541\n",
      "2023-12-06 00:12:25,658 INFO     Training average loss at step 92900: 0.097022\n",
      "2023-12-06 00:12:30,970 INFO     Training average positive_sample_loss at step 93000: 0.109255\n",
      "2023-12-06 00:12:30,971 INFO     Training average negative_sample_loss at step 93000: 0.083433\n",
      "2023-12-06 00:12:30,971 INFO     Training average loss at step 93000: 0.096344\n",
      "2023-12-06 00:12:36,425 INFO     Training average positive_sample_loss at step 93100: 0.110076\n",
      "2023-12-06 00:12:36,425 INFO     Training average negative_sample_loss at step 93100: 0.083755\n",
      "2023-12-06 00:12:36,425 INFO     Training average loss at step 93100: 0.096915\n",
      "2023-12-06 00:12:42,786 INFO     Training average positive_sample_loss at step 93200: 0.109041\n",
      "2023-12-06 00:12:42,787 INFO     Training average negative_sample_loss at step 93200: 0.083321\n",
      "2023-12-06 00:12:42,787 INFO     Training average loss at step 93200: 0.096181\n",
      "2023-12-06 00:12:48,130 INFO     Training average positive_sample_loss at step 93300: 0.109649\n",
      "2023-12-06 00:12:48,131 INFO     Training average negative_sample_loss at step 93300: 0.083562\n",
      "2023-12-06 00:12:48,131 INFO     Training average loss at step 93300: 0.096606\n",
      "2023-12-06 00:12:54,435 INFO     Training average positive_sample_loss at step 93400: 0.110177\n",
      "2023-12-06 00:12:54,436 INFO     Training average negative_sample_loss at step 93400: 0.083762\n",
      "2023-12-06 00:12:54,436 INFO     Training average loss at step 93400: 0.096969\n",
      "2023-12-06 00:12:59,864 INFO     Training average positive_sample_loss at step 93500: 0.108829\n",
      "2023-12-06 00:12:59,865 INFO     Training average negative_sample_loss at step 93500: 0.083577\n",
      "2023-12-06 00:12:59,865 INFO     Training average loss at step 93500: 0.096203\n",
      "2023-12-06 00:13:05,560 INFO     Training average positive_sample_loss at step 93600: 0.109755\n",
      "2023-12-06 00:13:05,561 INFO     Training average negative_sample_loss at step 93600: 0.083688\n",
      "2023-12-06 00:13:05,561 INFO     Training average loss at step 93600: 0.096722\n",
      "2023-12-06 00:13:11,484 INFO     Training average positive_sample_loss at step 93700: 0.109165\n",
      "2023-12-06 00:13:11,484 INFO     Training average negative_sample_loss at step 93700: 0.083222\n",
      "2023-12-06 00:13:11,484 INFO     Training average loss at step 93700: 0.096193\n",
      "2023-12-06 00:13:16,668 INFO     Training average positive_sample_loss at step 93800: 0.109535\n",
      "2023-12-06 00:13:16,668 INFO     Training average negative_sample_loss at step 93800: 0.083464\n",
      "2023-12-06 00:13:16,668 INFO     Training average loss at step 93800: 0.096499\n",
      "2023-12-06 00:13:21,929 INFO     Training average positive_sample_loss at step 93900: 0.110241\n",
      "2023-12-06 00:13:21,930 INFO     Training average negative_sample_loss at step 93900: 0.084585\n",
      "2023-12-06 00:13:21,930 INFO     Training average loss at step 93900: 0.097413\n",
      "2023-12-06 00:13:28,177 INFO     Training average positive_sample_loss at step 94000: 0.108761\n",
      "2023-12-06 00:13:28,177 INFO     Training average negative_sample_loss at step 94000: 0.083414\n",
      "2023-12-06 00:13:28,177 INFO     Training average loss at step 94000: 0.096088\n",
      "2023-12-06 00:13:33,408 INFO     Training average positive_sample_loss at step 94100: 0.109869\n",
      "2023-12-06 00:13:33,408 INFO     Training average negative_sample_loss at step 94100: 0.083416\n",
      "2023-12-06 00:13:33,408 INFO     Training average loss at step 94100: 0.096642\n",
      "2023-12-06 00:13:39,760 INFO     Training average positive_sample_loss at step 94200: 0.109691\n",
      "2023-12-06 00:13:39,760 INFO     Training average negative_sample_loss at step 94200: 0.083455\n",
      "2023-12-06 00:13:39,760 INFO     Training average loss at step 94200: 0.096573\n",
      "2023-12-06 00:13:44,946 INFO     Training average positive_sample_loss at step 94300: 0.109185\n",
      "2023-12-06 00:13:44,947 INFO     Training average negative_sample_loss at step 94300: 0.084240\n",
      "2023-12-06 00:13:44,947 INFO     Training average loss at step 94300: 0.096713\n",
      "2023-12-06 00:13:50,145 INFO     Training average positive_sample_loss at step 94400: 0.110153\n",
      "2023-12-06 00:13:50,145 INFO     Training average negative_sample_loss at step 94400: 0.083920\n",
      "2023-12-06 00:13:50,145 INFO     Training average loss at step 94400: 0.097036\n",
      "2023-12-06 00:13:56,209 INFO     Training average positive_sample_loss at step 94500: 0.109041\n",
      "2023-12-06 00:13:56,209 INFO     Training average negative_sample_loss at step 94500: 0.082975\n",
      "2023-12-06 00:13:56,209 INFO     Training average loss at step 94500: 0.096008\n",
      "2023-12-06 00:14:01,672 INFO     Training average positive_sample_loss at step 94600: 0.109510\n",
      "2023-12-06 00:14:01,672 INFO     Training average negative_sample_loss at step 94600: 0.083325\n",
      "2023-12-06 00:14:01,672 INFO     Training average loss at step 94600: 0.096417\n",
      "2023-12-06 00:14:08,123 INFO     Training average positive_sample_loss at step 94700: 0.109884\n",
      "2023-12-06 00:14:08,124 INFO     Training average negative_sample_loss at step 94700: 0.083496\n",
      "2023-12-06 00:14:08,124 INFO     Training average loss at step 94700: 0.096690\n",
      "2023-12-06 00:14:13,314 INFO     Training average positive_sample_loss at step 94800: 0.108906\n",
      "2023-12-06 00:14:13,314 INFO     Training average negative_sample_loss at step 94800: 0.083108\n",
      "2023-12-06 00:14:13,314 INFO     Training average loss at step 94800: 0.096007\n",
      "2023-12-06 00:14:18,643 INFO     Training average positive_sample_loss at step 94900: 0.109982\n",
      "2023-12-06 00:14:18,643 INFO     Training average negative_sample_loss at step 94900: 0.083895\n",
      "2023-12-06 00:14:18,643 INFO     Training average loss at step 94900: 0.096938\n",
      "2023-12-06 00:14:25,400 INFO     Training average positive_sample_loss at step 95000: 0.109165\n",
      "2023-12-06 00:14:25,401 INFO     Training average negative_sample_loss at step 95000: 0.083193\n",
      "2023-12-06 00:14:25,401 INFO     Training average loss at step 95000: 0.096179\n",
      "2023-12-06 00:14:30,562 INFO     Training average positive_sample_loss at step 95100: 0.109391\n",
      "2023-12-06 00:14:30,562 INFO     Training average negative_sample_loss at step 95100: 0.083950\n",
      "2023-12-06 00:14:30,562 INFO     Training average loss at step 95100: 0.096670\n",
      "2023-12-06 00:14:35,863 INFO     Training average positive_sample_loss at step 95200: 0.110166\n",
      "2023-12-06 00:14:35,863 INFO     Training average negative_sample_loss at step 95200: 0.082920\n",
      "2023-12-06 00:14:35,863 INFO     Training average loss at step 95200: 0.096543\n",
      "2023-12-06 00:14:41,790 INFO     Training average positive_sample_loss at step 95300: 0.108770\n",
      "2023-12-06 00:14:41,790 INFO     Training average negative_sample_loss at step 95300: 0.083363\n",
      "2023-12-06 00:14:41,790 INFO     Training average loss at step 95300: 0.096066\n",
      "2023-12-06 00:14:47,658 INFO     Training average positive_sample_loss at step 95400: 0.109627\n",
      "2023-12-06 00:14:47,658 INFO     Training average negative_sample_loss at step 95400: 0.083970\n",
      "2023-12-06 00:14:47,658 INFO     Training average loss at step 95400: 0.096798\n",
      "2023-12-06 00:14:53,715 INFO     Training average positive_sample_loss at step 95500: 0.109881\n",
      "2023-12-06 00:14:53,716 INFO     Training average negative_sample_loss at step 95500: 0.083661\n",
      "2023-12-06 00:14:53,716 INFO     Training average loss at step 95500: 0.096771\n",
      "2023-12-06 00:14:58,934 INFO     Training average positive_sample_loss at step 95600: 0.109715\n",
      "2023-12-06 00:14:58,934 INFO     Training average negative_sample_loss at step 95600: 0.084231\n",
      "2023-12-06 00:14:58,934 INFO     Training average loss at step 95600: 0.096973\n",
      "2023-12-06 00:15:04,503 INFO     Training average positive_sample_loss at step 95700: 0.109450\n",
      "2023-12-06 00:15:04,503 INFO     Training average negative_sample_loss at step 95700: 0.083157\n",
      "2023-12-06 00:15:04,503 INFO     Training average loss at step 95700: 0.096303\n",
      "2023-12-06 00:15:10,842 INFO     Training average positive_sample_loss at step 95800: 0.109300\n",
      "2023-12-06 00:15:10,842 INFO     Training average negative_sample_loss at step 95800: 0.083839\n",
      "2023-12-06 00:15:10,842 INFO     Training average loss at step 95800: 0.096570\n",
      "2023-12-06 00:15:16,194 INFO     Training average positive_sample_loss at step 95900: 0.109456\n",
      "2023-12-06 00:15:16,194 INFO     Training average negative_sample_loss at step 95900: 0.082331\n",
      "2023-12-06 00:15:16,194 INFO     Training average loss at step 95900: 0.095893\n",
      "2023-12-06 00:15:22,169 INFO     Training average positive_sample_loss at step 96000: 0.109524\n",
      "2023-12-06 00:15:22,169 INFO     Training average negative_sample_loss at step 96000: 0.083684\n",
      "2023-12-06 00:15:22,169 INFO     Training average loss at step 96000: 0.096604\n",
      "2023-12-06 00:15:27,828 INFO     Training average positive_sample_loss at step 96100: 0.108967\n",
      "2023-12-06 00:15:27,829 INFO     Training average negative_sample_loss at step 96100: 0.083506\n",
      "2023-12-06 00:15:27,829 INFO     Training average loss at step 96100: 0.096236\n",
      "2023-12-06 00:15:33,081 INFO     Training average positive_sample_loss at step 96200: 0.110103\n",
      "2023-12-06 00:15:33,082 INFO     Training average negative_sample_loss at step 96200: 0.084225\n",
      "2023-12-06 00:15:33,082 INFO     Training average loss at step 96200: 0.097164\n",
      "2023-12-06 00:15:39,278 INFO     Training average positive_sample_loss at step 96300: 0.109370\n",
      "2023-12-06 00:15:39,279 INFO     Training average negative_sample_loss at step 96300: 0.083509\n",
      "2023-12-06 00:15:39,279 INFO     Training average loss at step 96300: 0.096440\n",
      "2023-12-06 00:15:44,496 INFO     Training average positive_sample_loss at step 96400: 0.109592\n",
      "2023-12-06 00:15:44,496 INFO     Training average negative_sample_loss at step 96400: 0.083419\n",
      "2023-12-06 00:15:44,496 INFO     Training average loss at step 96400: 0.096506\n",
      "2023-12-06 00:15:50,516 INFO     Training average positive_sample_loss at step 96500: 0.109990\n",
      "2023-12-06 00:15:50,516 INFO     Training average negative_sample_loss at step 96500: 0.083417\n",
      "2023-12-06 00:15:50,516 INFO     Training average loss at step 96500: 0.096703\n",
      "2023-12-06 00:15:56,119 INFO     Training average positive_sample_loss at step 96600: 0.108870\n",
      "2023-12-06 00:15:56,120 INFO     Training average negative_sample_loss at step 96600: 0.083046\n",
      "2023-12-06 00:15:56,120 INFO     Training average loss at step 96600: 0.095958\n",
      "2023-12-06 00:16:01,668 INFO     Training average positive_sample_loss at step 96700: 0.109989\n",
      "2023-12-06 00:16:01,669 INFO     Training average negative_sample_loss at step 96700: 0.084600\n",
      "2023-12-06 00:16:01,669 INFO     Training average loss at step 96700: 0.097295\n",
      "2023-12-06 00:16:07,787 INFO     Training average positive_sample_loss at step 96800: 0.109264\n",
      "2023-12-06 00:16:07,787 INFO     Training average negative_sample_loss at step 96800: 0.082950\n",
      "2023-12-06 00:16:07,787 INFO     Training average loss at step 96800: 0.096107\n",
      "2023-12-06 00:16:13,042 INFO     Training average positive_sample_loss at step 96900: 0.109012\n",
      "2023-12-06 00:16:13,042 INFO     Training average negative_sample_loss at step 96900: 0.083580\n",
      "2023-12-06 00:16:13,042 INFO     Training average loss at step 96900: 0.096296\n",
      "2023-12-06 00:16:18,649 INFO     Training average positive_sample_loss at step 97000: 0.110349\n",
      "2023-12-06 00:16:18,649 INFO     Training average negative_sample_loss at step 97000: 0.083850\n",
      "2023-12-06 00:16:18,649 INFO     Training average loss at step 97000: 0.097099\n",
      "2023-12-06 00:16:24,799 INFO     Training average positive_sample_loss at step 97100: 0.108795\n",
      "2023-12-06 00:16:24,800 INFO     Training average negative_sample_loss at step 97100: 0.083076\n",
      "2023-12-06 00:16:24,800 INFO     Training average loss at step 97100: 0.095935\n",
      "2023-12-06 00:16:30,463 INFO     Training average positive_sample_loss at step 97200: 0.109755\n",
      "2023-12-06 00:16:30,464 INFO     Training average negative_sample_loss at step 97200: 0.083080\n",
      "2023-12-06 00:16:30,464 INFO     Training average loss at step 97200: 0.096417\n",
      "2023-12-06 00:16:36,814 INFO     Training average positive_sample_loss at step 97300: 0.109829\n",
      "2023-12-06 00:16:36,814 INFO     Training average negative_sample_loss at step 97300: 0.084272\n",
      "2023-12-06 00:16:36,814 INFO     Training average loss at step 97300: 0.097051\n",
      "2023-12-06 00:16:42,262 INFO     Training average positive_sample_loss at step 97400: 0.109009\n",
      "2023-12-06 00:16:42,262 INFO     Training average negative_sample_loss at step 97400: 0.083622\n",
      "2023-12-06 00:16:42,262 INFO     Training average loss at step 97400: 0.096316\n",
      "2023-12-06 00:16:47,558 INFO     Training average positive_sample_loss at step 97500: 0.109772\n",
      "2023-12-06 00:16:47,558 INFO     Training average negative_sample_loss at step 97500: 0.082986\n",
      "2023-12-06 00:16:47,558 INFO     Training average loss at step 97500: 0.096379\n",
      "2023-12-06 00:16:53,788 INFO     Training average positive_sample_loss at step 97600: 0.109331\n",
      "2023-12-06 00:16:53,789 INFO     Training average negative_sample_loss at step 97600: 0.083308\n",
      "2023-12-06 00:16:53,789 INFO     Training average loss at step 97600: 0.096319\n",
      "2023-12-06 00:16:59,532 INFO     Training average positive_sample_loss at step 97700: 0.109566\n",
      "2023-12-06 00:16:59,532 INFO     Training average negative_sample_loss at step 97700: 0.083634\n",
      "2023-12-06 00:16:59,532 INFO     Training average loss at step 97700: 0.096600\n",
      "2023-12-06 00:17:05,705 INFO     Training average positive_sample_loss at step 97800: 0.109458\n",
      "2023-12-06 00:17:05,706 INFO     Training average negative_sample_loss at step 97800: 0.083510\n",
      "2023-12-06 00:17:05,706 INFO     Training average loss at step 97800: 0.096484\n",
      "2023-12-06 00:17:11,009 INFO     Training average positive_sample_loss at step 97900: 0.109487\n",
      "2023-12-06 00:17:11,009 INFO     Training average negative_sample_loss at step 97900: 0.084698\n",
      "2023-12-06 00:17:11,009 INFO     Training average loss at step 97900: 0.097093\n",
      "2023-12-06 00:17:16,685 INFO     Training average positive_sample_loss at step 98000: 0.109465\n",
      "2023-12-06 00:17:16,685 INFO     Training average negative_sample_loss at step 98000: 0.083544\n",
      "2023-12-06 00:17:16,685 INFO     Training average loss at step 98000: 0.096505\n",
      "2023-12-06 00:17:23,258 INFO     Training average positive_sample_loss at step 98100: 0.109643\n",
      "2023-12-06 00:17:23,259 INFO     Training average negative_sample_loss at step 98100: 0.083878\n",
      "2023-12-06 00:17:23,259 INFO     Training average loss at step 98100: 0.096760\n",
      "2023-12-06 00:17:28,435 INFO     Training average positive_sample_loss at step 98200: 0.109562\n",
      "2023-12-06 00:17:28,435 INFO     Training average negative_sample_loss at step 98200: 0.083616\n",
      "2023-12-06 00:17:28,436 INFO     Training average loss at step 98200: 0.096589\n",
      "2023-12-06 00:17:34,688 INFO     Training average positive_sample_loss at step 98300: 0.109682\n",
      "2023-12-06 00:17:34,688 INFO     Training average negative_sample_loss at step 98300: 0.083829\n",
      "2023-12-06 00:17:34,688 INFO     Training average loss at step 98300: 0.096756\n",
      "2023-12-06 00:17:40,102 INFO     Training average positive_sample_loss at step 98400: 0.108714\n",
      "2023-12-06 00:17:40,103 INFO     Training average negative_sample_loss at step 98400: 0.083692\n",
      "2023-12-06 00:17:40,103 INFO     Training average loss at step 98400: 0.096203\n",
      "2023-12-06 00:17:45,316 INFO     Training average positive_sample_loss at step 98500: 0.109455\n",
      "2023-12-06 00:17:45,316 INFO     Training average negative_sample_loss at step 98500: 0.083854\n",
      "2023-12-06 00:17:45,316 INFO     Training average loss at step 98500: 0.096655\n",
      "2023-12-06 00:17:51,778 INFO     Training average positive_sample_loss at step 98600: 0.109745\n",
      "2023-12-06 00:17:51,779 INFO     Training average negative_sample_loss at step 98600: 0.083482\n",
      "2023-12-06 00:17:51,779 INFO     Training average loss at step 98600: 0.096614\n",
      "2023-12-06 00:17:56,970 INFO     Training average positive_sample_loss at step 98700: 0.109572\n",
      "2023-12-06 00:17:56,970 INFO     Training average negative_sample_loss at step 98700: 0.083556\n",
      "2023-12-06 00:17:56,970 INFO     Training average loss at step 98700: 0.096564\n",
      "2023-12-06 00:18:02,262 INFO     Training average positive_sample_loss at step 98800: 0.110018\n",
      "2023-12-06 00:18:02,262 INFO     Training average negative_sample_loss at step 98800: 0.083463\n",
      "2023-12-06 00:18:02,262 INFO     Training average loss at step 98800: 0.096741\n",
      "2023-12-06 00:18:08,283 INFO     Training average positive_sample_loss at step 98900: 0.109328\n",
      "2023-12-06 00:18:08,284 INFO     Training average negative_sample_loss at step 98900: 0.083622\n",
      "2023-12-06 00:18:08,284 INFO     Training average loss at step 98900: 0.096475\n",
      "2023-12-06 00:18:14,086 INFO     Training average positive_sample_loss at step 99000: 0.109382\n",
      "2023-12-06 00:18:14,087 INFO     Training average negative_sample_loss at step 99000: 0.083421\n",
      "2023-12-06 00:18:14,087 INFO     Training average loss at step 99000: 0.096401\n",
      "2023-12-06 00:18:19,850 INFO     Training average positive_sample_loss at step 99100: 0.109135\n",
      "2023-12-06 00:18:19,850 INFO     Training average negative_sample_loss at step 99100: 0.083513\n",
      "2023-12-06 00:18:19,850 INFO     Training average loss at step 99100: 0.096324\n",
      "2023-12-06 00:18:25,169 INFO     Training average positive_sample_loss at step 99200: 0.109243\n",
      "2023-12-06 00:18:25,169 INFO     Training average negative_sample_loss at step 99200: 0.083031\n",
      "2023-12-06 00:18:25,169 INFO     Training average loss at step 99200: 0.096137\n",
      "2023-12-06 00:18:31,007 INFO     Training average positive_sample_loss at step 99300: 0.110075\n",
      "2023-12-06 00:18:31,007 INFO     Training average negative_sample_loss at step 99300: 0.083208\n",
      "2023-12-06 00:18:31,007 INFO     Training average loss at step 99300: 0.096642\n",
      "2023-12-06 00:18:36,982 INFO     Training average positive_sample_loss at step 99400: 0.109135\n",
      "2023-12-06 00:18:36,982 INFO     Training average negative_sample_loss at step 99400: 0.083588\n",
      "2023-12-06 00:18:36,982 INFO     Training average loss at step 99400: 0.096361\n",
      "2023-12-06 00:18:42,201 INFO     Training average positive_sample_loss at step 99500: 0.109613\n",
      "2023-12-06 00:18:42,201 INFO     Training average negative_sample_loss at step 99500: 0.083219\n",
      "2023-12-06 00:18:42,201 INFO     Training average loss at step 99500: 0.096416\n",
      "2023-12-06 00:18:48,270 INFO     Training average positive_sample_loss at step 99600: 0.109664\n",
      "2023-12-06 00:18:48,271 INFO     Training average negative_sample_loss at step 99600: 0.084134\n",
      "2023-12-06 00:18:48,271 INFO     Training average loss at step 99600: 0.096899\n",
      "2023-12-06 00:18:54,173 INFO     Training average positive_sample_loss at step 99700: 0.108633\n",
      "2023-12-06 00:18:54,174 INFO     Training average negative_sample_loss at step 99700: 0.083125\n",
      "2023-12-06 00:18:54,174 INFO     Training average loss at step 99700: 0.095879\n",
      "2023-12-06 00:18:59,422 INFO     Training average positive_sample_loss at step 99800: 0.110010\n",
      "2023-12-06 00:18:59,422 INFO     Training average negative_sample_loss at step 99800: 0.083002\n",
      "2023-12-06 00:18:59,422 INFO     Training average loss at step 99800: 0.096506\n",
      "2023-12-06 00:19:05,440 INFO     Training average positive_sample_loss at step 99900: 0.109161\n",
      "2023-12-06 00:19:05,440 INFO     Training average negative_sample_loss at step 99900: 0.083000\n",
      "2023-12-06 00:19:05,440 INFO     Training average loss at step 99900: 0.096081\n",
      "2023-12-06 00:19:18,781 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 00:19:19,503 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 00:19:51,478 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 00:20:11,394 INFO     Valid MRR at step 99999: 0.576142\n",
      "2023-12-06 00:20:11,395 INFO     Valid MR at step 99999: 266.438911\n",
      "2023-12-06 00:20:11,395 INFO     Valid HITS@1 at step 99999: 0.509141\n",
      "2023-12-06 00:20:11,395 INFO     Valid HITS@3 at step 99999: 0.601405\n",
      "2023-12-06 00:20:11,395 INFO     Valid HITS@10 at step 99999: 0.707347\n",
      "2023-12-06 00:20:11,395 INFO     Evaluating on Test Dataset...\n",
      "2023-12-06 00:20:11,864 INFO     Evaluating the model... (0/4582)\n",
      "2023-12-06 00:20:40,925 INFO     Evaluating the model... (1000/4582)\n",
      "2023-12-06 00:21:09,906 INFO     Evaluating the model... (2000/4582)\n",
      "2023-12-06 00:21:34,659 INFO     Evaluating the model... (3000/4582)\n",
      "2023-12-06 00:21:59,946 INFO     Evaluating the model... (4000/4582)\n",
      "2023-12-06 00:22:15,088 INFO     Test MRR at step 99999: 0.575717\n",
      "2023-12-06 00:22:15,089 INFO     Test MR at step 99999: 252.057334\n",
      "2023-12-06 00:22:15,089 INFO     Test HITS@1 at step 99999: 0.508773\n",
      "2023-12-06 00:22:15,089 INFO     Test HITS@3 at step 99999: 0.600600\n",
      "2023-12-06 00:22:15,089 INFO     Test HITS@10 at step 99999: 0.706563\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE DBpedia15K 0 0 1024 256 1000 9.0 1.0 0.00005 100000 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione: 106 minuti e 47 secondi\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "minutes, seconds = divmod(execution_time, 60)\n",
    "print(f\"Tempo di esecuzione: {int(minutes)} minuti e {int(seconds)} secondi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addestramento di RotatE con Domain * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding_old\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-06 08:10:51,298 INFO     Model: RotatE\n",
      "2023-12-06 08:10:51,298 INFO     Data Path: data/DBpedia15K\n",
      "2023-12-06 08:10:51,298 INFO     #entity: 12863\n",
      "2023-12-06 08:10:51,298 INFO     #relation: 279\n",
      "2023-12-06 08:10:51,784 INFO     #train: 131918\n",
      "2023-12-06 08:10:51,887 INFO     #valid: 14659\n",
      "2023-12-06 08:10:52,169 INFO     #test: 36645\n",
      "2023-12-06 08:10:52,312 INFO     Model Parameter Configuration:\n",
      "2023-12-06 08:10:52,313 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-06 08:10:52,313 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-06 08:10:52,313 INFO     Parameter entity_embedding: torch.Size([12863, 2000]), require_grad = True\n",
      "2023-12-06 08:10:52,313 INFO     Parameter relation_embedding: torch.Size([279, 1000]), require_grad = True\n",
      "2023-12-06 08:10:54,003 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-06 08:10:54,003 INFO     Start Training...\n",
      "2023-12-06 08:10:54,003 INFO     init_step = 0\n",
      "2023-12-06 08:10:54,003 INFO     batch_size = 1024\n",
      "2023-12-06 08:10:54,003 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-06 08:10:54,003 INFO     hidden_dim = 1000\n",
      "2023-12-06 08:10:54,004 INFO     gamma = 9.000000\n",
      "2023-12-06 08:10:54,004 INFO     negative_adversarial_sampling = True\n",
      "2023-12-06 08:10:54,004 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-06 08:10:54,004 INFO     learning_rate = 0\n",
      "2023-12-06 08:11:09,025 INFO     Training average positive_sample_loss at step 0: 2.548851\n",
      "2023-12-06 08:11:09,025 INFO     Training average negative_sample_loss at step 0: 0.083082\n",
      "2023-12-06 08:11:09,025 INFO     Training average loss at step 0: 1.315966\n",
      "2023-12-06 08:11:09,025 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 08:11:09,620 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 08:11:36,956 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 08:11:57,987 INFO     Valid MRR at step 0: 0.006582\n",
      "2023-12-06 08:11:57,987 INFO     Valid MR at step 0: 5441.222764\n",
      "2023-12-06 08:11:57,987 INFO     Valid HITS@1 at step 0: 0.005287\n",
      "2023-12-06 08:11:57,987 INFO     Valid HITS@3 at step 0: 0.005867\n",
      "2023-12-06 08:11:57,987 INFO     Valid HITS@10 at step 0: 0.007367\n",
      "2023-12-06 08:12:24,839 INFO     Training average positive_sample_loss at step 100: 2.079013\n",
      "2023-12-06 08:12:24,839 INFO     Training average negative_sample_loss at step 100: 0.184367\n",
      "2023-12-06 08:12:24,839 INFO     Training average loss at step 100: 1.131690\n",
      "2023-12-06 08:12:50,856 INFO     Training average positive_sample_loss at step 200: 1.193720\n",
      "2023-12-06 08:12:50,856 INFO     Training average negative_sample_loss at step 200: 0.392718\n",
      "2023-12-06 08:12:50,856 INFO     Training average loss at step 200: 0.793219\n",
      "2023-12-06 08:13:19,848 INFO     Training average positive_sample_loss at step 300: 0.803071\n",
      "2023-12-06 08:13:19,849 INFO     Training average negative_sample_loss at step 300: 0.493115\n",
      "2023-12-06 08:13:19,849 INFO     Training average loss at step 300: 0.648093\n",
      "2023-12-06 08:13:44,776 INFO     Training average positive_sample_loss at step 400: 0.651078\n",
      "2023-12-06 08:13:44,776 INFO     Training average negative_sample_loss at step 400: 0.502760\n",
      "2023-12-06 08:13:44,776 INFO     Training average loss at step 400: 0.576919\n",
      "2023-12-06 08:14:10,546 INFO     Training average positive_sample_loss at step 500: 0.604564\n",
      "2023-12-06 08:14:10,546 INFO     Training average negative_sample_loss at step 500: 0.497884\n",
      "2023-12-06 08:14:10,546 INFO     Training average loss at step 500: 0.551224\n",
      "2023-12-06 08:14:40,543 INFO     Training average positive_sample_loss at step 600: 0.526469\n",
      "2023-12-06 08:14:40,543 INFO     Training average negative_sample_loss at step 600: 0.474657\n",
      "2023-12-06 08:14:40,543 INFO     Training average loss at step 600: 0.500563\n",
      "2023-12-06 08:15:04,727 INFO     Training average positive_sample_loss at step 700: 0.518816\n",
      "2023-12-06 08:15:04,727 INFO     Training average negative_sample_loss at step 700: 0.445801\n",
      "2023-12-06 08:15:04,727 INFO     Training average loss at step 700: 0.482309\n",
      "2023-12-06 08:15:32,533 INFO     Training average positive_sample_loss at step 800: 0.491128\n",
      "2023-12-06 08:15:32,534 INFO     Training average negative_sample_loss at step 800: 0.428125\n",
      "2023-12-06 08:15:32,534 INFO     Training average loss at step 800: 0.459626\n",
      "2023-12-06 08:15:57,531 INFO     Training average positive_sample_loss at step 900: 0.460127\n",
      "2023-12-06 08:15:57,534 INFO     Training average negative_sample_loss at step 900: 0.394108\n",
      "2023-12-06 08:15:57,534 INFO     Training average loss at step 900: 0.427117\n",
      "2023-12-06 08:16:23,139 INFO     Training average positive_sample_loss at step 1000: 0.458382\n",
      "2023-12-06 08:16:23,140 INFO     Training average negative_sample_loss at step 1000: 0.376710\n",
      "2023-12-06 08:16:23,140 INFO     Training average loss at step 1000: 0.417546\n",
      "2023-12-06 08:16:51,588 INFO     Training average positive_sample_loss at step 1100: 0.420583\n",
      "2023-12-06 08:16:51,588 INFO     Training average negative_sample_loss at step 1100: 0.356235\n",
      "2023-12-06 08:16:51,588 INFO     Training average loss at step 1100: 0.388409\n",
      "2023-12-06 08:17:16,668 INFO     Training average positive_sample_loss at step 1200: 0.415577\n",
      "2023-12-06 08:17:16,669 INFO     Training average negative_sample_loss at step 1200: 0.333570\n",
      "2023-12-06 08:17:16,669 INFO     Training average loss at step 1200: 0.374573\n",
      "2023-12-06 08:17:45,092 INFO     Training average positive_sample_loss at step 1300: 0.405167\n",
      "2023-12-06 08:17:45,092 INFO     Training average negative_sample_loss at step 1300: 0.321401\n",
      "2023-12-06 08:17:45,092 INFO     Training average loss at step 1300: 0.363284\n",
      "2023-12-06 08:18:10,259 INFO     Training average positive_sample_loss at step 1400: 0.372347\n",
      "2023-12-06 08:18:10,259 INFO     Training average negative_sample_loss at step 1400: 0.299987\n",
      "2023-12-06 08:18:10,259 INFO     Training average loss at step 1400: 0.336167\n",
      "2023-12-06 08:18:34,578 INFO     Training average positive_sample_loss at step 1500: 0.375274\n",
      "2023-12-06 08:18:34,578 INFO     Training average negative_sample_loss at step 1500: 0.287962\n",
      "2023-12-06 08:18:34,579 INFO     Training average loss at step 1500: 0.331618\n",
      "2023-12-06 08:19:03,800 INFO     Training average positive_sample_loss at step 1600: 0.351417\n",
      "2023-12-06 08:19:03,801 INFO     Training average negative_sample_loss at step 1600: 0.276573\n",
      "2023-12-06 08:19:03,801 INFO     Training average loss at step 1600: 0.313995\n",
      "2023-12-06 08:19:28,423 INFO     Training average positive_sample_loss at step 1700: 0.342777\n",
      "2023-12-06 08:19:28,423 INFO     Training average negative_sample_loss at step 1700: 0.259959\n",
      "2023-12-06 08:19:28,423 INFO     Training average loss at step 1700: 0.301368\n",
      "2023-12-06 08:19:53,318 INFO     Training average positive_sample_loss at step 1800: 0.341275\n",
      "2023-12-06 08:19:53,318 INFO     Training average negative_sample_loss at step 1800: 0.253077\n",
      "2023-12-06 08:19:53,318 INFO     Training average loss at step 1800: 0.297176\n",
      "2023-12-06 08:20:22,334 INFO     Training average positive_sample_loss at step 1900: 0.310686\n",
      "2023-12-06 08:20:22,334 INFO     Training average negative_sample_loss at step 1900: 0.239435\n",
      "2023-12-06 08:20:22,334 INFO     Training average loss at step 1900: 0.275061\n",
      "2023-12-06 08:20:47,163 INFO     Training average positive_sample_loss at step 2000: 0.314962\n",
      "2023-12-06 08:20:47,163 INFO     Training average negative_sample_loss at step 2000: 0.230470\n",
      "2023-12-06 08:20:47,163 INFO     Training average loss at step 2000: 0.272716\n",
      "2023-12-06 08:21:15,544 INFO     Training average positive_sample_loss at step 2100: 0.300917\n",
      "2023-12-06 08:21:15,545 INFO     Training average negative_sample_loss at step 2100: 0.225424\n",
      "2023-12-06 08:21:15,545 INFO     Training average loss at step 2100: 0.263171\n",
      "2023-12-06 08:21:40,019 INFO     Training average positive_sample_loss at step 2200: 0.290019\n",
      "2023-12-06 08:21:40,020 INFO     Training average negative_sample_loss at step 2200: 0.212228\n",
      "2023-12-06 08:21:40,020 INFO     Training average loss at step 2200: 0.251124\n",
      "2023-12-06 08:22:04,505 INFO     Training average positive_sample_loss at step 2300: 0.290793\n",
      "2023-12-06 08:22:04,505 INFO     Training average negative_sample_loss at step 2300: 0.208565\n",
      "2023-12-06 08:22:04,505 INFO     Training average loss at step 2300: 0.249679\n",
      "2023-12-06 08:22:32,205 INFO     Training average positive_sample_loss at step 2400: 0.268836\n",
      "2023-12-06 08:22:32,205 INFO     Training average negative_sample_loss at step 2400: 0.200600\n",
      "2023-12-06 08:22:32,205 INFO     Training average loss at step 2400: 0.234718\n",
      "2023-12-06 08:22:56,635 INFO     Training average positive_sample_loss at step 2500: 0.271391\n",
      "2023-12-06 08:22:56,636 INFO     Training average negative_sample_loss at step 2500: 0.192931\n",
      "2023-12-06 08:22:56,636 INFO     Training average loss at step 2500: 0.232161\n",
      "2023-12-06 08:23:24,770 INFO     Training average positive_sample_loss at step 2600: 0.264998\n",
      "2023-12-06 08:23:24,770 INFO     Training average negative_sample_loss at step 2600: 0.190765\n",
      "2023-12-06 08:23:24,770 INFO     Training average loss at step 2600: 0.227882\n",
      "2023-12-06 08:23:52,776 INFO     Training average positive_sample_loss at step 2700: 0.250219\n",
      "2023-12-06 08:23:52,777 INFO     Training average negative_sample_loss at step 2700: 0.180926\n",
      "2023-12-06 08:23:52,777 INFO     Training average loss at step 2700: 0.215572\n",
      "2023-12-06 08:24:18,626 INFO     Training average positive_sample_loss at step 2800: 0.254958\n",
      "2023-12-06 08:24:18,626 INFO     Training average negative_sample_loss at step 2800: 0.178699\n",
      "2023-12-06 08:24:18,626 INFO     Training average loss at step 2800: 0.216828\n",
      "2023-12-06 08:24:48,105 INFO     Training average positive_sample_loss at step 2900: 0.239401\n",
      "2023-12-06 08:24:48,106 INFO     Training average negative_sample_loss at step 2900: 0.174894\n",
      "2023-12-06 08:24:48,106 INFO     Training average loss at step 2900: 0.207148\n",
      "2023-12-06 08:25:13,413 INFO     Training average positive_sample_loss at step 3000: 0.239410\n",
      "2023-12-06 08:25:13,413 INFO     Training average negative_sample_loss at step 3000: 0.168329\n",
      "2023-12-06 08:25:13,413 INFO     Training average loss at step 3000: 0.203869\n",
      "2023-12-06 08:25:41,617 INFO     Training average positive_sample_loss at step 3100: 0.239050\n",
      "2023-12-06 08:25:41,617 INFO     Training average negative_sample_loss at step 3100: 0.167632\n",
      "2023-12-06 08:25:41,617 INFO     Training average loss at step 3100: 0.203341\n",
      "2023-12-06 08:26:07,587 INFO     Training average positive_sample_loss at step 3200: 0.221185\n",
      "2023-12-06 08:26:07,587 INFO     Training average negative_sample_loss at step 3200: 0.160386\n",
      "2023-12-06 08:26:07,587 INFO     Training average loss at step 3200: 0.190785\n",
      "2023-12-06 08:26:32,764 INFO     Training average positive_sample_loss at step 3300: 0.228433\n",
      "2023-12-06 08:26:32,764 INFO     Training average negative_sample_loss at step 3300: 0.158403\n",
      "2023-12-06 08:26:32,764 INFO     Training average loss at step 3300: 0.193418\n",
      "2023-12-06 08:27:00,339 INFO     Training average positive_sample_loss at step 3400: 0.217721\n",
      "2023-12-06 08:27:00,340 INFO     Training average negative_sample_loss at step 3400: 0.157284\n",
      "2023-12-06 08:27:00,340 INFO     Training average loss at step 3400: 0.187502\n",
      "2023-12-06 08:27:25,222 INFO     Training average positive_sample_loss at step 3500: 0.215747\n",
      "2023-12-06 08:27:25,222 INFO     Training average negative_sample_loss at step 3500: 0.150981\n",
      "2023-12-06 08:27:25,222 INFO     Training average loss at step 3500: 0.183364\n",
      "2023-12-06 08:27:49,942 INFO     Training average positive_sample_loss at step 3600: 0.217664\n",
      "2023-12-06 08:27:49,942 INFO     Training average negative_sample_loss at step 3600: 0.150873\n",
      "2023-12-06 08:27:49,942 INFO     Training average loss at step 3600: 0.184268\n",
      "2023-12-06 08:28:18,497 INFO     Training average positive_sample_loss at step 3700: 0.201916\n",
      "2023-12-06 08:28:18,497 INFO     Training average negative_sample_loss at step 3700: 0.146670\n",
      "2023-12-06 08:28:18,497 INFO     Training average loss at step 3700: 0.174293\n",
      "2023-12-06 08:28:44,432 INFO     Training average positive_sample_loss at step 3800: 0.208091\n",
      "2023-12-06 08:28:44,433 INFO     Training average negative_sample_loss at step 3800: 0.144396\n",
      "2023-12-06 08:28:44,433 INFO     Training average loss at step 3800: 0.176243\n",
      "2023-12-06 08:29:14,313 INFO     Training average positive_sample_loss at step 3900: 0.202114\n",
      "2023-12-06 08:29:14,313 INFO     Training average negative_sample_loss at step 3900: 0.144133\n",
      "2023-12-06 08:29:14,313 INFO     Training average loss at step 3900: 0.173124\n",
      "2023-12-06 08:29:41,396 INFO     Training average positive_sample_loss at step 4000: 0.197243\n",
      "2023-12-06 08:29:41,397 INFO     Training average negative_sample_loss at step 4000: 0.139037\n",
      "2023-12-06 08:29:41,397 INFO     Training average loss at step 4000: 0.168140\n",
      "2023-12-06 08:30:05,297 INFO     Training average positive_sample_loss at step 4100: 0.200727\n",
      "2023-12-06 08:30:05,298 INFO     Training average negative_sample_loss at step 4100: 0.139260\n",
      "2023-12-06 08:30:05,298 INFO     Training average loss at step 4100: 0.169994\n",
      "2023-12-06 08:30:34,492 INFO     Training average positive_sample_loss at step 4200: 0.189025\n",
      "2023-12-06 08:30:34,493 INFO     Training average negative_sample_loss at step 4200: 0.136391\n",
      "2023-12-06 08:30:34,493 INFO     Training average loss at step 4200: 0.162708\n",
      "2023-12-06 08:30:59,780 INFO     Training average positive_sample_loss at step 4300: 0.191996\n",
      "2023-12-06 08:30:59,780 INFO     Training average negative_sample_loss at step 4300: 0.134104\n",
      "2023-12-06 08:30:59,780 INFO     Training average loss at step 4300: 0.163050\n",
      "2023-12-06 08:31:29,586 INFO     Training average positive_sample_loss at step 4400: 0.191392\n",
      "2023-12-06 08:31:29,586 INFO     Training average negative_sample_loss at step 4400: 0.134905\n",
      "2023-12-06 08:31:29,586 INFO     Training average loss at step 4400: 0.163149\n",
      "2023-12-06 08:31:54,269 INFO     Training average positive_sample_loss at step 4500: 0.182236\n",
      "2023-12-06 08:31:54,270 INFO     Training average negative_sample_loss at step 4500: 0.130154\n",
      "2023-12-06 08:31:54,270 INFO     Training average loss at step 4500: 0.156195\n",
      "2023-12-06 08:32:19,404 INFO     Training average positive_sample_loss at step 4600: 0.187083\n",
      "2023-12-06 08:32:19,405 INFO     Training average negative_sample_loss at step 4600: 0.130273\n",
      "2023-12-06 08:32:19,405 INFO     Training average loss at step 4600: 0.158678\n",
      "2023-12-06 08:32:47,705 INFO     Training average positive_sample_loss at step 4700: 0.178815\n",
      "2023-12-06 08:32:47,705 INFO     Training average negative_sample_loss at step 4700: 0.129112\n",
      "2023-12-06 08:32:47,706 INFO     Training average loss at step 4700: 0.153963\n",
      "2023-12-06 08:33:13,419 INFO     Training average positive_sample_loss at step 4800: 0.180448\n",
      "2023-12-06 08:33:13,420 INFO     Training average negative_sample_loss at step 4800: 0.126646\n",
      "2023-12-06 08:33:13,420 INFO     Training average loss at step 4800: 0.153547\n",
      "2023-12-06 08:33:38,161 INFO     Training average positive_sample_loss at step 4900: 0.183343\n",
      "2023-12-06 08:33:38,162 INFO     Training average negative_sample_loss at step 4900: 0.127461\n",
      "2023-12-06 08:33:38,162 INFO     Training average loss at step 4900: 0.155402\n",
      "2023-12-06 08:34:07,007 INFO     Training average positive_sample_loss at step 5000: 0.170212\n",
      "2023-12-06 08:34:07,007 INFO     Training average negative_sample_loss at step 5000: 0.124463\n",
      "2023-12-06 08:34:07,007 INFO     Training average loss at step 5000: 0.147338\n",
      "2023-12-06 08:34:33,324 INFO     Training average positive_sample_loss at step 5100: 0.177301\n",
      "2023-12-06 08:34:33,324 INFO     Training average negative_sample_loss at step 5100: 0.123659\n",
      "2023-12-06 08:34:33,324 INFO     Training average loss at step 5100: 0.150480\n",
      "2023-12-06 08:35:01,397 INFO     Training average positive_sample_loss at step 5200: 0.171444\n",
      "2023-12-06 08:35:01,397 INFO     Training average negative_sample_loss at step 5200: 0.123888\n",
      "2023-12-06 08:35:01,398 INFO     Training average loss at step 5200: 0.147666\n",
      "2023-12-06 08:35:25,962 INFO     Training average positive_sample_loss at step 5300: 0.170161\n",
      "2023-12-06 08:35:25,963 INFO     Training average negative_sample_loss at step 5300: 0.120966\n",
      "2023-12-06 08:35:25,963 INFO     Training average loss at step 5300: 0.145564\n",
      "2023-12-06 08:35:50,451 INFO     Training average positive_sample_loss at step 5400: 0.174061\n",
      "2023-12-06 08:35:50,452 INFO     Training average negative_sample_loss at step 5400: 0.121557\n",
      "2023-12-06 08:35:50,452 INFO     Training average loss at step 5400: 0.147809\n",
      "2023-12-06 08:36:19,647 INFO     Training average positive_sample_loss at step 5500: 0.163858\n",
      "2023-12-06 08:36:19,648 INFO     Training average negative_sample_loss at step 5500: 0.120295\n",
      "2023-12-06 08:36:19,648 INFO     Training average loss at step 5500: 0.142077\n",
      "2023-12-06 08:36:45,646 INFO     Training average positive_sample_loss at step 5600: 0.169128\n",
      "2023-12-06 08:36:45,646 INFO     Training average negative_sample_loss at step 5600: 0.118958\n",
      "2023-12-06 08:36:45,646 INFO     Training average loss at step 5600: 0.144043\n",
      "2023-12-06 08:37:15,422 INFO     Training average positive_sample_loss at step 5700: 0.165985\n",
      "2023-12-06 08:37:15,423 INFO     Training average negative_sample_loss at step 5700: 0.119830\n",
      "2023-12-06 08:37:15,423 INFO     Training average loss at step 5700: 0.142908\n",
      "2023-12-06 08:37:40,729 INFO     Training average positive_sample_loss at step 5800: 0.161762\n",
      "2023-12-06 08:37:40,729 INFO     Training average negative_sample_loss at step 5800: 0.115826\n",
      "2023-12-06 08:37:40,729 INFO     Training average loss at step 5800: 0.138794\n",
      "2023-12-06 08:38:05,552 INFO     Training average positive_sample_loss at step 5900: 0.167076\n",
      "2023-12-06 08:38:05,553 INFO     Training average negative_sample_loss at step 5900: 0.118148\n",
      "2023-12-06 08:38:05,553 INFO     Training average loss at step 5900: 0.142612\n",
      "2023-12-06 08:38:35,128 INFO     Training average positive_sample_loss at step 6000: 0.159018\n",
      "2023-12-06 08:38:35,128 INFO     Training average negative_sample_loss at step 6000: 0.116879\n",
      "2023-12-06 08:38:35,128 INFO     Training average loss at step 6000: 0.137949\n",
      "2023-12-06 08:39:01,407 INFO     Training average positive_sample_loss at step 6100: 0.162223\n",
      "2023-12-06 08:39:01,407 INFO     Training average negative_sample_loss at step 6100: 0.114358\n",
      "2023-12-06 08:39:01,407 INFO     Training average loss at step 6100: 0.138290\n",
      "2023-12-06 08:39:30,428 INFO     Training average positive_sample_loss at step 6200: 0.162737\n",
      "2023-12-06 08:39:30,428 INFO     Training average negative_sample_loss at step 6200: 0.116224\n",
      "2023-12-06 08:39:30,428 INFO     Training average loss at step 6200: 0.139480\n",
      "2023-12-06 08:39:56,550 INFO     Training average positive_sample_loss at step 6300: 0.155081\n",
      "2023-12-06 08:39:56,551 INFO     Training average negative_sample_loss at step 6300: 0.114059\n",
      "2023-12-06 08:39:56,551 INFO     Training average loss at step 6300: 0.134570\n",
      "2023-12-06 08:40:22,425 INFO     Training average positive_sample_loss at step 6400: 0.161023\n",
      "2023-12-06 08:40:22,426 INFO     Training average negative_sample_loss at step 6400: 0.113086\n",
      "2023-12-06 08:40:22,426 INFO     Training average loss at step 6400: 0.137054\n",
      "2023-12-06 08:40:50,121 INFO     Training average positive_sample_loss at step 6500: 0.155549\n",
      "2023-12-06 08:40:50,122 INFO     Training average negative_sample_loss at step 6500: 0.114724\n",
      "2023-12-06 08:40:50,122 INFO     Training average loss at step 6500: 0.135136\n",
      "2023-12-06 08:41:14,252 INFO     Training average positive_sample_loss at step 6600: 0.156162\n",
      "2023-12-06 08:41:14,253 INFO     Training average negative_sample_loss at step 6600: 0.111295\n",
      "2023-12-06 08:41:14,253 INFO     Training average loss at step 6600: 0.133729\n",
      "2023-12-06 08:41:39,832 INFO     Training average positive_sample_loss at step 6700: 0.159820\n",
      "2023-12-06 08:41:39,832 INFO     Training average negative_sample_loss at step 6700: 0.113324\n",
      "2023-12-06 08:41:39,832 INFO     Training average loss at step 6700: 0.136572\n",
      "2023-12-06 08:42:10,371 INFO     Training average positive_sample_loss at step 6800: 0.149420\n",
      "2023-12-06 08:42:10,371 INFO     Training average negative_sample_loss at step 6800: 0.111236\n",
      "2023-12-06 08:42:10,371 INFO     Training average loss at step 6800: 0.130328\n",
      "2023-12-06 08:42:35,309 INFO     Training average positive_sample_loss at step 6900: 0.156106\n",
      "2023-12-06 08:42:35,309 INFO     Training average negative_sample_loss at step 6900: 0.110667\n",
      "2023-12-06 08:42:35,309 INFO     Training average loss at step 6900: 0.133387\n",
      "2023-12-06 08:43:02,648 INFO     Training average positive_sample_loss at step 7000: 0.153206\n",
      "2023-12-06 08:43:02,648 INFO     Training average negative_sample_loss at step 7000: 0.112096\n",
      "2023-12-06 08:43:02,648 INFO     Training average loss at step 7000: 0.132651\n",
      "2023-12-06 08:43:28,038 INFO     Training average positive_sample_loss at step 7100: 0.150305\n",
      "2023-12-06 08:43:28,038 INFO     Training average negative_sample_loss at step 7100: 0.108681\n",
      "2023-12-06 08:43:28,038 INFO     Training average loss at step 7100: 0.129493\n",
      "2023-12-06 08:43:55,620 INFO     Training average positive_sample_loss at step 7200: 0.156574\n",
      "2023-12-06 08:43:55,621 INFO     Training average negative_sample_loss at step 7200: 0.110757\n",
      "2023-12-06 08:43:55,621 INFO     Training average loss at step 7200: 0.133666\n",
      "2023-12-06 08:44:24,910 INFO     Training average positive_sample_loss at step 7300: 0.147055\n",
      "2023-12-06 08:44:24,911 INFO     Training average negative_sample_loss at step 7300: 0.109544\n",
      "2023-12-06 08:44:24,911 INFO     Training average loss at step 7300: 0.128300\n",
      "2023-12-06 08:44:49,798 INFO     Training average positive_sample_loss at step 7400: 0.152187\n",
      "2023-12-06 08:44:49,798 INFO     Training average negative_sample_loss at step 7400: 0.108889\n",
      "2023-12-06 08:44:49,798 INFO     Training average loss at step 7400: 0.130538\n",
      "2023-12-06 08:45:18,221 INFO     Training average positive_sample_loss at step 7500: 0.151597\n",
      "2023-12-06 08:45:18,222 INFO     Training average negative_sample_loss at step 7500: 0.110914\n",
      "2023-12-06 08:45:18,222 INFO     Training average loss at step 7500: 0.131255\n",
      "2023-12-06 08:45:43,222 INFO     Training average positive_sample_loss at step 7600: 0.146640\n",
      "2023-12-06 08:45:43,223 INFO     Training average negative_sample_loss at step 7600: 0.106951\n",
      "2023-12-06 08:45:43,223 INFO     Training average loss at step 7600: 0.126795\n",
      "2023-12-06 08:46:08,111 INFO     Training average positive_sample_loss at step 7700: 0.152185\n",
      "2023-12-06 08:46:08,111 INFO     Training average negative_sample_loss at step 7700: 0.108370\n",
      "2023-12-06 08:46:08,111 INFO     Training average loss at step 7700: 0.130277\n",
      "2023-12-06 08:46:36,835 INFO     Training average positive_sample_loss at step 7800: 0.145792\n",
      "2023-12-06 08:46:36,835 INFO     Training average negative_sample_loss at step 7800: 0.109158\n",
      "2023-12-06 08:46:36,835 INFO     Training average loss at step 7800: 0.127475\n",
      "2023-12-06 08:47:02,189 INFO     Training average positive_sample_loss at step 7900: 0.148304\n",
      "2023-12-06 08:47:02,190 INFO     Training average negative_sample_loss at step 7900: 0.106436\n",
      "2023-12-06 08:47:02,190 INFO     Training average loss at step 7900: 0.127370\n",
      "2023-12-06 08:47:34,227 INFO     Training average positive_sample_loss at step 8000: 0.150662\n",
      "2023-12-06 08:47:34,228 INFO     Training average negative_sample_loss at step 8000: 0.108586\n",
      "2023-12-06 08:47:34,228 INFO     Training average loss at step 8000: 0.129624\n",
      "2023-12-06 08:47:59,065 INFO     Training average positive_sample_loss at step 8100: 0.142290\n",
      "2023-12-06 08:47:59,065 INFO     Training average negative_sample_loss at step 8100: 0.105769\n",
      "2023-12-06 08:47:59,065 INFO     Training average loss at step 8100: 0.124030\n",
      "2023-12-06 08:48:22,940 INFO     Training average positive_sample_loss at step 8200: 0.148851\n",
      "2023-12-06 08:48:22,941 INFO     Training average negative_sample_loss at step 8200: 0.106277\n",
      "2023-12-06 08:48:22,941 INFO     Training average loss at step 8200: 0.127564\n",
      "2023-12-06 08:48:51,524 INFO     Training average positive_sample_loss at step 8300: 0.144314\n",
      "2023-12-06 08:48:51,524 INFO     Training average negative_sample_loss at step 8300: 0.107413\n",
      "2023-12-06 08:48:51,525 INFO     Training average loss at step 8300: 0.125864\n",
      "2023-12-06 08:49:15,560 INFO     Training average positive_sample_loss at step 8400: 0.145078\n",
      "2023-12-06 08:49:15,560 INFO     Training average negative_sample_loss at step 8400: 0.104877\n",
      "2023-12-06 08:49:15,560 INFO     Training average loss at step 8400: 0.124977\n",
      "2023-12-06 08:49:40,726 INFO     Training average positive_sample_loss at step 8500: 0.148525\n",
      "2023-12-06 08:49:40,727 INFO     Training average negative_sample_loss at step 8500: 0.106911\n",
      "2023-12-06 08:49:40,727 INFO     Training average loss at step 8500: 0.127718\n",
      "2023-12-06 08:50:09,608 INFO     Training average positive_sample_loss at step 8600: 0.140811\n",
      "2023-12-06 08:50:09,608 INFO     Training average negative_sample_loss at step 8600: 0.105000\n",
      "2023-12-06 08:50:09,609 INFO     Training average loss at step 8600: 0.122905\n",
      "2023-12-06 08:50:34,802 INFO     Training average positive_sample_loss at step 8700: 0.146028\n",
      "2023-12-06 08:50:34,802 INFO     Training average negative_sample_loss at step 8700: 0.105362\n",
      "2023-12-06 08:50:34,802 INFO     Training average loss at step 8700: 0.125695\n",
      "2023-12-06 08:51:03,942 INFO     Training average positive_sample_loss at step 8800: 0.143521\n",
      "2023-12-06 08:51:03,943 INFO     Training average negative_sample_loss at step 8800: 0.106174\n",
      "2023-12-06 08:51:03,943 INFO     Training average loss at step 8800: 0.124848\n",
      "2023-12-06 08:51:29,154 INFO     Training average positive_sample_loss at step 8900: 0.142100\n",
      "2023-12-06 08:51:29,155 INFO     Training average negative_sample_loss at step 8900: 0.103863\n",
      "2023-12-06 08:51:29,155 INFO     Training average loss at step 8900: 0.122981\n",
      "2023-12-06 08:51:53,897 INFO     Training average positive_sample_loss at step 9000: 0.146299\n",
      "2023-12-06 08:51:53,897 INFO     Training average negative_sample_loss at step 9000: 0.104729\n",
      "2023-12-06 08:51:53,897 INFO     Training average loss at step 9000: 0.125514\n",
      "2023-12-06 08:52:22,211 INFO     Training average positive_sample_loss at step 9100: 0.138783\n",
      "2023-12-06 08:52:22,212 INFO     Training average negative_sample_loss at step 9100: 0.104805\n",
      "2023-12-06 08:52:22,212 INFO     Training average loss at step 9100: 0.121794\n",
      "2023-12-06 08:52:48,670 INFO     Training average positive_sample_loss at step 9200: 0.144172\n",
      "2023-12-06 08:52:48,670 INFO     Training average negative_sample_loss at step 9200: 0.103456\n",
      "2023-12-06 08:52:48,670 INFO     Training average loss at step 9200: 0.123814\n",
      "2023-12-06 08:53:18,461 INFO     Training average positive_sample_loss at step 9300: 0.143815\n",
      "2023-12-06 08:53:18,462 INFO     Training average negative_sample_loss at step 9300: 0.105735\n",
      "2023-12-06 08:53:18,462 INFO     Training average loss at step 9300: 0.124775\n",
      "2023-12-06 08:53:43,061 INFO     Training average positive_sample_loss at step 9400: 0.138586\n",
      "2023-12-06 08:53:43,061 INFO     Training average negative_sample_loss at step 9400: 0.102181\n",
      "2023-12-06 08:53:43,061 INFO     Training average loss at step 9400: 0.120383\n",
      "2023-12-06 08:54:08,131 INFO     Training average positive_sample_loss at step 9500: 0.143937\n",
      "2023-12-06 08:54:08,132 INFO     Training average negative_sample_loss at step 9500: 0.103867\n",
      "2023-12-06 08:54:08,132 INFO     Training average loss at step 9500: 0.123902\n",
      "2023-12-06 08:54:36,413 INFO     Training average positive_sample_loss at step 9600: 0.138900\n",
      "2023-12-06 08:54:36,414 INFO     Training average negative_sample_loss at step 9600: 0.103897\n",
      "2023-12-06 08:54:36,414 INFO     Training average loss at step 9600: 0.121399\n",
      "2023-12-06 08:55:00,817 INFO     Training average positive_sample_loss at step 9700: 0.141514\n",
      "2023-12-06 08:55:00,817 INFO     Training average negative_sample_loss at step 9700: 0.102813\n",
      "2023-12-06 08:55:00,817 INFO     Training average loss at step 9700: 0.122163\n",
      "2023-12-06 08:55:26,167 INFO     Training average positive_sample_loss at step 9800: 0.143952\n",
      "2023-12-06 08:55:26,168 INFO     Training average negative_sample_loss at step 9800: 0.103942\n",
      "2023-12-06 08:55:26,168 INFO     Training average loss at step 9800: 0.123947\n",
      "2023-12-06 08:55:55,099 INFO     Training average positive_sample_loss at step 9900: 0.135256\n",
      "2023-12-06 08:55:55,100 INFO     Training average negative_sample_loss at step 9900: 0.101622\n",
      "2023-12-06 08:55:55,100 INFO     Training average loss at step 9900: 0.118439\n",
      "2023-12-06 08:56:40,956 INFO     Training average positive_sample_loss at step 10000: 0.142216\n",
      "2023-12-06 08:56:40,956 INFO     Training average negative_sample_loss at step 10000: 0.102304\n",
      "2023-12-06 08:56:40,956 INFO     Training average loss at step 10000: 0.122260\n",
      "2023-12-06 08:56:40,956 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 08:56:41,541 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 08:57:10,448 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 08:57:30,905 INFO     Valid MRR at step 10000: 0.621822\n",
      "2023-12-06 08:57:30,906 INFO     Valid MR at step 10000: 271.907224\n",
      "2023-12-06 08:57:30,906 INFO     Valid HITS@1 at step 10000: 0.562965\n",
      "2023-12-06 08:57:30,906 INFO     Valid HITS@3 at step 10000: 0.660652\n",
      "2023-12-06 08:57:30,906 INFO     Valid HITS@10 at step 10000: 0.728460\n",
      "2023-12-06 08:57:56,032 INFO     Training average positive_sample_loss at step 10100: 0.138550\n",
      "2023-12-06 08:57:56,032 INFO     Training average negative_sample_loss at step 10100: 0.103491\n",
      "2023-12-06 08:57:56,032 INFO     Training average loss at step 10100: 0.121021\n",
      "2023-12-06 08:58:21,571 INFO     Training average positive_sample_loss at step 10200: 0.138864\n",
      "2023-12-06 08:58:21,572 INFO     Training average negative_sample_loss at step 10200: 0.100704\n",
      "2023-12-06 08:58:21,572 INFO     Training average loss at step 10200: 0.119784\n",
      "2023-12-06 08:58:46,898 INFO     Training average positive_sample_loss at step 10300: 0.142307\n",
      "2023-12-06 08:58:46,898 INFO     Training average negative_sample_loss at step 10300: 0.102930\n",
      "2023-12-06 08:58:46,898 INFO     Training average loss at step 10300: 0.122619\n",
      "2023-12-06 08:59:16,199 INFO     Training average positive_sample_loss at step 10400: 0.134809\n",
      "2023-12-06 08:59:16,200 INFO     Training average negative_sample_loss at step 10400: 0.101979\n",
      "2023-12-06 08:59:16,200 INFO     Training average loss at step 10400: 0.118394\n",
      "2023-12-06 08:59:42,201 INFO     Training average positive_sample_loss at step 10500: 0.140807\n",
      "2023-12-06 08:59:42,201 INFO     Training average negative_sample_loss at step 10500: 0.101630\n",
      "2023-12-06 08:59:42,201 INFO     Training average loss at step 10500: 0.121218\n",
      "2023-12-06 09:00:11,668 INFO     Training average positive_sample_loss at step 10600: 0.138385\n",
      "2023-12-06 09:00:11,668 INFO     Training average negative_sample_loss at step 10600: 0.102356\n",
      "2023-12-06 09:00:11,668 INFO     Training average loss at step 10600: 0.120371\n",
      "2023-12-06 09:00:37,118 INFO     Training average positive_sample_loss at step 10700: 0.135636\n",
      "2023-12-06 09:00:37,118 INFO     Training average negative_sample_loss at step 10700: 0.099757\n",
      "2023-12-06 09:00:37,118 INFO     Training average loss at step 10700: 0.117696\n",
      "2023-12-06 09:01:01,593 INFO     Training average positive_sample_loss at step 10800: 0.141195\n",
      "2023-12-06 09:01:01,594 INFO     Training average negative_sample_loss at step 10800: 0.101522\n",
      "2023-12-06 09:01:01,594 INFO     Training average loss at step 10800: 0.121358\n",
      "2023-12-06 09:01:30,444 INFO     Training average positive_sample_loss at step 10900: 0.134863\n",
      "2023-12-06 09:01:30,444 INFO     Training average negative_sample_loss at step 10900: 0.101675\n",
      "2023-12-06 09:01:30,444 INFO     Training average loss at step 10900: 0.118269\n",
      "2023-12-06 09:01:56,897 INFO     Training average positive_sample_loss at step 11000: 0.139063\n",
      "2023-12-06 09:01:56,898 INFO     Training average negative_sample_loss at step 11000: 0.100244\n",
      "2023-12-06 09:01:56,898 INFO     Training average loss at step 11000: 0.119654\n",
      "2023-12-06 09:02:24,389 INFO     Training average positive_sample_loss at step 11100: 0.139045\n",
      "2023-12-06 09:02:24,390 INFO     Training average negative_sample_loss at step 11100: 0.101846\n",
      "2023-12-06 09:02:24,390 INFO     Training average loss at step 11100: 0.120445\n",
      "2023-12-06 09:02:48,983 INFO     Training average positive_sample_loss at step 11200: 0.133304\n",
      "2023-12-06 09:02:48,984 INFO     Training average negative_sample_loss at step 11200: 0.099686\n",
      "2023-12-06 09:02:48,984 INFO     Training average loss at step 11200: 0.116495\n",
      "2023-12-06 09:03:42,938 INFO     Training average positive_sample_loss at step 11400: 0.134783\n",
      "2023-12-06 09:03:42,938 INFO     Training average negative_sample_loss at step 11400: 0.100652\n",
      "2023-12-06 09:03:42,938 INFO     Training average loss at step 11400: 0.117718\n",
      "2023-12-06 09:04:08,411 INFO     Training average positive_sample_loss at step 11500: 0.136296\n",
      "2023-12-06 09:04:08,412 INFO     Training average negative_sample_loss at step 11500: 0.099417\n",
      "2023-12-06 09:04:08,412 INFO     Training average loss at step 11500: 0.117857\n",
      "2023-12-06 09:04:33,097 INFO     Training average positive_sample_loss at step 11600: 0.139510\n",
      "2023-12-06 09:04:33,098 INFO     Training average negative_sample_loss at step 11600: 0.101070\n",
      "2023-12-06 09:04:33,098 INFO     Training average loss at step 11600: 0.120290\n",
      "2023-12-06 09:05:02,065 INFO     Training average positive_sample_loss at step 11700: 0.132077\n",
      "2023-12-06 09:05:02,065 INFO     Training average negative_sample_loss at step 11700: 0.100049\n",
      "2023-12-06 09:05:02,065 INFO     Training average loss at step 11700: 0.116063\n",
      "2023-12-06 09:05:27,226 INFO     Training average positive_sample_loss at step 11800: 0.138254\n",
      "2023-12-06 09:05:27,226 INFO     Training average negative_sample_loss at step 11800: 0.099364\n",
      "2023-12-06 09:05:27,226 INFO     Training average loss at step 11800: 0.118809\n",
      "2023-12-06 09:05:56,439 INFO     Training average positive_sample_loss at step 11900: 0.134702\n",
      "2023-12-06 09:05:56,439 INFO     Training average negative_sample_loss at step 11900: 0.100615\n",
      "2023-12-06 09:05:56,440 INFO     Training average loss at step 11900: 0.117658\n",
      "2023-12-06 09:06:20,677 INFO     Training average positive_sample_loss at step 12000: 0.134419\n",
      "2023-12-06 09:06:20,678 INFO     Training average negative_sample_loss at step 12000: 0.098751\n",
      "2023-12-06 09:06:20,678 INFO     Training average loss at step 12000: 0.116585\n",
      "2023-12-06 09:06:44,577 INFO     Training average positive_sample_loss at step 12100: 0.138560\n",
      "2023-12-06 09:06:44,578 INFO     Training average negative_sample_loss at step 12100: 0.100507\n",
      "2023-12-06 09:06:44,578 INFO     Training average loss at step 12100: 0.119534\n",
      "2023-12-06 09:07:13,546 INFO     Training average positive_sample_loss at step 12200: 0.131724\n",
      "2023-12-06 09:07:13,547 INFO     Training average negative_sample_loss at step 12200: 0.100007\n",
      "2023-12-06 09:07:13,547 INFO     Training average loss at step 12200: 0.115865\n",
      "2023-12-06 09:07:38,414 INFO     Training average positive_sample_loss at step 12300: 0.136850\n",
      "2023-12-06 09:07:38,414 INFO     Training average negative_sample_loss at step 12300: 0.099616\n",
      "2023-12-06 09:07:38,414 INFO     Training average loss at step 12300: 0.118233\n",
      "2023-12-06 09:08:07,901 INFO     Training average positive_sample_loss at step 12400: 0.135893\n",
      "2023-12-06 09:08:07,901 INFO     Training average negative_sample_loss at step 12400: 0.100622\n",
      "2023-12-06 09:08:07,902 INFO     Training average loss at step 12400: 0.118257\n",
      "2023-12-06 09:08:33,310 INFO     Training average positive_sample_loss at step 12500: 0.132312\n",
      "2023-12-06 09:08:33,310 INFO     Training average negative_sample_loss at step 12500: 0.099222\n",
      "2023-12-06 09:08:33,310 INFO     Training average loss at step 12500: 0.115767\n",
      "2023-12-06 09:08:59,446 INFO     Training average positive_sample_loss at step 12600: 0.137526\n",
      "2023-12-06 09:08:59,447 INFO     Training average negative_sample_loss at step 12600: 0.099281\n",
      "2023-12-06 09:08:59,447 INFO     Training average loss at step 12600: 0.118404\n",
      "2023-12-06 09:09:28,576 INFO     Training average positive_sample_loss at step 12700: 0.131966\n",
      "2023-12-06 09:09:28,577 INFO     Training average negative_sample_loss at step 12700: 0.099251\n",
      "2023-12-06 09:09:28,577 INFO     Training average loss at step 12700: 0.115608\n",
      "2023-12-06 09:09:53,331 INFO     Training average positive_sample_loss at step 12800: 0.134392\n",
      "2023-12-06 09:09:53,332 INFO     Training average negative_sample_loss at step 12800: 0.097479\n",
      "2023-12-06 09:09:53,332 INFO     Training average loss at step 12800: 0.115935\n",
      "2023-12-06 09:10:21,193 INFO     Training average positive_sample_loss at step 12900: 0.137168\n",
      "2023-12-06 09:10:21,194 INFO     Training average negative_sample_loss at step 12900: 0.099794\n",
      "2023-12-06 09:10:21,194 INFO     Training average loss at step 12900: 0.118481\n",
      "2023-12-06 09:10:47,369 INFO     Training average positive_sample_loss at step 13000: 0.129610\n",
      "2023-12-06 09:10:47,369 INFO     Training average negative_sample_loss at step 13000: 0.098230\n",
      "2023-12-06 09:10:47,369 INFO     Training average loss at step 13000: 0.113920\n",
      "2023-12-06 09:11:13,871 INFO     Training average positive_sample_loss at step 13100: 0.136489\n",
      "2023-12-06 09:11:13,871 INFO     Training average negative_sample_loss at step 13100: 0.098966\n",
      "2023-12-06 09:11:13,871 INFO     Training average loss at step 13100: 0.117728\n",
      "2023-12-06 09:11:43,398 INFO     Training average positive_sample_loss at step 13200: 0.132320\n",
      "2023-12-06 09:11:43,398 INFO     Training average negative_sample_loss at step 13200: 0.099331\n",
      "2023-12-06 09:11:43,398 INFO     Training average loss at step 13200: 0.115826\n",
      "2023-12-06 09:12:08,705 INFO     Training average positive_sample_loss at step 13300: 0.133596\n",
      "2023-12-06 09:12:08,705 INFO     Training average negative_sample_loss at step 13300: 0.097917\n",
      "2023-12-06 09:12:08,705 INFO     Training average loss at step 13300: 0.115756\n",
      "2023-12-06 09:12:32,540 INFO     Training average positive_sample_loss at step 13400: 0.136295\n",
      "2023-12-06 09:12:32,541 INFO     Training average negative_sample_loss at step 13400: 0.098824\n",
      "2023-12-06 09:12:32,541 INFO     Training average loss at step 13400: 0.117559\n",
      "2023-12-06 09:13:00,901 INFO     Training average positive_sample_loss at step 13500: 0.129332\n",
      "2023-12-06 09:13:00,902 INFO     Training average negative_sample_loss at step 13500: 0.097955\n",
      "2023-12-06 09:13:00,902 INFO     Training average loss at step 13500: 0.113643\n",
      "2023-12-06 09:13:25,785 INFO     Training average positive_sample_loss at step 13600: 0.134964\n",
      "2023-12-06 09:13:25,786 INFO     Training average negative_sample_loss at step 13600: 0.097600\n",
      "2023-12-06 09:13:25,786 INFO     Training average loss at step 13600: 0.116282\n",
      "2023-12-06 09:13:54,085 INFO     Training average positive_sample_loss at step 13700: 0.132843\n",
      "2023-12-06 09:13:54,086 INFO     Training average negative_sample_loss at step 13700: 0.099041\n",
      "2023-12-06 09:13:54,086 INFO     Training average loss at step 13700: 0.115942\n",
      "2023-12-06 09:14:18,485 INFO     Training average positive_sample_loss at step 13800: 0.131301\n",
      "2023-12-06 09:14:18,486 INFO     Training average negative_sample_loss at step 13800: 0.097102\n",
      "2023-12-06 09:14:18,486 INFO     Training average loss at step 13800: 0.114201\n",
      "2023-12-06 09:14:43,529 INFO     Training average positive_sample_loss at step 13900: 0.135698\n",
      "2023-12-06 09:14:43,529 INFO     Training average negative_sample_loss at step 13900: 0.098563\n",
      "2023-12-06 09:14:43,529 INFO     Training average loss at step 13900: 0.117131\n",
      "2023-12-06 09:15:11,412 INFO     Training average positive_sample_loss at step 14000: 0.129930\n",
      "2023-12-06 09:15:11,412 INFO     Training average negative_sample_loss at step 14000: 0.097734\n",
      "2023-12-06 09:15:11,412 INFO     Training average loss at step 14000: 0.113832\n",
      "2023-12-06 09:15:37,882 INFO     Training average positive_sample_loss at step 14100: 0.134108\n",
      "2023-12-06 09:15:37,882 INFO     Training average negative_sample_loss at step 14100: 0.097818\n",
      "2023-12-06 09:15:37,882 INFO     Training average loss at step 14100: 0.115963\n",
      "2023-12-06 09:16:04,920 INFO     Training average positive_sample_loss at step 14200: 0.134109\n",
      "2023-12-06 09:16:04,921 INFO     Training average negative_sample_loss at step 14200: 0.098691\n",
      "2023-12-06 09:16:04,921 INFO     Training average loss at step 14200: 0.116400\n",
      "2023-12-06 09:16:33,036 INFO     Training average positive_sample_loss at step 14300: 0.129574\n",
      "2023-12-06 09:16:33,037 INFO     Training average negative_sample_loss at step 14300: 0.097745\n",
      "2023-12-06 09:16:33,037 INFO     Training average loss at step 14300: 0.113660\n",
      "2023-12-06 09:16:56,951 INFO     Training average positive_sample_loss at step 14400: 0.134547\n",
      "2023-12-06 09:16:56,951 INFO     Training average negative_sample_loss at step 14400: 0.097232\n",
      "2023-12-06 09:16:56,951 INFO     Training average loss at step 14400: 0.115889\n",
      "2023-12-06 09:17:25,302 INFO     Training average positive_sample_loss at step 14500: 0.129816\n",
      "2023-12-06 09:17:25,302 INFO     Training average negative_sample_loss at step 14500: 0.097745\n",
      "2023-12-06 09:17:25,302 INFO     Training average loss at step 14500: 0.113780\n",
      "2023-12-06 09:17:50,360 INFO     Training average positive_sample_loss at step 14600: 0.132844\n",
      "2023-12-06 09:17:50,361 INFO     Training average negative_sample_loss at step 14600: 0.096868\n",
      "2023-12-06 09:17:50,361 INFO     Training average loss at step 14600: 0.114856\n",
      "2023-12-06 09:18:14,628 INFO     Training average positive_sample_loss at step 14700: 0.135254\n",
      "2023-12-06 09:18:14,628 INFO     Training average negative_sample_loss at step 14700: 0.098497\n",
      "2023-12-06 09:18:14,628 INFO     Training average loss at step 14700: 0.116875\n",
      "2023-12-06 09:18:44,268 INFO     Training average positive_sample_loss at step 14800: 0.127657\n",
      "2023-12-06 09:18:44,268 INFO     Training average negative_sample_loss at step 14800: 0.096506\n",
      "2023-12-06 09:18:44,268 INFO     Training average loss at step 14800: 0.112082\n",
      "2023-12-06 09:19:09,554 INFO     Training average positive_sample_loss at step 14900: 0.134058\n",
      "2023-12-06 09:19:09,554 INFO     Training average negative_sample_loss at step 14900: 0.097585\n",
      "2023-12-06 09:19:09,554 INFO     Training average loss at step 14900: 0.115821\n",
      "2023-12-06 09:19:37,808 INFO     Training average positive_sample_loss at step 15000: 0.130506\n",
      "2023-12-06 09:19:37,808 INFO     Training average negative_sample_loss at step 15000: 0.097848\n",
      "2023-12-06 09:19:37,809 INFO     Training average loss at step 15000: 0.114177\n",
      "2023-12-06 09:20:02,263 INFO     Training average positive_sample_loss at step 15100: 0.130572\n",
      "2023-12-06 09:20:02,263 INFO     Training average negative_sample_loss at step 15100: 0.095903\n",
      "2023-12-06 09:20:02,264 INFO     Training average loss at step 15100: 0.113238\n",
      "2023-12-06 09:20:28,090 INFO     Training average positive_sample_loss at step 15200: 0.134692\n",
      "2023-12-06 09:20:28,090 INFO     Training average negative_sample_loss at step 15200: 0.098306\n",
      "2023-12-06 09:20:28,090 INFO     Training average loss at step 15200: 0.116499\n",
      "2023-12-06 09:20:56,011 INFO     Training average positive_sample_loss at step 15300: 0.128210\n",
      "2023-12-06 09:20:56,011 INFO     Training average negative_sample_loss at step 15300: 0.097713\n",
      "2023-12-06 09:20:56,011 INFO     Training average loss at step 15300: 0.112962\n",
      "2023-12-06 09:21:21,569 INFO     Training average positive_sample_loss at step 15400: 0.133108\n",
      "2023-12-06 09:21:21,570 INFO     Training average negative_sample_loss at step 15400: 0.096659\n",
      "2023-12-06 09:21:21,570 INFO     Training average loss at step 15400: 0.114884\n",
      "2023-12-06 09:21:49,956 INFO     Training average positive_sample_loss at step 15500: 0.131919\n",
      "2023-12-06 09:21:49,956 INFO     Training average negative_sample_loss at step 15500: 0.098109\n",
      "2023-12-06 09:21:49,956 INFO     Training average loss at step 15500: 0.115014\n",
      "2023-12-06 09:22:14,221 INFO     Training average positive_sample_loss at step 15600: 0.128933\n",
      "2023-12-06 09:22:14,222 INFO     Training average negative_sample_loss at step 15600: 0.096006\n",
      "2023-12-06 09:22:14,222 INFO     Training average loss at step 15600: 0.112469\n",
      "2023-12-06 09:22:40,047 INFO     Training average positive_sample_loss at step 15700: 0.133743\n",
      "2023-12-06 09:22:40,048 INFO     Training average negative_sample_loss at step 15700: 0.097042\n",
      "2023-12-06 09:22:40,048 INFO     Training average loss at step 15700: 0.115393\n",
      "2023-12-06 09:23:10,018 INFO     Training average positive_sample_loss at step 15800: 0.127853\n",
      "2023-12-06 09:23:10,019 INFO     Training average negative_sample_loss at step 15800: 0.096802\n",
      "2023-12-06 09:23:10,019 INFO     Training average loss at step 15800: 0.112327\n",
      "2023-12-06 09:23:34,049 INFO     Training average positive_sample_loss at step 15900: 0.131686\n",
      "2023-12-06 09:23:34,050 INFO     Training average negative_sample_loss at step 15900: 0.095705\n",
      "2023-12-06 09:23:34,050 INFO     Training average loss at step 15900: 0.113696\n",
      "2023-12-06 09:24:04,075 INFO     Training average positive_sample_loss at step 16000: 0.133250\n",
      "2023-12-06 09:24:04,075 INFO     Training average negative_sample_loss at step 16000: 0.098098\n",
      "2023-12-06 09:24:04,075 INFO     Training average loss at step 16000: 0.115674\n",
      "2023-12-06 09:24:29,105 INFO     Training average positive_sample_loss at step 16100: 0.126873\n",
      "2023-12-06 09:24:29,105 INFO     Training average negative_sample_loss at step 16100: 0.095381\n",
      "2023-12-06 09:24:29,105 INFO     Training average loss at step 16100: 0.111127\n",
      "2023-12-06 09:24:53,451 INFO     Training average positive_sample_loss at step 16200: 0.132847\n",
      "2023-12-06 09:24:53,452 INFO     Training average negative_sample_loss at step 16200: 0.096287\n",
      "2023-12-06 09:24:53,452 INFO     Training average loss at step 16200: 0.114567\n",
      "2023-12-06 09:25:22,907 INFO     Training average positive_sample_loss at step 16300: 0.128721\n",
      "2023-12-06 09:25:22,907 INFO     Training average negative_sample_loss at step 16300: 0.097174\n",
      "2023-12-06 09:25:22,907 INFO     Training average loss at step 16300: 0.112947\n",
      "2023-12-06 09:25:48,252 INFO     Training average positive_sample_loss at step 16400: 0.130632\n",
      "2023-12-06 09:25:48,253 INFO     Training average negative_sample_loss at step 16400: 0.095206\n",
      "2023-12-06 09:25:48,253 INFO     Training average loss at step 16400: 0.112919\n",
      "2023-12-06 09:26:13,759 INFO     Training average positive_sample_loss at step 16500: 0.133565\n",
      "2023-12-06 09:26:13,759 INFO     Training average negative_sample_loss at step 16500: 0.097330\n",
      "2023-12-06 09:26:13,759 INFO     Training average loss at step 16500: 0.115447\n",
      "2023-12-06 09:26:42,438 INFO     Training average positive_sample_loss at step 16600: 0.126277\n",
      "2023-12-06 09:26:42,438 INFO     Training average negative_sample_loss at step 16600: 0.095909\n",
      "2023-12-06 09:26:42,438 INFO     Training average loss at step 16600: 0.111093\n",
      "2023-12-06 09:27:10,271 INFO     Training average positive_sample_loss at step 16700: 0.131937\n",
      "2023-12-06 09:27:10,272 INFO     Training average negative_sample_loss at step 16700: 0.095504\n",
      "2023-12-06 09:27:10,272 INFO     Training average loss at step 16700: 0.113721\n",
      "2023-12-06 09:27:38,916 INFO     Training average positive_sample_loss at step 16800: 0.129527\n",
      "2023-12-06 09:27:38,916 INFO     Training average negative_sample_loss at step 16800: 0.097013\n",
      "2023-12-06 09:27:38,916 INFO     Training average loss at step 16800: 0.113270\n",
      "2023-12-06 09:28:03,581 INFO     Training average positive_sample_loss at step 16900: 0.128949\n",
      "2023-12-06 09:28:03,582 INFO     Training average negative_sample_loss at step 16900: 0.094894\n",
      "2023-12-06 09:28:03,582 INFO     Training average loss at step 16900: 0.111922\n",
      "2023-12-06 09:28:28,811 INFO     Training average positive_sample_loss at step 17000: 0.132587\n",
      "2023-12-06 09:28:28,811 INFO     Training average negative_sample_loss at step 17000: 0.096191\n",
      "2023-12-06 09:28:28,811 INFO     Training average loss at step 17000: 0.114389\n",
      "2023-12-06 09:28:58,443 INFO     Training average positive_sample_loss at step 17100: 0.126519\n",
      "2023-12-06 09:28:58,443 INFO     Training average negative_sample_loss at step 17100: 0.095947\n",
      "2023-12-06 09:28:58,443 INFO     Training average loss at step 17100: 0.111233\n",
      "2023-12-06 09:29:22,911 INFO     Training average positive_sample_loss at step 17200: 0.130875\n",
      "2023-12-06 09:29:22,911 INFO     Training average negative_sample_loss at step 17200: 0.094870\n",
      "2023-12-06 09:29:22,911 INFO     Training average loss at step 17200: 0.112872\n",
      "2023-12-06 09:29:51,831 INFO     Training average positive_sample_loss at step 17300: 0.131437\n",
      "2023-12-06 09:29:51,831 INFO     Training average negative_sample_loss at step 17300: 0.096925\n",
      "2023-12-06 09:29:51,832 INFO     Training average loss at step 17300: 0.114181\n",
      "2023-12-06 09:30:17,164 INFO     Training average positive_sample_loss at step 17400: 0.127058\n",
      "2023-12-06 09:30:17,164 INFO     Training average negative_sample_loss at step 17400: 0.095512\n",
      "2023-12-06 09:30:17,164 INFO     Training average loss at step 17400: 0.111285\n",
      "2023-12-06 09:30:42,532 INFO     Training average positive_sample_loss at step 17500: 0.132246\n",
      "2023-12-06 09:30:42,533 INFO     Training average negative_sample_loss at step 17500: 0.095803\n",
      "2023-12-06 09:30:42,533 INFO     Training average loss at step 17500: 0.114024\n",
      "2023-12-06 09:31:11,165 INFO     Training average positive_sample_loss at step 17600: 0.127008\n",
      "2023-12-06 09:31:11,165 INFO     Training average negative_sample_loss at step 17600: 0.096609\n",
      "2023-12-06 09:31:11,166 INFO     Training average loss at step 17600: 0.111808\n",
      "2023-12-06 09:31:35,847 INFO     Training average positive_sample_loss at step 17700: 0.130302\n",
      "2023-12-06 09:31:35,847 INFO     Training average negative_sample_loss at step 17700: 0.094912\n",
      "2023-12-06 09:31:35,847 INFO     Training average loss at step 17700: 0.112607\n",
      "2023-12-06 09:32:01,049 INFO     Training average positive_sample_loss at step 17800: 0.132344\n",
      "2023-12-06 09:32:01,049 INFO     Training average negative_sample_loss at step 17800: 0.096639\n",
      "2023-12-06 09:32:01,049 INFO     Training average loss at step 17800: 0.114492\n",
      "2023-12-06 09:32:29,705 INFO     Training average positive_sample_loss at step 17900: 0.125694\n",
      "2023-12-06 09:32:29,705 INFO     Training average negative_sample_loss at step 17900: 0.095512\n",
      "2023-12-06 09:32:29,705 INFO     Training average loss at step 17900: 0.110603\n",
      "2023-12-06 09:32:55,460 INFO     Training average positive_sample_loss at step 18000: 0.131213\n",
      "2023-12-06 09:32:55,460 INFO     Training average negative_sample_loss at step 18000: 0.095546\n",
      "2023-12-06 09:32:55,460 INFO     Training average loss at step 18000: 0.113379\n",
      "2023-12-06 09:33:23,228 INFO     Training average positive_sample_loss at step 18100: 0.127895\n",
      "2023-12-06 09:33:23,229 INFO     Training average negative_sample_loss at step 18100: 0.095851\n",
      "2023-12-06 09:33:23,229 INFO     Training average loss at step 18100: 0.111873\n",
      "2023-12-06 09:33:48,067 INFO     Training average positive_sample_loss at step 18200: 0.128497\n",
      "2023-12-06 09:33:48,068 INFO     Training average negative_sample_loss at step 18200: 0.095111\n",
      "2023-12-06 09:33:48,068 INFO     Training average loss at step 18200: 0.111804\n",
      "2023-12-06 09:34:12,944 INFO     Training average positive_sample_loss at step 18300: 0.132314\n",
      "2023-12-06 09:34:12,944 INFO     Training average negative_sample_loss at step 18300: 0.096510\n",
      "2023-12-06 09:34:12,944 INFO     Training average loss at step 18300: 0.114412\n",
      "2023-12-06 09:34:43,234 INFO     Training average positive_sample_loss at step 18400: 0.125739\n",
      "2023-12-06 09:34:43,235 INFO     Training average negative_sample_loss at step 18400: 0.095086\n",
      "2023-12-06 09:34:43,235 INFO     Training average loss at step 18400: 0.110413\n",
      "2023-12-06 09:35:07,711 INFO     Training average positive_sample_loss at step 18500: 0.130342\n",
      "2023-12-06 09:35:07,711 INFO     Training average negative_sample_loss at step 18500: 0.095012\n",
      "2023-12-06 09:35:07,711 INFO     Training average loss at step 18500: 0.112677\n",
      "2023-12-06 09:35:35,935 INFO     Training average positive_sample_loss at step 18600: 0.128834\n",
      "2023-12-06 09:35:35,935 INFO     Training average negative_sample_loss at step 18600: 0.096665\n",
      "2023-12-06 09:35:35,936 INFO     Training average loss at step 18600: 0.112750\n",
      "2023-12-06 09:36:01,359 INFO     Training average positive_sample_loss at step 18700: 0.127277\n",
      "2023-12-06 09:36:01,360 INFO     Training average negative_sample_loss at step 18700: 0.093864\n",
      "2023-12-06 09:36:01,360 INFO     Training average loss at step 18700: 0.110571\n",
      "2023-12-06 09:36:25,643 INFO     Training average positive_sample_loss at step 18800: 0.131606\n",
      "2023-12-06 09:36:25,644 INFO     Training average negative_sample_loss at step 18800: 0.095334\n",
      "2023-12-06 09:36:25,644 INFO     Training average loss at step 18800: 0.113470\n",
      "2023-12-06 09:36:53,359 INFO     Training average positive_sample_loss at step 18900: 0.125142\n",
      "2023-12-06 09:36:53,359 INFO     Training average negative_sample_loss at step 18900: 0.095432\n",
      "2023-12-06 09:36:53,359 INFO     Training average loss at step 18900: 0.110287\n",
      "2023-12-06 09:37:17,802 INFO     Training average positive_sample_loss at step 19000: 0.130108\n",
      "2023-12-06 09:37:17,802 INFO     Training average negative_sample_loss at step 19000: 0.094811\n",
      "2023-12-06 09:37:17,802 INFO     Training average loss at step 19000: 0.112460\n",
      "2023-12-06 09:37:44,870 INFO     Training average positive_sample_loss at step 19100: 0.130769\n",
      "2023-12-06 09:37:44,871 INFO     Training average negative_sample_loss at step 19100: 0.096627\n",
      "2023-12-06 09:37:44,871 INFO     Training average loss at step 19100: 0.113698\n",
      "2023-12-06 09:38:09,455 INFO     Training average positive_sample_loss at step 19200: 0.125534\n",
      "2023-12-06 09:38:09,456 INFO     Training average negative_sample_loss at step 19200: 0.094220\n",
      "2023-12-06 09:38:09,456 INFO     Training average loss at step 19200: 0.109877\n",
      "2023-12-06 09:38:34,165 INFO     Training average positive_sample_loss at step 19300: 0.131223\n",
      "2023-12-06 09:38:34,166 INFO     Training average negative_sample_loss at step 19300: 0.094779\n",
      "2023-12-06 09:38:34,166 INFO     Training average loss at step 19300: 0.113001\n",
      "2023-12-06 09:39:02,523 INFO     Training average positive_sample_loss at step 19400: 0.126147\n",
      "2023-12-06 09:39:02,524 INFO     Training average negative_sample_loss at step 19400: 0.095948\n",
      "2023-12-06 09:39:02,524 INFO     Training average loss at step 19400: 0.111047\n",
      "2023-12-06 09:39:28,622 INFO     Training average positive_sample_loss at step 19500: 0.128528\n",
      "2023-12-06 09:39:28,622 INFO     Training average negative_sample_loss at step 19500: 0.093811\n",
      "2023-12-06 09:39:28,622 INFO     Training average loss at step 19500: 0.111170\n",
      "2023-12-06 09:39:52,621 INFO     Training average positive_sample_loss at step 19600: 0.131526\n",
      "2023-12-06 09:39:52,621 INFO     Training average negative_sample_loss at step 19600: 0.095726\n",
      "2023-12-06 09:39:52,621 INFO     Training average loss at step 19600: 0.113626\n",
      "2023-12-06 09:40:22,033 INFO     Training average positive_sample_loss at step 19700: 0.124817\n",
      "2023-12-06 09:40:22,033 INFO     Training average negative_sample_loss at step 19700: 0.094111\n",
      "2023-12-06 09:40:22,033 INFO     Training average loss at step 19700: 0.109464\n",
      "2023-12-06 09:40:46,393 INFO     Training average positive_sample_loss at step 19800: 0.129736\n",
      "2023-12-06 09:40:46,393 INFO     Training average negative_sample_loss at step 19800: 0.094229\n",
      "2023-12-06 09:40:46,394 INFO     Training average loss at step 19800: 0.111982\n",
      "2023-12-06 09:41:16,845 INFO     Training average positive_sample_loss at step 19900: 0.127276\n",
      "2023-12-06 09:41:16,845 INFO     Training average negative_sample_loss at step 19900: 0.095158\n",
      "2023-12-06 09:41:16,845 INFO     Training average loss at step 19900: 0.111217\n",
      "2023-12-06 09:41:55,246 INFO     Training average positive_sample_loss at step 20000: 0.127103\n",
      "2023-12-06 09:41:55,246 INFO     Training average negative_sample_loss at step 20000: 0.094104\n",
      "2023-12-06 09:41:55,246 INFO     Training average loss at step 20000: 0.110603\n",
      "2023-12-06 09:41:55,246 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 09:41:55,762 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 09:42:26,442 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 09:42:45,672 INFO     Valid MRR at step 20000: 0.619268\n",
      "2023-12-06 09:42:45,672 INFO     Valid MR at step 20000: 243.849103\n",
      "2023-12-06 09:42:45,672 INFO     Valid HITS@1 at step 20000: 0.558053\n",
      "2023-12-06 09:42:45,672 INFO     Valid HITS@3 at step 20000: 0.649635\n",
      "2023-12-06 09:42:45,673 INFO     Valid HITS@10 at step 20000: 0.741797\n",
      "2023-12-06 09:43:06,890 INFO     Training average positive_sample_loss at step 20100: 0.130854\n",
      "2023-12-06 09:43:06,891 INFO     Training average negative_sample_loss at step 20100: 0.095197\n",
      "2023-12-06 09:43:06,891 INFO     Training average loss at step 20100: 0.113026\n",
      "2023-12-06 09:43:38,855 INFO     Training average positive_sample_loss at step 20200: 0.124570\n",
      "2023-12-06 09:43:38,856 INFO     Training average negative_sample_loss at step 20200: 0.094564\n",
      "2023-12-06 09:43:38,856 INFO     Training average loss at step 20200: 0.109567\n",
      "2023-12-06 09:44:05,047 INFO     Training average positive_sample_loss at step 20300: 0.129695\n",
      "2023-12-06 09:44:05,047 INFO     Training average negative_sample_loss at step 20300: 0.095227\n",
      "2023-12-06 09:44:05,047 INFO     Training average loss at step 20300: 0.112461\n",
      "2023-12-06 09:44:34,966 INFO     Training average positive_sample_loss at step 20400: 0.128493\n",
      "2023-12-06 09:44:34,967 INFO     Training average negative_sample_loss at step 20400: 0.095366\n",
      "2023-12-06 09:44:34,967 INFO     Training average loss at step 20400: 0.111930\n",
      "2023-12-06 09:45:00,489 INFO     Training average positive_sample_loss at step 20500: 0.125631\n",
      "2023-12-06 09:45:00,490 INFO     Training average negative_sample_loss at step 20500: 0.092886\n",
      "2023-12-06 09:45:00,490 INFO     Training average loss at step 20500: 0.109258\n",
      "2023-12-06 09:45:27,086 INFO     Training average positive_sample_loss at step 20600: 0.130215\n",
      "2023-12-06 09:45:27,087 INFO     Training average negative_sample_loss at step 20600: 0.094667\n",
      "2023-12-06 09:45:27,087 INFO     Training average loss at step 20600: 0.112441\n",
      "2023-12-06 09:45:56,518 INFO     Training average positive_sample_loss at step 20700: 0.125078\n",
      "2023-12-06 09:45:56,518 INFO     Training average negative_sample_loss at step 20700: 0.094432\n",
      "2023-12-06 09:45:56,518 INFO     Training average loss at step 20700: 0.109755\n",
      "2023-12-06 09:46:21,920 INFO     Training average positive_sample_loss at step 20800: 0.128542\n",
      "2023-12-06 09:46:21,921 INFO     Training average negative_sample_loss at step 20800: 0.094153\n",
      "2023-12-06 09:46:21,921 INFO     Training average loss at step 20800: 0.111348\n",
      "2023-12-06 09:46:50,533 INFO     Training average positive_sample_loss at step 20900: 0.130086\n",
      "2023-12-06 09:46:50,533 INFO     Training average negative_sample_loss at step 20900: 0.094990\n",
      "2023-12-06 09:46:50,533 INFO     Training average loss at step 20900: 0.112538\n",
      "2023-12-06 09:47:14,414 INFO     Training average positive_sample_loss at step 21000: 0.123843\n",
      "2023-12-06 09:47:14,414 INFO     Training average negative_sample_loss at step 21000: 0.094218\n",
      "2023-12-06 09:47:14,414 INFO     Training average loss at step 21000: 0.109030\n",
      "2023-12-06 09:47:38,952 INFO     Training average positive_sample_loss at step 21100: 0.129949\n",
      "2023-12-06 09:47:38,953 INFO     Training average negative_sample_loss at step 21100: 0.093917\n",
      "2023-12-06 09:47:38,953 INFO     Training average loss at step 21100: 0.111933\n",
      "2023-12-06 09:48:09,261 INFO     Training average positive_sample_loss at step 21200: 0.125960\n",
      "2023-12-06 09:48:09,261 INFO     Training average negative_sample_loss at step 21200: 0.095185\n",
      "2023-12-06 09:48:09,261 INFO     Training average loss at step 21200: 0.110573\n",
      "2023-12-06 09:48:35,703 INFO     Training average positive_sample_loss at step 21300: 0.127258\n",
      "2023-12-06 09:48:35,703 INFO     Training average negative_sample_loss at step 21300: 0.092725\n",
      "2023-12-06 09:48:35,703 INFO     Training average loss at step 21300: 0.109991\n",
      "2023-12-06 09:49:00,562 INFO     Training average positive_sample_loss at step 21400: 0.130369\n",
      "2023-12-06 09:49:00,562 INFO     Training average negative_sample_loss at step 21400: 0.095279\n",
      "2023-12-06 09:49:00,562 INFO     Training average loss at step 21400: 0.112824\n",
      "2023-12-06 09:49:28,425 INFO     Training average positive_sample_loss at step 21500: 0.123684\n",
      "2023-12-06 09:49:28,426 INFO     Training average negative_sample_loss at step 21500: 0.093793\n",
      "2023-12-06 09:49:28,426 INFO     Training average loss at step 21500: 0.108738\n",
      "2023-12-06 09:49:53,277 INFO     Training average positive_sample_loss at step 21600: 0.128882\n",
      "2023-12-06 09:49:53,277 INFO     Training average negative_sample_loss at step 21600: 0.093743\n",
      "2023-12-06 09:49:53,277 INFO     Training average loss at step 21600: 0.111313\n",
      "2023-12-06 09:50:21,018 INFO     Training average positive_sample_loss at step 21700: 0.127176\n",
      "2023-12-06 09:50:21,018 INFO     Training average negative_sample_loss at step 21700: 0.095394\n",
      "2023-12-06 09:50:21,018 INFO     Training average loss at step 21700: 0.111285\n",
      "2023-12-06 09:50:47,156 INFO     Training average positive_sample_loss at step 21800: 0.126240\n",
      "2023-12-06 09:50:47,156 INFO     Training average negative_sample_loss at step 21800: 0.092302\n",
      "2023-12-06 09:50:47,156 INFO     Training average loss at step 21800: 0.109271\n",
      "2023-12-06 09:51:12,200 INFO     Training average positive_sample_loss at step 21900: 0.129559\n",
      "2023-12-06 09:51:12,200 INFO     Training average negative_sample_loss at step 21900: 0.094412\n",
      "2023-12-06 09:51:12,200 INFO     Training average loss at step 21900: 0.111986\n",
      "2023-12-06 09:51:40,428 INFO     Training average positive_sample_loss at step 22000: 0.124622\n",
      "2023-12-06 09:51:40,428 INFO     Training average negative_sample_loss at step 22000: 0.094271\n",
      "2023-12-06 09:51:40,428 INFO     Training average loss at step 22000: 0.109447\n",
      "2023-12-06 09:52:04,588 INFO     Training average positive_sample_loss at step 22100: 0.128470\n",
      "2023-12-06 09:52:04,588 INFO     Training average negative_sample_loss at step 22100: 0.093943\n",
      "2023-12-06 09:52:04,588 INFO     Training average loss at step 22100: 0.111206\n",
      "2023-12-06 09:52:34,620 INFO     Training average positive_sample_loss at step 22200: 0.128017\n",
      "2023-12-06 09:52:34,620 INFO     Training average negative_sample_loss at step 22200: 0.094944\n",
      "2023-12-06 09:52:34,620 INFO     Training average loss at step 22200: 0.111480\n",
      "2023-12-06 09:52:59,047 INFO     Training average positive_sample_loss at step 22300: 0.124522\n",
      "2023-12-06 09:52:59,047 INFO     Training average negative_sample_loss at step 22300: 0.092827\n",
      "2023-12-06 09:52:59,047 INFO     Training average loss at step 22300: 0.108674\n",
      "2023-12-06 09:53:23,428 INFO     Training average positive_sample_loss at step 22400: 0.129244\n",
      "2023-12-06 09:53:23,428 INFO     Training average negative_sample_loss at step 22400: 0.093389\n",
      "2023-12-06 09:53:23,428 INFO     Training average loss at step 22400: 0.111316\n",
      "2023-12-06 09:53:51,942 INFO     Training average positive_sample_loss at step 22500: 0.125000\n",
      "2023-12-06 09:53:51,942 INFO     Training average negative_sample_loss at step 22500: 0.095370\n",
      "2023-12-06 09:53:51,942 INFO     Training average loss at step 22500: 0.110185\n",
      "2023-12-06 09:54:16,404 INFO     Training average positive_sample_loss at step 22600: 0.127723\n",
      "2023-12-06 09:54:16,404 INFO     Training average negative_sample_loss at step 22600: 0.092768\n",
      "2023-12-06 09:54:16,404 INFO     Training average loss at step 22600: 0.110245\n",
      "2023-12-06 09:54:41,657 INFO     Training average positive_sample_loss at step 22700: 0.129702\n",
      "2023-12-06 09:54:41,658 INFO     Training average negative_sample_loss at step 22700: 0.094776\n",
      "2023-12-06 09:54:41,658 INFO     Training average loss at step 22700: 0.112239\n",
      "2023-12-06 09:55:10,049 INFO     Training average positive_sample_loss at step 22800: 0.122268\n",
      "2023-12-06 09:55:10,050 INFO     Training average negative_sample_loss at step 22800: 0.093058\n",
      "2023-12-06 09:55:10,050 INFO     Training average loss at step 22800: 0.107663\n",
      "2023-12-06 09:55:34,692 INFO     Training average positive_sample_loss at step 22900: 0.129166\n",
      "2023-12-06 09:55:34,693 INFO     Training average negative_sample_loss at step 22900: 0.093105\n",
      "2023-12-06 09:55:34,693 INFO     Training average loss at step 22900: 0.111135\n",
      "2023-12-06 09:56:01,778 INFO     Training average positive_sample_loss at step 23000: 0.125962\n",
      "2023-12-06 09:56:01,778 INFO     Training average negative_sample_loss at step 23000: 0.095413\n",
      "2023-12-06 09:56:01,778 INFO     Training average loss at step 23000: 0.110687\n",
      "2023-12-06 09:56:26,654 INFO     Training average positive_sample_loss at step 23100: 0.126347\n",
      "2023-12-06 09:56:26,654 INFO     Training average negative_sample_loss at step 23100: 0.092752\n",
      "2023-12-06 09:56:26,655 INFO     Training average loss at step 23100: 0.109550\n",
      "2023-12-06 09:56:53,398 INFO     Training average positive_sample_loss at step 23200: 0.129662\n",
      "2023-12-06 09:56:53,399 INFO     Training average negative_sample_loss at step 23200: 0.094607\n",
      "2023-12-06 09:56:53,399 INFO     Training average loss at step 23200: 0.112134\n",
      "2023-12-06 09:57:21,056 INFO     Training average positive_sample_loss at step 23300: 0.123217\n",
      "2023-12-06 09:57:21,057 INFO     Training average negative_sample_loss at step 23300: 0.093794\n",
      "2023-12-06 09:57:21,057 INFO     Training average loss at step 23300: 0.108505\n",
      "2023-12-06 09:57:45,483 INFO     Training average positive_sample_loss at step 23400: 0.128412\n",
      "2023-12-06 09:57:45,483 INFO     Training average negative_sample_loss at step 23400: 0.093269\n",
      "2023-12-06 09:57:45,483 INFO     Training average loss at step 23400: 0.110840\n",
      "2023-12-06 09:58:15,787 INFO     Training average positive_sample_loss at step 23500: 0.127344\n",
      "2023-12-06 09:58:15,787 INFO     Training average negative_sample_loss at step 23500: 0.094059\n",
      "2023-12-06 09:58:15,787 INFO     Training average loss at step 23500: 0.110701\n",
      "2023-12-06 09:58:41,707 INFO     Training average positive_sample_loss at step 23600: 0.124949\n",
      "2023-12-06 09:58:41,707 INFO     Training average negative_sample_loss at step 23600: 0.092529\n",
      "2023-12-06 09:58:41,707 INFO     Training average loss at step 23600: 0.108739\n",
      "2023-12-06 09:59:07,643 INFO     Training average positive_sample_loss at step 23700: 0.128240\n",
      "2023-12-06 09:59:07,643 INFO     Training average negative_sample_loss at step 23700: 0.093537\n",
      "2023-12-06 09:59:07,643 INFO     Training average loss at step 23700: 0.110889\n",
      "2023-12-06 09:59:35,094 INFO     Training average positive_sample_loss at step 23800: 0.123579\n",
      "2023-12-06 09:59:35,094 INFO     Training average negative_sample_loss at step 23800: 0.093392\n",
      "2023-12-06 09:59:35,094 INFO     Training average loss at step 23800: 0.108485\n",
      "2023-12-06 10:00:01,120 INFO     Training average positive_sample_loss at step 23900: 0.127299\n",
      "2023-12-06 10:00:01,121 INFO     Training average negative_sample_loss at step 23900: 0.092792\n",
      "2023-12-06 10:00:01,121 INFO     Training average loss at step 23900: 0.110046\n",
      "2023-12-06 10:00:29,064 INFO     Training average positive_sample_loss at step 24000: 0.128806\n",
      "2023-12-06 10:00:29,064 INFO     Training average negative_sample_loss at step 24000: 0.094182\n",
      "2023-12-06 10:00:29,064 INFO     Training average loss at step 24000: 0.111494\n",
      "2023-12-06 10:00:53,906 INFO     Training average positive_sample_loss at step 24100: 0.123768\n",
      "2023-12-06 10:00:53,906 INFO     Training average negative_sample_loss at step 24100: 0.092790\n",
      "2023-12-06 10:00:53,907 INFO     Training average loss at step 24100: 0.108279\n",
      "2023-12-06 10:01:19,398 INFO     Training average positive_sample_loss at step 24200: 0.128378\n",
      "2023-12-06 10:01:19,399 INFO     Training average negative_sample_loss at step 24200: 0.093181\n",
      "2023-12-06 10:01:19,399 INFO     Training average loss at step 24200: 0.110779\n",
      "2023-12-06 10:01:48,812 INFO     Training average positive_sample_loss at step 24300: 0.124217\n",
      "2023-12-06 10:01:48,812 INFO     Training average negative_sample_loss at step 24300: 0.093651\n",
      "2023-12-06 10:01:48,812 INFO     Training average loss at step 24300: 0.108934\n",
      "2023-12-06 10:02:13,976 INFO     Training average positive_sample_loss at step 24400: 0.126390\n",
      "2023-12-06 10:02:13,976 INFO     Training average negative_sample_loss at step 24400: 0.092745\n",
      "2023-12-06 10:02:13,976 INFO     Training average loss at step 24400: 0.109567\n",
      "2023-12-06 10:02:39,007 INFO     Training average positive_sample_loss at step 24500: 0.129040\n",
      "2023-12-06 10:02:39,008 INFO     Training average negative_sample_loss at step 24500: 0.094434\n",
      "2023-12-06 10:02:39,008 INFO     Training average loss at step 24500: 0.111737\n",
      "2023-12-06 10:03:07,931 INFO     Training average positive_sample_loss at step 24600: 0.122437\n",
      "2023-12-06 10:03:07,931 INFO     Training average negative_sample_loss at step 24600: 0.092336\n",
      "2023-12-06 10:03:07,931 INFO     Training average loss at step 24600: 0.107387\n",
      "2023-12-06 10:03:33,300 INFO     Training average positive_sample_loss at step 24700: 0.128369\n",
      "2023-12-06 10:03:33,300 INFO     Training average negative_sample_loss at step 24700: 0.093210\n",
      "2023-12-06 10:03:33,301 INFO     Training average loss at step 24700: 0.110790\n",
      "2023-12-06 10:04:03,357 INFO     Training average positive_sample_loss at step 24800: 0.124914\n",
      "2023-12-06 10:04:03,358 INFO     Training average negative_sample_loss at step 24800: 0.093475\n",
      "2023-12-06 10:04:03,358 INFO     Training average loss at step 24800: 0.109195\n",
      "2023-12-06 10:04:27,919 INFO     Training average positive_sample_loss at step 24900: 0.124899\n",
      "2023-12-06 10:04:27,919 INFO     Training average negative_sample_loss at step 24900: 0.091812\n",
      "2023-12-06 10:04:27,919 INFO     Training average loss at step 24900: 0.108356\n",
      "2023-12-06 10:04:52,494 INFO     Training average positive_sample_loss at step 25000: 0.129403\n",
      "2023-12-06 10:04:52,494 INFO     Training average negative_sample_loss at step 25000: 0.093265\n",
      "2023-12-06 10:04:52,494 INFO     Training average loss at step 25000: 0.111334\n",
      "2023-12-06 10:05:23,951 INFO     Training average positive_sample_loss at step 25100: 0.122821\n",
      "2023-12-06 10:05:23,952 INFO     Training average negative_sample_loss at step 25100: 0.093862\n",
      "2023-12-06 10:05:23,952 INFO     Training average loss at step 25100: 0.108342\n",
      "2023-12-06 10:05:49,231 INFO     Training average positive_sample_loss at step 25200: 0.127199\n",
      "2023-12-06 10:05:49,231 INFO     Training average negative_sample_loss at step 25200: 0.092854\n",
      "2023-12-06 10:05:49,231 INFO     Training average loss at step 25200: 0.110027\n",
      "2023-12-06 10:06:17,231 INFO     Training average positive_sample_loss at step 25300: 0.126965\n",
      "2023-12-06 10:06:17,232 INFO     Training average negative_sample_loss at step 25300: 0.094200\n",
      "2023-12-06 10:06:17,232 INFO     Training average loss at step 25300: 0.110583\n",
      "2023-12-06 10:06:41,931 INFO     Training average positive_sample_loss at step 25400: 0.123406\n",
      "2023-12-06 10:06:41,931 INFO     Training average negative_sample_loss at step 25400: 0.091562\n",
      "2023-12-06 10:06:41,932 INFO     Training average loss at step 25400: 0.107484\n",
      "2023-12-06 10:07:07,557 INFO     Training average positive_sample_loss at step 25500: 0.128580\n",
      "2023-12-06 10:07:07,557 INFO     Training average negative_sample_loss at step 25500: 0.093166\n",
      "2023-12-06 10:07:07,557 INFO     Training average loss at step 25500: 0.110873\n",
      "2023-12-06 10:07:37,099 INFO     Training average positive_sample_loss at step 25600: 0.122938\n",
      "2023-12-06 10:07:37,100 INFO     Training average negative_sample_loss at step 25600: 0.092969\n",
      "2023-12-06 10:07:37,100 INFO     Training average loss at step 25600: 0.107954\n",
      "2023-12-06 10:08:01,883 INFO     Training average positive_sample_loss at step 25700: 0.126263\n",
      "2023-12-06 10:08:01,883 INFO     Training average negative_sample_loss at step 25700: 0.092103\n",
      "2023-12-06 10:08:01,883 INFO     Training average loss at step 25700: 0.109183\n",
      "2023-12-06 10:08:31,990 INFO     Training average positive_sample_loss at step 25800: 0.129267\n",
      "2023-12-06 10:08:31,990 INFO     Training average negative_sample_loss at step 25800: 0.094054\n",
      "2023-12-06 10:08:31,990 INFO     Training average loss at step 25800: 0.111661\n",
      "2023-12-06 10:08:57,120 INFO     Training average positive_sample_loss at step 25900: 0.121926\n",
      "2023-12-06 10:08:57,120 INFO     Training average negative_sample_loss at step 25900: 0.092462\n",
      "2023-12-06 10:08:57,120 INFO     Training average loss at step 25900: 0.107194\n",
      "2023-12-06 10:09:22,699 INFO     Training average positive_sample_loss at step 26000: 0.127692\n",
      "2023-12-06 10:09:22,699 INFO     Training average negative_sample_loss at step 26000: 0.092364\n",
      "2023-12-06 10:09:22,699 INFO     Training average loss at step 26000: 0.110028\n",
      "2023-12-06 10:09:53,117 INFO     Training average positive_sample_loss at step 26100: 0.124445\n",
      "2023-12-06 10:09:53,117 INFO     Training average negative_sample_loss at step 26100: 0.093028\n",
      "2023-12-06 10:09:53,117 INFO     Training average loss at step 26100: 0.108737\n",
      "2023-12-06 10:10:18,248 INFO     Training average positive_sample_loss at step 26200: 0.125212\n",
      "2023-12-06 10:10:18,248 INFO     Training average negative_sample_loss at step 26200: 0.092026\n",
      "2023-12-06 10:10:18,248 INFO     Training average loss at step 26200: 0.108619\n",
      "2023-12-06 10:10:44,813 INFO     Training average positive_sample_loss at step 26300: 0.128191\n",
      "2023-12-06 10:10:44,813 INFO     Training average negative_sample_loss at step 26300: 0.093265\n",
      "2023-12-06 10:10:44,813 INFO     Training average loss at step 26300: 0.110728\n",
      "2023-12-06 10:11:12,232 INFO     Training average positive_sample_loss at step 26400: 0.122042\n",
      "2023-12-06 10:11:12,232 INFO     Training average negative_sample_loss at step 26400: 0.092177\n",
      "2023-12-06 10:11:12,232 INFO     Training average loss at step 26400: 0.107109\n",
      "2023-12-06 10:11:37,175 INFO     Training average positive_sample_loss at step 26500: 0.127315\n",
      "2023-12-06 10:11:37,175 INFO     Training average negative_sample_loss at step 26500: 0.092886\n",
      "2023-12-06 10:11:37,175 INFO     Training average loss at step 26500: 0.110101\n",
      "2023-12-06 10:12:05,358 INFO     Training average positive_sample_loss at step 26600: 0.125941\n",
      "2023-12-06 10:12:05,358 INFO     Training average negative_sample_loss at step 26600: 0.094103\n",
      "2023-12-06 10:12:05,358 INFO     Training average loss at step 26600: 0.110022\n",
      "2023-12-06 10:12:30,048 INFO     Training average positive_sample_loss at step 26700: 0.124177\n",
      "2023-12-06 10:12:30,048 INFO     Training average negative_sample_loss at step 26700: 0.091597\n",
      "2023-12-06 10:12:30,048 INFO     Training average loss at step 26700: 0.107887\n",
      "2023-12-06 10:12:55,325 INFO     Training average positive_sample_loss at step 26800: 0.127913\n",
      "2023-12-06 10:12:55,326 INFO     Training average negative_sample_loss at step 26800: 0.092371\n",
      "2023-12-06 10:12:55,326 INFO     Training average loss at step 26800: 0.110142\n",
      "2023-12-06 10:13:22,965 INFO     Training average positive_sample_loss at step 26900: 0.122490\n",
      "2023-12-06 10:13:22,965 INFO     Training average negative_sample_loss at step 26900: 0.093437\n",
      "2023-12-06 10:13:22,965 INFO     Training average loss at step 26900: 0.107964\n",
      "2023-12-06 10:13:47,180 INFO     Training average positive_sample_loss at step 27000: 0.126925\n",
      "2023-12-06 10:13:47,180 INFO     Training average negative_sample_loss at step 27000: 0.092492\n",
      "2023-12-06 10:13:47,180 INFO     Training average loss at step 27000: 0.109709\n",
      "2023-12-06 10:14:15,217 INFO     Training average positive_sample_loss at step 27100: 0.126952\n",
      "2023-12-06 10:14:15,217 INFO     Training average negative_sample_loss at step 27100: 0.094016\n",
      "2023-12-06 10:14:15,217 INFO     Training average loss at step 27100: 0.110484\n",
      "2023-12-06 10:14:40,115 INFO     Training average positive_sample_loss at step 27200: 0.122654\n",
      "2023-12-06 10:14:40,115 INFO     Training average negative_sample_loss at step 27200: 0.091638\n",
      "2023-12-06 10:14:40,115 INFO     Training average loss at step 27200: 0.107146\n",
      "2023-12-06 10:15:04,585 INFO     Training average positive_sample_loss at step 27300: 0.127722\n",
      "2023-12-06 10:15:04,585 INFO     Training average negative_sample_loss at step 27300: 0.093220\n",
      "2023-12-06 10:15:04,585 INFO     Training average loss at step 27300: 0.110471\n",
      "2023-12-06 10:15:33,809 INFO     Training average positive_sample_loss at step 27400: 0.123303\n",
      "2023-12-06 10:15:33,809 INFO     Training average negative_sample_loss at step 27400: 0.092979\n",
      "2023-12-06 10:15:33,809 INFO     Training average loss at step 27400: 0.108141\n",
      "2023-12-06 10:15:58,817 INFO     Training average positive_sample_loss at step 27500: 0.125724\n",
      "2023-12-06 10:15:58,817 INFO     Training average negative_sample_loss at step 27500: 0.091804\n",
      "2023-12-06 10:15:58,817 INFO     Training average loss at step 27500: 0.108764\n",
      "2023-12-06 10:16:25,908 INFO     Training average positive_sample_loss at step 27600: 0.128522\n",
      "2023-12-06 10:16:25,909 INFO     Training average negative_sample_loss at step 27600: 0.093594\n",
      "2023-12-06 10:16:25,909 INFO     Training average loss at step 27600: 0.111058\n",
      "2023-12-06 10:16:53,932 INFO     Training average positive_sample_loss at step 27700: 0.121872\n",
      "2023-12-06 10:16:53,933 INFO     Training average negative_sample_loss at step 27700: 0.092262\n",
      "2023-12-06 10:16:53,933 INFO     Training average loss at step 27700: 0.107067\n",
      "2023-12-06 10:17:20,201 INFO     Training average positive_sample_loss at step 27800: 0.126754\n",
      "2023-12-06 10:17:20,201 INFO     Training average negative_sample_loss at step 27800: 0.091533\n",
      "2023-12-06 10:17:20,201 INFO     Training average loss at step 27800: 0.109144\n",
      "2023-12-06 10:17:47,986 INFO     Training average positive_sample_loss at step 27900: 0.124350\n",
      "2023-12-06 10:17:47,986 INFO     Training average negative_sample_loss at step 27900: 0.093753\n",
      "2023-12-06 10:17:47,986 INFO     Training average loss at step 27900: 0.109052\n",
      "2023-12-06 10:18:14,020 INFO     Training average positive_sample_loss at step 28000: 0.124504\n",
      "2023-12-06 10:18:14,020 INFO     Training average negative_sample_loss at step 28000: 0.091109\n",
      "2023-12-06 10:18:14,020 INFO     Training average loss at step 28000: 0.107807\n",
      "2023-12-06 10:18:40,017 INFO     Training average positive_sample_loss at step 28100: 0.127853\n",
      "2023-12-06 10:18:40,017 INFO     Training average negative_sample_loss at step 28100: 0.093677\n",
      "2023-12-06 10:18:40,017 INFO     Training average loss at step 28100: 0.110765\n",
      "2023-12-06 10:19:08,438 INFO     Training average positive_sample_loss at step 28200: 0.122885\n",
      "2023-12-06 10:19:08,438 INFO     Training average negative_sample_loss at step 28200: 0.092628\n",
      "2023-12-06 10:19:08,438 INFO     Training average loss at step 28200: 0.107757\n",
      "2023-12-06 10:19:33,843 INFO     Training average positive_sample_loss at step 28300: 0.126090\n",
      "2023-12-06 10:19:33,843 INFO     Training average negative_sample_loss at step 28300: 0.091600\n",
      "2023-12-06 10:19:33,843 INFO     Training average loss at step 28300: 0.108845\n",
      "2023-12-06 10:20:02,330 INFO     Training average positive_sample_loss at step 28400: 0.125785\n",
      "2023-12-06 10:20:02,331 INFO     Training average negative_sample_loss at step 28400: 0.093986\n",
      "2023-12-06 10:20:02,331 INFO     Training average loss at step 28400: 0.109886\n",
      "2023-12-06 10:20:27,121 INFO     Training average positive_sample_loss at step 28500: 0.123400\n",
      "2023-12-06 10:20:27,121 INFO     Training average negative_sample_loss at step 28500: 0.091422\n",
      "2023-12-06 10:20:27,121 INFO     Training average loss at step 28500: 0.107411\n",
      "2023-12-06 10:20:52,205 INFO     Training average positive_sample_loss at step 28600: 0.127806\n",
      "2023-12-06 10:20:52,205 INFO     Training average negative_sample_loss at step 28600: 0.092784\n",
      "2023-12-06 10:20:52,205 INFO     Training average loss at step 28600: 0.110295\n",
      "2023-12-06 10:21:22,509 INFO     Training average positive_sample_loss at step 28700: 0.122065\n",
      "2023-12-06 10:21:22,510 INFO     Training average negative_sample_loss at step 28700: 0.092280\n",
      "2023-12-06 10:21:22,510 INFO     Training average loss at step 28700: 0.107172\n",
      "2023-12-06 10:21:48,472 INFO     Training average positive_sample_loss at step 28800: 0.125769\n",
      "2023-12-06 10:21:48,473 INFO     Training average negative_sample_loss at step 28800: 0.091932\n",
      "2023-12-06 10:21:48,473 INFO     Training average loss at step 28800: 0.108851\n",
      "2023-12-06 10:22:16,526 INFO     Training average positive_sample_loss at step 28900: 0.127563\n",
      "2023-12-06 10:22:16,527 INFO     Training average negative_sample_loss at step 28900: 0.093444\n",
      "2023-12-06 10:22:16,527 INFO     Training average loss at step 28900: 0.110503\n",
      "2023-12-06 10:22:41,035 INFO     Training average positive_sample_loss at step 29000: 0.121386\n",
      "2023-12-06 10:22:41,035 INFO     Training average negative_sample_loss at step 29000: 0.091716\n",
      "2023-12-06 10:22:41,035 INFO     Training average loss at step 29000: 0.106551\n",
      "2023-12-06 10:23:05,674 INFO     Training average positive_sample_loss at step 29100: 0.127287\n",
      "2023-12-06 10:23:05,675 INFO     Training average negative_sample_loss at step 29100: 0.092038\n",
      "2023-12-06 10:23:05,675 INFO     Training average loss at step 29100: 0.109663\n",
      "2023-12-06 10:23:34,300 INFO     Training average positive_sample_loss at step 29200: 0.123563\n",
      "2023-12-06 10:23:34,300 INFO     Training average negative_sample_loss at step 29200: 0.093508\n",
      "2023-12-06 10:23:34,300 INFO     Training average loss at step 29200: 0.108535\n",
      "2023-12-06 10:23:59,332 INFO     Training average positive_sample_loss at step 29300: 0.124844\n",
      "2023-12-06 10:23:59,332 INFO     Training average negative_sample_loss at step 29300: 0.091149\n",
      "2023-12-06 10:23:59,332 INFO     Training average loss at step 29300: 0.107997\n",
      "2023-12-06 10:24:23,501 INFO     Training average positive_sample_loss at step 29400: 0.127833\n",
      "2023-12-06 10:24:23,501 INFO     Training average negative_sample_loss at step 29400: 0.093366\n",
      "2023-12-06 10:24:23,501 INFO     Training average loss at step 29400: 0.110599\n",
      "2023-12-06 10:24:52,835 INFO     Training average positive_sample_loss at step 29500: 0.121353\n",
      "2023-12-06 10:24:52,835 INFO     Training average negative_sample_loss at step 29500: 0.092292\n",
      "2023-12-06 10:24:52,835 INFO     Training average loss at step 29500: 0.106822\n",
      "2023-12-06 10:25:18,656 INFO     Training average positive_sample_loss at step 29600: 0.126794\n",
      "2023-12-06 10:25:18,656 INFO     Training average negative_sample_loss at step 29600: 0.091818\n",
      "2023-12-06 10:25:18,656 INFO     Training average loss at step 29600: 0.109306\n",
      "2023-12-06 10:25:45,794 INFO     Training average positive_sample_loss at step 29700: 0.124261\n",
      "2023-12-06 10:25:45,794 INFO     Training average negative_sample_loss at step 29700: 0.092931\n",
      "2023-12-06 10:25:45,795 INFO     Training average loss at step 29700: 0.108596\n",
      "2023-12-06 10:26:10,729 INFO     Training average positive_sample_loss at step 29800: 0.124071\n",
      "2023-12-06 10:26:10,729 INFO     Training average negative_sample_loss at step 29800: 0.091316\n",
      "2023-12-06 10:26:10,729 INFO     Training average loss at step 29800: 0.107693\n",
      "2023-12-06 10:26:36,938 INFO     Training average positive_sample_loss at step 29900: 0.127216\n",
      "2023-12-06 10:26:36,939 INFO     Training average negative_sample_loss at step 29900: 0.092493\n",
      "2023-12-06 10:26:36,939 INFO     Training average loss at step 29900: 0.109854\n",
      "2023-12-06 10:27:18,439 INFO     Training average positive_sample_loss at step 30000: 0.121836\n",
      "2023-12-06 10:27:18,440 INFO     Training average negative_sample_loss at step 30000: 0.092334\n",
      "2023-12-06 10:27:18,440 INFO     Training average loss at step 30000: 0.107085\n",
      "2023-12-06 10:27:18,440 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 10:27:18,898 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 10:27:49,040 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 10:28:11,261 INFO     Valid MRR at step 30000: 0.621902\n",
      "2023-12-06 10:28:11,261 INFO     Valid MR at step 30000: 239.941947\n",
      "2023-12-06 10:28:11,261 INFO     Valid HITS@1 at step 30000: 0.559281\n",
      "2023-12-06 10:28:11,261 INFO     Valid HITS@3 at step 30000: 0.647964\n",
      "2023-12-06 10:28:11,261 INFO     Valid HITS@10 at step 30000: 0.743468\n",
      "2023-12-06 10:28:32,703 INFO     Training average positive_sample_loss at step 30100: 0.126273\n",
      "2023-12-06 10:28:32,703 INFO     Training average negative_sample_loss at step 30100: 0.092572\n",
      "2023-12-06 10:28:32,703 INFO     Training average loss at step 30100: 0.109423\n",
      "2023-12-06 10:29:03,009 INFO     Training average positive_sample_loss at step 30200: 0.125604\n",
      "2023-12-06 10:29:03,010 INFO     Training average negative_sample_loss at step 30200: 0.093716\n",
      "2023-12-06 10:29:03,010 INFO     Training average loss at step 30200: 0.109660\n",
      "2023-12-06 10:29:27,984 INFO     Training average positive_sample_loss at step 30300: 0.122277\n",
      "2023-12-06 10:29:27,984 INFO     Training average negative_sample_loss at step 30300: 0.090174\n",
      "2023-12-06 10:29:27,984 INFO     Training average loss at step 30300: 0.106226\n",
      "2023-12-06 10:29:53,612 INFO     Training average positive_sample_loss at step 30400: 0.127226\n",
      "2023-12-06 10:29:53,612 INFO     Training average negative_sample_loss at step 30400: 0.092756\n",
      "2023-12-06 10:29:53,612 INFO     Training average loss at step 30400: 0.109991\n",
      "2023-12-06 10:30:21,945 INFO     Training average positive_sample_loss at step 30500: 0.122471\n",
      "2023-12-06 10:30:21,945 INFO     Training average negative_sample_loss at step 30500: 0.092688\n",
      "2023-12-06 10:30:21,945 INFO     Training average loss at step 30500: 0.107580\n",
      "2023-12-06 10:30:47,482 INFO     Training average positive_sample_loss at step 30600: 0.125293\n",
      "2023-12-06 10:30:47,482 INFO     Training average negative_sample_loss at step 30600: 0.091319\n",
      "2023-12-06 10:30:47,482 INFO     Training average loss at step 30600: 0.108306\n",
      "2023-12-06 10:31:12,690 INFO     Training average positive_sample_loss at step 30700: 0.127018\n",
      "2023-12-06 10:31:12,690 INFO     Training average negative_sample_loss at step 30700: 0.092405\n",
      "2023-12-06 10:31:12,690 INFO     Training average loss at step 30700: 0.109712\n",
      "2023-12-06 10:31:40,710 INFO     Training average positive_sample_loss at step 30800: 0.120546\n",
      "2023-12-06 10:31:40,710 INFO     Training average negative_sample_loss at step 30800: 0.091088\n",
      "2023-12-06 10:31:40,710 INFO     Training average loss at step 30800: 0.105817\n",
      "2023-12-06 10:32:06,531 INFO     Training average positive_sample_loss at step 30900: 0.126736\n",
      "2023-12-06 10:32:06,532 INFO     Training average negative_sample_loss at step 30900: 0.091898\n",
      "2023-12-06 10:32:06,532 INFO     Training average loss at step 30900: 0.109317\n",
      "2023-12-06 10:32:34,147 INFO     Training average positive_sample_loss at step 31000: 0.123589\n",
      "2023-12-06 10:32:34,147 INFO     Training average negative_sample_loss at step 31000: 0.092446\n",
      "2023-12-06 10:32:34,147 INFO     Training average loss at step 31000: 0.108018\n",
      "2023-12-06 10:32:59,238 INFO     Training average positive_sample_loss at step 31100: 0.123810\n",
      "2023-12-06 10:32:59,238 INFO     Training average negative_sample_loss at step 31100: 0.091271\n",
      "2023-12-06 10:32:59,238 INFO     Training average loss at step 31100: 0.107540\n",
      "2023-12-06 10:33:26,625 INFO     Training average positive_sample_loss at step 31200: 0.127537\n",
      "2023-12-06 10:33:26,629 INFO     Training average negative_sample_loss at step 31200: 0.092871\n",
      "2023-12-06 10:33:26,629 INFO     Training average loss at step 31200: 0.110204\n",
      "2023-12-06 10:34:00,320 INFO     Training average positive_sample_loss at step 31300: 0.121308\n",
      "2023-12-06 10:34:00,321 INFO     Training average negative_sample_loss at step 31300: 0.091790\n",
      "2023-12-06 10:34:00,321 INFO     Training average loss at step 31300: 0.106549\n",
      "2023-12-06 10:34:25,007 INFO     Training average positive_sample_loss at step 31400: 0.126045\n",
      "2023-12-06 10:34:25,007 INFO     Training average negative_sample_loss at step 31400: 0.091155\n",
      "2023-12-06 10:34:25,007 INFO     Training average loss at step 31400: 0.108600\n",
      "2023-12-06 10:34:54,128 INFO     Training average positive_sample_loss at step 31500: 0.124054\n",
      "2023-12-06 10:34:54,129 INFO     Training average negative_sample_loss at step 31500: 0.092911\n",
      "2023-12-06 10:34:54,129 INFO     Training average loss at step 31500: 0.108482\n",
      "2023-12-06 10:35:19,755 INFO     Training average positive_sample_loss at step 31600: 0.123723\n",
      "2023-12-06 10:35:19,756 INFO     Training average negative_sample_loss at step 31600: 0.091551\n",
      "2023-12-06 10:35:19,756 INFO     Training average loss at step 31600: 0.107637\n",
      "2023-12-06 10:35:44,790 INFO     Training average positive_sample_loss at step 31700: 0.126833\n",
      "2023-12-06 10:35:44,791 INFO     Training average negative_sample_loss at step 31700: 0.092464\n",
      "2023-12-06 10:35:44,791 INFO     Training average loss at step 31700: 0.109648\n",
      "2023-12-06 10:36:14,096 INFO     Training average positive_sample_loss at step 31800: 0.121393\n",
      "2023-12-06 10:36:14,096 INFO     Training average negative_sample_loss at step 31800: 0.091698\n",
      "2023-12-06 10:36:14,096 INFO     Training average loss at step 31800: 0.106546\n",
      "2023-12-06 10:36:38,037 INFO     Training average positive_sample_loss at step 31900: 0.124958\n",
      "2023-12-06 10:36:38,037 INFO     Training average negative_sample_loss at step 31900: 0.091509\n",
      "2023-12-06 10:36:38,037 INFO     Training average loss at step 31900: 0.108234\n",
      "2023-12-06 10:37:06,208 INFO     Training average positive_sample_loss at step 32000: 0.126694\n",
      "2023-12-06 10:37:06,209 INFO     Training average negative_sample_loss at step 32000: 0.093087\n",
      "2023-12-06 10:37:06,209 INFO     Training average loss at step 32000: 0.109890\n",
      "2023-12-06 10:37:31,230 INFO     Training average positive_sample_loss at step 32100: 0.121412\n",
      "2023-12-06 10:37:31,231 INFO     Training average negative_sample_loss at step 32100: 0.091165\n",
      "2023-12-06 10:37:31,231 INFO     Training average loss at step 32100: 0.106289\n",
      "2023-12-06 10:37:56,745 INFO     Training average positive_sample_loss at step 32200: 0.126245\n",
      "2023-12-06 10:37:56,746 INFO     Training average negative_sample_loss at step 32200: 0.091710\n",
      "2023-12-06 10:37:56,746 INFO     Training average loss at step 32200: 0.108978\n",
      "2023-12-06 10:38:25,684 INFO     Training average positive_sample_loss at step 32300: 0.122936\n",
      "2023-12-06 10:38:25,685 INFO     Training average negative_sample_loss at step 32300: 0.092314\n",
      "2023-12-06 10:38:25,685 INFO     Training average loss at step 32300: 0.107625\n",
      "2023-12-06 10:38:51,913 INFO     Training average positive_sample_loss at step 32400: 0.124724\n",
      "2023-12-06 10:38:51,913 INFO     Training average negative_sample_loss at step 32400: 0.090524\n",
      "2023-12-06 10:38:51,913 INFO     Training average loss at step 32400: 0.107624\n",
      "2023-12-06 10:39:17,839 INFO     Training average positive_sample_loss at step 32500: 0.126430\n",
      "2023-12-06 10:39:17,840 INFO     Training average negative_sample_loss at step 32500: 0.092504\n",
      "2023-12-06 10:39:17,840 INFO     Training average loss at step 32500: 0.109467\n",
      "2023-12-06 10:39:48,138 INFO     Training average positive_sample_loss at step 32600: 0.120838\n",
      "2023-12-06 10:39:48,138 INFO     Training average negative_sample_loss at step 32600: 0.090933\n",
      "2023-12-06 10:39:48,139 INFO     Training average loss at step 32600: 0.105886\n",
      "2023-12-06 10:40:13,869 INFO     Training average positive_sample_loss at step 32700: 0.126046\n",
      "2023-12-06 10:40:13,870 INFO     Training average negative_sample_loss at step 32700: 0.091515\n",
      "2023-12-06 10:40:13,870 INFO     Training average loss at step 32700: 0.108781\n",
      "2023-12-06 10:40:41,660 INFO     Training average positive_sample_loss at step 32800: 0.123171\n",
      "2023-12-06 10:40:41,660 INFO     Training average negative_sample_loss at step 32800: 0.092553\n",
      "2023-12-06 10:40:41,660 INFO     Training average loss at step 32800: 0.107862\n",
      "2023-12-06 10:41:06,082 INFO     Training average positive_sample_loss at step 32900: 0.123206\n",
      "2023-12-06 10:41:06,082 INFO     Training average negative_sample_loss at step 32900: 0.090491\n",
      "2023-12-06 10:41:06,082 INFO     Training average loss at step 32900: 0.106849\n",
      "2023-12-06 10:41:31,006 INFO     Training average positive_sample_loss at step 33000: 0.126669\n",
      "2023-12-06 10:41:31,006 INFO     Training average negative_sample_loss at step 33000: 0.092030\n",
      "2023-12-06 10:41:31,006 INFO     Training average loss at step 33000: 0.109349\n",
      "2023-12-06 10:41:58,450 INFO     Training average positive_sample_loss at step 33100: 0.121076\n",
      "2023-12-06 10:41:58,451 INFO     Training average negative_sample_loss at step 33100: 0.090591\n",
      "2023-12-06 10:41:58,451 INFO     Training average loss at step 33100: 0.105833\n",
      "2023-12-06 10:42:23,996 INFO     Training average positive_sample_loss at step 33200: 0.125336\n",
      "2023-12-06 10:42:23,997 INFO     Training average negative_sample_loss at step 33200: 0.091317\n",
      "2023-12-06 10:42:23,997 INFO     Training average loss at step 33200: 0.108327\n",
      "2023-12-06 10:42:52,642 INFO     Training average positive_sample_loss at step 33300: 0.125176\n",
      "2023-12-06 10:42:52,643 INFO     Training average negative_sample_loss at step 33300: 0.092811\n",
      "2023-12-06 10:42:52,643 INFO     Training average loss at step 33300: 0.108994\n",
      "2023-12-06 10:43:18,804 INFO     Training average positive_sample_loss at step 33400: 0.122126\n",
      "2023-12-06 10:43:18,804 INFO     Training average negative_sample_loss at step 33400: 0.090868\n",
      "2023-12-06 10:43:18,805 INFO     Training average loss at step 33400: 0.106497\n",
      "2023-12-06 10:43:44,701 INFO     Training average positive_sample_loss at step 33500: 0.126610\n",
      "2023-12-06 10:43:44,702 INFO     Training average negative_sample_loss at step 33500: 0.091375\n",
      "2023-12-06 10:43:44,702 INFO     Training average loss at step 33500: 0.108993\n",
      "2023-12-06 10:44:13,584 INFO     Training average positive_sample_loss at step 33600: 0.121847\n",
      "2023-12-06 10:44:13,584 INFO     Training average negative_sample_loss at step 33600: 0.092228\n",
      "2023-12-06 10:44:13,584 INFO     Training average loss at step 33600: 0.107037\n",
      "2023-12-06 10:44:39,438 INFO     Training average positive_sample_loss at step 33700: 0.124404\n",
      "2023-12-06 10:44:39,438 INFO     Training average negative_sample_loss at step 33700: 0.090839\n",
      "2023-12-06 10:44:39,438 INFO     Training average loss at step 33700: 0.107621\n",
      "2023-12-06 10:45:09,416 INFO     Training average positive_sample_loss at step 33800: 0.126330\n",
      "2023-12-06 10:45:09,416 INFO     Training average negative_sample_loss at step 33800: 0.092514\n",
      "2023-12-06 10:45:09,417 INFO     Training average loss at step 33800: 0.109422\n",
      "2023-12-06 10:45:33,875 INFO     Training average positive_sample_loss at step 33900: 0.120607\n",
      "2023-12-06 10:45:33,875 INFO     Training average negative_sample_loss at step 33900: 0.091244\n",
      "2023-12-06 10:45:33,875 INFO     Training average loss at step 33900: 0.105925\n",
      "2023-12-06 10:45:58,153 INFO     Training average positive_sample_loss at step 34000: 0.125938\n",
      "2023-12-06 10:45:58,153 INFO     Training average negative_sample_loss at step 34000: 0.090586\n",
      "2023-12-06 10:45:58,153 INFO     Training average loss at step 34000: 0.108262\n",
      "2023-12-06 10:46:26,428 INFO     Training average positive_sample_loss at step 34100: 0.122432\n",
      "2023-12-06 10:46:26,429 INFO     Training average negative_sample_loss at step 34100: 0.092592\n",
      "2023-12-06 10:46:26,429 INFO     Training average loss at step 34100: 0.107512\n",
      "2023-12-06 10:46:51,795 INFO     Training average positive_sample_loss at step 34200: 0.123881\n",
      "2023-12-06 10:46:51,795 INFO     Training average negative_sample_loss at step 34200: 0.090713\n",
      "2023-12-06 10:46:51,795 INFO     Training average loss at step 34200: 0.107297\n",
      "2023-12-06 10:47:17,150 INFO     Training average positive_sample_loss at step 34300: 0.127064\n",
      "2023-12-06 10:47:17,150 INFO     Training average negative_sample_loss at step 34300: 0.092371\n",
      "2023-12-06 10:47:17,150 INFO     Training average loss at step 34300: 0.109717\n",
      "2023-12-06 10:47:45,552 INFO     Training average positive_sample_loss at step 34400: 0.120534\n",
      "2023-12-06 10:47:45,553 INFO     Training average negative_sample_loss at step 34400: 0.091724\n",
      "2023-12-06 10:47:45,553 INFO     Training average loss at step 34400: 0.106129\n",
      "2023-12-06 10:48:11,319 INFO     Training average positive_sample_loss at step 34500: 0.125320\n",
      "2023-12-06 10:48:11,319 INFO     Training average negative_sample_loss at step 34500: 0.090897\n",
      "2023-12-06 10:48:11,319 INFO     Training average loss at step 34500: 0.108109\n",
      "2023-12-06 10:48:39,845 INFO     Training average positive_sample_loss at step 34600: 0.124439\n",
      "2023-12-06 10:48:39,845 INFO     Training average negative_sample_loss at step 34600: 0.092667\n",
      "2023-12-06 10:48:39,845 INFO     Training average loss at step 34600: 0.108553\n",
      "2023-12-06 10:49:05,805 INFO     Training average positive_sample_loss at step 34700: 0.122614\n",
      "2023-12-06 10:49:05,805 INFO     Training average negative_sample_loss at step 34700: 0.091105\n",
      "2023-12-06 10:49:05,805 INFO     Training average loss at step 34700: 0.106859\n",
      "2023-12-06 10:49:29,790 INFO     Training average positive_sample_loss at step 34800: 0.126253\n",
      "2023-12-06 10:49:29,790 INFO     Training average negative_sample_loss at step 34800: 0.091173\n",
      "2023-12-06 10:49:29,790 INFO     Training average loss at step 34800: 0.108713\n",
      "2023-12-06 10:49:57,928 INFO     Training average positive_sample_loss at step 34900: 0.120444\n",
      "2023-12-06 10:49:57,929 INFO     Training average negative_sample_loss at step 34900: 0.091495\n",
      "2023-12-06 10:49:57,929 INFO     Training average loss at step 34900: 0.105970\n",
      "2023-12-06 10:50:24,418 INFO     Training average positive_sample_loss at step 35000: 0.125184\n",
      "2023-12-06 10:50:24,418 INFO     Training average negative_sample_loss at step 35000: 0.090640\n",
      "2023-12-06 10:50:24,418 INFO     Training average loss at step 35000: 0.107912\n",
      "2023-12-06 10:50:54,125 INFO     Training average positive_sample_loss at step 35100: 0.125857\n",
      "2023-12-06 10:50:54,126 INFO     Training average negative_sample_loss at step 35100: 0.092929\n",
      "2023-12-06 10:50:54,126 INFO     Training average loss at step 35100: 0.109393\n",
      "2023-12-06 10:51:18,551 INFO     Training average positive_sample_loss at step 35200: 0.121153\n",
      "2023-12-06 10:51:18,552 INFO     Training average negative_sample_loss at step 35200: 0.090410\n",
      "2023-12-06 10:51:18,552 INFO     Training average loss at step 35200: 0.105782\n",
      "2023-12-06 10:51:43,009 INFO     Training average positive_sample_loss at step 35300: 0.126065\n",
      "2023-12-06 10:51:43,009 INFO     Training average negative_sample_loss at step 35300: 0.091737\n",
      "2023-12-06 10:51:43,009 INFO     Training average loss at step 35300: 0.108901\n",
      "2023-12-06 10:52:11,833 INFO     Training average positive_sample_loss at step 35400: 0.121557\n",
      "2023-12-06 10:52:11,833 INFO     Training average negative_sample_loss at step 35400: 0.091313\n",
      "2023-12-06 10:52:11,833 INFO     Training average loss at step 35400: 0.106435\n",
      "2023-12-06 10:52:37,332 INFO     Training average positive_sample_loss at step 35500: 0.124284\n",
      "2023-12-06 10:52:37,332 INFO     Training average negative_sample_loss at step 35500: 0.090822\n",
      "2023-12-06 10:52:37,332 INFO     Training average loss at step 35500: 0.107553\n",
      "2023-12-06 10:53:02,403 INFO     Training average positive_sample_loss at step 35600: 0.126714\n",
      "2023-12-06 10:53:02,403 INFO     Training average negative_sample_loss at step 35600: 0.091852\n",
      "2023-12-06 10:53:02,403 INFO     Training average loss at step 35600: 0.109283\n",
      "2023-12-06 10:53:31,531 INFO     Training average positive_sample_loss at step 35700: 0.119725\n",
      "2023-12-06 10:53:31,532 INFO     Training average negative_sample_loss at step 35700: 0.090730\n",
      "2023-12-06 10:53:31,532 INFO     Training average loss at step 35700: 0.105228\n",
      "2023-12-06 10:53:57,174 INFO     Training average positive_sample_loss at step 35800: 0.125657\n",
      "2023-12-06 10:53:57,175 INFO     Training average negative_sample_loss at step 35800: 0.091474\n",
      "2023-12-06 10:53:57,175 INFO     Training average loss at step 35800: 0.108566\n",
      "2023-12-06 10:54:26,427 INFO     Training average positive_sample_loss at step 35900: 0.123318\n",
      "2023-12-06 10:54:26,428 INFO     Training average negative_sample_loss at step 35900: 0.092433\n",
      "2023-12-06 10:54:26,428 INFO     Training average loss at step 35900: 0.107875\n",
      "2023-12-06 10:54:51,557 INFO     Training average positive_sample_loss at step 36000: 0.123134\n",
      "2023-12-06 10:54:51,557 INFO     Training average negative_sample_loss at step 36000: 0.090174\n",
      "2023-12-06 10:54:51,557 INFO     Training average loss at step 36000: 0.106654\n",
      "2023-12-06 10:56:39,020 INFO     Training average positive_sample_loss at step 36400: 0.123464\n",
      "2023-12-06 10:56:39,021 INFO     Training average negative_sample_loss at step 36400: 0.091756\n",
      "2023-12-06 10:56:39,021 INFO     Training average loss at step 36400: 0.107610\n",
      "2023-12-06 10:57:04,516 INFO     Training average positive_sample_loss at step 36500: 0.121566\n",
      "2023-12-06 10:57:04,516 INFO     Training average negative_sample_loss at step 36500: 0.090214\n",
      "2023-12-06 10:57:04,516 INFO     Training average loss at step 36500: 0.105890\n",
      "2023-12-06 10:57:28,912 INFO     Training average positive_sample_loss at step 36600: 0.126578\n",
      "2023-12-06 10:57:28,913 INFO     Training average negative_sample_loss at step 36600: 0.091964\n",
      "2023-12-06 10:57:28,913 INFO     Training average loss at step 36600: 0.109271\n",
      "2023-12-06 10:57:56,306 INFO     Training average positive_sample_loss at step 36700: 0.121264\n",
      "2023-12-06 10:57:56,306 INFO     Training average negative_sample_loss at step 36700: 0.091269\n",
      "2023-12-06 10:57:56,306 INFO     Training average loss at step 36700: 0.106267\n",
      "2023-12-06 10:58:21,436 INFO     Training average positive_sample_loss at step 36800: 0.124406\n",
      "2023-12-06 10:58:21,436 INFO     Training average negative_sample_loss at step 36800: 0.090638\n",
      "2023-12-06 10:58:21,437 INFO     Training average loss at step 36800: 0.107522\n",
      "2023-12-06 10:58:52,034 INFO     Training average positive_sample_loss at step 36900: 0.125264\n",
      "2023-12-06 10:58:52,034 INFO     Training average negative_sample_loss at step 36900: 0.092503\n",
      "2023-12-06 10:58:52,034 INFO     Training average loss at step 36900: 0.108884\n",
      "2023-12-06 10:59:16,659 INFO     Training average positive_sample_loss at step 37000: 0.120603\n",
      "2023-12-06 10:59:16,659 INFO     Training average negative_sample_loss at step 37000: 0.090561\n",
      "2023-12-06 10:59:16,659 INFO     Training average loss at step 37000: 0.105582\n",
      "2023-12-06 10:59:41,413 INFO     Training average positive_sample_loss at step 37100: 0.125518\n",
      "2023-12-06 10:59:41,414 INFO     Training average negative_sample_loss at step 37100: 0.091803\n",
      "2023-12-06 10:59:41,414 INFO     Training average loss at step 37100: 0.108660\n",
      "2023-12-06 11:00:10,173 INFO     Training average positive_sample_loss at step 37200: 0.122483\n",
      "2023-12-06 11:00:10,174 INFO     Training average negative_sample_loss at step 37200: 0.092048\n",
      "2023-12-06 11:00:10,174 INFO     Training average loss at step 37200: 0.107266\n",
      "2023-12-06 11:00:34,931 INFO     Training average positive_sample_loss at step 37300: 0.123347\n",
      "2023-12-06 11:00:34,931 INFO     Training average negative_sample_loss at step 37300: 0.090668\n",
      "2023-12-06 11:00:34,931 INFO     Training average loss at step 37300: 0.107008\n",
      "2023-12-06 11:00:59,817 INFO     Training average positive_sample_loss at step 37400: 0.126760\n",
      "2023-12-06 11:00:59,817 INFO     Training average negative_sample_loss at step 37400: 0.091653\n",
      "2023-12-06 11:00:59,817 INFO     Training average loss at step 37400: 0.109207\n",
      "2023-12-06 11:01:27,742 INFO     Training average positive_sample_loss at step 37500: 0.120458\n",
      "2023-12-06 11:01:27,743 INFO     Training average negative_sample_loss at step 37500: 0.092253\n",
      "2023-12-06 11:01:27,743 INFO     Training average loss at step 37500: 0.106355\n",
      "2023-12-06 11:01:53,063 INFO     Training average positive_sample_loss at step 37600: 0.124985\n",
      "2023-12-06 11:01:53,063 INFO     Training average negative_sample_loss at step 37600: 0.090989\n",
      "2023-12-06 11:01:53,063 INFO     Training average loss at step 37600: 0.107987\n",
      "2023-12-06 11:02:22,190 INFO     Training average positive_sample_loss at step 37700: 0.123195\n",
      "2023-12-06 11:02:22,191 INFO     Training average negative_sample_loss at step 37700: 0.091637\n",
      "2023-12-06 11:02:22,191 INFO     Training average loss at step 37700: 0.107416\n",
      "2023-12-06 11:02:47,009 INFO     Training average positive_sample_loss at step 37800: 0.122706\n",
      "2023-12-06 11:02:47,009 INFO     Training average negative_sample_loss at step 37800: 0.090273\n",
      "2023-12-06 11:02:47,009 INFO     Training average loss at step 37800: 0.106490\n",
      "2023-12-06 11:03:11,504 INFO     Training average positive_sample_loss at step 37900: 0.125686\n",
      "2023-12-06 11:03:11,504 INFO     Training average negative_sample_loss at step 37900: 0.091436\n",
      "2023-12-06 11:03:11,504 INFO     Training average loss at step 37900: 0.108561\n",
      "2023-12-06 11:03:39,456 INFO     Training average positive_sample_loss at step 38000: 0.120024\n",
      "2023-12-06 11:03:39,457 INFO     Training average negative_sample_loss at step 38000: 0.091029\n",
      "2023-12-06 11:03:39,457 INFO     Training average loss at step 38000: 0.105526\n",
      "2023-12-06 11:04:03,522 INFO     Training average positive_sample_loss at step 38100: 0.125250\n",
      "2023-12-06 11:04:03,523 INFO     Training average negative_sample_loss at step 38100: 0.091062\n",
      "2023-12-06 11:04:03,523 INFO     Training average loss at step 38100: 0.108156\n",
      "2023-12-06 11:04:31,960 INFO     Training average positive_sample_loss at step 38200: 0.124117\n",
      "2023-12-06 11:04:31,960 INFO     Training average negative_sample_loss at step 38200: 0.091450\n",
      "2023-12-06 11:04:31,960 INFO     Training average loss at step 38200: 0.107784\n",
      "2023-12-06 11:04:56,984 INFO     Training average positive_sample_loss at step 38300: 0.120873\n",
      "2023-12-06 11:04:56,984 INFO     Training average negative_sample_loss at step 38300: 0.089494\n",
      "2023-12-06 11:04:56,984 INFO     Training average loss at step 38300: 0.105183\n",
      "2023-12-06 11:05:21,306 INFO     Training average positive_sample_loss at step 38400: 0.125626\n",
      "2023-12-06 11:05:21,306 INFO     Training average negative_sample_loss at step 38400: 0.091583\n",
      "2023-12-06 11:05:21,306 INFO     Training average loss at step 38400: 0.108604\n",
      "2023-12-06 11:05:48,896 INFO     Training average positive_sample_loss at step 38500: 0.121350\n",
      "2023-12-06 11:05:48,897 INFO     Training average negative_sample_loss at step 38500: 0.091410\n",
      "2023-12-06 11:05:48,897 INFO     Training average loss at step 38500: 0.106380\n",
      "2023-12-06 11:06:13,016 INFO     Training average positive_sample_loss at step 38600: 0.124058\n",
      "2023-12-06 11:06:13,016 INFO     Training average negative_sample_loss at step 38600: 0.090375\n",
      "2023-12-06 11:06:13,016 INFO     Training average loss at step 38600: 0.107217\n",
      "2023-12-06 11:06:39,185 INFO     Training average positive_sample_loss at step 38700: 0.125717\n",
      "2023-12-06 11:06:39,185 INFO     Training average negative_sample_loss at step 38700: 0.091667\n",
      "2023-12-06 11:06:39,185 INFO     Training average loss at step 38700: 0.108692\n",
      "2023-12-06 11:07:05,392 INFO     Training average positive_sample_loss at step 38800: 0.119899\n",
      "2023-12-06 11:07:05,392 INFO     Training average negative_sample_loss at step 38800: 0.090977\n",
      "2023-12-06 11:07:05,392 INFO     Training average loss at step 38800: 0.105438\n",
      "2023-12-06 11:07:29,773 INFO     Training average positive_sample_loss at step 38900: 0.125642\n",
      "2023-12-06 11:07:29,773 INFO     Training average negative_sample_loss at step 38900: 0.091178\n",
      "2023-12-06 11:07:29,773 INFO     Training average loss at step 38900: 0.108410\n",
      "2023-12-06 11:08:00,202 INFO     Training average positive_sample_loss at step 39000: 0.122112\n",
      "2023-12-06 11:08:00,202 INFO     Training average negative_sample_loss at step 39000: 0.091429\n",
      "2023-12-06 11:08:00,202 INFO     Training average loss at step 39000: 0.106771\n",
      "2023-12-06 11:08:24,809 INFO     Training average positive_sample_loss at step 39100: 0.122637\n",
      "2023-12-06 11:08:24,809 INFO     Training average negative_sample_loss at step 39100: 0.089917\n",
      "2023-12-06 11:08:24,809 INFO     Training average loss at step 39100: 0.106277\n",
      "2023-12-06 11:08:50,314 INFO     Training average positive_sample_loss at step 39200: 0.126192\n",
      "2023-12-06 11:08:50,314 INFO     Training average negative_sample_loss at step 39200: 0.092255\n",
      "2023-12-06 11:08:50,314 INFO     Training average loss at step 39200: 0.109224\n",
      "2023-12-06 11:09:20,643 INFO     Training average positive_sample_loss at step 39300: 0.119709\n",
      "2023-12-06 11:09:20,644 INFO     Training average negative_sample_loss at step 39300: 0.091289\n",
      "2023-12-06 11:09:20,644 INFO     Training average loss at step 39300: 0.105499\n",
      "2023-12-06 11:09:45,631 INFO     Training average positive_sample_loss at step 39400: 0.125400\n",
      "2023-12-06 11:09:45,632 INFO     Training average negative_sample_loss at step 39400: 0.091005\n",
      "2023-12-06 11:09:45,632 INFO     Training average loss at step 39400: 0.108203\n",
      "2023-12-06 11:10:14,844 INFO     Training average positive_sample_loss at step 39500: 0.123339\n",
      "2023-12-06 11:10:14,844 INFO     Training average negative_sample_loss at step 39500: 0.091535\n",
      "2023-12-06 11:10:14,844 INFO     Training average loss at step 39500: 0.107437\n",
      "2023-12-06 11:10:39,011 INFO     Training average positive_sample_loss at step 39600: 0.122371\n",
      "2023-12-06 11:10:39,011 INFO     Training average negative_sample_loss at step 39600: 0.091005\n",
      "2023-12-06 11:10:39,011 INFO     Training average loss at step 39600: 0.106688\n",
      "2023-12-06 11:11:04,409 INFO     Training average positive_sample_loss at step 39700: 0.125344\n",
      "2023-12-06 11:11:04,409 INFO     Training average negative_sample_loss at step 39700: 0.091077\n",
      "2023-12-06 11:11:04,409 INFO     Training average loss at step 39700: 0.108210\n",
      "2023-12-06 11:11:32,424 INFO     Training average positive_sample_loss at step 39800: 0.120898\n",
      "2023-12-06 11:11:32,424 INFO     Training average negative_sample_loss at step 39800: 0.091796\n",
      "2023-12-06 11:11:32,424 INFO     Training average loss at step 39800: 0.106347\n",
      "2023-12-06 11:11:56,642 INFO     Training average positive_sample_loss at step 39900: 0.124485\n",
      "2023-12-06 11:11:56,642 INFO     Training average negative_sample_loss at step 39900: 0.090768\n",
      "2023-12-06 11:11:56,642 INFO     Training average loss at step 39900: 0.107626\n",
      "2023-12-06 11:12:34,263 INFO     Training average positive_sample_loss at step 40000: 0.124241\n",
      "2023-12-06 11:12:34,264 INFO     Training average negative_sample_loss at step 40000: 0.092002\n",
      "2023-12-06 11:12:34,264 INFO     Training average loss at step 40000: 0.108121\n",
      "2023-12-06 11:12:34,264 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 11:12:35,222 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 11:13:01,969 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 11:13:19,269 INFO     Valid MRR at step 40000: 0.627860\n",
      "2023-12-06 11:13:19,269 INFO     Valid MR at step 40000: 239.373593\n",
      "2023-12-06 11:13:19,269 INFO     Valid HITS@1 at step 40000: 0.566819\n",
      "2023-12-06 11:13:19,269 INFO     Valid HITS@3 at step 40000: 0.656934\n",
      "2023-12-06 11:13:19,269 INFO     Valid HITS@10 at step 40000: 0.749369\n",
      "2023-12-06 11:13:41,694 INFO     Training average positive_sample_loss at step 40100: 0.120582\n",
      "2023-12-06 11:13:41,694 INFO     Training average negative_sample_loss at step 40100: 0.089975\n",
      "2023-12-06 11:13:41,694 INFO     Training average loss at step 40100: 0.105278\n",
      "2023-12-06 11:14:07,983 INFO     Training average positive_sample_loss at step 40200: 0.125716\n",
      "2023-12-06 11:14:07,984 INFO     Training average negative_sample_loss at step 40200: 0.091052\n",
      "2023-12-06 11:14:07,984 INFO     Training average loss at step 40200: 0.108384\n",
      "2023-12-06 11:14:37,478 INFO     Training average positive_sample_loss at step 40300: 0.121028\n",
      "2023-12-06 11:14:37,478 INFO     Training average negative_sample_loss at step 40300: 0.092293\n",
      "2023-12-06 11:14:37,478 INFO     Training average loss at step 40300: 0.106660\n",
      "2023-12-06 11:15:02,534 INFO     Training average positive_sample_loss at step 40400: 0.124038\n",
      "2023-12-06 11:15:02,535 INFO     Training average negative_sample_loss at step 40400: 0.090272\n",
      "2023-12-06 11:15:02,535 INFO     Training average loss at step 40400: 0.107155\n",
      "2023-12-06 11:15:28,188 INFO     Training average positive_sample_loss at step 40500: 0.125549\n",
      "2023-12-06 11:15:28,188 INFO     Training average negative_sample_loss at step 40500: 0.090965\n",
      "2023-12-06 11:15:28,188 INFO     Training average loss at step 40500: 0.108257\n",
      "2023-12-06 11:15:58,401 INFO     Training average positive_sample_loss at step 40600: 0.119005\n",
      "2023-12-06 11:15:58,402 INFO     Training average negative_sample_loss at step 40600: 0.089857\n",
      "2023-12-06 11:15:58,402 INFO     Training average loss at step 40600: 0.104431\n",
      "2023-12-06 11:16:22,653 INFO     Training average positive_sample_loss at step 40700: 0.125254\n",
      "2023-12-06 11:16:22,653 INFO     Training average negative_sample_loss at step 40700: 0.090988\n",
      "2023-12-06 11:16:22,653 INFO     Training average loss at step 40700: 0.108121\n",
      "2023-12-06 11:16:50,573 INFO     Training average positive_sample_loss at step 40800: 0.122010\n",
      "2023-12-06 11:16:50,573 INFO     Training average negative_sample_loss at step 40800: 0.091335\n",
      "2023-12-06 11:16:50,573 INFO     Training average loss at step 40800: 0.106672\n",
      "2023-12-06 11:17:15,056 INFO     Training average positive_sample_loss at step 40900: 0.122581\n",
      "2023-12-06 11:17:15,056 INFO     Training average negative_sample_loss at step 40900: 0.089799\n",
      "2023-12-06 11:17:15,056 INFO     Training average loss at step 40900: 0.106190\n",
      "2023-12-06 11:17:41,682 INFO     Training average positive_sample_loss at step 41000: 0.125647\n",
      "2023-12-06 11:17:41,682 INFO     Training average negative_sample_loss at step 41000: 0.090882\n",
      "2023-12-06 11:17:41,682 INFO     Training average loss at step 41000: 0.108265\n",
      "2023-12-06 11:18:11,348 INFO     Training average positive_sample_loss at step 41100: 0.119989\n",
      "2023-12-06 11:18:11,348 INFO     Training average negative_sample_loss at step 41100: 0.090593\n",
      "2023-12-06 11:18:11,348 INFO     Training average loss at step 41100: 0.105291\n",
      "2023-12-06 11:18:35,872 INFO     Training average positive_sample_loss at step 41200: 0.124368\n",
      "2023-12-06 11:18:35,873 INFO     Training average negative_sample_loss at step 41200: 0.091020\n",
      "2023-12-06 11:18:35,873 INFO     Training average loss at step 41200: 0.107694\n",
      "2023-12-06 11:19:04,389 INFO     Training average positive_sample_loss at step 41300: 0.123194\n",
      "2023-12-06 11:19:04,390 INFO     Training average negative_sample_loss at step 41300: 0.091919\n",
      "2023-12-06 11:19:04,390 INFO     Training average loss at step 41300: 0.107557\n",
      "2023-12-06 11:19:30,412 INFO     Training average positive_sample_loss at step 41400: 0.121483\n",
      "2023-12-06 11:19:30,412 INFO     Training average negative_sample_loss at step 41400: 0.090421\n",
      "2023-12-06 11:19:30,412 INFO     Training average loss at step 41400: 0.105952\n",
      "2023-12-06 11:19:56,400 INFO     Training average positive_sample_loss at step 41500: 0.125313\n",
      "2023-12-06 11:19:56,401 INFO     Training average negative_sample_loss at step 41500: 0.091183\n",
      "2023-12-06 11:19:56,401 INFO     Training average loss at step 41500: 0.108248\n",
      "2023-12-06 11:20:26,099 INFO     Training average positive_sample_loss at step 41600: 0.120878\n",
      "2023-12-06 11:20:26,100 INFO     Training average negative_sample_loss at step 41600: 0.091294\n",
      "2023-12-06 11:20:26,100 INFO     Training average loss at step 41600: 0.106086\n",
      "2023-12-06 11:20:50,804 INFO     Training average positive_sample_loss at step 41700: 0.123967\n",
      "2023-12-06 11:20:50,805 INFO     Training average negative_sample_loss at step 41700: 0.090315\n",
      "2023-12-06 11:20:50,805 INFO     Training average loss at step 41700: 0.107141\n",
      "2023-12-06 11:21:19,775 INFO     Training average positive_sample_loss at step 41800: 0.125093\n",
      "2023-12-06 11:21:19,775 INFO     Training average negative_sample_loss at step 41800: 0.091039\n",
      "2023-12-06 11:21:19,775 INFO     Training average loss at step 41800: 0.108066\n",
      "2023-12-06 11:21:43,823 INFO     Training average positive_sample_loss at step 41900: 0.119540\n",
      "2023-12-06 11:21:43,824 INFO     Training average negative_sample_loss at step 41900: 0.089264\n",
      "2023-12-06 11:21:43,824 INFO     Training average loss at step 41900: 0.104402\n",
      "2023-12-06 11:22:09,360 INFO     Training average positive_sample_loss at step 42000: 0.125008\n",
      "2023-12-06 11:22:09,361 INFO     Training average negative_sample_loss at step 42000: 0.091653\n",
      "2023-12-06 11:22:09,361 INFO     Training average loss at step 42000: 0.108330\n",
      "2023-12-06 11:22:39,224 INFO     Training average positive_sample_loss at step 42100: 0.121282\n",
      "2023-12-06 11:22:39,224 INFO     Training average negative_sample_loss at step 42100: 0.091166\n",
      "2023-12-06 11:22:39,224 INFO     Training average loss at step 42100: 0.106224\n",
      "2023-12-06 11:23:06,286 INFO     Training average positive_sample_loss at step 42200: 0.123087\n",
      "2023-12-06 11:23:06,287 INFO     Training average negative_sample_loss at step 42200: 0.090122\n",
      "2023-12-06 11:23:06,287 INFO     Training average loss at step 42200: 0.106605\n",
      "2023-12-06 11:23:31,018 INFO     Training average positive_sample_loss at step 42300: 0.125544\n",
      "2023-12-06 11:23:31,018 INFO     Training average negative_sample_loss at step 42300: 0.091952\n",
      "2023-12-06 11:23:31,018 INFO     Training average loss at step 42300: 0.108748\n",
      "2023-12-06 11:23:59,835 INFO     Training average positive_sample_loss at step 42400: 0.119543\n",
      "2023-12-06 11:23:59,836 INFO     Training average negative_sample_loss at step 42400: 0.089827\n",
      "2023-12-06 11:23:59,836 INFO     Training average loss at step 42400: 0.104685\n",
      "2023-12-06 11:24:26,472 INFO     Training average positive_sample_loss at step 42500: 0.124488\n",
      "2023-12-06 11:24:26,472 INFO     Training average negative_sample_loss at step 42500: 0.090518\n",
      "2023-12-06 11:24:26,472 INFO     Training average loss at step 42500: 0.107503\n",
      "2023-12-06 11:24:55,597 INFO     Training average positive_sample_loss at step 42600: 0.122422\n",
      "2023-12-06 11:24:55,598 INFO     Training average negative_sample_loss at step 42600: 0.091413\n",
      "2023-12-06 11:24:55,598 INFO     Training average loss at step 42600: 0.106917\n",
      "2023-12-06 11:25:20,140 INFO     Training average positive_sample_loss at step 42700: 0.121703\n",
      "2023-12-06 11:25:20,140 INFO     Training average negative_sample_loss at step 42700: 0.089237\n",
      "2023-12-06 11:25:20,140 INFO     Training average loss at step 42700: 0.105470\n",
      "2023-12-06 11:25:44,866 INFO     Training average positive_sample_loss at step 42800: 0.125221\n",
      "2023-12-06 11:25:44,867 INFO     Training average negative_sample_loss at step 42800: 0.091277\n",
      "2023-12-06 11:25:44,867 INFO     Training average loss at step 42800: 0.108249\n",
      "2023-12-06 11:26:15,920 INFO     Training average positive_sample_loss at step 42900: 0.120592\n",
      "2023-12-06 11:26:15,920 INFO     Training average negative_sample_loss at step 42900: 0.091255\n",
      "2023-12-06 11:26:15,920 INFO     Training average loss at step 42900: 0.105923\n",
      "2023-12-06 11:26:40,587 INFO     Training average positive_sample_loss at step 43000: 0.123808\n",
      "2023-12-06 11:26:40,588 INFO     Training average negative_sample_loss at step 43000: 0.089790\n",
      "2023-12-06 11:26:40,588 INFO     Training average loss at step 43000: 0.106799\n",
      "2023-12-06 11:27:08,632 INFO     Training average positive_sample_loss at step 43100: 0.123896\n",
      "2023-12-06 11:27:08,632 INFO     Training average negative_sample_loss at step 43100: 0.091105\n",
      "2023-12-06 11:27:08,632 INFO     Training average loss at step 43100: 0.107501\n",
      "2023-12-06 11:27:32,797 INFO     Training average positive_sample_loss at step 43200: 0.120388\n",
      "2023-12-06 11:27:32,797 INFO     Training average negative_sample_loss at step 43200: 0.089314\n",
      "2023-12-06 11:27:32,797 INFO     Training average loss at step 43200: 0.104851\n",
      "2023-12-06 11:27:57,882 INFO     Training average positive_sample_loss at step 43300: 0.125225\n",
      "2023-12-06 11:27:57,882 INFO     Training average negative_sample_loss at step 43300: 0.090537\n",
      "2023-12-06 11:27:57,882 INFO     Training average loss at step 43300: 0.107881\n",
      "2023-12-06 11:28:26,730 INFO     Training average positive_sample_loss at step 43400: 0.120770\n",
      "2023-12-06 11:28:26,730 INFO     Training average negative_sample_loss at step 43400: 0.090856\n",
      "2023-12-06 11:28:26,730 INFO     Training average loss at step 43400: 0.105813\n",
      "2023-12-06 11:28:51,790 INFO     Training average positive_sample_loss at step 43500: 0.122880\n",
      "2023-12-06 11:28:51,790 INFO     Training average negative_sample_loss at step 43500: 0.089857\n",
      "2023-12-06 11:28:51,790 INFO     Training average loss at step 43500: 0.106369\n",
      "2023-12-06 11:29:16,441 INFO     Training average positive_sample_loss at step 43600: 0.125504\n",
      "2023-12-06 11:29:16,442 INFO     Training average negative_sample_loss at step 43600: 0.091441\n",
      "2023-12-06 11:29:16,442 INFO     Training average loss at step 43600: 0.108472\n",
      "2023-12-06 11:29:44,084 INFO     Training average positive_sample_loss at step 43700: 0.118793\n",
      "2023-12-06 11:29:44,084 INFO     Training average negative_sample_loss at step 43700: 0.090013\n",
      "2023-12-06 11:29:44,084 INFO     Training average loss at step 43700: 0.104403\n",
      "2023-12-06 11:30:09,410 INFO     Training average positive_sample_loss at step 43800: 0.124476\n",
      "2023-12-06 11:30:09,411 INFO     Training average negative_sample_loss at step 43800: 0.089924\n",
      "2023-12-06 11:30:09,411 INFO     Training average loss at step 43800: 0.107200\n",
      "2023-12-06 11:30:38,176 INFO     Training average positive_sample_loss at step 43900: 0.122431\n",
      "2023-12-06 11:30:38,176 INFO     Training average negative_sample_loss at step 43900: 0.092658\n",
      "2023-12-06 11:30:38,177 INFO     Training average loss at step 43900: 0.107544\n",
      "2023-12-06 11:31:02,446 INFO     Training average positive_sample_loss at step 44000: 0.122844\n",
      "2023-12-06 11:31:02,447 INFO     Training average negative_sample_loss at step 44000: 0.090321\n",
      "2023-12-06 11:31:02,447 INFO     Training average loss at step 44000: 0.106583\n",
      "2023-12-06 11:31:28,281 INFO     Training average positive_sample_loss at step 44100: 0.125056\n",
      "2023-12-06 11:31:28,281 INFO     Training average negative_sample_loss at step 44100: 0.090939\n",
      "2023-12-06 11:31:28,281 INFO     Training average loss at step 44100: 0.107998\n",
      "2023-12-06 11:31:58,736 INFO     Training average positive_sample_loss at step 44200: 0.120265\n",
      "2023-12-06 11:31:58,736 INFO     Training average negative_sample_loss at step 44200: 0.090248\n",
      "2023-12-06 11:31:58,736 INFO     Training average loss at step 44200: 0.105256\n",
      "2023-12-06 11:32:23,190 INFO     Training average positive_sample_loss at step 44300: 0.123456\n",
      "2023-12-06 11:32:23,191 INFO     Training average negative_sample_loss at step 44300: 0.089928\n",
      "2023-12-06 11:32:23,191 INFO     Training average loss at step 44300: 0.106692\n",
      "2023-12-06 11:32:52,373 INFO     Training average positive_sample_loss at step 44400: 0.122594\n",
      "2023-12-06 11:32:52,373 INFO     Training average negative_sample_loss at step 44400: 0.091265\n",
      "2023-12-06 11:32:52,373 INFO     Training average loss at step 44400: 0.106929\n",
      "2023-12-06 11:33:17,830 INFO     Training average positive_sample_loss at step 44500: 0.121466\n",
      "2023-12-06 11:33:17,831 INFO     Training average negative_sample_loss at step 44500: 0.089105\n",
      "2023-12-06 11:33:17,831 INFO     Training average loss at step 44500: 0.105285\n",
      "2023-12-06 11:33:42,748 INFO     Training average positive_sample_loss at step 44600: 0.124820\n",
      "2023-12-06 11:33:42,748 INFO     Training average negative_sample_loss at step 44600: 0.090931\n",
      "2023-12-06 11:33:42,748 INFO     Training average loss at step 44600: 0.107875\n",
      "2023-12-06 11:34:11,642 INFO     Training average positive_sample_loss at step 44700: 0.119967\n",
      "2023-12-06 11:34:11,643 INFO     Training average negative_sample_loss at step 44700: 0.090166\n",
      "2023-12-06 11:34:11,643 INFO     Training average loss at step 44700: 0.105067\n",
      "2023-12-06 11:34:36,963 INFO     Training average positive_sample_loss at step 44800: 0.123805\n",
      "2023-12-06 11:34:36,963 INFO     Training average negative_sample_loss at step 44800: 0.090059\n",
      "2023-12-06 11:34:36,963 INFO     Training average loss at step 44800: 0.106932\n",
      "2023-12-06 11:35:05,468 INFO     Training average positive_sample_loss at step 44900: 0.124304\n",
      "2023-12-06 11:35:05,469 INFO     Training average negative_sample_loss at step 44900: 0.092253\n",
      "2023-12-06 11:35:05,469 INFO     Training average loss at step 44900: 0.108279\n",
      "2023-12-06 11:35:29,383 INFO     Training average positive_sample_loss at step 45000: 0.119887\n",
      "2023-12-06 11:35:29,383 INFO     Training average negative_sample_loss at step 45000: 0.090038\n",
      "2023-12-06 11:35:29,383 INFO     Training average loss at step 45000: 0.104962\n",
      "2023-12-06 11:35:54,465 INFO     Training average positive_sample_loss at step 45100: 0.125155\n",
      "2023-12-06 11:35:54,465 INFO     Training average negative_sample_loss at step 45100: 0.090247\n",
      "2023-12-06 11:35:54,465 INFO     Training average loss at step 45100: 0.107701\n",
      "2023-12-06 11:36:22,714 INFO     Training average positive_sample_loss at step 45200: 0.120801\n",
      "2023-12-06 11:36:22,715 INFO     Training average negative_sample_loss at step 45200: 0.090679\n",
      "2023-12-06 11:36:22,715 INFO     Training average loss at step 45200: 0.105740\n",
      "2023-12-06 11:36:48,078 INFO     Training average positive_sample_loss at step 45300: 0.122643\n",
      "2023-12-06 11:36:48,079 INFO     Training average negative_sample_loss at step 45300: 0.090036\n",
      "2023-12-06 11:36:48,079 INFO     Training average loss at step 45300: 0.106339\n",
      "2023-12-06 11:37:13,715 INFO     Training average positive_sample_loss at step 45400: 0.125680\n",
      "2023-12-06 11:37:13,715 INFO     Training average negative_sample_loss at step 45400: 0.091004\n",
      "2023-12-06 11:37:13,715 INFO     Training average loss at step 45400: 0.108342\n",
      "2023-12-06 11:37:43,162 INFO     Training average positive_sample_loss at step 45500: 0.118770\n",
      "2023-12-06 11:37:43,163 INFO     Training average negative_sample_loss at step 45500: 0.090024\n",
      "2023-12-06 11:37:43,163 INFO     Training average loss at step 45500: 0.104397\n",
      "2023-12-06 11:38:07,268 INFO     Training average positive_sample_loss at step 45600: 0.124591\n",
      "2023-12-06 11:38:07,268 INFO     Training average negative_sample_loss at step 45600: 0.090527\n",
      "2023-12-06 11:38:07,268 INFO     Training average loss at step 45600: 0.107559\n",
      "2023-12-06 11:38:36,177 INFO     Training average positive_sample_loss at step 45700: 0.121684\n",
      "2023-12-06 11:38:36,178 INFO     Training average negative_sample_loss at step 45700: 0.091296\n",
      "2023-12-06 11:38:36,178 INFO     Training average loss at step 45700: 0.106490\n",
      "2023-12-06 11:39:01,040 INFO     Training average positive_sample_loss at step 45800: 0.122012\n",
      "2023-12-06 11:39:01,040 INFO     Training average negative_sample_loss at step 45800: 0.089239\n",
      "2023-12-06 11:39:01,040 INFO     Training average loss at step 45800: 0.105626\n",
      "2023-12-06 11:39:26,132 INFO     Training average positive_sample_loss at step 45900: 0.124957\n",
      "2023-12-06 11:39:26,132 INFO     Training average negative_sample_loss at step 45900: 0.090825\n",
      "2023-12-06 11:39:26,132 INFO     Training average loss at step 45900: 0.107891\n",
      "2023-12-06 11:39:56,039 INFO     Training average positive_sample_loss at step 46000: 0.119926\n",
      "2023-12-06 11:39:56,039 INFO     Training average negative_sample_loss at step 46000: 0.090925\n",
      "2023-12-06 11:39:56,039 INFO     Training average loss at step 46000: 0.105425\n",
      "2023-12-06 11:40:21,003 INFO     Training average positive_sample_loss at step 46100: 0.123378\n",
      "2023-12-06 11:40:21,003 INFO     Training average negative_sample_loss at step 46100: 0.089487\n",
      "2023-12-06 11:40:21,003 INFO     Training average loss at step 46100: 0.106433\n",
      "2023-12-06 11:40:50,589 INFO     Training average positive_sample_loss at step 46200: 0.123149\n",
      "2023-12-06 11:40:50,590 INFO     Training average negative_sample_loss at step 46200: 0.091327\n",
      "2023-12-06 11:40:50,590 INFO     Training average loss at step 46200: 0.107238\n",
      "2023-12-06 11:41:15,932 INFO     Training average positive_sample_loss at step 46300: 0.120960\n",
      "2023-12-06 11:41:15,932 INFO     Training average negative_sample_loss at step 46300: 0.089917\n",
      "2023-12-06 11:41:15,932 INFO     Training average loss at step 46300: 0.105438\n",
      "2023-12-06 11:41:41,297 INFO     Training average positive_sample_loss at step 46400: 0.124935\n",
      "2023-12-06 11:41:41,297 INFO     Training average negative_sample_loss at step 46400: 0.090035\n",
      "2023-12-06 11:41:41,298 INFO     Training average loss at step 46400: 0.107485\n",
      "2023-12-06 11:42:09,552 INFO     Training average positive_sample_loss at step 46500: 0.119577\n",
      "2023-12-06 11:42:09,552 INFO     Training average negative_sample_loss at step 46500: 0.090371\n",
      "2023-12-06 11:42:09,552 INFO     Training average loss at step 46500: 0.104974\n",
      "2023-12-06 11:42:35,013 INFO     Training average positive_sample_loss at step 46600: 0.123412\n",
      "2023-12-06 11:42:35,013 INFO     Training average negative_sample_loss at step 46600: 0.089631\n",
      "2023-12-06 11:42:35,013 INFO     Training average loss at step 46600: 0.106521\n",
      "2023-12-06 11:43:06,186 INFO     Training average positive_sample_loss at step 46700: 0.125076\n",
      "2023-12-06 11:43:06,186 INFO     Training average negative_sample_loss at step 46700: 0.091689\n",
      "2023-12-06 11:43:06,186 INFO     Training average loss at step 46700: 0.108383\n",
      "2023-12-06 11:43:30,932 INFO     Training average positive_sample_loss at step 46800: 0.118537\n",
      "2023-12-06 11:43:30,932 INFO     Training average negative_sample_loss at step 46800: 0.089701\n",
      "2023-12-06 11:43:30,932 INFO     Training average loss at step 46800: 0.104119\n",
      "2023-12-06 11:43:55,382 INFO     Training average positive_sample_loss at step 46900: 0.124658\n",
      "2023-12-06 11:43:55,383 INFO     Training average negative_sample_loss at step 46900: 0.090338\n",
      "2023-12-06 11:43:55,383 INFO     Training average loss at step 46900: 0.107498\n",
      "2023-12-06 11:44:25,337 INFO     Training average positive_sample_loss at step 47000: 0.121882\n",
      "2023-12-06 11:44:25,337 INFO     Training average negative_sample_loss at step 47000: 0.092021\n",
      "2023-12-06 11:44:25,337 INFO     Training average loss at step 47000: 0.106951\n",
      "2023-12-06 11:44:52,832 INFO     Training average positive_sample_loss at step 47100: 0.122530\n",
      "2023-12-06 11:44:52,833 INFO     Training average negative_sample_loss at step 47100: 0.089541\n",
      "2023-12-06 11:44:52,833 INFO     Training average loss at step 47100: 0.106036\n",
      "2023-12-06 11:45:17,691 INFO     Training average positive_sample_loss at step 47200: 0.124812\n",
      "2023-12-06 11:45:17,692 INFO     Training average negative_sample_loss at step 47200: 0.090797\n",
      "2023-12-06 11:45:17,692 INFO     Training average loss at step 47200: 0.107805\n",
      "2023-12-06 11:45:46,790 INFO     Training average positive_sample_loss at step 47300: 0.119003\n",
      "2023-12-06 11:45:46,791 INFO     Training average negative_sample_loss at step 47300: 0.090045\n",
      "2023-12-06 11:45:46,791 INFO     Training average loss at step 47300: 0.104524\n",
      "2023-12-06 11:46:12,663 INFO     Training average positive_sample_loss at step 47400: 0.124167\n",
      "2023-12-06 11:46:12,663 INFO     Training average negative_sample_loss at step 47400: 0.090326\n",
      "2023-12-06 11:46:12,663 INFO     Training average loss at step 47400: 0.107246\n",
      "2023-12-06 11:46:40,363 INFO     Training average positive_sample_loss at step 47500: 0.122525\n",
      "2023-12-06 11:46:40,363 INFO     Training average negative_sample_loss at step 47500: 0.091802\n",
      "2023-12-06 11:46:40,363 INFO     Training average loss at step 47500: 0.107163\n",
      "2023-12-06 11:47:06,691 INFO     Training average positive_sample_loss at step 47600: 0.121428\n",
      "2023-12-06 11:47:06,691 INFO     Training average negative_sample_loss at step 47600: 0.088932\n",
      "2023-12-06 11:47:06,691 INFO     Training average loss at step 47600: 0.105180\n",
      "2023-12-06 11:47:32,392 INFO     Training average positive_sample_loss at step 47700: 0.124838\n",
      "2023-12-06 11:47:32,392 INFO     Training average negative_sample_loss at step 47700: 0.090255\n",
      "2023-12-06 11:47:32,392 INFO     Training average loss at step 47700: 0.107547\n",
      "2023-12-06 11:48:00,300 INFO     Training average positive_sample_loss at step 47800: 0.118953\n",
      "2023-12-06 11:48:00,301 INFO     Training average negative_sample_loss at step 47800: 0.089687\n",
      "2023-12-06 11:48:00,301 INFO     Training average loss at step 47800: 0.104320\n",
      "2023-12-06 11:48:25,666 INFO     Training average positive_sample_loss at step 47900: 0.123892\n",
      "2023-12-06 11:48:25,666 INFO     Training average negative_sample_loss at step 47900: 0.090252\n",
      "2023-12-06 11:48:25,666 INFO     Training average loss at step 47900: 0.107072\n",
      "2023-12-06 11:48:54,489 INFO     Training average positive_sample_loss at step 48000: 0.123178\n",
      "2023-12-06 11:48:54,490 INFO     Training average negative_sample_loss at step 48000: 0.091229\n",
      "2023-12-06 11:48:54,490 INFO     Training average loss at step 48000: 0.107203\n",
      "2023-12-06 11:49:18,846 INFO     Training average positive_sample_loss at step 48100: 0.120706\n",
      "2023-12-06 11:49:18,846 INFO     Training average negative_sample_loss at step 48100: 0.089920\n",
      "2023-12-06 11:49:18,846 INFO     Training average loss at step 48100: 0.105313\n",
      "2023-12-06 11:49:44,225 INFO     Training average positive_sample_loss at step 48200: 0.124272\n",
      "2023-12-06 11:49:44,226 INFO     Training average negative_sample_loss at step 48200: 0.090387\n",
      "2023-12-06 11:49:44,226 INFO     Training average loss at step 48200: 0.107330\n",
      "2023-12-06 11:50:12,608 INFO     Training average positive_sample_loss at step 48300: 0.120416\n",
      "2023-12-06 11:50:12,608 INFO     Training average negative_sample_loss at step 48300: 0.091069\n",
      "2023-12-06 11:50:12,608 INFO     Training average loss at step 48300: 0.105742\n",
      "2023-12-06 11:51:56,411 INFO     Training average positive_sample_loss at step 48700: 0.123639\n",
      "2023-12-06 11:51:56,411 INFO     Training average negative_sample_loss at step 48700: 0.089916\n",
      "2023-12-06 11:51:56,412 INFO     Training average loss at step 48700: 0.106778\n",
      "2023-12-06 11:52:25,263 INFO     Training average positive_sample_loss at step 48800: 0.121195\n",
      "2023-12-06 11:52:25,263 INFO     Training average negative_sample_loss at step 48800: 0.090837\n",
      "2023-12-06 11:52:25,263 INFO     Training average loss at step 48800: 0.106016\n",
      "2023-12-06 11:52:51,229 INFO     Training average positive_sample_loss at step 48900: 0.122131\n",
      "2023-12-06 11:52:51,230 INFO     Training average negative_sample_loss at step 48900: 0.090143\n",
      "2023-12-06 11:52:51,230 INFO     Training average loss at step 48900: 0.106137\n",
      "2023-12-06 11:53:17,228 INFO     Training average positive_sample_loss at step 49000: 0.125113\n",
      "2023-12-06 11:53:17,228 INFO     Training average negative_sample_loss at step 49000: 0.090507\n",
      "2023-12-06 11:53:17,228 INFO     Training average loss at step 49000: 0.107810\n",
      "2023-12-06 11:53:46,588 INFO     Training average positive_sample_loss at step 49100: 0.119619\n",
      "2023-12-06 11:53:46,588 INFO     Training average negative_sample_loss at step 49100: 0.090426\n",
      "2023-12-06 11:53:46,588 INFO     Training average loss at step 49100: 0.105022\n",
      "2023-12-06 11:54:11,593 INFO     Training average positive_sample_loss at step 49200: 0.123582\n",
      "2023-12-06 11:54:11,594 INFO     Training average negative_sample_loss at step 49200: 0.089897\n",
      "2023-12-06 11:54:11,594 INFO     Training average loss at step 49200: 0.106739\n",
      "2023-12-06 11:54:42,655 INFO     Training average positive_sample_loss at step 49300: 0.122292\n",
      "2023-12-06 11:54:42,655 INFO     Training average negative_sample_loss at step 49300: 0.091393\n",
      "2023-12-06 11:54:42,655 INFO     Training average loss at step 49300: 0.106842\n",
      "2023-12-06 11:55:08,006 INFO     Training average positive_sample_loss at step 49400: 0.120962\n",
      "2023-12-06 11:55:08,007 INFO     Training average negative_sample_loss at step 49400: 0.089203\n",
      "2023-12-06 11:55:08,007 INFO     Training average loss at step 49400: 0.105083\n",
      "2023-12-06 11:55:34,083 INFO     Training average positive_sample_loss at step 49500: 0.124406\n",
      "2023-12-06 11:55:34,083 INFO     Training average negative_sample_loss at step 49500: 0.091160\n",
      "2023-12-06 11:55:34,083 INFO     Training average loss at step 49500: 0.107783\n",
      "2023-12-06 11:56:01,466 INFO     Training average positive_sample_loss at step 49600: 0.119894\n",
      "2023-12-06 11:56:01,467 INFO     Training average negative_sample_loss at step 49600: 0.090528\n",
      "2023-12-06 11:56:01,467 INFO     Training average loss at step 49600: 0.105211\n",
      "2023-12-06 11:56:26,021 INFO     Training average positive_sample_loss at step 49700: 0.123344\n",
      "2023-12-06 11:56:26,021 INFO     Training average negative_sample_loss at step 49700: 0.088837\n",
      "2023-12-06 11:56:26,021 INFO     Training average loss at step 49700: 0.106091\n",
      "2023-12-06 11:56:55,045 INFO     Training average positive_sample_loss at step 49800: 0.123873\n",
      "2023-12-06 11:56:55,046 INFO     Training average negative_sample_loss at step 49800: 0.091037\n",
      "2023-12-06 11:56:55,046 INFO     Training average loss at step 49800: 0.107455\n",
      "2023-12-06 11:57:20,544 INFO     Training average positive_sample_loss at step 49900: 0.119232\n",
      "2023-12-06 11:57:20,544 INFO     Training average negative_sample_loss at step 49900: 0.089333\n",
      "2023-12-06 11:57:20,544 INFO     Training average loss at step 49900: 0.104283\n",
      "2023-12-06 11:57:45,311 INFO     Change learning_rate to 0.000005 at step 50000\n",
      "2023-12-06 11:57:54,644 INFO     Training average positive_sample_loss at step 50000: 0.124394\n",
      "2023-12-06 11:57:54,645 INFO     Training average negative_sample_loss at step 50000: 0.090119\n",
      "2023-12-06 11:57:54,645 INFO     Training average loss at step 50000: 0.107257\n",
      "2023-12-06 11:57:54,645 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 11:57:55,185 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 11:58:23,924 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 11:58:42,276 INFO     Valid MRR at step 50000: 0.628161\n",
      "2023-12-06 11:58:42,277 INFO     Valid MR at step 50000: 239.218739\n",
      "2023-12-06 11:58:42,277 INFO     Valid HITS@1 at step 50000: 0.570707\n",
      "2023-12-06 11:58:42,277 INFO     Valid HITS@3 at step 50000: 0.653046\n",
      "2023-12-06 11:58:42,277 INFO     Valid HITS@10 at step 50000: 0.743229\n",
      "2023-12-06 11:59:06,955 INFO     Training average positive_sample_loss at step 50100: 0.119946\n",
      "2023-12-06 11:59:06,955 INFO     Training average negative_sample_loss at step 50100: 0.089352\n",
      "2023-12-06 11:59:06,955 INFO     Training average loss at step 50100: 0.104649\n",
      "2023-12-06 11:59:33,286 INFO     Training average positive_sample_loss at step 50200: 0.114370\n",
      "2023-12-06 11:59:33,287 INFO     Training average negative_sample_loss at step 50200: 0.088088\n",
      "2023-12-06 11:59:33,287 INFO     Training average loss at step 50200: 0.101229\n",
      "2023-12-06 11:59:58,882 INFO     Training average positive_sample_loss at step 50300: 0.114814\n",
      "2023-12-06 11:59:58,882 INFO     Training average negative_sample_loss at step 50300: 0.088302\n",
      "2023-12-06 11:59:58,882 INFO     Training average loss at step 50300: 0.101558\n",
      "2023-12-06 12:00:28,091 INFO     Training average positive_sample_loss at step 50400: 0.113173\n",
      "2023-12-06 12:00:28,092 INFO     Training average negative_sample_loss at step 50400: 0.088111\n",
      "2023-12-06 12:00:28,092 INFO     Training average loss at step 50400: 0.100642\n",
      "2023-12-06 12:00:52,685 INFO     Training average positive_sample_loss at step 50500: 0.113531\n",
      "2023-12-06 12:00:52,686 INFO     Training average negative_sample_loss at step 50500: 0.087485\n",
      "2023-12-06 12:00:52,686 INFO     Training average loss at step 50500: 0.100508\n",
      "2023-12-06 12:01:23,344 INFO     Training average positive_sample_loss at step 50600: 0.113593\n",
      "2023-12-06 12:01:23,344 INFO     Training average negative_sample_loss at step 50600: 0.086837\n",
      "2023-12-06 12:01:23,344 INFO     Training average loss at step 50600: 0.100215\n",
      "2023-12-06 12:01:47,996 INFO     Training average positive_sample_loss at step 50700: 0.113031\n",
      "2023-12-06 12:01:47,996 INFO     Training average negative_sample_loss at step 50700: 0.086947\n",
      "2023-12-06 12:01:47,997 INFO     Training average loss at step 50700: 0.099989\n",
      "2023-12-06 12:02:12,462 INFO     Training average positive_sample_loss at step 50800: 0.114240\n",
      "2023-12-06 12:02:12,462 INFO     Training average negative_sample_loss at step 50800: 0.086530\n",
      "2023-12-06 12:02:12,463 INFO     Training average loss at step 50800: 0.100385\n",
      "2023-12-06 12:02:41,419 INFO     Training average positive_sample_loss at step 50900: 0.112885\n",
      "2023-12-06 12:02:41,420 INFO     Training average negative_sample_loss at step 50900: 0.087616\n",
      "2023-12-06 12:02:41,420 INFO     Training average loss at step 50900: 0.100251\n",
      "2023-12-06 12:03:07,557 INFO     Training average positive_sample_loss at step 51000: 0.113340\n",
      "2023-12-06 12:03:07,557 INFO     Training average negative_sample_loss at step 51000: 0.085544\n",
      "2023-12-06 12:03:07,557 INFO     Training average loss at step 51000: 0.099442\n",
      "2023-12-06 12:03:36,111 INFO     Training average positive_sample_loss at step 51100: 0.113826\n",
      "2023-12-06 12:03:36,112 INFO     Training average negative_sample_loss at step 51100: 0.087236\n",
      "2023-12-06 12:03:36,112 INFO     Training average loss at step 51100: 0.100531\n",
      "2023-12-06 12:04:01,254 INFO     Training average positive_sample_loss at step 51200: 0.112729\n",
      "2023-12-06 12:04:01,254 INFO     Training average negative_sample_loss at step 51200: 0.085540\n",
      "2023-12-06 12:04:01,254 INFO     Training average loss at step 51200: 0.099135\n",
      "2023-12-06 12:04:26,325 INFO     Training average positive_sample_loss at step 51300: 0.113788\n",
      "2023-12-06 12:04:26,325 INFO     Training average negative_sample_loss at step 51300: 0.085664\n",
      "2023-12-06 12:04:26,325 INFO     Training average loss at step 51300: 0.099726\n",
      "2023-12-06 12:04:54,936 INFO     Training average positive_sample_loss at step 51400: 0.112545\n",
      "2023-12-06 12:04:54,936 INFO     Training average negative_sample_loss at step 51400: 0.085705\n",
      "2023-12-06 12:04:54,936 INFO     Training average loss at step 51400: 0.099125\n",
      "2023-12-06 12:05:20,068 INFO     Training average positive_sample_loss at step 51500: 0.112797\n",
      "2023-12-06 12:05:20,069 INFO     Training average negative_sample_loss at step 51500: 0.086101\n",
      "2023-12-06 12:05:20,069 INFO     Training average loss at step 51500: 0.099449\n",
      "2023-12-06 12:05:48,601 INFO     Training average positive_sample_loss at step 51600: 0.114569\n",
      "2023-12-06 12:05:48,602 INFO     Training average negative_sample_loss at step 51600: 0.086146\n",
      "2023-12-06 12:05:48,602 INFO     Training average loss at step 51600: 0.100358\n",
      "2023-12-06 12:06:15,146 INFO     Training average positive_sample_loss at step 51700: 0.112580\n",
      "2023-12-06 12:06:15,146 INFO     Training average negative_sample_loss at step 51700: 0.085318\n",
      "2023-12-06 12:06:15,146 INFO     Training average loss at step 51700: 0.098949\n",
      "2023-12-06 12:06:40,376 INFO     Training average positive_sample_loss at step 51800: 0.113474\n",
      "2023-12-06 12:06:40,376 INFO     Training average negative_sample_loss at step 51800: 0.086102\n",
      "2023-12-06 12:06:40,376 INFO     Training average loss at step 51800: 0.099788\n",
      "2023-12-06 12:07:09,340 INFO     Training average positive_sample_loss at step 51900: 0.112876\n",
      "2023-12-06 12:07:09,340 INFO     Training average negative_sample_loss at step 51900: 0.085169\n",
      "2023-12-06 12:07:09,340 INFO     Training average loss at step 51900: 0.099023\n",
      "2023-12-06 12:07:34,347 INFO     Training average positive_sample_loss at step 52000: 0.113265\n",
      "2023-12-06 12:07:34,347 INFO     Training average negative_sample_loss at step 52000: 0.085044\n",
      "2023-12-06 12:07:34,347 INFO     Training average loss at step 52000: 0.099155\n",
      "2023-12-06 12:07:59,053 INFO     Training average positive_sample_loss at step 52100: 0.113663\n",
      "2023-12-06 12:07:59,053 INFO     Training average negative_sample_loss at step 52100: 0.085615\n",
      "2023-12-06 12:07:59,053 INFO     Training average loss at step 52100: 0.099639\n",
      "2023-12-06 12:08:27,619 INFO     Training average positive_sample_loss at step 52200: 0.112622\n",
      "2023-12-06 12:08:27,619 INFO     Training average negative_sample_loss at step 52200: 0.085175\n",
      "2023-12-06 12:08:27,619 INFO     Training average loss at step 52200: 0.098898\n",
      "2023-12-06 12:08:53,224 INFO     Training average positive_sample_loss at step 52300: 0.113696\n",
      "2023-12-06 12:08:53,224 INFO     Training average negative_sample_loss at step 52300: 0.085843\n",
      "2023-12-06 12:08:53,224 INFO     Training average loss at step 52300: 0.099769\n",
      "2023-12-06 12:09:24,167 INFO     Training average positive_sample_loss at step 52400: 0.113163\n",
      "2023-12-06 12:09:24,167 INFO     Training average negative_sample_loss at step 52400: 0.085454\n",
      "2023-12-06 12:09:24,167 INFO     Training average loss at step 52400: 0.099308\n",
      "2023-12-06 12:09:49,357 INFO     Training average positive_sample_loss at step 52500: 0.112823\n",
      "2023-12-06 12:09:49,357 INFO     Training average negative_sample_loss at step 52500: 0.085091\n",
      "2023-12-06 12:09:49,357 INFO     Training average loss at step 52500: 0.098957\n",
      "2023-12-06 12:10:13,804 INFO     Training average positive_sample_loss at step 52600: 0.113613\n",
      "2023-12-06 12:10:13,805 INFO     Training average negative_sample_loss at step 52600: 0.084889\n",
      "2023-12-06 12:10:13,805 INFO     Training average loss at step 52600: 0.099251\n",
      "2023-12-06 12:10:42,616 INFO     Training average positive_sample_loss at step 52700: 0.112979\n",
      "2023-12-06 12:10:42,617 INFO     Training average negative_sample_loss at step 52700: 0.084988\n",
      "2023-12-06 12:10:42,617 INFO     Training average loss at step 52700: 0.098984\n",
      "2023-12-06 12:11:08,304 INFO     Training average positive_sample_loss at step 52800: 0.113134\n",
      "2023-12-06 12:11:08,304 INFO     Training average negative_sample_loss at step 52800: 0.084573\n",
      "2023-12-06 12:11:08,304 INFO     Training average loss at step 52800: 0.098854\n",
      "2023-12-06 12:11:37,913 INFO     Training average positive_sample_loss at step 52900: 0.113948\n",
      "2023-12-06 12:11:37,914 INFO     Training average negative_sample_loss at step 52900: 0.085366\n",
      "2023-12-06 12:11:37,914 INFO     Training average loss at step 52900: 0.099657\n",
      "2023-12-06 12:12:02,748 INFO     Training average positive_sample_loss at step 53000: 0.112673\n",
      "2023-12-06 12:12:02,749 INFO     Training average negative_sample_loss at step 53000: 0.085318\n",
      "2023-12-06 12:12:02,749 INFO     Training average loss at step 53000: 0.098996\n",
      "2023-12-06 12:12:28,348 INFO     Training average positive_sample_loss at step 53100: 0.113353\n",
      "2023-12-06 12:12:28,348 INFO     Training average negative_sample_loss at step 53100: 0.085491\n",
      "2023-12-06 12:12:28,348 INFO     Training average loss at step 53100: 0.099422\n",
      "2023-12-06 12:12:58,739 INFO     Training average positive_sample_loss at step 53200: 0.112831\n",
      "2023-12-06 12:12:58,739 INFO     Training average negative_sample_loss at step 53200: 0.084662\n",
      "2023-12-06 12:12:58,739 INFO     Training average loss at step 53200: 0.098746\n",
      "2023-12-06 12:13:23,837 INFO     Training average positive_sample_loss at step 53300: 0.113338\n",
      "2023-12-06 12:13:23,838 INFO     Training average negative_sample_loss at step 53300: 0.084925\n",
      "2023-12-06 12:13:23,838 INFO     Training average loss at step 53300: 0.099131\n",
      "2023-12-06 12:13:48,711 INFO     Training average positive_sample_loss at step 53400: 0.114168\n",
      "2023-12-06 12:13:48,712 INFO     Training average negative_sample_loss at step 53400: 0.085289\n",
      "2023-12-06 12:13:48,712 INFO     Training average loss at step 53400: 0.099729\n",
      "2023-12-06 12:14:16,584 INFO     Training average positive_sample_loss at step 53500: 0.112567\n",
      "2023-12-06 12:14:16,584 INFO     Training average negative_sample_loss at step 53500: 0.084527\n",
      "2023-12-06 12:14:16,584 INFO     Training average loss at step 53500: 0.098547\n",
      "2023-12-06 12:14:41,575 INFO     Training average positive_sample_loss at step 53600: 0.112882\n",
      "2023-12-06 12:14:41,576 INFO     Training average negative_sample_loss at step 53600: 0.085201\n",
      "2023-12-06 12:14:41,576 INFO     Training average loss at step 53600: 0.099041\n",
      "2023-12-06 12:15:09,764 INFO     Training average positive_sample_loss at step 53700: 0.114005\n",
      "2023-12-06 12:15:09,765 INFO     Training average negative_sample_loss at step 53700: 0.085797\n",
      "2023-12-06 12:15:09,765 INFO     Training average loss at step 53700: 0.099901\n",
      "2023-12-06 12:15:34,761 INFO     Training average positive_sample_loss at step 53800: 0.112489\n",
      "2023-12-06 12:15:34,762 INFO     Training average negative_sample_loss at step 53800: 0.085249\n",
      "2023-12-06 12:15:34,762 INFO     Training average loss at step 53800: 0.098869\n",
      "2023-12-06 12:16:00,223 INFO     Training average positive_sample_loss at step 53900: 0.114118\n",
      "2023-12-06 12:16:00,223 INFO     Training average negative_sample_loss at step 53900: 0.085175\n",
      "2023-12-06 12:16:00,223 INFO     Training average loss at step 53900: 0.099647\n",
      "2023-12-06 12:16:28,125 INFO     Training average positive_sample_loss at step 54000: 0.113284\n",
      "2023-12-06 12:16:28,126 INFO     Training average negative_sample_loss at step 54000: 0.085014\n",
      "2023-12-06 12:16:28,126 INFO     Training average loss at step 54000: 0.099149\n",
      "2023-12-06 12:16:53,276 INFO     Training average positive_sample_loss at step 54100: 0.113221\n",
      "2023-12-06 12:16:53,276 INFO     Training average negative_sample_loss at step 54100: 0.084655\n",
      "2023-12-06 12:16:53,276 INFO     Training average loss at step 54100: 0.098938\n",
      "2023-12-06 12:17:21,190 INFO     Training average positive_sample_loss at step 54200: 0.113425\n",
      "2023-12-06 12:17:21,191 INFO     Training average negative_sample_loss at step 54200: 0.084588\n",
      "2023-12-06 12:17:21,191 INFO     Training average loss at step 54200: 0.099007\n",
      "2023-12-06 12:17:46,650 INFO     Training average positive_sample_loss at step 54300: 0.112397\n",
      "2023-12-06 12:17:46,650 INFO     Training average negative_sample_loss at step 54300: 0.084727\n",
      "2023-12-06 12:17:46,650 INFO     Training average loss at step 54300: 0.098562\n",
      "2023-12-06 12:18:12,160 INFO     Training average positive_sample_loss at step 54400: 0.114173\n",
      "2023-12-06 12:18:12,160 INFO     Training average negative_sample_loss at step 54400: 0.085096\n",
      "2023-12-06 12:18:12,160 INFO     Training average loss at step 54400: 0.099634\n",
      "2023-12-06 12:18:41,609 INFO     Training average positive_sample_loss at step 54500: 0.112580\n",
      "2023-12-06 12:18:41,609 INFO     Training average negative_sample_loss at step 54500: 0.085549\n",
      "2023-12-06 12:18:41,610 INFO     Training average loss at step 54500: 0.099064\n",
      "2023-12-06 12:19:06,361 INFO     Training average positive_sample_loss at step 54600: 0.113873\n",
      "2023-12-06 12:19:06,362 INFO     Training average negative_sample_loss at step 54600: 0.084894\n",
      "2023-12-06 12:19:06,362 INFO     Training average loss at step 54600: 0.099383\n",
      "2023-12-06 12:19:34,749 INFO     Training average positive_sample_loss at step 54700: 0.113537\n",
      "2023-12-06 12:19:34,750 INFO     Training average negative_sample_loss at step 54700: 0.084303\n",
      "2023-12-06 12:19:34,750 INFO     Training average loss at step 54700: 0.098920\n",
      "2023-12-06 12:20:00,833 INFO     Training average positive_sample_loss at step 54800: 0.112898\n",
      "2023-12-06 12:20:00,833 INFO     Training average negative_sample_loss at step 54800: 0.085138\n",
      "2023-12-06 12:20:00,833 INFO     Training average loss at step 54800: 0.099018\n",
      "2023-12-06 12:20:26,933 INFO     Training average positive_sample_loss at step 54900: 0.113423\n",
      "2023-12-06 12:20:26,933 INFO     Training average negative_sample_loss at step 54900: 0.084984\n",
      "2023-12-06 12:20:26,933 INFO     Training average loss at step 54900: 0.099203\n",
      "2023-12-06 12:20:56,102 INFO     Training average positive_sample_loss at step 55000: 0.113127\n",
      "2023-12-06 12:20:56,102 INFO     Training average negative_sample_loss at step 55000: 0.084695\n",
      "2023-12-06 12:20:56,103 INFO     Training average loss at step 55000: 0.098911\n",
      "2023-12-06 12:21:21,016 INFO     Training average positive_sample_loss at step 55100: 0.112957\n",
      "2023-12-06 12:21:21,017 INFO     Training average negative_sample_loss at step 55100: 0.085643\n",
      "2023-12-06 12:21:21,017 INFO     Training average loss at step 55100: 0.099300\n",
      "2023-12-06 12:21:46,164 INFO     Training average positive_sample_loss at step 55200: 0.113917\n",
      "2023-12-06 12:21:46,164 INFO     Training average negative_sample_loss at step 55200: 0.084355\n",
      "2023-12-06 12:21:46,164 INFO     Training average loss at step 55200: 0.099136\n",
      "2023-12-06 12:22:15,423 INFO     Training average positive_sample_loss at step 55300: 0.112504\n",
      "2023-12-06 12:22:15,423 INFO     Training average negative_sample_loss at step 55300: 0.084253\n",
      "2023-12-06 12:22:15,423 INFO     Training average loss at step 55300: 0.098378\n",
      "2023-12-06 12:22:39,525 INFO     Training average positive_sample_loss at step 55400: 0.113338\n",
      "2023-12-06 12:22:39,525 INFO     Training average negative_sample_loss at step 55400: 0.084936\n",
      "2023-12-06 12:22:39,525 INFO     Training average loss at step 55400: 0.099137\n",
      "2023-12-06 12:23:07,873 INFO     Training average positive_sample_loss at step 55500: 0.113272\n",
      "2023-12-06 12:23:07,873 INFO     Training average negative_sample_loss at step 55500: 0.084749\n",
      "2023-12-06 12:23:07,873 INFO     Training average loss at step 55500: 0.099011\n",
      "2023-12-06 12:23:32,651 INFO     Training average positive_sample_loss at step 55600: 0.113152\n",
      "2023-12-06 12:23:32,652 INFO     Training average negative_sample_loss at step 55600: 0.084452\n",
      "2023-12-06 12:23:32,652 INFO     Training average loss at step 55600: 0.098802\n",
      "2023-12-06 12:23:57,890 INFO     Training average positive_sample_loss at step 55700: 0.113532\n",
      "2023-12-06 12:23:57,891 INFO     Training average negative_sample_loss at step 55700: 0.085356\n",
      "2023-12-06 12:23:57,891 INFO     Training average loss at step 55700: 0.099444\n",
      "2023-12-06 12:24:27,315 INFO     Training average positive_sample_loss at step 55800: 0.113201\n",
      "2023-12-06 12:24:27,315 INFO     Training average negative_sample_loss at step 55800: 0.084922\n",
      "2023-12-06 12:24:27,315 INFO     Training average loss at step 55800: 0.099061\n",
      "2023-12-06 12:24:51,844 INFO     Training average positive_sample_loss at step 55900: 0.113413\n",
      "2023-12-06 12:24:51,844 INFO     Training average negative_sample_loss at step 55900: 0.084406\n",
      "2023-12-06 12:24:51,844 INFO     Training average loss at step 55900: 0.098910\n",
      "2023-12-06 12:25:21,725 INFO     Training average positive_sample_loss at step 56000: 0.113409\n",
      "2023-12-06 12:25:21,725 INFO     Training average negative_sample_loss at step 56000: 0.084963\n",
      "2023-12-06 12:25:21,725 INFO     Training average loss at step 56000: 0.099186\n",
      "2023-12-06 12:25:47,787 INFO     Training average positive_sample_loss at step 56100: 0.112571\n",
      "2023-12-06 12:25:47,788 INFO     Training average negative_sample_loss at step 56100: 0.085168\n",
      "2023-12-06 12:25:47,788 INFO     Training average loss at step 56100: 0.098870\n",
      "2023-12-06 12:26:12,806 INFO     Training average positive_sample_loss at step 56200: 0.113594\n",
      "2023-12-06 12:26:12,806 INFO     Training average negative_sample_loss at step 56200: 0.084285\n",
      "2023-12-06 12:26:12,806 INFO     Training average loss at step 56200: 0.098940\n",
      "2023-12-06 12:26:40,503 INFO     Training average positive_sample_loss at step 56300: 0.112707\n",
      "2023-12-06 12:26:40,503 INFO     Training average negative_sample_loss at step 56300: 0.083972\n",
      "2023-12-06 12:26:40,503 INFO     Training average loss at step 56300: 0.098339\n",
      "2023-12-06 12:27:04,805 INFO     Training average positive_sample_loss at step 56400: 0.112720\n",
      "2023-12-06 12:27:04,805 INFO     Training average negative_sample_loss at step 56400: 0.084974\n",
      "2023-12-06 12:27:04,805 INFO     Training average loss at step 56400: 0.098847\n",
      "2023-12-06 12:27:30,077 INFO     Training average positive_sample_loss at step 56500: 0.114460\n",
      "2023-12-06 12:27:30,077 INFO     Training average negative_sample_loss at step 56500: 0.084877\n",
      "2023-12-06 12:27:30,077 INFO     Training average loss at step 56500: 0.099668\n",
      "2023-12-06 12:27:58,884 INFO     Training average positive_sample_loss at step 56600: 0.112665\n",
      "2023-12-06 12:27:58,885 INFO     Training average negative_sample_loss at step 56600: 0.084831\n",
      "2023-12-06 12:27:58,885 INFO     Training average loss at step 56600: 0.098748\n",
      "2023-12-06 12:28:24,434 INFO     Training average positive_sample_loss at step 56700: 0.113618\n",
      "2023-12-06 12:28:24,434 INFO     Training average negative_sample_loss at step 56700: 0.085212\n",
      "2023-12-06 12:28:24,434 INFO     Training average loss at step 56700: 0.099415\n",
      "2023-12-06 12:28:52,042 INFO     Training average positive_sample_loss at step 56800: 0.112780\n",
      "2023-12-06 12:28:52,043 INFO     Training average negative_sample_loss at step 56800: 0.084810\n",
      "2023-12-06 12:28:52,043 INFO     Training average loss at step 56800: 0.098795\n",
      "2023-12-06 12:29:17,188 INFO     Training average positive_sample_loss at step 56900: 0.112955\n",
      "2023-12-06 12:29:17,189 INFO     Training average negative_sample_loss at step 56900: 0.085123\n",
      "2023-12-06 12:29:17,189 INFO     Training average loss at step 56900: 0.099039\n",
      "2023-12-06 12:29:42,794 INFO     Training average positive_sample_loss at step 57000: 0.113629\n",
      "2023-12-06 12:29:42,795 INFO     Training average negative_sample_loss at step 57000: 0.084666\n",
      "2023-12-06 12:29:42,795 INFO     Training average loss at step 57000: 0.099148\n",
      "2023-12-06 12:30:11,865 INFO     Training average positive_sample_loss at step 57100: 0.112595\n",
      "2023-12-06 12:30:11,865 INFO     Training average negative_sample_loss at step 57100: 0.084326\n",
      "2023-12-06 12:30:11,865 INFO     Training average loss at step 57100: 0.098461\n",
      "2023-12-06 12:30:38,729 INFO     Training average positive_sample_loss at step 57200: 0.113504\n",
      "2023-12-06 12:30:38,729 INFO     Training average negative_sample_loss at step 57200: 0.085109\n",
      "2023-12-06 12:30:38,729 INFO     Training average loss at step 57200: 0.099306\n",
      "2023-12-06 12:31:08,073 INFO     Training average positive_sample_loss at step 57300: 0.113528\n",
      "2023-12-06 12:31:08,074 INFO     Training average negative_sample_loss at step 57300: 0.084608\n",
      "2023-12-06 12:31:08,074 INFO     Training average loss at step 57300: 0.099068\n",
      "2023-12-06 12:31:32,121 INFO     Training average positive_sample_loss at step 57400: 0.112897\n",
      "2023-12-06 12:31:32,121 INFO     Training average negative_sample_loss at step 57400: 0.085095\n",
      "2023-12-06 12:31:32,121 INFO     Training average loss at step 57400: 0.098996\n",
      "2023-12-06 12:31:56,726 INFO     Training average positive_sample_loss at step 57500: 0.113685\n",
      "2023-12-06 12:31:56,726 INFO     Training average negative_sample_loss at step 57500: 0.084865\n",
      "2023-12-06 12:31:56,726 INFO     Training average loss at step 57500: 0.099275\n",
      "2023-12-06 12:32:25,416 INFO     Training average positive_sample_loss at step 57600: 0.112438\n",
      "2023-12-06 12:32:25,416 INFO     Training average negative_sample_loss at step 57600: 0.083780\n",
      "2023-12-06 12:32:25,416 INFO     Training average loss at step 57600: 0.098109\n",
      "2023-12-06 12:32:49,996 INFO     Training average positive_sample_loss at step 57700: 0.113293\n",
      "2023-12-06 12:32:49,996 INFO     Training average negative_sample_loss at step 57700: 0.084895\n",
      "2023-12-06 12:32:49,996 INFO     Training average loss at step 57700: 0.099094\n",
      "2023-12-06 12:33:18,250 INFO     Training average positive_sample_loss at step 57800: 0.114072\n",
      "2023-12-06 12:33:18,250 INFO     Training average negative_sample_loss at step 57800: 0.085206\n",
      "2023-12-06 12:33:18,250 INFO     Training average loss at step 57800: 0.099639\n",
      "2023-12-06 12:33:43,694 INFO     Training average positive_sample_loss at step 57900: 0.112164\n",
      "2023-12-06 12:33:43,694 INFO     Training average negative_sample_loss at step 57900: 0.083955\n",
      "2023-12-06 12:33:43,694 INFO     Training average loss at step 57900: 0.098060\n",
      "2023-12-06 12:34:10,049 INFO     Training average positive_sample_loss at step 58000: 0.113488\n",
      "2023-12-06 12:34:10,050 INFO     Training average negative_sample_loss at step 58000: 0.084524\n",
      "2023-12-06 12:34:10,050 INFO     Training average loss at step 58000: 0.099006\n",
      "2023-12-06 12:34:37,506 INFO     Training average positive_sample_loss at step 58100: 0.113364\n",
      "2023-12-06 12:34:37,506 INFO     Training average negative_sample_loss at step 58100: 0.084662\n",
      "2023-12-06 12:34:37,506 INFO     Training average loss at step 58100: 0.099013\n",
      "2023-12-06 12:35:02,474 INFO     Training average positive_sample_loss at step 58200: 0.113181\n",
      "2023-12-06 12:35:02,474 INFO     Training average negative_sample_loss at step 58200: 0.084411\n",
      "2023-12-06 12:35:02,475 INFO     Training average loss at step 58200: 0.098796\n",
      "2023-12-06 12:35:28,651 INFO     Training average positive_sample_loss at step 58300: 0.113652\n",
      "2023-12-06 12:35:28,651 INFO     Training average negative_sample_loss at step 58300: 0.084786\n",
      "2023-12-06 12:35:28,651 INFO     Training average loss at step 58300: 0.099219\n",
      "2023-12-06 12:35:57,797 INFO     Training average positive_sample_loss at step 58400: 0.112597\n",
      "2023-12-06 12:35:57,797 INFO     Training average negative_sample_loss at step 58400: 0.084638\n",
      "2023-12-06 12:35:57,797 INFO     Training average loss at step 58400: 0.098617\n",
      "2023-12-06 12:36:22,027 INFO     Training average positive_sample_loss at step 58500: 0.113537\n",
      "2023-12-06 12:36:22,027 INFO     Training average negative_sample_loss at step 58500: 0.084799\n",
      "2023-12-06 12:36:22,027 INFO     Training average loss at step 58500: 0.099168\n",
      "2023-12-06 12:36:52,206 INFO     Training average positive_sample_loss at step 58600: 0.112838\n",
      "2023-12-06 12:36:52,207 INFO     Training average negative_sample_loss at step 58600: 0.083916\n",
      "2023-12-06 12:36:52,207 INFO     Training average loss at step 58600: 0.098377\n",
      "2023-12-06 12:37:17,330 INFO     Training average positive_sample_loss at step 58700: 0.112463\n",
      "2023-12-06 12:37:17,331 INFO     Training average negative_sample_loss at step 58700: 0.083694\n",
      "2023-12-06 12:37:17,331 INFO     Training average loss at step 58700: 0.098079\n",
      "2023-12-06 12:37:42,943 INFO     Training average positive_sample_loss at step 58800: 0.114102\n",
      "2023-12-06 12:37:42,943 INFO     Training average negative_sample_loss at step 58800: 0.084719\n",
      "2023-12-06 12:37:42,943 INFO     Training average loss at step 58800: 0.099410\n",
      "2023-12-06 12:38:11,611 INFO     Training average positive_sample_loss at step 58900: 0.113177\n",
      "2023-12-06 12:38:11,611 INFO     Training average negative_sample_loss at step 58900: 0.084746\n",
      "2023-12-06 12:38:11,611 INFO     Training average loss at step 58900: 0.098962\n",
      "2023-12-06 12:38:36,850 INFO     Training average positive_sample_loss at step 59000: 0.113342\n",
      "2023-12-06 12:38:36,850 INFO     Training average negative_sample_loss at step 59000: 0.085142\n",
      "2023-12-06 12:38:36,850 INFO     Training average loss at step 59000: 0.099242\n",
      "2023-12-06 12:39:05,328 INFO     Training average positive_sample_loss at step 59100: 0.112734\n",
      "2023-12-06 12:39:05,329 INFO     Training average negative_sample_loss at step 59100: 0.084013\n",
      "2023-12-06 12:39:05,329 INFO     Training average loss at step 59100: 0.098374\n",
      "2023-12-06 12:39:30,411 INFO     Training average positive_sample_loss at step 59200: 0.112978\n",
      "2023-12-06 12:39:30,411 INFO     Training average negative_sample_loss at step 59200: 0.084010\n",
      "2023-12-06 12:39:30,411 INFO     Training average loss at step 59200: 0.098494\n",
      "2023-12-06 12:39:56,214 INFO     Training average positive_sample_loss at step 59300: 0.113480\n",
      "2023-12-06 12:39:56,214 INFO     Training average negative_sample_loss at step 59300: 0.084924\n",
      "2023-12-06 12:39:56,214 INFO     Training average loss at step 59300: 0.099202\n",
      "2023-12-06 12:40:23,800 INFO     Training average positive_sample_loss at step 59400: 0.113238\n",
      "2023-12-06 12:40:23,801 INFO     Training average negative_sample_loss at step 59400: 0.084129\n",
      "2023-12-06 12:40:23,801 INFO     Training average loss at step 59400: 0.098684\n",
      "2023-12-06 12:40:49,034 INFO     Training average positive_sample_loss at step 59500: 0.112576\n",
      "2023-12-06 12:40:49,035 INFO     Training average negative_sample_loss at step 59500: 0.083952\n",
      "2023-12-06 12:40:49,035 INFO     Training average loss at step 59500: 0.098264\n",
      "2023-12-06 12:41:18,457 INFO     Training average positive_sample_loss at step 59600: 0.113846\n",
      "2023-12-06 12:41:18,458 INFO     Training average negative_sample_loss at step 59600: 0.085386\n",
      "2023-12-06 12:41:18,458 INFO     Training average loss at step 59600: 0.099616\n",
      "2023-12-06 12:41:42,361 INFO     Training average positive_sample_loss at step 59700: 0.112070\n",
      "2023-12-06 12:41:42,362 INFO     Training average negative_sample_loss at step 59700: 0.084627\n",
      "2023-12-06 12:41:42,362 INFO     Training average loss at step 59700: 0.098349\n",
      "2023-12-06 12:42:06,906 INFO     Training average positive_sample_loss at step 59800: 0.113711\n",
      "2023-12-06 12:42:06,907 INFO     Training average negative_sample_loss at step 59800: 0.085016\n",
      "2023-12-06 12:42:06,907 INFO     Training average loss at step 59800: 0.099364\n",
      "2023-12-06 12:42:35,468 INFO     Training average positive_sample_loss at step 59900: 0.113206\n",
      "2023-12-06 12:42:35,469 INFO     Training average negative_sample_loss at step 59900: 0.084816\n",
      "2023-12-06 12:42:35,469 INFO     Training average loss at step 59900: 0.099011\n",
      "2023-12-06 12:43:15,217 INFO     Training average positive_sample_loss at step 60000: 0.113177\n",
      "2023-12-06 12:43:15,217 INFO     Training average negative_sample_loss at step 60000: 0.083987\n",
      "2023-12-06 12:43:15,217 INFO     Training average loss at step 60000: 0.098582\n",
      "2023-12-06 12:43:15,217 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 12:43:15,723 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 12:43:45,337 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 12:44:06,350 INFO     Valid MRR at step 60000: 0.640388\n",
      "2023-12-06 12:44:06,351 INFO     Valid MR at step 60000: 236.038372\n",
      "2023-12-06 12:44:06,351 INFO     Valid HITS@1 at step 60000: 0.583805\n",
      "2023-12-06 12:44:06,351 INFO     Valid HITS@3 at step 60000: 0.661368\n",
      "2023-12-06 12:44:06,351 INFO     Valid HITS@10 at step 60000: 0.755065\n",
      "2023-12-06 12:44:28,236 INFO     Training average positive_sample_loss at step 60100: 0.113471\n",
      "2023-12-06 12:44:28,236 INFO     Training average negative_sample_loss at step 60100: 0.084201\n",
      "2023-12-06 12:44:28,236 INFO     Training average loss at step 60100: 0.098836\n",
      "2023-12-06 12:44:58,252 INFO     Training average positive_sample_loss at step 60200: 0.112666\n",
      "2023-12-06 12:44:58,252 INFO     Training average negative_sample_loss at step 60200: 0.085889\n",
      "2023-12-06 12:44:58,252 INFO     Training average loss at step 60200: 0.099277\n",
      "2023-12-06 12:45:24,436 INFO     Training average positive_sample_loss at step 60300: 0.113097\n",
      "2023-12-06 12:45:24,436 INFO     Training average negative_sample_loss at step 60300: 0.084146\n",
      "2023-12-06 12:45:24,436 INFO     Training average loss at step 60300: 0.098622\n",
      "2023-12-06 12:45:52,474 INFO     Training average positive_sample_loss at step 60400: 0.113723\n",
      "2023-12-06 12:45:52,474 INFO     Training average negative_sample_loss at step 60400: 0.084974\n",
      "2023-12-06 12:45:52,475 INFO     Training average loss at step 60400: 0.099348\n",
      "2023-12-06 12:46:17,030 INFO     Training average positive_sample_loss at step 60500: 0.112261\n",
      "2023-12-06 12:46:17,030 INFO     Training average negative_sample_loss at step 60500: 0.084204\n",
      "2023-12-06 12:46:17,031 INFO     Training average loss at step 60500: 0.098232\n",
      "2023-12-06 12:46:41,945 INFO     Training average positive_sample_loss at step 60600: 0.114023\n",
      "2023-12-06 12:46:41,946 INFO     Training average negative_sample_loss at step 60600: 0.084473\n",
      "2023-12-06 12:46:41,946 INFO     Training average loss at step 60600: 0.099248\n",
      "2023-12-06 12:47:10,933 INFO     Training average positive_sample_loss at step 60700: 0.112085\n",
      "2023-12-06 12:47:10,933 INFO     Training average negative_sample_loss at step 60700: 0.084276\n",
      "2023-12-06 12:47:10,934 INFO     Training average loss at step 60700: 0.098180\n",
      "2023-12-06 12:47:35,981 INFO     Training average positive_sample_loss at step 60800: 0.113797\n",
      "2023-12-06 12:47:35,982 INFO     Training average negative_sample_loss at step 60800: 0.085054\n",
      "2023-12-06 12:47:35,982 INFO     Training average loss at step 60800: 0.099425\n",
      "2023-12-06 12:48:06,733 INFO     Training average positive_sample_loss at step 60900: 0.113418\n",
      "2023-12-06 12:48:06,733 INFO     Training average negative_sample_loss at step 60900: 0.084038\n",
      "2023-12-06 12:48:06,733 INFO     Training average loss at step 60900: 0.098728\n",
      "2023-12-06 12:48:30,934 INFO     Training average positive_sample_loss at step 61000: 0.112730\n",
      "2023-12-06 12:48:30,934 INFO     Training average negative_sample_loss at step 61000: 0.084576\n",
      "2023-12-06 12:48:30,934 INFO     Training average loss at step 61000: 0.098653\n",
      "2023-12-06 12:48:55,214 INFO     Training average positive_sample_loss at step 61100: 0.113302\n",
      "2023-12-06 12:48:55,214 INFO     Training average negative_sample_loss at step 61100: 0.083719\n",
      "2023-12-06 12:48:55,214 INFO     Training average loss at step 61100: 0.098510\n",
      "2023-12-06 12:49:25,022 INFO     Training average positive_sample_loss at step 61200: 0.112896\n",
      "2023-12-06 12:49:25,022 INFO     Training average negative_sample_loss at step 61200: 0.084800\n",
      "2023-12-06 12:49:25,022 INFO     Training average loss at step 61200: 0.098848\n",
      "2023-12-06 12:49:50,504 INFO     Training average positive_sample_loss at step 61300: 0.112454\n",
      "2023-12-06 12:49:50,504 INFO     Training average negative_sample_loss at step 61300: 0.084708\n",
      "2023-12-06 12:49:50,504 INFO     Training average loss at step 61300: 0.098581\n",
      "2023-12-06 12:50:15,316 INFO     Training average positive_sample_loss at step 61400: 0.114249\n",
      "2023-12-06 12:50:15,317 INFO     Training average negative_sample_loss at step 61400: 0.084525\n",
      "2023-12-06 12:50:15,317 INFO     Training average loss at step 61400: 0.099387\n",
      "2023-12-06 12:50:43,716 INFO     Training average positive_sample_loss at step 61500: 0.112127\n",
      "2023-12-06 12:50:43,717 INFO     Training average negative_sample_loss at step 61500: 0.084700\n",
      "2023-12-06 12:50:43,717 INFO     Training average loss at step 61500: 0.098413\n",
      "2023-12-06 12:51:08,270 INFO     Training average positive_sample_loss at step 61600: 0.113431\n",
      "2023-12-06 12:51:08,271 INFO     Training average negative_sample_loss at step 61600: 0.084648\n",
      "2023-12-06 12:51:08,271 INFO     Training average loss at step 61600: 0.099040\n",
      "2023-12-06 12:51:35,919 INFO     Training average positive_sample_loss at step 61700: 0.113225\n",
      "2023-12-06 12:51:35,920 INFO     Training average negative_sample_loss at step 61700: 0.084038\n",
      "2023-12-06 12:51:35,920 INFO     Training average loss at step 61700: 0.098631\n",
      "2023-12-06 12:52:00,359 INFO     Training average positive_sample_loss at step 61800: 0.112612\n",
      "2023-12-06 12:52:00,360 INFO     Training average negative_sample_loss at step 61800: 0.084643\n",
      "2023-12-06 12:52:00,360 INFO     Training average loss at step 61800: 0.098628\n",
      "2023-12-06 12:52:25,069 INFO     Training average positive_sample_loss at step 61900: 0.113852\n",
      "2023-12-06 12:52:25,070 INFO     Training average negative_sample_loss at step 61900: 0.084849\n",
      "2023-12-06 12:52:25,070 INFO     Training average loss at step 61900: 0.099351\n",
      "2023-12-06 12:52:53,323 INFO     Training average positive_sample_loss at step 62000: 0.112901\n",
      "2023-12-06 12:52:53,324 INFO     Training average negative_sample_loss at step 62000: 0.084349\n",
      "2023-12-06 12:52:53,324 INFO     Training average loss at step 62000: 0.098625\n",
      "2023-12-06 12:53:19,349 INFO     Training average positive_sample_loss at step 62100: 0.113053\n",
      "2023-12-06 12:53:19,349 INFO     Training average negative_sample_loss at step 62100: 0.084991\n",
      "2023-12-06 12:53:19,349 INFO     Training average loss at step 62100: 0.099022\n",
      "2023-12-06 12:53:49,717 INFO     Training average positive_sample_loss at step 62200: 0.113285\n",
      "2023-12-06 12:53:49,718 INFO     Training average negative_sample_loss at step 62200: 0.084290\n",
      "2023-12-06 12:53:49,718 INFO     Training average loss at step 62200: 0.098787\n",
      "2023-12-06 12:54:14,341 INFO     Training average positive_sample_loss at step 62300: 0.112416\n",
      "2023-12-06 12:54:14,341 INFO     Training average negative_sample_loss at step 62300: 0.084154\n",
      "2023-12-06 12:54:14,341 INFO     Training average loss at step 62300: 0.098285\n",
      "2023-12-06 12:54:38,370 INFO     Training average positive_sample_loss at step 62400: 0.113661\n",
      "2023-12-06 12:54:38,370 INFO     Training average negative_sample_loss at step 62400: 0.085162\n",
      "2023-12-06 12:54:38,370 INFO     Training average loss at step 62400: 0.099412\n",
      "2023-12-06 12:55:07,532 INFO     Training average positive_sample_loss at step 62500: 0.112583\n",
      "2023-12-06 12:55:07,532 INFO     Training average negative_sample_loss at step 62500: 0.084163\n",
      "2023-12-06 12:55:07,532 INFO     Training average loss at step 62500: 0.098373\n",
      "2023-12-06 12:55:33,112 INFO     Training average positive_sample_loss at step 62600: 0.113643\n",
      "2023-12-06 12:55:33,112 INFO     Training average negative_sample_loss at step 62600: 0.084292\n",
      "2023-12-06 12:55:33,112 INFO     Training average loss at step 62600: 0.098968\n",
      "2023-12-06 12:56:02,002 INFO     Training average positive_sample_loss at step 62700: 0.113378\n",
      "2023-12-06 12:56:02,002 INFO     Training average negative_sample_loss at step 62700: 0.084065\n",
      "2023-12-06 12:56:02,002 INFO     Training average loss at step 62700: 0.098722\n",
      "2023-12-06 12:56:28,122 INFO     Training average positive_sample_loss at step 62800: 0.112949\n",
      "2023-12-06 12:56:28,122 INFO     Training average negative_sample_loss at step 62800: 0.084759\n",
      "2023-12-06 12:56:28,123 INFO     Training average loss at step 62800: 0.098854\n",
      "2023-12-06 12:56:53,688 INFO     Training average positive_sample_loss at step 62900: 0.112810\n",
      "2023-12-06 12:56:53,688 INFO     Training average negative_sample_loss at step 62900: 0.085215\n",
      "2023-12-06 12:56:53,689 INFO     Training average loss at step 62900: 0.099013\n",
      "2023-12-06 12:57:23,027 INFO     Training average positive_sample_loss at step 63000: 0.113391\n",
      "2023-12-06 12:57:23,027 INFO     Training average negative_sample_loss at step 63000: 0.084649\n",
      "2023-12-06 12:57:23,027 INFO     Training average loss at step 63000: 0.099020\n",
      "2023-12-06 12:57:48,336 INFO     Training average positive_sample_loss at step 63100: 0.112452\n",
      "2023-12-06 12:57:48,337 INFO     Training average negative_sample_loss at step 63100: 0.084350\n",
      "2023-12-06 12:57:48,337 INFO     Training average loss at step 63100: 0.098401\n",
      "2023-12-06 12:58:14,110 INFO     Training average positive_sample_loss at step 63200: 0.113606\n",
      "2023-12-06 12:58:14,110 INFO     Training average negative_sample_loss at step 63200: 0.084835\n",
      "2023-12-06 12:58:14,111 INFO     Training average loss at step 63200: 0.099221\n",
      "2023-12-06 12:58:42,627 INFO     Training average positive_sample_loss at step 63300: 0.112690\n",
      "2023-12-06 12:58:42,627 INFO     Training average negative_sample_loss at step 63300: 0.083910\n",
      "2023-12-06 12:58:42,627 INFO     Training average loss at step 63300: 0.098300\n",
      "2023-12-06 12:59:08,075 INFO     Training average positive_sample_loss at step 63400: 0.113382\n",
      "2023-12-06 12:59:08,076 INFO     Training average negative_sample_loss at step 63400: 0.083951\n",
      "2023-12-06 12:59:08,076 INFO     Training average loss at step 63400: 0.098666\n",
      "2023-12-06 12:59:38,546 INFO     Training average positive_sample_loss at step 63500: 0.112564\n",
      "2023-12-06 12:59:38,546 INFO     Training average negative_sample_loss at step 63500: 0.084406\n",
      "2023-12-06 12:59:38,546 INFO     Training average loss at step 63500: 0.098485\n",
      "2023-12-06 13:00:03,500 INFO     Training average positive_sample_loss at step 63600: 0.112813\n",
      "2023-12-06 13:00:03,500 INFO     Training average negative_sample_loss at step 63600: 0.084533\n",
      "2023-12-06 13:00:03,500 INFO     Training average loss at step 63600: 0.098673\n",
      "2023-12-06 13:00:29,611 INFO     Training average positive_sample_loss at step 63700: 0.113608\n",
      "2023-12-06 13:00:29,612 INFO     Training average negative_sample_loss at step 63700: 0.084385\n",
      "2023-12-06 13:00:29,612 INFO     Training average loss at step 63700: 0.098996\n",
      "2023-12-06 13:00:57,671 INFO     Training average positive_sample_loss at step 63800: 0.112815\n",
      "2023-12-06 13:00:57,672 INFO     Training average negative_sample_loss at step 63800: 0.084708\n",
      "2023-12-06 13:00:57,672 INFO     Training average loss at step 63800: 0.098761\n",
      "2023-12-06 13:01:23,314 INFO     Training average positive_sample_loss at step 63900: 0.113200\n",
      "2023-12-06 13:01:23,314 INFO     Training average negative_sample_loss at step 63900: 0.084632\n",
      "2023-12-06 13:01:23,314 INFO     Training average loss at step 63900: 0.098916\n",
      "2023-12-06 13:01:52,892 INFO     Training average positive_sample_loss at step 64000: 0.113313\n",
      "2023-12-06 13:01:52,892 INFO     Training average negative_sample_loss at step 64000: 0.084540\n",
      "2023-12-06 13:01:52,892 INFO     Training average loss at step 64000: 0.098927\n",
      "2023-12-06 13:02:17,464 INFO     Training average positive_sample_loss at step 64100: 0.113051\n",
      "2023-12-06 13:02:17,465 INFO     Training average negative_sample_loss at step 64100: 0.085519\n",
      "2023-12-06 13:02:17,465 INFO     Training average loss at step 64100: 0.099285\n",
      "2023-12-06 13:02:42,917 INFO     Training average positive_sample_loss at step 64200: 0.113015\n",
      "2023-12-06 13:02:42,917 INFO     Training average negative_sample_loss at step 64200: 0.083651\n",
      "2023-12-06 13:02:42,917 INFO     Training average loss at step 64200: 0.098333\n",
      "2023-12-06 13:03:10,736 INFO     Training average positive_sample_loss at step 64300: 0.112653\n",
      "2023-12-06 13:03:10,737 INFO     Training average negative_sample_loss at step 64300: 0.084350\n",
      "2023-12-06 13:03:10,737 INFO     Training average loss at step 64300: 0.098501\n",
      "2023-12-06 13:03:36,012 INFO     Training average positive_sample_loss at step 64400: 0.112799\n",
      "2023-12-06 13:03:36,013 INFO     Training average negative_sample_loss at step 64400: 0.084946\n",
      "2023-12-06 13:03:36,013 INFO     Training average loss at step 64400: 0.098872\n",
      "2023-12-06 13:04:03,762 INFO     Training average positive_sample_loss at step 64500: 0.113949\n",
      "2023-12-06 13:04:03,762 INFO     Training average negative_sample_loss at step 64500: 0.084834\n",
      "2023-12-06 13:04:03,762 INFO     Training average loss at step 64500: 0.099391\n",
      "2023-12-06 13:04:30,542 INFO     Training average positive_sample_loss at step 64600: 0.112106\n",
      "2023-12-06 13:04:30,542 INFO     Training average negative_sample_loss at step 64600: 0.084592\n",
      "2023-12-06 13:04:30,542 INFO     Training average loss at step 64600: 0.098349\n",
      "2023-12-06 13:04:56,517 INFO     Training average positive_sample_loss at step 64700: 0.113390\n",
      "2023-12-06 13:04:56,517 INFO     Training average negative_sample_loss at step 64700: 0.084061\n",
      "2023-12-06 13:04:56,517 INFO     Training average loss at step 64700: 0.098726\n",
      "2023-12-06 13:05:24,556 INFO     Training average positive_sample_loss at step 64800: 0.113381\n",
      "2023-12-06 13:05:24,556 INFO     Training average negative_sample_loss at step 64800: 0.084394\n",
      "2023-12-06 13:05:24,557 INFO     Training average loss at step 64800: 0.098888\n",
      "2023-12-06 13:05:49,075 INFO     Training average positive_sample_loss at step 64900: 0.113069\n",
      "2023-12-06 13:05:49,075 INFO     Training average negative_sample_loss at step 64900: 0.084968\n",
      "2023-12-06 13:05:49,076 INFO     Training average loss at step 64900: 0.099019\n",
      "2023-12-06 13:06:14,063 INFO     Training average positive_sample_loss at step 65000: 0.113503\n",
      "2023-12-06 13:06:14,063 INFO     Training average negative_sample_loss at step 65000: 0.084564\n",
      "2023-12-06 13:06:14,064 INFO     Training average loss at step 65000: 0.099033\n",
      "2023-12-06 13:06:42,683 INFO     Training average positive_sample_loss at step 65100: 0.112294\n",
      "2023-12-06 13:06:42,683 INFO     Training average negative_sample_loss at step 65100: 0.083954\n",
      "2023-12-06 13:06:42,683 INFO     Training average loss at step 65100: 0.098124\n",
      "2023-12-06 13:07:09,311 INFO     Training average positive_sample_loss at step 65200: 0.113151\n",
      "2023-12-06 13:07:09,312 INFO     Training average negative_sample_loss at step 65200: 0.085327\n",
      "2023-12-06 13:07:09,312 INFO     Training average loss at step 65200: 0.099239\n",
      "2023-12-06 13:07:37,016 INFO     Training average positive_sample_loss at step 65300: 0.113672\n",
      "2023-12-06 13:07:37,016 INFO     Training average negative_sample_loss at step 65300: 0.084424\n",
      "2023-12-06 13:07:37,016 INFO     Training average loss at step 65300: 0.099048\n",
      "2023-12-06 13:08:03,006 INFO     Training average positive_sample_loss at step 65400: 0.112802\n",
      "2023-12-06 13:08:03,006 INFO     Training average negative_sample_loss at step 65400: 0.084543\n",
      "2023-12-06 13:08:03,006 INFO     Training average loss at step 65400: 0.098673\n",
      "2023-12-06 13:08:28,062 INFO     Training average positive_sample_loss at step 65500: 0.113133\n",
      "2023-12-06 13:08:28,062 INFO     Training average negative_sample_loss at step 65500: 0.084336\n",
      "2023-12-06 13:08:28,062 INFO     Training average loss at step 65500: 0.098735\n",
      "2023-12-06 13:08:55,552 INFO     Training average positive_sample_loss at step 65600: 0.112629\n",
      "2023-12-06 13:08:55,553 INFO     Training average negative_sample_loss at step 65600: 0.084367\n",
      "2023-12-06 13:08:55,553 INFO     Training average loss at step 65600: 0.098498\n",
      "2023-12-06 13:09:21,984 INFO     Training average positive_sample_loss at step 65700: 0.112752\n",
      "2023-12-06 13:09:21,984 INFO     Training average negative_sample_loss at step 65700: 0.084633\n",
      "2023-12-06 13:09:21,984 INFO     Training average loss at step 65700: 0.098692\n",
      "2023-12-06 13:09:50,519 INFO     Training average positive_sample_loss at step 65800: 0.113571\n",
      "2023-12-06 13:09:50,519 INFO     Training average negative_sample_loss at step 65800: 0.083305\n",
      "2023-12-06 13:09:50,519 INFO     Training average loss at step 65800: 0.098438\n",
      "2023-12-06 13:10:15,993 INFO     Training average positive_sample_loss at step 65900: 0.112603\n",
      "2023-12-06 13:10:15,994 INFO     Training average negative_sample_loss at step 65900: 0.084308\n",
      "2023-12-06 13:10:15,994 INFO     Training average loss at step 65900: 0.098455\n",
      "2023-12-06 13:10:40,254 INFO     Training average positive_sample_loss at step 66000: 0.112926\n",
      "2023-12-06 13:10:40,254 INFO     Training average negative_sample_loss at step 66000: 0.084248\n",
      "2023-12-06 13:10:40,254 INFO     Training average loss at step 66000: 0.098587\n",
      "2023-12-06 13:11:10,172 INFO     Training average positive_sample_loss at step 66100: 0.113289\n",
      "2023-12-06 13:11:10,172 INFO     Training average negative_sample_loss at step 66100: 0.084629\n",
      "2023-12-06 13:11:10,173 INFO     Training average loss at step 66100: 0.098959\n",
      "2023-12-06 13:11:36,000 INFO     Training average positive_sample_loss at step 66200: 0.112721\n",
      "2023-12-06 13:11:36,001 INFO     Training average negative_sample_loss at step 66200: 0.084954\n",
      "2023-12-06 13:11:36,001 INFO     Training average loss at step 66200: 0.098837\n",
      "2023-12-06 13:12:00,831 INFO     Training average positive_sample_loss at step 66300: 0.113793\n",
      "2023-12-06 13:12:00,831 INFO     Training average negative_sample_loss at step 66300: 0.084254\n",
      "2023-12-06 13:12:00,831 INFO     Training average loss at step 66300: 0.099023\n",
      "2023-12-06 13:12:28,891 INFO     Training average positive_sample_loss at step 66400: 0.112275\n",
      "2023-12-06 13:12:28,891 INFO     Training average negative_sample_loss at step 66400: 0.084549\n",
      "2023-12-06 13:12:28,891 INFO     Training average loss at step 66400: 0.098412\n",
      "2023-12-06 13:12:53,205 INFO     Training average positive_sample_loss at step 66500: 0.113353\n",
      "2023-12-06 13:12:53,205 INFO     Training average negative_sample_loss at step 66500: 0.084385\n",
      "2023-12-06 13:12:53,206 INFO     Training average loss at step 66500: 0.098869\n",
      "2023-12-06 13:13:21,374 INFO     Training average positive_sample_loss at step 66600: 0.112461\n",
      "2023-12-06 13:13:21,375 INFO     Training average negative_sample_loss at step 66600: 0.084110\n",
      "2023-12-06 13:13:21,375 INFO     Training average loss at step 66600: 0.098286\n",
      "2023-12-06 13:13:46,782 INFO     Training average positive_sample_loss at step 66700: 0.113058\n",
      "2023-12-06 13:13:46,783 INFO     Training average negative_sample_loss at step 66700: 0.084794\n",
      "2023-12-06 13:13:46,783 INFO     Training average loss at step 66700: 0.098926\n",
      "2023-12-06 13:14:12,147 INFO     Training average positive_sample_loss at step 66800: 0.113328\n",
      "2023-12-06 13:14:12,148 INFO     Training average negative_sample_loss at step 66800: 0.084621\n",
      "2023-12-06 13:14:12,148 INFO     Training average loss at step 66800: 0.098975\n",
      "2023-12-06 13:14:40,181 INFO     Training average positive_sample_loss at step 66900: 0.113206\n",
      "2023-12-06 13:14:40,181 INFO     Training average negative_sample_loss at step 66900: 0.085240\n",
      "2023-12-06 13:14:40,181 INFO     Training average loss at step 66900: 0.099223\n",
      "2023-12-06 13:15:05,355 INFO     Training average positive_sample_loss at step 67000: 0.113162\n",
      "2023-12-06 13:15:05,356 INFO     Training average negative_sample_loss at step 67000: 0.084619\n",
      "2023-12-06 13:15:05,356 INFO     Training average loss at step 67000: 0.098890\n",
      "2023-12-06 13:15:34,207 INFO     Training average positive_sample_loss at step 67100: 0.113427\n",
      "2023-12-06 13:15:34,207 INFO     Training average negative_sample_loss at step 67100: 0.084336\n",
      "2023-12-06 13:15:34,207 INFO     Training average loss at step 67100: 0.098881\n",
      "2023-12-06 13:15:58,842 INFO     Training average positive_sample_loss at step 67200: 0.112198\n",
      "2023-12-06 13:15:58,842 INFO     Training average negative_sample_loss at step 67200: 0.083932\n",
      "2023-12-06 13:15:58,842 INFO     Training average loss at step 67200: 0.098065\n",
      "2023-12-06 13:16:28,758 INFO     Training average positive_sample_loss at step 67300: 0.113241\n",
      "2023-12-06 13:16:28,758 INFO     Training average negative_sample_loss at step 67300: 0.084345\n",
      "2023-12-06 13:16:28,758 INFO     Training average loss at step 67300: 0.098793\n",
      "2023-12-06 13:16:59,597 INFO     Training average positive_sample_loss at step 67400: 0.112864\n",
      "2023-12-06 13:16:59,597 INFO     Training average negative_sample_loss at step 67400: 0.084644\n",
      "2023-12-06 13:16:59,598 INFO     Training average loss at step 67400: 0.098754\n",
      "2023-12-06 13:17:24,311 INFO     Training average positive_sample_loss at step 67500: 0.113032\n",
      "2023-12-06 13:17:24,312 INFO     Training average negative_sample_loss at step 67500: 0.084469\n",
      "2023-12-06 13:17:24,312 INFO     Training average loss at step 67500: 0.098751\n",
      "2023-12-06 13:17:53,515 INFO     Training average positive_sample_loss at step 67600: 0.113402\n",
      "2023-12-06 13:17:53,516 INFO     Training average negative_sample_loss at step 67600: 0.084800\n",
      "2023-12-06 13:17:53,516 INFO     Training average loss at step 67600: 0.099101\n",
      "2023-12-06 13:18:19,371 INFO     Training average positive_sample_loss at step 67700: 0.112701\n",
      "2023-12-06 13:18:19,372 INFO     Training average negative_sample_loss at step 67700: 0.084074\n",
      "2023-12-06 13:18:19,372 INFO     Training average loss at step 67700: 0.098388\n",
      "2023-12-06 13:18:44,511 INFO     Training average positive_sample_loss at step 67800: 0.112634\n",
      "2023-12-06 13:18:44,511 INFO     Training average negative_sample_loss at step 67800: 0.084628\n",
      "2023-12-06 13:18:44,511 INFO     Training average loss at step 67800: 0.098631\n",
      "2023-12-06 13:19:13,173 INFO     Training average positive_sample_loss at step 67900: 0.113681\n",
      "2023-12-06 13:19:13,173 INFO     Training average negative_sample_loss at step 67900: 0.085214\n",
      "2023-12-06 13:19:13,173 INFO     Training average loss at step 67900: 0.099448\n",
      "2023-12-06 13:19:38,187 INFO     Training average positive_sample_loss at step 68000: 0.112169\n",
      "2023-12-06 13:19:38,187 INFO     Training average negative_sample_loss at step 68000: 0.083820\n",
      "2023-12-06 13:19:38,187 INFO     Training average loss at step 68000: 0.097994\n",
      "2023-12-06 13:20:04,173 INFO     Training average positive_sample_loss at step 68100: 0.113937\n",
      "2023-12-06 13:20:04,173 INFO     Training average negative_sample_loss at step 68100: 0.085052\n",
      "2023-12-06 13:20:04,173 INFO     Training average loss at step 68100: 0.099494\n",
      "2023-12-06 13:20:33,410 INFO     Training average positive_sample_loss at step 68200: 0.112493\n",
      "2023-12-06 13:20:33,410 INFO     Training average negative_sample_loss at step 68200: 0.084408\n",
      "2023-12-06 13:20:33,410 INFO     Training average loss at step 68200: 0.098451\n",
      "2023-12-06 13:21:00,254 INFO     Training average positive_sample_loss at step 68300: 0.112629\n",
      "2023-12-06 13:21:00,254 INFO     Training average negative_sample_loss at step 68300: 0.084234\n",
      "2023-12-06 13:21:00,254 INFO     Training average loss at step 68300: 0.098431\n",
      "2023-12-06 13:21:28,531 INFO     Training average positive_sample_loss at step 68400: 0.113799\n",
      "2023-12-06 13:21:28,531 INFO     Training average negative_sample_loss at step 68400: 0.084277\n",
      "2023-12-06 13:21:28,531 INFO     Training average loss at step 68400: 0.099038\n",
      "2023-12-06 13:21:54,486 INFO     Training average positive_sample_loss at step 68500: 0.112062\n",
      "2023-12-06 13:21:54,486 INFO     Training average negative_sample_loss at step 68500: 0.083717\n",
      "2023-12-06 13:21:54,486 INFO     Training average loss at step 68500: 0.097889\n",
      "2023-12-06 13:22:20,218 INFO     Training average positive_sample_loss at step 68600: 0.113903\n",
      "2023-12-06 13:22:20,219 INFO     Training average negative_sample_loss at step 68600: 0.084962\n",
      "2023-12-06 13:22:20,219 INFO     Training average loss at step 68600: 0.099433\n",
      "2023-12-06 13:22:48,650 INFO     Training average positive_sample_loss at step 68700: 0.112405\n",
      "2023-12-06 13:22:48,651 INFO     Training average negative_sample_loss at step 68700: 0.084390\n",
      "2023-12-06 13:22:48,651 INFO     Training average loss at step 68700: 0.098398\n",
      "2023-12-06 13:23:14,557 INFO     Training average positive_sample_loss at step 68800: 0.112795\n",
      "2023-12-06 13:23:14,557 INFO     Training average negative_sample_loss at step 68800: 0.083874\n",
      "2023-12-06 13:23:14,557 INFO     Training average loss at step 68800: 0.098334\n",
      "2023-12-06 13:23:42,150 INFO     Training average positive_sample_loss at step 68900: 0.113850\n",
      "2023-12-06 13:23:42,151 INFO     Training average negative_sample_loss at step 68900: 0.084144\n",
      "2023-12-06 13:23:42,151 INFO     Training average loss at step 68900: 0.098997\n",
      "2023-12-06 13:24:08,135 INFO     Training average positive_sample_loss at step 69000: 0.112842\n",
      "2023-12-06 13:24:08,135 INFO     Training average negative_sample_loss at step 69000: 0.084975\n",
      "2023-12-06 13:24:08,135 INFO     Training average loss at step 69000: 0.098908\n",
      "2023-12-06 13:24:33,643 INFO     Training average positive_sample_loss at step 69100: 0.112841\n",
      "2023-12-06 13:24:33,643 INFO     Training average negative_sample_loss at step 69100: 0.084012\n",
      "2023-12-06 13:24:33,643 INFO     Training average loss at step 69100: 0.098427\n",
      "2023-12-06 13:25:00,790 INFO     Training average positive_sample_loss at step 69200: 0.112477\n",
      "2023-12-06 13:25:00,790 INFO     Training average negative_sample_loss at step 69200: 0.084756\n",
      "2023-12-06 13:25:00,791 INFO     Training average loss at step 69200: 0.098616\n",
      "2023-12-06 13:25:26,967 INFO     Training average positive_sample_loss at step 69300: 0.112716\n",
      "2023-12-06 13:25:26,968 INFO     Training average negative_sample_loss at step 69300: 0.083424\n",
      "2023-12-06 13:25:26,968 INFO     Training average loss at step 69300: 0.098070\n",
      "2023-12-06 13:25:52,779 INFO     Training average positive_sample_loss at step 69400: 0.113916\n",
      "2023-12-06 13:25:52,779 INFO     Training average negative_sample_loss at step 69400: 0.085294\n",
      "2023-12-06 13:25:52,779 INFO     Training average loss at step 69400: 0.099605\n",
      "2023-12-06 13:26:20,336 INFO     Training average positive_sample_loss at step 69500: 0.112476\n",
      "2023-12-06 13:26:20,337 INFO     Training average negative_sample_loss at step 69500: 0.084099\n",
      "2023-12-06 13:26:20,337 INFO     Training average loss at step 69500: 0.098288\n",
      "2023-12-06 13:26:45,691 INFO     Training average positive_sample_loss at step 69600: 0.113363\n",
      "2023-12-06 13:26:45,691 INFO     Training average negative_sample_loss at step 69600: 0.085189\n",
      "2023-12-06 13:26:45,691 INFO     Training average loss at step 69600: 0.099276\n",
      "2023-12-06 13:27:13,877 INFO     Training average positive_sample_loss at step 69700: 0.112741\n",
      "2023-12-06 13:27:13,877 INFO     Training average negative_sample_loss at step 69700: 0.084806\n",
      "2023-12-06 13:27:13,877 INFO     Training average loss at step 69700: 0.098773\n",
      "2023-12-06 13:27:39,617 INFO     Training average positive_sample_loss at step 69800: 0.112650\n",
      "2023-12-06 13:27:39,617 INFO     Training average negative_sample_loss at step 69800: 0.084458\n",
      "2023-12-06 13:27:39,617 INFO     Training average loss at step 69800: 0.098554\n",
      "2023-12-06 13:28:05,359 INFO     Training average positive_sample_loss at step 69900: 0.113728\n",
      "2023-12-06 13:28:05,359 INFO     Training average negative_sample_loss at step 69900: 0.084932\n",
      "2023-12-06 13:28:05,359 INFO     Training average loss at step 69900: 0.099330\n",
      "2023-12-06 13:28:47,504 INFO     Training average positive_sample_loss at step 70000: 0.112697\n",
      "2023-12-06 13:28:47,504 INFO     Training average negative_sample_loss at step 70000: 0.083928\n",
      "2023-12-06 13:28:47,505 INFO     Training average loss at step 70000: 0.098313\n",
      "2023-12-06 13:28:47,505 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 13:28:48,160 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 13:29:16,589 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 13:29:36,468 INFO     Valid MRR at step 70000: 0.642734\n",
      "2023-12-06 13:29:36,468 INFO     Valid MR at step 70000: 236.683334\n",
      "2023-12-06 13:29:36,468 INFO     Valid HITS@1 at step 70000: 0.585920\n",
      "2023-12-06 13:29:36,468 INFO     Valid HITS@3 at step 70000: 0.667576\n",
      "2023-12-06 13:29:36,468 INFO     Valid HITS@10 at step 70000: 0.756361\n",
      "2023-12-06 13:29:57,268 INFO     Training average positive_sample_loss at step 70100: 0.112984\n",
      "2023-12-06 13:29:57,269 INFO     Training average negative_sample_loss at step 70100: 0.084612\n",
      "2023-12-06 13:29:57,269 INFO     Training average loss at step 70100: 0.098798\n",
      "2023-12-06 13:30:27,321 INFO     Training average positive_sample_loss at step 70200: 0.112780\n",
      "2023-12-06 13:30:27,321 INFO     Training average negative_sample_loss at step 70200: 0.083846\n",
      "2023-12-06 13:30:27,321 INFO     Training average loss at step 70200: 0.098313\n",
      "2023-12-06 13:30:51,319 INFO     Training average positive_sample_loss at step 70300: 0.112640\n",
      "2023-12-06 13:30:51,319 INFO     Training average negative_sample_loss at step 70300: 0.084363\n",
      "2023-12-06 13:30:51,319 INFO     Training average loss at step 70300: 0.098501\n",
      "2023-12-06 13:31:16,559 INFO     Training average positive_sample_loss at step 70400: 0.113303\n",
      "2023-12-06 13:31:16,560 INFO     Training average negative_sample_loss at step 70400: 0.084087\n",
      "2023-12-06 13:31:16,560 INFO     Training average loss at step 70400: 0.098695\n",
      "2023-12-06 13:31:45,316 INFO     Training average positive_sample_loss at step 70500: 0.112657\n",
      "2023-12-06 13:31:45,317 INFO     Training average negative_sample_loss at step 70500: 0.084746\n",
      "2023-12-06 13:31:45,317 INFO     Training average loss at step 70500: 0.098702\n",
      "2023-12-06 13:32:10,259 INFO     Training average positive_sample_loss at step 70600: 0.112904\n",
      "2023-12-06 13:32:10,259 INFO     Training average negative_sample_loss at step 70600: 0.085128\n",
      "2023-12-06 13:32:10,259 INFO     Training average loss at step 70600: 0.099016\n",
      "2023-12-06 13:32:39,307 INFO     Training average positive_sample_loss at step 70700: 0.113426\n",
      "2023-12-06 13:32:39,307 INFO     Training average negative_sample_loss at step 70700: 0.084173\n",
      "2023-12-06 13:32:39,307 INFO     Training average loss at step 70700: 0.098799\n",
      "2023-12-06 13:33:03,547 INFO     Training average positive_sample_loss at step 70800: 0.112160\n",
      "2023-12-06 13:33:03,547 INFO     Training average negative_sample_loss at step 70800: 0.083872\n",
      "2023-12-06 13:33:03,547 INFO     Training average loss at step 70800: 0.098016\n",
      "2023-12-06 13:33:29,180 INFO     Training average positive_sample_loss at step 70900: 0.113486\n",
      "2023-12-06 13:33:29,181 INFO     Training average negative_sample_loss at step 70900: 0.084407\n",
      "2023-12-06 13:33:29,181 INFO     Training average loss at step 70900: 0.098947\n",
      "2023-12-06 13:33:56,906 INFO     Training average positive_sample_loss at step 71000: 0.112630\n",
      "2023-12-06 13:33:56,906 INFO     Training average negative_sample_loss at step 71000: 0.084654\n",
      "2023-12-06 13:33:56,906 INFO     Training average loss at step 71000: 0.098642\n",
      "2023-12-06 13:34:21,753 INFO     Training average positive_sample_loss at step 71100: 0.113220\n",
      "2023-12-06 13:34:21,753 INFO     Training average negative_sample_loss at step 71100: 0.084343\n",
      "2023-12-06 13:34:21,753 INFO     Training average loss at step 71100: 0.098781\n",
      "2023-12-06 13:34:46,573 INFO     Training average positive_sample_loss at step 71200: 0.113483\n",
      "2023-12-06 13:34:46,573 INFO     Training average negative_sample_loss at step 71200: 0.084449\n",
      "2023-12-06 13:34:46,573 INFO     Training average loss at step 71200: 0.098966\n",
      "2023-12-06 13:35:18,858 INFO     Training average positive_sample_loss at step 71300: 0.112159\n",
      "2023-12-06 13:35:18,859 INFO     Training average negative_sample_loss at step 71300: 0.084354\n",
      "2023-12-06 13:35:18,859 INFO     Training average loss at step 71300: 0.098257\n",
      "2023-12-06 13:35:44,025 INFO     Training average positive_sample_loss at step 71400: 0.113243\n",
      "2023-12-06 13:35:44,025 INFO     Training average negative_sample_loss at step 71400: 0.084611\n",
      "2023-12-06 13:35:44,025 INFO     Training average loss at step 71400: 0.098927\n",
      "2023-12-06 13:36:12,155 INFO     Training average positive_sample_loss at step 71500: 0.112975\n",
      "2023-12-06 13:36:12,155 INFO     Training average negative_sample_loss at step 71500: 0.084377\n",
      "2023-12-06 13:36:12,155 INFO     Training average loss at step 71500: 0.098676\n",
      "2023-12-06 13:36:37,184 INFO     Training average positive_sample_loss at step 71600: 0.112603\n",
      "2023-12-06 13:36:37,184 INFO     Training average negative_sample_loss at step 71600: 0.084208\n",
      "2023-12-06 13:36:37,184 INFO     Training average loss at step 71600: 0.098406\n",
      "2023-12-06 13:37:01,325 INFO     Training average positive_sample_loss at step 71700: 0.113504\n",
      "2023-12-06 13:37:01,326 INFO     Training average negative_sample_loss at step 71700: 0.083653\n",
      "2023-12-06 13:37:01,326 INFO     Training average loss at step 71700: 0.098578\n",
      "2023-12-06 13:37:30,446 INFO     Training average positive_sample_loss at step 71800: 0.112909\n",
      "2023-12-06 13:37:30,447 INFO     Training average negative_sample_loss at step 71800: 0.084402\n",
      "2023-12-06 13:37:30,447 INFO     Training average loss at step 71800: 0.098656\n",
      "2023-12-06 13:37:55,879 INFO     Training average positive_sample_loss at step 71900: 0.112800\n",
      "2023-12-06 13:37:55,879 INFO     Training average negative_sample_loss at step 71900: 0.084355\n",
      "2023-12-06 13:37:55,879 INFO     Training average loss at step 71900: 0.098577\n",
      "2023-12-06 13:38:23,493 INFO     Training average positive_sample_loss at step 72000: 0.112797\n",
      "2023-12-06 13:38:23,493 INFO     Training average negative_sample_loss at step 72000: 0.084236\n",
      "2023-12-06 13:38:23,493 INFO     Training average loss at step 72000: 0.098517\n",
      "2023-12-06 13:38:48,514 INFO     Training average positive_sample_loss at step 72100: 0.112507\n",
      "2023-12-06 13:38:48,515 INFO     Training average negative_sample_loss at step 72100: 0.084693\n",
      "2023-12-06 13:38:48,515 INFO     Training average loss at step 72100: 0.098600\n",
      "2023-12-06 13:39:12,469 INFO     Training average positive_sample_loss at step 72200: 0.113626\n",
      "2023-12-06 13:39:12,469 INFO     Training average negative_sample_loss at step 72200: 0.084299\n",
      "2023-12-06 13:39:12,469 INFO     Training average loss at step 72200: 0.098963\n",
      "2023-12-06 13:39:40,720 INFO     Training average positive_sample_loss at step 72300: 0.112181\n",
      "2023-12-06 13:39:40,721 INFO     Training average negative_sample_loss at step 72300: 0.084535\n",
      "2023-12-06 13:39:40,721 INFO     Training average loss at step 72300: 0.098358\n",
      "2023-12-06 13:40:06,042 INFO     Training average positive_sample_loss at step 72400: 0.112741\n",
      "2023-12-06 13:40:06,042 INFO     Training average negative_sample_loss at step 72400: 0.084175\n",
      "2023-12-06 13:40:06,042 INFO     Training average loss at step 72400: 0.098458\n",
      "2023-12-06 13:40:37,281 INFO     Training average positive_sample_loss at step 72500: 0.114037\n",
      "2023-12-06 13:40:37,281 INFO     Training average negative_sample_loss at step 72500: 0.084552\n",
      "2023-12-06 13:40:37,281 INFO     Training average loss at step 72500: 0.099294\n",
      "2023-12-06 13:41:03,225 INFO     Training average positive_sample_loss at step 72600: 0.112024\n",
      "2023-12-06 13:41:03,226 INFO     Training average negative_sample_loss at step 72600: 0.083663\n",
      "2023-12-06 13:41:03,226 INFO     Training average loss at step 72600: 0.097844\n",
      "2023-12-06 13:41:27,319 INFO     Training average positive_sample_loss at step 72700: 0.113287\n",
      "2023-12-06 13:41:27,319 INFO     Training average negative_sample_loss at step 72700: 0.084160\n",
      "2023-12-06 13:41:27,320 INFO     Training average loss at step 72700: 0.098724\n",
      "2023-12-06 13:41:56,098 INFO     Training average positive_sample_loss at step 72800: 0.112905\n",
      "2023-12-06 13:41:56,098 INFO     Training average negative_sample_loss at step 72800: 0.084022\n",
      "2023-12-06 13:41:56,098 INFO     Training average loss at step 72800: 0.098463\n",
      "2023-12-06 13:42:21,976 INFO     Training average positive_sample_loss at step 72900: 0.112951\n",
      "2023-12-06 13:42:21,977 INFO     Training average negative_sample_loss at step 72900: 0.084424\n",
      "2023-12-06 13:42:21,977 INFO     Training average loss at step 72900: 0.098688\n",
      "2023-12-06 13:42:45,888 INFO     Training average positive_sample_loss at step 73000: 0.113181\n",
      "2023-12-06 13:42:45,888 INFO     Training average negative_sample_loss at step 73000: 0.084239\n",
      "2023-12-06 13:42:45,888 INFO     Training average loss at step 73000: 0.098710\n",
      "2023-12-06 13:43:13,459 INFO     Training average positive_sample_loss at step 73100: 0.112751\n",
      "2023-12-06 13:43:13,460 INFO     Training average negative_sample_loss at step 73100: 0.083936\n",
      "2023-12-06 13:43:13,460 INFO     Training average loss at step 73100: 0.098343\n",
      "2023-12-06 13:43:37,760 INFO     Training average positive_sample_loss at step 73200: 0.112552\n",
      "2023-12-06 13:43:37,760 INFO     Training average negative_sample_loss at step 73200: 0.084717\n",
      "2023-12-06 13:43:37,760 INFO     Training average loss at step 73200: 0.098635\n",
      "2023-12-06 13:44:06,020 INFO     Training average positive_sample_loss at step 73300: 0.113318\n",
      "2023-12-06 13:44:06,020 INFO     Training average negative_sample_loss at step 73300: 0.084088\n",
      "2023-12-06 13:44:06,020 INFO     Training average loss at step 73300: 0.098703\n",
      "2023-12-06 13:44:31,383 INFO     Training average positive_sample_loss at step 73400: 0.112261\n",
      "2023-12-06 13:44:31,383 INFO     Training average negative_sample_loss at step 73400: 0.083750\n",
      "2023-12-06 13:44:31,383 INFO     Training average loss at step 73400: 0.098006\n",
      "2023-12-06 13:44:56,377 INFO     Training average positive_sample_loss at step 73500: 0.113407\n",
      "2023-12-06 13:44:56,377 INFO     Training average negative_sample_loss at step 73500: 0.084569\n",
      "2023-12-06 13:44:56,378 INFO     Training average loss at step 73500: 0.098988\n",
      "2023-12-06 13:45:23,811 INFO     Training average positive_sample_loss at step 73600: 0.112342\n",
      "2023-12-06 13:45:23,812 INFO     Training average negative_sample_loss at step 73600: 0.083547\n",
      "2023-12-06 13:45:23,812 INFO     Training average loss at step 73600: 0.097945\n",
      "2023-12-06 13:45:49,729 INFO     Training average positive_sample_loss at step 73700: 0.113223\n",
      "2023-12-06 13:45:49,729 INFO     Training average negative_sample_loss at step 73700: 0.084619\n",
      "2023-12-06 13:45:49,730 INFO     Training average loss at step 73700: 0.098921\n",
      "2023-12-06 13:46:19,120 INFO     Training average positive_sample_loss at step 73800: 0.113299\n",
      "2023-12-06 13:46:19,120 INFO     Training average negative_sample_loss at step 73800: 0.084825\n",
      "2023-12-06 13:46:19,120 INFO     Training average loss at step 73800: 0.099062\n",
      "2023-12-06 13:46:43,714 INFO     Training average positive_sample_loss at step 73900: 0.112684\n",
      "2023-12-06 13:46:43,715 INFO     Training average negative_sample_loss at step 73900: 0.084530\n",
      "2023-12-06 13:46:43,715 INFO     Training average loss at step 73900: 0.098607\n",
      "2023-12-06 13:47:09,807 INFO     Training average positive_sample_loss at step 74000: 0.113147\n",
      "2023-12-06 13:47:09,807 INFO     Training average negative_sample_loss at step 74000: 0.084333\n",
      "2023-12-06 13:47:09,807 INFO     Training average loss at step 74000: 0.098740\n",
      "2023-12-06 13:47:38,559 INFO     Training average positive_sample_loss at step 74100: 0.112717\n",
      "2023-12-06 13:47:38,559 INFO     Training average negative_sample_loss at step 74100: 0.083621\n",
      "2023-12-06 13:47:38,559 INFO     Training average loss at step 74100: 0.098169\n",
      "2023-12-06 13:48:03,952 INFO     Training average positive_sample_loss at step 74200: 0.112635\n",
      "2023-12-06 13:48:03,952 INFO     Training average negative_sample_loss at step 74200: 0.084219\n",
      "2023-12-06 13:48:03,952 INFO     Training average loss at step 74200: 0.098427\n",
      "2023-12-06 13:48:30,071 INFO     Training average positive_sample_loss at step 74300: 0.113527\n",
      "2023-12-06 13:48:30,072 INFO     Training average negative_sample_loss at step 74300: 0.084600\n",
      "2023-12-06 13:48:30,072 INFO     Training average loss at step 74300: 0.099064\n",
      "2023-12-06 13:48:58,134 INFO     Training average positive_sample_loss at step 74400: 0.111327\n",
      "2023-12-06 13:48:58,134 INFO     Training average negative_sample_loss at step 74400: 0.083274\n",
      "2023-12-06 13:48:58,135 INFO     Training average loss at step 74400: 0.097300\n",
      "2023-12-06 13:49:22,873 INFO     Training average positive_sample_loss at step 74500: 0.113466\n",
      "2023-12-06 13:49:22,874 INFO     Training average negative_sample_loss at step 74500: 0.084395\n",
      "2023-12-06 13:49:22,874 INFO     Training average loss at step 74500: 0.098931\n",
      "2023-12-06 13:49:51,551 INFO     Training average positive_sample_loss at step 74600: 0.113805\n",
      "2023-12-06 13:49:51,551 INFO     Training average negative_sample_loss at step 74600: 0.085054\n",
      "2023-12-06 13:49:51,551 INFO     Training average loss at step 74600: 0.099430\n",
      "2023-12-06 13:50:17,582 INFO     Training average positive_sample_loss at step 74700: 0.112224\n",
      "2023-12-06 13:50:17,583 INFO     Training average negative_sample_loss at step 74700: 0.084184\n",
      "2023-12-06 13:50:17,583 INFO     Training average loss at step 74700: 0.098204\n",
      "2023-12-06 13:50:42,580 INFO     Training average positive_sample_loss at step 74800: 0.113456\n",
      "2023-12-06 13:50:42,580 INFO     Training average negative_sample_loss at step 74800: 0.084115\n",
      "2023-12-06 13:50:42,580 INFO     Training average loss at step 74800: 0.098786\n",
      "2023-12-06 13:51:10,760 INFO     Training average positive_sample_loss at step 74900: 0.112289\n",
      "2023-12-06 13:51:10,761 INFO     Training average negative_sample_loss at step 74900: 0.083882\n",
      "2023-12-06 13:51:10,761 INFO     Training average loss at step 74900: 0.098086\n",
      "2023-12-06 13:51:35,818 INFO     Training average positive_sample_loss at step 75000: 0.113213\n",
      "2023-12-06 13:51:35,819 INFO     Training average negative_sample_loss at step 75000: 0.084335\n",
      "2023-12-06 13:51:35,819 INFO     Training average loss at step 75000: 0.098774\n",
      "2023-12-06 13:52:05,877 INFO     Training average positive_sample_loss at step 75100: 0.112970\n",
      "2023-12-06 13:52:05,877 INFO     Training average negative_sample_loss at step 75100: 0.084566\n",
      "2023-12-06 13:52:05,877 INFO     Training average loss at step 75100: 0.098768\n",
      "2023-12-06 13:52:31,038 INFO     Training average positive_sample_loss at step 75200: 0.112603\n",
      "2023-12-06 13:52:31,039 INFO     Training average negative_sample_loss at step 75200: 0.084844\n",
      "2023-12-06 13:52:31,039 INFO     Training average loss at step 75200: 0.098724\n",
      "2023-12-06 13:52:55,180 INFO     Training average positive_sample_loss at step 75300: 0.113284\n",
      "2023-12-06 13:52:55,180 INFO     Training average negative_sample_loss at step 75300: 0.083840\n",
      "2023-12-06 13:52:55,180 INFO     Training average loss at step 75300: 0.098562\n",
      "2023-12-06 13:53:23,240 INFO     Training average positive_sample_loss at step 75400: 0.112731\n",
      "2023-12-06 13:53:23,240 INFO     Training average negative_sample_loss at step 75400: 0.084561\n",
      "2023-12-06 13:53:23,240 INFO     Training average loss at step 75400: 0.098646\n",
      "2023-12-06 13:53:49,191 INFO     Training average positive_sample_loss at step 75500: 0.112459\n",
      "2023-12-06 13:53:49,192 INFO     Training average negative_sample_loss at step 75500: 0.084307\n",
      "2023-12-06 13:53:49,192 INFO     Training average loss at step 75500: 0.098383\n",
      "2023-12-06 13:54:17,147 INFO     Training average positive_sample_loss at step 75600: 0.113729\n",
      "2023-12-06 13:54:17,147 INFO     Training average negative_sample_loss at step 75600: 0.084309\n",
      "2023-12-06 13:54:17,147 INFO     Training average loss at step 75600: 0.099019\n",
      "2023-12-06 13:54:42,550 INFO     Training average positive_sample_loss at step 75700: 0.112267\n",
      "2023-12-06 13:54:42,550 INFO     Training average negative_sample_loss at step 75700: 0.084361\n",
      "2023-12-06 13:54:42,551 INFO     Training average loss at step 75700: 0.098314\n",
      "2023-12-06 13:55:07,731 INFO     Training average positive_sample_loss at step 75800: 0.113287\n",
      "2023-12-06 13:55:07,731 INFO     Training average negative_sample_loss at step 75800: 0.084845\n",
      "2023-12-06 13:55:07,731 INFO     Training average loss at step 75800: 0.099066\n",
      "2023-12-06 13:55:35,949 INFO     Training average positive_sample_loss at step 75900: 0.112905\n",
      "2023-12-06 13:55:35,949 INFO     Training average negative_sample_loss at step 75900: 0.083973\n",
      "2023-12-06 13:55:35,949 INFO     Training average loss at step 75900: 0.098439\n",
      "2023-12-06 13:56:00,551 INFO     Training average positive_sample_loss at step 76000: 0.112492\n",
      "2023-12-06 13:56:00,551 INFO     Training average negative_sample_loss at step 76000: 0.084154\n",
      "2023-12-06 13:56:00,551 INFO     Training average loss at step 76000: 0.098323\n",
      "2023-12-06 13:56:25,523 INFO     Training average positive_sample_loss at step 76100: 0.113494\n",
      "2023-12-06 13:56:25,524 INFO     Training average negative_sample_loss at step 76100: 0.084156\n",
      "2023-12-06 13:56:25,524 INFO     Training average loss at step 76100: 0.098825\n",
      "2023-12-06 13:56:54,590 INFO     Training average positive_sample_loss at step 76200: 0.112549\n",
      "2023-12-06 13:56:54,590 INFO     Training average negative_sample_loss at step 76200: 0.084444\n",
      "2023-12-06 13:56:54,591 INFO     Training average loss at step 76200: 0.098496\n",
      "2023-12-06 13:57:19,117 INFO     Training average positive_sample_loss at step 76300: 0.112943\n",
      "2023-12-06 13:57:19,117 INFO     Training average negative_sample_loss at step 76300: 0.084045\n",
      "2023-12-06 13:57:19,117 INFO     Training average loss at step 76300: 0.098494\n",
      "2023-12-06 13:57:48,956 INFO     Training average positive_sample_loss at step 76400: 0.112796\n",
      "2023-12-06 13:57:48,957 INFO     Training average negative_sample_loss at step 76400: 0.084572\n",
      "2023-12-06 13:57:48,957 INFO     Training average loss at step 76400: 0.098684\n",
      "2023-12-06 13:58:14,788 INFO     Training average positive_sample_loss at step 76500: 0.112731\n",
      "2023-12-06 13:58:14,788 INFO     Training average negative_sample_loss at step 76500: 0.084231\n",
      "2023-12-06 13:58:14,788 INFO     Training average loss at step 76500: 0.098481\n",
      "2023-12-06 13:58:39,950 INFO     Training average positive_sample_loss at step 76600: 0.113152\n",
      "2023-12-06 13:58:39,950 INFO     Training average negative_sample_loss at step 76600: 0.083881\n",
      "2023-12-06 13:58:39,950 INFO     Training average loss at step 76600: 0.098517\n",
      "2023-12-06 13:59:08,108 INFO     Training average positive_sample_loss at step 76700: 0.112754\n",
      "2023-12-06 13:59:08,108 INFO     Training average negative_sample_loss at step 76700: 0.084987\n",
      "2023-12-06 13:59:08,108 INFO     Training average loss at step 76700: 0.098871\n",
      "2023-12-06 13:59:33,566 INFO     Training average positive_sample_loss at step 76800: 0.113012\n",
      "2023-12-06 13:59:33,567 INFO     Training average negative_sample_loss at step 76800: 0.084252\n",
      "2023-12-06 13:59:33,567 INFO     Training average loss at step 76800: 0.098632\n",
      "2023-12-06 14:00:02,287 INFO     Training average positive_sample_loss at step 76900: 0.112931\n",
      "2023-12-06 14:00:02,288 INFO     Training average negative_sample_loss at step 76900: 0.083902\n",
      "2023-12-06 14:00:02,288 INFO     Training average loss at step 76900: 0.098417\n",
      "2023-12-06 14:00:28,124 INFO     Training average positive_sample_loss at step 77000: 0.112218\n",
      "2023-12-06 14:00:28,124 INFO     Training average negative_sample_loss at step 77000: 0.084030\n",
      "2023-12-06 14:00:28,124 INFO     Training average loss at step 77000: 0.098124\n",
      "2023-12-06 14:00:53,611 INFO     Training average positive_sample_loss at step 77100: 0.113483\n",
      "2023-12-06 14:00:53,612 INFO     Training average negative_sample_loss at step 77100: 0.083643\n",
      "2023-12-06 14:00:53,612 INFO     Training average loss at step 77100: 0.098563\n",
      "2023-12-06 14:01:23,300 INFO     Training average positive_sample_loss at step 77200: 0.112587\n",
      "2023-12-06 14:01:23,301 INFO     Training average negative_sample_loss at step 77200: 0.083980\n",
      "2023-12-06 14:01:23,301 INFO     Training average loss at step 77200: 0.098283\n",
      "2023-12-06 14:01:47,690 INFO     Training average positive_sample_loss at step 77300: 0.112708\n",
      "2023-12-06 14:01:47,691 INFO     Training average negative_sample_loss at step 77300: 0.084643\n",
      "2023-12-06 14:01:47,691 INFO     Training average loss at step 77300: 0.098675\n",
      "2023-12-06 14:02:14,952 INFO     Training average positive_sample_loss at step 77400: 0.113618\n",
      "2023-12-06 14:02:14,952 INFO     Training average negative_sample_loss at step 77400: 0.084249\n",
      "2023-12-06 14:02:14,952 INFO     Training average loss at step 77400: 0.098933\n",
      "2023-12-06 14:02:41,841 INFO     Training average positive_sample_loss at step 77500: 0.112011\n",
      "2023-12-06 14:02:41,842 INFO     Training average negative_sample_loss at step 77500: 0.083559\n",
      "2023-12-06 14:02:41,842 INFO     Training average loss at step 77500: 0.097785\n",
      "2023-12-06 14:03:07,220 INFO     Training average positive_sample_loss at step 77600: 0.113753\n",
      "2023-12-06 14:03:07,221 INFO     Training average negative_sample_loss at step 77600: 0.084585\n",
      "2023-12-06 14:03:07,221 INFO     Training average loss at step 77600: 0.099169\n",
      "2023-12-06 14:03:37,412 INFO     Training average positive_sample_loss at step 77700: 0.112193\n",
      "2023-12-06 14:03:37,413 INFO     Training average negative_sample_loss at step 77700: 0.083748\n",
      "2023-12-06 14:03:37,413 INFO     Training average loss at step 77700: 0.097970\n",
      "2023-12-06 14:04:03,409 INFO     Training average positive_sample_loss at step 77800: 0.112945\n",
      "2023-12-06 14:04:03,409 INFO     Training average negative_sample_loss at step 77800: 0.084280\n",
      "2023-12-06 14:04:03,409 INFO     Training average loss at step 77800: 0.098612\n",
      "2023-12-06 14:04:27,966 INFO     Training average positive_sample_loss at step 77900: 0.113283\n",
      "2023-12-06 14:04:27,967 INFO     Training average negative_sample_loss at step 77900: 0.084494\n",
      "2023-12-06 14:04:27,967 INFO     Training average loss at step 77900: 0.098889\n",
      "2023-12-06 14:04:55,940 INFO     Training average positive_sample_loss at step 78000: 0.112056\n",
      "2023-12-06 14:04:55,940 INFO     Training average negative_sample_loss at step 78000: 0.084521\n",
      "2023-12-06 14:04:55,940 INFO     Training average loss at step 78000: 0.098289\n",
      "2023-12-06 14:05:21,522 INFO     Training average positive_sample_loss at step 78100: 0.113661\n",
      "2023-12-06 14:05:21,523 INFO     Training average negative_sample_loss at step 78100: 0.084603\n",
      "2023-12-06 14:05:21,523 INFO     Training average loss at step 78100: 0.099132\n",
      "2023-12-06 14:05:49,661 INFO     Training average positive_sample_loss at step 78200: 0.113154\n",
      "2023-12-06 14:05:49,662 INFO     Training average negative_sample_loss at step 78200: 0.084042\n",
      "2023-12-06 14:05:49,662 INFO     Training average loss at step 78200: 0.098598\n",
      "2023-12-06 14:06:14,894 INFO     Training average positive_sample_loss at step 78300: 0.112287\n",
      "2023-12-06 14:06:14,894 INFO     Training average negative_sample_loss at step 78300: 0.083793\n",
      "2023-12-06 14:06:14,894 INFO     Training average loss at step 78300: 0.098040\n",
      "2023-12-06 14:06:40,150 INFO     Training average positive_sample_loss at step 78400: 0.113132\n",
      "2023-12-06 14:06:40,151 INFO     Training average negative_sample_loss at step 78400: 0.084146\n",
      "2023-12-06 14:06:40,151 INFO     Training average loss at step 78400: 0.098639\n",
      "2023-12-06 14:07:08,381 INFO     Training average positive_sample_loss at step 78500: 0.112843\n",
      "2023-12-06 14:07:08,382 INFO     Training average negative_sample_loss at step 78500: 0.084808\n",
      "2023-12-06 14:07:08,382 INFO     Training average loss at step 78500: 0.098826\n",
      "2023-12-06 14:07:32,989 INFO     Training average positive_sample_loss at step 78600: 0.113119\n",
      "2023-12-06 14:07:32,990 INFO     Training average negative_sample_loss at step 78600: 0.083671\n",
      "2023-12-06 14:07:32,990 INFO     Training average loss at step 78600: 0.098395\n",
      "2023-12-06 14:08:00,930 INFO     Training average positive_sample_loss at step 78700: 0.112717\n",
      "2023-12-06 14:08:00,931 INFO     Training average negative_sample_loss at step 78700: 0.084290\n",
      "2023-12-06 14:08:00,931 INFO     Training average loss at step 78700: 0.098503\n",
      "2023-12-06 14:08:26,695 INFO     Training average positive_sample_loss at step 78800: 0.112212\n",
      "2023-12-06 14:08:26,696 INFO     Training average negative_sample_loss at step 78800: 0.083890\n",
      "2023-12-06 14:08:26,696 INFO     Training average loss at step 78800: 0.098051\n",
      "2023-12-06 14:08:52,119 INFO     Training average positive_sample_loss at step 78900: 0.113017\n",
      "2023-12-06 14:08:52,119 INFO     Training average negative_sample_loss at step 78900: 0.083547\n",
      "2023-12-06 14:08:52,119 INFO     Training average loss at step 78900: 0.098282\n",
      "2023-12-06 14:09:24,317 INFO     Training average positive_sample_loss at step 79000: 0.112907\n",
      "2023-12-06 14:09:24,318 INFO     Training average negative_sample_loss at step 79000: 0.084673\n",
      "2023-12-06 14:09:24,318 INFO     Training average loss at step 79000: 0.098790\n",
      "2023-12-06 14:09:49,611 INFO     Training average positive_sample_loss at step 79100: 0.112943\n",
      "2023-12-06 14:09:49,611 INFO     Training average negative_sample_loss at step 79100: 0.084487\n",
      "2023-12-06 14:09:49,611 INFO     Training average loss at step 79100: 0.098715\n",
      "2023-12-06 14:10:14,984 INFO     Training average positive_sample_loss at step 79200: 0.113346\n",
      "2023-12-06 14:10:14,984 INFO     Training average negative_sample_loss at step 79200: 0.084414\n",
      "2023-12-06 14:10:14,984 INFO     Training average loss at step 79200: 0.098880\n",
      "2023-12-06 14:10:43,278 INFO     Training average positive_sample_loss at step 79300: 0.112340\n",
      "2023-12-06 14:10:43,279 INFO     Training average negative_sample_loss at step 79300: 0.084687\n",
      "2023-12-06 14:10:43,279 INFO     Training average loss at step 79300: 0.098514\n",
      "2023-12-06 14:11:08,540 INFO     Training average positive_sample_loss at step 79400: 0.112926\n",
      "2023-12-06 14:11:08,540 INFO     Training average negative_sample_loss at step 79400: 0.084508\n",
      "2023-12-06 14:11:08,540 INFO     Training average loss at step 79400: 0.098717\n",
      "2023-12-06 14:11:36,050 INFO     Training average positive_sample_loss at step 79500: 0.112987\n",
      "2023-12-06 14:11:36,050 INFO     Training average negative_sample_loss at step 79500: 0.084087\n",
      "2023-12-06 14:11:36,050 INFO     Training average loss at step 79500: 0.098537\n",
      "2023-12-06 14:12:01,341 INFO     Training average positive_sample_loss at step 79600: 0.112749\n",
      "2023-12-06 14:12:01,342 INFO     Training average negative_sample_loss at step 79600: 0.084207\n",
      "2023-12-06 14:12:01,342 INFO     Training average loss at step 79600: 0.098478\n",
      "2023-12-06 14:12:25,516 INFO     Training average positive_sample_loss at step 79700: 0.113396\n",
      "2023-12-06 14:12:25,516 INFO     Training average negative_sample_loss at step 79700: 0.084097\n",
      "2023-12-06 14:12:25,516 INFO     Training average loss at step 79700: 0.098746\n",
      "2023-12-06 14:12:53,220 INFO     Training average positive_sample_loss at step 79800: 0.112402\n",
      "2023-12-06 14:12:53,220 INFO     Training average negative_sample_loss at step 79800: 0.083961\n",
      "2023-12-06 14:12:53,220 INFO     Training average loss at step 79800: 0.098182\n",
      "2023-12-06 14:13:18,423 INFO     Training average positive_sample_loss at step 79900: 0.112807\n",
      "2023-12-06 14:13:18,424 INFO     Training average negative_sample_loss at step 79900: 0.083935\n",
      "2023-12-06 14:13:18,424 INFO     Training average loss at step 79900: 0.098371\n",
      "2023-12-06 14:13:55,391 INFO     Training average positive_sample_loss at step 80000: 0.113191\n",
      "2023-12-06 14:13:55,392 INFO     Training average negative_sample_loss at step 80000: 0.084355\n",
      "2023-12-06 14:13:55,392 INFO     Training average loss at step 80000: 0.098773\n",
      "2023-12-06 14:13:55,392 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 14:13:55,881 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 14:14:24,282 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 14:14:45,284 INFO     Valid MRR at step 80000: 0.642939\n",
      "2023-12-06 14:14:45,285 INFO     Valid MR at step 80000: 236.961150\n",
      "2023-12-06 14:14:45,285 INFO     Valid HITS@1 at step 80000: 0.585783\n",
      "2023-12-06 14:14:45,285 INFO     Valid HITS@3 at step 80000: 0.665632\n",
      "2023-12-06 14:14:45,285 INFO     Valid HITS@10 at step 80000: 0.755952\n",
      "2023-12-06 14:15:06,402 INFO     Training average positive_sample_loss at step 80100: 0.113015\n",
      "2023-12-06 14:15:06,403 INFO     Training average negative_sample_loss at step 80100: 0.084697\n",
      "2023-12-06 14:15:06,403 INFO     Training average loss at step 80100: 0.098856\n",
      "2023-12-06 14:15:31,547 INFO     Training average positive_sample_loss at step 80200: 0.112833\n",
      "2023-12-06 14:15:31,547 INFO     Training average negative_sample_loss at step 80200: 0.083360\n",
      "2023-12-06 14:15:31,547 INFO     Training average loss at step 80200: 0.098097\n",
      "2023-12-06 14:16:01,075 INFO     Training average positive_sample_loss at step 80300: 0.112371\n",
      "2023-12-06 14:16:01,075 INFO     Training average negative_sample_loss at step 80300: 0.083853\n",
      "2023-12-06 14:16:01,075 INFO     Training average loss at step 80300: 0.098112\n",
      "2023-12-06 14:16:24,913 INFO     Training average positive_sample_loss at step 80400: 0.112390\n",
      "2023-12-06 14:16:24,913 INFO     Training average negative_sample_loss at step 80400: 0.083844\n",
      "2023-12-06 14:16:24,913 INFO     Training average loss at step 80400: 0.098117\n",
      "2023-12-06 14:16:52,331 INFO     Training average positive_sample_loss at step 80500: 0.113936\n",
      "2023-12-06 14:16:52,332 INFO     Training average negative_sample_loss at step 80500: 0.085179\n",
      "2023-12-06 14:16:52,332 INFO     Training average loss at step 80500: 0.099557\n",
      "2023-12-06 14:17:17,483 INFO     Training average positive_sample_loss at step 80600: 0.112318\n",
      "2023-12-06 14:17:17,483 INFO     Training average negative_sample_loss at step 80600: 0.084351\n",
      "2023-12-06 14:17:17,484 INFO     Training average loss at step 80600: 0.098334\n",
      "2023-12-06 14:17:43,102 INFO     Training average positive_sample_loss at step 80700: 0.113171\n",
      "2023-12-06 14:17:43,102 INFO     Training average negative_sample_loss at step 80700: 0.084106\n",
      "2023-12-06 14:17:43,102 INFO     Training average loss at step 80700: 0.098638\n",
      "2023-12-06 14:18:10,638 INFO     Training average positive_sample_loss at step 80800: 0.112572\n",
      "2023-12-06 14:18:10,638 INFO     Training average negative_sample_loss at step 80800: 0.084114\n",
      "2023-12-06 14:18:10,638 INFO     Training average loss at step 80800: 0.098343\n",
      "2023-12-06 14:18:35,403 INFO     Training average positive_sample_loss at step 80900: 0.112428\n",
      "2023-12-06 14:18:35,403 INFO     Training average negative_sample_loss at step 80900: 0.084575\n",
      "2023-12-06 14:18:35,403 INFO     Training average loss at step 80900: 0.098502\n",
      "2023-12-06 14:19:00,157 INFO     Training average positive_sample_loss at step 81000: 0.113317\n",
      "2023-12-06 14:19:00,157 INFO     Training average negative_sample_loss at step 81000: 0.084400\n",
      "2023-12-06 14:19:00,157 INFO     Training average loss at step 81000: 0.098858\n",
      "2023-12-06 14:19:28,552 INFO     Training average positive_sample_loss at step 81100: 0.112931\n",
      "2023-12-06 14:19:28,552 INFO     Training average negative_sample_loss at step 81100: 0.085496\n",
      "2023-12-06 14:19:28,552 INFO     Training average loss at step 81100: 0.099213\n",
      "2023-12-06 14:19:54,814 INFO     Training average positive_sample_loss at step 81200: 0.112844\n",
      "2023-12-06 14:19:54,815 INFO     Training average negative_sample_loss at step 81200: 0.084624\n",
      "2023-12-06 14:19:54,815 INFO     Training average loss at step 81200: 0.098734\n",
      "2023-12-06 14:20:24,165 INFO     Training average positive_sample_loss at step 81300: 0.113202\n",
      "2023-12-06 14:20:24,165 INFO     Training average negative_sample_loss at step 81300: 0.083652\n",
      "2023-12-06 14:20:24,165 INFO     Training average loss at step 81300: 0.098427\n",
      "2023-12-06 14:20:48,872 INFO     Training average positive_sample_loss at step 81400: 0.112577\n",
      "2023-12-06 14:20:48,873 INFO     Training average negative_sample_loss at step 81400: 0.083956\n",
      "2023-12-06 14:20:48,873 INFO     Training average loss at step 81400: 0.098267\n",
      "2023-12-06 14:21:13,480 INFO     Training average positive_sample_loss at step 81500: 0.112940\n",
      "2023-12-06 14:21:13,481 INFO     Training average negative_sample_loss at step 81500: 0.084736\n",
      "2023-12-06 14:21:13,481 INFO     Training average loss at step 81500: 0.098838\n",
      "2023-12-06 14:21:42,840 INFO     Training average positive_sample_loss at step 81600: 0.112897\n",
      "2023-12-06 14:21:42,841 INFO     Training average negative_sample_loss at step 81600: 0.084544\n",
      "2023-12-06 14:21:42,841 INFO     Training average loss at step 81600: 0.098721\n",
      "2023-12-06 14:22:08,412 INFO     Training average positive_sample_loss at step 81700: 0.113139\n",
      "2023-12-06 14:22:08,413 INFO     Training average negative_sample_loss at step 81700: 0.084232\n",
      "2023-12-06 14:22:08,413 INFO     Training average loss at step 81700: 0.098686\n",
      "2023-12-06 14:22:36,490 INFO     Training average positive_sample_loss at step 81800: 0.112762\n",
      "2023-12-06 14:22:36,490 INFO     Training average negative_sample_loss at step 81800: 0.084450\n",
      "2023-12-06 14:22:36,491 INFO     Training average loss at step 81800: 0.098606\n",
      "2023-12-06 14:23:01,885 INFO     Training average positive_sample_loss at step 81900: 0.112392\n",
      "2023-12-06 14:23:01,886 INFO     Training average negative_sample_loss at step 81900: 0.084997\n",
      "2023-12-06 14:23:01,886 INFO     Training average loss at step 81900: 0.098694\n",
      "2023-12-06 14:23:26,258 INFO     Training average positive_sample_loss at step 82000: 0.113359\n",
      "2023-12-06 14:23:26,258 INFO     Training average negative_sample_loss at step 82000: 0.084296\n",
      "2023-12-06 14:23:26,258 INFO     Training average loss at step 82000: 0.098827\n",
      "2023-12-06 14:23:54,536 INFO     Training average positive_sample_loss at step 82100: 0.112601\n",
      "2023-12-06 14:23:54,537 INFO     Training average negative_sample_loss at step 82100: 0.084213\n",
      "2023-12-06 14:23:54,537 INFO     Training average loss at step 82100: 0.098407\n",
      "2023-12-06 14:24:19,914 INFO     Training average positive_sample_loss at step 82200: 0.112498\n",
      "2023-12-06 14:24:19,915 INFO     Training average negative_sample_loss at step 82200: 0.084418\n",
      "2023-12-06 14:24:19,915 INFO     Training average loss at step 82200: 0.098458\n",
      "2023-12-06 14:24:45,068 INFO     Training average positive_sample_loss at step 82300: 0.113887\n",
      "2023-12-06 14:24:45,069 INFO     Training average negative_sample_loss at step 82300: 0.084369\n",
      "2023-12-06 14:24:45,069 INFO     Training average loss at step 82300: 0.099128\n",
      "2023-12-06 14:25:14,127 INFO     Training average positive_sample_loss at step 82400: 0.112051\n",
      "2023-12-06 14:25:14,128 INFO     Training average negative_sample_loss at step 82400: 0.084157\n",
      "2023-12-06 14:25:14,128 INFO     Training average loss at step 82400: 0.098104\n",
      "2023-12-06 14:25:40,000 INFO     Training average positive_sample_loss at step 82500: 0.112537\n",
      "2023-12-06 14:25:40,000 INFO     Training average negative_sample_loss at step 82500: 0.084038\n",
      "2023-12-06 14:25:40,000 INFO     Training average loss at step 82500: 0.098287\n",
      "2023-12-06 14:26:08,795 INFO     Training average positive_sample_loss at step 82600: 0.113339\n",
      "2023-12-06 14:26:08,796 INFO     Training average negative_sample_loss at step 82600: 0.085165\n",
      "2023-12-06 14:26:08,796 INFO     Training average loss at step 82600: 0.099252\n",
      "2023-12-06 14:26:34,331 INFO     Training average positive_sample_loss at step 82700: 0.113177\n",
      "2023-12-06 14:26:34,332 INFO     Training average negative_sample_loss at step 82700: 0.084489\n",
      "2023-12-06 14:26:34,332 INFO     Training average loss at step 82700: 0.098833\n",
      "2023-12-06 14:26:59,824 INFO     Training average positive_sample_loss at step 82800: 0.113216\n",
      "2023-12-06 14:26:59,824 INFO     Training average negative_sample_loss at step 82800: 0.084168\n",
      "2023-12-06 14:26:59,824 INFO     Training average loss at step 82800: 0.098692\n",
      "2023-12-06 14:27:28,893 INFO     Training average positive_sample_loss at step 82900: 0.112537\n",
      "2023-12-06 14:27:28,894 INFO     Training average negative_sample_loss at step 82900: 0.084174\n",
      "2023-12-06 14:27:28,894 INFO     Training average loss at step 82900: 0.098355\n",
      "2023-12-06 14:27:53,052 INFO     Training average positive_sample_loss at step 83000: 0.112775\n",
      "2023-12-06 14:27:53,052 INFO     Training average negative_sample_loss at step 83000: 0.083894\n",
      "2023-12-06 14:27:53,052 INFO     Training average loss at step 83000: 0.098334\n",
      "2023-12-06 14:28:22,241 INFO     Training average positive_sample_loss at step 83100: 0.113045\n",
      "2023-12-06 14:28:22,242 INFO     Training average negative_sample_loss at step 83100: 0.083908\n",
      "2023-12-06 14:28:22,242 INFO     Training average loss at step 83100: 0.098477\n",
      "2023-12-06 14:28:47,453 INFO     Training average positive_sample_loss at step 83200: 0.112718\n",
      "2023-12-06 14:28:47,454 INFO     Training average negative_sample_loss at step 83200: 0.083665\n",
      "2023-12-06 14:28:47,454 INFO     Training average loss at step 83200: 0.098192\n",
      "2023-12-06 14:29:13,277 INFO     Training average positive_sample_loss at step 83300: 0.112797\n",
      "2023-12-06 14:29:13,277 INFO     Training average negative_sample_loss at step 83300: 0.084150\n",
      "2023-12-06 14:29:13,277 INFO     Training average loss at step 83300: 0.098474\n",
      "2023-12-06 14:29:41,206 INFO     Training average positive_sample_loss at step 83400: 0.112616\n",
      "2023-12-06 14:29:41,207 INFO     Training average negative_sample_loss at step 83400: 0.084580\n",
      "2023-12-06 14:29:41,207 INFO     Training average loss at step 83400: 0.098598\n",
      "2023-12-06 14:30:05,888 INFO     Training average positive_sample_loss at step 83500: 0.112577\n",
      "2023-12-06 14:30:05,889 INFO     Training average negative_sample_loss at step 83500: 0.084775\n",
      "2023-12-06 14:30:05,889 INFO     Training average loss at step 83500: 0.098676\n",
      "2023-12-06 14:30:33,500 INFO     Training average positive_sample_loss at step 83600: 0.113361\n",
      "2023-12-06 14:30:33,501 INFO     Training average negative_sample_loss at step 83600: 0.083883\n",
      "2023-12-06 14:30:33,501 INFO     Training average loss at step 83600: 0.098622\n",
      "2023-12-06 14:30:57,951 INFO     Training average positive_sample_loss at step 83700: 0.112755\n",
      "2023-12-06 14:30:57,951 INFO     Training average negative_sample_loss at step 83700: 0.084270\n",
      "2023-12-06 14:30:57,951 INFO     Training average loss at step 83700: 0.098512\n",
      "2023-12-06 14:31:23,840 INFO     Training average positive_sample_loss at step 83800: 0.112888\n",
      "2023-12-06 14:31:23,841 INFO     Training average negative_sample_loss at step 83800: 0.084699\n",
      "2023-12-06 14:31:23,841 INFO     Training average loss at step 83800: 0.098793\n",
      "2023-12-06 14:31:51,978 INFO     Training average positive_sample_loss at step 83900: 0.113051\n",
      "2023-12-06 14:31:51,979 INFO     Training average negative_sample_loss at step 83900: 0.084450\n",
      "2023-12-06 14:31:51,979 INFO     Training average loss at step 83900: 0.098750\n",
      "2023-12-06 14:32:17,997 INFO     Training average positive_sample_loss at step 84000: 0.112284\n",
      "2023-12-06 14:32:17,998 INFO     Training average negative_sample_loss at step 84000: 0.084040\n",
      "2023-12-06 14:32:17,998 INFO     Training average loss at step 84000: 0.098162\n",
      "2023-12-06 14:32:43,330 INFO     Training average positive_sample_loss at step 84100: 0.113451\n",
      "2023-12-06 14:32:43,331 INFO     Training average negative_sample_loss at step 84100: 0.083552\n",
      "2023-12-06 14:32:43,331 INFO     Training average loss at step 84100: 0.098501\n",
      "2023-12-06 14:33:12,979 INFO     Training average positive_sample_loss at step 84200: 0.111813\n",
      "2023-12-06 14:33:12,980 INFO     Training average negative_sample_loss at step 84200: 0.084346\n",
      "2023-12-06 14:33:12,980 INFO     Training average loss at step 84200: 0.098079\n",
      "2023-12-06 14:33:38,022 INFO     Training average positive_sample_loss at step 84300: 0.113401\n",
      "2023-12-06 14:33:38,022 INFO     Training average negative_sample_loss at step 84300: 0.084603\n",
      "2023-12-06 14:33:38,022 INFO     Training average loss at step 84300: 0.099002\n",
      "2023-12-06 14:34:07,288 INFO     Training average positive_sample_loss at step 84400: 0.113185\n",
      "2023-12-06 14:34:07,288 INFO     Training average negative_sample_loss at step 84400: 0.085006\n",
      "2023-12-06 14:34:07,288 INFO     Training average loss at step 84400: 0.099095\n",
      "2023-12-06 14:34:33,433 INFO     Training average positive_sample_loss at step 84500: 0.112358\n",
      "2023-12-06 14:34:33,433 INFO     Training average negative_sample_loss at step 84500: 0.084036\n",
      "2023-12-06 14:34:33,433 INFO     Training average loss at step 84500: 0.098197\n",
      "2023-12-06 14:34:58,669 INFO     Training average positive_sample_loss at step 84600: 0.113503\n",
      "2023-12-06 14:34:58,669 INFO     Training average negative_sample_loss at step 84600: 0.084654\n",
      "2023-12-06 14:34:58,670 INFO     Training average loss at step 84600: 0.099078\n",
      "2023-12-06 14:35:26,234 INFO     Training average positive_sample_loss at step 84700: 0.112054\n",
      "2023-12-06 14:35:26,235 INFO     Training average negative_sample_loss at step 84700: 0.084328\n",
      "2023-12-06 14:35:26,235 INFO     Training average loss at step 84700: 0.098191\n",
      "2023-12-06 14:35:51,646 INFO     Training average positive_sample_loss at step 84800: 0.113259\n",
      "2023-12-06 14:35:51,646 INFO     Training average negative_sample_loss at step 84800: 0.084201\n",
      "2023-12-06 14:35:51,646 INFO     Training average loss at step 84800: 0.098730\n",
      "2023-12-06 14:36:20,216 INFO     Training average positive_sample_loss at step 84900: 0.112930\n",
      "2023-12-06 14:36:20,217 INFO     Training average negative_sample_loss at step 84900: 0.084176\n",
      "2023-12-06 14:36:20,217 INFO     Training average loss at step 84900: 0.098553\n",
      "2023-12-06 14:36:46,278 INFO     Training average positive_sample_loss at step 85000: 0.112374\n",
      "2023-12-06 14:36:46,278 INFO     Training average negative_sample_loss at step 85000: 0.084645\n",
      "2023-12-06 14:36:46,278 INFO     Training average loss at step 85000: 0.098509\n",
      "2023-12-06 14:37:10,974 INFO     Training average positive_sample_loss at step 85100: 0.113174\n",
      "2023-12-06 14:37:10,975 INFO     Training average negative_sample_loss at step 85100: 0.084613\n",
      "2023-12-06 14:37:10,975 INFO     Training average loss at step 85100: 0.098893\n",
      "2023-12-06 14:37:38,528 INFO     Training average positive_sample_loss at step 85200: 0.112901\n",
      "2023-12-06 14:37:38,528 INFO     Training average negative_sample_loss at step 85200: 0.084241\n",
      "2023-12-06 14:37:38,529 INFO     Training average loss at step 85200: 0.098571\n",
      "2023-12-06 14:38:04,084 INFO     Training average positive_sample_loss at step 85300: 0.112339\n",
      "2023-12-06 14:38:04,085 INFO     Training average negative_sample_loss at step 85300: 0.083338\n",
      "2023-12-06 14:38:04,085 INFO     Training average loss at step 85300: 0.097838\n",
      "2023-12-06 14:38:34,826 INFO     Training average positive_sample_loss at step 85400: 0.113690\n",
      "2023-12-06 14:38:34,827 INFO     Training average negative_sample_loss at step 85400: 0.083231\n",
      "2023-12-06 14:38:34,827 INFO     Training average loss at step 85400: 0.098460\n",
      "2023-12-06 14:38:59,475 INFO     Training average positive_sample_loss at step 85500: 0.112263\n",
      "2023-12-06 14:38:59,475 INFO     Training average negative_sample_loss at step 85500: 0.085001\n",
      "2023-12-06 14:38:59,475 INFO     Training average loss at step 85500: 0.098632\n",
      "2023-12-06 14:39:24,806 INFO     Training average positive_sample_loss at step 85600: 0.112753\n",
      "2023-12-06 14:39:24,806 INFO     Training average negative_sample_loss at step 85600: 0.083702\n",
      "2023-12-06 14:39:24,806 INFO     Training average loss at step 85600: 0.098227\n",
      "2023-12-06 14:39:54,414 INFO     Training average positive_sample_loss at step 85700: 0.112711\n",
      "2023-12-06 14:39:54,414 INFO     Training average negative_sample_loss at step 85700: 0.084016\n",
      "2023-12-06 14:39:54,414 INFO     Training average loss at step 85700: 0.098363\n",
      "2023-12-06 14:40:20,205 INFO     Training average positive_sample_loss at step 85800: 0.112718\n",
      "2023-12-06 14:40:20,205 INFO     Training average negative_sample_loss at step 85800: 0.084343\n",
      "2023-12-06 14:40:20,205 INFO     Training average loss at step 85800: 0.098531\n",
      "2023-12-06 14:40:45,699 INFO     Training average positive_sample_loss at step 85900: 0.113615\n",
      "2023-12-06 14:40:45,699 INFO     Training average negative_sample_loss at step 85900: 0.084624\n",
      "2023-12-06 14:40:45,699 INFO     Training average loss at step 85900: 0.099119\n",
      "2023-12-06 14:41:13,698 INFO     Training average positive_sample_loss at step 86000: 0.112163\n",
      "2023-12-06 14:41:13,698 INFO     Training average negative_sample_loss at step 86000: 0.084603\n",
      "2023-12-06 14:41:13,698 INFO     Training average loss at step 86000: 0.098383\n",
      "2023-12-06 14:41:38,977 INFO     Training average positive_sample_loss at step 86100: 0.113179\n",
      "2023-12-06 14:41:38,978 INFO     Training average negative_sample_loss at step 86100: 0.084025\n",
      "2023-12-06 14:41:38,978 INFO     Training average loss at step 86100: 0.098602\n",
      "2023-12-06 14:42:06,702 INFO     Training average positive_sample_loss at step 86200: 0.112649\n",
      "2023-12-06 14:42:06,703 INFO     Training average negative_sample_loss at step 86200: 0.084579\n",
      "2023-12-06 14:42:06,703 INFO     Training average loss at step 86200: 0.098614\n",
      "2023-12-06 14:42:32,563 INFO     Training average positive_sample_loss at step 86300: 0.112424\n",
      "2023-12-06 14:42:32,564 INFO     Training average negative_sample_loss at step 86300: 0.084509\n",
      "2023-12-06 14:42:32,564 INFO     Training average loss at step 86300: 0.098467\n",
      "2023-12-06 14:42:56,909 INFO     Training average positive_sample_loss at step 86400: 0.113505\n",
      "2023-12-06 14:42:56,910 INFO     Training average negative_sample_loss at step 86400: 0.084408\n",
      "2023-12-06 14:42:56,910 INFO     Training average loss at step 86400: 0.098956\n",
      "2023-12-06 14:43:24,861 INFO     Training average positive_sample_loss at step 86500: 0.112295\n",
      "2023-12-06 14:43:24,862 INFO     Training average negative_sample_loss at step 86500: 0.083923\n",
      "2023-12-06 14:43:24,862 INFO     Training average loss at step 86500: 0.098109\n",
      "2023-12-06 14:43:50,257 INFO     Training average positive_sample_loss at step 86600: 0.112903\n",
      "2023-12-06 14:43:50,257 INFO     Training average negative_sample_loss at step 86600: 0.084562\n",
      "2023-12-06 14:43:50,258 INFO     Training average loss at step 86600: 0.098733\n",
      "2023-12-06 14:44:20,551 INFO     Training average positive_sample_loss at step 86700: 0.113267\n",
      "2023-12-06 14:44:20,551 INFO     Training average negative_sample_loss at step 86700: 0.084198\n",
      "2023-12-06 14:44:20,551 INFO     Training average loss at step 86700: 0.098732\n",
      "2023-12-06 14:44:45,431 INFO     Training average positive_sample_loss at step 86800: 0.111748\n",
      "2023-12-06 14:44:45,432 INFO     Training average negative_sample_loss at step 86800: 0.083646\n",
      "2023-12-06 14:44:45,432 INFO     Training average loss at step 86800: 0.097697\n",
      "2023-12-06 14:45:09,880 INFO     Training average positive_sample_loss at step 86900: 0.113275\n",
      "2023-12-06 14:45:09,880 INFO     Training average negative_sample_loss at step 86900: 0.084583\n",
      "2023-12-06 14:45:09,881 INFO     Training average loss at step 86900: 0.098929\n",
      "2023-12-06 14:45:38,096 INFO     Training average positive_sample_loss at step 87000: 0.112405\n",
      "2023-12-06 14:45:38,097 INFO     Training average negative_sample_loss at step 87000: 0.083655\n",
      "2023-12-06 14:45:38,097 INFO     Training average loss at step 87000: 0.098030\n",
      "2023-12-06 14:46:03,469 INFO     Training average positive_sample_loss at step 87100: 0.112330\n",
      "2023-12-06 14:46:03,469 INFO     Training average negative_sample_loss at step 87100: 0.084500\n",
      "2023-12-06 14:46:03,470 INFO     Training average loss at step 87100: 0.098415\n",
      "2023-12-06 14:46:28,578 INFO     Training average positive_sample_loss at step 87200: 0.114387\n",
      "2023-12-06 14:46:28,578 INFO     Training average negative_sample_loss at step 87200: 0.084737\n",
      "2023-12-06 14:46:28,578 INFO     Training average loss at step 87200: 0.099562\n",
      "2023-12-06 14:46:56,501 INFO     Training average positive_sample_loss at step 87300: 0.111929\n",
      "2023-12-06 14:46:56,501 INFO     Training average negative_sample_loss at step 87300: 0.083934\n",
      "2023-12-06 14:46:56,501 INFO     Training average loss at step 87300: 0.097932\n",
      "2023-12-06 14:47:22,106 INFO     Training average positive_sample_loss at step 87400: 0.113625\n",
      "2023-12-06 14:47:22,106 INFO     Training average negative_sample_loss at step 87400: 0.085062\n",
      "2023-12-06 14:47:22,106 INFO     Training average loss at step 87400: 0.099343\n",
      "2023-12-06 14:47:49,667 INFO     Training average positive_sample_loss at step 87500: 0.112043\n",
      "2023-12-06 14:47:49,667 INFO     Training average negative_sample_loss at step 87500: 0.084736\n",
      "2023-12-06 14:47:49,667 INFO     Training average loss at step 87500: 0.098389\n",
      "2023-12-06 14:48:16,002 INFO     Training average positive_sample_loss at step 87600: 0.112819\n",
      "2023-12-06 14:48:16,002 INFO     Training average negative_sample_loss at step 87600: 0.083727\n",
      "2023-12-06 14:48:16,002 INFO     Training average loss at step 87600: 0.098273\n",
      "2023-12-06 14:48:40,703 INFO     Training average positive_sample_loss at step 87700: 0.113447\n",
      "2023-12-06 14:48:40,703 INFO     Training average negative_sample_loss at step 87700: 0.084525\n",
      "2023-12-06 14:48:40,704 INFO     Training average loss at step 87700: 0.098986\n",
      "2023-12-06 14:49:09,035 INFO     Training average positive_sample_loss at step 87800: 0.112876\n",
      "2023-12-06 14:49:09,036 INFO     Training average negative_sample_loss at step 87800: 0.084522\n",
      "2023-12-06 14:49:09,036 INFO     Training average loss at step 87800: 0.098699\n",
      "2023-12-06 14:49:35,392 INFO     Training average positive_sample_loss at step 87900: 0.112565\n",
      "2023-12-06 14:49:35,393 INFO     Training average negative_sample_loss at step 87900: 0.083701\n",
      "2023-12-06 14:49:35,393 INFO     Training average loss at step 87900: 0.098133\n",
      "2023-12-06 14:50:04,812 INFO     Training average positive_sample_loss at step 88000: 0.113117\n",
      "2023-12-06 14:50:04,812 INFO     Training average negative_sample_loss at step 88000: 0.083214\n",
      "2023-12-06 14:50:04,812 INFO     Training average loss at step 88000: 0.098166\n",
      "2023-12-06 14:50:29,441 INFO     Training average positive_sample_loss at step 88100: 0.111900\n",
      "2023-12-06 14:50:29,442 INFO     Training average negative_sample_loss at step 88100: 0.084351\n",
      "2023-12-06 14:50:29,442 INFO     Training average loss at step 88100: 0.098125\n",
      "2023-12-06 14:50:55,294 INFO     Training average positive_sample_loss at step 88200: 0.113482\n",
      "2023-12-06 14:50:55,295 INFO     Training average negative_sample_loss at step 88200: 0.084066\n",
      "2023-12-06 14:50:55,295 INFO     Training average loss at step 88200: 0.098774\n",
      "2023-12-06 14:51:26,105 INFO     Training average positive_sample_loss at step 88300: 0.112630\n",
      "2023-12-06 14:51:26,106 INFO     Training average negative_sample_loss at step 88300: 0.083979\n",
      "2023-12-06 14:51:26,106 INFO     Training average loss at step 88300: 0.098304\n",
      "2023-12-06 14:51:51,362 INFO     Training average positive_sample_loss at step 88400: 0.112591\n",
      "2023-12-06 14:51:51,362 INFO     Training average negative_sample_loss at step 88400: 0.084258\n",
      "2023-12-06 14:51:51,362 INFO     Training average loss at step 88400: 0.098425\n",
      "2023-12-06 14:52:18,682 INFO     Training average positive_sample_loss at step 88500: 0.113722\n",
      "2023-12-06 14:52:18,682 INFO     Training average negative_sample_loss at step 88500: 0.084001\n",
      "2023-12-06 14:52:18,682 INFO     Training average loss at step 88500: 0.098862\n",
      "2023-12-06 14:52:43,692 INFO     Training average positive_sample_loss at step 88600: 0.111948\n",
      "2023-12-06 14:52:43,692 INFO     Training average negative_sample_loss at step 88600: 0.084552\n",
      "2023-12-06 14:52:43,692 INFO     Training average loss at step 88600: 0.098250\n",
      "2023-12-06 14:53:09,217 INFO     Training average positive_sample_loss at step 88700: 0.113032\n",
      "2023-12-06 14:53:09,217 INFO     Training average negative_sample_loss at step 88700: 0.083815\n",
      "2023-12-06 14:53:09,217 INFO     Training average loss at step 88700: 0.098424\n",
      "2023-12-06 14:53:37,503 INFO     Training average positive_sample_loss at step 88800: 0.112739\n",
      "2023-12-06 14:53:37,504 INFO     Training average negative_sample_loss at step 88800: 0.083855\n",
      "2023-12-06 14:53:37,504 INFO     Training average loss at step 88800: 0.098297\n",
      "2023-12-06 14:54:02,500 INFO     Training average positive_sample_loss at step 88900: 0.112533\n",
      "2023-12-06 14:54:02,500 INFO     Training average negative_sample_loss at step 88900: 0.084210\n",
      "2023-12-06 14:54:02,500 INFO     Training average loss at step 88900: 0.098371\n",
      "2023-12-06 14:54:26,893 INFO     Training average positive_sample_loss at step 89000: 0.113556\n",
      "2023-12-06 14:54:26,894 INFO     Training average negative_sample_loss at step 89000: 0.084263\n",
      "2023-12-06 14:54:26,894 INFO     Training average loss at step 89000: 0.098909\n",
      "2023-12-06 14:54:54,324 INFO     Training average positive_sample_loss at step 89100: 0.112427\n",
      "2023-12-06 14:54:54,324 INFO     Training average negative_sample_loss at step 89100: 0.084460\n",
      "2023-12-06 14:54:54,324 INFO     Training average loss at step 89100: 0.098443\n",
      "2023-12-06 14:55:19,543 INFO     Training average positive_sample_loss at step 89200: 0.112676\n",
      "2023-12-06 14:55:19,543 INFO     Training average negative_sample_loss at step 89200: 0.084449\n",
      "2023-12-06 14:55:19,543 INFO     Training average loss at step 89200: 0.098562\n",
      "2023-12-06 14:55:50,870 INFO     Training average positive_sample_loss at step 89300: 0.112985\n",
      "2023-12-06 14:55:50,870 INFO     Training average negative_sample_loss at step 89300: 0.084966\n",
      "2023-12-06 14:55:50,870 INFO     Training average loss at step 89300: 0.098975\n",
      "2023-12-06 14:56:16,826 INFO     Training average positive_sample_loss at step 89400: 0.112136\n",
      "2023-12-06 14:56:16,827 INFO     Training average negative_sample_loss at step 89400: 0.083500\n",
      "2023-12-06 14:56:16,827 INFO     Training average loss at step 89400: 0.097818\n",
      "2023-12-06 14:56:42,437 INFO     Training average positive_sample_loss at step 89500: 0.113171\n",
      "2023-12-06 14:56:42,438 INFO     Training average negative_sample_loss at step 89500: 0.083979\n",
      "2023-12-06 14:56:42,438 INFO     Training average loss at step 89500: 0.098575\n",
      "2023-12-06 14:57:10,589 INFO     Training average positive_sample_loss at step 89600: 0.112816\n",
      "2023-12-06 14:57:10,590 INFO     Training average negative_sample_loss at step 89600: 0.084459\n",
      "2023-12-06 14:57:10,590 INFO     Training average loss at step 89600: 0.098638\n",
      "2023-12-06 14:57:35,738 INFO     Training average positive_sample_loss at step 89700: 0.112936\n",
      "2023-12-06 14:57:35,738 INFO     Training average negative_sample_loss at step 89700: 0.084144\n",
      "2023-12-06 14:57:35,738 INFO     Training average loss at step 89700: 0.098540\n",
      "2023-12-06 14:58:04,918 INFO     Training average positive_sample_loss at step 89800: 0.112832\n",
      "2023-12-06 14:58:04,918 INFO     Training average negative_sample_loss at step 89800: 0.083898\n",
      "2023-12-06 14:58:04,918 INFO     Training average loss at step 89800: 0.098365\n",
      "2023-12-06 14:58:30,207 INFO     Training average positive_sample_loss at step 89900: 0.112702\n",
      "2023-12-06 14:58:30,207 INFO     Training average negative_sample_loss at step 89900: 0.083918\n",
      "2023-12-06 14:58:30,207 INFO     Training average loss at step 89900: 0.098310\n",
      "2023-12-06 14:59:06,088 INFO     Training average positive_sample_loss at step 90000: 0.112749\n",
      "2023-12-06 14:59:06,088 INFO     Training average negative_sample_loss at step 90000: 0.083981\n",
      "2023-12-06 14:59:06,088 INFO     Training average loss at step 90000: 0.098365\n",
      "2023-12-06 14:59:06,088 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 14:59:06,663 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 14:59:37,207 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 14:59:58,352 INFO     Valid MRR at step 90000: 0.643317\n",
      "2023-12-06 14:59:58,352 INFO     Valid MR at step 90000: 237.035951\n",
      "2023-12-06 14:59:58,352 INFO     Valid HITS@1 at step 90000: 0.587898\n",
      "2023-12-06 14:59:58,352 INFO     Valid HITS@3 at step 90000: 0.664745\n",
      "2023-12-06 14:59:58,352 INFO     Valid HITS@10 at step 90000: 0.756634\n",
      "2023-12-06 15:00:23,807 INFO     Training average positive_sample_loss at step 90100: 0.112537\n",
      "2023-12-06 15:00:23,808 INFO     Training average negative_sample_loss at step 90100: 0.084226\n",
      "2023-12-06 15:00:23,808 INFO     Training average loss at step 90100: 0.098382\n",
      "2023-12-06 15:00:48,743 INFO     Training average positive_sample_loss at step 90200: 0.112588\n",
      "2023-12-06 15:00:48,743 INFO     Training average negative_sample_loss at step 90200: 0.084412\n",
      "2023-12-06 15:00:48,743 INFO     Training average loss at step 90200: 0.098500\n",
      "2023-12-06 15:01:16,511 INFO     Training average positive_sample_loss at step 90300: 0.113334\n",
      "2023-12-06 15:01:16,511 INFO     Training average negative_sample_loss at step 90300: 0.084207\n",
      "2023-12-06 15:01:16,511 INFO     Training average loss at step 90300: 0.098771\n",
      "2023-12-06 15:01:42,809 INFO     Training average positive_sample_loss at step 90400: 0.111674\n",
      "2023-12-06 15:01:42,809 INFO     Training average negative_sample_loss at step 90400: 0.083637\n",
      "2023-12-06 15:01:42,809 INFO     Training average loss at step 90400: 0.097655\n",
      "2023-12-06 15:02:07,848 INFO     Training average positive_sample_loss at step 90500: 0.113165\n",
      "2023-12-06 15:02:07,848 INFO     Training average negative_sample_loss at step 90500: 0.083482\n",
      "2023-12-06 15:02:07,848 INFO     Training average loss at step 90500: 0.098324\n",
      "2023-12-06 15:02:38,867 INFO     Training average positive_sample_loss at step 90600: 0.113112\n",
      "2023-12-06 15:02:38,868 INFO     Training average negative_sample_loss at step 90600: 0.083897\n",
      "2023-12-06 15:02:38,868 INFO     Training average loss at step 90600: 0.098505\n",
      "2023-12-06 15:03:02,828 INFO     Training average positive_sample_loss at step 90700: 0.112208\n",
      "2023-12-06 15:03:02,828 INFO     Training average negative_sample_loss at step 90700: 0.084100\n",
      "2023-12-06 15:03:02,828 INFO     Training average loss at step 90700: 0.098154\n",
      "2023-12-06 15:03:27,267 INFO     Training average positive_sample_loss at step 90800: 0.113395\n",
      "2023-12-06 15:03:27,268 INFO     Training average negative_sample_loss at step 90800: 0.083338\n",
      "2023-12-06 15:03:27,268 INFO     Training average loss at step 90800: 0.098367\n",
      "2023-12-06 15:03:57,401 INFO     Training average positive_sample_loss at step 90900: 0.112160\n",
      "2023-12-06 15:03:57,401 INFO     Training average negative_sample_loss at step 90900: 0.084437\n",
      "2023-12-06 15:03:57,401 INFO     Training average loss at step 90900: 0.098298\n",
      "2023-12-06 15:04:21,461 INFO     Training average positive_sample_loss at step 91000: 0.112560\n",
      "2023-12-06 15:04:21,462 INFO     Training average negative_sample_loss at step 91000: 0.083980\n",
      "2023-12-06 15:04:21,462 INFO     Training average loss at step 91000: 0.098270\n",
      "2023-12-06 15:04:49,531 INFO     Training average positive_sample_loss at step 91100: 0.112918\n",
      "2023-12-06 15:04:49,532 INFO     Training average negative_sample_loss at step 91100: 0.083703\n",
      "2023-12-06 15:04:49,532 INFO     Training average loss at step 91100: 0.098310\n",
      "2023-12-06 15:05:14,928 INFO     Training average positive_sample_loss at step 91200: 0.112277\n",
      "2023-12-06 15:05:14,928 INFO     Training average negative_sample_loss at step 91200: 0.083584\n",
      "2023-12-06 15:05:14,928 INFO     Training average loss at step 91200: 0.097931\n",
      "2023-12-06 15:05:40,894 INFO     Training average positive_sample_loss at step 91300: 0.113600\n",
      "2023-12-06 15:05:40,895 INFO     Training average negative_sample_loss at step 91300: 0.084033\n",
      "2023-12-06 15:05:40,895 INFO     Training average loss at step 91300: 0.098816\n",
      "2023-12-06 15:06:08,834 INFO     Training average positive_sample_loss at step 91400: 0.112527\n",
      "2023-12-06 15:06:08,834 INFO     Training average negative_sample_loss at step 91400: 0.084316\n",
      "2023-12-06 15:06:08,834 INFO     Training average loss at step 91400: 0.098422\n",
      "2023-12-06 15:06:34,497 INFO     Training average positive_sample_loss at step 91500: 0.112328\n",
      "2023-12-06 15:06:34,498 INFO     Training average negative_sample_loss at step 91500: 0.083865\n",
      "2023-12-06 15:06:34,498 INFO     Training average loss at step 91500: 0.098096\n",
      "2023-12-06 15:07:02,506 INFO     Training average positive_sample_loss at step 91600: 0.113382\n",
      "2023-12-06 15:07:02,506 INFO     Training average negative_sample_loss at step 91600: 0.084768\n",
      "2023-12-06 15:07:02,506 INFO     Training average loss at step 91600: 0.099075\n",
      "2023-12-06 15:07:28,948 INFO     Training average positive_sample_loss at step 91700: 0.112492\n",
      "2023-12-06 15:07:28,948 INFO     Training average negative_sample_loss at step 91700: 0.084136\n",
      "2023-12-06 15:07:28,948 INFO     Training average loss at step 91700: 0.098314\n",
      "2023-12-06 15:07:53,825 INFO     Training average positive_sample_loss at step 91800: 0.112980\n",
      "2023-12-06 15:07:53,825 INFO     Training average negative_sample_loss at step 91800: 0.084195\n",
      "2023-12-06 15:07:53,825 INFO     Training average loss at step 91800: 0.098587\n",
      "2023-12-06 15:08:22,614 INFO     Training average positive_sample_loss at step 91900: 0.112547\n",
      "2023-12-06 15:08:22,615 INFO     Training average negative_sample_loss at step 91900: 0.084406\n",
      "2023-12-06 15:08:22,615 INFO     Training average loss at step 91900: 0.098476\n",
      "2023-12-06 15:08:48,058 INFO     Training average positive_sample_loss at step 92000: 0.112224\n",
      "2023-12-06 15:08:48,059 INFO     Training average negative_sample_loss at step 92000: 0.084835\n",
      "2023-12-06 15:08:48,059 INFO     Training average loss at step 92000: 0.098530\n",
      "2023-12-06 15:09:13,979 INFO     Training average positive_sample_loss at step 92100: 0.113720\n",
      "2023-12-06 15:09:13,980 INFO     Training average negative_sample_loss at step 92100: 0.084502\n",
      "2023-12-06 15:09:13,980 INFO     Training average loss at step 92100: 0.099111\n",
      "2023-12-06 15:09:43,733 INFO     Training average positive_sample_loss at step 92200: 0.112494\n",
      "2023-12-06 15:09:43,734 INFO     Training average negative_sample_loss at step 92200: 0.084515\n",
      "2023-12-06 15:09:43,734 INFO     Training average loss at step 92200: 0.098505\n",
      "2023-12-06 15:10:08,349 INFO     Training average positive_sample_loss at step 92300: 0.112890\n",
      "2023-12-06 15:10:08,349 INFO     Training average negative_sample_loss at step 92300: 0.083977\n",
      "2023-12-06 15:10:08,350 INFO     Training average loss at step 92300: 0.098434\n",
      "2023-12-06 15:10:37,450 INFO     Training average positive_sample_loss at step 92400: 0.112836\n",
      "2023-12-06 15:10:37,451 INFO     Training average negative_sample_loss at step 92400: 0.084218\n",
      "2023-12-06 15:10:37,451 INFO     Training average loss at step 92400: 0.098527\n",
      "2023-12-06 15:11:03,012 INFO     Training average positive_sample_loss at step 92500: 0.112318\n",
      "2023-12-06 15:11:03,013 INFO     Training average negative_sample_loss at step 92500: 0.084192\n",
      "2023-12-06 15:11:03,013 INFO     Training average loss at step 92500: 0.098255\n",
      "2023-12-06 15:11:28,823 INFO     Training average positive_sample_loss at step 92600: 0.113197\n",
      "2023-12-06 15:11:28,823 INFO     Training average negative_sample_loss at step 92600: 0.084131\n",
      "2023-12-06 15:11:28,823 INFO     Training average loss at step 92600: 0.098664\n",
      "2023-12-06 15:11:57,009 INFO     Training average positive_sample_loss at step 92700: 0.112180\n",
      "2023-12-06 15:11:57,010 INFO     Training average negative_sample_loss at step 92700: 0.084017\n",
      "2023-12-06 15:11:57,010 INFO     Training average loss at step 92700: 0.098099\n",
      "2023-12-06 15:12:21,922 INFO     Training average positive_sample_loss at step 92800: 0.113287\n",
      "2023-12-06 15:12:21,923 INFO     Training average negative_sample_loss at step 92800: 0.084622\n",
      "2023-12-06 15:12:21,923 INFO     Training average loss at step 92800: 0.098954\n",
      "2023-12-06 15:12:50,752 INFO     Training average positive_sample_loss at step 92900: 0.113150\n",
      "2023-12-06 15:12:50,753 INFO     Training average negative_sample_loss at step 92900: 0.084112\n",
      "2023-12-06 15:12:50,753 INFO     Training average loss at step 92900: 0.098631\n",
      "2023-12-06 15:13:16,231 INFO     Training average positive_sample_loss at step 93000: 0.112154\n",
      "2023-12-06 15:13:16,232 INFO     Training average negative_sample_loss at step 93000: 0.083742\n",
      "2023-12-06 15:13:16,232 INFO     Training average loss at step 93000: 0.097948\n",
      "2023-12-06 15:13:41,536 INFO     Training average positive_sample_loss at step 93100: 0.113389\n",
      "2023-12-06 15:13:41,536 INFO     Training average negative_sample_loss at step 93100: 0.084388\n",
      "2023-12-06 15:13:41,536 INFO     Training average loss at step 93100: 0.098888\n",
      "2023-12-06 15:14:11,448 INFO     Training average positive_sample_loss at step 93200: 0.112057\n",
      "2023-12-06 15:14:11,448 INFO     Training average negative_sample_loss at step 93200: 0.083941\n",
      "2023-12-06 15:14:11,448 INFO     Training average loss at step 93200: 0.097999\n",
      "2023-12-06 15:14:36,545 INFO     Training average positive_sample_loss at step 93300: 0.112673\n",
      "2023-12-06 15:14:36,545 INFO     Training average negative_sample_loss at step 93300: 0.083538\n",
      "2023-12-06 15:14:36,545 INFO     Training average loss at step 93300: 0.098105\n",
      "2023-12-06 15:15:06,933 INFO     Training average positive_sample_loss at step 93400: 0.113615\n",
      "2023-12-06 15:15:06,934 INFO     Training average negative_sample_loss at step 93400: 0.085070\n",
      "2023-12-06 15:15:06,934 INFO     Training average loss at step 93400: 0.099342\n",
      "2023-12-06 15:15:32,575 INFO     Training average positive_sample_loss at step 93500: 0.112015\n",
      "2023-12-06 15:15:32,575 INFO     Training average negative_sample_loss at step 93500: 0.084221\n",
      "2023-12-06 15:15:32,575 INFO     Training average loss at step 93500: 0.098118\n",
      "2023-12-06 15:15:58,573 INFO     Training average positive_sample_loss at step 93600: 0.112855\n",
      "2023-12-06 15:15:58,573 INFO     Training average negative_sample_loss at step 93600: 0.083622\n",
      "2023-12-06 15:15:58,574 INFO     Training average loss at step 93600: 0.098238\n",
      "2023-12-06 15:16:27,446 INFO     Training average positive_sample_loss at step 93700: 0.112889\n",
      "2023-12-06 15:16:27,447 INFO     Training average negative_sample_loss at step 93700: 0.083734\n",
      "2023-12-06 15:16:27,447 INFO     Training average loss at step 93700: 0.098311\n",
      "2023-12-06 15:16:52,299 INFO     Training average positive_sample_loss at step 93800: 0.112754\n",
      "2023-12-06 15:16:52,300 INFO     Training average negative_sample_loss at step 93800: 0.084162\n",
      "2023-12-06 15:16:52,300 INFO     Training average loss at step 93800: 0.098458\n",
      "2023-12-06 15:17:17,921 INFO     Training average positive_sample_loss at step 93900: 0.113111\n",
      "2023-12-06 15:17:17,921 INFO     Training average negative_sample_loss at step 93900: 0.084706\n",
      "2023-12-06 15:17:17,921 INFO     Training average loss at step 93900: 0.098909\n",
      "2023-12-06 15:17:45,726 INFO     Training average positive_sample_loss at step 94000: 0.112240\n",
      "2023-12-06 15:17:45,727 INFO     Training average negative_sample_loss at step 94000: 0.083658\n",
      "2023-12-06 15:17:45,727 INFO     Training average loss at step 94000: 0.097949\n",
      "2023-12-06 15:18:11,082 INFO     Training average positive_sample_loss at step 94100: 0.112774\n",
      "2023-12-06 15:18:11,083 INFO     Training average negative_sample_loss at step 94100: 0.085161\n",
      "2023-12-06 15:18:11,083 INFO     Training average loss at step 94100: 0.098968\n",
      "2023-12-06 15:18:39,542 INFO     Training average positive_sample_loss at step 94200: 0.112837\n",
      "2023-12-06 15:18:39,543 INFO     Training average negative_sample_loss at step 94200: 0.084381\n",
      "2023-12-06 15:18:39,543 INFO     Training average loss at step 94200: 0.098609\n",
      "2023-12-06 15:19:05,687 INFO     Training average positive_sample_loss at step 94300: 0.112656\n",
      "2023-12-06 15:19:05,688 INFO     Training average negative_sample_loss at step 94300: 0.084218\n",
      "2023-12-06 15:19:05,688 INFO     Training average loss at step 94300: 0.098437\n",
      "2023-12-06 15:19:30,616 INFO     Training average positive_sample_loss at step 94400: 0.113142\n",
      "2023-12-06 15:19:30,617 INFO     Training average negative_sample_loss at step 94400: 0.084427\n",
      "2023-12-06 15:19:30,617 INFO     Training average loss at step 94400: 0.098785\n",
      "2023-12-06 15:19:59,966 INFO     Training average positive_sample_loss at step 94500: 0.112525\n",
      "2023-12-06 15:19:59,966 INFO     Training average negative_sample_loss at step 94500: 0.084549\n",
      "2023-12-06 15:19:59,966 INFO     Training average loss at step 94500: 0.098537\n",
      "2023-12-06 15:20:25,569 INFO     Training average positive_sample_loss at step 94600: 0.112705\n",
      "2023-12-06 15:20:25,570 INFO     Training average negative_sample_loss at step 94600: 0.084334\n",
      "2023-12-06 15:20:25,570 INFO     Training average loss at step 94600: 0.098519\n",
      "2023-12-06 15:20:53,396 INFO     Training average positive_sample_loss at step 94700: 0.113301\n",
      "2023-12-06 15:20:53,397 INFO     Training average negative_sample_loss at step 94700: 0.083723\n",
      "2023-12-06 15:20:53,397 INFO     Training average loss at step 94700: 0.098512\n",
      "2023-12-06 15:21:18,038 INFO     Training average positive_sample_loss at step 94800: 0.111992\n",
      "2023-12-06 15:21:18,039 INFO     Training average negative_sample_loss at step 94800: 0.084184\n",
      "2023-12-06 15:21:18,039 INFO     Training average loss at step 94800: 0.098088\n",
      "2023-12-06 15:21:42,357 INFO     Training average positive_sample_loss at step 94900: 0.113148\n",
      "2023-12-06 15:21:42,358 INFO     Training average negative_sample_loss at step 94900: 0.084110\n",
      "2023-12-06 15:21:42,358 INFO     Training average loss at step 94900: 0.098629\n",
      "2023-12-06 15:22:11,631 INFO     Training average positive_sample_loss at step 95000: 0.112469\n",
      "2023-12-06 15:22:11,632 INFO     Training average negative_sample_loss at step 95000: 0.084042\n",
      "2023-12-06 15:22:11,632 INFO     Training average loss at step 95000: 0.098255\n",
      "2023-12-06 15:22:35,822 INFO     Training average positive_sample_loss at step 95100: 0.112753\n",
      "2023-12-06 15:22:35,823 INFO     Training average negative_sample_loss at step 95100: 0.083821\n",
      "2023-12-06 15:22:35,823 INFO     Training average loss at step 95100: 0.098287\n",
      "2023-12-06 15:23:00,688 INFO     Training average positive_sample_loss at step 95200: 0.113524\n",
      "2023-12-06 15:23:00,688 INFO     Training average negative_sample_loss at step 95200: 0.084013\n",
      "2023-12-06 15:23:00,688 INFO     Training average loss at step 95200: 0.098768\n",
      "2023-12-06 15:23:29,612 INFO     Training average positive_sample_loss at step 95300: 0.112402\n",
      "2023-12-06 15:23:29,612 INFO     Training average negative_sample_loss at step 95300: 0.085107\n",
      "2023-12-06 15:23:29,612 INFO     Training average loss at step 95300: 0.098755\n",
      "2023-12-06 15:23:53,904 INFO     Training average positive_sample_loss at step 95400: 0.112583\n",
      "2023-12-06 15:23:53,905 INFO     Training average negative_sample_loss at step 95400: 0.083888\n",
      "2023-12-06 15:23:53,905 INFO     Training average loss at step 95400: 0.098236\n",
      "2023-12-06 15:24:22,608 INFO     Training average positive_sample_loss at step 95500: 0.112842\n",
      "2023-12-06 15:24:22,608 INFO     Training average negative_sample_loss at step 95500: 0.083633\n",
      "2023-12-06 15:24:22,608 INFO     Training average loss at step 95500: 0.098238\n",
      "2023-12-06 15:24:47,932 INFO     Training average positive_sample_loss at step 95600: 0.112724\n",
      "2023-12-06 15:24:47,933 INFO     Training average negative_sample_loss at step 95600: 0.084384\n",
      "2023-12-06 15:24:47,933 INFO     Training average loss at step 95600: 0.098554\n",
      "2023-12-06 15:25:13,528 INFO     Training average positive_sample_loss at step 95700: 0.113193\n",
      "2023-12-06 15:25:13,529 INFO     Training average negative_sample_loss at step 95700: 0.084299\n",
      "2023-12-06 15:25:13,529 INFO     Training average loss at step 95700: 0.098746\n",
      "2023-12-06 15:25:44,014 INFO     Training average positive_sample_loss at step 95800: 0.111898\n",
      "2023-12-06 15:25:44,014 INFO     Training average negative_sample_loss at step 95800: 0.084134\n",
      "2023-12-06 15:25:44,014 INFO     Training average loss at step 95800: 0.098016\n",
      "2023-12-06 15:26:08,139 INFO     Training average positive_sample_loss at step 95900: 0.113149\n",
      "2023-12-06 15:26:08,140 INFO     Training average negative_sample_loss at step 95900: 0.084844\n",
      "2023-12-06 15:26:08,140 INFO     Training average loss at step 95900: 0.098997\n",
      "2023-12-06 15:26:36,471 INFO     Training average positive_sample_loss at step 96000: 0.112787\n",
      "2023-12-06 15:26:36,471 INFO     Training average negative_sample_loss at step 96000: 0.083321\n",
      "2023-12-06 15:26:36,471 INFO     Training average loss at step 96000: 0.098054\n",
      "2023-12-06 15:27:01,050 INFO     Training average positive_sample_loss at step 96100: 0.112274\n",
      "2023-12-06 15:27:01,051 INFO     Training average negative_sample_loss at step 96100: 0.083764\n",
      "2023-12-06 15:27:01,051 INFO     Training average loss at step 96100: 0.098019\n",
      "2023-12-06 15:27:25,731 INFO     Training average positive_sample_loss at step 96200: 0.113159\n",
      "2023-12-06 15:27:25,732 INFO     Training average negative_sample_loss at step 96200: 0.084387\n",
      "2023-12-06 15:27:25,732 INFO     Training average loss at step 96200: 0.098773\n",
      "2023-12-06 15:27:54,957 INFO     Training average positive_sample_loss at step 96300: 0.112862\n",
      "2023-12-06 15:27:54,957 INFO     Training average negative_sample_loss at step 96300: 0.084279\n",
      "2023-12-06 15:27:54,957 INFO     Training average loss at step 96300: 0.098571\n",
      "2023-12-06 15:28:20,328 INFO     Training average positive_sample_loss at step 96400: 0.112554\n",
      "2023-12-06 15:28:20,329 INFO     Training average negative_sample_loss at step 96400: 0.084020\n",
      "2023-12-06 15:28:20,329 INFO     Training average loss at step 96400: 0.098287\n",
      "2023-12-06 15:28:49,384 INFO     Training average positive_sample_loss at step 96500: 0.113017\n",
      "2023-12-06 15:28:49,384 INFO     Training average negative_sample_loss at step 96500: 0.083501\n",
      "2023-12-06 15:28:49,384 INFO     Training average loss at step 96500: 0.098259\n",
      "2023-12-06 15:29:14,559 INFO     Training average positive_sample_loss at step 96600: 0.112500\n",
      "2023-12-06 15:29:14,560 INFO     Training average negative_sample_loss at step 96600: 0.084040\n",
      "2023-12-06 15:29:14,560 INFO     Training average loss at step 96600: 0.098270\n",
      "2023-12-06 15:29:39,504 INFO     Training average positive_sample_loss at step 96700: 0.112664\n",
      "2023-12-06 15:29:39,505 INFO     Training average negative_sample_loss at step 96700: 0.084224\n",
      "2023-12-06 15:29:39,505 INFO     Training average loss at step 96700: 0.098444\n",
      "2023-12-06 15:30:07,766 INFO     Training average positive_sample_loss at step 96800: 0.112242\n",
      "2023-12-06 15:30:07,766 INFO     Training average negative_sample_loss at step 96800: 0.083880\n",
      "2023-12-06 15:30:07,767 INFO     Training average loss at step 96800: 0.098061\n",
      "2023-12-06 15:30:33,082 INFO     Training average positive_sample_loss at step 96900: 0.112664\n",
      "2023-12-06 15:30:33,082 INFO     Training average negative_sample_loss at step 96900: 0.084365\n",
      "2023-12-06 15:30:33,082 INFO     Training average loss at step 96900: 0.098515\n",
      "2023-12-06 15:30:57,875 INFO     Training average positive_sample_loss at step 97000: 0.113434\n",
      "2023-12-06 15:30:57,875 INFO     Training average negative_sample_loss at step 97000: 0.084464\n",
      "2023-12-06 15:30:57,875 INFO     Training average loss at step 97000: 0.098949\n",
      "2023-12-06 15:31:27,952 INFO     Training average positive_sample_loss at step 97100: 0.112376\n",
      "2023-12-06 15:31:27,952 INFO     Training average negative_sample_loss at step 97100: 0.084355\n",
      "2023-12-06 15:31:27,952 INFO     Training average loss at step 97100: 0.098365\n",
      "2023-12-06 15:31:52,869 INFO     Training average positive_sample_loss at step 97200: 0.112955\n",
      "2023-12-06 15:31:52,869 INFO     Training average negative_sample_loss at step 97200: 0.084404\n",
      "2023-12-06 15:31:52,869 INFO     Training average loss at step 97200: 0.098679\n",
      "2023-12-06 15:32:22,130 INFO     Training average positive_sample_loss at step 97300: 0.112768\n",
      "2023-12-06 15:32:22,131 INFO     Training average negative_sample_loss at step 97300: 0.084781\n",
      "2023-12-06 15:32:22,131 INFO     Training average loss at step 97300: 0.098775\n",
      "2023-12-06 15:32:46,690 INFO     Training average positive_sample_loss at step 97400: 0.112505\n",
      "2023-12-06 15:32:46,691 INFO     Training average negative_sample_loss at step 97400: 0.083659\n",
      "2023-12-06 15:32:46,691 INFO     Training average loss at step 97400: 0.098082\n",
      "2023-12-06 15:33:11,333 INFO     Training average positive_sample_loss at step 97500: 0.113307\n",
      "2023-12-06 15:33:11,333 INFO     Training average negative_sample_loss at step 97500: 0.084527\n",
      "2023-12-06 15:33:11,333 INFO     Training average loss at step 97500: 0.098917\n",
      "2023-12-06 15:33:40,805 INFO     Training average positive_sample_loss at step 97600: 0.111901\n",
      "2023-12-06 15:33:40,806 INFO     Training average negative_sample_loss at step 97600: 0.084265\n",
      "2023-12-06 15:33:40,806 INFO     Training average loss at step 97600: 0.098083\n",
      "2023-12-06 15:34:06,274 INFO     Training average positive_sample_loss at step 97700: 0.113149\n",
      "2023-12-06 15:34:06,275 INFO     Training average negative_sample_loss at step 97700: 0.084321\n",
      "2023-12-06 15:34:06,275 INFO     Training average loss at step 97700: 0.098735\n",
      "2023-12-06 15:34:35,223 INFO     Training average positive_sample_loss at step 97800: 0.113164\n",
      "2023-12-06 15:34:35,223 INFO     Training average negative_sample_loss at step 97800: 0.084799\n",
      "2023-12-06 15:34:35,223 INFO     Training average loss at step 97800: 0.098981\n",
      "2023-12-06 15:35:00,091 INFO     Training average positive_sample_loss at step 97900: 0.111902\n",
      "2023-12-06 15:35:00,091 INFO     Training average negative_sample_loss at step 97900: 0.084230\n",
      "2023-12-06 15:35:00,091 INFO     Training average loss at step 97900: 0.098066\n",
      "2023-12-06 15:35:25,627 INFO     Training average positive_sample_loss at step 98000: 0.113310\n",
      "2023-12-06 15:35:25,627 INFO     Training average negative_sample_loss at step 98000: 0.083641\n",
      "2023-12-06 15:35:25,627 INFO     Training average loss at step 98000: 0.098476\n",
      "2023-12-06 15:35:53,767 INFO     Training average positive_sample_loss at step 98100: 0.112320\n",
      "2023-12-06 15:35:53,767 INFO     Training average negative_sample_loss at step 98100: 0.084725\n",
      "2023-12-06 15:35:53,768 INFO     Training average loss at step 98100: 0.098522\n",
      "2023-12-06 15:36:17,976 INFO     Training average positive_sample_loss at step 98200: 0.112743\n",
      "2023-12-06 15:36:17,977 INFO     Training average negative_sample_loss at step 98200: 0.084812\n",
      "2023-12-06 15:36:17,977 INFO     Training average loss at step 98200: 0.098777\n",
      "2023-12-06 15:36:48,033 INFO     Training average positive_sample_loss at step 98300: 0.113769\n",
      "2023-12-06 15:36:48,034 INFO     Training average negative_sample_loss at step 98300: 0.083826\n",
      "2023-12-06 15:36:48,034 INFO     Training average loss at step 98300: 0.098798\n",
      "2023-12-06 15:37:12,873 INFO     Training average positive_sample_loss at step 98400: 0.112120\n",
      "2023-12-06 15:37:12,874 INFO     Training average negative_sample_loss at step 98400: 0.083956\n",
      "2023-12-06 15:37:12,874 INFO     Training average loss at step 98400: 0.098038\n",
      "2023-12-06 15:37:37,350 INFO     Training average positive_sample_loss at step 98500: 0.113216\n",
      "2023-12-06 15:37:37,351 INFO     Training average negative_sample_loss at step 98500: 0.084006\n",
      "2023-12-06 15:37:37,351 INFO     Training average loss at step 98500: 0.098611\n",
      "2023-12-06 15:38:07,285 INFO     Training average positive_sample_loss at step 98600: 0.112812\n",
      "2023-12-06 15:38:07,285 INFO     Training average negative_sample_loss at step 98600: 0.084106\n",
      "2023-12-06 15:38:07,285 INFO     Training average loss at step 98600: 0.098459\n",
      "2023-12-06 15:38:32,636 INFO     Training average positive_sample_loss at step 98700: 0.112193\n",
      "2023-12-06 15:38:32,636 INFO     Training average negative_sample_loss at step 98700: 0.083991\n",
      "2023-12-06 15:38:32,636 INFO     Training average loss at step 98700: 0.098092\n",
      "2023-12-06 15:38:57,460 INFO     Training average positive_sample_loss at step 98800: 0.113369\n",
      "2023-12-06 15:38:57,461 INFO     Training average negative_sample_loss at step 98800: 0.083648\n",
      "2023-12-06 15:38:57,461 INFO     Training average loss at step 98800: 0.098509\n",
      "2023-12-06 15:39:26,501 INFO     Training average positive_sample_loss at step 98900: 0.112306\n",
      "2023-12-06 15:39:26,502 INFO     Training average negative_sample_loss at step 98900: 0.084702\n",
      "2023-12-06 15:39:26,502 INFO     Training average loss at step 98900: 0.098504\n",
      "2023-12-06 15:39:52,243 INFO     Training average positive_sample_loss at step 99000: 0.112816\n",
      "2023-12-06 15:39:52,243 INFO     Training average negative_sample_loss at step 99000: 0.083995\n",
      "2023-12-06 15:39:52,243 INFO     Training average loss at step 99000: 0.098406\n",
      "2023-12-06 15:40:21,736 INFO     Training average positive_sample_loss at step 99100: 0.112981\n",
      "2023-12-06 15:40:21,736 INFO     Training average negative_sample_loss at step 99100: 0.084097\n",
      "2023-12-06 15:40:21,737 INFO     Training average loss at step 99100: 0.098539\n",
      "2023-12-06 15:40:45,868 INFO     Training average positive_sample_loss at step 99200: 0.112546\n",
      "2023-12-06 15:40:45,868 INFO     Training average negative_sample_loss at step 99200: 0.083498\n",
      "2023-12-06 15:40:45,868 INFO     Training average loss at step 99200: 0.098022\n",
      "2023-12-06 15:41:10,584 INFO     Training average positive_sample_loss at step 99300: 0.112818\n",
      "2023-12-06 15:41:10,584 INFO     Training average negative_sample_loss at step 99300: 0.083778\n",
      "2023-12-06 15:41:10,584 INFO     Training average loss at step 99300: 0.098298\n",
      "2023-12-06 15:41:39,436 INFO     Training average positive_sample_loss at step 99400: 0.112401\n",
      "2023-12-06 15:41:39,436 INFO     Training average negative_sample_loss at step 99400: 0.084442\n",
      "2023-12-06 15:41:39,436 INFO     Training average loss at step 99400: 0.098421\n",
      "2023-12-06 15:42:04,758 INFO     Training average positive_sample_loss at step 99500: 0.112877\n",
      "2023-12-06 15:42:04,758 INFO     Training average negative_sample_loss at step 99500: 0.083958\n",
      "2023-12-06 15:42:04,758 INFO     Training average loss at step 99500: 0.098417\n",
      "2023-12-06 15:42:35,029 INFO     Training average positive_sample_loss at step 99600: 0.112962\n",
      "2023-12-06 15:42:35,029 INFO     Training average negative_sample_loss at step 99600: 0.085102\n",
      "2023-12-06 15:42:35,030 INFO     Training average loss at step 99600: 0.099032\n",
      "2023-12-06 15:42:59,358 INFO     Training average positive_sample_loss at step 99700: 0.112014\n",
      "2023-12-06 15:42:59,358 INFO     Training average negative_sample_loss at step 99700: 0.084067\n",
      "2023-12-06 15:42:59,358 INFO     Training average loss at step 99700: 0.098040\n",
      "2023-12-06 15:43:23,769 INFO     Training average positive_sample_loss at step 99800: 0.113114\n",
      "2023-12-06 15:43:23,769 INFO     Training average negative_sample_loss at step 99800: 0.084099\n",
      "2023-12-06 15:43:23,770 INFO     Training average loss at step 99800: 0.098606\n",
      "2023-12-06 15:43:53,630 INFO     Training average positive_sample_loss at step 99900: 0.112792\n",
      "2023-12-06 15:43:53,630 INFO     Training average negative_sample_loss at step 99900: 0.084247\n",
      "2023-12-06 15:43:53,630 INFO     Training average loss at step 99900: 0.098519\n",
      "2023-12-06 15:44:32,053 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 15:44:32,686 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 15:45:00,908 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 15:45:21,194 INFO     Valid MRR at step 99999: 0.643654\n",
      "2023-12-06 15:45:21,194 INFO     Valid MR at step 99999: 237.017464\n",
      "2023-12-06 15:45:21,194 INFO     Valid HITS@1 at step 99999: 0.585988\n",
      "2023-12-06 15:45:21,194 INFO     Valid HITS@3 at step 99999: 0.667235\n",
      "2023-12-06 15:45:21,194 INFO     Valid HITS@10 at step 99999: 0.756498\n",
      "2023-12-06 15:45:21,194 INFO     Evaluating on Test Dataset...\n",
      "2023-12-06 15:45:21,566 INFO     Evaluating the model... (0/4582)\n",
      "2023-12-06 15:45:49,455 INFO     Evaluating the model... (1000/4582)\n",
      "2023-12-06 15:46:19,184 INFO     Evaluating the model... (2000/4582)\n",
      "2023-12-06 15:46:47,783 INFO     Evaluating the model... (3000/4582)\n",
      "2023-12-06 15:47:14,910 INFO     Evaluating the model... (4000/4582)\n",
      "2023-12-06 15:47:29,699 INFO     Test MRR at step 99999: 0.642088\n",
      "2023-12-06 15:47:29,700 INFO     Test MR at step 99999: 219.874540\n",
      "2023-12-06 15:47:29,700 INFO     Test HITS@1 at step 99999: 0.584732\n",
      "2023-12-06 15:47:29,700 INFO     Test HITS@3 at step 99999: 0.664879\n",
      "2023-12-06 15:47:29,700 INFO     Test HITS@10 at step 99999: 0.754701\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE DBpedia15K 0 0 1024 256 1000 9.0 1.0 0.00005 100000 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione: 456 minuti e 45 secondi\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "minutes, seconds = divmod(execution_time, 60)\n",
    "print(f\"Tempo di esecuzione: {int(minutes)} minuti e {int(seconds)} secondi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vecchio metodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding_patt\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding_patt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-06 22:25:25,512 INFO     Model: RotatE\n",
      "2023-12-06 22:25:25,512 INFO     Data Path: data/DBpedia15K\n",
      "2023-12-06 22:25:25,512 INFO     #entity: 12863\n",
      "2023-12-06 22:25:25,512 INFO     #relation: 279\n",
      "2023-12-06 22:25:25,647 INFO     #train: 131918\n",
      "2023-12-06 22:25:25,669 INFO     #valid: 14659\n",
      "2023-12-06 22:25:25,721 INFO     #test: 36645\n",
      "2023-12-06 22:25:25,863 INFO     Model Parameter Configuration:\n",
      "2023-12-06 22:25:25,864 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-06 22:25:25,864 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-06 22:25:25,864 INFO     Parameter entity_embedding: torch.Size([12863, 2000]), require_grad = True\n",
      "2023-12-06 22:25:25,864 INFO     Parameter relation_embedding: torch.Size([279, 1000]), require_grad = True\n",
      "2023-12-06 22:38:36,112 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-06 22:38:36,112 INFO     Start Training...\n",
      "2023-12-06 22:38:36,112 INFO     init_step = 0\n",
      "2023-12-06 22:38:36,112 INFO     batch_size = 1024\n",
      "2023-12-06 22:38:36,112 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-06 22:38:36,112 INFO     hidden_dim = 1000\n",
      "2023-12-06 22:38:36,112 INFO     gamma = 9.000000\n",
      "2023-12-06 22:38:36,112 INFO     negative_adversarial_sampling = True\n",
      "2023-12-06 22:38:36,112 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-06 22:38:36,112 INFO     learning_rate = 0\n",
      "2023-12-06 22:38:53,765 INFO     Training average positive_sample_loss at step 0: 2.552984\n",
      "2023-12-06 22:38:53,766 INFO     Training average negative_sample_loss at step 0: 0.084302\n",
      "2023-12-06 22:38:53,766 INFO     Training average loss at step 0: 1.318643\n",
      "2023-12-06 22:38:53,766 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 22:38:54,209 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 22:39:19,177 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 22:39:41,116 INFO     Valid MRR at step 0: 0.006991\n",
      "2023-12-06 22:39:41,116 INFO     Valid MR at step 0: 5142.241183\n",
      "2023-12-06 22:39:41,116 INFO     Valid HITS@1 at step 0: 0.005901\n",
      "2023-12-06 22:39:41,116 INFO     Valid HITS@3 at step 0: 0.006105\n",
      "2023-12-06 22:39:41,116 INFO     Valid HITS@10 at step 0: 0.007470\n",
      "2023-12-06 22:40:21,243 INFO     Training average positive_sample_loss at step 100: 2.093022\n",
      "2023-12-06 22:40:21,244 INFO     Training average negative_sample_loss at step 100: 0.152230\n",
      "2023-12-06 22:40:21,244 INFO     Training average loss at step 100: 1.122626\n",
      "2023-12-06 22:41:00,382 INFO     Training average positive_sample_loss at step 200: 1.171655\n",
      "2023-12-06 22:41:00,383 INFO     Training average negative_sample_loss at step 200: 0.329581\n",
      "2023-12-06 22:41:00,383 INFO     Training average loss at step 200: 0.750618\n",
      "2023-12-06 22:41:46,582 INFO     Training average positive_sample_loss at step 300: 0.755032\n",
      "2023-12-06 22:41:46,582 INFO     Training average negative_sample_loss at step 300: 0.458285\n",
      "2023-12-06 22:41:46,583 INFO     Training average loss at step 300: 0.606658\n",
      "2023-12-06 22:42:25,530 INFO     Training average positive_sample_loss at step 400: 0.605197\n",
      "2023-12-06 22:42:25,530 INFO     Training average negative_sample_loss at step 400: 0.482521\n",
      "2023-12-06 22:42:25,530 INFO     Training average loss at step 400: 0.543859\n",
      "2023-12-06 22:43:04,397 INFO     Training average positive_sample_loss at step 500: 0.565284\n",
      "2023-12-06 22:43:04,398 INFO     Training average negative_sample_loss at step 500: 0.479902\n",
      "2023-12-06 22:43:04,398 INFO     Training average loss at step 500: 0.522593\n",
      "2023-12-06 22:43:46,094 INFO     Training average positive_sample_loss at step 600: 0.492420\n",
      "2023-12-06 22:43:46,094 INFO     Training average negative_sample_loss at step 600: 0.457676\n",
      "2023-12-06 22:43:46,094 INFO     Training average loss at step 600: 0.475048\n",
      "2023-12-06 22:44:24,612 INFO     Training average positive_sample_loss at step 700: 0.486832\n",
      "2023-12-06 22:44:24,613 INFO     Training average negative_sample_loss at step 700: 0.428183\n",
      "2023-12-06 22:44:24,613 INFO     Training average loss at step 700: 0.457508\n",
      "2023-12-06 22:45:06,234 INFO     Training average positive_sample_loss at step 800: 0.462735\n",
      "2023-12-06 22:45:06,234 INFO     Training average negative_sample_loss at step 800: 0.411597\n",
      "2023-12-06 22:45:06,234 INFO     Training average loss at step 800: 0.437166\n",
      "2023-12-06 22:45:44,746 INFO     Training average positive_sample_loss at step 900: 0.432804\n",
      "2023-12-06 22:45:44,747 INFO     Training average negative_sample_loss at step 900: 0.378834\n",
      "2023-12-06 22:45:44,747 INFO     Training average loss at step 900: 0.405819\n",
      "2023-12-06 22:46:23,029 INFO     Training average positive_sample_loss at step 1000: 0.431682\n",
      "2023-12-06 22:46:23,029 INFO     Training average negative_sample_loss at step 1000: 0.360391\n",
      "2023-12-06 22:46:23,029 INFO     Training average loss at step 1000: 0.396037\n",
      "2023-12-06 22:47:05,177 INFO     Training average positive_sample_loss at step 1100: 0.395868\n",
      "2023-12-06 22:47:05,177 INFO     Training average negative_sample_loss at step 1100: 0.341532\n",
      "2023-12-06 22:47:05,177 INFO     Training average loss at step 1100: 0.368700\n",
      "2023-12-06 22:47:43,559 INFO     Training average positive_sample_loss at step 1200: 0.390639\n",
      "2023-12-06 22:47:43,559 INFO     Training average negative_sample_loss at step 1200: 0.318942\n",
      "2023-12-06 22:47:43,560 INFO     Training average loss at step 1200: 0.354791\n",
      "2023-12-06 22:48:24,945 INFO     Training average positive_sample_loss at step 1300: 0.381894\n",
      "2023-12-06 22:48:24,945 INFO     Training average negative_sample_loss at step 1300: 0.308767\n",
      "2023-12-06 22:48:24,945 INFO     Training average loss at step 1300: 0.345330\n",
      "2023-12-06 22:49:03,393 INFO     Training average positive_sample_loss at step 1400: 0.350909\n",
      "2023-12-06 22:49:03,393 INFO     Training average negative_sample_loss at step 1400: 0.288217\n",
      "2023-12-06 22:49:03,393 INFO     Training average loss at step 1400: 0.319563\n",
      "2023-12-06 22:49:41,625 INFO     Training average positive_sample_loss at step 1500: 0.353759\n",
      "2023-12-06 22:49:41,625 INFO     Training average negative_sample_loss at step 1500: 0.276254\n",
      "2023-12-06 22:49:41,625 INFO     Training average loss at step 1500: 0.315006\n",
      "2023-12-06 22:50:26,875 INFO     Training average positive_sample_loss at step 1600: 0.331031\n",
      "2023-12-06 22:50:26,875 INFO     Training average negative_sample_loss at step 1600: 0.265958\n",
      "2023-12-06 22:50:26,875 INFO     Training average loss at step 1600: 0.298495\n",
      "2023-12-06 22:51:06,119 INFO     Training average positive_sample_loss at step 1700: 0.323865\n",
      "2023-12-06 22:51:06,119 INFO     Training average negative_sample_loss at step 1700: 0.250877\n",
      "2023-12-06 22:51:06,119 INFO     Training average loss at step 1700: 0.287371\n",
      "2023-12-06 22:51:44,965 INFO     Training average positive_sample_loss at step 1800: 0.321210\n",
      "2023-12-06 22:51:44,966 INFO     Training average negative_sample_loss at step 1800: 0.243906\n",
      "2023-12-06 22:51:44,966 INFO     Training average loss at step 1800: 0.282558\n",
      "2023-12-06 22:52:27,671 INFO     Training average positive_sample_loss at step 1900: 0.294941\n",
      "2023-12-06 22:52:27,671 INFO     Training average negative_sample_loss at step 1900: 0.232684\n",
      "2023-12-06 22:52:27,671 INFO     Training average loss at step 1900: 0.263813\n",
      "2023-12-06 22:53:06,525 INFO     Training average positive_sample_loss at step 2000: 0.297958\n",
      "2023-12-06 22:53:06,525 INFO     Training average negative_sample_loss at step 2000: 0.222936\n",
      "2023-12-06 22:53:06,525 INFO     Training average loss at step 2000: 0.260447\n",
      "2023-12-06 22:53:48,796 INFO     Training average positive_sample_loss at step 2100: 0.285513\n",
      "2023-12-06 22:53:48,797 INFO     Training average negative_sample_loss at step 2100: 0.218132\n",
      "2023-12-06 22:53:48,797 INFO     Training average loss at step 2100: 0.251823\n",
      "2023-12-06 22:54:27,366 INFO     Training average positive_sample_loss at step 2200: 0.274680\n",
      "2023-12-06 22:54:27,367 INFO     Training average negative_sample_loss at step 2200: 0.206717\n",
      "2023-12-06 22:54:27,367 INFO     Training average loss at step 2200: 0.240698\n",
      "2023-12-06 22:55:05,591 INFO     Training average positive_sample_loss at step 2300: 0.277323\n",
      "2023-12-06 22:55:05,591 INFO     Training average negative_sample_loss at step 2300: 0.203309\n",
      "2023-12-06 22:55:05,591 INFO     Training average loss at step 2300: 0.240316\n",
      "2023-12-06 22:55:47,071 INFO     Training average positive_sample_loss at step 2400: 0.256486\n",
      "2023-12-06 22:55:47,072 INFO     Training average negative_sample_loss at step 2400: 0.196184\n",
      "2023-12-06 22:55:47,072 INFO     Training average loss at step 2400: 0.226335\n",
      "2023-12-06 22:56:25,760 INFO     Training average positive_sample_loss at step 2500: 0.258885\n",
      "2023-12-06 22:56:25,761 INFO     Training average negative_sample_loss at step 2500: 0.188117\n",
      "2023-12-06 22:56:25,761 INFO     Training average loss at step 2500: 0.223501\n",
      "2023-12-06 22:57:07,598 INFO     Training average positive_sample_loss at step 2600: 0.252142\n",
      "2023-12-06 22:57:07,599 INFO     Training average negative_sample_loss at step 2600: 0.186061\n",
      "2023-12-06 22:57:07,599 INFO     Training average loss at step 2600: 0.219101\n",
      "2023-12-06 22:57:46,146 INFO     Training average positive_sample_loss at step 2700: 0.239639\n",
      "2023-12-06 22:57:46,146 INFO     Training average negative_sample_loss at step 2700: 0.177827\n",
      "2023-12-06 22:57:46,146 INFO     Training average loss at step 2700: 0.208733\n",
      "2023-12-06 22:58:24,114 INFO     Training average positive_sample_loss at step 2800: 0.243646\n",
      "2023-12-06 22:58:24,115 INFO     Training average negative_sample_loss at step 2800: 0.174599\n",
      "2023-12-06 22:58:24,115 INFO     Training average loss at step 2800: 0.209122\n",
      "2023-12-06 22:59:08,905 INFO     Training average positive_sample_loss at step 2900: 0.229092\n",
      "2023-12-06 22:59:08,905 INFO     Training average negative_sample_loss at step 2900: 0.171274\n",
      "2023-12-06 22:59:08,905 INFO     Training average loss at step 2900: 0.200183\n",
      "2023-12-06 22:59:47,392 INFO     Training average positive_sample_loss at step 3000: 0.229674\n",
      "2023-12-06 22:59:47,393 INFO     Training average negative_sample_loss at step 3000: 0.164607\n",
      "2023-12-06 22:59:47,393 INFO     Training average loss at step 3000: 0.197140\n",
      "2023-12-06 23:00:29,168 INFO     Training average positive_sample_loss at step 3100: 0.229089\n",
      "2023-12-06 23:00:29,168 INFO     Training average negative_sample_loss at step 3100: 0.164051\n",
      "2023-12-06 23:00:29,168 INFO     Training average loss at step 3100: 0.196570\n",
      "2023-12-06 23:01:07,918 INFO     Training average positive_sample_loss at step 3200: 0.212994\n",
      "2023-12-06 23:01:07,918 INFO     Training average negative_sample_loss at step 3200: 0.158274\n",
      "2023-12-06 23:01:07,918 INFO     Training average loss at step 3200: 0.185634\n",
      "2023-12-06 23:01:46,479 INFO     Training average positive_sample_loss at step 3300: 0.219297\n",
      "2023-12-06 23:01:46,479 INFO     Training average negative_sample_loss at step 3300: 0.155416\n",
      "2023-12-06 23:01:46,479 INFO     Training average loss at step 3300: 0.187356\n",
      "2023-12-06 23:02:28,668 INFO     Training average positive_sample_loss at step 3400: 0.209636\n",
      "2023-12-06 23:02:28,668 INFO     Training average negative_sample_loss at step 3400: 0.154187\n",
      "2023-12-06 23:02:28,668 INFO     Training average loss at step 3400: 0.181911\n",
      "2023-12-06 23:03:07,540 INFO     Training average positive_sample_loss at step 3500: 0.207003\n",
      "2023-12-06 23:03:07,540 INFO     Training average negative_sample_loss at step 3500: 0.148422\n",
      "2023-12-06 23:03:07,540 INFO     Training average loss at step 3500: 0.177712\n",
      "2023-12-06 23:03:46,435 INFO     Training average positive_sample_loss at step 3600: 0.209947\n",
      "2023-12-06 23:03:46,435 INFO     Training average negative_sample_loss at step 3600: 0.148398\n",
      "2023-12-06 23:03:46,435 INFO     Training average loss at step 3600: 0.179173\n",
      "2023-12-06 23:04:28,086 INFO     Training average positive_sample_loss at step 3700: 0.195340\n",
      "2023-12-06 23:04:28,086 INFO     Training average negative_sample_loss at step 3700: 0.145275\n",
      "2023-12-06 23:04:28,086 INFO     Training average loss at step 3700: 0.170307\n",
      "2023-12-06 23:05:06,459 INFO     Training average positive_sample_loss at step 3800: 0.201351\n",
      "2023-12-06 23:05:06,460 INFO     Training average negative_sample_loss at step 3800: 0.141837\n",
      "2023-12-06 23:05:06,460 INFO     Training average loss at step 3800: 0.171594\n",
      "2023-12-06 23:05:48,322 INFO     Training average positive_sample_loss at step 3900: 0.195636\n",
      "2023-12-06 23:05:48,322 INFO     Training average negative_sample_loss at step 3900: 0.142293\n",
      "2023-12-06 23:05:48,322 INFO     Training average loss at step 3900: 0.168964\n",
      "2023-12-06 23:06:26,771 INFO     Training average positive_sample_loss at step 4000: 0.191003\n",
      "2023-12-06 23:06:26,771 INFO     Training average negative_sample_loss at step 4000: 0.137423\n",
      "2023-12-06 23:06:26,771 INFO     Training average loss at step 4000: 0.164213\n",
      "2023-12-06 23:07:05,796 INFO     Training average positive_sample_loss at step 4100: 0.194159\n",
      "2023-12-06 23:07:05,796 INFO     Training average negative_sample_loss at step 4100: 0.137324\n",
      "2023-12-06 23:07:05,796 INFO     Training average loss at step 4100: 0.165741\n",
      "2023-12-06 23:07:55,889 INFO     Training average positive_sample_loss at step 4200: 0.183482\n",
      "2023-12-06 23:07:55,889 INFO     Training average negative_sample_loss at step 4200: 0.135031\n",
      "2023-12-06 23:07:55,889 INFO     Training average loss at step 4200: 0.159257\n",
      "2023-12-06 23:08:35,715 INFO     Training average positive_sample_loss at step 4300: 0.186658\n",
      "2023-12-06 23:08:35,716 INFO     Training average negative_sample_loss at step 4300: 0.131683\n",
      "2023-12-06 23:08:35,716 INFO     Training average loss at step 4300: 0.159171\n",
      "2023-12-06 23:09:17,811 INFO     Training average positive_sample_loss at step 4400: 0.185405\n",
      "2023-12-06 23:09:17,812 INFO     Training average negative_sample_loss at step 4400: 0.132522\n",
      "2023-12-06 23:09:17,812 INFO     Training average loss at step 4400: 0.158963\n",
      "2023-12-06 23:09:56,761 INFO     Training average positive_sample_loss at step 4500: 0.176899\n",
      "2023-12-06 23:09:56,761 INFO     Training average negative_sample_loss at step 4500: 0.128555\n",
      "2023-12-06 23:09:56,762 INFO     Training average loss at step 4500: 0.152727\n",
      "2023-12-06 23:10:35,436 INFO     Training average positive_sample_loss at step 4600: 0.182947\n",
      "2023-12-06 23:10:35,436 INFO     Training average negative_sample_loss at step 4600: 0.129017\n",
      "2023-12-06 23:10:35,437 INFO     Training average loss at step 4600: 0.155982\n",
      "2023-12-06 23:11:17,190 INFO     Training average positive_sample_loss at step 4700: 0.173899\n",
      "2023-12-06 23:11:17,191 INFO     Training average negative_sample_loss at step 4700: 0.127796\n",
      "2023-12-06 23:11:17,191 INFO     Training average loss at step 4700: 0.150847\n",
      "2023-12-06 23:11:55,427 INFO     Training average positive_sample_loss at step 4800: 0.176115\n",
      "2023-12-06 23:11:55,427 INFO     Training average negative_sample_loss at step 4800: 0.124735\n",
      "2023-12-06 23:11:55,427 INFO     Training average loss at step 4800: 0.150425\n",
      "2023-12-06 23:12:33,678 INFO     Training average positive_sample_loss at step 4900: 0.178203\n",
      "2023-12-06 23:12:33,679 INFO     Training average negative_sample_loss at step 4900: 0.126049\n",
      "2023-12-06 23:12:33,679 INFO     Training average loss at step 4900: 0.152126\n",
      "2023-12-06 23:13:15,443 INFO     Training average positive_sample_loss at step 5000: 0.165737\n",
      "2023-12-06 23:13:15,443 INFO     Training average negative_sample_loss at step 5000: 0.122480\n",
      "2023-12-06 23:13:15,443 INFO     Training average loss at step 5000: 0.144109\n",
      "2023-12-06 23:13:53,756 INFO     Training average positive_sample_loss at step 5100: 0.173801\n",
      "2023-12-06 23:13:53,757 INFO     Training average negative_sample_loss at step 5100: 0.122436\n",
      "2023-12-06 23:13:53,757 INFO     Training average loss at step 5100: 0.148119\n",
      "2023-12-06 23:14:35,219 INFO     Training average positive_sample_loss at step 5200: 0.167782\n",
      "2023-12-06 23:14:35,220 INFO     Training average negative_sample_loss at step 5200: 0.122704\n",
      "2023-12-06 23:14:35,220 INFO     Training average loss at step 5200: 0.145243\n",
      "2023-12-06 23:15:13,835 INFO     Training average positive_sample_loss at step 5300: 0.167292\n",
      "2023-12-06 23:15:13,835 INFO     Training average negative_sample_loss at step 5300: 0.119391\n",
      "2023-12-06 23:15:13,835 INFO     Training average loss at step 5300: 0.143342\n",
      "2023-12-06 23:15:52,575 INFO     Training average positive_sample_loss at step 5400: 0.170565\n",
      "2023-12-06 23:15:52,575 INFO     Training average negative_sample_loss at step 5400: 0.120236\n",
      "2023-12-06 23:15:52,575 INFO     Training average loss at step 5400: 0.145400\n",
      "2023-12-06 23:16:37,385 INFO     Training average positive_sample_loss at step 5500: 0.160126\n",
      "2023-12-06 23:16:37,386 INFO     Training average negative_sample_loss at step 5500: 0.117991\n",
      "2023-12-06 23:16:37,386 INFO     Training average loss at step 5500: 0.139059\n",
      "2023-12-06 23:17:15,810 INFO     Training average positive_sample_loss at step 5600: 0.165855\n",
      "2023-12-06 23:17:15,810 INFO     Training average negative_sample_loss at step 5600: 0.117271\n",
      "2023-12-06 23:17:15,810 INFO     Training average loss at step 5600: 0.141563\n",
      "2023-12-06 23:17:58,741 INFO     Training average positive_sample_loss at step 5700: 0.163357\n",
      "2023-12-06 23:17:58,741 INFO     Training average negative_sample_loss at step 5700: 0.118371\n",
      "2023-12-06 23:17:58,741 INFO     Training average loss at step 5700: 0.140864\n",
      "2023-12-06 23:18:37,067 INFO     Training average positive_sample_loss at step 5800: 0.159026\n",
      "2023-12-06 23:18:37,067 INFO     Training average negative_sample_loss at step 5800: 0.114890\n",
      "2023-12-06 23:18:37,067 INFO     Training average loss at step 5800: 0.136958\n",
      "2023-12-06 23:19:15,399 INFO     Training average positive_sample_loss at step 5900: 0.164179\n",
      "2023-12-06 23:19:15,400 INFO     Training average negative_sample_loss at step 5900: 0.115606\n",
      "2023-12-06 23:19:15,400 INFO     Training average loss at step 5900: 0.139892\n",
      "2023-12-06 23:19:57,780 INFO     Training average positive_sample_loss at step 6000: 0.156276\n",
      "2023-12-06 23:19:57,781 INFO     Training average negative_sample_loss at step 6000: 0.114937\n",
      "2023-12-06 23:19:57,781 INFO     Training average loss at step 6000: 0.135606\n",
      "2023-12-06 23:20:36,416 INFO     Training average positive_sample_loss at step 6100: 0.160067\n",
      "2023-12-06 23:20:36,417 INFO     Training average negative_sample_loss at step 6100: 0.113838\n",
      "2023-12-06 23:20:36,417 INFO     Training average loss at step 6100: 0.136952\n",
      "2023-12-06 23:21:18,259 INFO     Training average positive_sample_loss at step 6200: 0.160039\n",
      "2023-12-06 23:21:18,260 INFO     Training average negative_sample_loss at step 6200: 0.114533\n",
      "2023-12-06 23:21:18,260 INFO     Training average loss at step 6200: 0.137286\n",
      "2023-12-06 23:21:56,691 INFO     Training average positive_sample_loss at step 6300: 0.152598\n",
      "2023-12-06 23:21:56,691 INFO     Training average negative_sample_loss at step 6300: 0.111631\n",
      "2023-12-06 23:21:56,691 INFO     Training average loss at step 6300: 0.132115\n",
      "2023-12-06 23:22:35,563 INFO     Training average positive_sample_loss at step 6400: 0.159138\n",
      "2023-12-06 23:22:35,563 INFO     Training average negative_sample_loss at step 6400: 0.111982\n",
      "2023-12-06 23:22:35,563 INFO     Training average loss at step 6400: 0.135560\n",
      "2023-12-06 23:23:17,523 INFO     Training average positive_sample_loss at step 6500: 0.152757\n",
      "2023-12-06 23:23:17,523 INFO     Training average negative_sample_loss at step 6500: 0.112723\n",
      "2023-12-06 23:23:17,523 INFO     Training average loss at step 6500: 0.132740\n",
      "2023-12-06 23:23:56,611 INFO     Training average positive_sample_loss at step 6600: 0.154379\n",
      "2023-12-06 23:23:56,611 INFO     Training average negative_sample_loss at step 6600: 0.109628\n",
      "2023-12-06 23:23:56,612 INFO     Training average loss at step 6600: 0.132003\n",
      "2023-12-06 23:24:35,395 INFO     Training average positive_sample_loss at step 6700: 0.157476\n",
      "2023-12-06 23:24:35,395 INFO     Training average negative_sample_loss at step 6700: 0.111674\n",
      "2023-12-06 23:24:35,396 INFO     Training average loss at step 6700: 0.134575\n",
      "2023-12-06 23:25:20,236 INFO     Training average positive_sample_loss at step 6800: 0.147914\n",
      "2023-12-06 23:25:20,236 INFO     Training average negative_sample_loss at step 6800: 0.109788\n",
      "2023-12-06 23:25:20,236 INFO     Training average loss at step 6800: 0.128851\n",
      "2023-12-06 23:25:58,342 INFO     Training average positive_sample_loss at step 6900: 0.154986\n",
      "2023-12-06 23:25:58,343 INFO     Training average negative_sample_loss at step 6900: 0.109315\n",
      "2023-12-06 23:25:58,343 INFO     Training average loss at step 6900: 0.132150\n",
      "2023-12-06 23:26:41,245 INFO     Training average positive_sample_loss at step 7000: 0.150716\n",
      "2023-12-06 23:26:41,245 INFO     Training average negative_sample_loss at step 7000: 0.110225\n",
      "2023-12-06 23:26:41,245 INFO     Training average loss at step 7000: 0.130470\n",
      "2023-12-06 23:27:19,660 INFO     Training average positive_sample_loss at step 7100: 0.149690\n",
      "2023-12-06 23:27:19,660 INFO     Training average negative_sample_loss at step 7100: 0.107916\n",
      "2023-12-06 23:27:19,660 INFO     Training average loss at step 7100: 0.128803\n",
      "2023-12-06 23:27:58,130 INFO     Training average positive_sample_loss at step 7200: 0.154239\n",
      "2023-12-06 23:27:58,130 INFO     Training average negative_sample_loss at step 7200: 0.108961\n",
      "2023-12-06 23:27:58,130 INFO     Training average loss at step 7200: 0.131600\n",
      "2023-12-06 23:28:40,266 INFO     Training average positive_sample_loss at step 7300: 0.145715\n",
      "2023-12-06 23:28:40,266 INFO     Training average negative_sample_loss at step 7300: 0.108121\n",
      "2023-12-06 23:28:40,266 INFO     Training average loss at step 7300: 0.126918\n",
      "2023-12-06 23:29:19,413 INFO     Training average positive_sample_loss at step 7400: 0.151694\n",
      "2023-12-06 23:29:19,413 INFO     Training average negative_sample_loss at step 7400: 0.107574\n",
      "2023-12-06 23:29:19,413 INFO     Training average loss at step 7400: 0.129634\n",
      "2023-12-06 23:30:01,323 INFO     Training average positive_sample_loss at step 7500: 0.149020\n",
      "2023-12-06 23:30:01,323 INFO     Training average negative_sample_loss at step 7500: 0.107693\n",
      "2023-12-06 23:30:01,323 INFO     Training average loss at step 7500: 0.128356\n",
      "2023-12-06 23:30:40,048 INFO     Training average positive_sample_loss at step 7600: 0.145751\n",
      "2023-12-06 23:30:40,048 INFO     Training average negative_sample_loss at step 7600: 0.106100\n",
      "2023-12-06 23:30:40,048 INFO     Training average loss at step 7600: 0.125925\n",
      "2023-12-06 23:31:18,338 INFO     Training average positive_sample_loss at step 7700: 0.151208\n",
      "2023-12-06 23:31:18,339 INFO     Training average negative_sample_loss at step 7700: 0.106929\n",
      "2023-12-06 23:31:18,339 INFO     Training average loss at step 7700: 0.129069\n",
      "2023-12-06 23:31:59,980 INFO     Training average positive_sample_loss at step 7800: 0.144092\n",
      "2023-12-06 23:31:59,981 INFO     Training average negative_sample_loss at step 7800: 0.107153\n",
      "2023-12-06 23:31:59,981 INFO     Training average loss at step 7800: 0.125623\n",
      "2023-12-06 23:32:38,453 INFO     Training average positive_sample_loss at step 7900: 0.147797\n",
      "2023-12-06 23:32:38,453 INFO     Training average negative_sample_loss at step 7900: 0.105155\n",
      "2023-12-06 23:32:38,453 INFO     Training average loss at step 7900: 0.126476\n",
      "2023-12-06 23:33:23,310 INFO     Training average positive_sample_loss at step 8000: 0.149805\n",
      "2023-12-06 23:33:23,311 INFO     Training average negative_sample_loss at step 8000: 0.106825\n",
      "2023-12-06 23:33:23,311 INFO     Training average loss at step 8000: 0.128315\n",
      "2023-12-06 23:34:01,382 INFO     Training average positive_sample_loss at step 8100: 0.141620\n",
      "2023-12-06 23:34:01,383 INFO     Training average negative_sample_loss at step 8100: 0.104577\n",
      "2023-12-06 23:34:01,383 INFO     Training average loss at step 8100: 0.123098\n",
      "2023-12-06 23:34:39,945 INFO     Training average positive_sample_loss at step 8200: 0.147670\n",
      "2023-12-06 23:34:39,945 INFO     Training average negative_sample_loss at step 8200: 0.104016\n",
      "2023-12-06 23:34:39,945 INFO     Training average loss at step 8200: 0.125843\n",
      "2023-12-06 23:35:21,633 INFO     Training average positive_sample_loss at step 8300: 0.143333\n",
      "2023-12-06 23:35:21,633 INFO     Training average negative_sample_loss at step 8300: 0.105574\n",
      "2023-12-06 23:35:21,633 INFO     Training average loss at step 8300: 0.124454\n",
      "2023-12-06 23:36:00,072 INFO     Training average positive_sample_loss at step 8400: 0.144316\n",
      "2023-12-06 23:36:00,073 INFO     Training average negative_sample_loss at step 8400: 0.103180\n",
      "2023-12-06 23:36:00,073 INFO     Training average loss at step 8400: 0.123748\n",
      "2023-12-06 23:36:39,211 INFO     Training average positive_sample_loss at step 8500: 0.148025\n",
      "2023-12-06 23:36:39,211 INFO     Training average negative_sample_loss at step 8500: 0.105320\n",
      "2023-12-06 23:36:39,211 INFO     Training average loss at step 8500: 0.126672\n",
      "2023-12-06 23:37:21,762 INFO     Training average positive_sample_loss at step 8600: 0.139987\n",
      "2023-12-06 23:37:21,763 INFO     Training average negative_sample_loss at step 8600: 0.103722\n",
      "2023-12-06 23:37:21,763 INFO     Training average loss at step 8600: 0.121855\n",
      "2023-12-06 23:38:01,067 INFO     Training average positive_sample_loss at step 8700: 0.145263\n",
      "2023-12-06 23:38:01,068 INFO     Training average negative_sample_loss at step 8700: 0.103150\n",
      "2023-12-06 23:38:01,068 INFO     Training average loss at step 8700: 0.124207\n",
      "2023-12-06 23:38:43,009 INFO     Training average positive_sample_loss at step 8800: 0.142643\n",
      "2023-12-06 23:38:43,009 INFO     Training average negative_sample_loss at step 8800: 0.104439\n",
      "2023-12-06 23:38:43,009 INFO     Training average loss at step 8800: 0.123541\n",
      "2023-12-06 23:39:21,230 INFO     Training average positive_sample_loss at step 8900: 0.141930\n",
      "2023-12-06 23:39:21,231 INFO     Training average negative_sample_loss at step 8900: 0.101447\n",
      "2023-12-06 23:39:21,231 INFO     Training average loss at step 8900: 0.121688\n",
      "2023-12-06 23:40:00,164 INFO     Training average positive_sample_loss at step 9000: 0.145710\n",
      "2023-12-06 23:40:00,165 INFO     Training average negative_sample_loss at step 9000: 0.103361\n",
      "2023-12-06 23:40:00,165 INFO     Training average loss at step 9000: 0.124536\n",
      "2023-12-06 23:40:42,009 INFO     Training average positive_sample_loss at step 9100: 0.138566\n",
      "2023-12-06 23:40:42,010 INFO     Training average negative_sample_loss at step 9100: 0.102732\n",
      "2023-12-06 23:40:42,010 INFO     Training average loss at step 9100: 0.120649\n",
      "2023-12-06 23:41:20,776 INFO     Training average positive_sample_loss at step 9200: 0.143223\n",
      "2023-12-06 23:41:20,776 INFO     Training average negative_sample_loss at step 9200: 0.102032\n",
      "2023-12-06 23:41:20,776 INFO     Training average loss at step 9200: 0.122627\n",
      "2023-12-06 23:42:06,372 INFO     Training average positive_sample_loss at step 9300: 0.143949\n",
      "2023-12-06 23:42:06,373 INFO     Training average negative_sample_loss at step 9300: 0.103390\n",
      "2023-12-06 23:42:06,373 INFO     Training average loss at step 9300: 0.123669\n",
      "2023-12-06 23:42:44,662 INFO     Training average positive_sample_loss at step 9400: 0.138643\n",
      "2023-12-06 23:42:44,662 INFO     Training average negative_sample_loss at step 9400: 0.101707\n",
      "2023-12-06 23:42:44,662 INFO     Training average loss at step 9400: 0.120175\n",
      "2023-12-06 23:43:23,047 INFO     Training average positive_sample_loss at step 9500: 0.143058\n",
      "2023-12-06 23:43:23,047 INFO     Training average negative_sample_loss at step 9500: 0.101672\n",
      "2023-12-06 23:43:23,047 INFO     Training average loss at step 9500: 0.122365\n",
      "2023-12-06 23:44:05,002 INFO     Training average positive_sample_loss at step 9600: 0.138932\n",
      "2023-12-06 23:44:05,002 INFO     Training average negative_sample_loss at step 9600: 0.102531\n",
      "2023-12-06 23:44:05,002 INFO     Training average loss at step 9600: 0.120732\n",
      "2023-12-06 23:44:44,115 INFO     Training average positive_sample_loss at step 9700: 0.141076\n",
      "2023-12-06 23:44:44,115 INFO     Training average negative_sample_loss at step 9700: 0.100495\n",
      "2023-12-06 23:44:44,115 INFO     Training average loss at step 9700: 0.120785\n",
      "2023-12-06 23:45:22,703 INFO     Training average positive_sample_loss at step 9800: 0.143815\n",
      "2023-12-06 23:45:22,703 INFO     Training average negative_sample_loss at step 9800: 0.102115\n",
      "2023-12-06 23:45:22,703 INFO     Training average loss at step 9800: 0.122965\n",
      "2023-12-06 23:46:04,480 INFO     Training average positive_sample_loss at step 9900: 0.135853\n",
      "2023-12-06 23:46:04,481 INFO     Training average negative_sample_loss at step 9900: 0.100889\n",
      "2023-12-06 23:46:04,481 INFO     Training average loss at step 9900: 0.118371\n",
      "2023-12-06 23:46:54,749 INFO     Training average positive_sample_loss at step 10000: 0.141892\n",
      "2023-12-06 23:46:54,750 INFO     Training average negative_sample_loss at step 10000: 0.100450\n",
      "2023-12-06 23:46:54,750 INFO     Training average loss at step 10000: 0.121171\n",
      "2023-12-06 23:46:54,750 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-06 23:46:55,223 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-06 23:47:22,412 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-06 23:47:38,173 INFO     Valid MRR at step 10000: 0.561072\n",
      "2023-12-06 23:47:38,173 INFO     Valid MR at step 10000: 295.730132\n",
      "2023-12-06 23:47:38,173 INFO     Valid HITS@1 at step 10000: 0.479671\n",
      "2023-12-06 23:47:38,173 INFO     Valid HITS@3 at step 10000: 0.603998\n",
      "2023-12-06 23:47:38,173 INFO     Valid HITS@10 at step 10000: 0.716284\n",
      "2023-12-06 23:48:15,966 INFO     Training average positive_sample_loss at step 10100: 0.138475\n",
      "2023-12-06 23:48:15,967 INFO     Training average negative_sample_loss at step 10100: 0.101326\n",
      "2023-12-06 23:48:15,967 INFO     Training average loss at step 10100: 0.119900\n",
      "2023-12-06 23:48:55,502 INFO     Training average positive_sample_loss at step 10200: 0.138931\n",
      "2023-12-06 23:48:55,502 INFO     Training average negative_sample_loss at step 10200: 0.099647\n",
      "2023-12-06 23:48:55,502 INFO     Training average loss at step 10200: 0.119289\n",
      "2023-12-06 23:49:34,197 INFO     Training average positive_sample_loss at step 10300: 0.142266\n",
      "2023-12-06 23:49:34,198 INFO     Training average negative_sample_loss at step 10300: 0.101717\n",
      "2023-12-06 23:49:34,198 INFO     Training average loss at step 10300: 0.121991\n",
      "2023-12-06 23:50:16,270 INFO     Training average positive_sample_loss at step 10400: 0.135427\n",
      "2023-12-06 23:50:16,271 INFO     Training average negative_sample_loss at step 10400: 0.100503\n",
      "2023-12-06 23:50:16,271 INFO     Training average loss at step 10400: 0.117965\n",
      "2023-12-06 23:50:55,726 INFO     Training average positive_sample_loss at step 10500: 0.139959\n",
      "2023-12-06 23:50:55,726 INFO     Training average negative_sample_loss at step 10500: 0.099336\n",
      "2023-12-06 23:50:55,726 INFO     Training average loss at step 10500: 0.119647\n",
      "2023-12-06 23:51:40,774 INFO     Training average positive_sample_loss at step 10600: 0.139681\n",
      "2023-12-06 23:51:40,774 INFO     Training average negative_sample_loss at step 10600: 0.102000\n",
      "2023-12-06 23:51:40,774 INFO     Training average loss at step 10600: 0.120840\n",
      "2023-12-06 23:52:19,137 INFO     Training average positive_sample_loss at step 10700: 0.135947\n",
      "2023-12-06 23:52:19,137 INFO     Training average negative_sample_loss at step 10700: 0.098442\n",
      "2023-12-06 23:52:19,137 INFO     Training average loss at step 10700: 0.117194\n",
      "2023-12-06 23:52:57,149 INFO     Training average positive_sample_loss at step 10800: 0.141102\n",
      "2023-12-06 23:52:57,149 INFO     Training average negative_sample_loss at step 10800: 0.099863\n",
      "2023-12-06 23:52:57,149 INFO     Training average loss at step 10800: 0.120482\n",
      "2023-12-06 23:53:40,484 INFO     Training average positive_sample_loss at step 10900: 0.135545\n",
      "2023-12-06 23:53:40,484 INFO     Training average negative_sample_loss at step 10900: 0.100393\n",
      "2023-12-06 23:53:40,484 INFO     Training average loss at step 10900: 0.117969\n",
      "2023-12-06 23:54:19,726 INFO     Training average positive_sample_loss at step 11000: 0.138868\n",
      "2023-12-06 23:54:19,727 INFO     Training average negative_sample_loss at step 11000: 0.098862\n",
      "2023-12-06 23:54:19,727 INFO     Training average loss at step 11000: 0.118865\n",
      "2023-12-06 23:55:01,859 INFO     Training average positive_sample_loss at step 11100: 0.140096\n",
      "2023-12-06 23:55:01,860 INFO     Training average negative_sample_loss at step 11100: 0.100154\n",
      "2023-12-06 23:55:01,860 INFO     Training average loss at step 11100: 0.120125\n",
      "2023-12-06 23:55:40,268 INFO     Training average positive_sample_loss at step 11200: 0.134377\n",
      "2023-12-06 23:55:40,268 INFO     Training average negative_sample_loss at step 11200: 0.098518\n",
      "2023-12-06 23:55:40,268 INFO     Training average loss at step 11200: 0.116448\n",
      "2023-12-06 23:56:18,633 INFO     Training average positive_sample_loss at step 11300: 0.139188\n",
      "2023-12-06 23:56:18,633 INFO     Training average negative_sample_loss at step 11300: 0.098684\n",
      "2023-12-06 23:56:18,633 INFO     Training average loss at step 11300: 0.118936\n",
      "2023-12-06 23:57:00,081 INFO     Training average positive_sample_loss at step 11400: 0.134531\n",
      "2023-12-06 23:57:00,081 INFO     Training average negative_sample_loss at step 11400: 0.099001\n",
      "2023-12-06 23:57:00,081 INFO     Training average loss at step 11400: 0.116766\n",
      "2023-12-06 23:57:38,651 INFO     Training average positive_sample_loss at step 11500: 0.137310\n",
      "2023-12-06 23:57:38,652 INFO     Training average negative_sample_loss at step 11500: 0.098122\n",
      "2023-12-06 23:57:38,652 INFO     Training average loss at step 11500: 0.117716\n",
      "2023-12-06 23:58:17,980 INFO     Training average positive_sample_loss at step 11600: 0.139931\n",
      "2023-12-06 23:58:17,980 INFO     Training average negative_sample_loss at step 11600: 0.099525\n",
      "2023-12-06 23:58:17,980 INFO     Training average loss at step 11600: 0.119728\n",
      "2023-12-06 23:58:59,601 INFO     Training average positive_sample_loss at step 11700: 0.132431\n",
      "2023-12-06 23:58:59,602 INFO     Training average negative_sample_loss at step 11700: 0.098019\n",
      "2023-12-06 23:58:59,602 INFO     Training average loss at step 11700: 0.115225\n",
      "2023-12-06 23:59:37,642 INFO     Training average positive_sample_loss at step 11800: 0.138602\n",
      "2023-12-06 23:59:37,642 INFO     Training average negative_sample_loss at step 11800: 0.097910\n",
      "2023-12-06 23:59:37,642 INFO     Training average loss at step 11800: 0.118256\n",
      "2023-12-07 00:00:22,568 INFO     Training average positive_sample_loss at step 11900: 0.135689\n",
      "2023-12-07 00:00:22,568 INFO     Training average negative_sample_loss at step 11900: 0.100371\n",
      "2023-12-07 00:00:22,568 INFO     Training average loss at step 11900: 0.118030\n",
      "2023-12-07 00:01:01,319 INFO     Training average positive_sample_loss at step 12000: 0.135315\n",
      "2023-12-07 00:01:01,319 INFO     Training average negative_sample_loss at step 12000: 0.097281\n",
      "2023-12-07 00:01:01,319 INFO     Training average loss at step 12000: 0.116298\n",
      "2023-12-07 00:01:39,506 INFO     Training average positive_sample_loss at step 12100: 0.139012\n",
      "2023-12-07 00:01:39,507 INFO     Training average negative_sample_loss at step 12100: 0.098708\n",
      "2023-12-07 00:01:39,507 INFO     Training average loss at step 12100: 0.118860\n",
      "2023-12-07 00:02:21,136 INFO     Training average positive_sample_loss at step 12200: 0.132983\n",
      "2023-12-07 00:02:21,136 INFO     Training average negative_sample_loss at step 12200: 0.097885\n",
      "2023-12-07 00:02:21,136 INFO     Training average loss at step 12200: 0.115434\n",
      "2023-12-07 00:02:59,691 INFO     Training average positive_sample_loss at step 12300: 0.136794\n",
      "2023-12-07 00:02:59,691 INFO     Training average negative_sample_loss at step 12300: 0.097349\n",
      "2023-12-07 00:02:59,691 INFO     Training average loss at step 12300: 0.117071\n",
      "2023-12-07 00:03:41,416 INFO     Training average positive_sample_loss at step 12400: 0.136365\n",
      "2023-12-07 00:03:41,417 INFO     Training average negative_sample_loss at step 12400: 0.098527\n",
      "2023-12-07 00:03:41,417 INFO     Training average loss at step 12400: 0.117446\n",
      "2023-12-07 00:04:19,953 INFO     Training average positive_sample_loss at step 12500: 0.133065\n",
      "2023-12-07 00:04:19,953 INFO     Training average negative_sample_loss at step 12500: 0.096860\n",
      "2023-12-07 00:04:19,953 INFO     Training average loss at step 12500: 0.114962\n",
      "2023-12-07 00:04:58,121 INFO     Training average positive_sample_loss at step 12600: 0.137375\n",
      "2023-12-07 00:04:58,121 INFO     Training average negative_sample_loss at step 12600: 0.097896\n",
      "2023-12-07 00:04:58,121 INFO     Training average loss at step 12600: 0.117635\n",
      "2023-12-07 00:05:39,854 INFO     Training average positive_sample_loss at step 12700: 0.133177\n",
      "2023-12-07 00:05:39,855 INFO     Training average negative_sample_loss at step 12700: 0.097785\n",
      "2023-12-07 00:05:39,855 INFO     Training average loss at step 12700: 0.115481\n",
      "2023-12-07 00:06:18,315 INFO     Training average positive_sample_loss at step 12800: 0.135676\n",
      "2023-12-07 00:06:18,315 INFO     Training average negative_sample_loss at step 12800: 0.097392\n",
      "2023-12-07 00:06:18,315 INFO     Training average loss at step 12800: 0.116534\n",
      "2023-12-07 00:06:59,916 INFO     Training average positive_sample_loss at step 12900: 0.138140\n",
      "2023-12-07 00:06:59,916 INFO     Training average negative_sample_loss at step 12900: 0.098043\n",
      "2023-12-07 00:06:59,916 INFO     Training average loss at step 12900: 0.118092\n",
      "2023-12-07 00:07:39,244 INFO     Training average positive_sample_loss at step 13000: 0.130220\n",
      "2023-12-07 00:07:39,244 INFO     Training average negative_sample_loss at step 13000: 0.096346\n",
      "2023-12-07 00:07:39,245 INFO     Training average loss at step 13000: 0.113283\n",
      "2023-12-07 00:08:18,092 INFO     Training average positive_sample_loss at step 13100: 0.137485\n",
      "2023-12-07 00:08:18,092 INFO     Training average negative_sample_loss at step 13100: 0.097501\n",
      "2023-12-07 00:08:18,093 INFO     Training average loss at step 13100: 0.117493\n",
      "2023-12-07 00:09:02,736 INFO     Training average positive_sample_loss at step 13200: 0.133280\n",
      "2023-12-07 00:09:02,736 INFO     Training average negative_sample_loss at step 13200: 0.097925\n",
      "2023-12-07 00:09:02,736 INFO     Training average loss at step 13200: 0.115603\n",
      "2023-12-07 00:09:41,267 INFO     Training average positive_sample_loss at step 13300: 0.133933\n",
      "2023-12-07 00:09:41,267 INFO     Training average negative_sample_loss at step 13300: 0.095951\n",
      "2023-12-07 00:09:41,267 INFO     Training average loss at step 13300: 0.114942\n",
      "2023-12-07 00:10:20,194 INFO     Training average positive_sample_loss at step 13400: 0.137560\n",
      "2023-12-07 00:10:20,195 INFO     Training average negative_sample_loss at step 13400: 0.097718\n",
      "2023-12-07 00:10:20,195 INFO     Training average loss at step 13400: 0.117639\n",
      "2023-12-07 00:11:02,069 INFO     Training average positive_sample_loss at step 13500: 0.130385\n",
      "2023-12-07 00:11:02,069 INFO     Training average negative_sample_loss at step 13500: 0.096583\n",
      "2023-12-07 00:11:02,069 INFO     Training average loss at step 13500: 0.113484\n",
      "2023-12-07 00:11:40,629 INFO     Training average positive_sample_loss at step 13600: 0.135532\n",
      "2023-12-07 00:11:40,630 INFO     Training average negative_sample_loss at step 13600: 0.096010\n",
      "2023-12-07 00:11:40,630 INFO     Training average loss at step 13600: 0.115771\n",
      "2023-12-07 00:12:22,403 INFO     Training average positive_sample_loss at step 13700: 0.134531\n",
      "2023-12-07 00:12:22,403 INFO     Training average negative_sample_loss at step 13700: 0.097466\n",
      "2023-12-07 00:12:22,403 INFO     Training average loss at step 13700: 0.115999\n",
      "2023-12-07 00:13:00,793 INFO     Training average positive_sample_loss at step 13800: 0.132650\n",
      "2023-12-07 00:13:00,794 INFO     Training average negative_sample_loss at step 13800: 0.095889\n",
      "2023-12-07 00:13:00,794 INFO     Training average loss at step 13800: 0.114269\n",
      "2023-12-07 00:13:39,379 INFO     Training average positive_sample_loss at step 13900: 0.136780\n",
      "2023-12-07 00:13:39,379 INFO     Training average negative_sample_loss at step 13900: 0.096949\n",
      "2023-12-07 00:13:39,379 INFO     Training average loss at step 13900: 0.116865\n",
      "2023-12-07 00:14:20,958 INFO     Training average positive_sample_loss at step 14000: 0.130296\n",
      "2023-12-07 00:14:20,959 INFO     Training average negative_sample_loss at step 14000: 0.095485\n",
      "2023-12-07 00:14:20,959 INFO     Training average loss at step 14000: 0.112890\n",
      "2023-12-07 00:14:59,185 INFO     Training average positive_sample_loss at step 14100: 0.134475\n",
      "2023-12-07 00:14:59,185 INFO     Training average negative_sample_loss at step 14100: 0.095257\n",
      "2023-12-07 00:14:59,185 INFO     Training average loss at step 14100: 0.114866\n",
      "2023-12-07 00:15:40,967 INFO     Training average positive_sample_loss at step 14200: 0.135689\n",
      "2023-12-07 00:15:40,967 INFO     Training average negative_sample_loss at step 14200: 0.098339\n",
      "2023-12-07 00:15:40,967 INFO     Training average loss at step 14200: 0.117014\n",
      "2023-12-07 00:16:19,034 INFO     Training average positive_sample_loss at step 14300: 0.130486\n",
      "2023-12-07 00:16:19,034 INFO     Training average negative_sample_loss at step 14300: 0.094859\n",
      "2023-12-07 00:16:19,034 INFO     Training average loss at step 14300: 0.112673\n",
      "2023-12-07 00:16:57,613 INFO     Training average positive_sample_loss at step 14400: 0.135646\n",
      "2023-12-07 00:16:57,613 INFO     Training average negative_sample_loss at step 14400: 0.096187\n",
      "2023-12-07 00:16:57,613 INFO     Training average loss at step 14400: 0.115917\n",
      "2023-12-07 00:17:43,093 INFO     Training average positive_sample_loss at step 14500: 0.130934\n",
      "2023-12-07 00:17:43,094 INFO     Training average negative_sample_loss at step 14500: 0.096265\n",
      "2023-12-07 00:17:43,094 INFO     Training average loss at step 14500: 0.113600\n",
      "2023-12-07 00:18:22,119 INFO     Training average positive_sample_loss at step 14600: 0.133069\n",
      "2023-12-07 00:18:22,119 INFO     Training average negative_sample_loss at step 14600: 0.094990\n",
      "2023-12-07 00:18:22,119 INFO     Training average loss at step 14600: 0.114029\n",
      "2023-12-07 00:19:00,803 INFO     Training average positive_sample_loss at step 14700: 0.136587\n",
      "2023-12-07 00:19:00,803 INFO     Training average negative_sample_loss at step 14700: 0.097404\n",
      "2023-12-07 00:19:00,803 INFO     Training average loss at step 14700: 0.116995\n",
      "2023-12-07 00:19:42,984 INFO     Training average positive_sample_loss at step 14800: 0.128706\n",
      "2023-12-07 00:19:42,984 INFO     Training average negative_sample_loss at step 14800: 0.095123\n",
      "2023-12-07 00:19:42,984 INFO     Training average loss at step 14800: 0.111915\n",
      "2023-12-07 00:20:21,573 INFO     Training average positive_sample_loss at step 14900: 0.134904\n",
      "2023-12-07 00:20:21,574 INFO     Training average negative_sample_loss at step 14900: 0.094770\n",
      "2023-12-07 00:20:21,574 INFO     Training average loss at step 14900: 0.114837\n",
      "2023-12-07 00:21:03,196 INFO     Training average positive_sample_loss at step 15000: 0.132330\n",
      "2023-12-07 00:21:03,196 INFO     Training average negative_sample_loss at step 15000: 0.097444\n",
      "2023-12-07 00:21:03,196 INFO     Training average loss at step 15000: 0.114887\n",
      "2023-12-07 00:21:41,794 INFO     Training average positive_sample_loss at step 15100: 0.131966\n",
      "2023-12-07 00:21:41,795 INFO     Training average negative_sample_loss at step 15100: 0.094440\n",
      "2023-12-07 00:21:41,795 INFO     Training average loss at step 15100: 0.113203\n",
      "2023-12-07 00:22:20,104 INFO     Training average positive_sample_loss at step 15200: 0.135555\n",
      "2023-12-07 00:22:20,104 INFO     Training average negative_sample_loss at step 15200: 0.096524\n",
      "2023-12-07 00:22:20,104 INFO     Training average loss at step 15200: 0.116040\n",
      "2023-12-07 00:23:01,886 INFO     Training average positive_sample_loss at step 15300: 0.128988\n",
      "2023-12-07 00:23:01,886 INFO     Training average negative_sample_loss at step 15300: 0.094984\n",
      "2023-12-07 00:23:01,886 INFO     Training average loss at step 15300: 0.111986\n",
      "2023-12-07 00:23:40,640 INFO     Training average positive_sample_loss at step 15400: 0.133754\n",
      "2023-12-07 00:23:40,641 INFO     Training average negative_sample_loss at step 15400: 0.095084\n",
      "2023-12-07 00:23:40,641 INFO     Training average loss at step 15400: 0.114419\n",
      "2023-12-07 00:24:22,077 INFO     Training average positive_sample_loss at step 15500: 0.132649\n",
      "2023-12-07 00:24:22,077 INFO     Training average negative_sample_loss at step 15500: 0.095831\n",
      "2023-12-07 00:24:22,077 INFO     Training average loss at step 15500: 0.114240\n",
      "2023-12-07 00:25:00,380 INFO     Training average positive_sample_loss at step 15600: 0.129894\n",
      "2023-12-07 00:25:00,380 INFO     Training average negative_sample_loss at step 15600: 0.093656\n",
      "2023-12-07 00:25:00,380 INFO     Training average loss at step 15600: 0.111775\n",
      "2023-12-07 00:25:39,522 INFO     Training average positive_sample_loss at step 15700: 0.134898\n",
      "2023-12-07 00:25:39,522 INFO     Training average negative_sample_loss at step 15700: 0.095121\n",
      "2023-12-07 00:25:39,522 INFO     Training average loss at step 15700: 0.115009\n",
      "2023-12-07 00:26:24,092 INFO     Training average positive_sample_loss at step 15800: 0.129524\n",
      "2023-12-07 00:26:24,093 INFO     Training average negative_sample_loss at step 15800: 0.095267\n",
      "2023-12-07 00:26:24,093 INFO     Training average loss at step 15800: 0.112396\n",
      "2023-12-07 00:27:02,489 INFO     Training average positive_sample_loss at step 15900: 0.133034\n",
      "2023-12-07 00:27:02,490 INFO     Training average negative_sample_loss at step 15900: 0.094558\n",
      "2023-12-07 00:27:02,490 INFO     Training average loss at step 15900: 0.113796\n",
      "2023-12-07 00:27:43,892 INFO     Training average positive_sample_loss at step 16000: 0.134161\n",
      "2023-12-07 00:27:43,892 INFO     Training average negative_sample_loss at step 16000: 0.096617\n",
      "2023-12-07 00:27:43,892 INFO     Training average loss at step 16000: 0.115389\n",
      "2023-12-07 00:28:22,223 INFO     Training average positive_sample_loss at step 16100: 0.128813\n",
      "2023-12-07 00:28:22,223 INFO     Training average negative_sample_loss at step 16100: 0.094004\n",
      "2023-12-07 00:28:22,223 INFO     Training average loss at step 16100: 0.111408\n",
      "2023-12-07 00:29:00,793 INFO     Training average positive_sample_loss at step 16200: 0.134257\n",
      "2023-12-07 00:29:00,793 INFO     Training average negative_sample_loss at step 16200: 0.095143\n",
      "2023-12-07 00:29:00,793 INFO     Training average loss at step 16200: 0.114700\n",
      "2023-12-07 00:29:43,299 INFO     Training average positive_sample_loss at step 16300: 0.129755\n",
      "2023-12-07 00:29:43,299 INFO     Training average negative_sample_loss at step 16300: 0.095362\n",
      "2023-12-07 00:29:43,299 INFO     Training average loss at step 16300: 0.112558\n",
      "2023-12-07 00:30:21,837 INFO     Training average positive_sample_loss at step 16400: 0.131579\n",
      "2023-12-07 00:30:21,838 INFO     Training average negative_sample_loss at step 16400: 0.093402\n",
      "2023-12-07 00:30:21,838 INFO     Training average loss at step 16400: 0.112491\n",
      "2023-12-07 00:31:00,404 INFO     Training average positive_sample_loss at step 16500: 0.134476\n",
      "2023-12-07 00:31:00,404 INFO     Training average negative_sample_loss at step 16500: 0.096041\n",
      "2023-12-07 00:31:00,404 INFO     Training average loss at step 16500: 0.115259\n",
      "2023-12-07 00:31:41,870 INFO     Training average positive_sample_loss at step 16600: 0.127752\n",
      "2023-12-07 00:31:41,870 INFO     Training average negative_sample_loss at step 16600: 0.094330\n",
      "2023-12-07 00:31:41,870 INFO     Training average loss at step 16600: 0.111041\n",
      "2023-12-07 00:32:20,575 INFO     Training average positive_sample_loss at step 16700: 0.133343\n",
      "2023-12-07 00:32:20,575 INFO     Training average negative_sample_loss at step 16700: 0.093696\n",
      "2023-12-07 00:32:20,575 INFO     Training average loss at step 16700: 0.113519\n",
      "2023-12-07 00:33:01,825 INFO     Training average positive_sample_loss at step 16800: 0.131565\n",
      "2023-12-07 00:33:01,825 INFO     Training average negative_sample_loss at step 16800: 0.096468\n",
      "2023-12-07 00:33:01,826 INFO     Training average loss at step 16800: 0.114017\n",
      "2023-12-07 00:33:40,124 INFO     Training average positive_sample_loss at step 16900: 0.130263\n",
      "2023-12-07 00:33:40,124 INFO     Training average negative_sample_loss at step 16900: 0.093296\n",
      "2023-12-07 00:33:40,125 INFO     Training average loss at step 16900: 0.111780\n",
      "2023-12-07 00:34:18,424 INFO     Training average positive_sample_loss at step 17000: 0.133970\n",
      "2023-12-07 00:34:18,424 INFO     Training average negative_sample_loss at step 17000: 0.094812\n",
      "2023-12-07 00:34:18,424 INFO     Training average loss at step 17000: 0.114391\n",
      "2023-12-07 00:35:03,066 INFO     Training average positive_sample_loss at step 17100: 0.127690\n",
      "2023-12-07 00:35:03,066 INFO     Training average negative_sample_loss at step 17100: 0.093771\n",
      "2023-12-07 00:35:03,066 INFO     Training average loss at step 17100: 0.110731\n",
      "2023-12-07 00:35:41,622 INFO     Training average positive_sample_loss at step 17200: 0.132063\n",
      "2023-12-07 00:35:41,623 INFO     Training average negative_sample_loss at step 17200: 0.093075\n",
      "2023-12-07 00:35:41,623 INFO     Training average loss at step 17200: 0.112569\n",
      "2023-12-07 00:36:23,722 INFO     Training average positive_sample_loss at step 17300: 0.132845\n",
      "2023-12-07 00:36:23,722 INFO     Training average negative_sample_loss at step 17300: 0.095814\n",
      "2023-12-07 00:36:23,722 INFO     Training average loss at step 17300: 0.114330\n",
      "2023-12-07 00:37:02,157 INFO     Training average positive_sample_loss at step 17400: 0.128683\n",
      "2023-12-07 00:37:02,157 INFO     Training average negative_sample_loss at step 17400: 0.094601\n",
      "2023-12-07 00:37:02,158 INFO     Training average loss at step 17400: 0.111642\n",
      "2023-12-07 00:37:40,984 INFO     Training average positive_sample_loss at step 17500: 0.133746\n",
      "2023-12-07 00:37:40,984 INFO     Training average negative_sample_loss at step 17500: 0.094876\n",
      "2023-12-07 00:37:40,984 INFO     Training average loss at step 17500: 0.114311\n",
      "2023-12-07 00:38:22,901 INFO     Training average positive_sample_loss at step 17600: 0.128813\n",
      "2023-12-07 00:38:22,901 INFO     Training average negative_sample_loss at step 17600: 0.094868\n",
      "2023-12-07 00:38:22,901 INFO     Training average loss at step 17600: 0.111840\n",
      "2023-12-07 00:39:01,826 INFO     Training average positive_sample_loss at step 17700: 0.131359\n",
      "2023-12-07 00:39:01,826 INFO     Training average negative_sample_loss at step 17700: 0.093322\n",
      "2023-12-07 00:39:01,826 INFO     Training average loss at step 17700: 0.112340\n",
      "2023-12-07 00:39:40,351 INFO     Training average positive_sample_loss at step 17800: 0.133941\n",
      "2023-12-07 00:39:40,352 INFO     Training average negative_sample_loss at step 17800: 0.094797\n",
      "2023-12-07 00:39:40,352 INFO     Training average loss at step 17800: 0.114369\n",
      "2023-12-07 00:40:21,938 INFO     Training average positive_sample_loss at step 17900: 0.126693\n",
      "2023-12-07 00:40:21,939 INFO     Training average negative_sample_loss at step 17900: 0.093591\n",
      "2023-12-07 00:40:21,939 INFO     Training average loss at step 17900: 0.110142\n",
      "2023-12-07 00:41:00,548 INFO     Training average positive_sample_loss at step 18000: 0.132847\n",
      "2023-12-07 00:41:00,548 INFO     Training average negative_sample_loss at step 18000: 0.093834\n",
      "2023-12-07 00:41:00,548 INFO     Training average loss at step 18000: 0.113341\n",
      "2023-12-07 00:41:41,938 INFO     Training average positive_sample_loss at step 18100: 0.129730\n",
      "2023-12-07 00:41:41,938 INFO     Training average negative_sample_loss at step 18100: 0.094826\n",
      "2023-12-07 00:41:41,938 INFO     Training average loss at step 18100: 0.112278\n",
      "2023-12-07 00:42:20,752 INFO     Training average positive_sample_loss at step 18200: 0.129923\n",
      "2023-12-07 00:42:20,752 INFO     Training average negative_sample_loss at step 18200: 0.093289\n",
      "2023-12-07 00:42:20,752 INFO     Training average loss at step 18200: 0.111606\n",
      "2023-12-07 00:42:59,598 INFO     Training average positive_sample_loss at step 18300: 0.133357\n",
      "2023-12-07 00:42:59,598 INFO     Training average negative_sample_loss at step 18300: 0.094322\n",
      "2023-12-07 00:42:59,598 INFO     Training average loss at step 18300: 0.113840\n",
      "2023-12-07 00:43:44,664 INFO     Training average positive_sample_loss at step 18400: 0.127367\n",
      "2023-12-07 00:43:44,665 INFO     Training average negative_sample_loss at step 18400: 0.094104\n",
      "2023-12-07 00:43:44,665 INFO     Training average loss at step 18400: 0.110736\n",
      "2023-12-07 00:44:23,601 INFO     Training average positive_sample_loss at step 18500: 0.131592\n",
      "2023-12-07 00:44:23,601 INFO     Training average negative_sample_loss at step 18500: 0.093276\n",
      "2023-12-07 00:44:23,601 INFO     Training average loss at step 18500: 0.112434\n",
      "2023-12-07 00:45:05,193 INFO     Training average positive_sample_loss at step 18600: 0.130903\n",
      "2023-12-07 00:45:05,193 INFO     Training average negative_sample_loss at step 18600: 0.094985\n",
      "2023-12-07 00:45:05,193 INFO     Training average loss at step 18600: 0.112944\n",
      "2023-12-07 00:45:43,610 INFO     Training average positive_sample_loss at step 18700: 0.128781\n",
      "2023-12-07 00:45:43,610 INFO     Training average negative_sample_loss at step 18700: 0.093001\n",
      "2023-12-07 00:45:43,610 INFO     Training average loss at step 18700: 0.110891\n",
      "2023-12-07 00:46:22,056 INFO     Training average positive_sample_loss at step 18800: 0.133295\n",
      "2023-12-07 00:46:22,056 INFO     Training average negative_sample_loss at step 18800: 0.093594\n",
      "2023-12-07 00:46:22,056 INFO     Training average loss at step 18800: 0.113444\n",
      "2023-12-07 00:47:03,994 INFO     Training average positive_sample_loss at step 18900: 0.127830\n",
      "2023-12-07 00:47:03,995 INFO     Training average negative_sample_loss at step 18900: 0.094363\n",
      "2023-12-07 00:47:03,995 INFO     Training average loss at step 18900: 0.111096\n",
      "2023-12-07 00:47:42,576 INFO     Training average positive_sample_loss at step 19000: 0.130659\n",
      "2023-12-07 00:47:42,576 INFO     Training average negative_sample_loss at step 19000: 0.092623\n",
      "2023-12-07 00:47:42,576 INFO     Training average loss at step 19000: 0.111641\n",
      "2023-12-07 00:48:24,361 INFO     Training average positive_sample_loss at step 19100: 0.132331\n",
      "2023-12-07 00:48:24,362 INFO     Training average negative_sample_loss at step 19100: 0.094813\n",
      "2023-12-07 00:48:24,362 INFO     Training average loss at step 19100: 0.113572\n",
      "2023-12-07 00:49:02,999 INFO     Training average positive_sample_loss at step 19200: 0.127257\n",
      "2023-12-07 00:49:02,999 INFO     Training average negative_sample_loss at step 19200: 0.093139\n",
      "2023-12-07 00:49:02,999 INFO     Training average loss at step 19200: 0.110198\n",
      "2023-12-07 00:49:41,819 INFO     Training average positive_sample_loss at step 19300: 0.132125\n",
      "2023-12-07 00:49:41,819 INFO     Training average negative_sample_loss at step 19300: 0.093795\n",
      "2023-12-07 00:49:41,819 INFO     Training average loss at step 19300: 0.112960\n",
      "2023-12-07 00:50:23,386 INFO     Training average positive_sample_loss at step 19400: 0.128176\n",
      "2023-12-07 00:50:23,386 INFO     Training average negative_sample_loss at step 19400: 0.094737\n",
      "2023-12-07 00:50:23,387 INFO     Training average loss at step 19400: 0.111457\n",
      "2023-12-07 00:51:02,275 INFO     Training average positive_sample_loss at step 19500: 0.130480\n",
      "2023-12-07 00:51:02,275 INFO     Training average negative_sample_loss at step 19500: 0.092833\n",
      "2023-12-07 00:51:02,275 INFO     Training average loss at step 19500: 0.111656\n",
      "2023-12-07 00:51:40,866 INFO     Training average positive_sample_loss at step 19600: 0.132944\n",
      "2023-12-07 00:51:40,867 INFO     Training average negative_sample_loss at step 19600: 0.094562\n",
      "2023-12-07 00:51:40,867 INFO     Training average loss at step 19600: 0.113753\n",
      "2023-12-07 00:52:26,210 INFO     Training average positive_sample_loss at step 19700: 0.126326\n",
      "2023-12-07 00:52:26,211 INFO     Training average negative_sample_loss at step 19700: 0.093267\n",
      "2023-12-07 00:52:26,211 INFO     Training average loss at step 19700: 0.109796\n",
      "2023-12-07 00:53:05,057 INFO     Training average positive_sample_loss at step 19800: 0.130944\n",
      "2023-12-07 00:53:05,057 INFO     Training average negative_sample_loss at step 19800: 0.092591\n",
      "2023-12-07 00:53:05,057 INFO     Training average loss at step 19800: 0.111768\n",
      "2023-12-07 00:53:47,358 INFO     Training average positive_sample_loss at step 19900: 0.130111\n",
      "2023-12-07 00:53:47,358 INFO     Training average negative_sample_loss at step 19900: 0.095027\n",
      "2023-12-07 00:53:47,359 INFO     Training average loss at step 19900: 0.112569\n",
      "2023-12-07 00:54:37,881 INFO     Training average positive_sample_loss at step 20000: 0.128587\n",
      "2023-12-07 00:54:37,881 INFO     Training average negative_sample_loss at step 20000: 0.092111\n",
      "2023-12-07 00:54:37,881 INFO     Training average loss at step 20000: 0.110349\n",
      "2023-12-07 00:54:37,881 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 00:54:38,369 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 00:55:02,369 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 00:55:17,348 INFO     Valid MRR at step 20000: 0.546094\n",
      "2023-12-07 00:55:17,348 INFO     Valid MR at step 20000: 266.966369\n",
      "2023-12-07 00:55:17,348 INFO     Valid HITS@1 at step 20000: 0.477761\n",
      "2023-12-07 00:55:17,348 INFO     Valid HITS@3 at step 20000: 0.575756\n",
      "2023-12-07 00:55:17,348 INFO     Valid HITS@10 at step 20000: 0.674364\n",
      "2023-12-07 00:55:49,219 INFO     Training average positive_sample_loss at step 20100: 0.132430\n",
      "2023-12-07 00:55:49,220 INFO     Training average negative_sample_loss at step 20100: 0.094619\n",
      "2023-12-07 00:55:49,220 INFO     Training average loss at step 20100: 0.113524\n",
      "2023-12-07 00:56:34,456 INFO     Training average positive_sample_loss at step 20200: 0.126815\n",
      "2023-12-07 00:56:34,457 INFO     Training average negative_sample_loss at step 20200: 0.092516\n",
      "2023-12-07 00:56:34,457 INFO     Training average loss at step 20200: 0.109665\n",
      "2023-12-07 00:57:12,911 INFO     Training average positive_sample_loss at step 20300: 0.130180\n",
      "2023-12-07 00:57:12,911 INFO     Training average negative_sample_loss at step 20300: 0.091926\n",
      "2023-12-07 00:57:12,911 INFO     Training average loss at step 20300: 0.111053\n",
      "2023-12-07 00:57:54,749 INFO     Training average positive_sample_loss at step 20400: 0.130779\n",
      "2023-12-07 00:57:54,749 INFO     Training average negative_sample_loss at step 20400: 0.094242\n",
      "2023-12-07 00:57:54,749 INFO     Training average loss at step 20400: 0.112510\n",
      "2023-12-07 00:58:33,271 INFO     Training average positive_sample_loss at step 20500: 0.127719\n",
      "2023-12-07 00:58:33,272 INFO     Training average negative_sample_loss at step 20500: 0.092535\n",
      "2023-12-07 00:58:33,272 INFO     Training average loss at step 20500: 0.110127\n",
      "2023-12-07 00:59:11,719 INFO     Training average positive_sample_loss at step 20600: 0.131718\n",
      "2023-12-07 00:59:11,719 INFO     Training average negative_sample_loss at step 20600: 0.093004\n",
      "2023-12-07 00:59:11,719 INFO     Training average loss at step 20600: 0.112361\n",
      "2023-12-07 00:59:53,203 INFO     Training average positive_sample_loss at step 20700: 0.126693\n",
      "2023-12-07 00:59:53,203 INFO     Training average negative_sample_loss at step 20700: 0.093042\n",
      "2023-12-07 00:59:53,203 INFO     Training average loss at step 20700: 0.109868\n",
      "2023-12-07 01:00:31,861 INFO     Training average positive_sample_loss at step 20800: 0.130588\n",
      "2023-12-07 01:00:31,861 INFO     Training average negative_sample_loss at step 20800: 0.092761\n",
      "2023-12-07 01:00:31,861 INFO     Training average loss at step 20800: 0.111674\n",
      "2023-12-07 01:01:16,441 INFO     Training average positive_sample_loss at step 20900: 0.131655\n",
      "2023-12-07 01:01:16,441 INFO     Training average negative_sample_loss at step 20900: 0.094480\n",
      "2023-12-07 01:01:16,441 INFO     Training average loss at step 20900: 0.113067\n",
      "2023-12-07 01:01:55,094 INFO     Training average positive_sample_loss at step 21000: 0.125541\n",
      "2023-12-07 01:01:55,094 INFO     Training average negative_sample_loss at step 21000: 0.092257\n",
      "2023-12-07 01:01:55,095 INFO     Training average loss at step 21000: 0.108899\n",
      "2023-12-07 01:02:33,492 INFO     Training average positive_sample_loss at step 21100: 0.131852\n",
      "2023-12-07 01:02:33,493 INFO     Training average negative_sample_loss at step 21100: 0.092927\n",
      "2023-12-07 01:02:33,493 INFO     Training average loss at step 21100: 0.112390\n",
      "2023-12-07 01:03:15,882 INFO     Training average positive_sample_loss at step 21200: 0.127453\n",
      "2023-12-07 01:03:15,882 INFO     Training average negative_sample_loss at step 21200: 0.093178\n",
      "2023-12-07 01:03:15,882 INFO     Training average loss at step 21200: 0.110315\n",
      "2023-12-07 01:03:54,944 INFO     Training average positive_sample_loss at step 21300: 0.129189\n",
      "2023-12-07 01:03:54,945 INFO     Training average negative_sample_loss at step 21300: 0.091871\n",
      "2023-12-07 01:03:54,945 INFO     Training average loss at step 21300: 0.110530\n",
      "2023-12-07 01:04:33,926 INFO     Training average positive_sample_loss at step 21400: 0.131943\n",
      "2023-12-07 01:04:33,926 INFO     Training average negative_sample_loss at step 21400: 0.093631\n",
      "2023-12-07 01:04:33,926 INFO     Training average loss at step 21400: 0.112787\n",
      "2023-12-07 01:05:15,427 INFO     Training average positive_sample_loss at step 21500: 0.125577\n",
      "2023-12-07 01:05:15,427 INFO     Training average negative_sample_loss at step 21500: 0.092558\n",
      "2023-12-07 01:05:15,427 INFO     Training average loss at step 21500: 0.109067\n",
      "2023-12-07 01:05:53,974 INFO     Training average positive_sample_loss at step 21600: 0.130866\n",
      "2023-12-07 01:05:53,975 INFO     Training average negative_sample_loss at step 21600: 0.092314\n",
      "2023-12-07 01:05:53,975 INFO     Training average loss at step 21600: 0.111590\n",
      "2023-12-07 01:06:36,000 INFO     Training average positive_sample_loss at step 21700: 0.129100\n",
      "2023-12-07 01:06:36,000 INFO     Training average negative_sample_loss at step 21700: 0.094461\n",
      "2023-12-07 01:06:36,000 INFO     Training average loss at step 21700: 0.111780\n",
      "2023-12-07 01:07:14,816 INFO     Training average positive_sample_loss at step 21800: 0.128239\n",
      "2023-12-07 01:07:14,816 INFO     Training average negative_sample_loss at step 21800: 0.092280\n",
      "2023-12-07 01:07:14,816 INFO     Training average loss at step 21800: 0.110260\n",
      "2023-12-07 01:07:53,461 INFO     Training average positive_sample_loss at step 21900: 0.131246\n",
      "2023-12-07 01:07:53,461 INFO     Training average negative_sample_loss at step 21900: 0.092881\n",
      "2023-12-07 01:07:53,461 INFO     Training average loss at step 21900: 0.112063\n",
      "2023-12-07 01:08:34,732 INFO     Training average positive_sample_loss at step 22000: 0.125770\n",
      "2023-12-07 01:08:34,732 INFO     Training average negative_sample_loss at step 22000: 0.092420\n",
      "2023-12-07 01:08:34,732 INFO     Training average loss at step 22000: 0.109095\n",
      "2023-12-07 01:09:13,150 INFO     Training average positive_sample_loss at step 22100: 0.130188\n",
      "2023-12-07 01:09:13,151 INFO     Training average negative_sample_loss at step 22100: 0.092210\n",
      "2023-12-07 01:09:13,151 INFO     Training average loss at step 22100: 0.111199\n",
      "2023-12-07 01:09:58,145 INFO     Training average positive_sample_loss at step 22200: 0.130424\n",
      "2023-12-07 01:09:58,146 INFO     Training average negative_sample_loss at step 22200: 0.093750\n",
      "2023-12-07 01:09:58,146 INFO     Training average loss at step 22200: 0.112087\n",
      "2023-12-07 01:10:37,653 INFO     Training average positive_sample_loss at step 22300: 0.125783\n",
      "2023-12-07 01:10:37,653 INFO     Training average negative_sample_loss at step 22300: 0.091176\n",
      "2023-12-07 01:10:37,653 INFO     Training average loss at step 22300: 0.108479\n",
      "2023-12-07 01:11:16,571 INFO     Training average positive_sample_loss at step 22400: 0.131413\n",
      "2023-12-07 01:11:16,571 INFO     Training average negative_sample_loss at step 22400: 0.092862\n",
      "2023-12-07 01:11:16,571 INFO     Training average loss at step 22400: 0.112137\n",
      "2023-12-07 01:11:58,740 INFO     Training average positive_sample_loss at step 22500: 0.126954\n",
      "2023-12-07 01:11:58,740 INFO     Training average negative_sample_loss at step 22500: 0.094008\n",
      "2023-12-07 01:11:58,740 INFO     Training average loss at step 22500: 0.110481\n",
      "2023-12-07 01:12:37,608 INFO     Training average positive_sample_loss at step 22600: 0.129115\n",
      "2023-12-07 01:12:37,609 INFO     Training average negative_sample_loss at step 22600: 0.090936\n",
      "2023-12-07 01:12:37,609 INFO     Training average loss at step 22600: 0.110025\n",
      "2023-12-07 01:13:16,233 INFO     Training average positive_sample_loss at step 22700: 0.131607\n",
      "2023-12-07 01:13:16,234 INFO     Training average negative_sample_loss at step 22700: 0.092179\n",
      "2023-12-07 01:13:16,234 INFO     Training average loss at step 22700: 0.111893\n",
      "2023-12-07 01:13:57,915 INFO     Training average positive_sample_loss at step 22800: 0.124621\n",
      "2023-12-07 01:13:57,916 INFO     Training average negative_sample_loss at step 22800: 0.092217\n",
      "2023-12-07 01:13:57,916 INFO     Training average loss at step 22800: 0.108419\n",
      "2023-12-07 01:14:36,584 INFO     Training average positive_sample_loss at step 22900: 0.131058\n",
      "2023-12-07 01:14:36,584 INFO     Training average negative_sample_loss at step 22900: 0.092837\n",
      "2023-12-07 01:14:36,584 INFO     Training average loss at step 22900: 0.111948\n",
      "2023-12-07 01:15:18,364 INFO     Training average positive_sample_loss at step 23000: 0.127494\n",
      "2023-12-07 01:15:18,365 INFO     Training average negative_sample_loss at step 23000: 0.092661\n",
      "2023-12-07 01:15:18,365 INFO     Training average loss at step 23000: 0.110077\n",
      "2023-12-07 01:15:56,918 INFO     Training average positive_sample_loss at step 23100: 0.128160\n",
      "2023-12-07 01:15:56,918 INFO     Training average negative_sample_loss at step 23100: 0.092018\n",
      "2023-12-07 01:15:56,918 INFO     Training average loss at step 23100: 0.110089\n",
      "2023-12-07 01:16:35,406 INFO     Training average positive_sample_loss at step 23200: 0.131399\n",
      "2023-12-07 01:16:35,407 INFO     Training average negative_sample_loss at step 23200: 0.092697\n",
      "2023-12-07 01:16:35,407 INFO     Training average loss at step 23200: 0.112048\n",
      "2023-12-07 01:17:16,266 INFO     Training average positive_sample_loss at step 23300: 0.125088\n",
      "2023-12-07 01:17:16,266 INFO     Training average negative_sample_loss at step 23300: 0.092452\n",
      "2023-12-07 01:17:16,266 INFO     Training average loss at step 23300: 0.108770\n",
      "2023-12-07 01:17:54,671 INFO     Training average positive_sample_loss at step 23400: 0.130686\n",
      "2023-12-07 01:17:54,671 INFO     Training average negative_sample_loss at step 23400: 0.092337\n",
      "2023-12-07 01:17:54,671 INFO     Training average loss at step 23400: 0.111511\n",
      "2023-12-07 01:18:39,137 INFO     Training average positive_sample_loss at step 23500: 0.128856\n",
      "2023-12-07 01:18:39,137 INFO     Training average negative_sample_loss at step 23500: 0.093338\n",
      "2023-12-07 01:18:39,137 INFO     Training average loss at step 23500: 0.111097\n",
      "2023-12-07 01:19:17,156 INFO     Training average positive_sample_loss at step 23600: 0.126910\n",
      "2023-12-07 01:19:17,156 INFO     Training average negative_sample_loss at step 23600: 0.091751\n",
      "2023-12-07 01:19:17,156 INFO     Training average loss at step 23600: 0.109331\n",
      "2023-12-07 01:19:55,238 INFO     Training average positive_sample_loss at step 23700: 0.130901\n",
      "2023-12-07 01:19:55,239 INFO     Training average negative_sample_loss at step 23700: 0.092454\n",
      "2023-12-07 01:19:55,239 INFO     Training average loss at step 23700: 0.111677\n",
      "2023-12-07 01:20:37,696 INFO     Training average positive_sample_loss at step 23800: 0.126462\n",
      "2023-12-07 01:20:37,697 INFO     Training average negative_sample_loss at step 23800: 0.092716\n",
      "2023-12-07 01:20:37,697 INFO     Training average loss at step 23800: 0.109589\n",
      "2023-12-07 01:21:16,573 INFO     Training average positive_sample_loss at step 23900: 0.129265\n",
      "2023-12-07 01:21:16,573 INFO     Training average negative_sample_loss at step 23900: 0.091479\n",
      "2023-12-07 01:21:16,573 INFO     Training average loss at step 23900: 0.110372\n",
      "2023-12-07 01:21:58,167 INFO     Training average positive_sample_loss at step 24000: 0.129685\n",
      "2023-12-07 01:21:58,167 INFO     Training average negative_sample_loss at step 24000: 0.093151\n",
      "2023-12-07 01:21:58,167 INFO     Training average loss at step 24000: 0.111418\n",
      "2023-12-07 01:22:36,954 INFO     Training average positive_sample_loss at step 24100: 0.125319\n",
      "2023-12-07 01:22:36,954 INFO     Training average negative_sample_loss at step 24100: 0.091541\n",
      "2023-12-07 01:22:36,954 INFO     Training average loss at step 24100: 0.108430\n",
      "2023-12-07 01:23:15,431 INFO     Training average positive_sample_loss at step 24200: 0.130473\n",
      "2023-12-07 01:23:15,431 INFO     Training average negative_sample_loss at step 24200: 0.092339\n",
      "2023-12-07 01:23:15,431 INFO     Training average loss at step 24200: 0.111406\n",
      "2023-12-07 01:23:56,941 INFO     Training average positive_sample_loss at step 24300: 0.126550\n",
      "2023-12-07 01:23:56,941 INFO     Training average negative_sample_loss at step 24300: 0.092218\n",
      "2023-12-07 01:23:56,941 INFO     Training average loss at step 24300: 0.109384\n",
      "2023-12-07 01:24:36,952 INFO     Training average positive_sample_loss at step 24400: 0.128497\n",
      "2023-12-07 01:24:36,952 INFO     Training average negative_sample_loss at step 24400: 0.092033\n",
      "2023-12-07 01:24:36,952 INFO     Training average loss at step 24400: 0.110265\n",
      "2023-12-07 01:25:16,670 INFO     Training average positive_sample_loss at step 24500: 0.130928\n",
      "2023-12-07 01:25:16,671 INFO     Training average negative_sample_loss at step 24500: 0.092933\n",
      "2023-12-07 01:25:16,671 INFO     Training average loss at step 24500: 0.111931\n",
      "2023-12-07 01:25:58,507 INFO     Training average positive_sample_loss at step 24600: 0.124408\n",
      "2023-12-07 01:25:58,507 INFO     Training average negative_sample_loss at step 24600: 0.091810\n",
      "2023-12-07 01:25:58,507 INFO     Training average loss at step 24600: 0.108109\n",
      "2023-12-07 01:26:36,978 INFO     Training average positive_sample_loss at step 24700: 0.130547\n",
      "2023-12-07 01:26:36,978 INFO     Training average negative_sample_loss at step 24700: 0.091951\n",
      "2023-12-07 01:26:36,978 INFO     Training average loss at step 24700: 0.111249\n",
      "2023-12-07 01:27:22,223 INFO     Training average positive_sample_loss at step 24800: 0.127773\n",
      "2023-12-07 01:27:22,223 INFO     Training average negative_sample_loss at step 24800: 0.093369\n",
      "2023-12-07 01:27:22,223 INFO     Training average loss at step 24800: 0.110571\n",
      "2023-12-07 01:28:00,920 INFO     Training average positive_sample_loss at step 24900: 0.127110\n",
      "2023-12-07 01:28:00,920 INFO     Training average negative_sample_loss at step 24900: 0.091307\n",
      "2023-12-07 01:28:00,920 INFO     Training average loss at step 24900: 0.109208\n",
      "2023-12-07 01:28:39,829 INFO     Training average positive_sample_loss at step 25000: 0.130932\n",
      "2023-12-07 01:28:39,830 INFO     Training average negative_sample_loss at step 25000: 0.092542\n",
      "2023-12-07 01:28:39,830 INFO     Training average loss at step 25000: 0.111737\n",
      "2023-12-07 01:29:21,963 INFO     Training average positive_sample_loss at step 25100: 0.125117\n",
      "2023-12-07 01:29:21,964 INFO     Training average negative_sample_loss at step 25100: 0.091335\n",
      "2023-12-07 01:29:21,964 INFO     Training average loss at step 25100: 0.108226\n",
      "2023-12-07 01:30:00,479 INFO     Training average positive_sample_loss at step 25200: 0.129298\n",
      "2023-12-07 01:30:00,479 INFO     Training average negative_sample_loss at step 25200: 0.091938\n",
      "2023-12-07 01:30:00,479 INFO     Training average loss at step 25200: 0.110618\n",
      "2023-12-07 01:30:42,224 INFO     Training average positive_sample_loss at step 25300: 0.128831\n",
      "2023-12-07 01:30:42,224 INFO     Training average negative_sample_loss at step 25300: 0.092519\n",
      "2023-12-07 01:30:42,224 INFO     Training average loss at step 25300: 0.110675\n",
      "2023-12-07 01:31:21,320 INFO     Training average positive_sample_loss at step 25400: 0.125906\n",
      "2023-12-07 01:31:21,321 INFO     Training average negative_sample_loss at step 25400: 0.091209\n",
      "2023-12-07 01:31:21,321 INFO     Training average loss at step 25400: 0.108557\n",
      "2023-12-07 01:31:59,874 INFO     Training average positive_sample_loss at step 25500: 0.130255\n",
      "2023-12-07 01:31:59,875 INFO     Training average negative_sample_loss at step 25500: 0.091085\n",
      "2023-12-07 01:31:59,875 INFO     Training average loss at step 25500: 0.110670\n",
      "2023-12-07 01:32:41,321 INFO     Training average positive_sample_loss at step 25600: 0.125458\n",
      "2023-12-07 01:32:41,322 INFO     Training average negative_sample_loss at step 25600: 0.092167\n",
      "2023-12-07 01:32:41,322 INFO     Training average loss at step 25600: 0.108812\n",
      "2023-12-07 01:33:19,711 INFO     Training average positive_sample_loss at step 25700: 0.128593\n",
      "2023-12-07 01:33:19,712 INFO     Training average negative_sample_loss at step 25700: 0.090827\n",
      "2023-12-07 01:33:19,712 INFO     Training average loss at step 25700: 0.109710\n",
      "2023-12-07 01:34:00,449 INFO     Training average positive_sample_loss at step 25800: 0.130461\n",
      "2023-12-07 01:34:00,450 INFO     Training average negative_sample_loss at step 25800: 0.093133\n",
      "2023-12-07 01:34:00,450 INFO     Training average loss at step 25800: 0.111797\n",
      "2023-12-07 01:34:39,691 INFO     Training average positive_sample_loss at step 25900: 0.123816\n",
      "2023-12-07 01:34:39,691 INFO     Training average negative_sample_loss at step 25900: 0.090860\n",
      "2023-12-07 01:34:39,691 INFO     Training average loss at step 25900: 0.107338\n",
      "2023-12-07 01:35:18,422 INFO     Training average positive_sample_loss at step 26000: 0.130632\n",
      "2023-12-07 01:35:18,423 INFO     Training average negative_sample_loss at step 26000: 0.091865\n",
      "2023-12-07 01:35:18,423 INFO     Training average loss at step 26000: 0.111248\n",
      "2023-12-07 01:36:03,130 INFO     Training average positive_sample_loss at step 26100: 0.126061\n",
      "2023-12-07 01:36:03,130 INFO     Training average negative_sample_loss at step 26100: 0.092564\n",
      "2023-12-07 01:36:03,130 INFO     Training average loss at step 26100: 0.109313\n",
      "2023-12-07 01:36:41,278 INFO     Training average positive_sample_loss at step 26200: 0.127594\n",
      "2023-12-07 01:36:41,279 INFO     Training average negative_sample_loss at step 26200: 0.090506\n",
      "2023-12-07 01:36:41,279 INFO     Training average loss at step 26200: 0.109050\n",
      "2023-12-07 01:37:19,760 INFO     Training average positive_sample_loss at step 26300: 0.130222\n",
      "2023-12-07 01:37:19,760 INFO     Training average negative_sample_loss at step 26300: 0.091743\n",
      "2023-12-07 01:37:19,760 INFO     Training average loss at step 26300: 0.110982\n",
      "2023-12-07 01:38:01,453 INFO     Training average positive_sample_loss at step 26400: 0.124532\n",
      "2023-12-07 01:38:01,453 INFO     Training average negative_sample_loss at step 26400: 0.091685\n",
      "2023-12-07 01:38:01,453 INFO     Training average loss at step 26400: 0.108109\n",
      "2023-12-07 01:38:39,917 INFO     Training average positive_sample_loss at step 26500: 0.128830\n",
      "2023-12-07 01:38:39,917 INFO     Training average negative_sample_loss at step 26500: 0.090936\n",
      "2023-12-07 01:38:39,917 INFO     Training average loss at step 26500: 0.109883\n",
      "2023-12-07 01:39:21,310 INFO     Training average positive_sample_loss at step 26600: 0.127994\n",
      "2023-12-07 01:39:21,310 INFO     Training average negative_sample_loss at step 26600: 0.091704\n",
      "2023-12-07 01:39:21,310 INFO     Training average loss at step 26600: 0.109849\n",
      "2023-12-07 01:40:00,402 INFO     Training average positive_sample_loss at step 26700: 0.125737\n",
      "2023-12-07 01:40:00,402 INFO     Training average negative_sample_loss at step 26700: 0.090433\n",
      "2023-12-07 01:40:00,403 INFO     Training average loss at step 26700: 0.108085\n",
      "2023-12-07 01:40:39,025 INFO     Training average positive_sample_loss at step 26800: 0.130437\n",
      "2023-12-07 01:40:39,025 INFO     Training average negative_sample_loss at step 26800: 0.092156\n",
      "2023-12-07 01:40:39,025 INFO     Training average loss at step 26800: 0.111297\n",
      "2023-12-07 01:41:21,569 INFO     Training average positive_sample_loss at step 26900: 0.124175\n",
      "2023-12-07 01:41:21,569 INFO     Training average negative_sample_loss at step 26900: 0.091146\n",
      "2023-12-07 01:41:21,569 INFO     Training average loss at step 26900: 0.107660\n",
      "2023-12-07 01:42:00,471 INFO     Training average positive_sample_loss at step 27000: 0.128833\n",
      "2023-12-07 01:42:00,471 INFO     Training average negative_sample_loss at step 27000: 0.091009\n",
      "2023-12-07 01:42:00,471 INFO     Training average loss at step 27000: 0.109921\n",
      "2023-12-07 01:42:42,895 INFO     Training average positive_sample_loss at step 27100: 0.129452\n",
      "2023-12-07 01:42:42,895 INFO     Training average negative_sample_loss at step 27100: 0.093554\n",
      "2023-12-07 01:42:42,895 INFO     Training average loss at step 27100: 0.111503\n",
      "2023-12-07 01:43:21,736 INFO     Training average positive_sample_loss at step 27200: 0.124877\n",
      "2023-12-07 01:43:21,736 INFO     Training average negative_sample_loss at step 27200: 0.090933\n",
      "2023-12-07 01:43:21,736 INFO     Training average loss at step 27200: 0.107905\n",
      "2023-12-07 01:44:01,048 INFO     Training average positive_sample_loss at step 27300: 0.129734\n",
      "2023-12-07 01:44:01,049 INFO     Training average negative_sample_loss at step 27300: 0.091224\n",
      "2023-12-07 01:44:01,049 INFO     Training average loss at step 27300: 0.110479\n",
      "2023-12-07 01:44:45,275 INFO     Training average positive_sample_loss at step 27400: 0.125442\n",
      "2023-12-07 01:44:45,275 INFO     Training average negative_sample_loss at step 27400: 0.091739\n",
      "2023-12-07 01:44:45,275 INFO     Training average loss at step 27400: 0.108591\n",
      "2023-12-07 01:45:24,082 INFO     Training average positive_sample_loss at step 27500: 0.128196\n",
      "2023-12-07 01:45:24,082 INFO     Training average negative_sample_loss at step 27500: 0.090540\n",
      "2023-12-07 01:45:24,082 INFO     Training average loss at step 27500: 0.109368\n",
      "2023-12-07 01:46:02,552 INFO     Training average positive_sample_loss at step 27600: 0.130127\n",
      "2023-12-07 01:46:02,552 INFO     Training average negative_sample_loss at step 27600: 0.091796\n",
      "2023-12-07 01:46:02,552 INFO     Training average loss at step 27600: 0.110961\n",
      "2023-12-07 01:46:43,965 INFO     Training average positive_sample_loss at step 27700: 0.123603\n",
      "2023-12-07 01:46:43,966 INFO     Training average negative_sample_loss at step 27700: 0.090692\n",
      "2023-12-07 01:46:43,966 INFO     Training average loss at step 27700: 0.107147\n",
      "2023-12-07 01:47:22,127 INFO     Training average positive_sample_loss at step 27800: 0.129027\n",
      "2023-12-07 01:47:22,128 INFO     Training average negative_sample_loss at step 27800: 0.090874\n",
      "2023-12-07 01:47:22,128 INFO     Training average loss at step 27800: 0.109950\n",
      "2023-12-07 01:48:03,826 INFO     Training average positive_sample_loss at step 27900: 0.127090\n",
      "2023-12-07 01:48:03,826 INFO     Training average negative_sample_loss at step 27900: 0.092418\n",
      "2023-12-07 01:48:03,826 INFO     Training average loss at step 27900: 0.109754\n",
      "2023-12-07 01:48:42,382 INFO     Training average positive_sample_loss at step 28000: 0.126541\n",
      "2023-12-07 01:48:42,383 INFO     Training average negative_sample_loss at step 28000: 0.090165\n",
      "2023-12-07 01:48:42,383 INFO     Training average loss at step 28000: 0.108353\n",
      "2023-12-07 01:49:21,514 INFO     Training average positive_sample_loss at step 28100: 0.130089\n",
      "2023-12-07 01:49:21,514 INFO     Training average negative_sample_loss at step 28100: 0.092473\n",
      "2023-12-07 01:49:21,515 INFO     Training average loss at step 28100: 0.111281\n",
      "2023-12-07 01:50:03,202 INFO     Training average positive_sample_loss at step 28200: 0.124106\n",
      "2023-12-07 01:50:03,203 INFO     Training average negative_sample_loss at step 28200: 0.091001\n",
      "2023-12-07 01:50:03,203 INFO     Training average loss at step 28200: 0.107553\n",
      "2023-12-07 01:50:41,388 INFO     Training average positive_sample_loss at step 28300: 0.128882\n",
      "2023-12-07 01:50:41,389 INFO     Training average negative_sample_loss at step 28300: 0.091104\n",
      "2023-12-07 01:50:41,389 INFO     Training average loss at step 28300: 0.109993\n",
      "2023-12-07 01:51:23,034 INFO     Training average positive_sample_loss at step 28400: 0.128167\n",
      "2023-12-07 01:51:23,034 INFO     Training average negative_sample_loss at step 28400: 0.092332\n",
      "2023-12-07 01:51:23,034 INFO     Training average loss at step 28400: 0.110250\n",
      "2023-12-07 01:52:01,192 INFO     Training average positive_sample_loss at step 28500: 0.125595\n",
      "2023-12-07 01:52:01,192 INFO     Training average negative_sample_loss at step 28500: 0.090294\n",
      "2023-12-07 01:52:01,192 INFO     Training average loss at step 28500: 0.107945\n",
      "2023-12-07 01:52:39,825 INFO     Training average positive_sample_loss at step 28600: 0.129349\n",
      "2023-12-07 01:52:39,826 INFO     Training average negative_sample_loss at step 28600: 0.091060\n",
      "2023-12-07 01:52:39,826 INFO     Training average loss at step 28600: 0.110205\n",
      "2023-12-07 01:53:24,622 INFO     Training average positive_sample_loss at step 28700: 0.124507\n",
      "2023-12-07 01:53:24,622 INFO     Training average negative_sample_loss at step 28700: 0.091359\n",
      "2023-12-07 01:53:24,622 INFO     Training average loss at step 28700: 0.107933\n",
      "2023-12-07 01:54:02,920 INFO     Training average positive_sample_loss at step 28800: 0.127924\n",
      "2023-12-07 01:54:02,920 INFO     Training average negative_sample_loss at step 28800: 0.090840\n",
      "2023-12-07 01:54:02,921 INFO     Training average loss at step 28800: 0.109382\n",
      "2023-12-07 01:54:44,938 INFO     Training average positive_sample_loss at step 28900: 0.130237\n",
      "2023-12-07 01:54:44,938 INFO     Training average negative_sample_loss at step 28900: 0.093044\n",
      "2023-12-07 01:54:44,939 INFO     Training average loss at step 28900: 0.111640\n",
      "2023-12-07 01:55:23,439 INFO     Training average positive_sample_loss at step 29000: 0.123731\n",
      "2023-12-07 01:55:23,439 INFO     Training average negative_sample_loss at step 29000: 0.089980\n",
      "2023-12-07 01:55:23,439 INFO     Training average loss at step 29000: 0.106856\n",
      "2023-12-07 01:56:02,147 INFO     Training average positive_sample_loss at step 29100: 0.129458\n",
      "2023-12-07 01:56:02,147 INFO     Training average negative_sample_loss at step 29100: 0.091751\n",
      "2023-12-07 01:56:02,148 INFO     Training average loss at step 29100: 0.110605\n",
      "2023-12-07 01:56:43,672 INFO     Training average positive_sample_loss at step 29200: 0.125804\n",
      "2023-12-07 01:56:43,673 INFO     Training average negative_sample_loss at step 29200: 0.092312\n",
      "2023-12-07 01:56:43,673 INFO     Training average loss at step 29200: 0.109058\n",
      "2023-12-07 01:57:22,252 INFO     Training average positive_sample_loss at step 29300: 0.126671\n",
      "2023-12-07 01:57:22,253 INFO     Training average negative_sample_loss at step 29300: 0.089552\n",
      "2023-12-07 01:57:22,253 INFO     Training average loss at step 29300: 0.108111\n",
      "2023-12-07 01:58:00,575 INFO     Training average positive_sample_loss at step 29400: 0.130019\n",
      "2023-12-07 01:58:00,575 INFO     Training average negative_sample_loss at step 29400: 0.091976\n",
      "2023-12-07 01:58:00,575 INFO     Training average loss at step 29400: 0.110997\n",
      "2023-12-07 01:58:42,549 INFO     Training average positive_sample_loss at step 29500: 0.123842\n",
      "2023-12-07 01:58:42,549 INFO     Training average negative_sample_loss at step 29500: 0.090420\n",
      "2023-12-07 01:58:42,549 INFO     Training average loss at step 29500: 0.107131\n",
      "2023-12-07 01:59:21,802 INFO     Training average positive_sample_loss at step 29600: 0.128814\n",
      "2023-12-07 01:59:21,802 INFO     Training average negative_sample_loss at step 29600: 0.091700\n",
      "2023-12-07 01:59:21,802 INFO     Training average loss at step 29600: 0.110257\n",
      "2023-12-07 02:00:03,229 INFO     Training average positive_sample_loss at step 29700: 0.126554\n",
      "2023-12-07 02:00:03,230 INFO     Training average negative_sample_loss at step 29700: 0.092027\n",
      "2023-12-07 02:00:03,230 INFO     Training average loss at step 29700: 0.109291\n",
      "2023-12-07 02:00:42,374 INFO     Training average positive_sample_loss at step 29800: 0.126074\n",
      "2023-12-07 02:00:42,375 INFO     Training average negative_sample_loss at step 29800: 0.089726\n",
      "2023-12-07 02:00:42,375 INFO     Training average loss at step 29800: 0.107900\n",
      "2023-12-07 02:01:20,886 INFO     Training average positive_sample_loss at step 29900: 0.129649\n",
      "2023-12-07 02:01:20,886 INFO     Training average negative_sample_loss at step 29900: 0.090883\n",
      "2023-12-07 02:01:20,886 INFO     Training average loss at step 29900: 0.110266\n",
      "2023-12-07 02:02:20,591 INFO     Training average positive_sample_loss at step 30000: 0.124231\n",
      "2023-12-07 02:02:20,592 INFO     Training average negative_sample_loss at step 30000: 0.091447\n",
      "2023-12-07 02:02:20,592 INFO     Training average loss at step 30000: 0.107839\n",
      "2023-12-07 02:02:20,592 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 02:02:21,040 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 02:02:49,291 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 02:03:09,210 INFO     Valid MRR at step 30000: 0.541972\n",
      "2023-12-07 02:03:09,211 INFO     Valid MR at step 30000: 263.850808\n",
      "2023-12-07 02:03:09,211 INFO     Valid HITS@1 at step 30000: 0.471894\n",
      "2023-12-07 02:03:09,211 INFO     Valid HITS@3 at step 30000: 0.575892\n",
      "2023-12-07 02:03:09,211 INFO     Valid HITS@10 at step 30000: 0.666894\n",
      "2023-12-07 02:03:40,664 INFO     Training average positive_sample_loss at step 30100: 0.127858\n",
      "2023-12-07 02:03:40,664 INFO     Training average negative_sample_loss at step 30100: 0.090604\n",
      "2023-12-07 02:03:40,664 INFO     Training average loss at step 30100: 0.109231\n",
      "2023-12-07 02:04:25,360 INFO     Training average positive_sample_loss at step 30200: 0.127903\n",
      "2023-12-07 02:04:25,360 INFO     Training average negative_sample_loss at step 30200: 0.091709\n",
      "2023-12-07 02:04:25,360 INFO     Training average loss at step 30200: 0.109806\n",
      "2023-12-07 02:05:04,442 INFO     Training average positive_sample_loss at step 30300: 0.124622\n",
      "2023-12-07 02:05:04,442 INFO     Training average negative_sample_loss at step 30300: 0.089959\n",
      "2023-12-07 02:05:04,442 INFO     Training average loss at step 30300: 0.107290\n",
      "2023-12-07 02:05:43,163 INFO     Training average positive_sample_loss at step 30400: 0.129726\n",
      "2023-12-07 02:05:43,163 INFO     Training average negative_sample_loss at step 30400: 0.091687\n",
      "2023-12-07 02:05:43,164 INFO     Training average loss at step 30400: 0.110706\n",
      "2023-12-07 02:06:25,459 INFO     Training average positive_sample_loss at step 30500: 0.124816\n",
      "2023-12-07 02:06:25,459 INFO     Training average negative_sample_loss at step 30500: 0.091372\n",
      "2023-12-07 02:06:25,459 INFO     Training average loss at step 30500: 0.108094\n",
      "2023-12-07 02:07:04,190 INFO     Training average positive_sample_loss at step 30600: 0.127030\n",
      "2023-12-07 02:07:04,190 INFO     Training average negative_sample_loss at step 30600: 0.089859\n",
      "2023-12-07 02:07:04,190 INFO     Training average loss at step 30600: 0.108444\n",
      "2023-12-07 02:07:42,652 INFO     Training average positive_sample_loss at step 30700: 0.129955\n",
      "2023-12-07 02:07:42,653 INFO     Training average negative_sample_loss at step 30700: 0.091568\n",
      "2023-12-07 02:07:42,653 INFO     Training average loss at step 30700: 0.110761\n",
      "2023-12-07 02:08:24,876 INFO     Training average positive_sample_loss at step 30800: 0.123215\n",
      "2023-12-07 02:08:24,877 INFO     Training average negative_sample_loss at step 30800: 0.090618\n",
      "2023-12-07 02:08:24,877 INFO     Training average loss at step 30800: 0.106916\n",
      "2023-12-07 02:09:03,995 INFO     Training average positive_sample_loss at step 30900: 0.128223\n",
      "2023-12-07 02:09:03,995 INFO     Training average negative_sample_loss at step 30900: 0.090347\n",
      "2023-12-07 02:09:03,995 INFO     Training average loss at step 30900: 0.109285\n",
      "2023-12-07 02:09:46,116 INFO     Training average positive_sample_loss at step 31000: 0.125440\n",
      "2023-12-07 02:09:46,117 INFO     Training average negative_sample_loss at step 31000: 0.091406\n",
      "2023-12-07 02:09:46,117 INFO     Training average loss at step 31000: 0.108423\n",
      "2023-12-07 02:10:24,433 INFO     Training average positive_sample_loss at step 31100: 0.126890\n",
      "2023-12-07 02:10:24,433 INFO     Training average negative_sample_loss at step 31100: 0.089884\n",
      "2023-12-07 02:10:24,433 INFO     Training average loss at step 31100: 0.108387\n",
      "2023-12-07 02:11:02,974 INFO     Training average positive_sample_loss at step 31200: 0.129403\n",
      "2023-12-07 02:11:02,974 INFO     Training average negative_sample_loss at step 31200: 0.091464\n",
      "2023-12-07 02:11:02,974 INFO     Training average loss at step 31200: 0.110434\n",
      "2023-12-07 02:11:48,622 INFO     Training average positive_sample_loss at step 31300: 0.123907\n",
      "2023-12-07 02:11:48,622 INFO     Training average negative_sample_loss at step 31300: 0.091131\n",
      "2023-12-07 02:11:48,622 INFO     Training average loss at step 31300: 0.107519\n",
      "2023-12-07 02:12:26,972 INFO     Training average positive_sample_loss at step 31400: 0.127853\n",
      "2023-12-07 02:12:26,973 INFO     Training average negative_sample_loss at step 31400: 0.090836\n",
      "2023-12-07 02:12:26,973 INFO     Training average loss at step 31400: 0.109344\n",
      "2023-12-07 02:13:09,017 INFO     Training average positive_sample_loss at step 31500: 0.127308\n",
      "2023-12-07 02:13:09,018 INFO     Training average negative_sample_loss at step 31500: 0.091836\n",
      "2023-12-07 02:13:09,018 INFO     Training average loss at step 31500: 0.109572\n",
      "2023-12-07 02:13:47,491 INFO     Training average positive_sample_loss at step 31600: 0.125495\n",
      "2023-12-07 02:13:47,491 INFO     Training average negative_sample_loss at step 31600: 0.089765\n",
      "2023-12-07 02:13:47,491 INFO     Training average loss at step 31600: 0.107630\n",
      "2023-12-07 02:14:26,410 INFO     Training average positive_sample_loss at step 31700: 0.128678\n",
      "2023-12-07 02:14:26,410 INFO     Training average negative_sample_loss at step 31700: 0.091073\n",
      "2023-12-07 02:14:26,410 INFO     Training average loss at step 31700: 0.109875\n",
      "2023-12-07 02:15:08,226 INFO     Training average positive_sample_loss at step 31800: 0.124033\n",
      "2023-12-07 02:15:08,226 INFO     Training average negative_sample_loss at step 31800: 0.090141\n",
      "2023-12-07 02:15:08,226 INFO     Training average loss at step 31800: 0.107087\n",
      "2023-12-07 02:15:46,548 INFO     Training average positive_sample_loss at step 31900: 0.127122\n",
      "2023-12-07 02:15:46,549 INFO     Training average negative_sample_loss at step 31900: 0.089684\n",
      "2023-12-07 02:15:46,549 INFO     Training average loss at step 31900: 0.108403\n",
      "2023-12-07 02:16:28,205 INFO     Training average positive_sample_loss at step 32000: 0.128414\n",
      "2023-12-07 02:16:28,205 INFO     Training average negative_sample_loss at step 32000: 0.091601\n",
      "2023-12-07 02:16:28,205 INFO     Training average loss at step 32000: 0.110008\n",
      "2023-12-07 02:17:07,165 INFO     Training average positive_sample_loss at step 32100: 0.123637\n",
      "2023-12-07 02:17:07,165 INFO     Training average negative_sample_loss at step 32100: 0.090151\n",
      "2023-12-07 02:17:07,165 INFO     Training average loss at step 32100: 0.106894\n",
      "2023-12-07 02:17:45,672 INFO     Training average positive_sample_loss at step 32200: 0.128969\n",
      "2023-12-07 02:17:45,672 INFO     Training average negative_sample_loss at step 32200: 0.091161\n",
      "2023-12-07 02:17:45,672 INFO     Training average loss at step 32200: 0.110065\n",
      "2023-12-07 02:18:27,029 INFO     Training average positive_sample_loss at step 32300: 0.125180\n",
      "2023-12-07 02:18:27,030 INFO     Training average negative_sample_loss at step 32300: 0.091413\n",
      "2023-12-07 02:18:27,030 INFO     Training average loss at step 32300: 0.108296\n",
      "2023-12-07 02:19:06,136 INFO     Training average positive_sample_loss at step 32400: 0.126897\n",
      "2023-12-07 02:19:06,136 INFO     Training average negative_sample_loss at step 32400: 0.090290\n",
      "2023-12-07 02:19:06,136 INFO     Training average loss at step 32400: 0.108594\n",
      "2023-12-07 02:19:44,299 INFO     Training average positive_sample_loss at step 32500: 0.129143\n",
      "2023-12-07 02:19:44,299 INFO     Training average negative_sample_loss at step 32500: 0.090757\n",
      "2023-12-07 02:19:44,299 INFO     Training average loss at step 32500: 0.109950\n",
      "2023-12-07 02:20:30,472 INFO     Training average positive_sample_loss at step 32600: 0.122710\n",
      "2023-12-07 02:20:30,473 INFO     Training average negative_sample_loss at step 32600: 0.089941\n",
      "2023-12-07 02:20:30,473 INFO     Training average loss at step 32600: 0.106325\n",
      "2023-12-07 02:21:09,727 INFO     Training average positive_sample_loss at step 32700: 0.128200\n",
      "2023-12-07 02:21:09,728 INFO     Training average negative_sample_loss at step 32700: 0.090225\n",
      "2023-12-07 02:21:09,728 INFO     Training average loss at step 32700: 0.109212\n",
      "2023-12-07 02:21:51,577 INFO     Training average positive_sample_loss at step 32800: 0.126156\n",
      "2023-12-07 02:21:51,577 INFO     Training average negative_sample_loss at step 32800: 0.091425\n",
      "2023-12-07 02:21:51,577 INFO     Training average loss at step 32800: 0.108791\n",
      "2023-12-07 02:22:30,226 INFO     Training average positive_sample_loss at step 32900: 0.125036\n",
      "2023-12-07 02:22:30,227 INFO     Training average negative_sample_loss at step 32900: 0.089362\n",
      "2023-12-07 02:22:30,227 INFO     Training average loss at step 32900: 0.107199\n",
      "2023-12-07 02:23:09,067 INFO     Training average positive_sample_loss at step 33000: 0.129498\n",
      "2023-12-07 02:23:09,067 INFO     Training average negative_sample_loss at step 33000: 0.090700\n",
      "2023-12-07 02:23:09,067 INFO     Training average loss at step 33000: 0.110099\n",
      "2023-12-07 02:23:51,024 INFO     Training average positive_sample_loss at step 33100: 0.122588\n",
      "2023-12-07 02:23:51,024 INFO     Training average negative_sample_loss at step 33100: 0.089811\n",
      "2023-12-07 02:23:51,024 INFO     Training average loss at step 33100: 0.106200\n",
      "2023-12-07 02:24:30,156 INFO     Training average positive_sample_loss at step 33200: 0.128672\n",
      "2023-12-07 02:24:30,157 INFO     Training average negative_sample_loss at step 33200: 0.090953\n",
      "2023-12-07 02:24:30,157 INFO     Training average loss at step 33200: 0.109813\n",
      "2023-12-07 02:25:12,382 INFO     Training average positive_sample_loss at step 33300: 0.126722\n",
      "2023-12-07 02:25:12,382 INFO     Training average negative_sample_loss at step 33300: 0.090903\n",
      "2023-12-07 02:25:12,382 INFO     Training average loss at step 33300: 0.108812\n",
      "2023-12-07 02:25:51,140 INFO     Training average positive_sample_loss at step 33400: 0.124184\n",
      "2023-12-07 02:25:51,140 INFO     Training average negative_sample_loss at step 33400: 0.089605\n",
      "2023-12-07 02:25:51,140 INFO     Training average loss at step 33400: 0.106895\n",
      "2023-12-07 02:26:29,849 INFO     Training average positive_sample_loss at step 33500: 0.129380\n",
      "2023-12-07 02:26:29,849 INFO     Training average negative_sample_loss at step 33500: 0.091072\n",
      "2023-12-07 02:26:29,849 INFO     Training average loss at step 33500: 0.110226\n",
      "2023-12-07 02:27:11,643 INFO     Training average positive_sample_loss at step 33600: 0.124072\n",
      "2023-12-07 02:27:11,643 INFO     Training average negative_sample_loss at step 33600: 0.091390\n",
      "2023-12-07 02:27:11,643 INFO     Training average loss at step 33600: 0.107731\n",
      "2023-12-07 02:27:50,292 INFO     Training average positive_sample_loss at step 33700: 0.127129\n",
      "2023-12-07 02:27:50,293 INFO     Training average negative_sample_loss at step 33700: 0.089643\n",
      "2023-12-07 02:27:50,293 INFO     Training average loss at step 33700: 0.108386\n",
      "2023-12-07 02:28:35,264 INFO     Training average positive_sample_loss at step 33800: 0.128785\n",
      "2023-12-07 02:28:35,264 INFO     Training average negative_sample_loss at step 33800: 0.090762\n",
      "2023-12-07 02:28:35,264 INFO     Training average loss at step 33800: 0.109773\n",
      "2023-12-07 02:29:13,632 INFO     Training average positive_sample_loss at step 33900: 0.122444\n",
      "2023-12-07 02:29:13,632 INFO     Training average negative_sample_loss at step 33900: 0.089430\n",
      "2023-12-07 02:29:13,632 INFO     Training average loss at step 33900: 0.105937\n",
      "2023-12-07 02:29:51,979 INFO     Training average positive_sample_loss at step 34000: 0.128647\n",
      "2023-12-07 02:29:51,979 INFO     Training average negative_sample_loss at step 34000: 0.090724\n",
      "2023-12-07 02:29:51,979 INFO     Training average loss at step 34000: 0.109686\n",
      "2023-12-07 02:30:34,692 INFO     Training average positive_sample_loss at step 34100: 0.125114\n",
      "2023-12-07 02:30:34,692 INFO     Training average negative_sample_loss at step 34100: 0.090913\n",
      "2023-12-07 02:30:34,692 INFO     Training average loss at step 34100: 0.108014\n",
      "2023-12-07 02:31:13,658 INFO     Training average positive_sample_loss at step 34200: 0.126418\n",
      "2023-12-07 02:31:13,658 INFO     Training average negative_sample_loss at step 34200: 0.089779\n",
      "2023-12-07 02:31:13,658 INFO     Training average loss at step 34200: 0.108098\n",
      "2023-12-07 02:31:52,357 INFO     Training average positive_sample_loss at step 34300: 0.128616\n",
      "2023-12-07 02:31:52,357 INFO     Training average negative_sample_loss at step 34300: 0.091430\n",
      "2023-12-07 02:31:52,357 INFO     Training average loss at step 34300: 0.110023\n",
      "2023-12-07 02:32:35,283 INFO     Training average positive_sample_loss at step 34400: 0.123406\n",
      "2023-12-07 02:32:35,283 INFO     Training average negative_sample_loss at step 34400: 0.089491\n",
      "2023-12-07 02:32:35,283 INFO     Training average loss at step 34400: 0.106448\n",
      "2023-12-07 02:33:14,392 INFO     Training average positive_sample_loss at step 34500: 0.127430\n",
      "2023-12-07 02:33:14,392 INFO     Training average negative_sample_loss at step 34500: 0.089717\n",
      "2023-12-07 02:33:14,392 INFO     Training average loss at step 34500: 0.108573\n",
      "2023-12-07 02:33:56,926 INFO     Training average positive_sample_loss at step 34600: 0.125643\n",
      "2023-12-07 02:33:56,926 INFO     Training average negative_sample_loss at step 34600: 0.090833\n",
      "2023-12-07 02:33:56,926 INFO     Training average loss at step 34600: 0.108238\n",
      "2023-12-07 02:34:35,222 INFO     Training average positive_sample_loss at step 34700: 0.125019\n",
      "2023-12-07 02:34:35,223 INFO     Training average negative_sample_loss at step 34700: 0.088998\n",
      "2023-12-07 02:34:35,223 INFO     Training average loss at step 34700: 0.107009\n",
      "2023-12-07 02:35:13,826 INFO     Training average positive_sample_loss at step 34800: 0.128756\n",
      "2023-12-07 02:35:13,826 INFO     Training average negative_sample_loss at step 34800: 0.090900\n",
      "2023-12-07 02:35:13,826 INFO     Training average loss at step 34800: 0.109828\n",
      "2023-12-07 02:35:55,741 INFO     Training average positive_sample_loss at step 34900: 0.123404\n",
      "2023-12-07 02:35:55,742 INFO     Training average negative_sample_loss at step 34900: 0.090505\n",
      "2023-12-07 02:35:55,742 INFO     Training average loss at step 34900: 0.106955\n",
      "2023-12-07 02:36:34,151 INFO     Training average positive_sample_loss at step 35000: 0.127348\n",
      "2023-12-07 02:36:34,151 INFO     Training average negative_sample_loss at step 35000: 0.089746\n",
      "2023-12-07 02:36:34,151 INFO     Training average loss at step 35000: 0.108547\n",
      "2023-12-07 02:37:19,415 INFO     Training average positive_sample_loss at step 35100: 0.127798\n",
      "2023-12-07 02:37:19,415 INFO     Training average negative_sample_loss at step 35100: 0.091201\n",
      "2023-12-07 02:37:19,415 INFO     Training average loss at step 35100: 0.109499\n",
      "2023-12-07 02:37:58,151 INFO     Training average positive_sample_loss at step 35200: 0.123913\n",
      "2023-12-07 02:37:58,152 INFO     Training average negative_sample_loss at step 35200: 0.089188\n",
      "2023-12-07 02:37:58,152 INFO     Training average loss at step 35200: 0.106550\n",
      "2023-12-07 02:38:36,966 INFO     Training average positive_sample_loss at step 35300: 0.128130\n",
      "2023-12-07 02:38:36,966 INFO     Training average negative_sample_loss at step 35300: 0.090667\n",
      "2023-12-07 02:38:36,966 INFO     Training average loss at step 35300: 0.109398\n",
      "2023-12-07 02:39:18,874 INFO     Training average positive_sample_loss at step 35400: 0.124356\n",
      "2023-12-07 02:39:18,874 INFO     Training average negative_sample_loss at step 35400: 0.091387\n",
      "2023-12-07 02:39:18,874 INFO     Training average loss at step 35400: 0.107871\n",
      "2023-12-07 02:39:57,819 INFO     Training average positive_sample_loss at step 35500: 0.126278\n",
      "2023-12-07 02:39:57,819 INFO     Training average negative_sample_loss at step 35500: 0.089283\n",
      "2023-12-07 02:39:57,819 INFO     Training average loss at step 35500: 0.107781\n",
      "2023-12-07 02:40:36,392 INFO     Training average positive_sample_loss at step 35600: 0.129216\n",
      "2023-12-07 02:40:36,392 INFO     Training average negative_sample_loss at step 35600: 0.091185\n",
      "2023-12-07 02:40:36,392 INFO     Training average loss at step 35600: 0.110201\n",
      "2023-12-07 02:41:18,470 INFO     Training average positive_sample_loss at step 35700: 0.122291\n",
      "2023-12-07 02:41:18,471 INFO     Training average negative_sample_loss at step 35700: 0.089663\n",
      "2023-12-07 02:41:18,471 INFO     Training average loss at step 35700: 0.105977\n",
      "2023-12-07 02:41:57,282 INFO     Training average positive_sample_loss at step 35800: 0.128208\n",
      "2023-12-07 02:41:57,282 INFO     Training average negative_sample_loss at step 35800: 0.090181\n",
      "2023-12-07 02:41:57,282 INFO     Training average loss at step 35800: 0.109194\n",
      "2023-12-07 02:42:39,104 INFO     Training average positive_sample_loss at step 35900: 0.125151\n",
      "2023-12-07 02:42:39,105 INFO     Training average negative_sample_loss at step 35900: 0.091217\n",
      "2023-12-07 02:42:39,105 INFO     Training average loss at step 35900: 0.108184\n",
      "2023-12-07 02:43:17,317 INFO     Training average positive_sample_loss at step 36000: 0.125493\n",
      "2023-12-07 02:43:17,317 INFO     Training average negative_sample_loss at step 36000: 0.089014\n",
      "2023-12-07 02:43:17,317 INFO     Training average loss at step 36000: 0.107253\n",
      "2023-12-07 02:43:55,596 INFO     Training average positive_sample_loss at step 36100: 0.128914\n",
      "2023-12-07 02:43:55,596 INFO     Training average negative_sample_loss at step 36100: 0.090934\n",
      "2023-12-07 02:43:55,596 INFO     Training average loss at step 36100: 0.109924\n",
      "2023-12-07 02:44:37,235 INFO     Training average positive_sample_loss at step 36200: 0.122917\n",
      "2023-12-07 02:44:37,235 INFO     Training average negative_sample_loss at step 36200: 0.089653\n",
      "2023-12-07 02:44:37,235 INFO     Training average loss at step 36200: 0.106285\n",
      "2023-12-07 02:45:16,228 INFO     Training average positive_sample_loss at step 36300: 0.127202\n",
      "2023-12-07 02:45:16,228 INFO     Training average negative_sample_loss at step 36300: 0.089555\n",
      "2023-12-07 02:45:16,228 INFO     Training average loss at step 36300: 0.108379\n",
      "2023-12-07 02:46:01,436 INFO     Training average positive_sample_loss at step 36400: 0.126542\n",
      "2023-12-07 02:46:01,436 INFO     Training average negative_sample_loss at step 36400: 0.091377\n",
      "2023-12-07 02:46:01,436 INFO     Training average loss at step 36400: 0.108960\n",
      "2023-12-07 02:46:40,036 INFO     Training average positive_sample_loss at step 36500: 0.124023\n",
      "2023-12-07 02:46:40,036 INFO     Training average negative_sample_loss at step 36500: 0.088984\n",
      "2023-12-07 02:46:40,036 INFO     Training average loss at step 36500: 0.106503\n",
      "2023-12-07 02:47:18,341 INFO     Training average positive_sample_loss at step 36600: 0.127809\n",
      "2023-12-07 02:47:18,341 INFO     Training average negative_sample_loss at step 36600: 0.089729\n",
      "2023-12-07 02:47:18,341 INFO     Training average loss at step 36600: 0.108769\n",
      "2023-12-07 02:48:00,102 INFO     Training average positive_sample_loss at step 36700: 0.123844\n",
      "2023-12-07 02:48:00,103 INFO     Training average negative_sample_loss at step 36700: 0.090375\n",
      "2023-12-07 02:48:00,103 INFO     Training average loss at step 36700: 0.107110\n",
      "2023-12-07 02:48:38,816 INFO     Training average positive_sample_loss at step 36800: 0.126635\n",
      "2023-12-07 02:48:38,816 INFO     Training average negative_sample_loss at step 36800: 0.089381\n",
      "2023-12-07 02:48:38,816 INFO     Training average loss at step 36800: 0.108008\n",
      "2023-12-07 02:49:20,762 INFO     Training average positive_sample_loss at step 36900: 0.127979\n",
      "2023-12-07 02:49:20,763 INFO     Training average negative_sample_loss at step 36900: 0.090711\n",
      "2023-12-07 02:49:20,763 INFO     Training average loss at step 36900: 0.109345\n",
      "2023-12-07 02:49:59,782 INFO     Training average positive_sample_loss at step 37000: 0.122937\n",
      "2023-12-07 02:49:59,782 INFO     Training average negative_sample_loss at step 37000: 0.088991\n",
      "2023-12-07 02:49:59,782 INFO     Training average loss at step 37000: 0.105964\n",
      "2023-12-07 02:50:38,225 INFO     Training average positive_sample_loss at step 37100: 0.127885\n",
      "2023-12-07 02:50:38,225 INFO     Training average negative_sample_loss at step 37100: 0.089869\n",
      "2023-12-07 02:50:38,225 INFO     Training average loss at step 37100: 0.108877\n",
      "2023-12-07 02:51:19,827 INFO     Training average positive_sample_loss at step 37200: 0.124574\n",
      "2023-12-07 02:51:19,827 INFO     Training average negative_sample_loss at step 37200: 0.091262\n",
      "2023-12-07 02:51:19,827 INFO     Training average loss at step 37200: 0.107918\n",
      "2023-12-07 02:51:58,149 INFO     Training average positive_sample_loss at step 37300: 0.125790\n",
      "2023-12-07 02:51:58,149 INFO     Training average negative_sample_loss at step 37300: 0.088782\n",
      "2023-12-07 02:51:58,149 INFO     Training average loss at step 37300: 0.107286\n",
      "2023-12-07 02:52:36,611 INFO     Training average positive_sample_loss at step 37400: 0.128417\n",
      "2023-12-07 02:52:36,611 INFO     Training average negative_sample_loss at step 37400: 0.090308\n",
      "2023-12-07 02:52:36,611 INFO     Training average loss at step 37400: 0.109363\n",
      "2023-12-07 02:53:18,051 INFO     Training average positive_sample_loss at step 37500: 0.122615\n",
      "2023-12-07 02:53:18,051 INFO     Training average negative_sample_loss at step 37500: 0.089859\n",
      "2023-12-07 02:53:18,051 INFO     Training average loss at step 37500: 0.106237\n",
      "2023-12-07 02:53:56,625 INFO     Training average positive_sample_loss at step 37600: 0.127668\n",
      "2023-12-07 02:53:56,625 INFO     Training average negative_sample_loss at step 37600: 0.090350\n",
      "2023-12-07 02:53:56,625 INFO     Training average loss at step 37600: 0.109009\n",
      "2023-12-07 02:54:41,689 INFO     Training average positive_sample_loss at step 37700: 0.125059\n",
      "2023-12-07 02:54:41,689 INFO     Training average negative_sample_loss at step 37700: 0.090930\n",
      "2023-12-07 02:54:41,689 INFO     Training average loss at step 37700: 0.107994\n",
      "2023-12-07 02:55:20,016 INFO     Training average positive_sample_loss at step 37800: 0.125296\n",
      "2023-12-07 02:55:20,016 INFO     Training average negative_sample_loss at step 37800: 0.089778\n",
      "2023-12-07 02:55:20,016 INFO     Training average loss at step 37800: 0.107537\n",
      "2023-12-07 02:55:58,453 INFO     Training average positive_sample_loss at step 37900: 0.128797\n",
      "2023-12-07 02:55:58,454 INFO     Training average negative_sample_loss at step 37900: 0.090825\n",
      "2023-12-07 02:55:58,454 INFO     Training average loss at step 37900: 0.109811\n",
      "2023-12-07 02:56:40,221 INFO     Training average positive_sample_loss at step 38000: 0.123057\n",
      "2023-12-07 02:56:40,221 INFO     Training average negative_sample_loss at step 38000: 0.090603\n",
      "2023-12-07 02:56:40,221 INFO     Training average loss at step 38000: 0.106830\n",
      "2023-12-07 02:57:18,971 INFO     Training average positive_sample_loss at step 38100: 0.127090\n",
      "2023-12-07 02:57:18,971 INFO     Training average negative_sample_loss at step 38100: 0.090157\n",
      "2023-12-07 02:57:18,971 INFO     Training average loss at step 38100: 0.108623\n",
      "2023-12-07 02:58:01,066 INFO     Training average positive_sample_loss at step 38200: 0.126873\n",
      "2023-12-07 02:58:01,066 INFO     Training average negative_sample_loss at step 38200: 0.091243\n",
      "2023-12-07 02:58:01,066 INFO     Training average loss at step 38200: 0.109058\n",
      "2023-12-07 02:58:39,778 INFO     Training average positive_sample_loss at step 38300: 0.124022\n",
      "2023-12-07 02:58:39,779 INFO     Training average negative_sample_loss at step 38300: 0.089683\n",
      "2023-12-07 02:58:39,779 INFO     Training average loss at step 38300: 0.106852\n",
      "2023-12-07 02:59:19,054 INFO     Training average positive_sample_loss at step 38400: 0.127701\n",
      "2023-12-07 02:59:19,054 INFO     Training average negative_sample_loss at step 38400: 0.089138\n",
      "2023-12-07 02:59:19,054 INFO     Training average loss at step 38400: 0.108420\n",
      "2023-12-07 03:00:00,791 INFO     Training average positive_sample_loss at step 38500: 0.124056\n",
      "2023-12-07 03:00:00,792 INFO     Training average negative_sample_loss at step 38500: 0.090300\n",
      "2023-12-07 03:00:00,792 INFO     Training average loss at step 38500: 0.107178\n",
      "2023-12-07 03:00:39,424 INFO     Training average positive_sample_loss at step 38600: 0.125972\n",
      "2023-12-07 03:00:39,424 INFO     Training average negative_sample_loss at step 38600: 0.089736\n",
      "2023-12-07 03:00:39,424 INFO     Training average loss at step 38600: 0.107854\n",
      "2023-12-07 03:01:20,042 INFO     Training average positive_sample_loss at step 38700: 0.128473\n",
      "2023-12-07 03:01:20,042 INFO     Training average negative_sample_loss at step 38700: 0.090781\n",
      "2023-12-07 03:01:20,042 INFO     Training average loss at step 38700: 0.109627\n",
      "2023-12-07 03:01:59,354 INFO     Training average positive_sample_loss at step 38800: 0.122304\n",
      "2023-12-07 03:01:59,354 INFO     Training average negative_sample_loss at step 38800: 0.089074\n",
      "2023-12-07 03:01:59,354 INFO     Training average loss at step 38800: 0.105689\n",
      "2023-12-07 03:02:38,431 INFO     Training average positive_sample_loss at step 38900: 0.127665\n",
      "2023-12-07 03:02:38,431 INFO     Training average negative_sample_loss at step 38900: 0.089435\n",
      "2023-12-07 03:02:38,431 INFO     Training average loss at step 38900: 0.108550\n",
      "2023-12-07 03:03:23,585 INFO     Training average positive_sample_loss at step 39000: 0.123661\n",
      "2023-12-07 03:03:23,585 INFO     Training average negative_sample_loss at step 39000: 0.089570\n",
      "2023-12-07 03:03:23,585 INFO     Training average loss at step 39000: 0.106615\n",
      "2023-12-07 03:04:01,842 INFO     Training average positive_sample_loss at step 39100: 0.125324\n",
      "2023-12-07 03:04:01,842 INFO     Training average negative_sample_loss at step 39100: 0.089014\n",
      "2023-12-07 03:04:01,842 INFO     Training average loss at step 39100: 0.107169\n",
      "2023-12-07 03:04:39,528 INFO     Training average positive_sample_loss at step 39200: 0.128177\n",
      "2023-12-07 03:04:39,528 INFO     Training average negative_sample_loss at step 39200: 0.090533\n",
      "2023-12-07 03:04:39,528 INFO     Training average loss at step 39200: 0.109355\n",
      "2023-12-07 03:05:22,622 INFO     Training average positive_sample_loss at step 39300: 0.122512\n",
      "2023-12-07 03:05:22,623 INFO     Training average negative_sample_loss at step 39300: 0.089287\n",
      "2023-12-07 03:05:22,623 INFO     Training average loss at step 39300: 0.105900\n",
      "2023-12-07 03:06:01,015 INFO     Training average positive_sample_loss at step 39400: 0.126975\n",
      "2023-12-07 03:06:01,015 INFO     Training average negative_sample_loss at step 39400: 0.089279\n",
      "2023-12-07 03:06:01,015 INFO     Training average loss at step 39400: 0.108127\n",
      "2023-12-07 03:06:42,863 INFO     Training average positive_sample_loss at step 39500: 0.125513\n",
      "2023-12-07 03:06:42,864 INFO     Training average negative_sample_loss at step 39500: 0.090536\n",
      "2023-12-07 03:06:42,864 INFO     Training average loss at step 39500: 0.108024\n",
      "2023-12-07 03:07:21,412 INFO     Training average positive_sample_loss at step 39600: 0.124416\n",
      "2023-12-07 03:07:21,413 INFO     Training average negative_sample_loss at step 39600: 0.088255\n",
      "2023-12-07 03:07:21,413 INFO     Training average loss at step 39600: 0.106335\n",
      "2023-12-07 03:08:00,327 INFO     Training average positive_sample_loss at step 39700: 0.127814\n",
      "2023-12-07 03:08:00,327 INFO     Training average negative_sample_loss at step 39700: 0.090342\n",
      "2023-12-07 03:08:00,327 INFO     Training average loss at step 39700: 0.109078\n",
      "2023-12-07 03:08:41,840 INFO     Training average positive_sample_loss at step 39800: 0.122992\n",
      "2023-12-07 03:08:41,841 INFO     Training average negative_sample_loss at step 39800: 0.090572\n",
      "2023-12-07 03:08:41,841 INFO     Training average loss at step 39800: 0.106782\n",
      "2023-12-07 03:09:20,430 INFO     Training average positive_sample_loss at step 39900: 0.126690\n",
      "2023-12-07 03:09:20,430 INFO     Training average negative_sample_loss at step 39900: 0.088829\n",
      "2023-12-07 03:09:20,430 INFO     Training average loss at step 39900: 0.107760\n",
      "2023-12-07 03:10:15,373 INFO     Training average positive_sample_loss at step 40000: 0.127339\n",
      "2023-12-07 03:10:15,374 INFO     Training average negative_sample_loss at step 40000: 0.090299\n",
      "2023-12-07 03:10:15,374 INFO     Training average loss at step 40000: 0.108819\n",
      "2023-12-07 03:10:15,374 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 03:10:15,852 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 03:10:43,371 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 03:10:59,687 INFO     Valid MRR at step 40000: 0.540580\n",
      "2023-12-07 03:10:59,687 INFO     Valid MR at step 40000: 260.561191\n",
      "2023-12-07 03:10:59,687 INFO     Valid HITS@1 at step 40000: 0.472201\n",
      "2023-12-07 03:10:59,687 INFO     Valid HITS@3 at step 40000: 0.571765\n",
      "2023-12-07 03:10:59,687 INFO     Valid HITS@10 at step 40000: 0.667781\n",
      "2023-12-07 03:11:31,437 INFO     Training average positive_sample_loss at step 40100: 0.122914\n",
      "2023-12-07 03:11:31,437 INFO     Training average negative_sample_loss at step 40100: 0.088543\n",
      "2023-12-07 03:11:31,437 INFO     Training average loss at step 40100: 0.105728\n",
      "2023-12-07 03:12:09,984 INFO     Training average positive_sample_loss at step 40200: 0.127525\n",
      "2023-12-07 03:12:09,984 INFO     Training average negative_sample_loss at step 40200: 0.089661\n",
      "2023-12-07 03:12:09,984 INFO     Training average loss at step 40200: 0.108593\n",
      "2023-12-07 03:12:54,261 INFO     Training average positive_sample_loss at step 40300: 0.123513\n",
      "2023-12-07 03:12:54,261 INFO     Training average negative_sample_loss at step 40300: 0.089991\n",
      "2023-12-07 03:12:54,261 INFO     Training average loss at step 40300: 0.106752\n",
      "2023-12-07 03:13:32,605 INFO     Training average positive_sample_loss at step 40400: 0.126153\n",
      "2023-12-07 03:13:32,606 INFO     Training average negative_sample_loss at step 40400: 0.089187\n",
      "2023-12-07 03:13:32,606 INFO     Training average loss at step 40400: 0.107670\n",
      "2023-12-07 03:14:10,598 INFO     Training average positive_sample_loss at step 40500: 0.127932\n",
      "2023-12-07 03:14:10,599 INFO     Training average negative_sample_loss at step 40500: 0.090381\n",
      "2023-12-07 03:14:10,599 INFO     Training average loss at step 40500: 0.109156\n",
      "2023-12-07 03:14:52,733 INFO     Training average positive_sample_loss at step 40600: 0.121896\n",
      "2023-12-07 03:14:52,733 INFO     Training average negative_sample_loss at step 40600: 0.088285\n",
      "2023-12-07 03:14:52,734 INFO     Training average loss at step 40600: 0.105091\n",
      "2023-12-07 03:15:31,506 INFO     Training average positive_sample_loss at step 40700: 0.127487\n",
      "2023-12-07 03:15:31,506 INFO     Training average negative_sample_loss at step 40700: 0.090231\n",
      "2023-12-07 03:15:31,506 INFO     Training average loss at step 40700: 0.108859\n",
      "2023-12-07 03:16:13,099 INFO     Training average positive_sample_loss at step 40800: 0.124494\n",
      "2023-12-07 03:16:13,099 INFO     Training average negative_sample_loss at step 40800: 0.090534\n",
      "2023-12-07 03:16:13,099 INFO     Training average loss at step 40800: 0.107514\n",
      "2023-12-07 03:16:51,409 INFO     Training average positive_sample_loss at step 40900: 0.125251\n",
      "2023-12-07 03:16:51,409 INFO     Training average negative_sample_loss at step 40900: 0.088304\n",
      "2023-12-07 03:16:51,409 INFO     Training average loss at step 40900: 0.106777\n",
      "2023-12-07 03:17:29,963 INFO     Training average positive_sample_loss at step 41000: 0.127849\n",
      "2023-12-07 03:17:29,963 INFO     Training average negative_sample_loss at step 41000: 0.090544\n",
      "2023-12-07 03:17:29,963 INFO     Training average loss at step 41000: 0.109197\n",
      "2023-12-07 03:18:11,353 INFO     Training average positive_sample_loss at step 41100: 0.122603\n",
      "2023-12-07 03:18:11,353 INFO     Training average negative_sample_loss at step 41100: 0.089777\n",
      "2023-12-07 03:18:11,353 INFO     Training average loss at step 41100: 0.106190\n",
      "2023-12-07 03:18:50,007 INFO     Training average positive_sample_loss at step 41200: 0.126398\n",
      "2023-12-07 03:18:50,007 INFO     Training average negative_sample_loss at step 41200: 0.088987\n",
      "2023-12-07 03:18:50,007 INFO     Training average loss at step 41200: 0.107693\n",
      "2023-12-07 03:19:31,932 INFO     Training average positive_sample_loss at step 41300: 0.125942\n",
      "2023-12-07 03:19:31,932 INFO     Training average negative_sample_loss at step 41300: 0.090274\n",
      "2023-12-07 03:19:31,932 INFO     Training average loss at step 41300: 0.108108\n",
      "2023-12-07 03:20:10,887 INFO     Training average positive_sample_loss at step 41400: 0.123322\n",
      "2023-12-07 03:20:10,887 INFO     Training average negative_sample_loss at step 41400: 0.087709\n",
      "2023-12-07 03:20:10,887 INFO     Training average loss at step 41400: 0.105515\n",
      "2023-12-07 03:20:49,757 INFO     Training average positive_sample_loss at step 41500: 0.128234\n",
      "2023-12-07 03:20:49,758 INFO     Training average negative_sample_loss at step 41500: 0.090870\n",
      "2023-12-07 03:20:49,758 INFO     Training average loss at step 41500: 0.109552\n",
      "2023-12-07 03:21:34,532 INFO     Training average positive_sample_loss at step 41600: 0.122887\n",
      "2023-12-07 03:21:34,532 INFO     Training average negative_sample_loss at step 41600: 0.089972\n",
      "2023-12-07 03:21:34,532 INFO     Training average loss at step 41600: 0.106429\n",
      "2023-12-07 03:22:12,885 INFO     Training average positive_sample_loss at step 41700: 0.126059\n",
      "2023-12-07 03:22:12,886 INFO     Training average negative_sample_loss at step 41700: 0.088800\n",
      "2023-12-07 03:22:12,886 INFO     Training average loss at step 41700: 0.107429\n",
      "2023-12-07 03:22:55,422 INFO     Training average positive_sample_loss at step 41800: 0.127949\n",
      "2023-12-07 03:22:55,422 INFO     Training average negative_sample_loss at step 41800: 0.090630\n",
      "2023-12-07 03:22:55,422 INFO     Training average loss at step 41800: 0.109290\n",
      "2023-12-07 03:23:33,979 INFO     Training average positive_sample_loss at step 41900: 0.122050\n",
      "2023-12-07 03:23:33,979 INFO     Training average negative_sample_loss at step 41900: 0.088334\n",
      "2023-12-07 03:23:33,979 INFO     Training average loss at step 41900: 0.105192\n",
      "2023-12-07 03:24:12,530 INFO     Training average positive_sample_loss at step 42000: 0.127593\n",
      "2023-12-07 03:24:12,531 INFO     Training average negative_sample_loss at step 42000: 0.090008\n",
      "2023-12-07 03:24:12,531 INFO     Training average loss at step 42000: 0.108800\n",
      "2023-12-07 03:24:53,850 INFO     Training average positive_sample_loss at step 42100: 0.123681\n",
      "2023-12-07 03:24:53,851 INFO     Training average negative_sample_loss at step 42100: 0.090126\n",
      "2023-12-07 03:24:53,851 INFO     Training average loss at step 42100: 0.106904\n",
      "2023-12-07 03:25:32,783 INFO     Training average positive_sample_loss at step 42200: 0.125133\n",
      "2023-12-07 03:25:32,784 INFO     Training average negative_sample_loss at step 42200: 0.087978\n",
      "2023-12-07 03:25:32,784 INFO     Training average loss at step 42200: 0.106556\n",
      "2023-12-07 03:26:11,078 INFO     Training average positive_sample_loss at step 42300: 0.128226\n",
      "2023-12-07 03:26:11,078 INFO     Training average negative_sample_loss at step 42300: 0.090312\n",
      "2023-12-07 03:26:11,078 INFO     Training average loss at step 42300: 0.109269\n",
      "2023-12-07 03:26:52,920 INFO     Training average positive_sample_loss at step 42400: 0.122225\n",
      "2023-12-07 03:26:52,920 INFO     Training average negative_sample_loss at step 42400: 0.089526\n",
      "2023-12-07 03:26:52,921 INFO     Training average loss at step 42400: 0.105875\n",
      "2023-12-07 03:27:31,657 INFO     Training average positive_sample_loss at step 42500: 0.126302\n",
      "2023-12-07 03:27:31,657 INFO     Training average negative_sample_loss at step 42500: 0.089074\n",
      "2023-12-07 03:27:31,657 INFO     Training average loss at step 42500: 0.107688\n",
      "2023-12-07 03:28:13,958 INFO     Training average positive_sample_loss at step 42600: 0.125219\n",
      "2023-12-07 03:28:13,958 INFO     Training average negative_sample_loss at step 42600: 0.090245\n",
      "2023-12-07 03:28:13,958 INFO     Training average loss at step 42600: 0.107732\n",
      "2023-12-07 03:28:52,637 INFO     Training average positive_sample_loss at step 42700: 0.124185\n",
      "2023-12-07 03:28:52,637 INFO     Training average negative_sample_loss at step 42700: 0.087539\n",
      "2023-12-07 03:28:52,637 INFO     Training average loss at step 42700: 0.105862\n",
      "2023-12-07 03:29:31,455 INFO     Training average positive_sample_loss at step 42800: 0.127760\n",
      "2023-12-07 03:29:31,455 INFO     Training average negative_sample_loss at step 42800: 0.089824\n",
      "2023-12-07 03:29:31,455 INFO     Training average loss at step 42800: 0.108792\n",
      "2023-12-07 03:30:16,221 INFO     Training average positive_sample_loss at step 42900: 0.122322\n",
      "2023-12-07 03:30:16,221 INFO     Training average negative_sample_loss at step 42900: 0.089508\n",
      "2023-12-07 03:30:16,221 INFO     Training average loss at step 42900: 0.105915\n",
      "2023-12-07 03:30:54,835 INFO     Training average positive_sample_loss at step 43000: 0.126315\n",
      "2023-12-07 03:30:54,835 INFO     Training average negative_sample_loss at step 43000: 0.088541\n",
      "2023-12-07 03:30:54,835 INFO     Training average loss at step 43000: 0.107428\n",
      "2023-12-07 03:31:36,341 INFO     Training average positive_sample_loss at step 43100: 0.126379\n",
      "2023-12-07 03:31:36,342 INFO     Training average negative_sample_loss at step 43100: 0.090589\n",
      "2023-12-07 03:31:36,342 INFO     Training average loss at step 43100: 0.108484\n",
      "2023-12-07 03:32:14,719 INFO     Training average positive_sample_loss at step 43200: 0.123364\n",
      "2023-12-07 03:32:14,719 INFO     Training average negative_sample_loss at step 43200: 0.088631\n",
      "2023-12-07 03:32:14,719 INFO     Training average loss at step 43200: 0.105998\n",
      "2023-12-07 03:32:53,131 INFO     Training average positive_sample_loss at step 43300: 0.127135\n",
      "2023-12-07 03:32:53,131 INFO     Training average negative_sample_loss at step 43300: 0.089927\n",
      "2023-12-07 03:32:53,131 INFO     Training average loss at step 43300: 0.108531\n",
      "2023-12-07 03:33:35,519 INFO     Training average positive_sample_loss at step 43400: 0.123207\n",
      "2023-12-07 03:33:35,520 INFO     Training average negative_sample_loss at step 43400: 0.089973\n",
      "2023-12-07 03:33:35,520 INFO     Training average loss at step 43400: 0.106590\n",
      "2023-12-07 03:34:14,896 INFO     Training average positive_sample_loss at step 43500: 0.126204\n",
      "2023-12-07 03:34:14,897 INFO     Training average negative_sample_loss at step 43500: 0.089537\n",
      "2023-12-07 03:34:14,897 INFO     Training average loss at step 43500: 0.107871\n",
      "2023-12-07 03:34:53,918 INFO     Training average positive_sample_loss at step 43600: 0.127964\n",
      "2023-12-07 03:34:53,918 INFO     Training average negative_sample_loss at step 43600: 0.089571\n",
      "2023-12-07 03:34:53,918 INFO     Training average loss at step 43600: 0.108768\n",
      "2023-12-07 03:35:35,513 INFO     Training average positive_sample_loss at step 43700: 0.120836\n",
      "2023-12-07 03:35:35,513 INFO     Training average negative_sample_loss at step 43700: 0.088434\n",
      "2023-12-07 03:35:35,514 INFO     Training average loss at step 43700: 0.104635\n",
      "2023-12-07 03:36:14,183 INFO     Training average positive_sample_loss at step 43800: 0.127130\n",
      "2023-12-07 03:36:14,183 INFO     Training average negative_sample_loss at step 43800: 0.088872\n",
      "2023-12-07 03:36:14,184 INFO     Training average loss at step 43800: 0.108001\n",
      "2023-12-07 03:36:56,237 INFO     Training average positive_sample_loss at step 43900: 0.124771\n",
      "2023-12-07 03:36:56,238 INFO     Training average negative_sample_loss at step 43900: 0.091220\n",
      "2023-12-07 03:36:56,238 INFO     Training average loss at step 43900: 0.107995\n",
      "2023-12-07 03:37:34,745 INFO     Training average positive_sample_loss at step 44000: 0.124553\n",
      "2023-12-07 03:37:34,745 INFO     Training average negative_sample_loss at step 44000: 0.088636\n",
      "2023-12-07 03:37:34,745 INFO     Training average loss at step 44000: 0.106595\n",
      "2023-12-07 03:38:13,453 INFO     Training average positive_sample_loss at step 44100: 0.128081\n",
      "2023-12-07 03:38:13,453 INFO     Training average negative_sample_loss at step 44100: 0.089870\n",
      "2023-12-07 03:38:13,453 INFO     Training average loss at step 44100: 0.108976\n",
      "2023-12-07 03:38:58,099 INFO     Training average positive_sample_loss at step 44200: 0.122175\n",
      "2023-12-07 03:38:58,099 INFO     Training average negative_sample_loss at step 44200: 0.089551\n",
      "2023-12-07 03:38:58,099 INFO     Training average loss at step 44200: 0.105863\n",
      "2023-12-07 03:39:36,845 INFO     Training average positive_sample_loss at step 44300: 0.126569\n",
      "2023-12-07 03:39:36,845 INFO     Training average negative_sample_loss at step 44300: 0.089080\n",
      "2023-12-07 03:39:36,845 INFO     Training average loss at step 44300: 0.107825\n",
      "2023-12-07 03:40:18,434 INFO     Training average positive_sample_loss at step 44400: 0.125169\n",
      "2023-12-07 03:40:18,434 INFO     Training average negative_sample_loss at step 44400: 0.089834\n",
      "2023-12-07 03:40:18,434 INFO     Training average loss at step 44400: 0.107502\n",
      "2023-12-07 03:40:56,775 INFO     Training average positive_sample_loss at step 44500: 0.123825\n",
      "2023-12-07 03:40:56,775 INFO     Training average negative_sample_loss at step 44500: 0.089020\n",
      "2023-12-07 03:40:56,775 INFO     Training average loss at step 44500: 0.106422\n",
      "2023-12-07 03:41:35,183 INFO     Training average positive_sample_loss at step 44600: 0.127858\n",
      "2023-12-07 03:41:35,183 INFO     Training average negative_sample_loss at step 44600: 0.089917\n",
      "2023-12-07 03:41:35,183 INFO     Training average loss at step 44600: 0.108888\n",
      "2023-12-07 03:42:17,778 INFO     Training average positive_sample_loss at step 44700: 0.122851\n",
      "2023-12-07 03:42:17,778 INFO     Training average negative_sample_loss at step 44700: 0.090073\n",
      "2023-12-07 03:42:17,778 INFO     Training average loss at step 44700: 0.106462\n",
      "2023-12-07 03:42:56,635 INFO     Training average positive_sample_loss at step 44800: 0.126268\n",
      "2023-12-07 03:42:56,635 INFO     Training average negative_sample_loss at step 44800: 0.088244\n",
      "2023-12-07 03:42:56,635 INFO     Training average loss at step 44800: 0.107256\n",
      "2023-12-07 03:43:38,309 INFO     Training average positive_sample_loss at step 44900: 0.126197\n",
      "2023-12-07 03:43:38,310 INFO     Training average negative_sample_loss at step 44900: 0.089483\n",
      "2023-12-07 03:43:38,310 INFO     Training average loss at step 44900: 0.107840\n",
      "2023-12-07 03:44:16,730 INFO     Training average positive_sample_loss at step 45000: 0.122544\n",
      "2023-12-07 03:44:16,730 INFO     Training average negative_sample_loss at step 45000: 0.089014\n",
      "2023-12-07 03:44:16,730 INFO     Training average loss at step 45000: 0.105779\n",
      "2023-12-07 03:44:56,116 INFO     Training average positive_sample_loss at step 45100: 0.126821\n",
      "2023-12-07 03:44:56,116 INFO     Training average negative_sample_loss at step 45100: 0.088828\n",
      "2023-12-07 03:44:56,116 INFO     Training average loss at step 45100: 0.107824\n",
      "2023-12-07 03:45:38,104 INFO     Training average positive_sample_loss at step 45200: 0.123443\n",
      "2023-12-07 03:45:38,105 INFO     Training average negative_sample_loss at step 45200: 0.089787\n",
      "2023-12-07 03:45:38,105 INFO     Training average loss at step 45200: 0.106615\n",
      "2023-12-07 03:46:16,475 INFO     Training average positive_sample_loss at step 45300: 0.125593\n",
      "2023-12-07 03:46:16,475 INFO     Training average negative_sample_loss at step 45300: 0.088227\n",
      "2023-12-07 03:46:16,475 INFO     Training average loss at step 45300: 0.106910\n",
      "2023-12-07 03:46:55,233 INFO     Training average positive_sample_loss at step 45400: 0.127132\n",
      "2023-12-07 03:46:55,234 INFO     Training average negative_sample_loss at step 45400: 0.089877\n",
      "2023-12-07 03:46:55,234 INFO     Training average loss at step 45400: 0.108505\n",
      "2023-12-07 03:47:39,761 INFO     Training average positive_sample_loss at step 45500: 0.121588\n",
      "2023-12-07 03:47:39,761 INFO     Training average negative_sample_loss at step 45500: 0.088691\n",
      "2023-12-07 03:47:39,761 INFO     Training average loss at step 45500: 0.105140\n",
      "2023-12-07 03:48:18,824 INFO     Training average positive_sample_loss at step 45600: 0.126641\n",
      "2023-12-07 03:48:18,825 INFO     Training average negative_sample_loss at step 45600: 0.088502\n",
      "2023-12-07 03:48:18,825 INFO     Training average loss at step 45600: 0.107571\n",
      "2023-12-07 03:49:00,681 INFO     Training average positive_sample_loss at step 45700: 0.124250\n",
      "2023-12-07 03:49:00,682 INFO     Training average negative_sample_loss at step 45700: 0.089761\n",
      "2023-12-07 03:49:00,682 INFO     Training average loss at step 45700: 0.107005\n",
      "2023-12-07 03:49:39,227 INFO     Training average positive_sample_loss at step 45800: 0.124272\n",
      "2023-12-07 03:49:39,228 INFO     Training average negative_sample_loss at step 45800: 0.088025\n",
      "2023-12-07 03:49:39,228 INFO     Training average loss at step 45800: 0.106149\n",
      "2023-12-07 03:50:17,945 INFO     Training average positive_sample_loss at step 45900: 0.127761\n",
      "2023-12-07 03:50:17,945 INFO     Training average negative_sample_loss at step 45900: 0.089744\n",
      "2023-12-07 03:50:17,945 INFO     Training average loss at step 45900: 0.108753\n",
      "2023-12-07 03:50:59,541 INFO     Training average positive_sample_loss at step 46000: 0.121983\n",
      "2023-12-07 03:50:59,541 INFO     Training average negative_sample_loss at step 46000: 0.088850\n",
      "2023-12-07 03:50:59,541 INFO     Training average loss at step 46000: 0.105416\n",
      "2023-12-07 03:51:38,166 INFO     Training average positive_sample_loss at step 46100: 0.126056\n",
      "2023-12-07 03:51:38,166 INFO     Training average negative_sample_loss at step 46100: 0.088602\n",
      "2023-12-07 03:51:38,166 INFO     Training average loss at step 46100: 0.107329\n",
      "2023-12-07 03:52:19,886 INFO     Training average positive_sample_loss at step 46200: 0.125620\n",
      "2023-12-07 03:52:19,886 INFO     Training average negative_sample_loss at step 46200: 0.089866\n",
      "2023-12-07 03:52:19,886 INFO     Training average loss at step 46200: 0.107743\n",
      "2023-12-07 03:52:59,165 INFO     Training average positive_sample_loss at step 46300: 0.123283\n",
      "2023-12-07 03:52:59,165 INFO     Training average negative_sample_loss at step 46300: 0.088589\n",
      "2023-12-07 03:52:59,165 INFO     Training average loss at step 46300: 0.105936\n",
      "2023-12-07 03:53:38,221 INFO     Training average positive_sample_loss at step 46400: 0.127174\n",
      "2023-12-07 03:53:38,221 INFO     Training average negative_sample_loss at step 46400: 0.089741\n",
      "2023-12-07 03:53:38,221 INFO     Training average loss at step 46400: 0.108458\n",
      "2023-12-07 03:54:20,533 INFO     Training average positive_sample_loss at step 46500: 0.123091\n",
      "2023-12-07 03:54:20,534 INFO     Training average negative_sample_loss at step 46500: 0.089375\n",
      "2023-12-07 03:54:20,534 INFO     Training average loss at step 46500: 0.106233\n",
      "2023-12-07 03:54:59,049 INFO     Training average positive_sample_loss at step 46600: 0.125537\n",
      "2023-12-07 03:54:59,049 INFO     Training average negative_sample_loss at step 46600: 0.087911\n",
      "2023-12-07 03:54:59,049 INFO     Training average loss at step 46600: 0.106724\n",
      "2023-12-07 03:55:43,381 INFO     Training average positive_sample_loss at step 46700: 0.127646\n",
      "2023-12-07 03:55:43,382 INFO     Training average negative_sample_loss at step 46700: 0.091031\n",
      "2023-12-07 03:55:43,382 INFO     Training average loss at step 46700: 0.109338\n",
      "2023-12-07 03:56:21,502 INFO     Training average positive_sample_loss at step 46800: 0.121916\n",
      "2023-12-07 03:56:21,502 INFO     Training average negative_sample_loss at step 46800: 0.088622\n",
      "2023-12-07 03:56:21,502 INFO     Training average loss at step 46800: 0.105269\n",
      "2023-12-07 03:57:00,384 INFO     Training average positive_sample_loss at step 46900: 0.126268\n",
      "2023-12-07 03:57:00,384 INFO     Training average negative_sample_loss at step 46900: 0.088811\n",
      "2023-12-07 03:57:00,384 INFO     Training average loss at step 46900: 0.107539\n",
      "2023-12-07 03:57:42,636 INFO     Training average positive_sample_loss at step 47000: 0.123503\n",
      "2023-12-07 03:57:42,636 INFO     Training average negative_sample_loss at step 47000: 0.089041\n",
      "2023-12-07 03:57:42,636 INFO     Training average loss at step 47000: 0.106272\n",
      "2023-12-07 03:58:21,505 INFO     Training average positive_sample_loss at step 47100: 0.124947\n",
      "2023-12-07 03:58:21,505 INFO     Training average negative_sample_loss at step 47100: 0.088726\n",
      "2023-12-07 03:58:21,505 INFO     Training average loss at step 47100: 0.106836\n",
      "2023-12-07 03:59:00,568 INFO     Training average positive_sample_loss at step 47200: 0.127483\n",
      "2023-12-07 03:59:00,569 INFO     Training average negative_sample_loss at step 47200: 0.089926\n",
      "2023-12-07 03:59:00,569 INFO     Training average loss at step 47200: 0.108705\n",
      "2023-12-07 03:59:42,218 INFO     Training average positive_sample_loss at step 47300: 0.121673\n",
      "2023-12-07 03:59:42,218 INFO     Training average negative_sample_loss at step 47300: 0.088753\n",
      "2023-12-07 03:59:42,218 INFO     Training average loss at step 47300: 0.105213\n",
      "2023-12-07 04:00:21,532 INFO     Training average positive_sample_loss at step 47400: 0.126123\n",
      "2023-12-07 04:00:21,532 INFO     Training average negative_sample_loss at step 47400: 0.088999\n",
      "2023-12-07 04:00:21,533 INFO     Training average loss at step 47400: 0.107561\n",
      "2023-12-07 04:01:03,247 INFO     Training average positive_sample_loss at step 47500: 0.124838\n",
      "2023-12-07 04:01:03,247 INFO     Training average negative_sample_loss at step 47500: 0.089399\n",
      "2023-12-07 04:01:03,248 INFO     Training average loss at step 47500: 0.107119\n",
      "2023-12-07 04:01:41,895 INFO     Training average positive_sample_loss at step 47600: 0.124050\n",
      "2023-12-07 04:01:41,895 INFO     Training average negative_sample_loss at step 47600: 0.088558\n",
      "2023-12-07 04:01:41,895 INFO     Training average loss at step 47600: 0.106304\n",
      "2023-12-07 04:02:20,843 INFO     Training average positive_sample_loss at step 47700: 0.127445\n",
      "2023-12-07 04:02:20,843 INFO     Training average negative_sample_loss at step 47700: 0.089951\n",
      "2023-12-07 04:02:20,843 INFO     Training average loss at step 47700: 0.108698\n",
      "2023-12-07 04:03:02,885 INFO     Training average positive_sample_loss at step 47800: 0.122762\n",
      "2023-12-07 04:03:02,886 INFO     Training average negative_sample_loss at step 47800: 0.089415\n",
      "2023-12-07 04:03:02,886 INFO     Training average loss at step 47800: 0.106088\n",
      "2023-12-07 04:03:42,614 INFO     Training average positive_sample_loss at step 47900: 0.126053\n",
      "2023-12-07 04:03:42,614 INFO     Training average negative_sample_loss at step 47900: 0.088567\n",
      "2023-12-07 04:03:42,614 INFO     Training average loss at step 47900: 0.107310\n",
      "2023-12-07 04:04:28,594 INFO     Training average positive_sample_loss at step 48000: 0.125693\n",
      "2023-12-07 04:04:28,595 INFO     Training average negative_sample_loss at step 48000: 0.089880\n",
      "2023-12-07 04:04:28,595 INFO     Training average loss at step 48000: 0.107787\n",
      "2023-12-07 04:05:06,856 INFO     Training average positive_sample_loss at step 48100: 0.121980\n",
      "2023-12-07 04:05:06,856 INFO     Training average negative_sample_loss at step 48100: 0.088304\n",
      "2023-12-07 04:05:06,856 INFO     Training average loss at step 48100: 0.105142\n",
      "2023-12-07 04:05:45,151 INFO     Training average positive_sample_loss at step 48200: 0.127293\n",
      "2023-12-07 04:05:45,151 INFO     Training average negative_sample_loss at step 48200: 0.089612\n",
      "2023-12-07 04:05:45,151 INFO     Training average loss at step 48200: 0.108453\n",
      "2023-12-07 04:06:26,496 INFO     Training average positive_sample_loss at step 48300: 0.123452\n",
      "2023-12-07 04:06:26,496 INFO     Training average negative_sample_loss at step 48300: 0.089765\n",
      "2023-12-07 04:06:26,496 INFO     Training average loss at step 48300: 0.106609\n",
      "2023-12-07 04:07:05,422 INFO     Training average positive_sample_loss at step 48400: 0.125457\n",
      "2023-12-07 04:07:05,423 INFO     Training average negative_sample_loss at step 48400: 0.088691\n",
      "2023-12-07 04:07:05,423 INFO     Training average loss at step 48400: 0.107074\n",
      "2023-12-07 04:07:44,169 INFO     Training average positive_sample_loss at step 48500: 0.127840\n",
      "2023-12-07 04:07:44,170 INFO     Training average negative_sample_loss at step 48500: 0.090322\n",
      "2023-12-07 04:07:44,170 INFO     Training average loss at step 48500: 0.109081\n",
      "2023-12-07 04:08:25,817 INFO     Training average positive_sample_loss at step 48600: 0.121209\n",
      "2023-12-07 04:08:25,817 INFO     Training average negative_sample_loss at step 48600: 0.088610\n",
      "2023-12-07 04:08:25,817 INFO     Training average loss at step 48600: 0.104909\n",
      "2023-12-07 04:09:04,430 INFO     Training average positive_sample_loss at step 48700: 0.126413\n",
      "2023-12-07 04:09:04,430 INFO     Training average negative_sample_loss at step 48700: 0.088029\n",
      "2023-12-07 04:09:04,430 INFO     Training average loss at step 48700: 0.107221\n",
      "2023-12-07 04:09:46,143 INFO     Training average positive_sample_loss at step 48800: 0.123665\n",
      "2023-12-07 04:09:46,143 INFO     Training average negative_sample_loss at step 48800: 0.089938\n",
      "2023-12-07 04:09:46,143 INFO     Training average loss at step 48800: 0.106801\n",
      "2023-12-07 04:10:24,782 INFO     Training average positive_sample_loss at step 48900: 0.124535\n",
      "2023-12-07 04:10:24,782 INFO     Training average negative_sample_loss at step 48900: 0.088522\n",
      "2023-12-07 04:10:24,782 INFO     Training average loss at step 48900: 0.106529\n",
      "2023-12-07 04:11:03,043 INFO     Training average positive_sample_loss at step 49000: 0.127721\n",
      "2023-12-07 04:11:03,043 INFO     Training average negative_sample_loss at step 49000: 0.089444\n",
      "2023-12-07 04:11:03,043 INFO     Training average loss at step 49000: 0.108582\n",
      "2023-12-07 04:11:44,326 INFO     Training average positive_sample_loss at step 49100: 0.121360\n",
      "2023-12-07 04:11:44,326 INFO     Training average negative_sample_loss at step 49100: 0.089335\n",
      "2023-12-07 04:11:44,326 INFO     Training average loss at step 49100: 0.105348\n",
      "2023-12-07 04:12:23,276 INFO     Training average positive_sample_loss at step 49200: 0.126615\n",
      "2023-12-07 04:12:23,276 INFO     Training average negative_sample_loss at step 49200: 0.089409\n",
      "2023-12-07 04:12:23,276 INFO     Training average loss at step 49200: 0.108012\n",
      "2023-12-07 04:13:09,056 INFO     Training average positive_sample_loss at step 49300: 0.125082\n",
      "2023-12-07 04:13:09,057 INFO     Training average negative_sample_loss at step 49300: 0.089538\n",
      "2023-12-07 04:13:09,057 INFO     Training average loss at step 49300: 0.107310\n",
      "2023-12-07 04:13:47,480 INFO     Training average positive_sample_loss at step 49400: 0.123097\n",
      "2023-12-07 04:13:47,480 INFO     Training average negative_sample_loss at step 49400: 0.088238\n",
      "2023-12-07 04:13:47,480 INFO     Training average loss at step 49400: 0.105668\n",
      "2023-12-07 04:14:26,526 INFO     Training average positive_sample_loss at step 49500: 0.127352\n",
      "2023-12-07 04:14:26,527 INFO     Training average negative_sample_loss at step 49500: 0.089301\n",
      "2023-12-07 04:14:26,527 INFO     Training average loss at step 49500: 0.108327\n",
      "2023-12-07 04:15:08,697 INFO     Training average positive_sample_loss at step 49600: 0.122286\n",
      "2023-12-07 04:15:08,697 INFO     Training average negative_sample_loss at step 49600: 0.089186\n",
      "2023-12-07 04:15:08,697 INFO     Training average loss at step 49600: 0.105736\n",
      "2023-12-07 04:15:47,390 INFO     Training average positive_sample_loss at step 49700: 0.125094\n",
      "2023-12-07 04:15:47,391 INFO     Training average negative_sample_loss at step 49700: 0.087782\n",
      "2023-12-07 04:15:47,391 INFO     Training average loss at step 49700: 0.106438\n",
      "2023-12-07 04:16:29,343 INFO     Training average positive_sample_loss at step 49800: 0.126802\n",
      "2023-12-07 04:16:29,344 INFO     Training average negative_sample_loss at step 49800: 0.089810\n",
      "2023-12-07 04:16:29,344 INFO     Training average loss at step 49800: 0.108306\n",
      "2023-12-07 04:17:07,725 INFO     Training average positive_sample_loss at step 49900: 0.121646\n",
      "2023-12-07 04:17:07,726 INFO     Training average negative_sample_loss at step 49900: 0.088606\n",
      "2023-12-07 04:17:07,726 INFO     Training average loss at step 49900: 0.105126\n",
      "2023-12-07 04:17:46,328 INFO     Change learning_rate to 0.000005 at step 50000\n",
      "2023-12-07 04:17:53,267 INFO     Training average positive_sample_loss at step 50000: 0.127006\n",
      "2023-12-07 04:17:53,345 INFO     Training average negative_sample_loss at step 50000: 0.089284\n",
      "2023-12-07 04:17:53,346 INFO     Training average loss at step 50000: 0.108145\n",
      "2023-12-07 04:17:53,346 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 04:17:53,769 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 04:18:20,730 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 04:18:37,096 INFO     Valid MRR at step 50000: 0.536695\n",
      "2023-12-07 04:18:37,097 INFO     Valid MR at step 50000: 260.240910\n",
      "2023-12-07 04:18:37,097 INFO     Valid HITS@1 at step 50000: 0.467563\n",
      "2023-12-07 04:18:37,097 INFO     Valid HITS@3 at step 50000: 0.570435\n",
      "2023-12-07 04:18:37,097 INFO     Valid HITS@10 at step 50000: 0.662426\n",
      "2023-12-07 04:19:14,170 INFO     Training average positive_sample_loss at step 50100: 0.122851\n",
      "2023-12-07 04:19:14,171 INFO     Training average negative_sample_loss at step 50100: 0.088342\n",
      "2023-12-07 04:19:14,171 INFO     Training average loss at step 50100: 0.105597\n",
      "2023-12-07 04:19:52,851 INFO     Training average positive_sample_loss at step 50200: 0.117847\n",
      "2023-12-07 04:19:52,851 INFO     Training average negative_sample_loss at step 50200: 0.087047\n",
      "2023-12-07 04:19:52,851 INFO     Training average loss at step 50200: 0.102447\n",
      "2023-12-07 04:20:31,538 INFO     Training average positive_sample_loss at step 50300: 0.118139\n",
      "2023-12-07 04:20:31,538 INFO     Training average negative_sample_loss at step 50300: 0.087086\n",
      "2023-12-07 04:20:31,538 INFO     Training average loss at step 50300: 0.102613\n",
      "2023-12-07 04:21:12,964 INFO     Training average positive_sample_loss at step 50400: 0.116154\n",
      "2023-12-07 04:21:12,964 INFO     Training average negative_sample_loss at step 50400: 0.086592\n",
      "2023-12-07 04:21:12,964 INFO     Training average loss at step 50400: 0.101373\n",
      "2023-12-07 04:21:52,066 INFO     Training average positive_sample_loss at step 50500: 0.117469\n",
      "2023-12-07 04:21:52,066 INFO     Training average negative_sample_loss at step 50500: 0.086084\n",
      "2023-12-07 04:21:52,066 INFO     Training average loss at step 50500: 0.101776\n",
      "2023-12-07 04:22:36,978 INFO     Training average positive_sample_loss at step 50600: 0.116436\n",
      "2023-12-07 04:22:36,978 INFO     Training average negative_sample_loss at step 50600: 0.085636\n",
      "2023-12-07 04:22:36,978 INFO     Training average loss at step 50600: 0.101036\n",
      "2023-12-07 04:23:15,218 INFO     Training average positive_sample_loss at step 50700: 0.116214\n",
      "2023-12-07 04:23:15,218 INFO     Training average negative_sample_loss at step 50700: 0.085325\n",
      "2023-12-07 04:23:15,218 INFO     Training average loss at step 50700: 0.100769\n",
      "2023-12-07 04:23:53,501 INFO     Training average positive_sample_loss at step 50800: 0.116851\n",
      "2023-12-07 04:23:53,502 INFO     Training average negative_sample_loss at step 50800: 0.085891\n",
      "2023-12-07 04:23:53,502 INFO     Training average loss at step 50800: 0.101371\n",
      "2023-12-07 04:24:35,097 INFO     Training average positive_sample_loss at step 50900: 0.115290\n",
      "2023-12-07 04:24:35,097 INFO     Training average negative_sample_loss at step 50900: 0.086252\n",
      "2023-12-07 04:24:35,097 INFO     Training average loss at step 50900: 0.100771\n",
      "2023-12-07 04:25:13,765 INFO     Training average positive_sample_loss at step 51000: 0.115973\n",
      "2023-12-07 04:25:13,765 INFO     Training average negative_sample_loss at step 51000: 0.085114\n",
      "2023-12-07 04:25:13,765 INFO     Training average loss at step 51000: 0.100544\n",
      "2023-12-07 04:25:54,896 INFO     Training average positive_sample_loss at step 51100: 0.117219\n",
      "2023-12-07 04:25:54,896 INFO     Training average negative_sample_loss at step 51100: 0.085158\n",
      "2023-12-07 04:25:54,896 INFO     Training average loss at step 51100: 0.101188\n",
      "2023-12-07 04:26:33,568 INFO     Training average positive_sample_loss at step 51200: 0.115743\n",
      "2023-12-07 04:26:33,569 INFO     Training average negative_sample_loss at step 51200: 0.085352\n",
      "2023-12-07 04:26:33,569 INFO     Training average loss at step 51200: 0.100548\n",
      "2023-12-07 04:27:12,123 INFO     Training average positive_sample_loss at step 51300: 0.115755\n",
      "2023-12-07 04:27:12,123 INFO     Training average negative_sample_loss at step 51300: 0.085041\n",
      "2023-12-07 04:27:12,123 INFO     Training average loss at step 51300: 0.100398\n",
      "2023-12-07 04:27:53,572 INFO     Training average positive_sample_loss at step 51400: 0.115385\n",
      "2023-12-07 04:27:53,572 INFO     Training average negative_sample_loss at step 51400: 0.084951\n",
      "2023-12-07 04:27:53,572 INFO     Training average loss at step 51400: 0.100168\n",
      "2023-12-07 04:28:32,188 INFO     Training average positive_sample_loss at step 51500: 0.116112\n",
      "2023-12-07 04:28:32,188 INFO     Training average negative_sample_loss at step 51500: 0.084094\n",
      "2023-12-07 04:28:32,188 INFO     Training average loss at step 51500: 0.100103\n",
      "2023-12-07 04:29:12,975 INFO     Training average positive_sample_loss at step 51600: 0.116845\n",
      "2023-12-07 04:29:12,975 INFO     Training average negative_sample_loss at step 51600: 0.083931\n",
      "2023-12-07 04:29:12,975 INFO     Training average loss at step 51600: 0.100388\n",
      "2023-12-07 04:29:52,414 INFO     Training average positive_sample_loss at step 51700: 0.115269\n",
      "2023-12-07 04:29:52,414 INFO     Training average negative_sample_loss at step 51700: 0.085448\n",
      "2023-12-07 04:29:52,414 INFO     Training average loss at step 51700: 0.100358\n",
      "2023-12-07 04:30:31,283 INFO     Training average positive_sample_loss at step 51800: 0.116017\n",
      "2023-12-07 04:30:31,283 INFO     Training average negative_sample_loss at step 51800: 0.084331\n",
      "2023-12-07 04:30:31,283 INFO     Training average loss at step 51800: 0.100174\n",
      "2023-12-07 04:31:16,365 INFO     Training average positive_sample_loss at step 51900: 0.116157\n",
      "2023-12-07 04:31:16,365 INFO     Training average negative_sample_loss at step 51900: 0.084799\n",
      "2023-12-07 04:31:16,365 INFO     Training average loss at step 51900: 0.100478\n",
      "2023-12-07 04:31:55,082 INFO     Training average positive_sample_loss at step 52000: 0.115588\n",
      "2023-12-07 04:31:55,082 INFO     Training average negative_sample_loss at step 52000: 0.084170\n",
      "2023-12-07 04:31:55,083 INFO     Training average loss at step 52000: 0.099879\n",
      "2023-12-07 04:32:33,664 INFO     Training average positive_sample_loss at step 52100: 0.116445\n",
      "2023-12-07 04:32:33,664 INFO     Training average negative_sample_loss at step 52100: 0.084574\n",
      "2023-12-07 04:32:33,664 INFO     Training average loss at step 52100: 0.100509\n",
      "2023-12-07 04:33:15,263 INFO     Training average positive_sample_loss at step 52200: 0.115169\n",
      "2023-12-07 04:33:15,263 INFO     Training average negative_sample_loss at step 52200: 0.085118\n",
      "2023-12-07 04:33:15,263 INFO     Training average loss at step 52200: 0.100144\n",
      "2023-12-07 04:33:54,101 INFO     Training average positive_sample_loss at step 52300: 0.116206\n",
      "2023-12-07 04:33:54,102 INFO     Training average negative_sample_loss at step 52300: 0.083620\n",
      "2023-12-07 04:33:54,102 INFO     Training average loss at step 52300: 0.099913\n",
      "2023-12-07 04:34:35,967 INFO     Training average positive_sample_loss at step 52400: 0.116354\n",
      "2023-12-07 04:34:35,967 INFO     Training average negative_sample_loss at step 52400: 0.083508\n",
      "2023-12-07 04:34:35,967 INFO     Training average loss at step 52400: 0.099931\n",
      "2023-12-07 04:35:14,635 INFO     Training average positive_sample_loss at step 52500: 0.115262\n",
      "2023-12-07 04:35:14,635 INFO     Training average negative_sample_loss at step 52500: 0.083833\n",
      "2023-12-07 04:35:14,635 INFO     Training average loss at step 52500: 0.099547\n",
      "2023-12-07 04:35:53,288 INFO     Training average positive_sample_loss at step 52600: 0.116123\n",
      "2023-12-07 04:35:53,289 INFO     Training average negative_sample_loss at step 52600: 0.083232\n",
      "2023-12-07 04:35:53,289 INFO     Training average loss at step 52600: 0.099677\n",
      "2023-12-07 04:36:35,600 INFO     Training average positive_sample_loss at step 52700: 0.115857\n",
      "2023-12-07 04:36:35,600 INFO     Training average negative_sample_loss at step 52700: 0.084170\n",
      "2023-12-07 04:36:35,600 INFO     Training average loss at step 52700: 0.100013\n",
      "2023-12-07 04:37:14,893 INFO     Training average positive_sample_loss at step 52800: 0.116174\n",
      "2023-12-07 04:37:14,894 INFO     Training average negative_sample_loss at step 52800: 0.085173\n",
      "2023-12-07 04:37:14,894 INFO     Training average loss at step 52800: 0.100673\n",
      "2023-12-07 04:37:57,099 INFO     Training average positive_sample_loss at step 52900: 0.115945\n",
      "2023-12-07 04:37:57,099 INFO     Training average negative_sample_loss at step 52900: 0.083946\n",
      "2023-12-07 04:37:57,099 INFO     Training average loss at step 52900: 0.099945\n",
      "2023-12-07 04:38:35,649 INFO     Training average positive_sample_loss at step 53000: 0.115107\n",
      "2023-12-07 04:38:35,649 INFO     Training average negative_sample_loss at step 53000: 0.084225\n",
      "2023-12-07 04:38:35,650 INFO     Training average loss at step 53000: 0.099666\n",
      "2023-12-07 04:39:14,150 INFO     Training average positive_sample_loss at step 53100: 0.116655\n",
      "2023-12-07 04:39:14,150 INFO     Training average negative_sample_loss at step 53100: 0.084155\n",
      "2023-12-07 04:39:14,150 INFO     Training average loss at step 53100: 0.100405\n",
      "2023-12-07 04:39:59,165 INFO     Training average positive_sample_loss at step 53200: 0.115694\n",
      "2023-12-07 04:39:59,165 INFO     Training average negative_sample_loss at step 53200: 0.083527\n",
      "2023-12-07 04:39:59,165 INFO     Training average loss at step 53200: 0.099611\n",
      "2023-12-07 04:40:37,461 INFO     Training average positive_sample_loss at step 53300: 0.115765\n",
      "2023-12-07 04:40:37,462 INFO     Training average negative_sample_loss at step 53300: 0.083975\n",
      "2023-12-07 04:40:37,462 INFO     Training average loss at step 53300: 0.099870\n",
      "2023-12-07 04:41:15,689 INFO     Training average positive_sample_loss at step 53400: 0.116467\n",
      "2023-12-07 04:41:15,689 INFO     Training average negative_sample_loss at step 53400: 0.083866\n",
      "2023-12-07 04:41:15,689 INFO     Training average loss at step 53400: 0.100166\n",
      "2023-12-07 04:41:58,415 INFO     Training average positive_sample_loss at step 53500: 0.115074\n",
      "2023-12-07 04:41:58,416 INFO     Training average negative_sample_loss at step 53500: 0.083555\n",
      "2023-12-07 04:41:58,416 INFO     Training average loss at step 53500: 0.099315\n",
      "2023-12-07 04:42:37,488 INFO     Training average positive_sample_loss at step 53600: 0.116069\n",
      "2023-12-07 04:42:37,488 INFO     Training average negative_sample_loss at step 53600: 0.084407\n",
      "2023-12-07 04:42:37,488 INFO     Training average loss at step 53600: 0.100238\n",
      "2023-12-07 04:43:19,728 INFO     Training average positive_sample_loss at step 53700: 0.116027\n",
      "2023-12-07 04:43:19,729 INFO     Training average negative_sample_loss at step 53700: 0.084470\n",
      "2023-12-07 04:43:19,729 INFO     Training average loss at step 53700: 0.100248\n",
      "2023-12-07 04:43:57,863 INFO     Training average positive_sample_loss at step 53800: 0.115869\n",
      "2023-12-07 04:43:57,863 INFO     Training average negative_sample_loss at step 53800: 0.083896\n",
      "2023-12-07 04:43:57,863 INFO     Training average loss at step 53800: 0.099882\n",
      "2023-12-07 04:44:36,712 INFO     Training average positive_sample_loss at step 53900: 0.116354\n",
      "2023-12-07 04:44:36,712 INFO     Training average negative_sample_loss at step 53900: 0.084031\n",
      "2023-12-07 04:44:36,712 INFO     Training average loss at step 53900: 0.100192\n",
      "2023-12-07 04:45:18,483 INFO     Training average positive_sample_loss at step 54000: 0.114938\n",
      "2023-12-07 04:45:18,483 INFO     Training average negative_sample_loss at step 54000: 0.083604\n",
      "2023-12-07 04:45:18,484 INFO     Training average loss at step 54000: 0.099271\n",
      "2023-12-07 04:45:57,902 INFO     Training average positive_sample_loss at step 54100: 0.116775\n",
      "2023-12-07 04:45:57,902 INFO     Training average negative_sample_loss at step 54100: 0.084188\n",
      "2023-12-07 04:45:57,902 INFO     Training average loss at step 54100: 0.100481\n",
      "2023-12-07 04:46:39,771 INFO     Training average positive_sample_loss at step 54200: 0.115534\n",
      "2023-12-07 04:46:39,771 INFO     Training average negative_sample_loss at step 54200: 0.083468\n",
      "2023-12-07 04:46:39,771 INFO     Training average loss at step 54200: 0.099501\n",
      "2023-12-07 04:47:18,298 INFO     Training average positive_sample_loss at step 54300: 0.115459\n",
      "2023-12-07 04:47:18,299 INFO     Training average negative_sample_loss at step 54300: 0.083066\n",
      "2023-12-07 04:47:18,299 INFO     Training average loss at step 54300: 0.099262\n",
      "2023-12-07 04:47:57,040 INFO     Training average positive_sample_loss at step 54400: 0.116101\n",
      "2023-12-07 04:47:57,040 INFO     Training average negative_sample_loss at step 54400: 0.083982\n",
      "2023-12-07 04:47:57,040 INFO     Training average loss at step 54400: 0.100041\n",
      "2023-12-07 04:48:41,502 INFO     Training average positive_sample_loss at step 54500: 0.115662\n",
      "2023-12-07 04:48:41,502 INFO     Training average negative_sample_loss at step 54500: 0.083961\n",
      "2023-12-07 04:48:41,502 INFO     Training average loss at step 54500: 0.099812\n",
      "2023-12-07 04:49:19,731 INFO     Training average positive_sample_loss at step 54600: 0.115666\n",
      "2023-12-07 04:49:19,732 INFO     Training average negative_sample_loss at step 54600: 0.084163\n",
      "2023-12-07 04:49:19,732 INFO     Training average loss at step 54600: 0.099915\n",
      "2023-12-07 04:50:01,481 INFO     Training average positive_sample_loss at step 54700: 0.116717\n",
      "2023-12-07 04:50:01,481 INFO     Training average negative_sample_loss at step 54700: 0.083843\n",
      "2023-12-07 04:50:01,481 INFO     Training average loss at step 54700: 0.100280\n",
      "2023-12-07 04:50:39,883 INFO     Training average positive_sample_loss at step 54800: 0.115142\n",
      "2023-12-07 04:50:39,883 INFO     Training average negative_sample_loss at step 54800: 0.083893\n",
      "2023-12-07 04:50:39,883 INFO     Training average loss at step 54800: 0.099517\n",
      "2023-12-07 04:51:18,062 INFO     Training average positive_sample_loss at step 54900: 0.116298\n",
      "2023-12-07 04:51:18,062 INFO     Training average negative_sample_loss at step 54900: 0.083559\n",
      "2023-12-07 04:51:18,062 INFO     Training average loss at step 54900: 0.099928\n",
      "2023-12-07 04:52:00,064 INFO     Training average positive_sample_loss at step 55000: 0.116146\n",
      "2023-12-07 04:52:00,064 INFO     Training average negative_sample_loss at step 55000: 0.083377\n",
      "2023-12-07 04:52:00,065 INFO     Training average loss at step 55000: 0.099762\n",
      "2023-12-07 04:52:38,750 INFO     Training average positive_sample_loss at step 55100: 0.115570\n",
      "2023-12-07 04:52:38,750 INFO     Training average negative_sample_loss at step 55100: 0.083758\n",
      "2023-12-07 04:52:38,750 INFO     Training average loss at step 55100: 0.099664\n",
      "2023-12-07 04:53:17,511 INFO     Training average positive_sample_loss at step 55200: 0.116008\n",
      "2023-12-07 04:53:17,511 INFO     Training average negative_sample_loss at step 55200: 0.083987\n",
      "2023-12-07 04:53:17,511 INFO     Training average loss at step 55200: 0.099997\n",
      "2023-12-07 04:53:59,580 INFO     Training average positive_sample_loss at step 55300: 0.115193\n",
      "2023-12-07 04:53:59,580 INFO     Training average negative_sample_loss at step 55300: 0.082846\n",
      "2023-12-07 04:53:59,580 INFO     Training average loss at step 55300: 0.099020\n",
      "2023-12-07 04:54:38,972 INFO     Training average positive_sample_loss at step 55400: 0.116240\n",
      "2023-12-07 04:54:38,972 INFO     Training average negative_sample_loss at step 55400: 0.084238\n",
      "2023-12-07 04:54:38,972 INFO     Training average loss at step 55400: 0.100239\n",
      "2023-12-07 04:55:21,427 INFO     Training average positive_sample_loss at step 55500: 0.116047\n",
      "2023-12-07 04:55:21,427 INFO     Training average negative_sample_loss at step 55500: 0.083560\n",
      "2023-12-07 04:55:21,428 INFO     Training average loss at step 55500: 0.099804\n",
      "2023-12-07 04:56:00,391 INFO     Training average positive_sample_loss at step 55600: 0.115414\n",
      "2023-12-07 04:56:00,391 INFO     Training average negative_sample_loss at step 55600: 0.084106\n",
      "2023-12-07 04:56:00,391 INFO     Training average loss at step 55600: 0.099760\n",
      "2023-12-07 04:56:39,269 INFO     Training average positive_sample_loss at step 55700: 0.116248\n",
      "2023-12-07 04:56:39,269 INFO     Training average negative_sample_loss at step 55700: 0.083852\n",
      "2023-12-07 04:56:39,269 INFO     Training average loss at step 55700: 0.100050\n",
      "2023-12-07 04:57:24,159 INFO     Training average positive_sample_loss at step 55800: 0.115517\n",
      "2023-12-07 04:57:24,160 INFO     Training average negative_sample_loss at step 55800: 0.083599\n",
      "2023-12-07 04:57:24,160 INFO     Training average loss at step 55800: 0.099558\n",
      "2023-12-07 04:58:01,990 INFO     Training average positive_sample_loss at step 55900: 0.115620\n",
      "2023-12-07 04:58:01,990 INFO     Training average negative_sample_loss at step 55900: 0.083474\n",
      "2023-12-07 04:58:01,990 INFO     Training average loss at step 55900: 0.099547\n",
      "2023-12-07 04:58:44,332 INFO     Training average positive_sample_loss at step 56000: 0.116506\n",
      "2023-12-07 04:58:44,333 INFO     Training average negative_sample_loss at step 56000: 0.084167\n",
      "2023-12-07 04:58:44,333 INFO     Training average loss at step 56000: 0.100336\n",
      "2023-12-07 04:59:22,877 INFO     Training average positive_sample_loss at step 56100: 0.115075\n",
      "2023-12-07 04:59:22,877 INFO     Training average negative_sample_loss at step 56100: 0.084091\n",
      "2023-12-07 04:59:22,877 INFO     Training average loss at step 56100: 0.099583\n",
      "2023-12-07 05:00:01,501 INFO     Training average positive_sample_loss at step 56200: 0.116326\n",
      "2023-12-07 05:00:01,501 INFO     Training average negative_sample_loss at step 56200: 0.083108\n",
      "2023-12-07 05:00:01,501 INFO     Training average loss at step 56200: 0.099717\n",
      "2023-12-07 05:00:42,808 INFO     Training average positive_sample_loss at step 56300: 0.115400\n",
      "2023-12-07 05:00:42,808 INFO     Training average negative_sample_loss at step 56300: 0.083426\n",
      "2023-12-07 05:00:42,808 INFO     Training average loss at step 56300: 0.099413\n",
      "2023-12-07 05:01:21,078 INFO     Training average positive_sample_loss at step 56400: 0.116116\n",
      "2023-12-07 05:01:21,078 INFO     Training average negative_sample_loss at step 56400: 0.084147\n",
      "2023-12-07 05:01:21,078 INFO     Training average loss at step 56400: 0.100131\n",
      "2023-12-07 05:01:59,486 INFO     Training average positive_sample_loss at step 56500: 0.116091\n",
      "2023-12-07 05:01:59,487 INFO     Training average negative_sample_loss at step 56500: 0.083870\n",
      "2023-12-07 05:01:59,487 INFO     Training average loss at step 56500: 0.099981\n",
      "2023-12-07 05:02:41,559 INFO     Training average positive_sample_loss at step 56600: 0.115108\n",
      "2023-12-07 05:02:41,559 INFO     Training average negative_sample_loss at step 56600: 0.083530\n",
      "2023-12-07 05:02:41,559 INFO     Training average loss at step 56600: 0.099319\n",
      "2023-12-07 05:03:19,848 INFO     Training average positive_sample_loss at step 56700: 0.116533\n",
      "2023-12-07 05:03:19,849 INFO     Training average negative_sample_loss at step 56700: 0.084200\n",
      "2023-12-07 05:03:19,849 INFO     Training average loss at step 56700: 0.100366\n",
      "2023-12-07 05:04:01,501 INFO     Training average positive_sample_loss at step 56800: 0.115629\n",
      "2023-12-07 05:04:01,502 INFO     Training average negative_sample_loss at step 56800: 0.083195\n",
      "2023-12-07 05:04:01,502 INFO     Training average loss at step 56800: 0.099412\n",
      "2023-12-07 05:04:40,099 INFO     Training average positive_sample_loss at step 56900: 0.115707\n",
      "2023-12-07 05:04:40,099 INFO     Training average negative_sample_loss at step 56900: 0.084641\n",
      "2023-12-07 05:04:40,099 INFO     Training average loss at step 56900: 0.100174\n",
      "2023-12-07 05:05:19,354 INFO     Training average positive_sample_loss at step 57000: 0.116200\n",
      "2023-12-07 05:05:19,354 INFO     Training average negative_sample_loss at step 57000: 0.083348\n",
      "2023-12-07 05:05:19,354 INFO     Training average loss at step 57000: 0.099774\n",
      "2023-12-07 05:06:03,469 INFO     Training average positive_sample_loss at step 57100: 0.115559\n",
      "2023-12-07 05:06:03,469 INFO     Training average negative_sample_loss at step 57100: 0.083191\n",
      "2023-12-07 05:06:03,469 INFO     Training average loss at step 57100: 0.099375\n",
      "2023-12-07 05:06:41,714 INFO     Training average positive_sample_loss at step 57200: 0.115639\n",
      "2023-12-07 05:06:41,714 INFO     Training average negative_sample_loss at step 57200: 0.083138\n",
      "2023-12-07 05:06:41,714 INFO     Training average loss at step 57200: 0.099389\n",
      "2023-12-07 05:07:23,641 INFO     Training average positive_sample_loss at step 57300: 0.115991\n",
      "2023-12-07 05:07:23,642 INFO     Training average negative_sample_loss at step 57300: 0.084096\n",
      "2023-12-07 05:07:23,642 INFO     Training average loss at step 57300: 0.100044\n",
      "2023-12-07 05:08:01,846 INFO     Training average positive_sample_loss at step 57400: 0.115867\n",
      "2023-12-07 05:08:01,846 INFO     Training average negative_sample_loss at step 57400: 0.083737\n",
      "2023-12-07 05:08:01,846 INFO     Training average loss at step 57400: 0.099802\n",
      "2023-12-07 05:08:40,630 INFO     Training average positive_sample_loss at step 57500: 0.116132\n",
      "2023-12-07 05:08:40,630 INFO     Training average negative_sample_loss at step 57500: 0.084272\n",
      "2023-12-07 05:08:40,631 INFO     Training average loss at step 57500: 0.100202\n",
      "2023-12-07 05:09:22,346 INFO     Training average positive_sample_loss at step 57600: 0.115742\n",
      "2023-12-07 05:09:22,346 INFO     Training average negative_sample_loss at step 57600: 0.083799\n",
      "2023-12-07 05:09:22,346 INFO     Training average loss at step 57600: 0.099770\n",
      "2023-12-07 05:10:00,456 INFO     Training average positive_sample_loss at step 57700: 0.115867\n",
      "2023-12-07 05:10:00,456 INFO     Training average negative_sample_loss at step 57700: 0.083817\n",
      "2023-12-07 05:10:00,456 INFO     Training average loss at step 57700: 0.099842\n",
      "2023-12-07 05:10:41,776 INFO     Training average positive_sample_loss at step 57800: 0.115828\n",
      "2023-12-07 05:10:41,777 INFO     Training average negative_sample_loss at step 57800: 0.083111\n",
      "2023-12-07 05:10:41,777 INFO     Training average loss at step 57800: 0.099470\n",
      "2023-12-07 05:11:20,500 INFO     Training average positive_sample_loss at step 57900: 0.114968\n",
      "2023-12-07 05:11:20,500 INFO     Training average negative_sample_loss at step 57900: 0.083192\n",
      "2023-12-07 05:11:20,500 INFO     Training average loss at step 57900: 0.099080\n",
      "2023-12-07 05:11:59,548 INFO     Training average positive_sample_loss at step 58000: 0.116017\n",
      "2023-12-07 05:11:59,548 INFO     Training average negative_sample_loss at step 58000: 0.082811\n",
      "2023-12-07 05:11:59,548 INFO     Training average loss at step 58000: 0.099414\n",
      "2023-12-07 05:12:41,359 INFO     Training average positive_sample_loss at step 58100: 0.116077\n",
      "2023-12-07 05:12:41,360 INFO     Training average negative_sample_loss at step 58100: 0.084118\n",
      "2023-12-07 05:12:41,360 INFO     Training average loss at step 58100: 0.100098\n",
      "2023-12-07 05:13:20,058 INFO     Training average positive_sample_loss at step 58200: 0.115650\n",
      "2023-12-07 05:13:20,058 INFO     Training average negative_sample_loss at step 58200: 0.083430\n",
      "2023-12-07 05:13:20,058 INFO     Training average loss at step 58200: 0.099540\n",
      "2023-12-07 05:13:58,513 INFO     Training average positive_sample_loss at step 58300: 0.116284\n",
      "2023-12-07 05:13:58,513 INFO     Training average negative_sample_loss at step 58300: 0.083206\n",
      "2023-12-07 05:13:58,513 INFO     Training average loss at step 58300: 0.099745\n",
      "2023-12-07 05:14:43,185 INFO     Training average positive_sample_loss at step 58400: 0.115429\n",
      "2023-12-07 05:14:43,185 INFO     Training average negative_sample_loss at step 58400: 0.084169\n",
      "2023-12-07 05:14:43,185 INFO     Training average loss at step 58400: 0.099799\n",
      "2023-12-07 05:15:21,494 INFO     Training average positive_sample_loss at step 58500: 0.116324\n",
      "2023-12-07 05:15:21,494 INFO     Training average negative_sample_loss at step 58500: 0.083351\n",
      "2023-12-07 05:15:21,494 INFO     Training average loss at step 58500: 0.099838\n",
      "2023-12-07 05:16:03,534 INFO     Training average positive_sample_loss at step 58600: 0.115421\n",
      "2023-12-07 05:16:03,535 INFO     Training average negative_sample_loss at step 58600: 0.083057\n",
      "2023-12-07 05:16:03,535 INFO     Training average loss at step 58600: 0.099239\n",
      "2023-12-07 05:16:42,008 INFO     Training average positive_sample_loss at step 58700: 0.114999\n",
      "2023-12-07 05:16:42,009 INFO     Training average negative_sample_loss at step 58700: 0.082998\n",
      "2023-12-07 05:16:42,009 INFO     Training average loss at step 58700: 0.098999\n",
      "2023-12-07 05:17:20,918 INFO     Training average positive_sample_loss at step 58800: 0.116307\n",
      "2023-12-07 05:17:20,919 INFO     Training average negative_sample_loss at step 58800: 0.083584\n",
      "2023-12-07 05:17:20,919 INFO     Training average loss at step 58800: 0.099946\n",
      "2023-12-07 05:18:02,671 INFO     Training average positive_sample_loss at step 58900: 0.115663\n",
      "2023-12-07 05:18:02,671 INFO     Training average negative_sample_loss at step 58900: 0.084275\n",
      "2023-12-07 05:18:02,671 INFO     Training average loss at step 58900: 0.099969\n",
      "2023-12-07 05:18:40,991 INFO     Training average positive_sample_loss at step 59000: 0.115616\n",
      "2023-12-07 05:18:40,992 INFO     Training average negative_sample_loss at step 59000: 0.082942\n",
      "2023-12-07 05:18:40,992 INFO     Training average loss at step 59000: 0.099279\n",
      "2023-12-07 05:19:22,615 INFO     Training average positive_sample_loss at step 59100: 0.116215\n",
      "2023-12-07 05:19:22,615 INFO     Training average negative_sample_loss at step 59100: 0.083382\n",
      "2023-12-07 05:19:22,615 INFO     Training average loss at step 59100: 0.099798\n",
      "2023-12-07 05:20:01,202 INFO     Training average positive_sample_loss at step 59200: 0.115281\n",
      "2023-12-07 05:20:01,202 INFO     Training average negative_sample_loss at step 59200: 0.083778\n",
      "2023-12-07 05:20:01,202 INFO     Training average loss at step 59200: 0.099529\n",
      "2023-12-07 05:20:40,390 INFO     Training average positive_sample_loss at step 59300: 0.116387\n",
      "2023-12-07 05:20:40,390 INFO     Training average negative_sample_loss at step 59300: 0.083337\n",
      "2023-12-07 05:20:40,390 INFO     Training average loss at step 59300: 0.099862\n",
      "2023-12-07 05:21:22,019 INFO     Training average positive_sample_loss at step 59400: 0.115120\n",
      "2023-12-07 05:21:22,020 INFO     Training average negative_sample_loss at step 59400: 0.083795\n",
      "2023-12-07 05:21:22,020 INFO     Training average loss at step 59400: 0.099458\n",
      "2023-12-07 05:22:00,722 INFO     Training average positive_sample_loss at step 59500: 0.115525\n",
      "2023-12-07 05:22:00,722 INFO     Training average negative_sample_loss at step 59500: 0.082230\n",
      "2023-12-07 05:22:00,722 INFO     Training average loss at step 59500: 0.098878\n",
      "2023-12-07 05:22:45,670 INFO     Training average positive_sample_loss at step 59600: 0.116600\n",
      "2023-12-07 05:22:45,670 INFO     Training average negative_sample_loss at step 59600: 0.084167\n",
      "2023-12-07 05:22:45,670 INFO     Training average loss at step 59600: 0.100383\n",
      "2023-12-07 05:23:24,045 INFO     Training average positive_sample_loss at step 59700: 0.114506\n",
      "2023-12-07 05:23:24,046 INFO     Training average negative_sample_loss at step 59700: 0.083411\n",
      "2023-12-07 05:23:24,046 INFO     Training average loss at step 59700: 0.098958\n",
      "2023-12-07 05:24:02,430 INFO     Training average positive_sample_loss at step 59800: 0.116399\n",
      "2023-12-07 05:24:02,430 INFO     Training average negative_sample_loss at step 59800: 0.083178\n",
      "2023-12-07 05:24:02,430 INFO     Training average loss at step 59800: 0.099788\n",
      "2023-12-07 05:24:44,261 INFO     Training average positive_sample_loss at step 59900: 0.116146\n",
      "2023-12-07 05:24:44,261 INFO     Training average negative_sample_loss at step 59900: 0.083979\n",
      "2023-12-07 05:24:44,261 INFO     Training average loss at step 59900: 0.100063\n",
      "2023-12-07 05:25:34,924 INFO     Training average positive_sample_loss at step 60000: 0.114819\n",
      "2023-12-07 05:25:34,924 INFO     Training average negative_sample_loss at step 60000: 0.083815\n",
      "2023-12-07 05:25:34,924 INFO     Training average loss at step 60000: 0.099317\n",
      "2023-12-07 05:25:34,924 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 05:25:35,421 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 05:26:01,674 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 05:26:17,368 INFO     Valid MRR at step 60000: 0.548390\n",
      "2023-12-07 05:26:17,368 INFO     Valid MR at step 60000: 255.640460\n",
      "2023-12-07 05:26:17,368 INFO     Valid HITS@1 at step 60000: 0.479057\n",
      "2023-12-07 05:26:17,368 INFO     Valid HITS@3 at step 60000: 0.582782\n",
      "2023-12-07 05:26:17,368 INFO     Valid HITS@10 at step 60000: 0.669691\n",
      "2023-12-07 05:26:49,065 INFO     Training average positive_sample_loss at step 60100: 0.116740\n",
      "2023-12-07 05:26:49,066 INFO     Training average negative_sample_loss at step 60100: 0.083688\n",
      "2023-12-07 05:26:49,066 INFO     Training average loss at step 60100: 0.100214\n",
      "2023-12-07 05:27:33,471 INFO     Training average positive_sample_loss at step 60200: 0.115053\n",
      "2023-12-07 05:27:33,471 INFO     Training average negative_sample_loss at step 60200: 0.083214\n",
      "2023-12-07 05:27:33,471 INFO     Training average loss at step 60200: 0.099134\n",
      "2023-12-07 05:28:11,852 INFO     Training average positive_sample_loss at step 60300: 0.115882\n",
      "2023-12-07 05:28:11,852 INFO     Training average negative_sample_loss at step 60300: 0.083842\n",
      "2023-12-07 05:28:11,852 INFO     Training average loss at step 60300: 0.099862\n",
      "2023-12-07 05:28:53,304 INFO     Training average positive_sample_loss at step 60400: 0.115477\n",
      "2023-12-07 05:28:53,304 INFO     Training average negative_sample_loss at step 60400: 0.083461\n",
      "2023-12-07 05:28:53,304 INFO     Training average loss at step 60400: 0.099469\n",
      "2023-12-07 05:29:32,106 INFO     Training average positive_sample_loss at step 60500: 0.115742\n",
      "2023-12-07 05:29:32,107 INFO     Training average negative_sample_loss at step 60500: 0.084192\n",
      "2023-12-07 05:29:32,107 INFO     Training average loss at step 60500: 0.099967\n",
      "2023-12-07 05:30:10,693 INFO     Training average positive_sample_loss at step 60600: 0.116107\n",
      "2023-12-07 05:30:10,693 INFO     Training average negative_sample_loss at step 60600: 0.083034\n",
      "2023-12-07 05:30:10,693 INFO     Training average loss at step 60600: 0.099570\n",
      "2023-12-07 05:30:53,039 INFO     Training average positive_sample_loss at step 60700: 0.115257\n",
      "2023-12-07 05:30:53,040 INFO     Training average negative_sample_loss at step 60700: 0.082960\n",
      "2023-12-07 05:30:53,040 INFO     Training average loss at step 60700: 0.099109\n",
      "2023-12-07 05:31:32,445 INFO     Training average positive_sample_loss at step 60800: 0.115475\n",
      "2023-12-07 05:31:32,445 INFO     Training average negative_sample_loss at step 60800: 0.084094\n",
      "2023-12-07 05:31:32,445 INFO     Training average loss at step 60800: 0.099784\n",
      "2023-12-07 05:32:18,357 INFO     Training average positive_sample_loss at step 60900: 0.116622\n",
      "2023-12-07 05:32:18,358 INFO     Training average negative_sample_loss at step 60900: 0.083337\n",
      "2023-12-07 05:32:18,358 INFO     Training average loss at step 60900: 0.099980\n",
      "2023-12-07 05:32:57,126 INFO     Training average positive_sample_loss at step 61000: 0.114933\n",
      "2023-12-07 05:32:57,126 INFO     Training average negative_sample_loss at step 61000: 0.084136\n",
      "2023-12-07 05:32:57,127 INFO     Training average loss at step 61000: 0.099535\n",
      "2023-12-07 05:33:35,723 INFO     Training average positive_sample_loss at step 61100: 0.115844\n",
      "2023-12-07 05:33:35,723 INFO     Training average negative_sample_loss at step 61100: 0.083717\n",
      "2023-12-07 05:33:35,723 INFO     Training average loss at step 61100: 0.099780\n",
      "2023-12-07 05:34:17,073 INFO     Training average positive_sample_loss at step 61200: 0.116052\n",
      "2023-12-07 05:34:17,073 INFO     Training average negative_sample_loss at step 61200: 0.083308\n",
      "2023-12-07 05:34:17,073 INFO     Training average loss at step 61200: 0.099680\n",
      "2023-12-07 05:34:55,695 INFO     Training average positive_sample_loss at step 61300: 0.115880\n",
      "2023-12-07 05:34:55,695 INFO     Training average negative_sample_loss at step 61300: 0.083192\n",
      "2023-12-07 05:34:55,695 INFO     Training average loss at step 61300: 0.099536\n",
      "2023-12-07 05:35:34,144 INFO     Training average positive_sample_loss at step 61400: 0.115934\n",
      "2023-12-07 05:35:34,144 INFO     Training average negative_sample_loss at step 61400: 0.083949\n",
      "2023-12-07 05:35:34,145 INFO     Training average loss at step 61400: 0.099941\n",
      "2023-12-07 05:36:16,111 INFO     Training average positive_sample_loss at step 61500: 0.115167\n",
      "2023-12-07 05:36:16,112 INFO     Training average negative_sample_loss at step 61500: 0.083821\n",
      "2023-12-07 05:36:16,112 INFO     Training average loss at step 61500: 0.099494\n",
      "2023-12-07 05:36:54,688 INFO     Training average positive_sample_loss at step 61600: 0.116156\n",
      "2023-12-07 05:36:54,688 INFO     Training average negative_sample_loss at step 61600: 0.083886\n",
      "2023-12-07 05:36:54,688 INFO     Training average loss at step 61600: 0.100021\n",
      "2023-12-07 05:37:36,794 INFO     Training average positive_sample_loss at step 61700: 0.115147\n",
      "2023-12-07 05:37:36,794 INFO     Training average negative_sample_loss at step 61700: 0.083397\n",
      "2023-12-07 05:37:36,794 INFO     Training average loss at step 61700: 0.099272\n",
      "2023-12-07 05:38:15,287 INFO     Training average positive_sample_loss at step 61800: 0.115796\n",
      "2023-12-07 05:38:15,287 INFO     Training average negative_sample_loss at step 61800: 0.083484\n",
      "2023-12-07 05:38:15,287 INFO     Training average loss at step 61800: 0.099640\n",
      "2023-12-07 05:38:53,725 INFO     Training average positive_sample_loss at step 61900: 0.115893\n",
      "2023-12-07 05:38:53,725 INFO     Training average negative_sample_loss at step 61900: 0.082879\n",
      "2023-12-07 05:38:53,725 INFO     Training average loss at step 61900: 0.099386\n",
      "2023-12-07 05:39:35,268 INFO     Training average positive_sample_loss at step 62000: 0.115186\n",
      "2023-12-07 05:39:35,268 INFO     Training average negative_sample_loss at step 62000: 0.083278\n",
      "2023-12-07 05:39:35,268 INFO     Training average loss at step 62000: 0.099232\n",
      "2023-12-07 05:40:14,071 INFO     Training average positive_sample_loss at step 62100: 0.116284\n",
      "2023-12-07 05:40:14,071 INFO     Training average negative_sample_loss at step 62100: 0.084228\n",
      "2023-12-07 05:40:14,071 INFO     Training average loss at step 62100: 0.100256\n",
      "2023-12-07 05:40:59,390 INFO     Training average positive_sample_loss at step 62200: 0.116060\n",
      "2023-12-07 05:40:59,390 INFO     Training average negative_sample_loss at step 62200: 0.082828\n",
      "2023-12-07 05:40:59,390 INFO     Training average loss at step 62200: 0.099444\n",
      "2023-12-07 05:41:37,864 INFO     Training average positive_sample_loss at step 62300: 0.115842\n",
      "2023-12-07 05:41:37,864 INFO     Training average negative_sample_loss at step 62300: 0.083226\n",
      "2023-12-07 05:41:37,864 INFO     Training average loss at step 62300: 0.099534\n",
      "2023-12-07 05:42:16,352 INFO     Training average positive_sample_loss at step 62400: 0.115742\n",
      "2023-12-07 05:42:16,352 INFO     Training average negative_sample_loss at step 62400: 0.083132\n",
      "2023-12-07 05:42:16,352 INFO     Training average loss at step 62400: 0.099437\n",
      "2023-12-07 05:42:58,635 INFO     Training average positive_sample_loss at step 62500: 0.115188\n",
      "2023-12-07 05:42:58,635 INFO     Training average negative_sample_loss at step 62500: 0.082853\n",
      "2023-12-07 05:42:58,635 INFO     Training average loss at step 62500: 0.099021\n",
      "2023-12-07 05:43:36,506 INFO     Training average positive_sample_loss at step 62600: 0.115518\n",
      "2023-12-07 05:43:36,506 INFO     Training average negative_sample_loss at step 62600: 0.083892\n",
      "2023-12-07 05:43:36,506 INFO     Training average loss at step 62600: 0.099705\n",
      "2023-12-07 05:44:18,703 INFO     Training average positive_sample_loss at step 62700: 0.116166\n",
      "2023-12-07 05:44:18,703 INFO     Training average negative_sample_loss at step 62700: 0.083553\n",
      "2023-12-07 05:44:18,703 INFO     Training average loss at step 62700: 0.099859\n",
      "2023-12-07 05:44:58,086 INFO     Training average positive_sample_loss at step 62800: 0.115132\n",
      "2023-12-07 05:44:58,086 INFO     Training average negative_sample_loss at step 62800: 0.083268\n",
      "2023-12-07 05:44:58,086 INFO     Training average loss at step 62800: 0.099200\n",
      "2023-12-07 05:45:37,122 INFO     Training average positive_sample_loss at step 62900: 0.115783\n",
      "2023-12-07 05:45:37,122 INFO     Training average negative_sample_loss at step 62900: 0.083422\n",
      "2023-12-07 05:45:37,122 INFO     Training average loss at step 62900: 0.099603\n",
      "2023-12-07 05:46:18,354 INFO     Training average positive_sample_loss at step 63000: 0.115880\n",
      "2023-12-07 05:46:18,355 INFO     Training average negative_sample_loss at step 63000: 0.084051\n",
      "2023-12-07 05:46:18,355 INFO     Training average loss at step 63000: 0.099965\n",
      "2023-12-07 05:46:56,905 INFO     Training average positive_sample_loss at step 63100: 0.115549\n",
      "2023-12-07 05:46:56,905 INFO     Training average negative_sample_loss at step 63100: 0.083107\n",
      "2023-12-07 05:46:56,905 INFO     Training average loss at step 63100: 0.099328\n",
      "2023-12-07 05:47:35,163 INFO     Training average positive_sample_loss at step 63200: 0.116166\n",
      "2023-12-07 05:47:35,164 INFO     Training average negative_sample_loss at step 63200: 0.083441\n",
      "2023-12-07 05:47:35,164 INFO     Training average loss at step 63200: 0.099804\n",
      "2023-12-07 05:48:17,209 INFO     Training average positive_sample_loss at step 63300: 0.114914\n",
      "2023-12-07 05:48:17,209 INFO     Training average negative_sample_loss at step 63300: 0.082982\n",
      "2023-12-07 05:48:17,209 INFO     Training average loss at step 63300: 0.098948\n",
      "2023-12-07 05:48:55,873 INFO     Training average positive_sample_loss at step 63400: 0.116230\n",
      "2023-12-07 05:48:55,873 INFO     Training average negative_sample_loss at step 63400: 0.083833\n",
      "2023-12-07 05:48:55,873 INFO     Training average loss at step 63400: 0.100031\n",
      "2023-12-07 05:49:40,853 INFO     Training average positive_sample_loss at step 63500: 0.115781\n",
      "2023-12-07 05:49:40,853 INFO     Training average negative_sample_loss at step 63500: 0.083455\n",
      "2023-12-07 05:49:40,853 INFO     Training average loss at step 63500: 0.099618\n",
      "2023-12-07 05:50:19,427 INFO     Training average positive_sample_loss at step 63600: 0.115716\n",
      "2023-12-07 05:50:19,427 INFO     Training average negative_sample_loss at step 63600: 0.083205\n",
      "2023-12-07 05:50:19,427 INFO     Training average loss at step 63600: 0.099461\n",
      "2023-12-07 05:50:58,189 INFO     Training average positive_sample_loss at step 63700: 0.115602\n",
      "2023-12-07 05:50:58,189 INFO     Training average negative_sample_loss at step 63700: 0.083582\n",
      "2023-12-07 05:50:58,189 INFO     Training average loss at step 63700: 0.099592\n",
      "2023-12-07 05:51:39,605 INFO     Training average positive_sample_loss at step 63800: 0.115298\n",
      "2023-12-07 05:51:39,605 INFO     Training average negative_sample_loss at step 63800: 0.083124\n",
      "2023-12-07 05:51:39,605 INFO     Training average loss at step 63800: 0.099211\n",
      "2023-12-07 05:52:17,985 INFO     Training average positive_sample_loss at step 63900: 0.115976\n",
      "2023-12-07 05:52:17,985 INFO     Training average negative_sample_loss at step 63900: 0.083070\n",
      "2023-12-07 05:52:17,985 INFO     Training average loss at step 63900: 0.099523\n",
      "2023-12-07 05:53:00,224 INFO     Training average positive_sample_loss at step 64000: 0.115855\n",
      "2023-12-07 05:53:00,225 INFO     Training average negative_sample_loss at step 64000: 0.082987\n",
      "2023-12-07 05:53:00,225 INFO     Training average loss at step 64000: 0.099421\n",
      "2023-12-07 05:53:38,814 INFO     Training average positive_sample_loss at step 64100: 0.114842\n",
      "2023-12-07 05:53:38,814 INFO     Training average negative_sample_loss at step 64100: 0.082291\n",
      "2023-12-07 05:53:38,814 INFO     Training average loss at step 64100: 0.098567\n",
      "2023-12-07 05:54:17,815 INFO     Training average positive_sample_loss at step 64200: 0.115841\n",
      "2023-12-07 05:54:17,815 INFO     Training average negative_sample_loss at step 64200: 0.083086\n",
      "2023-12-07 05:54:17,815 INFO     Training average loss at step 64200: 0.099464\n",
      "2023-12-07 05:54:59,516 INFO     Training average positive_sample_loss at step 64300: 0.115851\n",
      "2023-12-07 05:54:59,516 INFO     Training average negative_sample_loss at step 64300: 0.083610\n",
      "2023-12-07 05:54:59,516 INFO     Training average loss at step 64300: 0.099731\n",
      "2023-12-07 05:55:37,851 INFO     Training average positive_sample_loss at step 64400: 0.115651\n",
      "2023-12-07 05:55:37,851 INFO     Training average negative_sample_loss at step 64400: 0.082453\n",
      "2023-12-07 05:55:37,851 INFO     Training average loss at step 64400: 0.099052\n",
      "2023-12-07 05:56:18,787 INFO     Training average positive_sample_loss at step 64500: 0.115807\n",
      "2023-12-07 05:56:18,787 INFO     Training average negative_sample_loss at step 64500: 0.082491\n",
      "2023-12-07 05:56:18,787 INFO     Training average loss at step 64500: 0.099149\n",
      "2023-12-07 05:56:57,857 INFO     Training average positive_sample_loss at step 64600: 0.114667\n",
      "2023-12-07 05:56:57,858 INFO     Training average negative_sample_loss at step 64600: 0.083057\n",
      "2023-12-07 05:56:57,858 INFO     Training average loss at step 64600: 0.098862\n",
      "2023-12-07 05:57:36,301 INFO     Training average positive_sample_loss at step 64700: 0.115797\n",
      "2023-12-07 05:57:36,301 INFO     Training average negative_sample_loss at step 64700: 0.082348\n",
      "2023-12-07 05:57:36,301 INFO     Training average loss at step 64700: 0.099073\n",
      "2023-12-07 05:58:21,336 INFO     Training average positive_sample_loss at step 64800: 0.115920\n",
      "2023-12-07 05:58:21,337 INFO     Training average negative_sample_loss at step 64800: 0.083971\n",
      "2023-12-07 05:58:21,337 INFO     Training average loss at step 64800: 0.099946\n",
      "2023-12-07 05:58:59,380 INFO     Training average positive_sample_loss at step 64900: 0.115082\n",
      "2023-12-07 05:58:59,380 INFO     Training average negative_sample_loss at step 64900: 0.083409\n",
      "2023-12-07 05:58:59,381 INFO     Training average loss at step 64900: 0.099245\n",
      "2023-12-07 05:59:37,395 INFO     Training average positive_sample_loss at step 65000: 0.115950\n",
      "2023-12-07 05:59:37,396 INFO     Training average negative_sample_loss at step 65000: 0.083190\n",
      "2023-12-07 05:59:37,396 INFO     Training average loss at step 65000: 0.099570\n",
      "2023-12-07 06:00:19,366 INFO     Training average positive_sample_loss at step 65100: 0.115493\n",
      "2023-12-07 06:00:19,366 INFO     Training average negative_sample_loss at step 65100: 0.083121\n",
      "2023-12-07 06:00:19,366 INFO     Training average loss at step 65100: 0.099307\n",
      "2023-12-07 06:00:58,111 INFO     Training average positive_sample_loss at step 65200: 0.115666\n",
      "2023-12-07 06:00:58,111 INFO     Training average negative_sample_loss at step 65200: 0.083709\n",
      "2023-12-07 06:00:58,111 INFO     Training average loss at step 65200: 0.099688\n",
      "2023-12-07 06:01:39,708 INFO     Training average positive_sample_loss at step 65300: 0.115686\n",
      "2023-12-07 06:01:39,708 INFO     Training average negative_sample_loss at step 65300: 0.083521\n",
      "2023-12-07 06:01:39,708 INFO     Training average loss at step 65300: 0.099603\n",
      "2023-12-07 06:02:18,312 INFO     Training average positive_sample_loss at step 65400: 0.115045\n",
      "2023-12-07 06:02:18,312 INFO     Training average negative_sample_loss at step 65400: 0.082559\n",
      "2023-12-07 06:02:18,312 INFO     Training average loss at step 65400: 0.098802\n",
      "2023-12-07 06:02:56,496 INFO     Training average positive_sample_loss at step 65500: 0.116204\n",
      "2023-12-07 06:02:56,497 INFO     Training average negative_sample_loss at step 65500: 0.083395\n",
      "2023-12-07 06:02:56,497 INFO     Training average loss at step 65500: 0.099800\n",
      "2023-12-07 06:03:37,878 INFO     Training average positive_sample_loss at step 65600: 0.115201\n",
      "2023-12-07 06:03:37,878 INFO     Training average negative_sample_loss at step 65600: 0.083385\n",
      "2023-12-07 06:03:37,878 INFO     Training average loss at step 65600: 0.099293\n",
      "2023-12-07 06:04:16,498 INFO     Training average positive_sample_loss at step 65700: 0.116129\n",
      "2023-12-07 06:04:16,498 INFO     Training average negative_sample_loss at step 65700: 0.084090\n",
      "2023-12-07 06:04:16,498 INFO     Training average loss at step 65700: 0.100110\n",
      "2023-12-07 06:04:57,699 INFO     Training average positive_sample_loss at step 65800: 0.115584\n",
      "2023-12-07 06:04:57,699 INFO     Training average negative_sample_loss at step 65800: 0.083830\n",
      "2023-12-07 06:04:57,699 INFO     Training average loss at step 65800: 0.099707\n",
      "2023-12-07 06:05:36,943 INFO     Training average positive_sample_loss at step 65900: 0.115053\n",
      "2023-12-07 06:05:36,943 INFO     Training average negative_sample_loss at step 65900: 0.082920\n",
      "2023-12-07 06:05:36,943 INFO     Training average loss at step 65900: 0.098987\n",
      "2023-12-07 06:06:15,463 INFO     Training average positive_sample_loss at step 66000: 0.115908\n",
      "2023-12-07 06:06:15,463 INFO     Training average negative_sample_loss at step 66000: 0.083428\n",
      "2023-12-07 06:06:15,463 INFO     Training average loss at step 66000: 0.099668\n",
      "2023-12-07 06:07:00,507 INFO     Training average positive_sample_loss at step 66100: 0.115707\n",
      "2023-12-07 06:07:00,507 INFO     Training average negative_sample_loss at step 66100: 0.084007\n",
      "2023-12-07 06:07:00,507 INFO     Training average loss at step 66100: 0.099857\n",
      "2023-12-07 06:07:38,394 INFO     Training average positive_sample_loss at step 66200: 0.115316\n",
      "2023-12-07 06:07:38,394 INFO     Training average negative_sample_loss at step 66200: 0.083317\n",
      "2023-12-07 06:07:38,394 INFO     Training average loss at step 66200: 0.099317\n",
      "2023-12-07 06:08:17,063 INFO     Training average positive_sample_loss at step 66300: 0.116413\n",
      "2023-12-07 06:08:17,063 INFO     Training average negative_sample_loss at step 66300: 0.083022\n",
      "2023-12-07 06:08:17,063 INFO     Training average loss at step 66300: 0.099717\n",
      "2023-12-07 06:08:58,940 INFO     Training average positive_sample_loss at step 66400: 0.114972\n",
      "2023-12-07 06:08:58,940 INFO     Training average negative_sample_loss at step 66400: 0.083780\n",
      "2023-12-07 06:08:58,940 INFO     Training average loss at step 66400: 0.099376\n",
      "2023-12-07 06:09:37,185 INFO     Training average positive_sample_loss at step 66500: 0.115713\n",
      "2023-12-07 06:09:37,185 INFO     Training average negative_sample_loss at step 66500: 0.082348\n",
      "2023-12-07 06:09:37,185 INFO     Training average loss at step 66500: 0.099031\n",
      "2023-12-07 06:10:19,661 INFO     Training average positive_sample_loss at step 66600: 0.115976\n",
      "2023-12-07 06:10:19,662 INFO     Training average negative_sample_loss at step 66600: 0.083629\n",
      "2023-12-07 06:10:19,662 INFO     Training average loss at step 66600: 0.099803\n",
      "2023-12-07 06:10:57,980 INFO     Training average positive_sample_loss at step 66700: 0.115685\n",
      "2023-12-07 06:10:57,980 INFO     Training average negative_sample_loss at step 66700: 0.083475\n",
      "2023-12-07 06:10:57,980 INFO     Training average loss at step 66700: 0.099580\n",
      "2023-12-07 06:11:36,510 INFO     Training average positive_sample_loss at step 66800: 0.115256\n",
      "2023-12-07 06:11:36,511 INFO     Training average negative_sample_loss at step 66800: 0.082913\n",
      "2023-12-07 06:11:36,511 INFO     Training average loss at step 66800: 0.099085\n",
      "2023-12-07 06:12:18,353 INFO     Training average positive_sample_loss at step 66900: 0.115368\n",
      "2023-12-07 06:12:18,354 INFO     Training average negative_sample_loss at step 66900: 0.082872\n",
      "2023-12-07 06:12:18,354 INFO     Training average loss at step 66900: 0.099120\n",
      "2023-12-07 06:12:57,183 INFO     Training average positive_sample_loss at step 67000: 0.115554\n",
      "2023-12-07 06:12:57,183 INFO     Training average negative_sample_loss at step 67000: 0.083187\n",
      "2023-12-07 06:12:57,183 INFO     Training average loss at step 67000: 0.099370\n",
      "2023-12-07 06:13:39,160 INFO     Training average positive_sample_loss at step 67100: 0.115915\n",
      "2023-12-07 06:13:39,160 INFO     Training average negative_sample_loss at step 67100: 0.083717\n",
      "2023-12-07 06:13:39,160 INFO     Training average loss at step 67100: 0.099816\n",
      "2023-12-07 06:14:17,832 INFO     Training average positive_sample_loss at step 67200: 0.115096\n",
      "2023-12-07 06:14:17,833 INFO     Training average negative_sample_loss at step 67200: 0.083270\n",
      "2023-12-07 06:14:17,833 INFO     Training average loss at step 67200: 0.099183\n",
      "2023-12-07 06:14:56,888 INFO     Training average positive_sample_loss at step 67300: 0.116153\n",
      "2023-12-07 06:14:56,889 INFO     Training average negative_sample_loss at step 67300: 0.082990\n",
      "2023-12-07 06:14:56,889 INFO     Training average loss at step 67300: 0.099571\n",
      "2023-12-07 06:15:41,575 INFO     Training average positive_sample_loss at step 67400: 0.115232\n",
      "2023-12-07 06:15:41,575 INFO     Training average negative_sample_loss at step 67400: 0.083719\n",
      "2023-12-07 06:15:41,575 INFO     Training average loss at step 67400: 0.099476\n",
      "2023-12-07 06:16:19,824 INFO     Training average positive_sample_loss at step 67500: 0.115253\n",
      "2023-12-07 06:16:19,825 INFO     Training average negative_sample_loss at step 67500: 0.083853\n",
      "2023-12-07 06:16:19,825 INFO     Training average loss at step 67500: 0.099553\n",
      "2023-12-07 06:17:01,815 INFO     Training average positive_sample_loss at step 67600: 0.116389\n",
      "2023-12-07 06:17:01,815 INFO     Training average negative_sample_loss at step 67600: 0.083540\n",
      "2023-12-07 06:17:01,815 INFO     Training average loss at step 67600: 0.099964\n",
      "2023-12-07 06:17:40,619 INFO     Training average positive_sample_loss at step 67700: 0.114949\n",
      "2023-12-07 06:17:40,619 INFO     Training average negative_sample_loss at step 67700: 0.083749\n",
      "2023-12-07 06:17:40,619 INFO     Training average loss at step 67700: 0.099349\n",
      "2023-12-07 06:18:19,432 INFO     Training average positive_sample_loss at step 67800: 0.115719\n",
      "2023-12-07 06:18:19,433 INFO     Training average negative_sample_loss at step 67800: 0.083624\n",
      "2023-12-07 06:18:19,433 INFO     Training average loss at step 67800: 0.099672\n",
      "2023-12-07 06:19:01,236 INFO     Training average positive_sample_loss at step 67900: 0.116061\n",
      "2023-12-07 06:19:01,236 INFO     Training average negative_sample_loss at step 67900: 0.083319\n",
      "2023-12-07 06:19:01,236 INFO     Training average loss at step 67900: 0.099690\n",
      "2023-12-07 06:19:39,566 INFO     Training average positive_sample_loss at step 68000: 0.115262\n",
      "2023-12-07 06:19:39,566 INFO     Training average negative_sample_loss at step 68000: 0.083509\n",
      "2023-12-07 06:19:39,566 INFO     Training average loss at step 68000: 0.099385\n",
      "2023-12-07 06:20:17,950 INFO     Training average positive_sample_loss at step 68100: 0.116059\n",
      "2023-12-07 06:20:17,950 INFO     Training average negative_sample_loss at step 68100: 0.082896\n",
      "2023-12-07 06:20:17,950 INFO     Training average loss at step 68100: 0.099478\n",
      "2023-12-07 06:20:59,764 INFO     Training average positive_sample_loss at step 68200: 0.114781\n",
      "2023-12-07 06:20:59,765 INFO     Training average negative_sample_loss at step 68200: 0.083295\n",
      "2023-12-07 06:20:59,765 INFO     Training average loss at step 68200: 0.099038\n",
      "2023-12-07 06:21:38,269 INFO     Training average positive_sample_loss at step 68300: 0.115391\n",
      "2023-12-07 06:21:38,269 INFO     Training average negative_sample_loss at step 68300: 0.082313\n",
      "2023-12-07 06:21:38,269 INFO     Training average loss at step 68300: 0.098852\n",
      "2023-12-07 06:22:19,974 INFO     Training average positive_sample_loss at step 68400: 0.116369\n",
      "2023-12-07 06:22:19,975 INFO     Training average negative_sample_loss at step 68400: 0.083204\n",
      "2023-12-07 06:22:19,975 INFO     Training average loss at step 68400: 0.099787\n",
      "2023-12-07 06:22:58,444 INFO     Training average positive_sample_loss at step 68500: 0.115442\n",
      "2023-12-07 06:22:58,445 INFO     Training average negative_sample_loss at step 68500: 0.083231\n",
      "2023-12-07 06:22:58,445 INFO     Training average loss at step 68500: 0.099336\n",
      "2023-12-07 06:23:37,074 INFO     Training average positive_sample_loss at step 68600: 0.115875\n",
      "2023-12-07 06:23:37,074 INFO     Training average negative_sample_loss at step 68600: 0.082309\n",
      "2023-12-07 06:23:37,074 INFO     Training average loss at step 68600: 0.099092\n",
      "2023-12-07 06:24:21,523 INFO     Training average positive_sample_loss at step 68700: 0.114894\n",
      "2023-12-07 06:24:21,523 INFO     Training average negative_sample_loss at step 68700: 0.082704\n",
      "2023-12-07 06:24:21,524 INFO     Training average loss at step 68700: 0.098799\n",
      "2023-12-07 06:25:00,124 INFO     Training average positive_sample_loss at step 68800: 0.115723\n",
      "2023-12-07 06:25:00,124 INFO     Training average negative_sample_loss at step 68800: 0.083311\n",
      "2023-12-07 06:25:00,124 INFO     Training average loss at step 68800: 0.099517\n",
      "2023-12-07 06:25:41,876 INFO     Training average positive_sample_loss at step 68900: 0.115620\n",
      "2023-12-07 06:25:41,876 INFO     Training average negative_sample_loss at step 68900: 0.083214\n",
      "2023-12-07 06:25:41,877 INFO     Training average loss at step 68900: 0.099417\n",
      "2023-12-07 06:26:20,692 INFO     Training average positive_sample_loss at step 69000: 0.115657\n",
      "2023-12-07 06:26:20,692 INFO     Training average negative_sample_loss at step 69000: 0.082655\n",
      "2023-12-07 06:26:20,692 INFO     Training average loss at step 69000: 0.099156\n",
      "2023-12-07 06:26:58,939 INFO     Training average positive_sample_loss at step 69100: 0.115603\n",
      "2023-12-07 06:26:58,939 INFO     Training average negative_sample_loss at step 69100: 0.083092\n",
      "2023-12-07 06:26:58,939 INFO     Training average loss at step 69100: 0.099347\n",
      "2023-12-07 06:27:40,823 INFO     Training average positive_sample_loss at step 69200: 0.114983\n",
      "2023-12-07 06:27:40,823 INFO     Training average negative_sample_loss at step 69200: 0.083797\n",
      "2023-12-07 06:27:40,823 INFO     Training average loss at step 69200: 0.099390\n",
      "2023-12-07 06:28:19,694 INFO     Training average positive_sample_loss at step 69300: 0.115587\n",
      "2023-12-07 06:28:19,694 INFO     Training average negative_sample_loss at step 69300: 0.083293\n",
      "2023-12-07 06:28:19,694 INFO     Training average loss at step 69300: 0.099440\n",
      "2023-12-07 06:28:57,997 INFO     Training average positive_sample_loss at step 69400: 0.116317\n",
      "2023-12-07 06:28:57,997 INFO     Training average negative_sample_loss at step 69400: 0.084053\n",
      "2023-12-07 06:28:57,997 INFO     Training average loss at step 69400: 0.100185\n",
      "2023-12-07 06:29:39,526 INFO     Training average positive_sample_loss at step 69500: 0.115070\n",
      "2023-12-07 06:29:39,527 INFO     Training average negative_sample_loss at step 69500: 0.083515\n",
      "2023-12-07 06:29:39,527 INFO     Training average loss at step 69500: 0.099292\n",
      "2023-12-07 06:30:17,750 INFO     Training average positive_sample_loss at step 69600: 0.115884\n",
      "2023-12-07 06:30:17,750 INFO     Training average negative_sample_loss at step 69600: 0.083157\n",
      "2023-12-07 06:30:17,751 INFO     Training average loss at step 69600: 0.099520\n",
      "2023-12-07 06:30:59,118 INFO     Training average positive_sample_loss at step 69700: 0.115314\n",
      "2023-12-07 06:30:59,118 INFO     Training average negative_sample_loss at step 69700: 0.082564\n",
      "2023-12-07 06:30:59,118 INFO     Training average loss at step 69700: 0.098939\n",
      "2023-12-07 06:31:37,773 INFO     Training average positive_sample_loss at step 69800: 0.115304\n",
      "2023-12-07 06:31:37,773 INFO     Training average negative_sample_loss at step 69800: 0.083354\n",
      "2023-12-07 06:31:37,773 INFO     Training average loss at step 69800: 0.099329\n",
      "2023-12-07 06:32:16,504 INFO     Training average positive_sample_loss at step 69900: 0.116325\n",
      "2023-12-07 06:32:16,504 INFO     Training average negative_sample_loss at step 69900: 0.083433\n",
      "2023-12-07 06:32:16,504 INFO     Training average loss at step 69900: 0.099879\n",
      "2023-12-07 06:33:12,155 INFO     Training average positive_sample_loss at step 70000: 0.114885\n",
      "2023-12-07 06:33:12,156 INFO     Training average negative_sample_loss at step 70000: 0.083259\n",
      "2023-12-07 06:33:12,156 INFO     Training average loss at step 70000: 0.099072\n",
      "2023-12-07 06:33:12,156 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 06:33:12,590 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 06:33:35,717 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 06:33:51,242 INFO     Valid MRR at step 70000: 0.550192\n",
      "2023-12-07 06:33:51,242 INFO     Valid MR at step 70000: 256.543318\n",
      "2023-12-07 06:33:51,243 INFO     Valid HITS@1 at step 70000: 0.481922\n",
      "2023-12-07 06:33:51,243 INFO     Valid HITS@3 at step 70000: 0.583737\n",
      "2023-12-07 06:33:51,243 INFO     Valid HITS@10 at step 70000: 0.670203\n",
      "2023-12-07 06:34:22,642 INFO     Training average positive_sample_loss at step 70100: 0.115615\n",
      "2023-12-07 06:34:22,642 INFO     Training average negative_sample_loss at step 70100: 0.083577\n",
      "2023-12-07 06:34:22,642 INFO     Training average loss at step 70100: 0.099596\n",
      "2023-12-07 06:35:07,556 INFO     Training average positive_sample_loss at step 70200: 0.116128\n",
      "2023-12-07 06:35:07,556 INFO     Training average negative_sample_loss at step 70200: 0.083708\n",
      "2023-12-07 06:35:07,556 INFO     Training average loss at step 70200: 0.099918\n",
      "2023-12-07 06:35:46,107 INFO     Training average positive_sample_loss at step 70300: 0.115066\n",
      "2023-12-07 06:35:46,108 INFO     Training average negative_sample_loss at step 70300: 0.083292\n",
      "2023-12-07 06:35:46,108 INFO     Training average loss at step 70300: 0.099179\n",
      "2023-12-07 06:36:24,613 INFO     Training average positive_sample_loss at step 70400: 0.115964\n",
      "2023-12-07 06:36:24,613 INFO     Training average negative_sample_loss at step 70400: 0.083113\n",
      "2023-12-07 06:36:24,613 INFO     Training average loss at step 70400: 0.099538\n",
      "2023-12-07 06:37:06,416 INFO     Training average positive_sample_loss at step 70500: 0.115259\n",
      "2023-12-07 06:37:06,416 INFO     Training average negative_sample_loss at step 70500: 0.083473\n",
      "2023-12-07 06:37:06,417 INFO     Training average loss at step 70500: 0.099366\n",
      "2023-12-07 06:37:45,083 INFO     Training average positive_sample_loss at step 70600: 0.115661\n",
      "2023-12-07 06:37:45,083 INFO     Training average negative_sample_loss at step 70600: 0.083945\n",
      "2023-12-07 06:37:45,083 INFO     Training average loss at step 70600: 0.099803\n",
      "2023-12-07 06:38:26,451 INFO     Training average positive_sample_loss at step 70700: 0.116170\n",
      "2023-12-07 06:38:26,452 INFO     Training average negative_sample_loss at step 70700: 0.083805\n",
      "2023-12-07 06:38:26,452 INFO     Training average loss at step 70700: 0.099988\n",
      "2023-12-07 06:39:05,716 INFO     Training average positive_sample_loss at step 70800: 0.114632\n",
      "2023-12-07 06:39:05,717 INFO     Training average negative_sample_loss at step 70800: 0.083277\n",
      "2023-12-07 06:39:05,717 INFO     Training average loss at step 70800: 0.098955\n",
      "2023-12-07 06:39:45,126 INFO     Training average positive_sample_loss at step 70900: 0.116280\n",
      "2023-12-07 06:39:45,127 INFO     Training average negative_sample_loss at step 70900: 0.083219\n",
      "2023-12-07 06:39:45,127 INFO     Training average loss at step 70900: 0.099750\n",
      "2023-12-07 06:40:27,430 INFO     Training average positive_sample_loss at step 71000: 0.115513\n",
      "2023-12-07 06:40:27,431 INFO     Training average negative_sample_loss at step 71000: 0.084058\n",
      "2023-12-07 06:40:27,431 INFO     Training average loss at step 71000: 0.099785\n",
      "2023-12-07 06:41:06,812 INFO     Training average positive_sample_loss at step 71100: 0.115295\n",
      "2023-12-07 06:41:06,812 INFO     Training average negative_sample_loss at step 71100: 0.083634\n",
      "2023-12-07 06:41:06,812 INFO     Training average loss at step 71100: 0.099464\n",
      "2023-12-07 06:41:45,908 INFO     Training average positive_sample_loss at step 71200: 0.116181\n",
      "2023-12-07 06:41:45,908 INFO     Training average negative_sample_loss at step 71200: 0.083281\n",
      "2023-12-07 06:41:45,908 INFO     Training average loss at step 71200: 0.099731\n",
      "2023-12-07 06:42:30,738 INFO     Training average positive_sample_loss at step 71300: 0.115281\n",
      "2023-12-07 06:42:30,738 INFO     Training average negative_sample_loss at step 71300: 0.082598\n",
      "2023-12-07 06:42:30,738 INFO     Training average loss at step 71300: 0.098939\n",
      "2023-12-07 06:43:08,838 INFO     Training average positive_sample_loss at step 71400: 0.115815\n",
      "2023-12-07 06:43:08,838 INFO     Training average negative_sample_loss at step 71400: 0.082778\n",
      "2023-12-07 06:43:08,838 INFO     Training average loss at step 71400: 0.099296\n",
      "2023-12-07 06:43:50,720 INFO     Training average positive_sample_loss at step 71500: 0.115153\n",
      "2023-12-07 06:43:50,720 INFO     Training average negative_sample_loss at step 71500: 0.082720\n",
      "2023-12-07 06:43:50,720 INFO     Training average loss at step 71500: 0.098936\n",
      "2023-12-07 06:44:29,192 INFO     Training average positive_sample_loss at step 71600: 0.115139\n",
      "2023-12-07 06:44:29,192 INFO     Training average negative_sample_loss at step 71600: 0.083009\n",
      "2023-12-07 06:44:29,192 INFO     Training average loss at step 71600: 0.099074\n",
      "2023-12-07 06:45:07,812 INFO     Training average positive_sample_loss at step 71700: 0.116417\n",
      "2023-12-07 06:45:07,812 INFO     Training average negative_sample_loss at step 71700: 0.083338\n",
      "2023-12-07 06:45:07,812 INFO     Training average loss at step 71700: 0.099877\n",
      "2023-12-07 06:45:49,379 INFO     Training average positive_sample_loss at step 71800: 0.114987\n",
      "2023-12-07 06:45:49,380 INFO     Training average negative_sample_loss at step 71800: 0.082793\n",
      "2023-12-07 06:45:49,380 INFO     Training average loss at step 71800: 0.098890\n",
      "2023-12-07 06:46:28,108 INFO     Training average positive_sample_loss at step 71900: 0.115731\n",
      "2023-12-07 06:46:28,108 INFO     Training average negative_sample_loss at step 71900: 0.083649\n",
      "2023-12-07 06:46:28,108 INFO     Training average loss at step 71900: 0.099690\n",
      "2023-12-07 06:47:09,426 INFO     Training average positive_sample_loss at step 72000: 0.116111\n",
      "2023-12-07 06:47:09,426 INFO     Training average negative_sample_loss at step 72000: 0.083883\n",
      "2023-12-07 06:47:09,426 INFO     Training average loss at step 72000: 0.099997\n",
      "2023-12-07 06:47:47,879 INFO     Training average positive_sample_loss at step 72100: 0.114723\n",
      "2023-12-07 06:47:47,880 INFO     Training average negative_sample_loss at step 72100: 0.082904\n",
      "2023-12-07 06:47:47,880 INFO     Training average loss at step 72100: 0.098813\n",
      "2023-12-07 06:48:26,721 INFO     Training average positive_sample_loss at step 72200: 0.115901\n",
      "2023-12-07 06:48:26,721 INFO     Training average negative_sample_loss at step 72200: 0.082728\n",
      "2023-12-07 06:48:26,721 INFO     Training average loss at step 72200: 0.099314\n",
      "2023-12-07 06:49:08,539 INFO     Training average positive_sample_loss at step 72300: 0.115642\n",
      "2023-12-07 06:49:08,539 INFO     Training average negative_sample_loss at step 72300: 0.082318\n",
      "2023-12-07 06:49:08,539 INFO     Training average loss at step 72300: 0.098980\n",
      "2023-12-07 06:49:47,332 INFO     Training average positive_sample_loss at step 72400: 0.114973\n",
      "2023-12-07 06:49:47,333 INFO     Training average negative_sample_loss at step 72400: 0.083060\n",
      "2023-12-07 06:49:47,333 INFO     Training average loss at step 72400: 0.099017\n",
      "2023-12-07 06:50:32,170 INFO     Training average positive_sample_loss at step 72500: 0.116234\n",
      "2023-12-07 06:50:32,170 INFO     Training average negative_sample_loss at step 72500: 0.083816\n",
      "2023-12-07 06:50:32,170 INFO     Training average loss at step 72500: 0.100025\n",
      "2023-12-07 06:51:10,448 INFO     Training average positive_sample_loss at step 72600: 0.114916\n",
      "2023-12-07 06:51:10,449 INFO     Training average negative_sample_loss at step 72600: 0.082837\n",
      "2023-12-07 06:51:10,449 INFO     Training average loss at step 72600: 0.098876\n",
      "2023-12-07 06:51:48,438 INFO     Training average positive_sample_loss at step 72700: 0.115722\n",
      "2023-12-07 06:51:48,438 INFO     Training average negative_sample_loss at step 72700: 0.082926\n",
      "2023-12-07 06:51:48,438 INFO     Training average loss at step 72700: 0.099324\n",
      "2023-12-07 06:52:30,044 INFO     Training average positive_sample_loss at step 72800: 0.115826\n",
      "2023-12-07 06:52:30,044 INFO     Training average negative_sample_loss at step 72800: 0.082953\n",
      "2023-12-07 06:52:30,044 INFO     Training average loss at step 72800: 0.099389\n",
      "2023-12-07 06:53:08,239 INFO     Training average positive_sample_loss at step 72900: 0.114666\n",
      "2023-12-07 06:53:08,239 INFO     Training average negative_sample_loss at step 72900: 0.083248\n",
      "2023-12-07 06:53:08,239 INFO     Training average loss at step 72900: 0.098957\n",
      "2023-12-07 06:53:46,703 INFO     Training average positive_sample_loss at step 73000: 0.116292\n",
      "2023-12-07 06:53:46,704 INFO     Training average negative_sample_loss at step 73000: 0.082711\n",
      "2023-12-07 06:53:46,704 INFO     Training average loss at step 73000: 0.099501\n",
      "2023-12-07 06:54:28,336 INFO     Training average positive_sample_loss at step 73100: 0.114864\n",
      "2023-12-07 06:54:28,337 INFO     Training average negative_sample_loss at step 73100: 0.082963\n",
      "2023-12-07 06:54:28,337 INFO     Training average loss at step 73100: 0.098913\n",
      "2023-12-07 06:55:07,533 INFO     Training average positive_sample_loss at step 73200: 0.115476\n",
      "2023-12-07 06:55:07,533 INFO     Training average negative_sample_loss at step 73200: 0.083434\n",
      "2023-12-07 06:55:07,533 INFO     Training average loss at step 73200: 0.099455\n",
      "2023-12-07 06:55:49,412 INFO     Training average positive_sample_loss at step 73300: 0.116097\n",
      "2023-12-07 06:55:49,412 INFO     Training average negative_sample_loss at step 73300: 0.083212\n",
      "2023-12-07 06:55:49,413 INFO     Training average loss at step 73300: 0.099655\n",
      "2023-12-07 06:56:28,348 INFO     Training average positive_sample_loss at step 73400: 0.114868\n",
      "2023-12-07 06:56:28,348 INFO     Training average negative_sample_loss at step 73400: 0.082801\n",
      "2023-12-07 06:56:28,348 INFO     Training average loss at step 73400: 0.098834\n",
      "2023-12-07 06:57:07,237 INFO     Training average positive_sample_loss at step 73500: 0.116272\n",
      "2023-12-07 06:57:07,238 INFO     Training average negative_sample_loss at step 73500: 0.084170\n",
      "2023-12-07 06:57:07,238 INFO     Training average loss at step 73500: 0.100221\n",
      "2023-12-07 06:57:49,285 INFO     Training average positive_sample_loss at step 73600: 0.115144\n",
      "2023-12-07 06:57:49,286 INFO     Training average negative_sample_loss at step 73600: 0.083792\n",
      "2023-12-07 06:57:49,286 INFO     Training average loss at step 73600: 0.099468\n",
      "2023-12-07 06:58:28,072 INFO     Training average positive_sample_loss at step 73700: 0.115637\n",
      "2023-12-07 06:58:28,072 INFO     Training average negative_sample_loss at step 73700: 0.083801\n",
      "2023-12-07 06:58:28,072 INFO     Training average loss at step 73700: 0.099719\n",
      "2023-12-07 06:59:13,148 INFO     Training average positive_sample_loss at step 73800: 0.115652\n",
      "2023-12-07 06:59:13,149 INFO     Training average negative_sample_loss at step 73800: 0.083066\n",
      "2023-12-07 06:59:13,149 INFO     Training average loss at step 73800: 0.099359\n",
      "2023-12-07 06:59:51,513 INFO     Training average positive_sample_loss at step 73900: 0.114365\n",
      "2023-12-07 06:59:51,514 INFO     Training average negative_sample_loss at step 73900: 0.082512\n",
      "2023-12-07 06:59:51,514 INFO     Training average loss at step 73900: 0.098438\n",
      "2023-12-07 07:00:29,913 INFO     Training average positive_sample_loss at step 74000: 0.116367\n",
      "2023-12-07 07:00:29,913 INFO     Training average negative_sample_loss at step 74000: 0.083027\n",
      "2023-12-07 07:00:29,913 INFO     Training average loss at step 74000: 0.099697\n",
      "2023-12-07 07:01:11,732 INFO     Training average positive_sample_loss at step 74100: 0.115294\n",
      "2023-12-07 07:01:11,733 INFO     Training average negative_sample_loss at step 74100: 0.083003\n",
      "2023-12-07 07:01:11,733 INFO     Training average loss at step 74100: 0.099148\n",
      "2023-12-07 07:01:50,377 INFO     Training average positive_sample_loss at step 74200: 0.115736\n",
      "2023-12-07 07:01:50,377 INFO     Training average negative_sample_loss at step 74200: 0.083083\n",
      "2023-12-07 07:01:50,377 INFO     Training average loss at step 74200: 0.099410\n",
      "2023-12-07 07:02:28,540 INFO     Training average positive_sample_loss at step 74300: 0.115739\n",
      "2023-12-07 07:02:28,541 INFO     Training average negative_sample_loss at step 74300: 0.083293\n",
      "2023-12-07 07:02:28,541 INFO     Training average loss at step 74300: 0.099516\n",
      "2023-12-07 07:03:10,415 INFO     Training average positive_sample_loss at step 74400: 0.115666\n",
      "2023-12-07 07:03:10,416 INFO     Training average negative_sample_loss at step 74400: 0.084038\n",
      "2023-12-07 07:03:10,416 INFO     Training average loss at step 74400: 0.099852\n",
      "2023-12-07 07:03:48,869 INFO     Training average positive_sample_loss at step 74500: 0.115319\n",
      "2023-12-07 07:03:48,869 INFO     Training average negative_sample_loss at step 74500: 0.082864\n",
      "2023-12-07 07:03:48,869 INFO     Training average loss at step 74500: 0.099091\n",
      "2023-12-07 07:04:30,305 INFO     Training average positive_sample_loss at step 74600: 0.115253\n",
      "2023-12-07 07:04:30,306 INFO     Training average negative_sample_loss at step 74600: 0.083527\n",
      "2023-12-07 07:04:30,306 INFO     Training average loss at step 74600: 0.099390\n",
      "2023-12-07 07:05:09,104 INFO     Training average positive_sample_loss at step 74700: 0.115089\n",
      "2023-12-07 07:05:09,104 INFO     Training average negative_sample_loss at step 74700: 0.082918\n",
      "2023-12-07 07:05:09,104 INFO     Training average loss at step 74700: 0.099003\n",
      "2023-12-07 07:05:47,738 INFO     Training average positive_sample_loss at step 74800: 0.116152\n",
      "2023-12-07 07:05:47,739 INFO     Training average negative_sample_loss at step 74800: 0.083202\n",
      "2023-12-07 07:05:47,739 INFO     Training average loss at step 74800: 0.099677\n",
      "2023-12-07 07:06:29,181 INFO     Training average positive_sample_loss at step 74900: 0.115145\n",
      "2023-12-07 07:06:29,181 INFO     Training average negative_sample_loss at step 74900: 0.083323\n",
      "2023-12-07 07:06:29,182 INFO     Training average loss at step 74900: 0.099234\n",
      "2023-12-07 07:07:08,111 INFO     Training average positive_sample_loss at step 75000: 0.115435\n",
      "2023-12-07 07:07:08,111 INFO     Training average negative_sample_loss at step 75000: 0.083228\n",
      "2023-12-07 07:07:08,111 INFO     Training average loss at step 75000: 0.099331\n",
      "2023-12-07 07:07:52,719 INFO     Training average positive_sample_loss at step 75100: 0.115780\n",
      "2023-12-07 07:07:52,720 INFO     Training average negative_sample_loss at step 75100: 0.083075\n",
      "2023-12-07 07:07:52,720 INFO     Training average loss at step 75100: 0.099427\n",
      "2023-12-07 07:08:31,711 INFO     Training average positive_sample_loss at step 75200: 0.114680\n",
      "2023-12-07 07:08:31,711 INFO     Training average negative_sample_loss at step 75200: 0.083267\n",
      "2023-12-07 07:08:31,711 INFO     Training average loss at step 75200: 0.098974\n",
      "2023-12-07 07:09:10,464 INFO     Training average positive_sample_loss at step 75300: 0.116137\n",
      "2023-12-07 07:09:10,464 INFO     Training average negative_sample_loss at step 75300: 0.083476\n",
      "2023-12-07 07:09:10,464 INFO     Training average loss at step 75300: 0.099806\n",
      "2023-12-07 07:09:52,080 INFO     Training average positive_sample_loss at step 75400: 0.115336\n",
      "2023-12-07 07:09:52,080 INFO     Training average negative_sample_loss at step 75400: 0.083335\n",
      "2023-12-07 07:09:52,080 INFO     Training average loss at step 75400: 0.099335\n",
      "2023-12-07 07:10:30,561 INFO     Training average positive_sample_loss at step 75500: 0.116071\n",
      "2023-12-07 07:10:30,562 INFO     Training average negative_sample_loss at step 75500: 0.083220\n",
      "2023-12-07 07:10:30,562 INFO     Training average loss at step 75500: 0.099645\n",
      "2023-12-07 07:11:12,703 INFO     Training average positive_sample_loss at step 75600: 0.115449\n",
      "2023-12-07 07:11:12,703 INFO     Training average negative_sample_loss at step 75600: 0.082806\n",
      "2023-12-07 07:11:12,703 INFO     Training average loss at step 75600: 0.099128\n",
      "2023-12-07 07:11:50,906 INFO     Training average positive_sample_loss at step 75700: 0.114889\n",
      "2023-12-07 07:11:50,906 INFO     Training average negative_sample_loss at step 75700: 0.083035\n",
      "2023-12-07 07:11:50,906 INFO     Training average loss at step 75700: 0.098962\n",
      "2023-12-07 07:12:29,041 INFO     Training average positive_sample_loss at step 75800: 0.116086\n",
      "2023-12-07 07:12:29,041 INFO     Training average negative_sample_loss at step 75800: 0.083830\n",
      "2023-12-07 07:12:29,041 INFO     Training average loss at step 75800: 0.099958\n",
      "2023-12-07 07:13:10,561 INFO     Training average positive_sample_loss at step 75900: 0.115020\n",
      "2023-12-07 07:13:10,561 INFO     Training average negative_sample_loss at step 75900: 0.083380\n",
      "2023-12-07 07:13:10,561 INFO     Training average loss at step 75900: 0.099200\n",
      "2023-12-07 07:13:48,879 INFO     Training average positive_sample_loss at step 76000: 0.115640\n",
      "2023-12-07 07:13:48,879 INFO     Training average negative_sample_loss at step 76000: 0.082791\n",
      "2023-12-07 07:13:48,879 INFO     Training average loss at step 76000: 0.099216\n",
      "2023-12-07 07:14:27,096 INFO     Training average positive_sample_loss at step 76100: 0.116262\n",
      "2023-12-07 07:14:27,096 INFO     Training average negative_sample_loss at step 76100: 0.082784\n",
      "2023-12-07 07:14:27,096 INFO     Training average loss at step 76100: 0.099523\n",
      "2023-12-07 07:15:08,820 INFO     Training average positive_sample_loss at step 76200: 0.115190\n",
      "2023-12-07 07:15:08,820 INFO     Training average negative_sample_loss at step 76200: 0.083679\n",
      "2023-12-07 07:15:08,820 INFO     Training average loss at step 76200: 0.099434\n",
      "2023-12-07 07:15:47,436 INFO     Training average positive_sample_loss at step 76300: 0.115157\n",
      "2023-12-07 07:15:47,436 INFO     Training average negative_sample_loss at step 76300: 0.082948\n",
      "2023-12-07 07:15:47,436 INFO     Training average loss at step 76300: 0.099052\n",
      "2023-12-07 07:16:32,285 INFO     Training average positive_sample_loss at step 76400: 0.115485\n",
      "2023-12-07 07:16:32,285 INFO     Training average negative_sample_loss at step 76400: 0.081786\n",
      "2023-12-07 07:16:32,285 INFO     Training average loss at step 76400: 0.098636\n",
      "2023-12-07 07:17:10,906 INFO     Training average positive_sample_loss at step 76500: 0.115895\n",
      "2023-12-07 07:17:10,906 INFO     Training average negative_sample_loss at step 76500: 0.083781\n",
      "2023-12-07 07:17:10,906 INFO     Training average loss at step 76500: 0.099838\n",
      "2023-12-07 07:17:49,414 INFO     Training average positive_sample_loss at step 76600: 0.115454\n",
      "2023-12-07 07:17:49,414 INFO     Training average negative_sample_loss at step 76600: 0.083728\n",
      "2023-12-07 07:17:49,414 INFO     Training average loss at step 76600: 0.099591\n",
      "2023-12-07 07:18:32,209 INFO     Training average positive_sample_loss at step 76700: 0.114561\n",
      "2023-12-07 07:18:32,209 INFO     Training average negative_sample_loss at step 76700: 0.082817\n",
      "2023-12-07 07:18:32,209 INFO     Training average loss at step 76700: 0.098689\n",
      "2023-12-07 07:19:10,686 INFO     Training average positive_sample_loss at step 76800: 0.115986\n",
      "2023-12-07 07:19:10,687 INFO     Training average negative_sample_loss at step 76800: 0.082833\n",
      "2023-12-07 07:19:10,687 INFO     Training average loss at step 76800: 0.099409\n",
      "2023-12-07 07:19:52,849 INFO     Training average positive_sample_loss at step 76900: 0.116141\n",
      "2023-12-07 07:19:52,850 INFO     Training average negative_sample_loss at step 76900: 0.083159\n",
      "2023-12-07 07:19:52,850 INFO     Training average loss at step 76900: 0.099650\n",
      "2023-12-07 07:20:31,096 INFO     Training average positive_sample_loss at step 77000: 0.114977\n",
      "2023-12-07 07:20:31,096 INFO     Training average negative_sample_loss at step 77000: 0.082367\n",
      "2023-12-07 07:20:31,096 INFO     Training average loss at step 77000: 0.098672\n",
      "2023-12-07 07:21:09,757 INFO     Training average positive_sample_loss at step 77100: 0.115573\n",
      "2023-12-07 07:21:09,757 INFO     Training average negative_sample_loss at step 77100: 0.082553\n",
      "2023-12-07 07:21:09,758 INFO     Training average loss at step 77100: 0.099063\n",
      "2023-12-07 07:21:51,425 INFO     Training average positive_sample_loss at step 77200: 0.115437\n",
      "2023-12-07 07:21:51,425 INFO     Training average negative_sample_loss at step 77200: 0.082746\n",
      "2023-12-07 07:21:51,425 INFO     Training average loss at step 77200: 0.099092\n",
      "2023-12-07 07:22:29,756 INFO     Training average positive_sample_loss at step 77300: 0.115572\n",
      "2023-12-07 07:22:29,757 INFO     Training average negative_sample_loss at step 77300: 0.083280\n",
      "2023-12-07 07:22:29,757 INFO     Training average loss at step 77300: 0.099426\n",
      "2023-12-07 07:23:10,430 INFO     Training average positive_sample_loss at step 77400: 0.115444\n",
      "2023-12-07 07:23:10,431 INFO     Training average negative_sample_loss at step 77400: 0.083534\n",
      "2023-12-07 07:23:10,431 INFO     Training average loss at step 77400: 0.099489\n",
      "2023-12-07 07:23:50,470 INFO     Training average positive_sample_loss at step 77500: 0.114719\n",
      "2023-12-07 07:23:50,471 INFO     Training average negative_sample_loss at step 77500: 0.083004\n",
      "2023-12-07 07:23:50,471 INFO     Training average loss at step 77500: 0.098861\n",
      "2023-12-07 07:24:28,573 INFO     Training average positive_sample_loss at step 77600: 0.115648\n",
      "2023-12-07 07:24:28,573 INFO     Training average negative_sample_loss at step 77600: 0.082445\n",
      "2023-12-07 07:24:28,573 INFO     Training average loss at step 77600: 0.099047\n",
      "2023-12-07 07:25:13,889 INFO     Training average positive_sample_loss at step 77700: 0.115802\n",
      "2023-12-07 07:25:13,890 INFO     Training average negative_sample_loss at step 77700: 0.082986\n",
      "2023-12-07 07:25:13,890 INFO     Training average loss at step 77700: 0.099394\n",
      "2023-12-07 07:25:52,615 INFO     Training average positive_sample_loss at step 77800: 0.115067\n",
      "2023-12-07 07:25:52,616 INFO     Training average negative_sample_loss at step 77800: 0.083247\n",
      "2023-12-07 07:25:52,616 INFO     Training average loss at step 77800: 0.099157\n",
      "2023-12-07 07:26:31,019 INFO     Training average positive_sample_loss at step 77900: 0.115410\n",
      "2023-12-07 07:26:31,019 INFO     Training average negative_sample_loss at step 77900: 0.083122\n",
      "2023-12-07 07:26:31,019 INFO     Training average loss at step 77900: 0.099266\n",
      "2023-12-07 07:27:12,587 INFO     Training average positive_sample_loss at step 78000: 0.114891\n",
      "2023-12-07 07:27:12,588 INFO     Training average negative_sample_loss at step 78000: 0.082512\n",
      "2023-12-07 07:27:12,588 INFO     Training average loss at step 78000: 0.098702\n",
      "2023-12-07 07:27:51,016 INFO     Training average positive_sample_loss at step 78100: 0.115688\n",
      "2023-12-07 07:27:51,017 INFO     Training average negative_sample_loss at step 78100: 0.082827\n",
      "2023-12-07 07:27:51,017 INFO     Training average loss at step 78100: 0.099258\n",
      "2023-12-07 07:28:32,522 INFO     Training average positive_sample_loss at step 78200: 0.115887\n",
      "2023-12-07 07:28:32,522 INFO     Training average negative_sample_loss at step 78200: 0.084470\n",
      "2023-12-07 07:28:32,522 INFO     Training average loss at step 78200: 0.100178\n",
      "2023-12-07 07:29:11,374 INFO     Training average positive_sample_loss at step 78300: 0.115514\n",
      "2023-12-07 07:29:11,374 INFO     Training average negative_sample_loss at step 78300: 0.083225\n",
      "2023-12-07 07:29:11,374 INFO     Training average loss at step 78300: 0.099369\n",
      "2023-12-07 07:29:49,413 INFO     Training average positive_sample_loss at step 78400: 0.115385\n",
      "2023-12-07 07:29:49,414 INFO     Training average negative_sample_loss at step 78400: 0.082435\n",
      "2023-12-07 07:29:49,414 INFO     Training average loss at step 78400: 0.098910\n",
      "2023-12-07 07:30:31,222 INFO     Training average positive_sample_loss at step 78500: 0.115232\n",
      "2023-12-07 07:30:31,222 INFO     Training average negative_sample_loss at step 78500: 0.083120\n",
      "2023-12-07 07:30:31,222 INFO     Training average loss at step 78500: 0.099176\n",
      "2023-12-07 07:31:09,606 INFO     Training average positive_sample_loss at step 78600: 0.115422\n",
      "2023-12-07 07:31:09,606 INFO     Training average negative_sample_loss at step 78600: 0.083868\n",
      "2023-12-07 07:31:09,606 INFO     Training average loss at step 78600: 0.099645\n",
      "2023-12-07 07:31:51,037 INFO     Training average positive_sample_loss at step 78700: 0.116157\n",
      "2023-12-07 07:31:51,037 INFO     Training average negative_sample_loss at step 78700: 0.083404\n",
      "2023-12-07 07:31:51,037 INFO     Training average loss at step 78700: 0.099781\n",
      "2023-12-07 07:32:29,391 INFO     Training average positive_sample_loss at step 78800: 0.115200\n",
      "2023-12-07 07:32:29,391 INFO     Training average negative_sample_loss at step 78800: 0.082750\n",
      "2023-12-07 07:32:29,391 INFO     Training average loss at step 78800: 0.098975\n",
      "2023-12-07 07:33:08,032 INFO     Training average positive_sample_loss at step 78900: 0.115187\n",
      "2023-12-07 07:33:08,033 INFO     Training average negative_sample_loss at step 78900: 0.082504\n",
      "2023-12-07 07:33:08,033 INFO     Training average loss at step 78900: 0.098845\n",
      "2023-12-07 07:33:53,048 INFO     Training average positive_sample_loss at step 79000: 0.115724\n",
      "2023-12-07 07:33:53,048 INFO     Training average negative_sample_loss at step 79000: 0.083489\n",
      "2023-12-07 07:33:53,048 INFO     Training average loss at step 79000: 0.099607\n",
      "2023-12-07 07:34:31,472 INFO     Training average positive_sample_loss at step 79100: 0.115469\n",
      "2023-12-07 07:34:31,472 INFO     Training average negative_sample_loss at step 79100: 0.083199\n",
      "2023-12-07 07:34:31,472 INFO     Training average loss at step 79100: 0.099334\n",
      "2023-12-07 07:35:09,812 INFO     Training average positive_sample_loss at step 79200: 0.115500\n",
      "2023-12-07 07:35:09,812 INFO     Training average negative_sample_loss at step 79200: 0.082804\n",
      "2023-12-07 07:35:09,812 INFO     Training average loss at step 79200: 0.099152\n",
      "2023-12-07 07:35:52,666 INFO     Training average positive_sample_loss at step 79300: 0.114438\n",
      "2023-12-07 07:35:52,666 INFO     Training average negative_sample_loss at step 79300: 0.082997\n",
      "2023-12-07 07:35:52,666 INFO     Training average loss at step 79300: 0.098717\n",
      "2023-12-07 07:36:31,697 INFO     Training average positive_sample_loss at step 79400: 0.115646\n",
      "2023-12-07 07:36:31,697 INFO     Training average negative_sample_loss at step 79400: 0.083052\n",
      "2023-12-07 07:36:31,698 INFO     Training average loss at step 79400: 0.099349\n",
      "2023-12-07 07:37:13,657 INFO     Training average positive_sample_loss at step 79500: 0.115775\n",
      "2023-12-07 07:37:13,658 INFO     Training average negative_sample_loss at step 79500: 0.082930\n",
      "2023-12-07 07:37:13,658 INFO     Training average loss at step 79500: 0.099353\n",
      "2023-12-07 07:37:52,599 INFO     Training average positive_sample_loss at step 79600: 0.115280\n",
      "2023-12-07 07:37:52,600 INFO     Training average negative_sample_loss at step 79600: 0.083640\n",
      "2023-12-07 07:37:52,600 INFO     Training average loss at step 79600: 0.099460\n",
      "2023-12-07 07:38:31,476 INFO     Training average positive_sample_loss at step 79700: 0.115980\n",
      "2023-12-07 07:38:31,477 INFO     Training average negative_sample_loss at step 79700: 0.083776\n",
      "2023-12-07 07:38:31,477 INFO     Training average loss at step 79700: 0.099878\n",
      "2023-12-07 07:39:13,234 INFO     Training average positive_sample_loss at step 79800: 0.115524\n",
      "2023-12-07 07:39:13,235 INFO     Training average negative_sample_loss at step 79800: 0.083301\n",
      "2023-12-07 07:39:13,235 INFO     Training average loss at step 79800: 0.099413\n",
      "2023-12-07 07:39:51,991 INFO     Training average positive_sample_loss at step 79900: 0.115052\n",
      "2023-12-07 07:39:51,991 INFO     Training average negative_sample_loss at step 79900: 0.082488\n",
      "2023-12-07 07:39:51,991 INFO     Training average loss at step 79900: 0.098770\n",
      "2023-12-07 07:40:50,876 INFO     Training average positive_sample_loss at step 80000: 0.115716\n",
      "2023-12-07 07:40:50,877 INFO     Training average negative_sample_loss at step 80000: 0.082997\n",
      "2023-12-07 07:40:50,877 INFO     Training average loss at step 80000: 0.099356\n",
      "2023-12-07 07:40:50,877 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 07:40:51,322 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 07:41:15,043 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 07:41:30,162 INFO     Valid MRR at step 80000: 0.550185\n",
      "2023-12-07 07:41:30,162 INFO     Valid MR at step 80000: 256.775189\n",
      "2023-12-07 07:41:30,162 INFO     Valid HITS@1 at step 80000: 0.481752\n",
      "2023-12-07 07:41:30,162 INFO     Valid HITS@3 at step 80000: 0.583703\n",
      "2023-12-07 07:41:30,163 INFO     Valid HITS@10 at step 80000: 0.670339\n",
      "2023-12-07 07:42:01,651 INFO     Training average positive_sample_loss at step 80100: 0.114942\n",
      "2023-12-07 07:42:01,651 INFO     Training average negative_sample_loss at step 80100: 0.083466\n",
      "2023-12-07 07:42:01,651 INFO     Training average loss at step 80100: 0.099204\n",
      "2023-12-07 07:42:40,291 INFO     Training average positive_sample_loss at step 80200: 0.115840\n",
      "2023-12-07 07:42:40,292 INFO     Training average negative_sample_loss at step 80200: 0.083348\n",
      "2023-12-07 07:42:40,292 INFO     Training average loss at step 80200: 0.099594\n",
      "2023-12-07 07:43:24,767 INFO     Training average positive_sample_loss at step 80300: 0.116058\n",
      "2023-12-07 07:43:24,767 INFO     Training average negative_sample_loss at step 80300: 0.083888\n",
      "2023-12-07 07:43:24,768 INFO     Training average loss at step 80300: 0.099973\n",
      "2023-12-07 07:44:03,287 INFO     Training average positive_sample_loss at step 80400: 0.114999\n",
      "2023-12-07 07:44:03,287 INFO     Training average negative_sample_loss at step 80400: 0.082330\n",
      "2023-12-07 07:44:03,287 INFO     Training average loss at step 80400: 0.098664\n",
      "2023-12-07 07:44:44,822 INFO     Training average positive_sample_loss at step 80500: 0.115760\n",
      "2023-12-07 07:44:44,822 INFO     Training average negative_sample_loss at step 80500: 0.082654\n",
      "2023-12-07 07:44:44,822 INFO     Training average loss at step 80500: 0.099207\n",
      "2023-12-07 07:45:23,644 INFO     Training average positive_sample_loss at step 80600: 0.114911\n",
      "2023-12-07 07:45:23,645 INFO     Training average negative_sample_loss at step 80600: 0.082727\n",
      "2023-12-07 07:45:23,645 INFO     Training average loss at step 80600: 0.098819\n",
      "2023-12-07 07:46:01,749 INFO     Training average positive_sample_loss at step 80700: 0.115648\n",
      "2023-12-07 07:46:01,749 INFO     Training average negative_sample_loss at step 80700: 0.083278\n",
      "2023-12-07 07:46:01,749 INFO     Training average loss at step 80700: 0.099463\n",
      "2023-12-07 07:46:43,245 INFO     Training average positive_sample_loss at step 80800: 0.115517\n",
      "2023-12-07 07:46:43,246 INFO     Training average negative_sample_loss at step 80800: 0.083529\n",
      "2023-12-07 07:46:43,246 INFO     Training average loss at step 80800: 0.099523\n",
      "2023-12-07 07:47:21,983 INFO     Training average positive_sample_loss at step 80900: 0.115394\n",
      "2023-12-07 07:47:21,983 INFO     Training average negative_sample_loss at step 80900: 0.083032\n",
      "2023-12-07 07:47:21,983 INFO     Training average loss at step 80900: 0.099213\n",
      "2023-12-07 07:48:00,567 INFO     Training average positive_sample_loss at step 81000: 0.115663\n",
      "2023-12-07 07:48:00,567 INFO     Training average negative_sample_loss at step 81000: 0.082876\n",
      "2023-12-07 07:48:00,567 INFO     Training average loss at step 81000: 0.099270\n",
      "2023-12-07 07:48:42,149 INFO     Training average positive_sample_loss at step 81100: 0.115131\n",
      "2023-12-07 07:48:42,150 INFO     Training average negative_sample_loss at step 81100: 0.083615\n",
      "2023-12-07 07:48:42,150 INFO     Training average loss at step 81100: 0.099373\n",
      "2023-12-07 07:49:21,299 INFO     Training average positive_sample_loss at step 81200: 0.115797\n",
      "2023-12-07 07:49:21,299 INFO     Training average negative_sample_loss at step 81200: 0.082746\n",
      "2023-12-07 07:49:21,299 INFO     Training average loss at step 81200: 0.099271\n",
      "2023-12-07 07:50:02,996 INFO     Training average positive_sample_loss at step 81300: 0.115797\n",
      "2023-12-07 07:50:02,997 INFO     Training average negative_sample_loss at step 81300: 0.082155\n",
      "2023-12-07 07:50:02,997 INFO     Training average loss at step 81300: 0.098976\n",
      "2023-12-07 07:50:41,233 INFO     Training average positive_sample_loss at step 81400: 0.114932\n",
      "2023-12-07 07:50:41,234 INFO     Training average negative_sample_loss at step 81400: 0.083045\n",
      "2023-12-07 07:50:41,234 INFO     Training average loss at step 81400: 0.098989\n",
      "2023-12-07 07:51:19,952 INFO     Training average positive_sample_loss at step 81500: 0.115581\n",
      "2023-12-07 07:51:19,952 INFO     Training average negative_sample_loss at step 81500: 0.083757\n",
      "2023-12-07 07:51:19,952 INFO     Training average loss at step 81500: 0.099669\n",
      "2023-12-07 07:52:04,567 INFO     Training average positive_sample_loss at step 81600: 0.114838\n",
      "2023-12-07 07:52:04,567 INFO     Training average negative_sample_loss at step 81600: 0.083178\n",
      "2023-12-07 07:52:04,567 INFO     Training average loss at step 81600: 0.099008\n",
      "2023-12-07 07:52:42,630 INFO     Training average positive_sample_loss at step 81700: 0.115369\n",
      "2023-12-07 07:52:42,631 INFO     Training average negative_sample_loss at step 81700: 0.083366\n",
      "2023-12-07 07:52:42,631 INFO     Training average loss at step 81700: 0.099367\n",
      "2023-12-07 07:53:24,595 INFO     Training average positive_sample_loss at step 81800: 0.115965\n",
      "2023-12-07 07:53:24,596 INFO     Training average negative_sample_loss at step 81800: 0.083561\n",
      "2023-12-07 07:53:24,596 INFO     Training average loss at step 81800: 0.099763\n",
      "2023-12-07 07:54:03,144 INFO     Training average positive_sample_loss at step 81900: 0.115091\n",
      "2023-12-07 07:54:03,145 INFO     Training average negative_sample_loss at step 81900: 0.082587\n",
      "2023-12-07 07:54:03,145 INFO     Training average loss at step 81900: 0.098839\n",
      "2023-12-07 07:54:41,483 INFO     Training average positive_sample_loss at step 82000: 0.115741\n",
      "2023-12-07 07:54:41,484 INFO     Training average negative_sample_loss at step 82000: 0.082845\n",
      "2023-12-07 07:54:41,484 INFO     Training average loss at step 82000: 0.099293\n",
      "2023-12-07 07:55:23,331 INFO     Training average positive_sample_loss at step 82100: 0.115599\n",
      "2023-12-07 07:55:23,332 INFO     Training average negative_sample_loss at step 82100: 0.083090\n",
      "2023-12-07 07:55:23,332 INFO     Training average loss at step 82100: 0.099345\n",
      "2023-12-07 07:56:01,945 INFO     Training average positive_sample_loss at step 82200: 0.115004\n",
      "2023-12-07 07:56:01,945 INFO     Training average negative_sample_loss at step 82200: 0.083061\n",
      "2023-12-07 07:56:01,945 INFO     Training average loss at step 82200: 0.099032\n",
      "2023-12-07 07:56:40,062 INFO     Training average positive_sample_loss at step 82300: 0.116041\n",
      "2023-12-07 07:56:40,062 INFO     Training average negative_sample_loss at step 82300: 0.082798\n",
      "2023-12-07 07:56:40,062 INFO     Training average loss at step 82300: 0.099420\n",
      "2023-12-07 07:57:21,756 INFO     Training average positive_sample_loss at step 82400: 0.114907\n",
      "2023-12-07 07:57:21,756 INFO     Training average negative_sample_loss at step 82400: 0.082903\n",
      "2023-12-07 07:57:21,756 INFO     Training average loss at step 82400: 0.098905\n",
      "2023-12-07 07:58:00,902 INFO     Training average positive_sample_loss at step 82500: 0.115745\n",
      "2023-12-07 07:58:00,902 INFO     Training average negative_sample_loss at step 82500: 0.082255\n",
      "2023-12-07 07:58:00,903 INFO     Training average loss at step 82500: 0.099000\n",
      "2023-12-07 07:58:42,396 INFO     Training average positive_sample_loss at step 82600: 0.115313\n",
      "2023-12-07 07:58:42,397 INFO     Training average negative_sample_loss at step 82600: 0.082520\n",
      "2023-12-07 07:58:42,397 INFO     Training average loss at step 82600: 0.098917\n",
      "2023-12-07 07:59:21,463 INFO     Training average positive_sample_loss at step 82700: 0.115393\n",
      "2023-12-07 07:59:21,463 INFO     Training average negative_sample_loss at step 82700: 0.082865\n",
      "2023-12-07 07:59:21,463 INFO     Training average loss at step 82700: 0.099129\n",
      "2023-12-07 08:00:00,367 INFO     Training average positive_sample_loss at step 82800: 0.115505\n",
      "2023-12-07 08:00:00,368 INFO     Training average negative_sample_loss at step 82800: 0.082481\n",
      "2023-12-07 08:00:00,368 INFO     Training average loss at step 82800: 0.098993\n",
      "2023-12-07 08:00:45,207 INFO     Training average positive_sample_loss at step 82900: 0.114814\n",
      "2023-12-07 08:00:45,207 INFO     Training average negative_sample_loss at step 82900: 0.082677\n",
      "2023-12-07 08:00:45,207 INFO     Training average loss at step 82900: 0.098746\n",
      "2023-12-07 08:01:23,579 INFO     Training average positive_sample_loss at step 83000: 0.115577\n",
      "2023-12-07 08:01:23,579 INFO     Training average negative_sample_loss at step 83000: 0.082634\n",
      "2023-12-07 08:01:23,579 INFO     Training average loss at step 83000: 0.099105\n",
      "2023-12-07 08:02:05,620 INFO     Training average positive_sample_loss at step 83100: 0.115662\n",
      "2023-12-07 08:02:05,620 INFO     Training average negative_sample_loss at step 83100: 0.083308\n",
      "2023-12-07 08:02:05,620 INFO     Training average loss at step 83100: 0.099485\n",
      "2023-12-07 08:02:44,108 INFO     Training average positive_sample_loss at step 83200: 0.114952\n",
      "2023-12-07 08:02:44,108 INFO     Training average negative_sample_loss at step 83200: 0.083206\n",
      "2023-12-07 08:02:44,108 INFO     Training average loss at step 83200: 0.099079\n",
      "2023-12-07 08:03:22,775 INFO     Training average positive_sample_loss at step 83300: 0.115703\n",
      "2023-12-07 08:03:22,775 INFO     Training average negative_sample_loss at step 83300: 0.083093\n",
      "2023-12-07 08:03:22,775 INFO     Training average loss at step 83300: 0.099398\n",
      "2023-12-07 08:04:04,516 INFO     Training average positive_sample_loss at step 83400: 0.114950\n",
      "2023-12-07 08:04:04,516 INFO     Training average negative_sample_loss at step 83400: 0.082247\n",
      "2023-12-07 08:04:04,517 INFO     Training average loss at step 83400: 0.098599\n",
      "2023-12-07 08:04:42,770 INFO     Training average positive_sample_loss at step 83500: 0.115580\n",
      "2023-12-07 08:04:42,771 INFO     Training average negative_sample_loss at step 83500: 0.083773\n",
      "2023-12-07 08:04:42,771 INFO     Training average loss at step 83500: 0.099677\n",
      "2023-12-07 08:05:24,277 INFO     Training average positive_sample_loss at step 83600: 0.115838\n",
      "2023-12-07 08:05:24,277 INFO     Training average negative_sample_loss at step 83600: 0.083447\n",
      "2023-12-07 08:05:24,277 INFO     Training average loss at step 83600: 0.099643\n",
      "2023-12-07 08:06:03,251 INFO     Training average positive_sample_loss at step 83700: 0.114340\n",
      "2023-12-07 08:06:03,251 INFO     Training average negative_sample_loss at step 83700: 0.083030\n",
      "2023-12-07 08:06:03,251 INFO     Training average loss at step 83700: 0.098685\n",
      "2023-12-07 08:06:42,662 INFO     Training average positive_sample_loss at step 83800: 0.116269\n",
      "2023-12-07 08:06:42,662 INFO     Training average negative_sample_loss at step 83800: 0.083702\n",
      "2023-12-07 08:06:42,662 INFO     Training average loss at step 83800: 0.099986\n",
      "2023-12-07 08:07:24,865 INFO     Training average positive_sample_loss at step 83900: 0.115484\n",
      "2023-12-07 08:07:24,865 INFO     Training average negative_sample_loss at step 83900: 0.083703\n",
      "2023-12-07 08:07:24,865 INFO     Training average loss at step 83900: 0.099594\n",
      "2023-12-07 08:08:03,602 INFO     Training average positive_sample_loss at step 84000: 0.115582\n",
      "2023-12-07 08:08:03,603 INFO     Training average negative_sample_loss at step 84000: 0.082713\n",
      "2023-12-07 08:08:03,603 INFO     Training average loss at step 84000: 0.099148\n",
      "2023-12-07 08:08:42,115 INFO     Training average positive_sample_loss at step 84100: 0.115662\n",
      "2023-12-07 08:08:42,115 INFO     Training average negative_sample_loss at step 84100: 0.083223\n",
      "2023-12-07 08:08:42,115 INFO     Training average loss at step 84100: 0.099442\n",
      "2023-12-07 08:09:27,340 INFO     Training average positive_sample_loss at step 84200: 0.115004\n",
      "2023-12-07 08:09:27,340 INFO     Training average negative_sample_loss at step 84200: 0.083800\n",
      "2023-12-07 08:09:27,340 INFO     Training average loss at step 84200: 0.099402\n",
      "2023-12-07 08:10:06,082 INFO     Training average positive_sample_loss at step 84300: 0.115501\n",
      "2023-12-07 08:10:06,082 INFO     Training average negative_sample_loss at step 84300: 0.083107\n",
      "2023-12-07 08:10:06,082 INFO     Training average loss at step 84300: 0.099304\n",
      "2023-12-07 08:10:48,017 INFO     Training average positive_sample_loss at step 84400: 0.115388\n",
      "2023-12-07 08:10:48,018 INFO     Training average negative_sample_loss at step 84400: 0.083414\n",
      "2023-12-07 08:10:48,018 INFO     Training average loss at step 84400: 0.099401\n",
      "2023-12-07 08:11:26,670 INFO     Training average positive_sample_loss at step 84500: 0.115802\n",
      "2023-12-07 08:11:26,670 INFO     Training average negative_sample_loss at step 84500: 0.083751\n",
      "2023-12-07 08:11:26,670 INFO     Training average loss at step 84500: 0.099777\n",
      "2023-12-07 08:12:05,399 INFO     Training average positive_sample_loss at step 84600: 0.115593\n",
      "2023-12-07 08:12:05,399 INFO     Training average negative_sample_loss at step 84600: 0.083539\n",
      "2023-12-07 08:12:05,399 INFO     Training average loss at step 84600: 0.099566\n",
      "2023-12-07 08:12:47,675 INFO     Training average positive_sample_loss at step 84700: 0.115200\n",
      "2023-12-07 08:12:47,675 INFO     Training average negative_sample_loss at step 84700: 0.082955\n",
      "2023-12-07 08:12:47,675 INFO     Training average loss at step 84700: 0.099078\n",
      "2023-12-07 08:13:26,652 INFO     Training average positive_sample_loss at step 84800: 0.115543\n",
      "2023-12-07 08:13:26,652 INFO     Training average negative_sample_loss at step 84800: 0.083005\n",
      "2023-12-07 08:13:26,652 INFO     Training average loss at step 84800: 0.099274\n",
      "2023-12-07 08:14:08,877 INFO     Training average positive_sample_loss at step 84900: 0.115522\n",
      "2023-12-07 08:14:08,877 INFO     Training average negative_sample_loss at step 84900: 0.083457\n",
      "2023-12-07 08:14:08,877 INFO     Training average loss at step 84900: 0.099489\n",
      "2023-12-07 08:14:47,696 INFO     Training average positive_sample_loss at step 85000: 0.115272\n",
      "2023-12-07 08:14:47,697 INFO     Training average negative_sample_loss at step 85000: 0.083272\n",
      "2023-12-07 08:14:47,697 INFO     Training average loss at step 85000: 0.099272\n",
      "2023-12-07 08:15:26,207 INFO     Training average positive_sample_loss at step 85100: 0.115460\n",
      "2023-12-07 08:15:26,207 INFO     Training average negative_sample_loss at step 85100: 0.082806\n",
      "2023-12-07 08:15:26,207 INFO     Training average loss at step 85100: 0.099133\n",
      "2023-12-07 08:16:07,704 INFO     Training average positive_sample_loss at step 85200: 0.115305\n",
      "2023-12-07 08:16:07,704 INFO     Training average negative_sample_loss at step 85200: 0.082870\n",
      "2023-12-07 08:16:07,705 INFO     Training average loss at step 85200: 0.099088\n",
      "2023-12-07 08:16:46,279 INFO     Training average positive_sample_loss at step 85300: 0.115708\n",
      "2023-12-07 08:16:46,279 INFO     Training average negative_sample_loss at step 85300: 0.083008\n",
      "2023-12-07 08:16:46,279 INFO     Training average loss at step 85300: 0.099358\n",
      "2023-12-07 08:17:30,846 INFO     Training average positive_sample_loss at step 85400: 0.115749\n",
      "2023-12-07 08:17:30,847 INFO     Training average negative_sample_loss at step 85400: 0.083534\n",
      "2023-12-07 08:17:30,847 INFO     Training average loss at step 85400: 0.099641\n",
      "2023-12-07 08:18:09,277 INFO     Training average positive_sample_loss at step 85500: 0.114761\n",
      "2023-12-07 08:18:09,277 INFO     Training average negative_sample_loss at step 85500: 0.082586\n",
      "2023-12-07 08:18:09,277 INFO     Training average loss at step 85500: 0.098674\n",
      "2023-12-07 08:18:48,063 INFO     Training average positive_sample_loss at step 85600: 0.115993\n",
      "2023-12-07 08:18:48,064 INFO     Training average negative_sample_loss at step 85600: 0.083510\n",
      "2023-12-07 08:18:48,064 INFO     Training average loss at step 85600: 0.099752\n",
      "2023-12-07 08:19:29,736 INFO     Training average positive_sample_loss at step 85700: 0.115323\n",
      "2023-12-07 08:19:29,736 INFO     Training average negative_sample_loss at step 85700: 0.083531\n",
      "2023-12-07 08:19:29,736 INFO     Training average loss at step 85700: 0.099427\n",
      "2023-12-07 08:20:08,214 INFO     Training average positive_sample_loss at step 85800: 0.115466\n",
      "2023-12-07 08:20:08,214 INFO     Training average negative_sample_loss at step 85800: 0.083108\n",
      "2023-12-07 08:20:08,214 INFO     Training average loss at step 85800: 0.099287\n",
      "2023-12-07 08:20:47,065 INFO     Training average positive_sample_loss at step 85900: 0.115662\n",
      "2023-12-07 08:20:47,066 INFO     Training average negative_sample_loss at step 85900: 0.083279\n",
      "2023-12-07 08:20:47,066 INFO     Training average loss at step 85900: 0.099470\n",
      "2023-12-07 08:21:28,935 INFO     Training average positive_sample_loss at step 86000: 0.114610\n",
      "2023-12-07 08:21:28,935 INFO     Training average negative_sample_loss at step 86000: 0.082952\n",
      "2023-12-07 08:21:28,935 INFO     Training average loss at step 86000: 0.098781\n",
      "2023-12-07 08:22:07,943 INFO     Training average positive_sample_loss at step 86100: 0.115698\n",
      "2023-12-07 08:22:07,943 INFO     Training average negative_sample_loss at step 86100: 0.082864\n",
      "2023-12-07 08:22:07,943 INFO     Training average loss at step 86100: 0.099281\n",
      "2023-12-07 08:22:49,776 INFO     Training average positive_sample_loss at step 86200: 0.115680\n",
      "2023-12-07 08:22:49,777 INFO     Training average negative_sample_loss at step 86200: 0.082905\n",
      "2023-12-07 08:22:49,777 INFO     Training average loss at step 86200: 0.099293\n",
      "2023-12-07 08:23:29,070 INFO     Training average positive_sample_loss at step 86300: 0.115369\n",
      "2023-12-07 08:23:29,070 INFO     Training average negative_sample_loss at step 86300: 0.083316\n",
      "2023-12-07 08:23:29,070 INFO     Training average loss at step 86300: 0.099343\n",
      "2023-12-07 08:24:07,868 INFO     Training average positive_sample_loss at step 86400: 0.115550\n",
      "2023-12-07 08:24:07,868 INFO     Training average negative_sample_loss at step 86400: 0.083411\n",
      "2023-12-07 08:24:07,868 INFO     Training average loss at step 86400: 0.099480\n",
      "2023-12-07 08:24:49,792 INFO     Training average positive_sample_loss at step 86500: 0.114971\n",
      "2023-12-07 08:24:49,793 INFO     Training average negative_sample_loss at step 86500: 0.084171\n",
      "2023-12-07 08:24:49,793 INFO     Training average loss at step 86500: 0.099571\n",
      "2023-12-07 08:25:28,859 INFO     Training average positive_sample_loss at step 86600: 0.115705\n",
      "2023-12-07 08:25:28,859 INFO     Training average negative_sample_loss at step 86600: 0.083563\n",
      "2023-12-07 08:25:28,860 INFO     Training average loss at step 86600: 0.099634\n",
      "2023-12-07 08:26:14,085 INFO     Training average positive_sample_loss at step 86700: 0.115819\n",
      "2023-12-07 08:26:14,086 INFO     Training average negative_sample_loss at step 86700: 0.082642\n",
      "2023-12-07 08:26:14,086 INFO     Training average loss at step 86700: 0.099231\n",
      "2023-12-07 08:26:52,811 INFO     Training average positive_sample_loss at step 86800: 0.115241\n",
      "2023-12-07 08:26:52,811 INFO     Training average negative_sample_loss at step 86800: 0.082637\n",
      "2023-12-07 08:26:52,811 INFO     Training average loss at step 86800: 0.098939\n",
      "2023-12-07 08:27:31,299 INFO     Training average positive_sample_loss at step 86900: 0.115693\n",
      "2023-12-07 08:27:31,299 INFO     Training average negative_sample_loss at step 86900: 0.082376\n",
      "2023-12-07 08:27:31,299 INFO     Training average loss at step 86900: 0.099035\n",
      "2023-12-07 08:28:14,342 INFO     Training average positive_sample_loss at step 87000: 0.115095\n",
      "2023-12-07 08:28:14,343 INFO     Training average negative_sample_loss at step 87000: 0.083346\n",
      "2023-12-07 08:28:14,343 INFO     Training average loss at step 87000: 0.099220\n",
      "2023-12-07 08:28:52,424 INFO     Training average positive_sample_loss at step 87100: 0.114862\n",
      "2023-12-07 08:28:52,424 INFO     Training average negative_sample_loss at step 87100: 0.082108\n",
      "2023-12-07 08:28:52,424 INFO     Training average loss at step 87100: 0.098485\n",
      "2023-12-07 08:29:30,542 INFO     Training average positive_sample_loss at step 87200: 0.116294\n",
      "2023-12-07 08:29:30,543 INFO     Training average negative_sample_loss at step 87200: 0.083276\n",
      "2023-12-07 08:29:30,543 INFO     Training average loss at step 87200: 0.099785\n",
      "2023-12-07 08:30:12,174 INFO     Training average positive_sample_loss at step 87300: 0.114363\n",
      "2023-12-07 08:30:12,174 INFO     Training average negative_sample_loss at step 87300: 0.082674\n",
      "2023-12-07 08:30:12,174 INFO     Training average loss at step 87300: 0.098518\n",
      "2023-12-07 08:30:50,777 INFO     Training average positive_sample_loss at step 87400: 0.115668\n",
      "2023-12-07 08:30:50,777 INFO     Training average negative_sample_loss at step 87400: 0.084121\n",
      "2023-12-07 08:30:50,777 INFO     Training average loss at step 87400: 0.099895\n",
      "2023-12-07 08:31:32,287 INFO     Training average positive_sample_loss at step 87500: 0.115690\n",
      "2023-12-07 08:31:32,287 INFO     Training average negative_sample_loss at step 87500: 0.083143\n",
      "2023-12-07 08:31:32,287 INFO     Training average loss at step 87500: 0.099416\n",
      "2023-12-07 08:32:10,968 INFO     Training average positive_sample_loss at step 87600: 0.115517\n",
      "2023-12-07 08:32:10,969 INFO     Training average negative_sample_loss at step 87600: 0.083219\n",
      "2023-12-07 08:32:10,969 INFO     Training average loss at step 87600: 0.099368\n",
      "2023-12-07 08:32:49,622 INFO     Training average positive_sample_loss at step 87700: 0.115879\n",
      "2023-12-07 08:32:49,623 INFO     Training average negative_sample_loss at step 87700: 0.083191\n",
      "2023-12-07 08:32:49,623 INFO     Training average loss at step 87700: 0.099535\n",
      "2023-12-07 08:33:31,722 INFO     Training average positive_sample_loss at step 87800: 0.115012\n",
      "2023-12-07 08:33:31,722 INFO     Training average negative_sample_loss at step 87800: 0.084182\n",
      "2023-12-07 08:33:31,722 INFO     Training average loss at step 87800: 0.099597\n",
      "2023-12-07 08:34:10,500 INFO     Training average positive_sample_loss at step 87900: 0.115308\n",
      "2023-12-07 08:34:10,500 INFO     Training average negative_sample_loss at step 87900: 0.082243\n",
      "2023-12-07 08:34:10,500 INFO     Training average loss at step 87900: 0.098775\n",
      "2023-12-07 08:34:55,429 INFO     Training average positive_sample_loss at step 88000: 0.115890\n",
      "2023-12-07 08:34:55,429 INFO     Training average negative_sample_loss at step 88000: 0.083792\n",
      "2023-12-07 08:34:55,429 INFO     Training average loss at step 88000: 0.099841\n",
      "2023-12-07 08:35:33,636 INFO     Training average positive_sample_loss at step 88100: 0.115129\n",
      "2023-12-07 08:35:33,636 INFO     Training average negative_sample_loss at step 88100: 0.082851\n",
      "2023-12-07 08:35:33,636 INFO     Training average loss at step 88100: 0.098990\n",
      "2023-12-07 08:36:11,580 INFO     Training average positive_sample_loss at step 88200: 0.115492\n",
      "2023-12-07 08:36:11,580 INFO     Training average negative_sample_loss at step 88200: 0.083172\n",
      "2023-12-07 08:36:11,580 INFO     Training average loss at step 88200: 0.099332\n",
      "2023-12-07 08:36:54,382 INFO     Training average positive_sample_loss at step 88300: 0.115537\n",
      "2023-12-07 08:36:54,382 INFO     Training average negative_sample_loss at step 88300: 0.082957\n",
      "2023-12-07 08:36:54,382 INFO     Training average loss at step 88300: 0.099247\n",
      "2023-12-07 08:37:32,888 INFO     Training average positive_sample_loss at step 88400: 0.115254\n",
      "2023-12-07 08:37:32,889 INFO     Training average negative_sample_loss at step 88400: 0.083221\n",
      "2023-12-07 08:37:32,889 INFO     Training average loss at step 88400: 0.099237\n",
      "2023-12-07 08:38:14,543 INFO     Training average positive_sample_loss at step 88500: 0.115788\n",
      "2023-12-07 08:38:14,544 INFO     Training average negative_sample_loss at step 88500: 0.083846\n",
      "2023-12-07 08:38:14,544 INFO     Training average loss at step 88500: 0.099817\n",
      "2023-12-07 08:38:52,966 INFO     Training average positive_sample_loss at step 88600: 0.115186\n",
      "2023-12-07 08:38:52,966 INFO     Training average negative_sample_loss at step 88600: 0.082907\n",
      "2023-12-07 08:38:52,966 INFO     Training average loss at step 88600: 0.099046\n",
      "2023-12-07 08:39:31,298 INFO     Training average positive_sample_loss at step 88700: 0.115365\n",
      "2023-12-07 08:39:31,299 INFO     Training average negative_sample_loss at step 88700: 0.082912\n",
      "2023-12-07 08:39:31,299 INFO     Training average loss at step 88700: 0.099138\n",
      "2023-12-07 08:40:13,055 INFO     Training average positive_sample_loss at step 88800: 0.115092\n",
      "2023-12-07 08:40:13,055 INFO     Training average negative_sample_loss at step 88800: 0.082943\n",
      "2023-12-07 08:40:13,055 INFO     Training average loss at step 88800: 0.099018\n",
      "2023-12-07 08:40:51,781 INFO     Training average positive_sample_loss at step 88900: 0.115193\n",
      "2023-12-07 08:40:51,781 INFO     Training average negative_sample_loss at step 88900: 0.083117\n",
      "2023-12-07 08:40:51,781 INFO     Training average loss at step 88900: 0.099155\n",
      "2023-12-07 08:41:30,717 INFO     Training average positive_sample_loss at step 89000: 0.116322\n",
      "2023-12-07 08:41:30,717 INFO     Training average negative_sample_loss at step 89000: 0.083551\n",
      "2023-12-07 08:41:30,717 INFO     Training average loss at step 89000: 0.099937\n",
      "2023-12-07 08:42:12,849 INFO     Training average positive_sample_loss at step 89100: 0.114357\n",
      "2023-12-07 08:42:12,850 INFO     Training average negative_sample_loss at step 89100: 0.083329\n",
      "2023-12-07 08:42:12,850 INFO     Training average loss at step 89100: 0.098843\n",
      "2023-12-07 08:42:51,573 INFO     Training average positive_sample_loss at step 89200: 0.115915\n",
      "2023-12-07 08:42:51,573 INFO     Training average negative_sample_loss at step 89200: 0.083792\n",
      "2023-12-07 08:42:51,573 INFO     Training average loss at step 89200: 0.099854\n",
      "2023-12-07 08:43:36,648 INFO     Training average positive_sample_loss at step 89300: 0.115813\n",
      "2023-12-07 08:43:36,649 INFO     Training average negative_sample_loss at step 89300: 0.082905\n",
      "2023-12-07 08:43:36,649 INFO     Training average loss at step 89300: 0.099359\n",
      "2023-12-07 08:44:15,363 INFO     Training average positive_sample_loss at step 89400: 0.114885\n",
      "2023-12-07 08:44:15,363 INFO     Training average negative_sample_loss at step 89400: 0.082548\n",
      "2023-12-07 08:44:15,363 INFO     Training average loss at step 89400: 0.098716\n",
      "2023-12-07 08:44:54,106 INFO     Training average positive_sample_loss at step 89500: 0.115921\n",
      "2023-12-07 08:44:54,106 INFO     Training average negative_sample_loss at step 89500: 0.083795\n",
      "2023-12-07 08:44:54,107 INFO     Training average loss at step 89500: 0.099858\n",
      "2023-12-07 08:45:36,908 INFO     Training average positive_sample_loss at step 89600: 0.114444\n",
      "2023-12-07 08:45:36,909 INFO     Training average negative_sample_loss at step 89600: 0.081489\n",
      "2023-12-07 08:45:36,909 INFO     Training average loss at step 89600: 0.097967\n",
      "2023-12-07 08:46:15,641 INFO     Training average positive_sample_loss at step 89700: 0.115762\n",
      "2023-12-07 08:46:15,641 INFO     Training average negative_sample_loss at step 89700: 0.083046\n",
      "2023-12-07 08:46:15,641 INFO     Training average loss at step 89700: 0.099404\n",
      "2023-12-07 08:46:57,163 INFO     Training average positive_sample_loss at step 89800: 0.115911\n",
      "2023-12-07 08:46:57,164 INFO     Training average negative_sample_loss at step 89800: 0.082900\n",
      "2023-12-07 08:46:57,164 INFO     Training average loss at step 89800: 0.099406\n",
      "2023-12-07 08:47:35,922 INFO     Training average positive_sample_loss at step 89900: 0.114850\n",
      "2023-12-07 08:47:35,922 INFO     Training average negative_sample_loss at step 89900: 0.082580\n",
      "2023-12-07 08:47:35,922 INFO     Training average loss at step 89900: 0.098715\n",
      "2023-12-07 08:48:31,957 INFO     Training average positive_sample_loss at step 90000: 0.115936\n",
      "2023-12-07 08:48:31,957 INFO     Training average negative_sample_loss at step 90000: 0.082616\n",
      "2023-12-07 08:48:31,958 INFO     Training average loss at step 90000: 0.099276\n",
      "2023-12-07 08:48:31,958 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 08:48:32,402 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 08:48:57,103 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 08:49:14,791 INFO     Valid MRR at step 90000: 0.550224\n",
      "2023-12-07 08:49:14,791 INFO     Valid MR at step 90000: 257.219967\n",
      "2023-12-07 08:49:14,791 INFO     Valid HITS@1 at step 90000: 0.481991\n",
      "2023-12-07 08:49:14,791 INFO     Valid HITS@3 at step 90000: 0.584317\n",
      "2023-12-07 08:49:14,791 INFO     Valid HITS@10 at step 90000: 0.670373\n",
      "2023-12-07 08:49:52,118 INFO     Training average positive_sample_loss at step 90100: 0.114650\n",
      "2023-12-07 08:49:52,119 INFO     Training average negative_sample_loss at step 90100: 0.083504\n",
      "2023-12-07 08:49:52,119 INFO     Training average loss at step 90100: 0.099077\n",
      "2023-12-07 08:50:31,114 INFO     Training average positive_sample_loss at step 90200: 0.115753\n",
      "2023-12-07 08:50:31,115 INFO     Training average negative_sample_loss at step 90200: 0.083178\n",
      "2023-12-07 08:50:31,115 INFO     Training average loss at step 90200: 0.099465\n",
      "2023-12-07 08:51:12,669 INFO     Training average positive_sample_loss at step 90300: 0.115712\n",
      "2023-12-07 08:51:12,669 INFO     Training average negative_sample_loss at step 90300: 0.082836\n",
      "2023-12-07 08:51:12,669 INFO     Training average loss at step 90300: 0.099274\n",
      "2023-12-07 08:51:51,830 INFO     Training average positive_sample_loss at step 90400: 0.115044\n",
      "2023-12-07 08:51:51,830 INFO     Training average negative_sample_loss at step 90400: 0.083292\n",
      "2023-12-07 08:51:51,830 INFO     Training average loss at step 90400: 0.099168\n",
      "2023-12-07 08:52:30,538 INFO     Training average positive_sample_loss at step 90500: 0.115305\n",
      "2023-12-07 08:52:30,538 INFO     Training average negative_sample_loss at step 90500: 0.082916\n",
      "2023-12-07 08:52:30,538 INFO     Training average loss at step 90500: 0.099110\n",
      "2023-12-07 08:53:15,499 INFO     Training average positive_sample_loss at step 90600: 0.115165\n",
      "2023-12-07 08:53:15,499 INFO     Training average negative_sample_loss at step 90600: 0.082927\n",
      "2023-12-07 08:53:15,499 INFO     Training average loss at step 90600: 0.099046\n",
      "2023-12-07 08:53:53,934 INFO     Training average positive_sample_loss at step 90700: 0.115236\n",
      "2023-12-07 08:53:53,934 INFO     Training average negative_sample_loss at step 90700: 0.083227\n",
      "2023-12-07 08:53:53,935 INFO     Training average loss at step 90700: 0.099232\n",
      "2023-12-07 08:54:32,680 INFO     Training average positive_sample_loss at step 90800: 0.115840\n",
      "2023-12-07 08:54:32,680 INFO     Training average negative_sample_loss at step 90800: 0.083005\n",
      "2023-12-07 08:54:32,680 INFO     Training average loss at step 90800: 0.099423\n",
      "2023-12-07 08:55:15,975 INFO     Training average positive_sample_loss at step 90900: 0.115022\n",
      "2023-12-07 08:55:15,975 INFO     Training average negative_sample_loss at step 90900: 0.083073\n",
      "2023-12-07 08:55:15,975 INFO     Training average loss at step 90900: 0.099048\n",
      "2023-12-07 08:55:55,314 INFO     Training average positive_sample_loss at step 91000: 0.115229\n",
      "2023-12-07 08:55:55,315 INFO     Training average negative_sample_loss at step 91000: 0.082378\n",
      "2023-12-07 08:55:55,315 INFO     Training average loss at step 91000: 0.098803\n",
      "2023-12-07 08:56:37,659 INFO     Training average positive_sample_loss at step 91100: 0.115932\n",
      "2023-12-07 08:56:37,659 INFO     Training average negative_sample_loss at step 91100: 0.083223\n",
      "2023-12-07 08:56:37,659 INFO     Training average loss at step 91100: 0.099578\n",
      "2023-12-07 08:57:16,331 INFO     Training average positive_sample_loss at step 91200: 0.115015\n",
      "2023-12-07 08:57:16,331 INFO     Training average negative_sample_loss at step 91200: 0.083610\n",
      "2023-12-07 08:57:16,331 INFO     Training average loss at step 91200: 0.099312\n",
      "2023-12-07 08:57:55,192 INFO     Training average positive_sample_loss at step 91300: 0.115921\n",
      "2023-12-07 08:57:55,192 INFO     Training average negative_sample_loss at step 91300: 0.083797\n",
      "2023-12-07 08:57:55,192 INFO     Training average loss at step 91300: 0.099859\n",
      "2023-12-07 08:58:36,821 INFO     Training average positive_sample_loss at step 91400: 0.114922\n",
      "2023-12-07 08:58:36,821 INFO     Training average negative_sample_loss at step 91400: 0.083061\n",
      "2023-12-07 08:58:36,822 INFO     Training average loss at step 91400: 0.098992\n",
      "2023-12-07 08:59:15,434 INFO     Training average positive_sample_loss at step 91500: 0.115061\n",
      "2023-12-07 08:59:15,435 INFO     Training average negative_sample_loss at step 91500: 0.082876\n",
      "2023-12-07 08:59:15,435 INFO     Training average loss at step 91500: 0.098968\n",
      "2023-12-07 08:59:57,305 INFO     Training average positive_sample_loss at step 91600: 0.116399\n",
      "2023-12-07 08:59:57,306 INFO     Training average negative_sample_loss at step 91600: 0.082781\n",
      "2023-12-07 08:59:57,306 INFO     Training average loss at step 91600: 0.099590\n",
      "2023-12-07 09:00:36,375 INFO     Training average positive_sample_loss at step 91700: 0.114384\n",
      "2023-12-07 09:00:36,375 INFO     Training average negative_sample_loss at step 91700: 0.083086\n",
      "2023-12-07 09:00:36,375 INFO     Training average loss at step 91700: 0.098735\n",
      "2023-12-07 09:01:14,999 INFO     Training average positive_sample_loss at step 91800: 0.115840\n",
      "2023-12-07 09:01:15,000 INFO     Training average negative_sample_loss at step 91800: 0.083656\n",
      "2023-12-07 09:01:15,000 INFO     Training average loss at step 91800: 0.099748\n",
      "2023-12-07 09:01:59,845 INFO     Training average positive_sample_loss at step 91900: 0.115827\n",
      "2023-12-07 09:01:59,845 INFO     Training average negative_sample_loss at step 91900: 0.083365\n",
      "2023-12-07 09:01:59,845 INFO     Training average loss at step 91900: 0.099596\n",
      "2023-12-07 09:02:38,577 INFO     Training average positive_sample_loss at step 92000: 0.115099\n",
      "2023-12-07 09:02:38,577 INFO     Training average negative_sample_loss at step 92000: 0.082813\n",
      "2023-12-07 09:02:38,577 INFO     Training average loss at step 92000: 0.098956\n",
      "2023-12-07 09:03:17,895 INFO     Training average positive_sample_loss at step 92100: 0.116026\n",
      "2023-12-07 09:03:17,896 INFO     Training average negative_sample_loss at step 92100: 0.083457\n",
      "2023-12-07 09:03:17,896 INFO     Training average loss at step 92100: 0.099741\n",
      "2023-12-07 09:03:59,912 INFO     Training average positive_sample_loss at step 92200: 0.114826\n",
      "2023-12-07 09:03:59,912 INFO     Training average negative_sample_loss at step 92200: 0.082738\n",
      "2023-12-07 09:03:59,912 INFO     Training average loss at step 92200: 0.098782\n",
      "2023-12-07 09:04:38,843 INFO     Training average positive_sample_loss at step 92300: 0.115397\n",
      "2023-12-07 09:04:38,843 INFO     Training average negative_sample_loss at step 92300: 0.083247\n",
      "2023-12-07 09:04:38,843 INFO     Training average loss at step 92300: 0.099322\n",
      "2023-12-07 09:05:20,732 INFO     Training average positive_sample_loss at step 92400: 0.115593\n",
      "2023-12-07 09:05:20,732 INFO     Training average negative_sample_loss at step 92400: 0.083543\n",
      "2023-12-07 09:05:20,732 INFO     Training average loss at step 92400: 0.099568\n",
      "2023-12-07 09:05:59,061 INFO     Training average positive_sample_loss at step 92500: 0.115171\n",
      "2023-12-07 09:05:59,061 INFO     Training average negative_sample_loss at step 92500: 0.083344\n",
      "2023-12-07 09:05:59,061 INFO     Training average loss at step 92500: 0.099258\n",
      "2023-12-07 09:06:37,590 INFO     Training average positive_sample_loss at step 92600: 0.115602\n",
      "2023-12-07 09:06:37,590 INFO     Training average negative_sample_loss at step 92600: 0.083243\n",
      "2023-12-07 09:06:37,590 INFO     Training average loss at step 92600: 0.099422\n",
      "2023-12-07 09:07:19,123 INFO     Training average positive_sample_loss at step 92700: 0.114971\n",
      "2023-12-07 09:07:19,124 INFO     Training average negative_sample_loss at step 92700: 0.083607\n",
      "2023-12-07 09:07:19,124 INFO     Training average loss at step 92700: 0.099289\n",
      "2023-12-07 09:07:57,722 INFO     Training average positive_sample_loss at step 92800: 0.115431\n",
      "2023-12-07 09:07:57,722 INFO     Training average negative_sample_loss at step 92800: 0.082524\n",
      "2023-12-07 09:07:57,722 INFO     Training average loss at step 92800: 0.098978\n",
      "2023-12-07 09:08:39,408 INFO     Training average positive_sample_loss at step 92900: 0.115728\n",
      "2023-12-07 09:08:39,408 INFO     Training average negative_sample_loss at step 92900: 0.082873\n",
      "2023-12-07 09:08:39,408 INFO     Training average loss at step 92900: 0.099300\n",
      "2023-12-07 09:09:17,929 INFO     Training average positive_sample_loss at step 93000: 0.114858\n",
      "2023-12-07 09:09:17,929 INFO     Training average negative_sample_loss at step 93000: 0.082177\n",
      "2023-12-07 09:09:17,929 INFO     Training average loss at step 93000: 0.098518\n",
      "2023-12-07 09:09:56,938 INFO     Training average positive_sample_loss at step 93100: 0.115920\n",
      "2023-12-07 09:09:56,938 INFO     Training average negative_sample_loss at step 93100: 0.082979\n",
      "2023-12-07 09:09:56,938 INFO     Training average loss at step 93100: 0.099450\n",
      "2023-12-07 09:10:42,397 INFO     Training average positive_sample_loss at step 93200: 0.115056\n",
      "2023-12-07 09:10:42,398 INFO     Training average negative_sample_loss at step 93200: 0.082540\n",
      "2023-12-07 09:10:42,398 INFO     Training average loss at step 93200: 0.098798\n",
      "2023-12-07 09:11:21,244 INFO     Training average positive_sample_loss at step 93300: 0.115172\n",
      "2023-12-07 09:11:21,244 INFO     Training average negative_sample_loss at step 93300: 0.082838\n",
      "2023-12-07 09:11:21,244 INFO     Training average loss at step 93300: 0.099005\n",
      "2023-12-07 09:12:03,268 INFO     Training average positive_sample_loss at step 93400: 0.115880\n",
      "2023-12-07 09:12:03,268 INFO     Training average negative_sample_loss at step 93400: 0.083626\n",
      "2023-12-07 09:12:03,268 INFO     Training average loss at step 93400: 0.099753\n",
      "2023-12-07 09:12:41,890 INFO     Training average positive_sample_loss at step 93500: 0.114796\n",
      "2023-12-07 09:12:41,890 INFO     Training average negative_sample_loss at step 93500: 0.083051\n",
      "2023-12-07 09:12:41,890 INFO     Training average loss at step 93500: 0.098924\n",
      "2023-12-07 09:13:20,764 INFO     Training average positive_sample_loss at step 93600: 0.115771\n",
      "2023-12-07 09:13:20,764 INFO     Training average negative_sample_loss at step 93600: 0.083092\n",
      "2023-12-07 09:13:20,764 INFO     Training average loss at step 93600: 0.099432\n",
      "2023-12-07 09:14:02,284 INFO     Training average positive_sample_loss at step 93700: 0.115114\n",
      "2023-12-07 09:14:02,284 INFO     Training average negative_sample_loss at step 93700: 0.083162\n",
      "2023-12-07 09:14:02,284 INFO     Training average loss at step 93700: 0.099138\n",
      "2023-12-07 09:14:40,640 INFO     Training average positive_sample_loss at step 93800: 0.115260\n",
      "2023-12-07 09:14:40,640 INFO     Training average negative_sample_loss at step 93800: 0.083825\n",
      "2023-12-07 09:14:40,640 INFO     Training average loss at step 93800: 0.099543\n",
      "2023-12-07 09:15:18,919 INFO     Training average positive_sample_loss at step 93900: 0.115860\n",
      "2023-12-07 09:15:18,919 INFO     Training average negative_sample_loss at step 93900: 0.083209\n",
      "2023-12-07 09:15:18,919 INFO     Training average loss at step 93900: 0.099535\n",
      "2023-12-07 09:16:01,197 INFO     Training average positive_sample_loss at step 94000: 0.114510\n",
      "2023-12-07 09:16:01,197 INFO     Training average negative_sample_loss at step 94000: 0.083133\n",
      "2023-12-07 09:16:01,197 INFO     Training average loss at step 94000: 0.098822\n",
      "2023-12-07 09:16:40,667 INFO     Training average positive_sample_loss at step 94100: 0.115949\n",
      "2023-12-07 09:16:40,667 INFO     Training average negative_sample_loss at step 94100: 0.082759\n",
      "2023-12-07 09:16:40,667 INFO     Training average loss at step 94100: 0.099354\n",
      "2023-12-07 09:17:23,564 INFO     Training average positive_sample_loss at step 94200: 0.115551\n",
      "2023-12-07 09:17:23,564 INFO     Training average negative_sample_loss at step 94200: 0.082946\n",
      "2023-12-07 09:17:23,565 INFO     Training average loss at step 94200: 0.099248\n",
      "2023-12-07 09:18:01,936 INFO     Training average positive_sample_loss at step 94300: 0.115260\n",
      "2023-12-07 09:18:01,936 INFO     Training average negative_sample_loss at step 94300: 0.083287\n",
      "2023-12-07 09:18:01,936 INFO     Training average loss at step 94300: 0.099274\n",
      "2023-12-07 09:18:40,609 INFO     Training average positive_sample_loss at step 94400: 0.115755\n",
      "2023-12-07 09:18:40,609 INFO     Training average negative_sample_loss at step 94400: 0.082539\n",
      "2023-12-07 09:18:40,609 INFO     Training average loss at step 94400: 0.099147\n",
      "2023-12-07 09:19:25,649 INFO     Training average positive_sample_loss at step 94500: 0.114829\n",
      "2023-12-07 09:19:25,649 INFO     Training average negative_sample_loss at step 94500: 0.083562\n",
      "2023-12-07 09:19:25,649 INFO     Training average loss at step 94500: 0.099196\n",
      "2023-12-07 09:20:03,722 INFO     Training average positive_sample_loss at step 94600: 0.115278\n",
      "2023-12-07 09:20:03,722 INFO     Training average negative_sample_loss at step 94600: 0.083130\n",
      "2023-12-07 09:20:03,722 INFO     Training average loss at step 94600: 0.099204\n",
      "2023-12-07 09:20:45,587 INFO     Training average positive_sample_loss at step 94700: 0.115936\n",
      "2023-12-07 09:20:45,587 INFO     Training average negative_sample_loss at step 94700: 0.082711\n",
      "2023-12-07 09:20:45,587 INFO     Training average loss at step 94700: 0.099323\n",
      "2023-12-07 09:21:24,269 INFO     Training average positive_sample_loss at step 94800: 0.115185\n",
      "2023-12-07 09:21:24,269 INFO     Training average negative_sample_loss at step 94800: 0.082936\n",
      "2023-12-07 09:21:24,269 INFO     Training average loss at step 94800: 0.099060\n",
      "2023-12-07 09:22:02,923 INFO     Training average positive_sample_loss at step 94900: 0.115662\n",
      "2023-12-07 09:22:02,924 INFO     Training average negative_sample_loss at step 94900: 0.082908\n",
      "2023-12-07 09:22:02,924 INFO     Training average loss at step 94900: 0.099285\n",
      "2023-12-07 09:22:44,610 INFO     Training average positive_sample_loss at step 95000: 0.114836\n",
      "2023-12-07 09:22:44,610 INFO     Training average negative_sample_loss at step 95000: 0.082950\n",
      "2023-12-07 09:22:44,611 INFO     Training average loss at step 95000: 0.098893\n",
      "2023-12-07 09:23:23,346 INFO     Training average positive_sample_loss at step 95100: 0.114901\n",
      "2023-12-07 09:23:23,346 INFO     Training average negative_sample_loss at step 95100: 0.082824\n",
      "2023-12-07 09:23:23,346 INFO     Training average loss at step 95100: 0.098862\n",
      "2023-12-07 09:24:02,659 INFO     Training average positive_sample_loss at step 95200: 0.116460\n",
      "2023-12-07 09:24:02,660 INFO     Training average negative_sample_loss at step 95200: 0.083405\n",
      "2023-12-07 09:24:02,660 INFO     Training average loss at step 95200: 0.099932\n",
      "2023-12-07 09:24:44,219 INFO     Training average positive_sample_loss at step 95300: 0.114848\n",
      "2023-12-07 09:24:44,219 INFO     Training average negative_sample_loss at step 95300: 0.083645\n",
      "2023-12-07 09:24:44,219 INFO     Training average loss at step 95300: 0.099246\n",
      "2023-12-07 09:25:22,808 INFO     Training average positive_sample_loss at step 95400: 0.115474\n",
      "2023-12-07 09:25:22,809 INFO     Training average negative_sample_loss at step 95400: 0.082961\n",
      "2023-12-07 09:25:22,809 INFO     Training average loss at step 95400: 0.099218\n",
      "2023-12-07 09:26:04,591 INFO     Training average positive_sample_loss at step 95500: 0.115412\n",
      "2023-12-07 09:26:04,592 INFO     Training average negative_sample_loss at step 95500: 0.082663\n",
      "2023-12-07 09:26:04,592 INFO     Training average loss at step 95500: 0.099037\n",
      "2023-12-07 09:26:43,157 INFO     Training average positive_sample_loss at step 95600: 0.114957\n",
      "2023-12-07 09:26:43,157 INFO     Training average negative_sample_loss at step 95600: 0.082576\n",
      "2023-12-07 09:26:43,157 INFO     Training average loss at step 95600: 0.098767\n",
      "2023-12-07 09:27:21,872 INFO     Training average positive_sample_loss at step 95700: 0.115820\n",
      "2023-12-07 09:27:21,872 INFO     Training average negative_sample_loss at step 95700: 0.082934\n",
      "2023-12-07 09:27:21,872 INFO     Training average loss at step 95700: 0.099377\n",
      "2023-12-07 09:28:07,031 INFO     Training average positive_sample_loss at step 95800: 0.115120\n",
      "2023-12-07 09:28:07,031 INFO     Training average negative_sample_loss at step 95800: 0.083192\n",
      "2023-12-07 09:28:07,031 INFO     Training average loss at step 95800: 0.099156\n",
      "2023-12-07 09:28:45,190 INFO     Training average positive_sample_loss at step 95900: 0.114987\n",
      "2023-12-07 09:28:45,190 INFO     Training average negative_sample_loss at step 95900: 0.083081\n",
      "2023-12-07 09:28:45,190 INFO     Training average loss at step 95900: 0.099034\n",
      "2023-12-07 09:29:26,732 INFO     Training average positive_sample_loss at step 96000: 0.115877\n",
      "2023-12-07 09:29:26,732 INFO     Training average negative_sample_loss at step 96000: 0.083417\n",
      "2023-12-07 09:29:26,732 INFO     Training average loss at step 96000: 0.099647\n",
      "2023-12-07 09:30:05,313 INFO     Training average positive_sample_loss at step 96100: 0.115023\n",
      "2023-12-07 09:30:05,313 INFO     Training average negative_sample_loss at step 96100: 0.082581\n",
      "2023-12-07 09:30:05,313 INFO     Training average loss at step 96100: 0.098802\n",
      "2023-12-07 09:30:43,774 INFO     Training average positive_sample_loss at step 96200: 0.115493\n",
      "2023-12-07 09:30:43,774 INFO     Training average negative_sample_loss at step 96200: 0.082992\n",
      "2023-12-07 09:30:43,774 INFO     Training average loss at step 96200: 0.099243\n",
      "2023-12-07 09:31:26,000 INFO     Training average positive_sample_loss at step 96300: 0.115577\n",
      "2023-12-07 09:31:26,000 INFO     Training average negative_sample_loss at step 96300: 0.082805\n",
      "2023-12-07 09:31:26,001 INFO     Training average loss at step 96300: 0.099191\n",
      "2023-12-07 09:32:04,840 INFO     Training average positive_sample_loss at step 96400: 0.114726\n",
      "2023-12-07 09:32:04,841 INFO     Training average negative_sample_loss at step 96400: 0.082611\n",
      "2023-12-07 09:32:04,841 INFO     Training average loss at step 96400: 0.098669\n",
      "2023-12-07 09:32:47,164 INFO     Training average positive_sample_loss at step 96500: 0.116139\n",
      "2023-12-07 09:32:47,165 INFO     Training average negative_sample_loss at step 96500: 0.082386\n",
      "2023-12-07 09:32:47,165 INFO     Training average loss at step 96500: 0.099262\n",
      "2023-12-07 09:33:25,056 INFO     Training average positive_sample_loss at step 96600: 0.114899\n",
      "2023-12-07 09:33:25,056 INFO     Training average negative_sample_loss at step 96600: 0.083216\n",
      "2023-12-07 09:33:25,056 INFO     Training average loss at step 96600: 0.099058\n",
      "2023-12-07 09:34:03,339 INFO     Training average positive_sample_loss at step 96700: 0.115380\n",
      "2023-12-07 09:34:03,340 INFO     Training average negative_sample_loss at step 96700: 0.082401\n",
      "2023-12-07 09:34:03,340 INFO     Training average loss at step 96700: 0.098891\n",
      "2023-12-07 09:34:45,311 INFO     Training average positive_sample_loss at step 96800: 0.115414\n",
      "2023-12-07 09:34:45,311 INFO     Training average negative_sample_loss at step 96800: 0.082508\n",
      "2023-12-07 09:34:45,311 INFO     Training average loss at step 96800: 0.098961\n",
      "2023-12-07 09:35:24,598 INFO     Training average positive_sample_loss at step 96900: 0.114809\n",
      "2023-12-07 09:35:24,598 INFO     Training average negative_sample_loss at step 96900: 0.083629\n",
      "2023-12-07 09:35:24,598 INFO     Training average loss at step 96900: 0.099219\n",
      "2023-12-07 09:36:03,183 INFO     Training average positive_sample_loss at step 97000: 0.116099\n",
      "2023-12-07 09:36:03,184 INFO     Training average negative_sample_loss at step 97000: 0.083199\n",
      "2023-12-07 09:36:03,184 INFO     Training average loss at step 97000: 0.099649\n",
      "2023-12-07 09:36:48,722 INFO     Training average positive_sample_loss at step 97100: 0.114110\n",
      "2023-12-07 09:36:48,722 INFO     Training average negative_sample_loss at step 97100: 0.082146\n",
      "2023-12-07 09:36:48,722 INFO     Training average loss at step 97100: 0.098128\n",
      "2023-12-07 09:37:27,194 INFO     Training average positive_sample_loss at step 97200: 0.115744\n",
      "2023-12-07 09:37:27,195 INFO     Training average negative_sample_loss at step 97200: 0.083224\n",
      "2023-12-07 09:37:27,195 INFO     Training average loss at step 97200: 0.099484\n",
      "2023-12-07 09:38:08,605 INFO     Training average positive_sample_loss at step 97300: 0.115973\n",
      "2023-12-07 09:38:08,606 INFO     Training average negative_sample_loss at step 97300: 0.083516\n",
      "2023-12-07 09:38:08,606 INFO     Training average loss at step 97300: 0.099744\n",
      "2023-12-07 09:38:47,316 INFO     Training average positive_sample_loss at step 97400: 0.114631\n",
      "2023-12-07 09:38:47,317 INFO     Training average negative_sample_loss at step 97400: 0.082703\n",
      "2023-12-07 09:38:47,317 INFO     Training average loss at step 97400: 0.098667\n",
      "2023-12-07 09:39:25,715 INFO     Training average positive_sample_loss at step 97500: 0.116170\n",
      "2023-12-07 09:39:25,715 INFO     Training average negative_sample_loss at step 97500: 0.083071\n",
      "2023-12-07 09:39:25,715 INFO     Training average loss at step 97500: 0.099620\n",
      "2023-12-07 09:40:07,319 INFO     Training average positive_sample_loss at step 97600: 0.114599\n",
      "2023-12-07 09:40:07,319 INFO     Training average negative_sample_loss at step 97600: 0.082509\n",
      "2023-12-07 09:40:07,319 INFO     Training average loss at step 97600: 0.098554\n",
      "2023-12-07 09:40:46,452 INFO     Training average positive_sample_loss at step 97700: 0.115980\n",
      "2023-12-07 09:40:46,452 INFO     Training average negative_sample_loss at step 97700: 0.083129\n",
      "2023-12-07 09:40:46,452 INFO     Training average loss at step 97700: 0.099555\n",
      "2023-12-07 09:41:28,174 INFO     Training average positive_sample_loss at step 97800: 0.115303\n",
      "2023-12-07 09:41:28,174 INFO     Training average negative_sample_loss at step 97800: 0.083504\n",
      "2023-12-07 09:41:28,174 INFO     Training average loss at step 97800: 0.099404\n",
      "2023-12-07 09:42:06,802 INFO     Training average positive_sample_loss at step 97900: 0.115336\n",
      "2023-12-07 09:42:06,802 INFO     Training average negative_sample_loss at step 97900: 0.082735\n",
      "2023-12-07 09:42:06,802 INFO     Training average loss at step 97900: 0.099036\n",
      "2023-12-07 09:42:45,187 INFO     Training average positive_sample_loss at step 98000: 0.115298\n",
      "2023-12-07 09:42:45,187 INFO     Training average negative_sample_loss at step 98000: 0.083088\n",
      "2023-12-07 09:42:45,187 INFO     Training average loss at step 98000: 0.099193\n",
      "2023-12-07 09:43:26,965 INFO     Training average positive_sample_loss at step 98100: 0.115472\n",
      "2023-12-07 09:43:26,966 INFO     Training average negative_sample_loss at step 98100: 0.083273\n",
      "2023-12-07 09:43:26,966 INFO     Training average loss at step 98100: 0.099373\n",
      "2023-12-07 09:44:06,163 INFO     Training average positive_sample_loss at step 98200: 0.114623\n",
      "2023-12-07 09:44:06,164 INFO     Training average negative_sample_loss at step 98200: 0.082359\n",
      "2023-12-07 09:44:06,164 INFO     Training average loss at step 98200: 0.098491\n",
      "2023-12-07 09:44:51,852 INFO     Training average positive_sample_loss at step 98300: 0.116444\n",
      "2023-12-07 09:44:51,853 INFO     Training average negative_sample_loss at step 98300: 0.083236\n",
      "2023-12-07 09:44:51,853 INFO     Training average loss at step 98300: 0.099840\n",
      "2023-12-07 09:45:30,329 INFO     Training average positive_sample_loss at step 98400: 0.114988\n",
      "2023-12-07 09:45:30,329 INFO     Training average negative_sample_loss at step 98400: 0.083582\n",
      "2023-12-07 09:45:30,329 INFO     Training average loss at step 98400: 0.099285\n",
      "2023-12-07 09:46:08,704 INFO     Training average positive_sample_loss at step 98500: 0.115516\n",
      "2023-12-07 09:46:08,704 INFO     Training average negative_sample_loss at step 98500: 0.082949\n",
      "2023-12-07 09:46:08,704 INFO     Training average loss at step 98500: 0.099233\n",
      "2023-12-07 09:46:50,717 INFO     Training average positive_sample_loss at step 98600: 0.115142\n",
      "2023-12-07 09:46:50,718 INFO     Training average negative_sample_loss at step 98600: 0.082883\n",
      "2023-12-07 09:46:50,718 INFO     Training average loss at step 98600: 0.099012\n",
      "2023-12-07 09:47:29,056 INFO     Training average positive_sample_loss at step 98700: 0.115109\n",
      "2023-12-07 09:47:29,057 INFO     Training average negative_sample_loss at step 98700: 0.083106\n",
      "2023-12-07 09:47:29,057 INFO     Training average loss at step 98700: 0.099108\n",
      "2023-12-07 09:48:07,150 INFO     Training average positive_sample_loss at step 98800: 0.116036\n",
      "2023-12-07 09:48:07,150 INFO     Training average negative_sample_loss at step 98800: 0.082604\n",
      "2023-12-07 09:48:07,150 INFO     Training average loss at step 98800: 0.099320\n",
      "2023-12-07 09:48:50,283 INFO     Training average positive_sample_loss at step 98900: 0.114695\n",
      "2023-12-07 09:48:50,283 INFO     Training average negative_sample_loss at step 98900: 0.082740\n",
      "2023-12-07 09:48:50,283 INFO     Training average loss at step 98900: 0.098717\n",
      "2023-12-07 09:49:28,884 INFO     Training average positive_sample_loss at step 99000: 0.115289\n",
      "2023-12-07 09:49:28,884 INFO     Training average negative_sample_loss at step 99000: 0.082849\n",
      "2023-12-07 09:49:28,884 INFO     Training average loss at step 99000: 0.099069\n",
      "2023-12-07 09:50:10,254 INFO     Training average positive_sample_loss at step 99100: 0.115861\n",
      "2023-12-07 09:50:10,254 INFO     Training average negative_sample_loss at step 99100: 0.083181\n",
      "2023-12-07 09:50:10,255 INFO     Training average loss at step 99100: 0.099521\n",
      "2023-12-07 09:50:49,201 INFO     Training average positive_sample_loss at step 99200: 0.115092\n",
      "2023-12-07 09:50:49,202 INFO     Training average negative_sample_loss at step 99200: 0.083062\n",
      "2023-12-07 09:50:49,202 INFO     Training average loss at step 99200: 0.099077\n",
      "2023-12-07 09:51:27,983 INFO     Training average positive_sample_loss at step 99300: 0.115479\n",
      "2023-12-07 09:51:27,984 INFO     Training average negative_sample_loss at step 99300: 0.082747\n",
      "2023-12-07 09:51:27,984 INFO     Training average loss at step 99300: 0.099113\n",
      "2023-12-07 09:52:09,881 INFO     Training average positive_sample_loss at step 99400: 0.115238\n",
      "2023-12-07 09:52:09,881 INFO     Training average negative_sample_loss at step 99400: 0.083393\n",
      "2023-12-07 09:52:09,881 INFO     Training average loss at step 99400: 0.099315\n",
      "2023-12-07 09:52:48,194 INFO     Training average positive_sample_loss at step 99500: 0.115481\n",
      "2023-12-07 09:52:48,194 INFO     Training average negative_sample_loss at step 99500: 0.083259\n",
      "2023-12-07 09:52:48,194 INFO     Training average loss at step 99500: 0.099370\n",
      "2023-12-07 09:53:33,194 INFO     Training average positive_sample_loss at step 99600: 0.115574\n",
      "2023-12-07 09:53:33,194 INFO     Training average negative_sample_loss at step 99600: 0.082767\n",
      "2023-12-07 09:53:33,194 INFO     Training average loss at step 99600: 0.099170\n",
      "2023-12-07 09:54:11,876 INFO     Training average positive_sample_loss at step 99700: 0.115222\n",
      "2023-12-07 09:54:11,877 INFO     Training average negative_sample_loss at step 99700: 0.082724\n",
      "2023-12-07 09:54:11,877 INFO     Training average loss at step 99700: 0.098973\n",
      "2023-12-07 09:54:50,755 INFO     Training average positive_sample_loss at step 99800: 0.115258\n",
      "2023-12-07 09:54:50,756 INFO     Training average negative_sample_loss at step 99800: 0.083200\n",
      "2023-12-07 09:54:50,756 INFO     Training average loss at step 99800: 0.099229\n",
      "2023-12-07 09:55:32,550 INFO     Training average positive_sample_loss at step 99900: 0.114933\n",
      "2023-12-07 09:55:32,551 INFO     Training average negative_sample_loss at step 99900: 0.083074\n",
      "2023-12-07 09:55:32,551 INFO     Training average loss at step 99900: 0.099003\n",
      "2023-12-07 09:56:23,998 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-07 09:56:24,498 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-07 09:56:48,140 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-07 09:57:04,571 INFO     Valid MRR at step 99999: 0.551131\n",
      "2023-12-07 09:57:04,572 INFO     Valid MR at step 99999: 257.035268\n",
      "2023-12-07 09:57:04,572 INFO     Valid HITS@1 at step 99999: 0.483764\n",
      "2023-12-07 09:57:04,572 INFO     Valid HITS@3 at step 99999: 0.583805\n",
      "2023-12-07 09:57:04,572 INFO     Valid HITS@10 at step 99999: 0.670953\n",
      "2023-12-07 09:57:04,572 INFO     Evaluating on Test Dataset...\n",
      "2023-12-07 09:57:04,935 INFO     Evaluating the model... (0/4582)\n",
      "2023-12-07 09:57:31,174 INFO     Evaluating the model... (1000/4582)\n",
      "2023-12-07 09:58:02,370 INFO     Evaluating the model... (2000/4582)\n",
      "2023-12-07 09:58:24,244 INFO     Evaluating the model... (3000/4582)\n",
      "2023-12-07 09:58:45,105 INFO     Evaluating the model... (4000/4582)\n",
      "2023-12-07 09:58:55,702 INFO     Test MRR at step 99999: 0.552537\n",
      "2023-12-07 09:58:55,702 INFO     Test MR at step 99999: 240.770146\n",
      "2023-12-07 09:58:55,702 INFO     Test HITS@1 at step 99999: 0.484977\n",
      "2023-12-07 09:58:55,702 INFO     Test HITS@3 at step 99999: 0.585387\n",
      "2023-12-07 09:58:55,703 INFO     Test HITS@10 at step 99999: 0.673339\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE DBpedia15K 0 0 1024 256 1000 9.0 1.0 0.00005 100000 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione: 693 minuti e 34 secondi\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "minutes, seconds = divmod(execution_time, 60)\n",
    "print(f\"Tempo di esecuzione: {int(minutes)} minuti e {int(seconds)} secondi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con metodo NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd KnowledgeGraphEmbedding_NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-12 15:57:46,231 INFO     Model: RotatE\n",
      "2023-12-12 15:57:46,231 INFO     Data Path: data/DBpedia15K\n",
      "2023-12-12 15:57:46,231 INFO     #entity: 12863\n",
      "2023-12-12 15:57:46,231 INFO     #relation: 279\n",
      "2023-12-12 15:57:46,408 INFO     #train: 131918\n",
      "2023-12-12 15:57:46,434 INFO     #valid: 14659\n",
      "2023-12-12 15:57:46,525 INFO     #test: 36645\n",
      "2023-12-12 15:57:46,739 INFO     Model Parameter Configuration:\n",
      "2023-12-12 15:57:46,739 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-12 15:57:46,739 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-12 15:57:46,739 INFO     Parameter entity_embedding: torch.Size([12863, 2000]), require_grad = True\n",
      "2023-12-12 15:57:46,739 INFO     Parameter relation_embedding: torch.Size([279, 1000]), require_grad = True\n",
      "2023-12-12 15:57:49,305 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-12 15:57:49,305 INFO     Start Training...\n",
      "2023-12-12 15:57:49,305 INFO     init_step = 0\n",
      "2023-12-12 15:57:49,305 INFO     batch_size = 1024\n",
      "2023-12-12 15:57:49,305 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-12 15:57:49,305 INFO     hidden_dim = 1000\n",
      "2023-12-12 15:57:49,305 INFO     gamma = 9.000000\n",
      "2023-12-12 15:57:49,305 INFO     negative_adversarial_sampling = True\n",
      "2023-12-12 15:57:49,305 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-12 15:57:49,305 INFO     learning_rate = 0\n",
      "2023-12-12 15:58:14,377 INFO     Training average positive_sample_loss at step 0: 2.550145\n",
      "2023-12-12 15:58:14,378 INFO     Training average negative_sample_loss at step 0: 0.083645\n",
      "2023-12-12 15:58:14,378 INFO     Training average loss at step 0: 1.316895\n",
      "2023-12-12 15:58:14,378 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-12 15:58:15,079 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-12 15:58:40,210 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-12 15:58:59,034 INFO     Valid MRR at step 0: 0.006873\n",
      "2023-12-12 15:58:59,034 INFO     Valid MR at step 0: 5048.778430\n",
      "2023-12-12 15:58:59,034 INFO     Valid HITS@1 at step 0: 0.005185\n",
      "2023-12-12 15:58:59,034 INFO     Valid HITS@3 at step 0: 0.006276\n",
      "2023-12-12 15:58:59,034 INFO     Valid HITS@10 at step 0: 0.007845\n",
      "2023-12-12 16:00:57,854 INFO     Training average positive_sample_loss at step 100: 2.033900\n",
      "2023-12-12 16:00:57,855 INFO     Training average negative_sample_loss at step 100: 0.175901\n",
      "2023-12-12 16:00:57,855 INFO     Training average loss at step 100: 1.104900\n",
      "2023-12-12 16:03:02,189 INFO     Training average positive_sample_loss at step 200: 1.149070\n",
      "2023-12-12 16:03:02,190 INFO     Training average negative_sample_loss at step 200: 0.415356\n",
      "2023-12-12 16:03:02,190 INFO     Training average loss at step 200: 0.782213\n",
      "2023-12-12 16:05:38,907 INFO     Training average positive_sample_loss at step 300: 0.776938\n",
      "2023-12-12 16:05:38,908 INFO     Training average negative_sample_loss at step 300: 0.513300\n",
      "2023-12-12 16:05:38,908 INFO     Training average loss at step 300: 0.645119\n",
      "2023-12-12 16:07:35,637 INFO     Training average positive_sample_loss at step 400: 0.633653\n",
      "2023-12-12 16:07:35,638 INFO     Training average negative_sample_loss at step 400: 0.512447\n",
      "2023-12-12 16:07:35,638 INFO     Training average loss at step 400: 0.573050\n",
      "2023-12-12 16:09:31,798 INFO     Training average positive_sample_loss at step 500: 0.590654\n",
      "2023-12-12 16:09:31,798 INFO     Training average negative_sample_loss at step 500: 0.504113\n",
      "2023-12-12 16:09:31,799 INFO     Training average loss at step 500: 0.547384\n",
      "2023-12-12 16:11:43,444 INFO     Training average positive_sample_loss at step 600: 0.506331\n",
      "2023-12-12 16:11:43,445 INFO     Training average negative_sample_loss at step 600: 0.475701\n",
      "2023-12-12 16:11:43,445 INFO     Training average loss at step 600: 0.491016\n",
      "2023-12-12 16:13:38,984 INFO     Training average positive_sample_loss at step 700: 0.500134\n",
      "2023-12-12 16:13:38,985 INFO     Training average negative_sample_loss at step 700: 0.445087\n",
      "2023-12-12 16:13:38,985 INFO     Training average loss at step 700: 0.472610\n",
      "2023-12-12 16:15:56,670 INFO     Training average positive_sample_loss at step 800: 0.470803\n",
      "2023-12-12 16:15:56,670 INFO     Training average negative_sample_loss at step 800: 0.426592\n",
      "2023-12-12 16:15:56,671 INFO     Training average loss at step 800: 0.448698\n",
      "2023-12-12 16:17:54,533 INFO     Training average positive_sample_loss at step 900: 0.438039\n",
      "2023-12-12 16:17:54,533 INFO     Training average negative_sample_loss at step 900: 0.392544\n",
      "2023-12-12 16:17:54,534 INFO     Training average loss at step 900: 0.415291\n",
      "2023-12-12 16:20:00,866 INFO     Training average positive_sample_loss at step 1000: 0.437209\n",
      "2023-12-12 16:20:00,867 INFO     Training average negative_sample_loss at step 1000: 0.375000\n",
      "2023-12-12 16:20:00,867 INFO     Training average loss at step 1000: 0.406104\n",
      "2023-12-12 16:22:14,113 INFO     Training average positive_sample_loss at step 1100: 0.398469\n",
      "2023-12-12 16:22:14,113 INFO     Training average negative_sample_loss at step 1100: 0.354765\n",
      "2023-12-12 16:22:14,113 INFO     Training average loss at step 1100: 0.376617\n",
      "2023-12-12 16:24:09,026 INFO     Training average positive_sample_loss at step 1200: 0.396589\n",
      "2023-12-12 16:24:09,027 INFO     Training average negative_sample_loss at step 1200: 0.332998\n",
      "2023-12-12 16:24:09,027 INFO     Training average loss at step 1200: 0.364793\n",
      "2023-12-12 16:26:27,456 INFO     Training average positive_sample_loss at step 1300: 0.387798\n",
      "2023-12-12 16:26:27,456 INFO     Training average negative_sample_loss at step 1300: 0.324074\n",
      "2023-12-12 16:26:27,456 INFO     Training average loss at step 1300: 0.355936\n",
      "2023-12-12 16:28:23,751 INFO     Training average positive_sample_loss at step 1400: 0.355928\n",
      "2023-12-12 16:28:23,752 INFO     Training average negative_sample_loss at step 1400: 0.302705\n",
      "2023-12-12 16:28:23,752 INFO     Training average loss at step 1400: 0.329317\n",
      "2023-12-12 16:30:20,146 INFO     Training average positive_sample_loss at step 1500: 0.362397\n",
      "2023-12-12 16:30:20,147 INFO     Training average negative_sample_loss at step 1500: 0.292157\n",
      "2023-12-12 16:30:20,147 INFO     Training average loss at step 1500: 0.327277\n",
      "2023-12-12 16:32:26,941 INFO     Training average positive_sample_loss at step 1600: 0.340857\n",
      "2023-12-12 16:32:26,941 INFO     Training average negative_sample_loss at step 1600: 0.283534\n",
      "2023-12-12 16:32:26,941 INFO     Training average loss at step 1600: 0.312196\n",
      "2023-12-12 16:34:30,113 INFO     Training average positive_sample_loss at step 1700: 0.334669\n",
      "2023-12-12 16:34:30,114 INFO     Training average negative_sample_loss at step 1700: 0.268314\n",
      "2023-12-12 16:34:30,114 INFO     Training average loss at step 1700: 0.301491\n",
      "2023-12-12 16:36:20,389 INFO     Training average positive_sample_loss at step 1800: 0.335151\n",
      "2023-12-12 16:36:20,389 INFO     Training average negative_sample_loss at step 1800: 0.262737\n",
      "2023-12-12 16:36:20,389 INFO     Training average loss at step 1800: 0.298944\n",
      "2023-12-12 16:38:29,591 INFO     Training average positive_sample_loss at step 1900: 0.307326\n",
      "2023-12-12 16:38:29,592 INFO     Training average negative_sample_loss at step 1900: 0.251692\n",
      "2023-12-12 16:38:29,592 INFO     Training average loss at step 1900: 0.279509\n",
      "2023-12-12 16:40:19,528 INFO     Training average positive_sample_loss at step 2000: 0.315055\n",
      "2023-12-12 16:40:19,529 INFO     Training average negative_sample_loss at step 2000: 0.244067\n",
      "2023-12-12 16:40:19,529 INFO     Training average loss at step 2000: 0.279561\n",
      "2023-12-12 16:42:34,547 INFO     Training average positive_sample_loss at step 2100: 0.301390\n",
      "2023-12-12 16:42:34,547 INFO     Training average negative_sample_loss at step 2100: 0.239554\n",
      "2023-12-12 16:42:34,547 INFO     Training average loss at step 2100: 0.270472\n",
      "2023-12-12 16:44:38,914 INFO     Training average positive_sample_loss at step 2200: 0.294097\n",
      "2023-12-12 16:44:38,914 INFO     Training average negative_sample_loss at step 2200: 0.227958\n",
      "2023-12-12 16:44:38,915 INFO     Training average loss at step 2200: 0.261027\n",
      "2023-12-12 16:46:31,352 INFO     Training average positive_sample_loss at step 2300: 0.299151\n",
      "2023-12-12 16:46:31,352 INFO     Training average negative_sample_loss at step 2300: 0.226355\n",
      "2023-12-12 16:46:31,352 INFO     Training average loss at step 2300: 0.262753\n",
      "2023-12-12 16:48:44,464 INFO     Training average positive_sample_loss at step 2400: 0.277442\n",
      "2023-12-12 16:48:44,465 INFO     Training average negative_sample_loss at step 2400: 0.219577\n",
      "2023-12-12 16:48:44,465 INFO     Training average loss at step 2400: 0.248509\n",
      "2023-12-12 16:50:58,931 INFO     Training average positive_sample_loss at step 2500: 0.283481\n",
      "2023-12-12 16:50:58,931 INFO     Training average negative_sample_loss at step 2500: 0.212808\n",
      "2023-12-12 16:50:58,931 INFO     Training average loss at step 2500: 0.248144\n",
      "2023-12-12 16:53:08,040 INFO     Training average positive_sample_loss at step 2600: 0.277149\n",
      "2023-12-12 16:53:08,041 INFO     Training average negative_sample_loss at step 2600: 0.211831\n",
      "2023-12-12 16:53:08,041 INFO     Training average loss at step 2600: 0.244490\n",
      "2023-12-12 16:55:04,173 INFO     Training average positive_sample_loss at step 2700: 0.266858\n",
      "2023-12-12 16:55:04,173 INFO     Training average negative_sample_loss at step 2700: 0.202674\n",
      "2023-12-12 16:55:04,173 INFO     Training average loss at step 2700: 0.234766\n",
      "2023-12-12 16:56:57,467 INFO     Training average positive_sample_loss at step 2800: 0.271932\n",
      "2023-12-12 16:56:57,468 INFO     Training average negative_sample_loss at step 2800: 0.201042\n",
      "2023-12-12 16:56:57,468 INFO     Training average loss at step 2800: 0.236487\n",
      "2023-12-12 16:59:07,590 INFO     Training average positive_sample_loss at step 2900: 0.256793\n",
      "2023-12-12 16:59:07,590 INFO     Training average negative_sample_loss at step 2900: 0.197600\n",
      "2023-12-12 16:59:07,590 INFO     Training average loss at step 2900: 0.227197\n",
      "2023-12-12 17:01:09,601 INFO     Training average positive_sample_loss at step 3000: 0.260450\n",
      "2023-12-12 17:01:09,601 INFO     Training average negative_sample_loss at step 3000: 0.191591\n",
      "2023-12-12 17:01:09,601 INFO     Training average loss at step 3000: 0.226020\n",
      "2023-12-12 17:03:30,767 INFO     Training average positive_sample_loss at step 3100: 0.261743\n",
      "2023-12-12 17:03:30,768 INFO     Training average negative_sample_loss at step 3100: 0.192847\n",
      "2023-12-12 17:03:30,768 INFO     Training average loss at step 3100: 0.227295\n",
      "2023-12-12 17:05:31,450 INFO     Training average positive_sample_loss at step 3200: 0.243596\n",
      "2023-12-12 17:05:31,451 INFO     Training average negative_sample_loss at step 3200: 0.184761\n",
      "2023-12-12 17:05:31,451 INFO     Training average loss at step 3200: 0.214178\n",
      "2023-12-12 17:07:32,494 INFO     Training average positive_sample_loss at step 3300: 0.254354\n",
      "2023-12-12 17:07:32,494 INFO     Training average negative_sample_loss at step 3300: 0.184302\n",
      "2023-12-12 17:07:32,494 INFO     Training average loss at step 3300: 0.219328\n",
      "2023-12-12 17:09:44,152 INFO     Training average positive_sample_loss at step 3400: 0.242955\n",
      "2023-12-12 17:09:44,152 INFO     Training average negative_sample_loss at step 3400: 0.182790\n",
      "2023-12-12 17:09:44,152 INFO     Training average loss at step 3400: 0.212872\n",
      "2023-12-12 17:11:44,832 INFO     Training average positive_sample_loss at step 3500: 0.242885\n",
      "2023-12-12 17:11:44,833 INFO     Training average negative_sample_loss at step 3500: 0.176693\n",
      "2023-12-12 17:11:44,833 INFO     Training average loss at step 3500: 0.209789\n",
      "2023-12-12 17:13:40,754 INFO     Training average positive_sample_loss at step 3600: 0.248003\n",
      "2023-12-12 17:13:40,754 INFO     Training average negative_sample_loss at step 3600: 0.178588\n",
      "2023-12-12 17:13:40,755 INFO     Training average loss at step 3600: 0.213296\n",
      "2023-12-12 17:15:56,531 INFO     Training average positive_sample_loss at step 3700: 0.230417\n",
      "2023-12-12 17:15:56,531 INFO     Training average negative_sample_loss at step 3700: 0.172954\n",
      "2023-12-12 17:15:56,531 INFO     Training average loss at step 3700: 0.201686\n",
      "2023-12-12 17:17:57,066 INFO     Training average positive_sample_loss at step 3800: 0.239349\n",
      "2023-12-12 17:17:57,067 INFO     Training average negative_sample_loss at step 3800: 0.171220\n",
      "2023-12-12 17:17:57,067 INFO     Training average loss at step 3800: 0.205284\n",
      "2023-12-12 17:20:08,225 INFO     Training average positive_sample_loss at step 3900: 0.233916\n",
      "2023-12-12 17:20:08,225 INFO     Training average negative_sample_loss at step 3900: 0.171901\n",
      "2023-12-12 17:20:08,225 INFO     Training average loss at step 3900: 0.202909\n",
      "2023-12-12 17:22:07,678 INFO     Training average positive_sample_loss at step 4000: 0.228722\n",
      "2023-12-12 17:22:07,679 INFO     Training average negative_sample_loss at step 4000: 0.165329\n",
      "2023-12-12 17:22:07,679 INFO     Training average loss at step 4000: 0.197026\n",
      "2023-12-12 17:24:12,307 INFO     Training average positive_sample_loss at step 4100: 0.235177\n",
      "2023-12-12 17:24:12,307 INFO     Training average negative_sample_loss at step 4100: 0.167329\n",
      "2023-12-12 17:24:12,307 INFO     Training average loss at step 4100: 0.201253\n",
      "2023-12-12 17:26:25,911 INFO     Training average positive_sample_loss at step 4200: 0.223106\n",
      "2023-12-12 17:26:25,912 INFO     Training average negative_sample_loss at step 4200: 0.164879\n",
      "2023-12-12 17:26:25,912 INFO     Training average loss at step 4200: 0.193993\n",
      "2023-12-12 17:28:19,683 INFO     Training average positive_sample_loss at step 4300: 0.226714\n",
      "2023-12-12 17:28:19,684 INFO     Training average negative_sample_loss at step 4300: 0.161024\n",
      "2023-12-12 17:28:19,684 INFO     Training average loss at step 4300: 0.193869\n",
      "2023-12-12 17:30:48,911 INFO     Training average positive_sample_loss at step 4400: 0.227139\n",
      "2023-12-12 17:30:48,912 INFO     Training average negative_sample_loss at step 4400: 0.163265\n",
      "2023-12-12 17:30:48,912 INFO     Training average loss at step 4400: 0.195202\n",
      "2023-12-12 17:32:46,729 INFO     Training average positive_sample_loss at step 4500: 0.218136\n",
      "2023-12-12 17:32:46,730 INFO     Training average negative_sample_loss at step 4500: 0.157592\n",
      "2023-12-12 17:32:46,730 INFO     Training average loss at step 4500: 0.187864\n",
      "2023-12-12 17:34:56,703 INFO     Training average positive_sample_loss at step 4600: 0.225619\n",
      "2023-12-12 17:34:56,704 INFO     Training average negative_sample_loss at step 4600: 0.158987\n",
      "2023-12-12 17:34:56,704 INFO     Training average loss at step 4600: 0.192303\n",
      "2023-12-12 17:37:21,654 INFO     Training average positive_sample_loss at step 4700: 0.215840\n",
      "2023-12-12 17:37:21,654 INFO     Training average negative_sample_loss at step 4700: 0.157754\n",
      "2023-12-12 17:37:21,654 INFO     Training average loss at step 4700: 0.186797\n",
      "2023-12-12 17:39:25,188 INFO     Training average positive_sample_loss at step 4800: 0.218652\n",
      "2023-12-12 17:39:25,188 INFO     Training average negative_sample_loss at step 4800: 0.154082\n",
      "2023-12-12 17:39:25,188 INFO     Training average loss at step 4800: 0.186367\n",
      "2023-12-12 17:41:28,969 INFO     Training average positive_sample_loss at step 4900: 0.222185\n",
      "2023-12-12 17:41:28,969 INFO     Training average negative_sample_loss at step 4900: 0.155951\n",
      "2023-12-12 17:41:28,969 INFO     Training average loss at step 4900: 0.189068\n",
      "2023-12-12 17:43:40,089 INFO     Training average positive_sample_loss at step 5000: 0.207906\n",
      "2023-12-12 17:43:40,089 INFO     Training average negative_sample_loss at step 5000: 0.151682\n",
      "2023-12-12 17:43:40,089 INFO     Training average loss at step 5000: 0.179794\n",
      "2023-12-12 17:45:52,430 INFO     Training average positive_sample_loss at step 5100: 0.217382\n",
      "2023-12-12 17:45:52,431 INFO     Training average negative_sample_loss at step 5100: 0.151771\n",
      "2023-12-12 17:45:52,431 INFO     Training average loss at step 5100: 0.184576\n",
      "2023-12-12 17:47:59,322 INFO     Training average positive_sample_loss at step 5200: 0.211493\n",
      "2023-12-12 17:47:59,323 INFO     Training average negative_sample_loss at step 5200: 0.152135\n",
      "2023-12-12 17:47:59,323 INFO     Training average loss at step 5200: 0.181814\n",
      "2023-12-12 17:50:01,347 INFO     Training average positive_sample_loss at step 5300: 0.210966\n",
      "2023-12-12 17:50:01,347 INFO     Training average negative_sample_loss at step 5300: 0.148283\n",
      "2023-12-12 17:50:01,347 INFO     Training average loss at step 5300: 0.179624\n",
      "2023-12-12 17:52:08,934 INFO     Training average positive_sample_loss at step 5400: 0.215821\n",
      "2023-12-12 17:52:08,935 INFO     Training average negative_sample_loss at step 5400: 0.150487\n",
      "2023-12-12 17:52:08,935 INFO     Training average loss at step 5400: 0.183154\n",
      "2023-12-12 17:54:22,679 INFO     Training average positive_sample_loss at step 5500: 0.203487\n",
      "2023-12-12 17:54:22,680 INFO     Training average negative_sample_loss at step 5500: 0.147239\n",
      "2023-12-12 17:54:22,680 INFO     Training average loss at step 5500: 0.175363\n",
      "2023-12-12 17:56:25,418 INFO     Training average positive_sample_loss at step 5600: 0.211202\n",
      "2023-12-12 17:56:25,419 INFO     Training average negative_sample_loss at step 5600: 0.146429\n",
      "2023-12-12 17:56:25,419 INFO     Training average loss at step 5600: 0.178815\n",
      "2023-12-12 17:58:45,613 INFO     Training average positive_sample_loss at step 5700: 0.208056\n",
      "2023-12-12 17:58:45,614 INFO     Training average negative_sample_loss at step 5700: 0.148352\n",
      "2023-12-12 17:58:45,614 INFO     Training average loss at step 5700: 0.178204\n",
      "2023-12-12 18:00:41,988 INFO     Training average positive_sample_loss at step 5800: 0.204421\n",
      "2023-12-12 18:00:41,989 INFO     Training average negative_sample_loss at step 5800: 0.143683\n",
      "2023-12-12 18:00:41,989 INFO     Training average loss at step 5800: 0.174052\n",
      "2023-12-12 18:02:42,135 INFO     Training average positive_sample_loss at step 5900: 0.209671\n",
      "2023-12-12 18:02:42,135 INFO     Training average negative_sample_loss at step 5900: 0.145235\n",
      "2023-12-12 18:02:42,136 INFO     Training average loss at step 5900: 0.177453\n",
      "2023-12-12 18:04:58,413 INFO     Training average positive_sample_loss at step 6000: 0.200374\n",
      "2023-12-12 18:04:58,414 INFO     Training average negative_sample_loss at step 6000: 0.144266\n",
      "2023-12-12 18:04:58,414 INFO     Training average loss at step 6000: 0.172320\n",
      "2023-12-12 18:06:59,044 INFO     Training average positive_sample_loss at step 6100: 0.204870\n",
      "2023-12-12 18:06:59,044 INFO     Training average negative_sample_loss at step 6100: 0.141623\n",
      "2023-12-12 18:06:59,044 INFO     Training average loss at step 6100: 0.173247\n",
      "2023-12-12 18:09:16,654 INFO     Training average positive_sample_loss at step 6200: 0.207364\n",
      "2023-12-12 18:09:16,654 INFO     Training average negative_sample_loss at step 6200: 0.144548\n",
      "2023-12-12 18:09:16,654 INFO     Training average loss at step 6200: 0.175956\n",
      "2023-12-12 18:11:16,598 INFO     Training average positive_sample_loss at step 6300: 0.196519\n",
      "2023-12-12 18:11:16,598 INFO     Training average negative_sample_loss at step 6300: 0.139652\n",
      "2023-12-12 18:11:16,598 INFO     Training average loss at step 6300: 0.168085\n",
      "2023-12-12 18:13:24,366 INFO     Training average positive_sample_loss at step 6400: 0.205504\n",
      "2023-12-12 18:13:24,366 INFO     Training average negative_sample_loss at step 6400: 0.141223\n",
      "2023-12-12 18:13:24,366 INFO     Training average loss at step 6400: 0.173364\n",
      "2023-12-12 18:15:39,865 INFO     Training average positive_sample_loss at step 6500: 0.197910\n",
      "2023-12-12 18:15:39,866 INFO     Training average negative_sample_loss at step 6500: 0.141458\n",
      "2023-12-12 18:15:39,866 INFO     Training average loss at step 6500: 0.169684\n",
      "2023-12-12 18:17:45,366 INFO     Training average positive_sample_loss at step 6600: 0.200185\n",
      "2023-12-12 18:17:45,367 INFO     Training average negative_sample_loss at step 6600: 0.138253\n",
      "2023-12-12 18:17:45,367 INFO     Training average loss at step 6600: 0.169219\n",
      "2023-12-12 18:19:48,059 INFO     Training average positive_sample_loss at step 6700: 0.204578\n",
      "2023-12-12 18:19:48,059 INFO     Training average negative_sample_loss at step 6700: 0.140920\n",
      "2023-12-12 18:19:48,059 INFO     Training average loss at step 6700: 0.172749\n",
      "2023-12-12 18:22:06,165 INFO     Training average positive_sample_loss at step 6800: 0.192496\n",
      "2023-12-12 18:22:06,165 INFO     Training average negative_sample_loss at step 6800: 0.137460\n",
      "2023-12-12 18:22:06,165 INFO     Training average loss at step 6800: 0.164978\n",
      "2023-12-12 18:24:02,139 INFO     Training average positive_sample_loss at step 6900: 0.200988\n",
      "2023-12-12 18:24:02,139 INFO     Training average negative_sample_loss at step 6900: 0.137849\n",
      "2023-12-12 18:24:02,140 INFO     Training average loss at step 6900: 0.169419\n",
      "2023-12-12 18:26:08,844 INFO     Training average positive_sample_loss at step 7000: 0.196662\n",
      "2023-12-12 18:26:08,844 INFO     Training average negative_sample_loss at step 7000: 0.139083\n",
      "2023-12-12 18:26:08,844 INFO     Training average loss at step 7000: 0.167872\n",
      "2023-12-12 18:28:03,153 INFO     Training average positive_sample_loss at step 7100: 0.194941\n",
      "2023-12-12 18:28:03,153 INFO     Training average negative_sample_loss at step 7100: 0.135336\n",
      "2023-12-12 18:28:03,153 INFO     Training average loss at step 7100: 0.165138\n",
      "2023-12-12 18:29:55,480 INFO     Training average positive_sample_loss at step 7200: 0.200999\n",
      "2023-12-12 18:29:55,480 INFO     Training average negative_sample_loss at step 7200: 0.137153\n",
      "2023-12-12 18:29:55,480 INFO     Training average loss at step 7200: 0.169076\n",
      "2023-12-12 18:32:04,776 INFO     Training average positive_sample_loss at step 7300: 0.191131\n",
      "2023-12-12 18:32:04,777 INFO     Training average negative_sample_loss at step 7300: 0.136038\n",
      "2023-12-12 18:32:04,777 INFO     Training average loss at step 7300: 0.163584\n",
      "2023-12-12 18:34:06,153 INFO     Training average positive_sample_loss at step 7400: 0.196637\n",
      "2023-12-12 18:34:06,154 INFO     Training average negative_sample_loss at step 7400: 0.134572\n",
      "2023-12-12 18:34:06,154 INFO     Training average loss at step 7400: 0.165604\n",
      "2023-12-12 18:36:20,463 INFO     Training average positive_sample_loss at step 7500: 0.196422\n",
      "2023-12-12 18:36:20,464 INFO     Training average negative_sample_loss at step 7500: 0.136968\n",
      "2023-12-12 18:36:20,464 INFO     Training average loss at step 7500: 0.166695\n",
      "2023-12-12 18:38:18,417 INFO     Training average positive_sample_loss at step 7600: 0.190625\n",
      "2023-12-12 18:38:18,417 INFO     Training average negative_sample_loss at step 7600: 0.132779\n",
      "2023-12-12 18:38:18,417 INFO     Training average loss at step 7600: 0.161702\n",
      "2023-12-12 18:40:21,591 INFO     Training average positive_sample_loss at step 7700: 0.197252\n",
      "2023-12-12 18:40:21,591 INFO     Training average negative_sample_loss at step 7700: 0.134564\n",
      "2023-12-12 18:40:21,592 INFO     Training average loss at step 7700: 0.165908\n",
      "2023-12-12 18:42:28,623 INFO     Training average positive_sample_loss at step 7800: 0.188643\n",
      "2023-12-12 18:42:28,624 INFO     Training average negative_sample_loss at step 7800: 0.133814\n",
      "2023-12-12 18:42:28,624 INFO     Training average loss at step 7800: 0.161228\n",
      "2023-12-12 18:44:34,970 INFO     Training average positive_sample_loss at step 7900: 0.194174\n",
      "2023-12-12 18:44:34,971 INFO     Training average negative_sample_loss at step 7900: 0.132353\n",
      "2023-12-12 18:44:34,971 INFO     Training average loss at step 7900: 0.163263\n",
      "2023-12-12 18:46:45,713 INFO     Training average positive_sample_loss at step 8000: 0.196540\n",
      "2023-12-12 18:46:45,713 INFO     Training average negative_sample_loss at step 8000: 0.134650\n",
      "2023-12-12 18:46:45,713 INFO     Training average loss at step 8000: 0.165595\n",
      "2023-12-12 18:48:33,923 INFO     Training average positive_sample_loss at step 8100: 0.185651\n",
      "2023-12-12 18:48:33,923 INFO     Training average negative_sample_loss at step 8100: 0.131243\n",
      "2023-12-12 18:48:33,923 INFO     Training average loss at step 8100: 0.158447\n",
      "2023-12-12 18:50:31,871 INFO     Training average positive_sample_loss at step 8200: 0.194210\n",
      "2023-12-12 18:50:31,872 INFO     Training average negative_sample_loss at step 8200: 0.132176\n",
      "2023-12-12 18:50:31,872 INFO     Training average loss at step 8200: 0.163193\n",
      "2023-12-12 18:52:51,429 INFO     Training average positive_sample_loss at step 8300: 0.188942\n",
      "2023-12-12 18:52:51,430 INFO     Training average negative_sample_loss at step 8300: 0.132864\n",
      "2023-12-12 18:52:51,430 INFO     Training average loss at step 8300: 0.160903\n",
      "2023-12-12 18:54:53,661 INFO     Training average positive_sample_loss at step 8400: 0.189359\n",
      "2023-12-12 18:54:53,662 INFO     Training average negative_sample_loss at step 8400: 0.129318\n",
      "2023-12-12 18:54:53,662 INFO     Training average loss at step 8400: 0.159338\n",
      "2023-12-12 18:56:54,818 INFO     Training average positive_sample_loss at step 8500: 0.194638\n",
      "2023-12-12 18:56:54,818 INFO     Training average negative_sample_loss at step 8500: 0.132649\n",
      "2023-12-12 18:56:54,818 INFO     Training average loss at step 8500: 0.163644\n",
      "2023-12-12 18:59:09,458 INFO     Training average positive_sample_loss at step 8600: 0.183389\n",
      "2023-12-12 18:59:09,458 INFO     Training average negative_sample_loss at step 8600: 0.129536\n",
      "2023-12-12 18:59:09,458 INFO     Training average loss at step 8600: 0.156463\n",
      "2023-12-12 19:01:16,459 INFO     Training average positive_sample_loss at step 8700: 0.192513\n",
      "2023-12-12 19:01:16,459 INFO     Training average negative_sample_loss at step 8700: 0.130125\n",
      "2023-12-12 19:01:16,459 INFO     Training average loss at step 8700: 0.161319\n",
      "2023-12-12 19:03:25,130 INFO     Training average positive_sample_loss at step 8800: 0.188803\n",
      "2023-12-12 19:03:25,130 INFO     Training average negative_sample_loss at step 8800: 0.132364\n",
      "2023-12-12 19:03:25,130 INFO     Training average loss at step 8800: 0.160583\n",
      "2023-12-12 19:05:18,654 INFO     Training average positive_sample_loss at step 8900: 0.186173\n",
      "2023-12-12 19:05:18,655 INFO     Training average negative_sample_loss at step 8900: 0.127712\n",
      "2023-12-12 19:05:18,655 INFO     Training average loss at step 8900: 0.156943\n",
      "2023-12-12 19:07:18,879 INFO     Training average positive_sample_loss at step 9000: 0.192320\n",
      "2023-12-12 19:07:18,880 INFO     Training average negative_sample_loss at step 9000: 0.130314\n",
      "2023-12-12 19:07:18,880 INFO     Training average loss at step 9000: 0.161317\n",
      "2023-12-12 19:09:22,811 INFO     Training average positive_sample_loss at step 9100: 0.183061\n",
      "2023-12-12 19:09:22,811 INFO     Training average negative_sample_loss at step 9100: 0.129520\n",
      "2023-12-12 19:09:22,811 INFO     Training average loss at step 9100: 0.156290\n",
      "2023-12-12 19:11:18,387 INFO     Training average positive_sample_loss at step 9200: 0.188716\n",
      "2023-12-12 19:11:18,388 INFO     Training average negative_sample_loss at step 9200: 0.127503\n",
      "2023-12-12 19:11:18,388 INFO     Training average loss at step 9200: 0.158110\n",
      "2023-12-12 19:13:39,620 INFO     Training average positive_sample_loss at step 9300: 0.189508\n",
      "2023-12-12 19:13:39,620 INFO     Training average negative_sample_loss at step 9300: 0.130408\n",
      "2023-12-12 19:13:39,620 INFO     Training average loss at step 9300: 0.159958\n",
      "2023-12-12 19:15:31,989 INFO     Training average positive_sample_loss at step 9400: 0.182198\n",
      "2023-12-12 19:15:31,989 INFO     Training average negative_sample_loss at step 9400: 0.126928\n",
      "2023-12-12 19:15:31,989 INFO     Training average loss at step 9400: 0.154563\n",
      "2023-12-12 19:17:30,959 INFO     Training average positive_sample_loss at step 9500: 0.190179\n",
      "2023-12-12 19:17:30,959 INFO     Training average negative_sample_loss at step 9500: 0.128567\n",
      "2023-12-12 19:17:30,959 INFO     Training average loss at step 9500: 0.159373\n",
      "2023-12-12 19:19:42,471 INFO     Training average positive_sample_loss at step 9600: 0.182616\n",
      "2023-12-12 19:19:42,472 INFO     Training average negative_sample_loss at step 9600: 0.128320\n",
      "2023-12-12 19:19:42,472 INFO     Training average loss at step 9600: 0.155468\n",
      "2023-12-12 19:21:37,776 INFO     Training average positive_sample_loss at step 9700: 0.185936\n",
      "2023-12-12 19:21:37,777 INFO     Training average negative_sample_loss at step 9700: 0.125888\n",
      "2023-12-12 19:21:37,777 INFO     Training average loss at step 9700: 0.155912\n",
      "2023-12-12 19:23:27,761 INFO     Training average positive_sample_loss at step 9800: 0.190381\n",
      "2023-12-12 19:23:27,761 INFO     Training average negative_sample_loss at step 9800: 0.128978\n",
      "2023-12-12 19:23:27,761 INFO     Training average loss at step 9800: 0.159680\n",
      "2023-12-12 19:25:36,496 INFO     Training average positive_sample_loss at step 9900: 0.179274\n",
      "2023-12-12 19:25:36,497 INFO     Training average negative_sample_loss at step 9900: 0.126037\n",
      "2023-12-12 19:25:36,497 INFO     Training average loss at step 9900: 0.152656\n",
      "2023-12-12 19:27:47,479 INFO     Training average positive_sample_loss at step 10000: 0.187221\n",
      "2023-12-12 19:27:47,480 INFO     Training average negative_sample_loss at step 10000: 0.126580\n",
      "2023-12-12 19:27:47,480 INFO     Training average loss at step 10000: 0.156900\n",
      "2023-12-12 19:27:47,480 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-12 19:27:48,005 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-12 19:28:11,880 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-12 19:28:27,984 INFO     Valid MRR at step 10000: 0.402355\n",
      "2023-12-12 19:28:27,984 INFO     Valid MR at step 10000: 807.432294\n",
      "2023-12-12 19:28:27,984 INFO     Valid HITS@1 at step 10000: 0.380347\n",
      "2023-12-12 19:28:27,984 INFO     Valid HITS@3 at step 10000: 0.401562\n",
      "2023-12-12 19:28:27,985 INFO     Valid HITS@10 at step 10000: 0.449076\n",
      "2023-12-12 19:30:20,696 INFO     Training average positive_sample_loss at step 10100: 0.183733\n",
      "2023-12-12 19:30:20,696 INFO     Training average negative_sample_loss at step 10100: 0.127930\n",
      "2023-12-12 19:30:20,696 INFO     Training average loss at step 10100: 0.155832\n",
      "2023-12-12 19:32:31,474 INFO     Training average positive_sample_loss at step 10200: 0.182308\n",
      "2023-12-12 19:32:31,474 INFO     Training average negative_sample_loss at step 10200: 0.124508\n",
      "2023-12-12 19:32:31,474 INFO     Training average loss at step 10200: 0.153408\n",
      "2023-12-12 19:34:32,388 INFO     Training average positive_sample_loss at step 10300: 0.188740\n",
      "2023-12-12 19:34:32,388 INFO     Training average negative_sample_loss at step 10300: 0.127364\n",
      "2023-12-12 19:34:32,388 INFO     Training average loss at step 10300: 0.158052\n",
      "2023-12-12 19:36:49,579 INFO     Training average positive_sample_loss at step 10400: 0.179404\n",
      "2023-12-12 19:36:49,579 INFO     Training average negative_sample_loss at step 10400: 0.125649\n",
      "2023-12-12 19:36:49,579 INFO     Training average loss at step 10400: 0.152527\n",
      "2023-12-12 19:38:48,997 INFO     Training average positive_sample_loss at step 10500: 0.185142\n",
      "2023-12-12 19:38:48,997 INFO     Training average negative_sample_loss at step 10500: 0.125126\n",
      "2023-12-12 19:38:48,997 INFO     Training average loss at step 10500: 0.155134\n",
      "2023-12-12 19:41:13,154 INFO     Training average positive_sample_loss at step 10600: 0.183961\n",
      "2023-12-12 19:41:13,155 INFO     Training average negative_sample_loss at step 10600: 0.127133\n",
      "2023-12-12 19:41:13,155 INFO     Training average loss at step 10600: 0.155547\n",
      "2023-12-12 19:43:17,189 INFO     Training average positive_sample_loss at step 10700: 0.179880\n",
      "2023-12-12 19:43:17,189 INFO     Training average negative_sample_loss at step 10700: 0.123234\n",
      "2023-12-12 19:43:17,189 INFO     Training average loss at step 10700: 0.151557\n",
      "2023-12-12 19:45:28,741 INFO     Training average positive_sample_loss at step 10800: 0.186425\n",
      "2023-12-12 19:45:28,742 INFO     Training average negative_sample_loss at step 10800: 0.125809\n",
      "2023-12-12 19:45:28,742 INFO     Training average loss at step 10800: 0.156117\n",
      "2023-12-12 19:47:38,278 INFO     Training average positive_sample_loss at step 10900: 0.178972\n",
      "2023-12-12 19:47:38,278 INFO     Training average negative_sample_loss at step 10900: 0.125162\n",
      "2023-12-12 19:47:38,279 INFO     Training average loss at step 10900: 0.152067\n",
      "2023-12-12 19:49:46,139 INFO     Training average positive_sample_loss at step 11000: 0.183835\n",
      "2023-12-12 19:49:46,140 INFO     Training average negative_sample_loss at step 11000: 0.123639\n",
      "2023-12-12 19:49:46,140 INFO     Training average loss at step 11000: 0.153737\n",
      "2023-12-12 19:52:03,417 INFO     Training average positive_sample_loss at step 11100: 0.184700\n",
      "2023-12-12 19:52:03,417 INFO     Training average negative_sample_loss at step 11100: 0.126085\n",
      "2023-12-12 19:52:03,418 INFO     Training average loss at step 11100: 0.155393\n",
      "2023-12-12 19:53:59,817 INFO     Training average positive_sample_loss at step 11200: 0.176876\n",
      "2023-12-12 19:53:59,817 INFO     Training average negative_sample_loss at step 11200: 0.122674\n",
      "2023-12-12 19:53:59,817 INFO     Training average loss at step 11200: 0.149775\n",
      "2023-12-12 19:56:10,363 INFO     Training average positive_sample_loss at step 11300: 0.185117\n",
      "2023-12-12 19:56:10,364 INFO     Training average negative_sample_loss at step 11300: 0.124304\n",
      "2023-12-12 19:56:10,364 INFO     Training average loss at step 11300: 0.154710\n",
      "2023-12-12 19:58:18,845 INFO     Training average positive_sample_loss at step 11400: 0.178656\n",
      "2023-12-12 19:58:18,845 INFO     Training average negative_sample_loss at step 11400: 0.124798\n",
      "2023-12-12 19:58:18,845 INFO     Training average loss at step 11400: 0.151727\n",
      "2023-12-12 20:00:17,920 INFO     Training average positive_sample_loss at step 11500: 0.180863\n",
      "2023-12-12 20:00:17,920 INFO     Training average negative_sample_loss at step 11500: 0.122346\n",
      "2023-12-12 20:00:17,920 INFO     Training average loss at step 11500: 0.151604\n",
      "2023-12-12 20:02:25,998 INFO     Training average positive_sample_loss at step 11600: 0.185184\n",
      "2023-12-12 20:02:25,998 INFO     Training average negative_sample_loss at step 11600: 0.124596\n",
      "2023-12-12 20:02:25,998 INFO     Training average loss at step 11600: 0.154890\n",
      "2023-12-12 20:04:44,431 INFO     Training average positive_sample_loss at step 11700: 0.175359\n",
      "2023-12-12 20:04:44,432 INFO     Training average negative_sample_loss at step 11700: 0.122746\n",
      "2023-12-12 20:04:44,432 INFO     Training average loss at step 11700: 0.149052\n",
      "2023-12-12 20:06:39,090 INFO     Training average positive_sample_loss at step 11800: 0.182724\n",
      "2023-12-12 20:06:39,090 INFO     Training average negative_sample_loss at step 11800: 0.122878\n",
      "2023-12-12 20:06:39,091 INFO     Training average loss at step 11800: 0.152801\n",
      "2023-12-12 20:08:47,324 INFO     Training average positive_sample_loss at step 11900: 0.179875\n",
      "2023-12-12 20:08:47,324 INFO     Training average negative_sample_loss at step 11900: 0.124378\n",
      "2023-12-12 20:08:47,324 INFO     Training average loss at step 11900: 0.152127\n",
      "2023-12-12 20:10:42,925 INFO     Training average positive_sample_loss at step 12000: 0.179580\n",
      "2023-12-12 20:10:42,925 INFO     Training average negative_sample_loss at step 12000: 0.121678\n",
      "2023-12-12 20:10:42,926 INFO     Training average loss at step 12000: 0.150629\n",
      "2023-12-12 20:12:49,887 INFO     Training average positive_sample_loss at step 12100: 0.183179\n",
      "2023-12-12 20:12:49,887 INFO     Training average negative_sample_loss at step 12100: 0.123412\n",
      "2023-12-12 20:12:49,887 INFO     Training average loss at step 12100: 0.153295\n",
      "2023-12-12 20:15:01,261 INFO     Training average positive_sample_loss at step 12200: 0.175182\n",
      "2023-12-12 20:15:01,262 INFO     Training average negative_sample_loss at step 12200: 0.122498\n",
      "2023-12-12 20:15:01,262 INFO     Training average loss at step 12200: 0.148840\n",
      "2023-12-12 20:16:59,341 INFO     Training average positive_sample_loss at step 12300: 0.181704\n",
      "2023-12-12 20:16:59,342 INFO     Training average negative_sample_loss at step 12300: 0.121710\n",
      "2023-12-12 20:16:59,342 INFO     Training average loss at step 12300: 0.151707\n",
      "2023-12-12 20:19:15,832 INFO     Training average positive_sample_loss at step 12400: 0.179943\n",
      "2023-12-12 20:19:15,833 INFO     Training average negative_sample_loss at step 12400: 0.123465\n",
      "2023-12-12 20:19:15,833 INFO     Training average loss at step 12400: 0.151704\n",
      "2023-12-12 20:21:07,371 INFO     Training average positive_sample_loss at step 12500: 0.176780\n",
      "2023-12-12 20:21:07,371 INFO     Training average negative_sample_loss at step 12500: 0.120776\n",
      "2023-12-12 20:21:07,371 INFO     Training average loss at step 12500: 0.148778\n",
      "2023-12-12 20:23:22,897 INFO     Training average positive_sample_loss at step 12600: 0.182004\n",
      "2023-12-12 20:23:22,898 INFO     Training average negative_sample_loss at step 12600: 0.122372\n",
      "2023-12-12 20:23:22,898 INFO     Training average loss at step 12600: 0.152188\n",
      "2023-12-12 20:25:42,539 INFO     Training average positive_sample_loss at step 12700: 0.175582\n",
      "2023-12-12 20:25:42,540 INFO     Training average negative_sample_loss at step 12700: 0.122599\n",
      "2023-12-12 20:25:42,540 INFO     Training average loss at step 12700: 0.149090\n",
      "2023-12-12 20:27:40,797 INFO     Training average positive_sample_loss at step 12800: 0.179346\n",
      "2023-12-12 20:27:40,797 INFO     Training average negative_sample_loss at step 12800: 0.120611\n",
      "2023-12-12 20:27:40,797 INFO     Training average loss at step 12800: 0.149978\n",
      "2023-12-12 20:29:51,048 INFO     Training average positive_sample_loss at step 12900: 0.182812\n",
      "2023-12-12 20:29:51,048 INFO     Training average negative_sample_loss at step 12900: 0.123311\n",
      "2023-12-12 20:29:51,048 INFO     Training average loss at step 12900: 0.153062\n",
      "2023-12-12 20:31:45,577 INFO     Training average positive_sample_loss at step 13000: 0.173246\n",
      "2023-12-12 20:31:45,577 INFO     Training average negative_sample_loss at step 13000: 0.120600\n",
      "2023-12-12 20:31:45,577 INFO     Training average loss at step 13000: 0.146923\n",
      "2023-12-12 20:33:31,210 INFO     Training average positive_sample_loss at step 13100: 0.180899\n",
      "2023-12-12 20:33:31,210 INFO     Training average negative_sample_loss at step 13100: 0.120769\n",
      "2023-12-12 20:33:31,210 INFO     Training average loss at step 13100: 0.150834\n",
      "2023-12-12 20:35:44,330 INFO     Training average positive_sample_loss at step 13200: 0.176258\n",
      "2023-12-12 20:35:44,330 INFO     Training average negative_sample_loss at step 13200: 0.122164\n",
      "2023-12-12 20:35:44,330 INFO     Training average loss at step 13200: 0.149211\n",
      "2023-12-12 20:37:36,384 INFO     Training average positive_sample_loss at step 13300: 0.177794\n",
      "2023-12-12 20:37:36,385 INFO     Training average negative_sample_loss at step 13300: 0.119807\n",
      "2023-12-12 20:37:36,385 INFO     Training average loss at step 13300: 0.148801\n",
      "2023-12-12 20:39:27,197 INFO     Training average positive_sample_loss at step 13400: 0.181030\n",
      "2023-12-12 20:39:27,197 INFO     Training average negative_sample_loss at step 13400: 0.121648\n",
      "2023-12-12 20:39:27,197 INFO     Training average loss at step 13400: 0.151339\n",
      "2023-12-12 20:41:35,038 INFO     Training average positive_sample_loss at step 13500: 0.172686\n",
      "2023-12-12 20:41:35,039 INFO     Training average negative_sample_loss at step 13500: 0.120462\n",
      "2023-12-12 20:41:35,039 INFO     Training average loss at step 13500: 0.146574\n",
      "2023-12-12 20:43:24,117 INFO     Training average positive_sample_loss at step 13600: 0.179873\n",
      "2023-12-12 20:43:24,118 INFO     Training average negative_sample_loss at step 13600: 0.120495\n",
      "2023-12-12 20:43:24,118 INFO     Training average loss at step 13600: 0.150184\n",
      "2023-12-12 20:45:31,932 INFO     Training average positive_sample_loss at step 13700: 0.177123\n",
      "2023-12-12 20:45:31,933 INFO     Training average negative_sample_loss at step 13700: 0.121996\n",
      "2023-12-12 20:45:31,933 INFO     Training average loss at step 13700: 0.149559\n",
      "2023-12-12 20:47:30,802 INFO     Training average positive_sample_loss at step 13800: 0.175467\n",
      "2023-12-12 20:47:30,803 INFO     Training average negative_sample_loss at step 13800: 0.118878\n",
      "2023-12-12 20:47:30,803 INFO     Training average loss at step 13800: 0.147173\n",
      "2023-12-12 20:49:43,149 INFO     Training average positive_sample_loss at step 13900: 0.180292\n",
      "2023-12-12 20:49:43,150 INFO     Training average negative_sample_loss at step 13900: 0.120919\n",
      "2023-12-12 20:49:43,150 INFO     Training average loss at step 13900: 0.150606\n",
      "2023-12-12 20:51:43,519 INFO     Training average positive_sample_loss at step 14000: 0.173919\n",
      "2023-12-12 20:51:43,520 INFO     Training average negative_sample_loss at step 14000: 0.120719\n",
      "2023-12-12 20:51:43,520 INFO     Training average loss at step 14000: 0.147319\n",
      "2023-12-12 20:53:46,498 INFO     Training average positive_sample_loss at step 14100: 0.177919\n",
      "2023-12-12 20:53:46,498 INFO     Training average negative_sample_loss at step 14100: 0.119495\n",
      "2023-12-12 20:53:46,498 INFO     Training average loss at step 14100: 0.148707\n",
      "2023-12-12 20:56:00,403 INFO     Training average positive_sample_loss at step 14200: 0.178748\n",
      "2023-12-12 20:56:00,404 INFO     Training average negative_sample_loss at step 14200: 0.121194\n",
      "2023-12-12 20:56:00,404 INFO     Training average loss at step 14200: 0.149971\n",
      "2023-12-12 20:57:54,640 INFO     Training average positive_sample_loss at step 14300: 0.171920\n",
      "2023-12-12 20:57:54,641 INFO     Training average negative_sample_loss at step 14300: 0.118298\n",
      "2023-12-12 20:57:54,641 INFO     Training average loss at step 14300: 0.145109\n",
      "2023-12-12 20:59:59,019 INFO     Training average positive_sample_loss at step 14400: 0.179863\n",
      "2023-12-12 20:59:59,019 INFO     Training average negative_sample_loss at step 14400: 0.120026\n",
      "2023-12-12 20:59:59,019 INFO     Training average loss at step 14400: 0.149945\n",
      "2023-12-12 21:02:16,087 INFO     Training average positive_sample_loss at step 14500: 0.173452\n",
      "2023-12-12 21:02:16,088 INFO     Training average negative_sample_loss at step 14500: 0.120828\n",
      "2023-12-12 21:02:16,088 INFO     Training average loss at step 14500: 0.147140\n",
      "2023-12-12 21:04:16,428 INFO     Training average positive_sample_loss at step 14600: 0.176779\n",
      "2023-12-12 21:04:16,429 INFO     Training average negative_sample_loss at step 14600: 0.118093\n",
      "2023-12-12 21:04:16,429 INFO     Training average loss at step 14600: 0.147436\n",
      "2023-12-12 21:06:17,008 INFO     Training average positive_sample_loss at step 14700: 0.180102\n",
      "2023-12-12 21:06:17,008 INFO     Training average negative_sample_loss at step 14700: 0.120929\n",
      "2023-12-12 21:06:17,008 INFO     Training average loss at step 14700: 0.150515\n",
      "2023-12-12 21:08:40,966 INFO     Training average positive_sample_loss at step 14800: 0.170040\n",
      "2023-12-12 21:08:40,967 INFO     Training average negative_sample_loss at step 14800: 0.118286\n",
      "2023-12-12 21:08:40,967 INFO     Training average loss at step 14800: 0.144163\n",
      "2023-12-12 21:10:38,875 INFO     Training average positive_sample_loss at step 14900: 0.178925\n",
      "2023-12-12 21:10:38,876 INFO     Training average negative_sample_loss at step 14900: 0.119389\n",
      "2023-12-12 21:10:38,876 INFO     Training average loss at step 14900: 0.149157\n",
      "2023-12-12 21:12:49,407 INFO     Training average positive_sample_loss at step 15000: 0.174195\n",
      "2023-12-12 21:12:49,408 INFO     Training average negative_sample_loss at step 15000: 0.120301\n",
      "2023-12-12 21:12:49,408 INFO     Training average loss at step 15000: 0.147248\n",
      "2023-12-12 21:14:59,904 INFO     Training average positive_sample_loss at step 15100: 0.174322\n",
      "2023-12-12 21:14:59,904 INFO     Training average negative_sample_loss at step 15100: 0.117539\n",
      "2023-12-12 21:14:59,904 INFO     Training average loss at step 15100: 0.145931\n",
      "2023-12-12 21:17:07,656 INFO     Training average positive_sample_loss at step 15200: 0.179670\n",
      "2023-12-12 21:17:07,657 INFO     Training average negative_sample_loss at step 15200: 0.120550\n",
      "2023-12-12 21:17:07,657 INFO     Training average loss at step 15200: 0.150110\n",
      "2023-12-12 21:19:20,802 INFO     Training average positive_sample_loss at step 15300: 0.170911\n",
      "2023-12-12 21:19:20,802 INFO     Training average negative_sample_loss at step 15300: 0.118620\n",
      "2023-12-12 21:19:20,802 INFO     Training average loss at step 15300: 0.144766\n",
      "2023-12-12 21:21:26,388 INFO     Training average positive_sample_loss at step 15400: 0.176806\n",
      "2023-12-12 21:21:26,389 INFO     Training average negative_sample_loss at step 15400: 0.117944\n",
      "2023-12-12 21:21:26,389 INFO     Training average loss at step 15400: 0.147375\n",
      "2023-12-12 21:23:47,653 INFO     Training average positive_sample_loss at step 15500: 0.175670\n",
      "2023-12-12 21:23:47,653 INFO     Training average negative_sample_loss at step 15500: 0.120542\n",
      "2023-12-12 21:23:47,653 INFO     Training average loss at step 15500: 0.148106\n",
      "2023-12-12 21:25:46,782 INFO     Training average positive_sample_loss at step 15600: 0.172498\n",
      "2023-12-12 21:25:46,783 INFO     Training average negative_sample_loss at step 15600: 0.117175\n",
      "2023-12-12 21:25:46,783 INFO     Training average loss at step 15600: 0.144837\n",
      "2023-12-12 21:27:53,565 INFO     Training average positive_sample_loss at step 15700: 0.177952\n",
      "2023-12-12 21:27:53,565 INFO     Training average negative_sample_loss at step 15700: 0.119026\n",
      "2023-12-12 21:27:53,565 INFO     Training average loss at step 15700: 0.148489\n",
      "2023-12-12 21:30:16,129 INFO     Training average positive_sample_loss at step 15800: 0.171722\n",
      "2023-12-12 21:30:16,129 INFO     Training average negative_sample_loss at step 15800: 0.119246\n",
      "2023-12-12 21:30:16,129 INFO     Training average loss at step 15800: 0.145484\n",
      "2023-12-12 21:32:11,578 INFO     Training average positive_sample_loss at step 15900: 0.175355\n",
      "2023-12-12 21:32:11,578 INFO     Training average negative_sample_loss at step 15900: 0.117259\n",
      "2023-12-12 21:32:11,578 INFO     Training average loss at step 15900: 0.146307\n",
      "2023-12-12 21:34:24,301 INFO     Training average positive_sample_loss at step 16000: 0.177779\n",
      "2023-12-12 21:34:24,301 INFO     Training average negative_sample_loss at step 16000: 0.119606\n",
      "2023-12-12 21:34:24,301 INFO     Training average loss at step 16000: 0.148693\n",
      "2023-12-12 21:36:17,861 INFO     Training average positive_sample_loss at step 16100: 0.169683\n",
      "2023-12-12 21:36:17,861 INFO     Training average negative_sample_loss at step 16100: 0.116951\n",
      "2023-12-12 21:36:17,861 INFO     Training average loss at step 16100: 0.143317\n",
      "2023-12-12 21:38:33,452 INFO     Training average positive_sample_loss at step 16200: 0.177092\n",
      "2023-12-12 21:38:33,453 INFO     Training average negative_sample_loss at step 16200: 0.118256\n",
      "2023-12-12 21:38:33,453 INFO     Training average loss at step 16200: 0.147674\n",
      "2023-12-12 21:40:50,543 INFO     Training average positive_sample_loss at step 16300: 0.172146\n",
      "2023-12-12 21:40:50,543 INFO     Training average negative_sample_loss at step 16300: 0.118763\n",
      "2023-12-12 21:40:50,544 INFO     Training average loss at step 16300: 0.145454\n",
      "2023-12-12 21:42:51,410 INFO     Training average positive_sample_loss at step 16400: 0.173656\n",
      "2023-12-12 21:42:51,411 INFO     Training average negative_sample_loss at step 16400: 0.116308\n",
      "2023-12-12 21:42:51,411 INFO     Training average loss at step 16400: 0.144982\n",
      "2023-12-12 21:44:50,465 INFO     Training average positive_sample_loss at step 16500: 0.177931\n",
      "2023-12-12 21:44:50,466 INFO     Training average negative_sample_loss at step 16500: 0.119097\n",
      "2023-12-12 21:44:50,466 INFO     Training average loss at step 16500: 0.148514\n",
      "2023-12-12 21:46:56,311 INFO     Training average positive_sample_loss at step 16600: 0.168863\n",
      "2023-12-12 21:46:56,311 INFO     Training average negative_sample_loss at step 16600: 0.117134\n",
      "2023-12-12 21:46:56,311 INFO     Training average loss at step 16600: 0.142999\n",
      "2023-12-12 21:48:52,600 INFO     Training average positive_sample_loss at step 16700: 0.176192\n",
      "2023-12-12 21:48:52,600 INFO     Training average negative_sample_loss at step 16700: 0.117244\n",
      "2023-12-12 21:48:52,600 INFO     Training average loss at step 16700: 0.146718\n",
      "2023-12-12 21:51:01,684 INFO     Training average positive_sample_loss at step 16800: 0.173296\n",
      "2023-12-12 21:51:01,685 INFO     Training average negative_sample_loss at step 16800: 0.119127\n",
      "2023-12-12 21:51:01,685 INFO     Training average loss at step 16800: 0.146212\n",
      "2023-12-12 21:53:00,052 INFO     Training average positive_sample_loss at step 16900: 0.172386\n",
      "2023-12-12 21:53:00,053 INFO     Training average negative_sample_loss at step 16900: 0.116395\n",
      "2023-12-12 21:53:00,053 INFO     Training average loss at step 16900: 0.144390\n",
      "2023-12-12 21:55:03,641 INFO     Training average positive_sample_loss at step 17000: 0.176900\n",
      "2023-12-12 21:55:03,641 INFO     Training average negative_sample_loss at step 17000: 0.118364\n",
      "2023-12-12 21:55:03,641 INFO     Training average loss at step 17000: 0.147632\n",
      "2023-12-12 21:57:22,959 INFO     Training average positive_sample_loss at step 17100: 0.168780\n",
      "2023-12-12 21:57:22,959 INFO     Training average negative_sample_loss at step 17100: 0.117007\n",
      "2023-12-12 21:57:22,959 INFO     Training average loss at step 17100: 0.142894\n",
      "2023-12-12 21:59:15,405 INFO     Training average positive_sample_loss at step 17200: 0.175249\n",
      "2023-12-12 21:59:15,406 INFO     Training average negative_sample_loss at step 17200: 0.116756\n",
      "2023-12-12 21:59:15,406 INFO     Training average loss at step 17200: 0.146003\n",
      "2023-12-12 22:01:40,467 INFO     Training average positive_sample_loss at step 17300: 0.174942\n",
      "2023-12-12 22:01:40,467 INFO     Training average negative_sample_loss at step 17300: 0.118977\n",
      "2023-12-12 22:01:40,467 INFO     Training average loss at step 17300: 0.146959\n",
      "2023-12-12 22:03:29,628 INFO     Training average positive_sample_loss at step 17400: 0.169775\n",
      "2023-12-12 22:03:29,628 INFO     Training average negative_sample_loss at step 17400: 0.115553\n",
      "2023-12-12 22:03:29,628 INFO     Training average loss at step 17400: 0.142664\n",
      "2023-12-12 22:05:26,583 INFO     Training average positive_sample_loss at step 17500: 0.176364\n",
      "2023-12-12 22:05:26,583 INFO     Training average negative_sample_loss at step 17500: 0.117417\n",
      "2023-12-12 22:05:26,583 INFO     Training average loss at step 17500: 0.146891\n",
      "2023-12-12 22:07:52,751 INFO     Training average positive_sample_loss at step 17600: 0.170311\n",
      "2023-12-12 22:07:52,751 INFO     Training average negative_sample_loss at step 17600: 0.117764\n",
      "2023-12-12 22:07:52,751 INFO     Training average loss at step 17600: 0.144038\n",
      "2023-12-12 22:09:56,410 INFO     Training average positive_sample_loss at step 17700: 0.172631\n",
      "2023-12-12 22:09:56,411 INFO     Training average negative_sample_loss at step 17700: 0.115484\n",
      "2023-12-12 22:09:56,411 INFO     Training average loss at step 17700: 0.144057\n",
      "2023-12-12 22:12:00,042 INFO     Training average positive_sample_loss at step 17800: 0.177323\n",
      "2023-12-12 22:12:00,042 INFO     Training average negative_sample_loss at step 17800: 0.118879\n",
      "2023-12-12 22:12:00,042 INFO     Training average loss at step 17800: 0.148101\n",
      "2023-12-12 22:14:18,815 INFO     Training average positive_sample_loss at step 17900: 0.167595\n",
      "2023-12-12 22:14:18,815 INFO     Training average negative_sample_loss at step 17900: 0.115612\n",
      "2023-12-12 22:14:18,815 INFO     Training average loss at step 17900: 0.141604\n",
      "2023-12-12 22:16:21,026 INFO     Training average positive_sample_loss at step 18000: 0.175329\n",
      "2023-12-12 22:16:21,027 INFO     Training average negative_sample_loss at step 18000: 0.116865\n",
      "2023-12-12 22:16:21,027 INFO     Training average loss at step 18000: 0.146097\n",
      "2023-12-12 22:18:44,231 INFO     Training average positive_sample_loss at step 18100: 0.170762\n",
      "2023-12-12 22:18:44,232 INFO     Training average negative_sample_loss at step 18100: 0.117816\n",
      "2023-12-12 22:18:44,232 INFO     Training average loss at step 18100: 0.144289\n",
      "2023-12-12 22:20:43,710 INFO     Training average positive_sample_loss at step 18200: 0.172853\n",
      "2023-12-12 22:20:43,710 INFO     Training average negative_sample_loss at step 18200: 0.115291\n",
      "2023-12-12 22:20:43,710 INFO     Training average loss at step 18200: 0.144072\n",
      "2023-12-12 22:22:45,832 INFO     Training average positive_sample_loss at step 18300: 0.175257\n",
      "2023-12-12 22:22:45,832 INFO     Training average negative_sample_loss at step 18300: 0.117570\n",
      "2023-12-12 22:22:45,832 INFO     Training average loss at step 18300: 0.146414\n",
      "2023-12-12 22:24:57,732 INFO     Training average positive_sample_loss at step 18400: 0.167945\n",
      "2023-12-12 22:24:57,732 INFO     Training average negative_sample_loss at step 18400: 0.115835\n",
      "2023-12-12 22:24:57,732 INFO     Training average loss at step 18400: 0.141890\n",
      "2023-12-12 22:26:58,902 INFO     Training average positive_sample_loss at step 18500: 0.173793\n",
      "2023-12-12 22:26:58,902 INFO     Training average negative_sample_loss at step 18500: 0.115928\n",
      "2023-12-12 22:26:58,902 INFO     Training average loss at step 18500: 0.144860\n",
      "2023-12-12 22:29:19,201 INFO     Training average positive_sample_loss at step 18600: 0.172578\n",
      "2023-12-12 22:29:19,201 INFO     Training average negative_sample_loss at step 18600: 0.118001\n",
      "2023-12-12 22:29:19,201 INFO     Training average loss at step 18600: 0.145290\n",
      "2023-12-12 22:31:22,215 INFO     Training average positive_sample_loss at step 18700: 0.169757\n",
      "2023-12-12 22:31:22,216 INFO     Training average negative_sample_loss at step 18700: 0.114390\n",
      "2023-12-12 22:31:22,216 INFO     Training average loss at step 18700: 0.142073\n",
      "2023-12-12 22:33:25,034 INFO     Training average positive_sample_loss at step 18800: 0.175783\n",
      "2023-12-12 22:33:25,035 INFO     Training average negative_sample_loss at step 18800: 0.117449\n",
      "2023-12-12 22:33:25,035 INFO     Training average loss at step 18800: 0.146616\n",
      "2023-12-12 22:35:37,790 INFO     Training average positive_sample_loss at step 18900: 0.167950\n",
      "2023-12-12 22:35:37,791 INFO     Training average negative_sample_loss at step 18900: 0.116245\n",
      "2023-12-12 22:35:37,791 INFO     Training average loss at step 18900: 0.142097\n",
      "2023-12-12 22:37:46,360 INFO     Training average positive_sample_loss at step 19000: 0.173441\n",
      "2023-12-12 22:37:46,361 INFO     Training average negative_sample_loss at step 19000: 0.115351\n",
      "2023-12-12 22:37:46,361 INFO     Training average loss at step 19000: 0.144396\n",
      "2023-12-12 22:40:01,598 INFO     Training average positive_sample_loss at step 19100: 0.174178\n",
      "2023-12-12 22:40:01,598 INFO     Training average negative_sample_loss at step 19100: 0.117597\n",
      "2023-12-12 22:40:01,598 INFO     Training average loss at step 19100: 0.145888\n",
      "2023-12-12 22:41:59,454 INFO     Training average positive_sample_loss at step 19200: 0.167661\n",
      "2023-12-12 22:41:59,455 INFO     Training average negative_sample_loss at step 19200: 0.114832\n",
      "2023-12-12 22:41:59,455 INFO     Training average loss at step 19200: 0.141247\n",
      "2023-12-12 22:44:20,111 INFO     Training average positive_sample_loss at step 19300: 0.174252\n",
      "2023-12-12 22:44:20,112 INFO     Training average negative_sample_loss at step 19300: 0.115674\n",
      "2023-12-12 22:44:20,112 INFO     Training average loss at step 19300: 0.144963\n",
      "2023-12-12 22:46:19,429 INFO     Training average positive_sample_loss at step 19400: 0.169069\n",
      "2023-12-12 22:46:19,429 INFO     Training average negative_sample_loss at step 19400: 0.116469\n",
      "2023-12-12 22:46:19,429 INFO     Training average loss at step 19400: 0.142769\n",
      "2023-12-12 22:48:30,344 INFO     Training average positive_sample_loss at step 19500: 0.171479\n",
      "2023-12-12 22:48:30,344 INFO     Training average negative_sample_loss at step 19500: 0.114477\n",
      "2023-12-12 22:48:30,344 INFO     Training average loss at step 19500: 0.142978\n",
      "2023-12-12 22:50:26,075 INFO     Training average positive_sample_loss at step 19600: 0.175921\n",
      "2023-12-12 22:50:26,076 INFO     Training average negative_sample_loss at step 19600: 0.117443\n",
      "2023-12-12 22:50:26,076 INFO     Training average loss at step 19600: 0.146682\n",
      "2023-12-12 22:52:36,208 INFO     Training average positive_sample_loss at step 19700: 0.165877\n",
      "2023-12-12 22:52:36,209 INFO     Training average negative_sample_loss at step 19700: 0.114927\n",
      "2023-12-12 22:52:36,209 INFO     Training average loss at step 19700: 0.140402\n",
      "2023-12-12 22:54:31,255 INFO     Training average positive_sample_loss at step 19800: 0.174037\n",
      "2023-12-12 22:54:31,256 INFO     Training average negative_sample_loss at step 19800: 0.115656\n",
      "2023-12-12 22:54:31,256 INFO     Training average loss at step 19800: 0.144847\n",
      "2023-12-12 22:56:55,013 INFO     Training average positive_sample_loss at step 19900: 0.170537\n",
      "2023-12-12 22:56:55,013 INFO     Training average negative_sample_loss at step 19900: 0.116959\n",
      "2023-12-12 22:56:55,013 INFO     Training average loss at step 19900: 0.143748\n",
      "2023-12-12 22:58:54,856 INFO     Training average positive_sample_loss at step 20000: 0.170114\n",
      "2023-12-12 22:58:54,856 INFO     Training average negative_sample_loss at step 20000: 0.114378\n",
      "2023-12-12 22:58:54,856 INFO     Training average loss at step 20000: 0.142246\n",
      "2023-12-12 22:58:54,856 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-12 22:58:55,310 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-12 22:59:19,770 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-12 22:59:36,691 INFO     Valid MRR at step 20000: 0.410414\n",
      "2023-12-12 22:59:36,692 INFO     Valid MR at step 20000: 747.585511\n",
      "2023-12-12 22:59:36,692 INFO     Valid HITS@1 at step 20000: 0.385395\n",
      "2023-12-12 22:59:36,692 INFO     Valid HITS@3 at step 20000: 0.412477\n",
      "2023-12-12 22:59:36,692 INFO     Valid HITS@10 at step 20000: 0.458694\n",
      "2023-12-12 23:01:16,987 INFO     Training average positive_sample_loss at step 20100: 0.174644\n",
      "2023-12-12 23:01:16,988 INFO     Training average negative_sample_loss at step 20100: 0.115996\n",
      "2023-12-12 23:01:16,988 INFO     Training average loss at step 20100: 0.145320\n",
      "2023-12-12 23:03:30,846 INFO     Training average positive_sample_loss at step 20200: 0.166717\n",
      "2023-12-12 23:03:30,846 INFO     Training average negative_sample_loss at step 20200: 0.115224\n",
      "2023-12-12 23:03:30,846 INFO     Training average loss at step 20200: 0.140970\n",
      "2023-12-12 23:05:31,951 INFO     Training average positive_sample_loss at step 20300: 0.172899\n",
      "2023-12-12 23:05:31,952 INFO     Training average negative_sample_loss at step 20300: 0.115114\n",
      "2023-12-12 23:05:31,952 INFO     Training average loss at step 20300: 0.144006\n",
      "2023-12-12 23:07:45,782 INFO     Training average positive_sample_loss at step 20400: 0.171701\n",
      "2023-12-12 23:07:45,783 INFO     Training average negative_sample_loss at step 20400: 0.116776\n",
      "2023-12-12 23:07:45,783 INFO     Training average loss at step 20400: 0.144239\n",
      "2023-12-12 23:09:45,543 INFO     Training average positive_sample_loss at step 20500: 0.168710\n",
      "2023-12-12 23:09:45,544 INFO     Training average negative_sample_loss at step 20500: 0.113665\n",
      "2023-12-12 23:09:45,544 INFO     Training average loss at step 20500: 0.141187\n",
      "2023-12-12 23:11:54,092 INFO     Training average positive_sample_loss at step 20600: 0.173439\n",
      "2023-12-12 23:11:54,093 INFO     Training average negative_sample_loss at step 20600: 0.116011\n",
      "2023-12-12 23:11:54,093 INFO     Training average loss at step 20600: 0.144725\n",
      "2023-12-12 23:14:07,569 INFO     Training average positive_sample_loss at step 20700: 0.167647\n",
      "2023-12-12 23:14:07,570 INFO     Training average negative_sample_loss at step 20700: 0.115199\n",
      "2023-12-12 23:14:07,570 INFO     Training average loss at step 20700: 0.141423\n",
      "2023-12-12 23:16:09,538 INFO     Training average positive_sample_loss at step 20800: 0.171268\n",
      "2023-12-12 23:16:09,539 INFO     Training average negative_sample_loss at step 20800: 0.114182\n",
      "2023-12-12 23:16:09,539 INFO     Training average loss at step 20800: 0.142725\n",
      "2023-12-12 23:18:37,311 INFO     Training average positive_sample_loss at step 20900: 0.174058\n",
      "2023-12-12 23:18:37,311 INFO     Training average negative_sample_loss at step 20900: 0.116564\n",
      "2023-12-12 23:18:37,311 INFO     Training average loss at step 20900: 0.145311\n",
      "2023-12-12 23:20:35,598 INFO     Training average positive_sample_loss at step 21000: 0.166356\n",
      "2023-12-12 23:20:35,598 INFO     Training average negative_sample_loss at step 21000: 0.113955\n",
      "2023-12-12 23:20:35,598 INFO     Training average loss at step 21000: 0.140156\n",
      "2023-12-12 23:22:43,324 INFO     Training average positive_sample_loss at step 21100: 0.172675\n",
      "2023-12-12 23:22:43,325 INFO     Training average negative_sample_loss at step 21100: 0.115140\n",
      "2023-12-12 23:22:43,325 INFO     Training average loss at step 21100: 0.143907\n",
      "2023-12-12 23:25:02,882 INFO     Training average positive_sample_loss at step 21200: 0.168429\n",
      "2023-12-12 23:25:02,882 INFO     Training average negative_sample_loss at step 21200: 0.115756\n",
      "2023-12-12 23:25:02,882 INFO     Training average loss at step 21200: 0.142092\n",
      "2023-12-12 23:27:01,499 INFO     Training average positive_sample_loss at step 21300: 0.170252\n",
      "2023-12-12 23:27:01,500 INFO     Training average negative_sample_loss at step 21300: 0.113616\n",
      "2023-12-12 23:27:01,500 INFO     Training average loss at step 21300: 0.141934\n",
      "2023-12-12 23:29:12,872 INFO     Training average positive_sample_loss at step 21400: 0.173635\n",
      "2023-12-12 23:29:12,872 INFO     Training average negative_sample_loss at step 21400: 0.116363\n",
      "2023-12-12 23:29:12,872 INFO     Training average loss at step 21400: 0.144999\n",
      "2023-12-12 23:31:24,143 INFO     Training average positive_sample_loss at step 21500: 0.165573\n",
      "2023-12-12 23:31:24,143 INFO     Training average negative_sample_loss at step 21500: 0.113924\n",
      "2023-12-12 23:31:24,143 INFO     Training average loss at step 21500: 0.139748\n",
      "2023-12-12 23:33:20,494 INFO     Training average positive_sample_loss at step 21600: 0.172081\n",
      "2023-12-12 23:33:20,494 INFO     Training average negative_sample_loss at step 21600: 0.114316\n",
      "2023-12-12 23:33:20,494 INFO     Training average loss at step 21600: 0.143199\n",
      "2023-12-12 23:35:36,780 INFO     Training average positive_sample_loss at step 21700: 0.170483\n",
      "2023-12-12 23:35:36,780 INFO     Training average negative_sample_loss at step 21700: 0.116454\n",
      "2023-12-12 23:35:36,780 INFO     Training average loss at step 21700: 0.143469\n",
      "2023-12-12 23:37:31,777 INFO     Training average positive_sample_loss at step 21800: 0.168414\n",
      "2023-12-12 23:37:31,778 INFO     Training average negative_sample_loss at step 21800: 0.112877\n",
      "2023-12-12 23:37:31,778 INFO     Training average loss at step 21800: 0.140645\n",
      "2023-12-12 23:39:33,114 INFO     Training average positive_sample_loss at step 21900: 0.173476\n",
      "2023-12-12 23:39:33,115 INFO     Training average negative_sample_loss at step 21900: 0.115726\n",
      "2023-12-12 23:39:33,115 INFO     Training average loss at step 21900: 0.144601\n",
      "2023-12-12 23:41:44,378 INFO     Training average positive_sample_loss at step 22000: 0.165937\n",
      "2023-12-12 23:41:44,378 INFO     Training average negative_sample_loss at step 22000: 0.114229\n",
      "2023-12-12 23:41:44,378 INFO     Training average loss at step 22000: 0.140083\n",
      "2023-12-12 23:43:50,052 INFO     Training average positive_sample_loss at step 22100: 0.171197\n",
      "2023-12-12 23:43:50,053 INFO     Training average negative_sample_loss at step 22100: 0.113843\n",
      "2023-12-12 23:43:50,053 INFO     Training average loss at step 22100: 0.142520\n",
      "2023-12-12 23:46:11,576 INFO     Training average positive_sample_loss at step 22200: 0.171794\n",
      "2023-12-12 23:46:11,576 INFO     Training average negative_sample_loss at step 22200: 0.115859\n",
      "2023-12-12 23:46:11,576 INFO     Training average loss at step 22200: 0.143826\n",
      "2023-12-12 23:48:08,584 INFO     Training average positive_sample_loss at step 22300: 0.166477\n",
      "2023-12-12 23:48:08,585 INFO     Training average negative_sample_loss at step 22300: 0.113197\n",
      "2023-12-12 23:48:08,585 INFO     Training average loss at step 22300: 0.139837\n",
      "2023-12-12 23:50:05,021 INFO     Training average positive_sample_loss at step 22400: 0.172257\n",
      "2023-12-12 23:50:05,021 INFO     Training average negative_sample_loss at step 22400: 0.114636\n",
      "2023-12-12 23:50:05,021 INFO     Training average loss at step 22400: 0.143447\n",
      "2023-12-12 23:52:21,588 INFO     Training average positive_sample_loss at step 22500: 0.166713\n",
      "2023-12-12 23:52:21,588 INFO     Training average negative_sample_loss at step 22500: 0.114661\n",
      "2023-12-12 23:52:21,588 INFO     Training average loss at step 22500: 0.140687\n",
      "2023-12-12 23:54:22,371 INFO     Training average positive_sample_loss at step 22600: 0.170662\n",
      "2023-12-12 23:54:22,371 INFO     Training average negative_sample_loss at step 22600: 0.113540\n",
      "2023-12-12 23:54:22,372 INFO     Training average loss at step 22600: 0.142101\n",
      "2023-12-12 23:56:28,128 INFO     Training average positive_sample_loss at step 22700: 0.173324\n",
      "2023-12-12 23:56:28,129 INFO     Training average negative_sample_loss at step 22700: 0.115392\n",
      "2023-12-12 23:56:28,129 INFO     Training average loss at step 22700: 0.144358\n",
      "2023-12-12 23:58:33,370 INFO     Training average positive_sample_loss at step 22800: 0.164894\n",
      "2023-12-12 23:58:33,370 INFO     Training average negative_sample_loss at step 22800: 0.113251\n",
      "2023-12-12 23:58:33,370 INFO     Training average loss at step 22800: 0.139072\n",
      "2023-12-13 00:00:35,130 INFO     Training average positive_sample_loss at step 22900: 0.171758\n",
      "2023-12-13 00:00:35,131 INFO     Training average negative_sample_loss at step 22900: 0.114218\n",
      "2023-12-13 00:00:35,131 INFO     Training average loss at step 22900: 0.142988\n",
      "2023-12-13 00:02:46,035 INFO     Training average positive_sample_loss at step 23000: 0.168132\n",
      "2023-12-13 00:02:46,036 INFO     Training average negative_sample_loss at step 23000: 0.115633\n",
      "2023-12-13 00:02:46,036 INFO     Training average loss at step 23000: 0.141882\n",
      "2023-12-13 00:04:51,672 INFO     Training average positive_sample_loss at step 23100: 0.168776\n",
      "2023-12-13 00:04:51,673 INFO     Training average negative_sample_loss at step 23100: 0.112805\n",
      "2023-12-13 00:04:51,673 INFO     Training average loss at step 23100: 0.140790\n",
      "2023-12-13 00:06:59,968 INFO     Training average positive_sample_loss at step 23200: 0.172547\n",
      "2023-12-13 00:06:59,968 INFO     Training average negative_sample_loss at step 23200: 0.114795\n",
      "2023-12-13 00:06:59,969 INFO     Training average loss at step 23200: 0.143671\n",
      "2023-12-13 00:09:17,455 INFO     Training average positive_sample_loss at step 23300: 0.164550\n",
      "2023-12-13 00:09:17,456 INFO     Training average negative_sample_loss at step 23300: 0.113386\n",
      "2023-12-13 00:09:17,456 INFO     Training average loss at step 23300: 0.138968\n",
      "2023-12-13 00:11:29,053 INFO     Training average positive_sample_loss at step 23400: 0.171363\n",
      "2023-12-13 00:11:29,054 INFO     Training average negative_sample_loss at step 23400: 0.113659\n",
      "2023-12-13 00:11:29,054 INFO     Training average loss at step 23400: 0.142511\n",
      "2023-12-13 00:14:01,868 INFO     Training average positive_sample_loss at step 23500: 0.169652\n",
      "2023-12-13 00:14:01,869 INFO     Training average negative_sample_loss at step 23500: 0.115523\n",
      "2023-12-13 00:14:01,869 INFO     Training average loss at step 23500: 0.142587\n",
      "2023-12-13 00:15:51,937 INFO     Training average positive_sample_loss at step 23600: 0.167422\n",
      "2023-12-13 00:15:51,937 INFO     Training average negative_sample_loss at step 23600: 0.112463\n",
      "2023-12-13 00:15:51,938 INFO     Training average loss at step 23600: 0.139943\n",
      "2023-12-13 00:17:45,067 INFO     Training average positive_sample_loss at step 23700: 0.171482\n",
      "2023-12-13 00:17:45,067 INFO     Training average negative_sample_loss at step 23700: 0.114044\n",
      "2023-12-13 00:17:45,067 INFO     Training average loss at step 23700: 0.142763\n",
      "2023-12-13 00:20:06,832 INFO     Training average positive_sample_loss at step 23800: 0.165887\n",
      "2023-12-13 00:20:06,832 INFO     Training average negative_sample_loss at step 23800: 0.114312\n",
      "2023-12-13 00:20:06,832 INFO     Training average loss at step 23800: 0.140099\n",
      "2023-12-13 00:22:06,366 INFO     Training average positive_sample_loss at step 23900: 0.169959\n",
      "2023-12-13 00:22:06,366 INFO     Training average negative_sample_loss at step 23900: 0.112792\n",
      "2023-12-13 00:22:06,366 INFO     Training average loss at step 23900: 0.141376\n",
      "2023-12-13 00:24:23,056 INFO     Training average positive_sample_loss at step 24000: 0.171783\n",
      "2023-12-13 00:24:23,056 INFO     Training average negative_sample_loss at step 24000: 0.115507\n",
      "2023-12-13 00:24:23,056 INFO     Training average loss at step 24000: 0.143645\n",
      "2023-12-13 00:26:29,965 INFO     Training average positive_sample_loss at step 24100: 0.165797\n",
      "2023-12-13 00:26:29,965 INFO     Training average negative_sample_loss at step 24100: 0.112619\n",
      "2023-12-13 00:26:29,965 INFO     Training average loss at step 24100: 0.139208\n",
      "2023-12-13 00:28:45,195 INFO     Training average positive_sample_loss at step 24200: 0.170864\n",
      "2023-12-13 00:28:45,195 INFO     Training average negative_sample_loss at step 24200: 0.113936\n",
      "2023-12-13 00:28:45,196 INFO     Training average loss at step 24200: 0.142400\n",
      "2023-12-13 00:30:58,056 INFO     Training average positive_sample_loss at step 24300: 0.166546\n",
      "2023-12-13 00:30:58,057 INFO     Training average negative_sample_loss at step 24300: 0.114127\n",
      "2023-12-13 00:30:58,057 INFO     Training average loss at step 24300: 0.140336\n",
      "2023-12-13 00:32:55,203 INFO     Training average positive_sample_loss at step 24400: 0.168770\n",
      "2023-12-13 00:32:55,204 INFO     Training average negative_sample_loss at step 24400: 0.112481\n",
      "2023-12-13 00:32:55,204 INFO     Training average loss at step 24400: 0.140626\n",
      "2023-12-13 00:35:01,078 INFO     Training average positive_sample_loss at step 24500: 0.172037\n",
      "2023-12-13 00:35:01,078 INFO     Training average negative_sample_loss at step 24500: 0.114869\n",
      "2023-12-13 00:35:01,078 INFO     Training average loss at step 24500: 0.143453\n",
      "2023-12-13 00:37:12,857 INFO     Training average positive_sample_loss at step 24600: 0.164414\n",
      "2023-12-13 00:37:12,857 INFO     Training average negative_sample_loss at step 24600: 0.112907\n",
      "2023-12-13 00:37:12,857 INFO     Training average loss at step 24600: 0.138661\n",
      "2023-12-13 00:39:16,208 INFO     Training average positive_sample_loss at step 24700: 0.170817\n",
      "2023-12-13 00:39:16,208 INFO     Training average negative_sample_loss at step 24700: 0.113265\n",
      "2023-12-13 00:39:16,208 INFO     Training average loss at step 24700: 0.142041\n",
      "2023-12-13 00:41:38,438 INFO     Training average positive_sample_loss at step 24800: 0.167032\n",
      "2023-12-13 00:41:38,438 INFO     Training average negative_sample_loss at step 24800: 0.114611\n",
      "2023-12-13 00:41:38,438 INFO     Training average loss at step 24800: 0.140822\n",
      "2023-12-13 00:43:50,020 INFO     Training average positive_sample_loss at step 24900: 0.167347\n",
      "2023-12-13 00:43:50,021 INFO     Training average negative_sample_loss at step 24900: 0.111727\n",
      "2023-12-13 00:43:50,021 INFO     Training average loss at step 24900: 0.139537\n",
      "2023-12-13 00:46:08,277 INFO     Training average positive_sample_loss at step 25000: 0.172290\n",
      "2023-12-13 00:46:08,278 INFO     Training average negative_sample_loss at step 25000: 0.114431\n",
      "2023-12-13 00:46:08,278 INFO     Training average loss at step 25000: 0.143360\n",
      "2023-12-13 00:48:16,266 INFO     Training average positive_sample_loss at step 25100: 0.164518\n",
      "2023-12-13 00:48:16,266 INFO     Training average negative_sample_loss at step 25100: 0.113331\n",
      "2023-12-13 00:48:16,266 INFO     Training average loss at step 25100: 0.138925\n",
      "2023-12-13 00:50:08,764 INFO     Training average positive_sample_loss at step 25200: 0.169596\n",
      "2023-12-13 00:50:08,764 INFO     Training average negative_sample_loss at step 25200: 0.112585\n",
      "2023-12-13 00:50:08,764 INFO     Training average loss at step 25200: 0.141090\n",
      "2023-12-13 00:52:15,243 INFO     Training average positive_sample_loss at step 25300: 0.170152\n",
      "2023-12-13 00:52:15,243 INFO     Training average negative_sample_loss at step 25300: 0.114962\n",
      "2023-12-13 00:52:15,243 INFO     Training average loss at step 25300: 0.142557\n",
      "2023-12-13 00:54:12,816 INFO     Training average positive_sample_loss at step 25400: 0.165398\n",
      "2023-12-13 00:54:12,817 INFO     Training average negative_sample_loss at step 25400: 0.112033\n",
      "2023-12-13 00:54:12,817 INFO     Training average loss at step 25400: 0.138716\n",
      "2023-12-13 00:56:16,217 INFO     Training average positive_sample_loss at step 25500: 0.171139\n",
      "2023-12-13 00:56:16,218 INFO     Training average negative_sample_loss at step 25500: 0.113786\n",
      "2023-12-13 00:56:16,218 INFO     Training average loss at step 25500: 0.142462\n",
      "2023-12-13 00:58:27,808 INFO     Training average positive_sample_loss at step 25600: 0.165348\n",
      "2023-12-13 00:58:27,808 INFO     Training average negative_sample_loss at step 25600: 0.113418\n",
      "2023-12-13 00:58:27,808 INFO     Training average loss at step 25600: 0.139383\n",
      "2023-12-13 01:00:26,348 INFO     Training average positive_sample_loss at step 25700: 0.168300\n",
      "2023-12-13 01:00:26,348 INFO     Training average negative_sample_loss at step 25700: 0.111709\n",
      "2023-12-13 01:00:26,348 INFO     Training average loss at step 25700: 0.140004\n",
      "2023-12-13 01:02:23,615 INFO     Training average positive_sample_loss at step 25800: 0.172431\n",
      "2023-12-13 01:02:23,615 INFO     Training average negative_sample_loss at step 25800: 0.114827\n",
      "2023-12-13 01:02:23,615 INFO     Training average loss at step 25800: 0.143629\n",
      "2023-12-13 01:04:26,484 INFO     Training average positive_sample_loss at step 25900: 0.163182\n",
      "2023-12-13 01:04:26,485 INFO     Training average negative_sample_loss at step 25900: 0.112277\n",
      "2023-12-13 01:04:26,485 INFO     Training average loss at step 25900: 0.137730\n",
      "2023-12-13 01:06:36,924 INFO     Training average positive_sample_loss at step 26000: 0.170458\n",
      "2023-12-13 01:06:36,925 INFO     Training average negative_sample_loss at step 26000: 0.112913\n",
      "2023-12-13 01:06:36,925 INFO     Training average loss at step 26000: 0.141686\n",
      "2023-12-13 01:08:46,515 INFO     Training average positive_sample_loss at step 26100: 0.166588\n",
      "2023-12-13 01:08:46,516 INFO     Training average negative_sample_loss at step 26100: 0.113961\n",
      "2023-12-13 01:08:46,516 INFO     Training average loss at step 26100: 0.140275\n",
      "2023-12-13 01:10:38,524 INFO     Training average positive_sample_loss at step 26200: 0.167364\n",
      "2023-12-13 01:10:38,525 INFO     Training average negative_sample_loss at step 26200: 0.111566\n",
      "2023-12-13 01:10:38,525 INFO     Training average loss at step 26200: 0.139465\n",
      "2023-12-13 01:12:25,422 INFO     Training average positive_sample_loss at step 26300: 0.171460\n",
      "2023-12-13 01:12:25,423 INFO     Training average negative_sample_loss at step 26300: 0.114264\n",
      "2023-12-13 01:12:25,423 INFO     Training average loss at step 26300: 0.142862\n",
      "2023-12-13 01:14:45,466 INFO     Training average positive_sample_loss at step 26400: 0.163418\n",
      "2023-12-13 01:14:45,466 INFO     Training average negative_sample_loss at step 26400: 0.112279\n",
      "2023-12-13 01:14:45,466 INFO     Training average loss at step 26400: 0.137848\n",
      "2023-12-13 01:16:54,369 INFO     Training average positive_sample_loss at step 26500: 0.169212\n",
      "2023-12-13 01:16:54,369 INFO     Training average negative_sample_loss at step 26500: 0.112417\n",
      "2023-12-13 01:16:54,369 INFO     Training average loss at step 26500: 0.140815\n",
      "2023-12-13 01:19:17,056 INFO     Training average positive_sample_loss at step 26600: 0.168223\n",
      "2023-12-13 01:19:17,056 INFO     Training average negative_sample_loss at step 26600: 0.114031\n",
      "2023-12-13 01:19:17,057 INFO     Training average loss at step 26600: 0.141127\n",
      "2023-12-13 01:21:10,168 INFO     Training average positive_sample_loss at step 26700: 0.165780\n",
      "2023-12-13 01:21:10,169 INFO     Training average negative_sample_loss at step 26700: 0.111493\n",
      "2023-12-13 01:21:10,169 INFO     Training average loss at step 26700: 0.138637\n",
      "2023-12-13 01:23:05,847 INFO     Training average positive_sample_loss at step 26800: 0.171430\n",
      "2023-12-13 01:23:05,848 INFO     Training average negative_sample_loss at step 26800: 0.113836\n",
      "2023-12-13 01:23:05,848 INFO     Training average loss at step 26800: 0.142633\n",
      "2023-12-13 01:25:15,433 INFO     Training average positive_sample_loss at step 26900: 0.164605\n",
      "2023-12-13 01:25:15,434 INFO     Training average negative_sample_loss at step 26900: 0.112991\n",
      "2023-12-13 01:25:15,434 INFO     Training average loss at step 26900: 0.138798\n",
      "2023-12-13 01:27:13,555 INFO     Training average positive_sample_loss at step 27000: 0.168684\n",
      "2023-12-13 01:27:13,556 INFO     Training average negative_sample_loss at step 27000: 0.111988\n",
      "2023-12-13 01:27:13,556 INFO     Training average loss at step 27000: 0.140336\n",
      "2023-12-13 01:29:26,874 INFO     Training average positive_sample_loss at step 27100: 0.169476\n",
      "2023-12-13 01:29:26,875 INFO     Training average negative_sample_loss at step 27100: 0.114023\n",
      "2023-12-13 01:29:26,875 INFO     Training average loss at step 27100: 0.141750\n",
      "2023-12-13 01:31:23,201 INFO     Training average positive_sample_loss at step 27200: 0.164686\n",
      "2023-12-13 01:31:23,202 INFO     Training average negative_sample_loss at step 27200: 0.111626\n",
      "2023-12-13 01:31:23,202 INFO     Training average loss at step 27200: 0.138156\n",
      "2023-12-13 01:33:23,123 INFO     Training average positive_sample_loss at step 27300: 0.169810\n",
      "2023-12-13 01:33:23,124 INFO     Training average negative_sample_loss at step 27300: 0.112569\n",
      "2023-12-13 01:33:23,124 INFO     Training average loss at step 27300: 0.141190\n",
      "2023-12-13 01:35:36,340 INFO     Training average positive_sample_loss at step 27400: 0.164660\n",
      "2023-12-13 01:35:36,341 INFO     Training average negative_sample_loss at step 27400: 0.113253\n",
      "2023-12-13 01:35:36,341 INFO     Training average loss at step 27400: 0.138957\n",
      "2023-12-13 01:37:40,987 INFO     Training average positive_sample_loss at step 27500: 0.168447\n",
      "2023-12-13 01:37:40,988 INFO     Training average negative_sample_loss at step 27500: 0.111825\n",
      "2023-12-13 01:37:40,988 INFO     Training average loss at step 27500: 0.140136\n",
      "2023-12-13 01:39:45,962 INFO     Training average positive_sample_loss at step 27600: 0.171015\n",
      "2023-12-13 01:39:45,962 INFO     Training average negative_sample_loss at step 27600: 0.113852\n",
      "2023-12-13 01:39:45,962 INFO     Training average loss at step 27600: 0.142434\n",
      "2023-12-13 01:42:00,654 INFO     Training average positive_sample_loss at step 27700: 0.162736\n",
      "2023-12-13 01:42:00,655 INFO     Training average negative_sample_loss at step 27700: 0.111683\n",
      "2023-12-13 01:42:00,655 INFO     Training average loss at step 27700: 0.137210\n",
      "2023-12-13 01:44:02,651 INFO     Training average positive_sample_loss at step 27800: 0.169633\n",
      "2023-12-13 01:44:02,651 INFO     Training average negative_sample_loss at step 27800: 0.112147\n",
      "2023-12-13 01:44:02,651 INFO     Training average loss at step 27800: 0.140890\n",
      "2023-12-13 01:46:10,324 INFO     Training average positive_sample_loss at step 27900: 0.166197\n",
      "2023-12-13 01:46:10,324 INFO     Training average negative_sample_loss at step 27900: 0.113470\n",
      "2023-12-13 01:46:10,324 INFO     Training average loss at step 27900: 0.139834\n",
      "2023-12-13 01:48:03,875 INFO     Training average positive_sample_loss at step 28000: 0.165684\n",
      "2023-12-13 01:48:03,876 INFO     Training average negative_sample_loss at step 28000: 0.110928\n",
      "2023-12-13 01:48:03,876 INFO     Training average loss at step 28000: 0.138306\n",
      "2023-12-13 01:50:12,547 INFO     Training average positive_sample_loss at step 28100: 0.171428\n",
      "2023-12-13 01:50:12,547 INFO     Training average negative_sample_loss at step 28100: 0.113738\n",
      "2023-12-13 01:50:12,547 INFO     Training average loss at step 28100: 0.142583\n",
      "2023-12-13 01:52:20,437 INFO     Training average positive_sample_loss at step 28200: 0.163455\n",
      "2023-12-13 01:52:20,437 INFO     Training average negative_sample_loss at step 28200: 0.112505\n",
      "2023-12-13 01:52:20,437 INFO     Training average loss at step 28200: 0.137980\n",
      "2023-12-13 01:54:27,458 INFO     Training average positive_sample_loss at step 28300: 0.168106\n",
      "2023-12-13 01:54:27,458 INFO     Training average negative_sample_loss at step 28300: 0.111358\n",
      "2023-12-13 01:54:27,458 INFO     Training average loss at step 28300: 0.139732\n",
      "2023-12-13 01:56:47,059 INFO     Training average positive_sample_loss at step 28400: 0.168266\n",
      "2023-12-13 01:56:47,060 INFO     Training average negative_sample_loss at step 28400: 0.114017\n",
      "2023-12-13 01:56:47,060 INFO     Training average loss at step 28400: 0.141141\n",
      "2023-12-13 01:58:47,031 INFO     Training average positive_sample_loss at step 28500: 0.165129\n",
      "2023-12-13 01:58:47,032 INFO     Training average negative_sample_loss at step 28500: 0.111000\n",
      "2023-12-13 01:58:47,033 INFO     Training average loss at step 28500: 0.138064\n",
      "2023-12-13 02:00:52,605 INFO     Training average positive_sample_loss at step 28600: 0.170124\n",
      "2023-12-13 02:00:52,605 INFO     Training average negative_sample_loss at step 28600: 0.112792\n",
      "2023-12-13 02:00:52,605 INFO     Training average loss at step 28600: 0.141458\n",
      "2023-12-13 02:03:04,326 INFO     Training average positive_sample_loss at step 28700: 0.163211\n",
      "2023-12-13 02:03:04,327 INFO     Training average negative_sample_loss at step 28700: 0.112141\n",
      "2023-12-13 02:03:04,327 INFO     Training average loss at step 28700: 0.137676\n",
      "2023-12-13 02:05:03,953 INFO     Training average positive_sample_loss at step 28800: 0.168101\n",
      "2023-12-13 02:05:03,953 INFO     Training average negative_sample_loss at step 28800: 0.111383\n",
      "2023-12-13 02:05:03,953 INFO     Training average loss at step 28800: 0.139742\n",
      "2023-12-13 02:07:23,524 INFO     Training average positive_sample_loss at step 28900: 0.170178\n",
      "2023-12-13 02:07:23,524 INFO     Training average negative_sample_loss at step 28900: 0.113784\n",
      "2023-12-13 02:07:23,524 INFO     Training average loss at step 28900: 0.141981\n",
      "2023-12-13 02:09:17,093 INFO     Training average positive_sample_loss at step 29000: 0.162775\n",
      "2023-12-13 02:09:17,093 INFO     Training average negative_sample_loss at step 29000: 0.111185\n",
      "2023-12-13 02:09:17,093 INFO     Training average loss at step 29000: 0.136980\n",
      "2023-12-13 02:11:12,754 INFO     Training average positive_sample_loss at step 29100: 0.170015\n",
      "2023-12-13 02:11:12,754 INFO     Training average negative_sample_loss at step 29100: 0.112289\n",
      "2023-12-13 02:11:12,754 INFO     Training average loss at step 29100: 0.141152\n",
      "2023-12-13 02:13:27,036 INFO     Training average positive_sample_loss at step 29200: 0.164612\n",
      "2023-12-13 02:13:27,036 INFO     Training average negative_sample_loss at step 29200: 0.112657\n",
      "2023-12-13 02:13:27,036 INFO     Training average loss at step 29200: 0.138634\n",
      "2023-12-13 02:15:19,365 INFO     Training average positive_sample_loss at step 29300: 0.166720\n",
      "2023-12-13 02:15:19,365 INFO     Training average negative_sample_loss at step 29300: 0.111230\n",
      "2023-12-13 02:15:19,365 INFO     Training average loss at step 29300: 0.138975\n",
      "2023-12-13 02:17:16,447 INFO     Training average positive_sample_loss at step 29400: 0.170215\n",
      "2023-12-13 02:17:16,447 INFO     Training average negative_sample_loss at step 29400: 0.112962\n",
      "2023-12-13 02:17:16,447 INFO     Training average loss at step 29400: 0.141589\n",
      "2023-12-13 02:19:18,044 INFO     Training average positive_sample_loss at step 29500: 0.161536\n",
      "2023-12-13 02:19:18,045 INFO     Training average negative_sample_loss at step 29500: 0.110530\n",
      "2023-12-13 02:19:18,045 INFO     Training average loss at step 29500: 0.136033\n",
      "2023-12-13 02:21:30,542 INFO     Training average positive_sample_loss at step 29600: 0.169389\n",
      "2023-12-13 02:21:30,542 INFO     Training average negative_sample_loss at step 29600: 0.112577\n",
      "2023-12-13 02:21:30,542 INFO     Training average loss at step 29600: 0.140983\n",
      "2023-12-13 02:23:43,931 INFO     Training average positive_sample_loss at step 29700: 0.166150\n",
      "2023-12-13 02:23:43,931 INFO     Training average negative_sample_loss at step 29700: 0.113007\n",
      "2023-12-13 02:23:43,931 INFO     Training average loss at step 29700: 0.139578\n",
      "2023-12-13 02:25:45,437 INFO     Training average positive_sample_loss at step 29800: 0.165787\n",
      "2023-12-13 02:25:45,437 INFO     Training average negative_sample_loss at step 29800: 0.110906\n",
      "2023-12-13 02:25:45,437 INFO     Training average loss at step 29800: 0.138347\n",
      "2023-12-13 02:27:41,270 INFO     Training average positive_sample_loss at step 29900: 0.170258\n",
      "2023-12-13 02:27:41,270 INFO     Training average negative_sample_loss at step 29900: 0.112868\n",
      "2023-12-13 02:27:41,270 INFO     Training average loss at step 29900: 0.141563\n",
      "2023-12-13 02:29:53,062 INFO     Training average positive_sample_loss at step 30000: 0.161631\n",
      "2023-12-13 02:29:53,063 INFO     Training average negative_sample_loss at step 30000: 0.111157\n",
      "2023-12-13 02:29:53,063 INFO     Training average loss at step 30000: 0.136394\n",
      "2023-12-13 02:29:53,063 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-13 02:29:53,647 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-13 02:30:17,159 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-13 02:30:34,985 INFO     Valid MRR at step 30000: 0.414502\n",
      "2023-12-13 02:30:34,986 INFO     Valid MR at step 30000: 723.787946\n",
      "2023-12-13 02:30:34,986 INFO     Valid HITS@1 at step 30000: 0.389078\n",
      "2023-12-13 02:30:34,986 INFO     Valid HITS@3 at step 30000: 0.416434\n",
      "2023-12-13 02:30:34,986 INFO     Valid HITS@10 at step 30000: 0.463299\n",
      "2023-12-13 02:32:12,558 INFO     Training average positive_sample_loss at step 30100: 0.168829\n",
      "2023-12-13 02:32:12,559 INFO     Training average negative_sample_loss at step 30100: 0.111620\n",
      "2023-12-13 02:32:12,559 INFO     Training average loss at step 30100: 0.140225\n",
      "2023-12-13 02:34:32,777 INFO     Training average positive_sample_loss at step 30200: 0.167984\n",
      "2023-12-13 02:34:32,777 INFO     Training average negative_sample_loss at step 30200: 0.113433\n",
      "2023-12-13 02:34:32,777 INFO     Training average loss at step 30200: 0.140709\n",
      "2023-12-13 02:36:29,176 INFO     Training average positive_sample_loss at step 30300: 0.163921\n",
      "2023-12-13 02:36:29,176 INFO     Training average negative_sample_loss at step 30300: 0.110535\n",
      "2023-12-13 02:36:29,176 INFO     Training average loss at step 30300: 0.137228\n",
      "2023-12-13 02:38:22,775 INFO     Training average positive_sample_loss at step 30400: 0.169674\n",
      "2023-12-13 02:38:22,775 INFO     Training average negative_sample_loss at step 30400: 0.112854\n",
      "2023-12-13 02:38:22,775 INFO     Training average loss at step 30400: 0.141264\n",
      "2023-12-13 02:40:32,904 INFO     Training average positive_sample_loss at step 30500: 0.163022\n",
      "2023-12-13 02:40:32,905 INFO     Training average negative_sample_loss at step 30500: 0.111996\n",
      "2023-12-13 02:40:32,905 INFO     Training average loss at step 30500: 0.137509\n",
      "2023-12-13 02:42:42,121 INFO     Training average positive_sample_loss at step 30600: 0.167035\n",
      "2023-12-13 02:42:42,121 INFO     Training average negative_sample_loss at step 30600: 0.110457\n",
      "2023-12-13 02:42:42,121 INFO     Training average loss at step 30600: 0.138746\n",
      "2023-12-13 02:44:45,270 INFO     Training average positive_sample_loss at step 30700: 0.170559\n",
      "2023-12-13 02:44:45,271 INFO     Training average negative_sample_loss at step 30700: 0.113239\n",
      "2023-12-13 02:44:45,271 INFO     Training average loss at step 30700: 0.141899\n",
      "2023-12-13 02:46:56,463 INFO     Training average positive_sample_loss at step 30800: 0.161000\n",
      "2023-12-13 02:46:56,464 INFO     Training average negative_sample_loss at step 30800: 0.110614\n",
      "2023-12-13 02:46:56,464 INFO     Training average loss at step 30800: 0.135807\n",
      "2023-12-13 02:49:02,560 INFO     Training average positive_sample_loss at step 30900: 0.168983\n",
      "2023-12-13 02:49:02,560 INFO     Training average negative_sample_loss at step 30900: 0.111800\n",
      "2023-12-13 02:49:02,560 INFO     Training average loss at step 30900: 0.140391\n",
      "2023-12-13 02:51:18,673 INFO     Training average positive_sample_loss at step 31000: 0.165353\n",
      "2023-12-13 02:51:18,673 INFO     Training average negative_sample_loss at step 31000: 0.113105\n",
      "2023-12-13 02:51:18,673 INFO     Training average loss at step 31000: 0.139229\n",
      "2023-12-13 02:53:24,167 INFO     Training average positive_sample_loss at step 31100: 0.165524\n",
      "2023-12-13 02:53:24,168 INFO     Training average negative_sample_loss at step 31100: 0.110220\n",
      "2023-12-13 02:53:24,168 INFO     Training average loss at step 31100: 0.137872\n",
      "2023-12-13 02:55:35,435 INFO     Training average positive_sample_loss at step 31200: 0.169763\n",
      "2023-12-13 02:55:35,435 INFO     Training average negative_sample_loss at step 31200: 0.112663\n",
      "2023-12-13 02:55:35,436 INFO     Training average loss at step 31200: 0.141213\n",
      "2023-12-13 02:57:46,610 INFO     Training average positive_sample_loss at step 31300: 0.161797\n",
      "2023-12-13 02:57:46,611 INFO     Training average negative_sample_loss at step 31300: 0.111499\n",
      "2023-12-13 02:57:46,611 INFO     Training average loss at step 31300: 0.136648\n",
      "2023-12-13 02:59:59,266 INFO     Training average positive_sample_loss at step 31400: 0.167993\n",
      "2023-12-13 02:59:59,266 INFO     Training average negative_sample_loss at step 31400: 0.110755\n",
      "2023-12-13 02:59:59,266 INFO     Training average loss at step 31400: 0.139374\n",
      "2023-12-13 03:02:16,452 INFO     Training average positive_sample_loss at step 31500: 0.166457\n",
      "2023-12-13 03:02:16,455 INFO     Training average negative_sample_loss at step 31500: 0.113004\n",
      "2023-12-13 03:02:16,455 INFO     Training average loss at step 31500: 0.139730\n",
      "2023-12-13 03:04:14,186 INFO     Training average positive_sample_loss at step 31600: 0.164172\n",
      "2023-12-13 03:04:14,186 INFO     Training average negative_sample_loss at step 31600: 0.110030\n",
      "2023-12-13 03:04:14,186 INFO     Training average loss at step 31600: 0.137101\n",
      "2023-12-13 03:06:27,404 INFO     Training average positive_sample_loss at step 31700: 0.169458\n",
      "2023-12-13 03:06:27,405 INFO     Training average negative_sample_loss at step 31700: 0.112536\n",
      "2023-12-13 03:06:27,405 INFO     Training average loss at step 31700: 0.140997\n",
      "2023-12-13 03:08:38,196 INFO     Training average positive_sample_loss at step 31800: 0.162999\n",
      "2023-12-13 03:08:38,196 INFO     Training average negative_sample_loss at step 31800: 0.111708\n",
      "2023-12-13 03:08:38,196 INFO     Training average loss at step 31800: 0.137353\n",
      "2023-12-13 03:10:35,735 INFO     Training average positive_sample_loss at step 31900: 0.167198\n",
      "2023-12-13 03:10:35,736 INFO     Training average negative_sample_loss at step 31900: 0.110569\n",
      "2023-12-13 03:10:35,736 INFO     Training average loss at step 31900: 0.138884\n",
      "2023-12-13 03:12:47,177 INFO     Training average positive_sample_loss at step 32000: 0.168273\n",
      "2023-12-13 03:12:47,177 INFO     Training average negative_sample_loss at step 32000: 0.112777\n",
      "2023-12-13 03:12:47,177 INFO     Training average loss at step 32000: 0.140525\n",
      "2023-12-13 03:14:35,693 INFO     Training average positive_sample_loss at step 32100: 0.161903\n",
      "2023-12-13 03:14:35,693 INFO     Training average negative_sample_loss at step 32100: 0.109791\n",
      "2023-12-13 03:14:35,693 INFO     Training average loss at step 32100: 0.135847\n",
      "2023-12-13 03:16:31,904 INFO     Training average positive_sample_loss at step 32200: 0.168685\n",
      "2023-12-13 03:16:31,905 INFO     Training average negative_sample_loss at step 32200: 0.111667\n",
      "2023-12-13 03:16:31,905 INFO     Training average loss at step 32200: 0.140176\n",
      "2023-12-13 03:18:44,558 INFO     Training average positive_sample_loss at step 32300: 0.163935\n",
      "2023-12-13 03:18:44,558 INFO     Training average negative_sample_loss at step 32300: 0.112270\n",
      "2023-12-13 03:18:44,558 INFO     Training average loss at step 32300: 0.138102\n",
      "2023-12-13 03:20:46,182 INFO     Training average positive_sample_loss at step 32400: 0.166733\n",
      "2023-12-13 03:20:46,182 INFO     Training average negative_sample_loss at step 32400: 0.110666\n",
      "2023-12-13 03:20:46,182 INFO     Training average loss at step 32400: 0.138700\n",
      "2023-12-13 03:22:46,513 INFO     Training average positive_sample_loss at step 32500: 0.169347\n",
      "2023-12-13 03:22:46,513 INFO     Training average negative_sample_loss at step 32500: 0.112465\n",
      "2023-12-13 03:22:46,514 INFO     Training average loss at step 32500: 0.140906\n",
      "2023-12-13 03:24:56,324 INFO     Training average positive_sample_loss at step 32600: 0.161176\n",
      "2023-12-13 03:24:56,324 INFO     Training average negative_sample_loss at step 32600: 0.110444\n",
      "2023-12-13 03:24:56,324 INFO     Training average loss at step 32600: 0.135810\n",
      "2023-12-13 03:27:01,531 INFO     Training average positive_sample_loss at step 32700: 0.168256\n",
      "2023-12-13 03:27:01,531 INFO     Training average negative_sample_loss at step 32700: 0.111441\n",
      "2023-12-13 03:27:01,532 INFO     Training average loss at step 32700: 0.139848\n",
      "2023-12-13 03:29:20,015 INFO     Training average positive_sample_loss at step 32800: 0.164833\n",
      "2023-12-13 03:29:20,016 INFO     Training average negative_sample_loss at step 32800: 0.112308\n",
      "2023-12-13 03:29:20,016 INFO     Training average loss at step 32800: 0.138570\n",
      "2023-12-13 03:31:18,614 INFO     Training average positive_sample_loss at step 32900: 0.165063\n",
      "2023-12-13 03:31:18,615 INFO     Training average negative_sample_loss at step 32900: 0.110037\n",
      "2023-12-13 03:31:18,615 INFO     Training average loss at step 32900: 0.137550\n",
      "2023-12-13 03:33:19,750 INFO     Training average positive_sample_loss at step 33000: 0.168706\n",
      "2023-12-13 03:33:19,750 INFO     Training average negative_sample_loss at step 33000: 0.111905\n",
      "2023-12-13 03:33:19,750 INFO     Training average loss at step 33000: 0.140305\n",
      "2023-12-13 03:35:27,342 INFO     Training average positive_sample_loss at step 33100: 0.161461\n",
      "2023-12-13 03:35:27,342 INFO     Training average negative_sample_loss at step 33100: 0.110858\n",
      "2023-12-13 03:35:27,342 INFO     Training average loss at step 33100: 0.136159\n",
      "2023-12-13 03:37:38,264 INFO     Training average positive_sample_loss at step 33200: 0.167717\n",
      "2023-12-13 03:37:38,264 INFO     Training average negative_sample_loss at step 33200: 0.110554\n",
      "2023-12-13 03:37:38,264 INFO     Training average loss at step 33200: 0.139136\n",
      "2023-12-13 03:39:55,763 INFO     Training average positive_sample_loss at step 33300: 0.166863\n",
      "2023-12-13 03:39:55,763 INFO     Training average negative_sample_loss at step 33300: 0.112734\n",
      "2023-12-13 03:39:55,763 INFO     Training average loss at step 33300: 0.139799\n",
      "2023-12-13 03:41:44,274 INFO     Training average positive_sample_loss at step 33400: 0.163438\n",
      "2023-12-13 03:41:44,275 INFO     Training average negative_sample_loss at step 33400: 0.110197\n",
      "2023-12-13 03:41:44,275 INFO     Training average loss at step 33400: 0.136818\n",
      "2023-12-13 03:43:45,556 INFO     Training average positive_sample_loss at step 33500: 0.168648\n",
      "2023-12-13 03:43:45,557 INFO     Training average negative_sample_loss at step 33500: 0.111600\n",
      "2023-12-13 03:43:45,557 INFO     Training average loss at step 33500: 0.140124\n",
      "2023-12-13 03:46:00,047 INFO     Training average positive_sample_loss at step 33600: 0.161986\n",
      "2023-12-13 03:46:00,048 INFO     Training average negative_sample_loss at step 33600: 0.110554\n",
      "2023-12-13 03:46:00,048 INFO     Training average loss at step 33600: 0.136270\n",
      "2023-12-13 03:48:11,256 INFO     Training average positive_sample_loss at step 33700: 0.166257\n",
      "2023-12-13 03:48:11,256 INFO     Training average negative_sample_loss at step 33700: 0.110130\n",
      "2023-12-13 03:48:11,256 INFO     Training average loss at step 33700: 0.138194\n",
      "2023-12-13 03:50:33,706 INFO     Training average positive_sample_loss at step 33800: 0.169182\n",
      "2023-12-13 03:50:33,707 INFO     Training average negative_sample_loss at step 33800: 0.112768\n",
      "2023-12-13 03:50:33,707 INFO     Training average loss at step 33800: 0.140975\n",
      "2023-12-13 03:52:33,696 INFO     Training average positive_sample_loss at step 33900: 0.160853\n",
      "2023-12-13 03:52:33,696 INFO     Training average negative_sample_loss at step 33900: 0.109876\n",
      "2023-12-13 03:52:33,696 INFO     Training average loss at step 33900: 0.135364\n",
      "2023-12-13 03:54:29,840 INFO     Training average positive_sample_loss at step 34000: 0.168116\n",
      "2023-12-13 03:54:29,840 INFO     Training average negative_sample_loss at step 34000: 0.110878\n",
      "2023-12-13 03:54:29,840 INFO     Training average loss at step 34000: 0.139497\n",
      "2023-12-13 03:56:44,476 INFO     Training average positive_sample_loss at step 34100: 0.163994\n",
      "2023-12-13 03:56:44,477 INFO     Training average negative_sample_loss at step 34100: 0.112010\n",
      "2023-12-13 03:56:44,477 INFO     Training average loss at step 34100: 0.138002\n",
      "2023-12-13 03:58:47,800 INFO     Training average positive_sample_loss at step 34200: 0.164893\n",
      "2023-12-13 03:58:47,800 INFO     Training average negative_sample_loss at step 34200: 0.109937\n",
      "2023-12-13 03:58:47,800 INFO     Training average loss at step 34200: 0.137415\n",
      "2023-12-13 04:00:46,108 INFO     Training average positive_sample_loss at step 34300: 0.168949\n",
      "2023-12-13 04:00:46,109 INFO     Training average negative_sample_loss at step 34300: 0.111585\n",
      "2023-12-13 04:00:46,109 INFO     Training average loss at step 34300: 0.140267\n",
      "2023-12-13 04:02:59,988 INFO     Training average positive_sample_loss at step 34400: 0.160763\n",
      "2023-12-13 04:02:59,988 INFO     Training average negative_sample_loss at step 34400: 0.109992\n",
      "2023-12-13 04:02:59,989 INFO     Training average loss at step 34400: 0.135377\n",
      "2023-12-13 04:05:01,597 INFO     Training average positive_sample_loss at step 34500: 0.167644\n",
      "2023-12-13 04:05:01,598 INFO     Training average negative_sample_loss at step 34500: 0.110744\n",
      "2023-12-13 04:05:01,598 INFO     Training average loss at step 34500: 0.139194\n",
      "2023-12-13 04:07:10,382 INFO     Training average positive_sample_loss at step 34600: 0.165173\n",
      "2023-12-13 04:07:10,383 INFO     Training average negative_sample_loss at step 34600: 0.112191\n",
      "2023-12-13 04:07:10,383 INFO     Training average loss at step 34600: 0.138682\n",
      "2023-12-13 04:09:04,120 INFO     Training average positive_sample_loss at step 34700: 0.163739\n",
      "2023-12-13 04:09:04,120 INFO     Training average negative_sample_loss at step 34700: 0.109489\n",
      "2023-12-13 04:09:04,121 INFO     Training average loss at step 34700: 0.136614\n",
      "2023-12-13 04:11:05,238 INFO     Training average positive_sample_loss at step 34800: 0.168840\n",
      "2023-12-13 04:11:05,239 INFO     Training average negative_sample_loss at step 34800: 0.111844\n",
      "2023-12-13 04:11:05,239 INFO     Training average loss at step 34800: 0.140342\n",
      "2023-12-13 04:13:18,114 INFO     Training average positive_sample_loss at step 34900: 0.161542\n",
      "2023-12-13 04:13:18,114 INFO     Training average negative_sample_loss at step 34900: 0.110553\n",
      "2023-12-13 04:13:18,114 INFO     Training average loss at step 34900: 0.136048\n",
      "2023-12-13 04:15:12,449 INFO     Training average positive_sample_loss at step 35000: 0.166462\n",
      "2023-12-13 04:15:12,449 INFO     Training average negative_sample_loss at step 35000: 0.109736\n",
      "2023-12-13 04:15:12,449 INFO     Training average loss at step 35000: 0.138099\n",
      "2023-12-13 04:17:36,955 INFO     Training average positive_sample_loss at step 35100: 0.166691\n",
      "2023-12-13 04:17:36,955 INFO     Training average negative_sample_loss at step 35100: 0.112592\n",
      "2023-12-13 04:17:36,955 INFO     Training average loss at step 35100: 0.139641\n",
      "2023-12-13 04:19:34,818 INFO     Training average positive_sample_loss at step 35200: 0.162383\n",
      "2023-12-13 04:19:34,819 INFO     Training average negative_sample_loss at step 35200: 0.109214\n",
      "2023-12-13 04:19:34,819 INFO     Training average loss at step 35200: 0.135798\n",
      "2023-12-13 04:21:33,141 INFO     Training average positive_sample_loss at step 35300: 0.167826\n",
      "2023-12-13 04:21:33,141 INFO     Training average negative_sample_loss at step 35300: 0.111272\n",
      "2023-12-13 04:21:33,142 INFO     Training average loss at step 35300: 0.139549\n",
      "2023-12-13 04:23:41,185 INFO     Training average positive_sample_loss at step 35400: 0.162884\n",
      "2023-12-13 04:23:41,186 INFO     Training average negative_sample_loss at step 35400: 0.111680\n",
      "2023-12-13 04:23:41,186 INFO     Training average loss at step 35400: 0.137282\n",
      "2023-12-13 04:25:48,453 INFO     Training average positive_sample_loss at step 35500: 0.165173\n",
      "2023-12-13 04:25:48,454 INFO     Training average negative_sample_loss at step 35500: 0.109365\n",
      "2023-12-13 04:25:48,454 INFO     Training average loss at step 35500: 0.137269\n",
      "2023-12-13 04:27:48,421 INFO     Training average positive_sample_loss at step 35600: 0.169157\n",
      "2023-12-13 04:27:48,422 INFO     Training average negative_sample_loss at step 35600: 0.111921\n",
      "2023-12-13 04:27:48,422 INFO     Training average loss at step 35600: 0.140539\n",
      "2023-12-13 04:30:05,757 INFO     Training average positive_sample_loss at step 35700: 0.160377\n",
      "2023-12-13 04:30:05,757 INFO     Training average negative_sample_loss at step 35700: 0.109772\n",
      "2023-12-13 04:30:05,757 INFO     Training average loss at step 35700: 0.135074\n",
      "2023-12-13 04:31:57,643 INFO     Training average positive_sample_loss at step 35800: 0.167580\n",
      "2023-12-13 04:31:57,644 INFO     Training average negative_sample_loss at step 35800: 0.110357\n",
      "2023-12-13 04:31:57,644 INFO     Training average loss at step 35800: 0.138969\n",
      "2023-12-13 04:34:11,604 INFO     Training average positive_sample_loss at step 35900: 0.163690\n",
      "2023-12-13 04:34:11,605 INFO     Training average negative_sample_loss at step 35900: 0.111733\n",
      "2023-12-13 04:34:11,605 INFO     Training average loss at step 35900: 0.137711\n",
      "2023-12-13 04:36:10,747 INFO     Training average positive_sample_loss at step 36000: 0.164317\n",
      "2023-12-13 04:36:10,747 INFO     Training average negative_sample_loss at step 36000: 0.109313\n",
      "2023-12-13 04:36:10,748 INFO     Training average loss at step 36000: 0.136815\n",
      "2023-12-13 04:38:08,238 INFO     Training average positive_sample_loss at step 36100: 0.168364\n",
      "2023-12-13 04:38:08,238 INFO     Training average negative_sample_loss at step 36100: 0.112076\n",
      "2023-12-13 04:38:08,238 INFO     Training average loss at step 36100: 0.140220\n",
      "2023-12-13 04:40:17,579 INFO     Training average positive_sample_loss at step 36200: 0.161750\n",
      "2023-12-13 04:40:17,579 INFO     Training average negative_sample_loss at step 36200: 0.110657\n",
      "2023-12-13 04:40:17,579 INFO     Training average loss at step 36200: 0.136204\n",
      "2023-12-13 04:42:15,619 INFO     Training average positive_sample_loss at step 36300: 0.165855\n",
      "2023-12-13 04:42:15,619 INFO     Training average negative_sample_loss at step 36300: 0.109645\n",
      "2023-12-13 04:42:15,619 INFO     Training average loss at step 36300: 0.137750\n",
      "2023-12-13 04:44:41,630 INFO     Training average positive_sample_loss at step 36400: 0.165550\n",
      "2023-12-13 04:44:41,630 INFO     Training average negative_sample_loss at step 36400: 0.112137\n",
      "2023-12-13 04:44:41,630 INFO     Training average loss at step 36400: 0.138843\n",
      "2023-12-13 04:46:53,719 INFO     Training average positive_sample_loss at step 36500: 0.162694\n",
      "2023-12-13 04:46:53,720 INFO     Training average negative_sample_loss at step 36500: 0.108917\n",
      "2023-12-13 04:46:53,720 INFO     Training average loss at step 36500: 0.135805\n",
      "2023-12-13 04:49:07,241 INFO     Training average positive_sample_loss at step 36600: 0.168220\n",
      "2023-12-13 04:49:07,241 INFO     Training average negative_sample_loss at step 36600: 0.111097\n",
      "2023-12-13 04:49:07,241 INFO     Training average loss at step 36600: 0.139659\n",
      "2023-12-13 04:51:17,649 INFO     Training average positive_sample_loss at step 36700: 0.161773\n",
      "2023-12-13 04:51:17,649 INFO     Training average negative_sample_loss at step 36700: 0.110845\n",
      "2023-12-13 04:51:17,649 INFO     Training average loss at step 36700: 0.136309\n",
      "2023-12-13 04:53:12,243 INFO     Training average positive_sample_loss at step 36800: 0.166163\n",
      "2023-12-13 04:53:12,244 INFO     Training average negative_sample_loss at step 36800: 0.109964\n",
      "2023-12-13 04:53:12,244 INFO     Training average loss at step 36800: 0.138063\n",
      "2023-12-13 04:55:33,661 INFO     Training average positive_sample_loss at step 36900: 0.167147\n",
      "2023-12-13 04:55:33,661 INFO     Training average negative_sample_loss at step 36900: 0.111832\n",
      "2023-12-13 04:55:33,661 INFO     Training average loss at step 36900: 0.139490\n",
      "2023-12-13 04:57:28,058 INFO     Training average positive_sample_loss at step 37000: 0.161074\n",
      "2023-12-13 04:57:28,059 INFO     Training average negative_sample_loss at step 37000: 0.109477\n",
      "2023-12-13 04:57:28,059 INFO     Training average loss at step 37000: 0.135276\n",
      "2023-12-13 04:59:42,625 INFO     Training average positive_sample_loss at step 37100: 0.167289\n",
      "2023-12-13 04:59:42,626 INFO     Training average negative_sample_loss at step 37100: 0.110646\n",
      "2023-12-13 04:59:42,626 INFO     Training average loss at step 37100: 0.138968\n",
      "2023-12-13 05:01:39,755 INFO     Training average positive_sample_loss at step 37200: 0.162366\n",
      "2023-12-13 05:01:39,756 INFO     Training average negative_sample_loss at step 37200: 0.110844\n",
      "2023-12-13 05:01:39,756 INFO     Training average loss at step 37200: 0.136605\n",
      "2023-12-13 05:03:36,413 INFO     Training average positive_sample_loss at step 37300: 0.165448\n",
      "2023-12-13 05:03:36,413 INFO     Training average negative_sample_loss at step 37300: 0.109147\n",
      "2023-12-13 05:03:36,413 INFO     Training average loss at step 37300: 0.137298\n",
      "2023-12-13 05:05:45,500 INFO     Training average positive_sample_loss at step 37400: 0.168110\n",
      "2023-12-13 05:05:45,501 INFO     Training average negative_sample_loss at step 37400: 0.111614\n",
      "2023-12-13 05:05:45,501 INFO     Training average loss at step 37400: 0.139862\n",
      "2023-12-13 05:07:53,419 INFO     Training average positive_sample_loss at step 37500: 0.159768\n",
      "2023-12-13 05:07:53,420 INFO     Training average negative_sample_loss at step 37500: 0.109418\n",
      "2023-12-13 05:07:53,420 INFO     Training average loss at step 37500: 0.134593\n",
      "2023-12-13 05:09:47,670 INFO     Training average positive_sample_loss at step 37600: 0.166924\n",
      "2023-12-13 05:09:47,671 INFO     Training average negative_sample_loss at step 37600: 0.110029\n",
      "2023-12-13 05:09:47,671 INFO     Training average loss at step 37600: 0.138476\n",
      "2023-12-13 05:11:59,744 INFO     Training average positive_sample_loss at step 37700: 0.164057\n",
      "2023-12-13 05:11:59,744 INFO     Training average negative_sample_loss at step 37700: 0.111600\n",
      "2023-12-13 05:11:59,744 INFO     Training average loss at step 37700: 0.137829\n",
      "2023-12-13 05:13:58,456 INFO     Training average positive_sample_loss at step 37800: 0.164062\n",
      "2023-12-13 05:13:58,456 INFO     Training average negative_sample_loss at step 37800: 0.109184\n",
      "2023-12-13 05:13:58,456 INFO     Training average loss at step 37800: 0.136623\n",
      "2023-12-13 05:16:06,485 INFO     Training average positive_sample_loss at step 37900: 0.167700\n",
      "2023-12-13 05:16:06,486 INFO     Training average negative_sample_loss at step 37900: 0.111242\n",
      "2023-12-13 05:16:06,486 INFO     Training average loss at step 37900: 0.139471\n",
      "2023-12-13 05:18:34,257 INFO     Training average positive_sample_loss at step 38000: 0.161469\n",
      "2023-12-13 05:18:34,257 INFO     Training average negative_sample_loss at step 38000: 0.110150\n",
      "2023-12-13 05:18:34,257 INFO     Training average loss at step 38000: 0.135810\n",
      "2023-12-13 05:20:38,630 INFO     Training average positive_sample_loss at step 38100: 0.165621\n",
      "2023-12-13 05:20:38,630 INFO     Training average negative_sample_loss at step 38100: 0.109800\n",
      "2023-12-13 05:20:38,631 INFO     Training average loss at step 38100: 0.137710\n",
      "2023-12-13 05:22:49,105 INFO     Training average positive_sample_loss at step 38200: 0.165382\n",
      "2023-12-13 05:22:49,106 INFO     Training average negative_sample_loss at step 38200: 0.111359\n",
      "2023-12-13 05:22:49,106 INFO     Training average loss at step 38200: 0.138371\n",
      "2023-12-13 05:24:47,169 INFO     Training average positive_sample_loss at step 38300: 0.162521\n",
      "2023-12-13 05:24:47,169 INFO     Training average negative_sample_loss at step 38300: 0.108872\n",
      "2023-12-13 05:24:47,169 INFO     Training average loss at step 38300: 0.135696\n",
      "2023-12-13 05:26:42,472 INFO     Training average positive_sample_loss at step 38400: 0.166779\n",
      "2023-12-13 05:26:42,473 INFO     Training average negative_sample_loss at step 38400: 0.110662\n",
      "2023-12-13 05:26:42,473 INFO     Training average loss at step 38400: 0.138720\n",
      "2023-12-13 05:28:49,029 INFO     Training average positive_sample_loss at step 38500: 0.161681\n",
      "2023-12-13 05:28:49,030 INFO     Training average negative_sample_loss at step 38500: 0.110740\n",
      "2023-12-13 05:28:49,030 INFO     Training average loss at step 38500: 0.136210\n",
      "2023-12-13 05:30:39,673 INFO     Training average positive_sample_loss at step 38600: 0.165288\n",
      "2023-12-13 05:30:39,673 INFO     Training average negative_sample_loss at step 38600: 0.108985\n",
      "2023-12-13 05:30:39,673 INFO     Training average loss at step 38600: 0.137137\n",
      "2023-12-13 05:33:00,147 INFO     Training average positive_sample_loss at step 38700: 0.167918\n",
      "2023-12-13 05:33:00,148 INFO     Training average negative_sample_loss at step 38700: 0.111886\n",
      "2023-12-13 05:33:00,148 INFO     Training average loss at step 38700: 0.139902\n",
      "2023-12-13 05:35:11,233 INFO     Training average positive_sample_loss at step 38800: 0.160264\n",
      "2023-12-13 05:35:11,234 INFO     Training average negative_sample_loss at step 38800: 0.109384\n",
      "2023-12-13 05:35:11,234 INFO     Training average loss at step 38800: 0.134824\n",
      "2023-12-13 05:37:23,688 INFO     Training average positive_sample_loss at step 38900: 0.166812\n",
      "2023-12-13 05:37:23,689 INFO     Training average negative_sample_loss at step 38900: 0.109985\n",
      "2023-12-13 05:37:23,689 INFO     Training average loss at step 38900: 0.138399\n",
      "2023-12-13 05:39:38,102 INFO     Training average positive_sample_loss at step 39000: 0.162225\n",
      "2023-12-13 05:39:38,102 INFO     Training average negative_sample_loss at step 39000: 0.111023\n",
      "2023-12-13 05:39:38,102 INFO     Training average loss at step 39000: 0.136624\n",
      "2023-12-13 05:41:44,275 INFO     Training average positive_sample_loss at step 39100: 0.165049\n",
      "2023-12-13 05:41:44,275 INFO     Training average negative_sample_loss at step 39100: 0.109380\n",
      "2023-12-13 05:41:44,275 INFO     Training average loss at step 39100: 0.137214\n",
      "2023-12-13 05:43:40,993 INFO     Training average positive_sample_loss at step 39200: 0.167236\n",
      "2023-12-13 05:43:40,993 INFO     Training average negative_sample_loss at step 39200: 0.110816\n",
      "2023-12-13 05:43:40,993 INFO     Training average loss at step 39200: 0.139026\n",
      "2023-12-13 05:45:45,103 INFO     Training average positive_sample_loss at step 39300: 0.160160\n",
      "2023-12-13 05:45:45,104 INFO     Training average negative_sample_loss at step 39300: 0.109332\n",
      "2023-12-13 05:45:45,104 INFO     Training average loss at step 39300: 0.134746\n",
      "2023-12-13 05:47:49,507 INFO     Training average positive_sample_loss at step 39400: 0.165638\n",
      "2023-12-13 05:47:49,508 INFO     Training average negative_sample_loss at step 39400: 0.109496\n",
      "2023-12-13 05:47:49,508 INFO     Training average loss at step 39400: 0.137567\n",
      "2023-12-13 05:49:49,184 INFO     Training average positive_sample_loss at step 39500: 0.165233\n",
      "2023-12-13 05:49:49,184 INFO     Training average negative_sample_loss at step 39500: 0.111875\n",
      "2023-12-13 05:49:49,184 INFO     Training average loss at step 39500: 0.138554\n",
      "2023-12-13 05:51:48,355 INFO     Training average positive_sample_loss at step 39600: 0.162517\n",
      "2023-12-13 05:51:48,356 INFO     Training average negative_sample_loss at step 39600: 0.108921\n",
      "2023-12-13 05:51:48,356 INFO     Training average loss at step 39600: 0.135719\n",
      "2023-12-13 05:53:48,005 INFO     Training average positive_sample_loss at step 39700: 0.167144\n",
      "2023-12-13 05:53:48,005 INFO     Training average negative_sample_loss at step 39700: 0.110366\n",
      "2023-12-13 05:53:48,005 INFO     Training average loss at step 39700: 0.138755\n",
      "2023-12-13 05:55:59,420 INFO     Training average positive_sample_loss at step 39800: 0.160579\n",
      "2023-12-13 05:55:59,420 INFO     Training average negative_sample_loss at step 39800: 0.110033\n",
      "2023-12-13 05:55:59,420 INFO     Training average loss at step 39800: 0.135306\n",
      "2023-12-13 05:58:00,739 INFO     Training average positive_sample_loss at step 39900: 0.165976\n",
      "2023-12-13 05:58:00,739 INFO     Training average negative_sample_loss at step 39900: 0.109087\n",
      "2023-12-13 05:58:00,740 INFO     Training average loss at step 39900: 0.137531\n",
      "2023-12-13 06:00:38,031 INFO     Training average positive_sample_loss at step 40000: 0.166016\n",
      "2023-12-13 06:00:38,032 INFO     Training average negative_sample_loss at step 40000: 0.111572\n",
      "2023-12-13 06:00:38,032 INFO     Training average loss at step 40000: 0.138794\n",
      "2023-12-13 06:00:38,032 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-13 06:00:38,532 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-13 06:01:03,770 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-13 06:01:18,273 INFO     Valid MRR at step 40000: 0.418180\n",
      "2023-12-13 06:01:18,273 INFO     Valid MR at step 40000: 709.258510\n",
      "2023-12-13 06:01:18,273 INFO     Valid HITS@1 at step 40000: 0.391978\n",
      "2023-12-13 06:01:18,274 INFO     Valid HITS@3 at step 40000: 0.420527\n",
      "2023-12-13 06:01:18,274 INFO     Valid HITS@10 at step 40000: 0.468040\n",
      "2023-12-13 06:02:53,764 INFO     Training average positive_sample_loss at step 40100: 0.160870\n",
      "2023-12-13 06:02:53,765 INFO     Training average negative_sample_loss at step 40100: 0.108530\n",
      "2023-12-13 06:02:53,765 INFO     Training average loss at step 40100: 0.134700\n",
      "2023-12-13 06:04:54,390 INFO     Training average positive_sample_loss at step 40200: 0.166593\n",
      "2023-12-13 06:04:54,390 INFO     Training average negative_sample_loss at step 40200: 0.110191\n",
      "2023-12-13 06:04:54,390 INFO     Training average loss at step 40200: 0.138392\n",
      "2023-12-13 06:07:11,425 INFO     Training average positive_sample_loss at step 40300: 0.162078\n",
      "2023-12-13 06:07:11,426 INFO     Training average negative_sample_loss at step 40300: 0.110912\n",
      "2023-12-13 06:07:11,426 INFO     Training average loss at step 40300: 0.136495\n",
      "2023-12-13 06:09:26,085 INFO     Training average positive_sample_loss at step 40400: 0.164575\n",
      "2023-12-13 06:09:26,086 INFO     Training average negative_sample_loss at step 40400: 0.108859\n",
      "2023-12-13 06:09:26,086 INFO     Training average loss at step 40400: 0.136717\n",
      "2023-12-13 06:11:26,626 INFO     Training average positive_sample_loss at step 40500: 0.167789\n",
      "2023-12-13 06:11:26,627 INFO     Training average negative_sample_loss at step 40500: 0.111099\n",
      "2023-12-13 06:11:26,627 INFO     Training average loss at step 40500: 0.139444\n",
      "2023-12-13 06:13:36,411 INFO     Training average positive_sample_loss at step 40600: 0.159210\n",
      "2023-12-13 06:13:36,412 INFO     Training average negative_sample_loss at step 40600: 0.108522\n",
      "2023-12-13 06:13:36,412 INFO     Training average loss at step 40600: 0.133866\n",
      "2023-12-13 06:15:43,610 INFO     Training average positive_sample_loss at step 40700: 0.166411\n",
      "2023-12-13 06:15:43,610 INFO     Training average negative_sample_loss at step 40700: 0.110075\n",
      "2023-12-13 06:15:43,610 INFO     Training average loss at step 40700: 0.138243\n",
      "2023-12-13 06:17:49,835 INFO     Training average positive_sample_loss at step 40800: 0.163501\n",
      "2023-12-13 06:17:49,835 INFO     Training average negative_sample_loss at step 40800: 0.111126\n",
      "2023-12-13 06:17:49,836 INFO     Training average loss at step 40800: 0.137313\n",
      "2023-12-13 06:19:39,015 INFO     Training average positive_sample_loss at step 40900: 0.162331\n",
      "2023-12-13 06:19:39,015 INFO     Training average negative_sample_loss at step 40900: 0.108208\n",
      "2023-12-13 06:19:39,015 INFO     Training average loss at step 40900: 0.135270\n",
      "2023-12-13 06:21:54,487 INFO     Training average positive_sample_loss at step 41000: 0.167789\n",
      "2023-12-13 06:21:54,488 INFO     Training average negative_sample_loss at step 41000: 0.111099\n",
      "2023-12-13 06:21:54,488 INFO     Training average loss at step 41000: 0.139444\n",
      "2023-12-13 06:23:59,479 INFO     Training average positive_sample_loss at step 41100: 0.160229\n",
      "2023-12-13 06:23:59,480 INFO     Training average negative_sample_loss at step 41100: 0.109436\n",
      "2023-12-13 06:23:59,480 INFO     Training average loss at step 41100: 0.134832\n",
      "2023-12-13 06:26:02,455 INFO     Training average positive_sample_loss at step 41200: 0.165829\n",
      "2023-12-13 06:26:02,456 INFO     Training average negative_sample_loss at step 41200: 0.109365\n",
      "2023-12-13 06:26:02,456 INFO     Training average loss at step 41200: 0.137597\n",
      "2023-12-13 06:28:20,498 INFO     Training average positive_sample_loss at step 41300: 0.164400\n",
      "2023-12-13 06:28:20,498 INFO     Training average negative_sample_loss at step 41300: 0.111324\n",
      "2023-12-13 06:28:20,498 INFO     Training average loss at step 41300: 0.137862\n",
      "2023-12-13 06:30:19,931 INFO     Training average positive_sample_loss at step 41400: 0.161606\n",
      "2023-12-13 06:30:19,932 INFO     Training average negative_sample_loss at step 41400: 0.108030\n",
      "2023-12-13 06:30:19,932 INFO     Training average loss at step 41400: 0.134818\n",
      "2023-12-13 06:32:28,482 INFO     Training average positive_sample_loss at step 41500: 0.167180\n",
      "2023-12-13 06:32:28,482 INFO     Training average negative_sample_loss at step 41500: 0.110428\n",
      "2023-12-13 06:32:28,482 INFO     Training average loss at step 41500: 0.138804\n",
      "2023-12-13 06:34:47,799 INFO     Training average positive_sample_loss at step 41600: 0.160771\n",
      "2023-12-13 06:34:47,800 INFO     Training average negative_sample_loss at step 41600: 0.110008\n",
      "2023-12-13 06:34:47,800 INFO     Training average loss at step 41600: 0.135390\n",
      "2023-12-13 06:36:45,255 INFO     Training average positive_sample_loss at step 41700: 0.164649\n",
      "2023-12-13 06:36:45,255 INFO     Training average negative_sample_loss at step 41700: 0.108917\n",
      "2023-12-13 06:36:45,255 INFO     Training average loss at step 41700: 0.136783\n",
      "2023-12-13 06:39:01,023 INFO     Training average positive_sample_loss at step 41800: 0.166858\n",
      "2023-12-13 06:39:01,024 INFO     Training average negative_sample_loss at step 41800: 0.110937\n",
      "2023-12-13 06:39:01,024 INFO     Training average loss at step 41800: 0.138898\n",
      "2023-12-13 06:41:01,274 INFO     Training average positive_sample_loss at step 41900: 0.159961\n",
      "2023-12-13 06:41:01,275 INFO     Training average negative_sample_loss at step 41900: 0.108430\n",
      "2023-12-13 06:41:01,275 INFO     Training average loss at step 41900: 0.134196\n",
      "2023-12-13 06:43:11,561 INFO     Training average positive_sample_loss at step 42000: 0.166483\n",
      "2023-12-13 06:43:11,562 INFO     Training average negative_sample_loss at step 42000: 0.109849\n",
      "2023-12-13 06:43:11,562 INFO     Training average loss at step 42000: 0.138166\n",
      "2023-12-13 06:45:19,228 INFO     Training average positive_sample_loss at step 42100: 0.161852\n",
      "2023-12-13 06:45:19,228 INFO     Training average negative_sample_loss at step 42100: 0.110527\n",
      "2023-12-13 06:45:19,228 INFO     Training average loss at step 42100: 0.136189\n",
      "2023-12-13 06:47:18,636 INFO     Training average positive_sample_loss at step 42200: 0.163849\n",
      "2023-12-13 06:47:18,636 INFO     Training average negative_sample_loss at step 42200: 0.108579\n",
      "2023-12-13 06:47:18,636 INFO     Training average loss at step 42200: 0.136214\n",
      "2023-12-13 06:49:10,994 INFO     Training average positive_sample_loss at step 42300: 0.167186\n",
      "2023-12-13 06:49:10,995 INFO     Training average negative_sample_loss at step 42300: 0.110997\n",
      "2023-12-13 06:49:10,995 INFO     Training average loss at step 42300: 0.139092\n",
      "2023-12-13 06:51:29,072 INFO     Training average positive_sample_loss at step 42400: 0.158538\n",
      "2023-12-13 06:51:29,073 INFO     Training average negative_sample_loss at step 42400: 0.108320\n",
      "2023-12-13 06:51:29,073 INFO     Training average loss at step 42400: 0.133429\n",
      "2023-12-13 06:53:30,042 INFO     Training average positive_sample_loss at step 42500: 0.166748\n",
      "2023-12-13 06:53:30,043 INFO     Training average negative_sample_loss at step 42500: 0.109927\n",
      "2023-12-13 06:53:30,043 INFO     Training average loss at step 42500: 0.138338\n",
      "2023-12-13 06:55:42,947 INFO     Training average positive_sample_loss at step 42600: 0.162941\n",
      "2023-12-13 06:55:42,947 INFO     Training average negative_sample_loss at step 42600: 0.110702\n",
      "2023-12-13 06:55:42,947 INFO     Training average loss at step 42600: 0.136822\n",
      "2023-12-13 06:57:40,129 INFO     Training average positive_sample_loss at step 42700: 0.162583\n",
      "2023-12-13 06:57:40,130 INFO     Training average negative_sample_loss at step 42700: 0.108283\n",
      "2023-12-13 06:57:40,130 INFO     Training average loss at step 42700: 0.135433\n",
      "2023-12-13 06:59:44,681 INFO     Training average positive_sample_loss at step 42800: 0.166784\n",
      "2023-12-13 06:59:44,682 INFO     Training average negative_sample_loss at step 42800: 0.110749\n",
      "2023-12-13 06:59:44,682 INFO     Training average loss at step 42800: 0.138766\n",
      "2023-12-13 07:02:02,578 INFO     Training average positive_sample_loss at step 42900: 0.160879\n",
      "2023-12-13 07:02:02,578 INFO     Training average negative_sample_loss at step 42900: 0.109709\n",
      "2023-12-13 07:02:02,578 INFO     Training average loss at step 42900: 0.135294\n",
      "2023-12-13 07:04:03,494 INFO     Training average positive_sample_loss at step 43000: 0.164646\n",
      "2023-12-13 07:04:03,494 INFO     Training average negative_sample_loss at step 43000: 0.108650\n",
      "2023-12-13 07:04:03,494 INFO     Training average loss at step 43000: 0.136648\n",
      "2023-12-13 07:06:27,763 INFO     Training average positive_sample_loss at step 43100: 0.164957\n",
      "2023-12-13 07:06:27,763 INFO     Training average negative_sample_loss at step 43100: 0.111114\n",
      "2023-12-13 07:06:27,763 INFO     Training average loss at step 43100: 0.138035\n",
      "2023-12-13 07:08:25,742 INFO     Training average positive_sample_loss at step 43200: 0.160916\n",
      "2023-12-13 07:08:25,742 INFO     Training average negative_sample_loss at step 43200: 0.107868\n",
      "2023-12-13 07:08:25,742 INFO     Training average loss at step 43200: 0.134392\n",
      "2023-12-13 07:10:31,957 INFO     Training average positive_sample_loss at step 43300: 0.166425\n",
      "2023-12-13 07:10:31,958 INFO     Training average negative_sample_loss at step 43300: 0.110001\n",
      "2023-12-13 07:10:31,958 INFO     Training average loss at step 43300: 0.138213\n",
      "2023-12-13 07:12:43,896 INFO     Training average positive_sample_loss at step 43400: 0.160724\n",
      "2023-12-13 07:12:43,897 INFO     Training average negative_sample_loss at step 43400: 0.110058\n",
      "2023-12-13 07:12:43,897 INFO     Training average loss at step 43400: 0.135391\n",
      "2023-12-13 07:14:49,912 INFO     Training average positive_sample_loss at step 43500: 0.164575\n",
      "2023-12-13 07:14:49,913 INFO     Training average negative_sample_loss at step 43500: 0.108408\n",
      "2023-12-13 07:14:49,913 INFO     Training average loss at step 43500: 0.136491\n",
      "2023-12-13 07:16:55,647 INFO     Training average positive_sample_loss at step 43600: 0.166894\n",
      "2023-12-13 07:16:55,648 INFO     Training average negative_sample_loss at step 43600: 0.110773\n",
      "2023-12-13 07:16:55,648 INFO     Training average loss at step 43600: 0.138834\n",
      "2023-12-13 07:19:01,110 INFO     Training average positive_sample_loss at step 43700: 0.158460\n",
      "2023-12-13 07:19:01,110 INFO     Training average negative_sample_loss at step 43700: 0.108159\n",
      "2023-12-13 07:19:01,111 INFO     Training average loss at step 43700: 0.133310\n",
      "2023-12-13 07:21:07,418 INFO     Training average positive_sample_loss at step 43800: 0.166279\n",
      "2023-12-13 07:21:07,418 INFO     Training average negative_sample_loss at step 43800: 0.109520\n",
      "2023-12-13 07:21:07,418 INFO     Training average loss at step 43800: 0.137900\n",
      "2023-12-13 07:23:24,597 INFO     Training average positive_sample_loss at step 43900: 0.162099\n",
      "2023-12-13 07:23:24,598 INFO     Training average negative_sample_loss at step 43900: 0.110518\n",
      "2023-12-13 07:23:24,598 INFO     Training average loss at step 43900: 0.136309\n",
      "2023-12-13 07:25:25,574 INFO     Training average positive_sample_loss at step 44000: 0.163093\n",
      "2023-12-13 07:25:25,575 INFO     Training average negative_sample_loss at step 44000: 0.108308\n",
      "2023-12-13 07:25:25,575 INFO     Training average loss at step 44000: 0.135701\n",
      "2023-12-13 07:27:32,696 INFO     Training average positive_sample_loss at step 44100: 0.166993\n",
      "2023-12-13 07:27:32,697 INFO     Training average negative_sample_loss at step 44100: 0.110561\n",
      "2023-12-13 07:27:32,697 INFO     Training average loss at step 44100: 0.138777\n",
      "2023-12-13 07:29:43,366 INFO     Training average positive_sample_loss at step 44200: 0.159756\n",
      "2023-12-13 07:29:43,366 INFO     Training average negative_sample_loss at step 44200: 0.109215\n",
      "2023-12-13 07:29:43,366 INFO     Training average loss at step 44200: 0.134486\n",
      "2023-12-13 07:31:47,050 INFO     Training average positive_sample_loss at step 44300: 0.165352\n",
      "2023-12-13 07:31:47,051 INFO     Training average negative_sample_loss at step 44300: 0.108706\n",
      "2023-12-13 07:31:47,051 INFO     Training average loss at step 44300: 0.137029\n",
      "2023-12-13 07:34:15,120 INFO     Training average positive_sample_loss at step 44400: 0.163236\n",
      "2023-12-13 07:34:15,121 INFO     Training average negative_sample_loss at step 44400: 0.110581\n",
      "2023-12-13 07:34:15,121 INFO     Training average loss at step 44400: 0.136909\n",
      "2023-12-13 07:36:16,056 INFO     Training average positive_sample_loss at step 44500: 0.161649\n",
      "2023-12-13 07:36:16,057 INFO     Training average negative_sample_loss at step 44500: 0.107971\n",
      "2023-12-13 07:36:16,057 INFO     Training average loss at step 44500: 0.134810\n",
      "2023-12-13 07:38:20,023 INFO     Training average positive_sample_loss at step 44600: 0.166394\n",
      "2023-12-13 07:38:20,024 INFO     Training average negative_sample_loss at step 44600: 0.110126\n",
      "2023-12-13 07:38:20,024 INFO     Training average loss at step 44600: 0.138260\n",
      "2023-12-13 07:40:32,126 INFO     Training average positive_sample_loss at step 44700: 0.160247\n",
      "2023-12-13 07:40:32,127 INFO     Training average negative_sample_loss at step 44700: 0.109323\n",
      "2023-12-13 07:40:32,127 INFO     Training average loss at step 44700: 0.134785\n",
      "2023-12-13 07:42:37,516 INFO     Training average positive_sample_loss at step 44800: 0.164494\n",
      "2023-12-13 07:42:37,517 INFO     Training average negative_sample_loss at step 44800: 0.108539\n",
      "2023-12-13 07:42:37,517 INFO     Training average loss at step 44800: 0.136516\n",
      "2023-12-13 07:44:54,441 INFO     Training average positive_sample_loss at step 44900: 0.165675\n",
      "2023-12-13 07:44:54,441 INFO     Training average negative_sample_loss at step 44900: 0.110846\n",
      "2023-12-13 07:44:54,441 INFO     Training average loss at step 44900: 0.138260\n",
      "2023-12-13 07:46:44,697 INFO     Training average positive_sample_loss at step 45000: 0.160334\n",
      "2023-12-13 07:46:44,697 INFO     Training average negative_sample_loss at step 45000: 0.108384\n",
      "2023-12-13 07:46:44,697 INFO     Training average loss at step 45000: 0.134359\n",
      "2023-12-13 07:48:43,949 INFO     Training average positive_sample_loss at step 45100: 0.165570\n",
      "2023-12-13 07:48:43,950 INFO     Training average negative_sample_loss at step 45100: 0.109491\n",
      "2023-12-13 07:48:43,950 INFO     Training average loss at step 45100: 0.137531\n",
      "2023-12-13 07:50:53,698 INFO     Training average positive_sample_loss at step 45200: 0.160471\n",
      "2023-12-13 07:50:53,699 INFO     Training average negative_sample_loss at step 45200: 0.109331\n",
      "2023-12-13 07:50:53,699 INFO     Training average loss at step 45200: 0.134901\n",
      "2023-12-13 07:52:45,213 INFO     Training average positive_sample_loss at step 45300: 0.163375\n",
      "2023-12-13 07:52:45,213 INFO     Training average negative_sample_loss at step 45300: 0.107795\n",
      "2023-12-13 07:52:45,213 INFO     Training average loss at step 45300: 0.135585\n",
      "2023-12-13 07:54:44,748 INFO     Training average positive_sample_loss at step 45400: 0.167541\n",
      "2023-12-13 07:54:44,748 INFO     Training average negative_sample_loss at step 45400: 0.110986\n",
      "2023-12-13 07:54:44,748 INFO     Training average loss at step 45400: 0.139263\n",
      "2023-12-13 07:57:14,951 INFO     Training average positive_sample_loss at step 45500: 0.158934\n",
      "2023-12-13 07:57:14,952 INFO     Training average negative_sample_loss at step 45500: 0.108424\n",
      "2023-12-13 07:57:14,952 INFO     Training average loss at step 45500: 0.133679\n",
      "2023-12-13 07:59:17,833 INFO     Training average positive_sample_loss at step 45600: 0.165168\n",
      "2023-12-13 07:59:17,833 INFO     Training average negative_sample_loss at step 45600: 0.108994\n",
      "2023-12-13 07:59:17,833 INFO     Training average loss at step 45600: 0.137081\n",
      "2023-12-13 08:01:29,803 INFO     Training average positive_sample_loss at step 45700: 0.162282\n",
      "2023-12-13 08:01:29,803 INFO     Training average negative_sample_loss at step 45700: 0.110239\n",
      "2023-12-13 08:01:29,803 INFO     Training average loss at step 45700: 0.136260\n",
      "2023-12-13 08:03:23,671 INFO     Training average positive_sample_loss at step 45800: 0.162414\n",
      "2023-12-13 08:03:23,672 INFO     Training average negative_sample_loss at step 45800: 0.108049\n",
      "2023-12-13 08:03:23,672 INFO     Training average loss at step 45800: 0.135232\n",
      "2023-12-13 08:05:32,390 INFO     Training average positive_sample_loss at step 45900: 0.166777\n",
      "2023-12-13 08:05:32,391 INFO     Training average negative_sample_loss at step 45900: 0.110208\n",
      "2023-12-13 08:05:32,391 INFO     Training average loss at step 45900: 0.138493\n",
      "2023-12-13 08:07:47,498 INFO     Training average positive_sample_loss at step 46000: 0.159409\n",
      "2023-12-13 08:07:47,499 INFO     Training average negative_sample_loss at step 46000: 0.108978\n",
      "2023-12-13 08:07:47,499 INFO     Training average loss at step 46000: 0.134193\n",
      "2023-12-13 08:09:50,125 INFO     Training average positive_sample_loss at step 46100: 0.165200\n",
      "2023-12-13 08:09:50,125 INFO     Training average negative_sample_loss at step 46100: 0.108905\n",
      "2023-12-13 08:09:50,125 INFO     Training average loss at step 46100: 0.137052\n",
      "2023-12-13 08:12:05,988 INFO     Training average positive_sample_loss at step 46200: 0.163431\n",
      "2023-12-13 08:12:05,988 INFO     Training average negative_sample_loss at step 46200: 0.110348\n",
      "2023-12-13 08:12:05,988 INFO     Training average loss at step 46200: 0.136889\n",
      "2023-12-13 08:14:00,231 INFO     Training average positive_sample_loss at step 46300: 0.160714\n",
      "2023-12-13 08:14:00,231 INFO     Training average negative_sample_loss at step 46300: 0.107473\n",
      "2023-12-13 08:14:00,231 INFO     Training average loss at step 46300: 0.134094\n",
      "2023-12-13 08:16:03,767 INFO     Training average positive_sample_loss at step 46400: 0.166284\n",
      "2023-12-13 08:16:03,768 INFO     Training average negative_sample_loss at step 46400: 0.109739\n",
      "2023-12-13 08:16:03,768 INFO     Training average loss at step 46400: 0.138012\n",
      "2023-12-13 08:18:16,801 INFO     Training average positive_sample_loss at step 46500: 0.159818\n",
      "2023-12-13 08:18:16,801 INFO     Training average negative_sample_loss at step 46500: 0.109101\n",
      "2023-12-13 08:18:16,801 INFO     Training average loss at step 46500: 0.134459\n",
      "2023-12-13 08:20:19,793 INFO     Training average positive_sample_loss at step 46600: 0.163584\n",
      "2023-12-13 08:20:19,793 INFO     Training average negative_sample_loss at step 46600: 0.107806\n",
      "2023-12-13 08:20:19,793 INFO     Training average loss at step 46600: 0.135695\n",
      "2023-12-13 08:22:43,758 INFO     Training average positive_sample_loss at step 46700: 0.167244\n",
      "2023-12-13 08:22:43,758 INFO     Training average negative_sample_loss at step 46700: 0.111073\n",
      "2023-12-13 08:22:43,758 INFO     Training average loss at step 46700: 0.139159\n",
      "2023-12-13 08:24:33,893 INFO     Training average positive_sample_loss at step 46800: 0.158719\n",
      "2023-12-13 08:24:33,893 INFO     Training average negative_sample_loss at step 46800: 0.108244\n",
      "2023-12-13 08:24:33,893 INFO     Training average loss at step 46800: 0.133482\n",
      "2023-12-13 08:26:31,442 INFO     Training average positive_sample_loss at step 46900: 0.165331\n",
      "2023-12-13 08:26:31,442 INFO     Training average negative_sample_loss at step 46900: 0.108808\n",
      "2023-12-13 08:26:31,442 INFO     Training average loss at step 46900: 0.137069\n",
      "2023-12-13 08:28:36,564 INFO     Training average positive_sample_loss at step 47000: 0.161367\n",
      "2023-12-13 08:28:36,564 INFO     Training average negative_sample_loss at step 47000: 0.110123\n",
      "2023-12-13 08:28:36,564 INFO     Training average loss at step 47000: 0.135745\n",
      "2023-12-13 08:30:38,304 INFO     Training average positive_sample_loss at step 47100: 0.162649\n",
      "2023-12-13 08:30:38,305 INFO     Training average negative_sample_loss at step 47100: 0.107630\n",
      "2023-12-13 08:30:38,305 INFO     Training average loss at step 47100: 0.135140\n",
      "2023-12-13 08:32:39,246 INFO     Training average positive_sample_loss at step 47200: 0.166546\n",
      "2023-12-13 08:32:39,247 INFO     Training average negative_sample_loss at step 47200: 0.110426\n",
      "2023-12-13 08:32:39,247 INFO     Training average loss at step 47200: 0.138486\n",
      "2023-12-13 08:34:48,759 INFO     Training average positive_sample_loss at step 47300: 0.158707\n",
      "2023-12-13 08:34:48,760 INFO     Training average negative_sample_loss at step 47300: 0.108171\n",
      "2023-12-13 08:34:48,760 INFO     Training average loss at step 47300: 0.133439\n",
      "2023-12-13 08:36:46,107 INFO     Training average positive_sample_loss at step 47400: 0.165900\n",
      "2023-12-13 08:36:46,107 INFO     Training average negative_sample_loss at step 47400: 0.109217\n",
      "2023-12-13 08:36:46,107 INFO     Training average loss at step 47400: 0.137559\n",
      "2023-12-13 08:39:00,228 INFO     Training average positive_sample_loss at step 47500: 0.162533\n",
      "2023-12-13 08:39:00,228 INFO     Training average negative_sample_loss at step 47500: 0.110271\n",
      "2023-12-13 08:39:00,228 INFO     Training average loss at step 47500: 0.136402\n",
      "2023-12-13 08:40:57,804 INFO     Training average positive_sample_loss at step 47600: 0.161690\n",
      "2023-12-13 08:40:57,804 INFO     Training average negative_sample_loss at step 47600: 0.107474\n",
      "2023-12-13 08:40:57,804 INFO     Training average loss at step 47600: 0.134582\n",
      "2023-12-13 08:42:56,199 INFO     Training average positive_sample_loss at step 47700: 0.165712\n",
      "2023-12-13 08:42:56,200 INFO     Training average negative_sample_loss at step 47700: 0.110026\n",
      "2023-12-13 08:42:56,200 INFO     Training average loss at step 47700: 0.137869\n",
      "2023-12-13 08:45:10,765 INFO     Training average positive_sample_loss at step 47800: 0.158453\n",
      "2023-12-13 08:45:10,766 INFO     Training average negative_sample_loss at step 47800: 0.108050\n",
      "2023-12-13 08:45:10,766 INFO     Training average loss at step 47800: 0.133251\n",
      "2023-12-13 08:47:14,040 INFO     Training average positive_sample_loss at step 47900: 0.164484\n",
      "2023-12-13 08:47:14,040 INFO     Training average negative_sample_loss at step 47900: 0.108153\n",
      "2023-12-13 08:47:14,041 INFO     Training average loss at step 47900: 0.136318\n",
      "2023-12-13 08:49:30,314 INFO     Training average positive_sample_loss at step 48000: 0.165988\n",
      "2023-12-13 08:49:30,314 INFO     Training average negative_sample_loss at step 48000: 0.111356\n",
      "2023-12-13 08:49:30,314 INFO     Training average loss at step 48000: 0.138672\n",
      "2023-12-13 08:51:28,602 INFO     Training average positive_sample_loss at step 48100: 0.159837\n",
      "2023-12-13 08:51:28,603 INFO     Training average negative_sample_loss at step 48100: 0.108053\n",
      "2023-12-13 08:51:28,603 INFO     Training average loss at step 48100: 0.133945\n",
      "2023-12-13 08:53:31,215 INFO     Training average positive_sample_loss at step 48200: 0.164785\n",
      "2023-12-13 08:53:31,215 INFO     Training average negative_sample_loss at step 48200: 0.108564\n",
      "2023-12-13 08:53:31,215 INFO     Training average loss at step 48200: 0.136675\n",
      "2023-12-13 08:55:37,478 INFO     Training average positive_sample_loss at step 48300: 0.160372\n",
      "2023-12-13 08:55:37,478 INFO     Training average negative_sample_loss at step 48300: 0.109538\n",
      "2023-12-13 08:55:37,478 INFO     Training average loss at step 48300: 0.134955\n",
      "2023-12-13 08:57:34,792 INFO     Training average positive_sample_loss at step 48400: 0.163153\n",
      "2023-12-13 08:57:34,792 INFO     Training average negative_sample_loss at step 48400: 0.107777\n",
      "2023-12-13 08:57:34,792 INFO     Training average loss at step 48400: 0.135465\n",
      "2023-12-13 08:59:33,160 INFO     Training average positive_sample_loss at step 48500: 0.167098\n",
      "2023-12-13 08:59:33,160 INFO     Training average negative_sample_loss at step 48500: 0.110421\n",
      "2023-12-13 08:59:33,160 INFO     Training average loss at step 48500: 0.138760\n",
      "2023-12-13 09:01:47,489 INFO     Training average positive_sample_loss at step 48600: 0.158147\n",
      "2023-12-13 09:01:47,489 INFO     Training average negative_sample_loss at step 48600: 0.107957\n",
      "2023-12-13 09:01:47,489 INFO     Training average loss at step 48600: 0.133052\n",
      "2023-12-13 09:03:46,347 INFO     Training average positive_sample_loss at step 48700: 0.164841\n",
      "2023-12-13 09:03:46,347 INFO     Training average negative_sample_loss at step 48700: 0.108889\n",
      "2023-12-13 09:03:46,347 INFO     Training average loss at step 48700: 0.136865\n",
      "2023-12-13 09:06:01,315 INFO     Training average positive_sample_loss at step 48800: 0.162226\n",
      "2023-12-13 09:06:01,315 INFO     Training average negative_sample_loss at step 48800: 0.110172\n",
      "2023-12-13 09:06:01,315 INFO     Training average loss at step 48800: 0.136199\n",
      "2023-12-13 09:08:00,656 INFO     Training average positive_sample_loss at step 48900: 0.161434\n",
      "2023-12-13 09:08:00,657 INFO     Training average negative_sample_loss at step 48900: 0.107120\n",
      "2023-12-13 09:08:00,657 INFO     Training average loss at step 48900: 0.134277\n",
      "2023-12-13 09:10:09,191 INFO     Training average positive_sample_loss at step 49000: 0.166341\n",
      "2023-12-13 09:10:09,191 INFO     Training average negative_sample_loss at step 49000: 0.109969\n",
      "2023-12-13 09:10:09,191 INFO     Training average loss at step 49000: 0.138155\n",
      "2023-12-13 09:12:24,250 INFO     Training average positive_sample_loss at step 49100: 0.159045\n",
      "2023-12-13 09:12:24,251 INFO     Training average negative_sample_loss at step 49100: 0.108490\n",
      "2023-12-13 09:12:24,251 INFO     Training average loss at step 49100: 0.133768\n",
      "2023-12-13 09:14:24,590 INFO     Training average positive_sample_loss at step 49200: 0.164126\n",
      "2023-12-13 09:14:24,591 INFO     Training average negative_sample_loss at step 49200: 0.108115\n",
      "2023-12-13 09:14:24,591 INFO     Training average loss at step 49200: 0.136121\n",
      "2023-12-13 09:16:44,056 INFO     Training average positive_sample_loss at step 49300: 0.163662\n",
      "2023-12-13 09:16:44,057 INFO     Training average negative_sample_loss at step 49300: 0.110591\n",
      "2023-12-13 09:16:44,057 INFO     Training average loss at step 49300: 0.137126\n",
      "2023-12-13 09:18:48,812 INFO     Training average positive_sample_loss at step 49400: 0.160781\n",
      "2023-12-13 09:18:48,813 INFO     Training average negative_sample_loss at step 49400: 0.107256\n",
      "2023-12-13 09:18:48,813 INFO     Training average loss at step 49400: 0.134018\n",
      "2023-12-13 09:20:49,261 INFO     Training average positive_sample_loss at step 49500: 0.165153\n",
      "2023-12-13 09:20:49,262 INFO     Training average negative_sample_loss at step 49500: 0.109298\n",
      "2023-12-13 09:20:49,262 INFO     Training average loss at step 49500: 0.137226\n",
      "2023-12-13 09:23:10,060 INFO     Training average positive_sample_loss at step 49600: 0.160295\n",
      "2023-12-13 09:23:10,060 INFO     Training average negative_sample_loss at step 49600: 0.109241\n",
      "2023-12-13 09:23:10,060 INFO     Training average loss at step 49600: 0.134768\n",
      "2023-12-13 09:25:18,213 INFO     Training average positive_sample_loss at step 49700: 0.163449\n",
      "2023-12-13 09:25:18,213 INFO     Training average negative_sample_loss at step 49700: 0.107845\n",
      "2023-12-13 09:25:18,213 INFO     Training average loss at step 49700: 0.135647\n",
      "2023-12-13 09:27:24,544 INFO     Training average positive_sample_loss at step 49800: 0.165279\n",
      "2023-12-13 09:27:24,545 INFO     Training average negative_sample_loss at step 49800: 0.110351\n",
      "2023-12-13 09:27:24,545 INFO     Training average loss at step 49800: 0.137815\n",
      "2023-12-13 09:29:18,426 INFO     Training average positive_sample_loss at step 49900: 0.158715\n",
      "2023-12-13 09:29:18,426 INFO     Training average negative_sample_loss at step 49900: 0.107351\n",
      "2023-12-13 09:29:18,427 INFO     Training average loss at step 49900: 0.133033\n",
      "2023-12-13 09:31:29,889 INFO     Change learning_rate to 0.000005 at step 50000\n",
      "2023-12-13 09:31:35,688 INFO     Training average positive_sample_loss at step 50000: 0.165288\n",
      "2023-12-13 09:31:35,688 INFO     Training average negative_sample_loss at step 50000: 0.109060\n",
      "2023-12-13 09:31:35,688 INFO     Training average loss at step 50000: 0.137174\n",
      "2023-12-13 09:31:35,688 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-13 09:31:36,194 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-13 09:31:58,969 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-13 09:32:16,444 INFO     Valid MRR at step 50000: 0.419732\n",
      "2023-12-13 09:32:16,445 INFO     Valid MR at step 50000: 702.068320\n",
      "2023-12-13 09:32:16,445 INFO     Valid HITS@1 at step 50000: 0.392796\n",
      "2023-12-13 09:32:16,445 INFO     Valid HITS@3 at step 50000: 0.423631\n",
      "2023-12-13 09:32:16,445 INFO     Valid HITS@10 at step 50000: 0.468893\n",
      "2023-12-13 09:34:12,841 INFO     Training average positive_sample_loss at step 50100: 0.161124\n",
      "2023-12-13 09:34:12,841 INFO     Training average negative_sample_loss at step 50100: 0.107033\n",
      "2023-12-13 09:34:12,841 INFO     Training average loss at step 50100: 0.134078\n",
      "2023-12-13 09:36:15,100 INFO     Training average positive_sample_loss at step 50200: 0.153266\n",
      "2023-12-13 09:36:15,101 INFO     Training average negative_sample_loss at step 50200: 0.105331\n",
      "2023-12-13 09:36:15,101 INFO     Training average loss at step 50200: 0.129298\n",
      "2023-12-13 09:38:17,889 INFO     Training average positive_sample_loss at step 50300: 0.153844\n",
      "2023-12-13 09:38:17,890 INFO     Training average negative_sample_loss at step 50300: 0.104888\n",
      "2023-12-13 09:38:17,890 INFO     Training average loss at step 50300: 0.129366\n",
      "2023-12-13 09:40:30,369 INFO     Training average positive_sample_loss at step 50400: 0.151680\n",
      "2023-12-13 09:40:30,369 INFO     Training average negative_sample_loss at step 50400: 0.104181\n",
      "2023-12-13 09:40:30,369 INFO     Training average loss at step 50400: 0.127930\n",
      "2023-12-13 09:42:32,161 INFO     Training average positive_sample_loss at step 50500: 0.152878\n",
      "2023-12-13 09:42:32,161 INFO     Training average negative_sample_loss at step 50500: 0.104053\n",
      "2023-12-13 09:42:32,162 INFO     Training average loss at step 50500: 0.128466\n",
      "2023-12-13 09:44:46,651 INFO     Training average positive_sample_loss at step 50600: 0.152174\n",
      "2023-12-13 09:44:46,652 INFO     Training average negative_sample_loss at step 50600: 0.103932\n",
      "2023-12-13 09:44:46,652 INFO     Training average loss at step 50600: 0.128053\n",
      "2023-12-13 09:46:42,306 INFO     Training average positive_sample_loss at step 50700: 0.151392\n",
      "2023-12-13 09:46:42,306 INFO     Training average negative_sample_loss at step 50700: 0.103697\n",
      "2023-12-13 09:46:42,306 INFO     Training average loss at step 50700: 0.127545\n",
      "2023-12-13 09:48:45,646 INFO     Training average positive_sample_loss at step 50800: 0.153325\n",
      "2023-12-13 09:48:45,647 INFO     Training average negative_sample_loss at step 50800: 0.103330\n",
      "2023-12-13 09:48:45,647 INFO     Training average loss at step 50800: 0.128328\n",
      "2023-12-13 09:51:00,569 INFO     Training average positive_sample_loss at step 50900: 0.151703\n",
      "2023-12-13 09:51:00,570 INFO     Training average negative_sample_loss at step 50900: 0.103544\n",
      "2023-12-13 09:51:00,570 INFO     Training average loss at step 50900: 0.127624\n",
      "2023-12-13 09:52:50,923 INFO     Training average positive_sample_loss at step 51000: 0.151553\n",
      "2023-12-13 09:52:50,923 INFO     Training average negative_sample_loss at step 51000: 0.103347\n",
      "2023-12-13 09:52:50,923 INFO     Training average loss at step 51000: 0.127450\n",
      "2023-12-13 09:54:57,147 INFO     Training average positive_sample_loss at step 51100: 0.152313\n",
      "2023-12-13 09:54:57,148 INFO     Training average negative_sample_loss at step 51100: 0.103543\n",
      "2023-12-13 09:54:57,148 INFO     Training average loss at step 51100: 0.127928\n",
      "2023-12-13 09:56:48,232 INFO     Training average positive_sample_loss at step 51200: 0.150868\n",
      "2023-12-13 09:56:48,232 INFO     Training average negative_sample_loss at step 51200: 0.103022\n",
      "2023-12-13 09:56:48,232 INFO     Training average loss at step 51200: 0.126945\n",
      "2023-12-13 09:58:51,712 INFO     Training average positive_sample_loss at step 51300: 0.152144\n",
      "2023-12-13 09:58:51,712 INFO     Training average negative_sample_loss at step 51300: 0.102813\n",
      "2023-12-13 09:58:51,712 INFO     Training average loss at step 51300: 0.127478\n",
      "2023-12-13 10:01:11,581 INFO     Training average positive_sample_loss at step 51400: 0.150697\n",
      "2023-12-13 10:01:11,581 INFO     Training average negative_sample_loss at step 51400: 0.102855\n",
      "2023-12-13 10:01:11,582 INFO     Training average loss at step 51400: 0.126776\n",
      "2023-12-13 10:03:13,191 INFO     Training average positive_sample_loss at step 51500: 0.151845\n",
      "2023-12-13 10:03:13,192 INFO     Training average negative_sample_loss at step 51500: 0.102957\n",
      "2023-12-13 10:03:13,192 INFO     Training average loss at step 51500: 0.127401\n",
      "2023-12-13 10:05:25,583 INFO     Training average positive_sample_loss at step 51600: 0.152431\n",
      "2023-12-13 10:05:25,584 INFO     Training average negative_sample_loss at step 51600: 0.103043\n",
      "2023-12-13 10:05:25,584 INFO     Training average loss at step 51600: 0.127737\n",
      "2023-12-13 10:07:31,938 INFO     Training average positive_sample_loss at step 51700: 0.150625\n",
      "2023-12-13 10:07:31,939 INFO     Training average negative_sample_loss at step 51700: 0.103117\n",
      "2023-12-13 10:07:31,939 INFO     Training average loss at step 51700: 0.126871\n",
      "2023-12-13 10:09:43,593 INFO     Training average positive_sample_loss at step 51800: 0.151598\n",
      "2023-12-13 10:09:43,594 INFO     Training average negative_sample_loss at step 51800: 0.102194\n",
      "2023-12-13 10:09:43,594 INFO     Training average loss at step 51800: 0.126896\n",
      "2023-12-13 10:11:51,940 INFO     Training average positive_sample_loss at step 51900: 0.151660\n",
      "2023-12-13 10:11:51,940 INFO     Training average negative_sample_loss at step 51900: 0.102817\n",
      "2023-12-13 10:11:51,940 INFO     Training average loss at step 51900: 0.127239\n",
      "2023-12-13 10:13:50,882 INFO     Training average positive_sample_loss at step 52000: 0.151420\n",
      "2023-12-13 10:13:50,883 INFO     Training average negative_sample_loss at step 52000: 0.102296\n",
      "2023-12-13 10:13:50,883 INFO     Training average loss at step 52000: 0.126858\n",
      "2023-12-13 10:15:42,023 INFO     Training average positive_sample_loss at step 52100: 0.152062\n",
      "2023-12-13 10:15:42,023 INFO     Training average negative_sample_loss at step 52100: 0.102907\n",
      "2023-12-13 10:15:42,023 INFO     Training average loss at step 52100: 0.127484\n",
      "2023-12-13 10:18:04,464 INFO     Training average positive_sample_loss at step 52200: 0.150424\n",
      "2023-12-13 10:18:04,465 INFO     Training average negative_sample_loss at step 52200: 0.102410\n",
      "2023-12-13 10:18:04,465 INFO     Training average loss at step 52200: 0.126417\n",
      "2023-12-13 10:19:55,089 INFO     Training average positive_sample_loss at step 52300: 0.151927\n",
      "2023-12-13 10:19:55,089 INFO     Training average negative_sample_loss at step 52300: 0.102692\n",
      "2023-12-13 10:19:55,089 INFO     Training average loss at step 52300: 0.127309\n",
      "2023-12-13 10:22:07,431 INFO     Training average positive_sample_loss at step 52400: 0.151253\n",
      "2023-12-13 10:22:07,431 INFO     Training average negative_sample_loss at step 52400: 0.102310\n",
      "2023-12-13 10:22:07,432 INFO     Training average loss at step 52400: 0.126782\n",
      "2023-12-13 10:24:04,679 INFO     Training average positive_sample_loss at step 52500: 0.150719\n",
      "2023-12-13 10:24:04,679 INFO     Training average negative_sample_loss at step 52500: 0.102061\n",
      "2023-12-13 10:24:04,679 INFO     Training average loss at step 52500: 0.126390\n",
      "2023-12-13 10:26:19,141 INFO     Training average positive_sample_loss at step 52600: 0.152675\n",
      "2023-12-13 10:26:19,141 INFO     Training average negative_sample_loss at step 52600: 0.102535\n",
      "2023-12-13 10:26:19,141 INFO     Training average loss at step 52600: 0.127605\n",
      "2023-12-13 10:28:35,167 INFO     Training average positive_sample_loss at step 52700: 0.150870\n",
      "2023-12-13 10:28:35,168 INFO     Training average negative_sample_loss at step 52700: 0.102294\n",
      "2023-12-13 10:28:35,168 INFO     Training average loss at step 52700: 0.126582\n",
      "2023-12-13 10:30:24,945 INFO     Training average positive_sample_loss at step 52800: 0.151588\n",
      "2023-12-13 10:30:24,945 INFO     Training average negative_sample_loss at step 52800: 0.102454\n",
      "2023-12-13 10:30:24,945 INFO     Training average loss at step 52800: 0.127021\n",
      "2023-12-13 10:32:38,054 INFO     Training average positive_sample_loss at step 52900: 0.151869\n",
      "2023-12-13 10:32:38,054 INFO     Training average negative_sample_loss at step 52900: 0.102301\n",
      "2023-12-13 10:32:38,054 INFO     Training average loss at step 52900: 0.127085\n",
      "2023-12-13 10:34:42,524 INFO     Training average positive_sample_loss at step 53000: 0.150463\n",
      "2023-12-13 10:34:42,524 INFO     Training average negative_sample_loss at step 53000: 0.101867\n",
      "2023-12-13 10:34:42,524 INFO     Training average loss at step 53000: 0.126165\n",
      "2023-12-13 10:36:42,698 INFO     Training average positive_sample_loss at step 53100: 0.151445\n",
      "2023-12-13 10:36:42,698 INFO     Training average negative_sample_loss at step 53100: 0.102263\n",
      "2023-12-13 10:36:42,698 INFO     Training average loss at step 53100: 0.126854\n",
      "2023-12-13 10:38:51,045 INFO     Training average positive_sample_loss at step 53200: 0.151016\n",
      "2023-12-13 10:38:51,046 INFO     Training average negative_sample_loss at step 53200: 0.102011\n",
      "2023-12-13 10:38:51,046 INFO     Training average loss at step 53200: 0.126514\n",
      "2023-12-13 10:40:48,684 INFO     Training average positive_sample_loss at step 53300: 0.152064\n",
      "2023-12-13 10:40:48,684 INFO     Training average negative_sample_loss at step 53300: 0.102484\n",
      "2023-12-13 10:40:48,684 INFO     Training average loss at step 53300: 0.127274\n",
      "2023-12-13 10:42:46,685 INFO     Training average positive_sample_loss at step 53400: 0.152025\n",
      "2023-12-13 10:42:46,685 INFO     Training average negative_sample_loss at step 53400: 0.101883\n",
      "2023-12-13 10:42:46,685 INFO     Training average loss at step 53400: 0.126954\n",
      "2023-12-13 10:45:07,669 INFO     Training average positive_sample_loss at step 53500: 0.150687\n",
      "2023-12-13 10:45:07,670 INFO     Training average negative_sample_loss at step 53500: 0.102382\n",
      "2023-12-13 10:45:07,670 INFO     Training average loss at step 53500: 0.126535\n",
      "2023-12-13 10:47:16,740 INFO     Training average positive_sample_loss at step 53600: 0.151479\n",
      "2023-12-13 10:47:16,740 INFO     Training average negative_sample_loss at step 53600: 0.102190\n",
      "2023-12-13 10:47:16,740 INFO     Training average loss at step 53600: 0.126834\n",
      "2023-12-13 10:49:28,946 INFO     Training average positive_sample_loss at step 53700: 0.151044\n",
      "2023-12-13 10:49:28,946 INFO     Training average negative_sample_loss at step 53700: 0.101767\n",
      "2023-12-13 10:49:28,946 INFO     Training average loss at step 53700: 0.126405\n",
      "2023-12-13 10:51:28,762 INFO     Training average positive_sample_loss at step 53800: 0.150558\n",
      "2023-12-13 10:51:28,762 INFO     Training average negative_sample_loss at step 53800: 0.101961\n",
      "2023-12-13 10:51:28,762 INFO     Training average loss at step 53800: 0.126259\n",
      "2023-12-13 10:53:32,801 INFO     Training average positive_sample_loss at step 53900: 0.152899\n",
      "2023-12-13 10:53:32,801 INFO     Training average negative_sample_loss at step 53900: 0.102340\n",
      "2023-12-13 10:53:32,801 INFO     Training average loss at step 53900: 0.127619\n",
      "2023-12-13 10:55:39,745 INFO     Training average positive_sample_loss at step 54000: 0.150716\n",
      "2023-12-13 10:55:39,745 INFO     Training average negative_sample_loss at step 54000: 0.102064\n",
      "2023-12-13 10:55:39,745 INFO     Training average loss at step 54000: 0.126390\n",
      "2023-12-13 10:57:40,462 INFO     Training average positive_sample_loss at step 54100: 0.151552\n",
      "2023-12-13 10:57:40,462 INFO     Training average negative_sample_loss at step 54100: 0.102134\n",
      "2023-12-13 10:57:40,462 INFO     Training average loss at step 54100: 0.126843\n",
      "2023-12-13 11:00:00,345 INFO     Training average positive_sample_loss at step 54200: 0.151058\n",
      "2023-12-13 11:00:00,345 INFO     Training average negative_sample_loss at step 54200: 0.102133\n",
      "2023-12-13 11:00:00,345 INFO     Training average loss at step 54200: 0.126596\n",
      "2023-12-13 11:01:48,524 INFO     Training average positive_sample_loss at step 54300: 0.151307\n",
      "2023-12-13 11:01:48,525 INFO     Training average negative_sample_loss at step 54300: 0.102016\n",
      "2023-12-13 11:01:48,525 INFO     Training average loss at step 54300: 0.126661\n",
      "2023-12-13 11:03:38,647 INFO     Training average positive_sample_loss at step 54400: 0.151146\n",
      "2023-12-13 11:03:38,648 INFO     Training average negative_sample_loss at step 54400: 0.102087\n",
      "2023-12-13 11:03:38,648 INFO     Training average loss at step 54400: 0.126617\n",
      "2023-12-13 11:06:00,717 INFO     Training average positive_sample_loss at step 54500: 0.151581\n",
      "2023-12-13 11:06:00,718 INFO     Training average negative_sample_loss at step 54500: 0.102095\n",
      "2023-12-13 11:06:00,718 INFO     Training average loss at step 54500: 0.126838\n",
      "2023-12-13 11:07:57,938 INFO     Training average positive_sample_loss at step 54600: 0.151696\n",
      "2023-12-13 11:07:57,939 INFO     Training average negative_sample_loss at step 54600: 0.102155\n",
      "2023-12-13 11:07:57,939 INFO     Training average loss at step 54600: 0.126925\n",
      "2023-12-13 11:10:07,088 INFO     Training average positive_sample_loss at step 54700: 0.151427\n",
      "2023-12-13 11:10:07,088 INFO     Training average negative_sample_loss at step 54700: 0.101805\n",
      "2023-12-13 11:10:07,088 INFO     Training average loss at step 54700: 0.126616\n",
      "2023-12-13 11:12:06,331 INFO     Training average positive_sample_loss at step 54800: 0.150521\n",
      "2023-12-13 11:12:06,332 INFO     Training average negative_sample_loss at step 54800: 0.101827\n",
      "2023-12-13 11:12:06,332 INFO     Training average loss at step 54800: 0.126174\n",
      "2023-12-13 11:14:06,656 INFO     Training average positive_sample_loss at step 54900: 0.151672\n",
      "2023-12-13 11:14:06,656 INFO     Training average negative_sample_loss at step 54900: 0.101922\n",
      "2023-12-13 11:14:06,656 INFO     Training average loss at step 54900: 0.126797\n",
      "2023-12-13 11:16:23,074 INFO     Training average positive_sample_loss at step 55000: 0.150962\n",
      "2023-12-13 11:16:23,074 INFO     Training average negative_sample_loss at step 55000: 0.102082\n",
      "2023-12-13 11:16:23,074 INFO     Training average loss at step 55000: 0.126522\n",
      "2023-12-13 11:18:18,672 INFO     Training average positive_sample_loss at step 55100: 0.151105\n",
      "2023-12-13 11:18:18,672 INFO     Training average negative_sample_loss at step 55100: 0.101983\n",
      "2023-12-13 11:18:18,672 INFO     Training average loss at step 55100: 0.126544\n",
      "2023-12-13 11:20:25,548 INFO     Training average positive_sample_loss at step 55200: 0.152045\n",
      "2023-12-13 11:20:25,548 INFO     Training average negative_sample_loss at step 55200: 0.102232\n",
      "2023-12-13 11:20:25,548 INFO     Training average loss at step 55200: 0.127139\n",
      "2023-12-13 11:22:34,241 INFO     Training average positive_sample_loss at step 55300: 0.150199\n",
      "2023-12-13 11:22:34,242 INFO     Training average negative_sample_loss at step 55300: 0.101698\n",
      "2023-12-13 11:22:34,242 INFO     Training average loss at step 55300: 0.125949\n",
      "2023-12-13 11:24:43,985 INFO     Training average positive_sample_loss at step 55400: 0.151531\n",
      "2023-12-13 11:24:43,986 INFO     Training average negative_sample_loss at step 55400: 0.101717\n",
      "2023-12-13 11:24:43,986 INFO     Training average loss at step 55400: 0.126624\n",
      "2023-12-13 11:26:48,283 INFO     Training average positive_sample_loss at step 55500: 0.152005\n",
      "2023-12-13 11:26:48,283 INFO     Training average negative_sample_loss at step 55500: 0.102291\n",
      "2023-12-13 11:26:48,283 INFO     Training average loss at step 55500: 0.127148\n",
      "2023-12-13 11:28:52,397 INFO     Training average positive_sample_loss at step 55600: 0.150698\n",
      "2023-12-13 11:28:52,397 INFO     Training average negative_sample_loss at step 55600: 0.101695\n",
      "2023-12-13 11:28:52,397 INFO     Training average loss at step 55600: 0.126196\n",
      "2023-12-13 11:30:51,209 INFO     Training average positive_sample_loss at step 55700: 0.151323\n",
      "2023-12-13 11:30:51,209 INFO     Training average negative_sample_loss at step 55700: 0.101674\n",
      "2023-12-13 11:30:51,209 INFO     Training average loss at step 55700: 0.126499\n",
      "2023-12-13 11:33:12,409 INFO     Training average positive_sample_loss at step 55800: 0.150330\n",
      "2023-12-13 11:33:12,410 INFO     Training average negative_sample_loss at step 55800: 0.102075\n",
      "2023-12-13 11:33:12,410 INFO     Training average loss at step 55800: 0.126202\n",
      "2023-12-13 11:35:08,223 INFO     Training average positive_sample_loss at step 55900: 0.151361\n",
      "2023-12-13 11:35:08,224 INFO     Training average negative_sample_loss at step 55900: 0.101769\n",
      "2023-12-13 11:35:08,224 INFO     Training average loss at step 55900: 0.126565\n",
      "2023-12-13 11:37:13,892 INFO     Training average positive_sample_loss at step 56000: 0.152502\n",
      "2023-12-13 11:37:13,893 INFO     Training average negative_sample_loss at step 56000: 0.102005\n",
      "2023-12-13 11:37:13,893 INFO     Training average loss at step 56000: 0.127254\n",
      "2023-12-13 11:39:12,331 INFO     Training average positive_sample_loss at step 56100: 0.150545\n",
      "2023-12-13 11:39:12,332 INFO     Training average negative_sample_loss at step 56100: 0.102156\n",
      "2023-12-13 11:39:12,332 INFO     Training average loss at step 56100: 0.126351\n",
      "2023-12-13 11:41:17,784 INFO     Training average positive_sample_loss at step 56200: 0.151796\n",
      "2023-12-13 11:41:17,784 INFO     Training average negative_sample_loss at step 56200: 0.101863\n",
      "2023-12-13 11:41:17,784 INFO     Training average loss at step 56200: 0.126830\n",
      "2023-12-13 11:43:27,976 INFO     Training average positive_sample_loss at step 56300: 0.150297\n",
      "2023-12-13 11:43:27,976 INFO     Training average negative_sample_loss at step 56300: 0.101491\n",
      "2023-12-13 11:43:27,976 INFO     Training average loss at step 56300: 0.125894\n",
      "2023-12-13 11:45:23,886 INFO     Training average positive_sample_loss at step 56400: 0.151312\n",
      "2023-12-13 11:45:23,886 INFO     Training average negative_sample_loss at step 56400: 0.102251\n",
      "2023-12-13 11:45:23,886 INFO     Training average loss at step 56400: 0.126781\n",
      "2023-12-13 11:47:22,931 INFO     Training average positive_sample_loss at step 56500: 0.152029\n",
      "2023-12-13 11:47:22,931 INFO     Training average negative_sample_loss at step 56500: 0.101887\n",
      "2023-12-13 11:47:22,931 INFO     Training average loss at step 56500: 0.126958\n",
      "2023-12-13 11:49:35,035 INFO     Training average positive_sample_loss at step 56600: 0.149953\n",
      "2023-12-13 11:49:35,036 INFO     Training average negative_sample_loss at step 56600: 0.101887\n",
      "2023-12-13 11:49:35,036 INFO     Training average loss at step 56600: 0.125920\n",
      "2023-12-13 11:51:32,439 INFO     Training average positive_sample_loss at step 56700: 0.152018\n",
      "2023-12-13 11:51:32,439 INFO     Training average negative_sample_loss at step 56700: 0.101679\n",
      "2023-12-13 11:51:32,439 INFO     Training average loss at step 56700: 0.126849\n",
      "2023-12-13 11:53:40,211 INFO     Training average positive_sample_loss at step 56800: 0.151193\n",
      "2023-12-13 11:53:40,211 INFO     Training average negative_sample_loss at step 56800: 0.102256\n",
      "2023-12-13 11:53:40,211 INFO     Training average loss at step 56800: 0.126724\n",
      "2023-12-13 11:55:38,374 INFO     Training average positive_sample_loss at step 56900: 0.150845\n",
      "2023-12-13 11:55:38,375 INFO     Training average negative_sample_loss at step 56900: 0.101639\n",
      "2023-12-13 11:55:38,375 INFO     Training average loss at step 56900: 0.126242\n",
      "2023-12-13 11:57:33,931 INFO     Training average positive_sample_loss at step 57000: 0.151729\n",
      "2023-12-13 11:57:33,932 INFO     Training average negative_sample_loss at step 57000: 0.101923\n",
      "2023-12-13 11:57:33,932 INFO     Training average loss at step 57000: 0.126826\n",
      "2023-12-13 11:59:43,678 INFO     Training average positive_sample_loss at step 57100: 0.150707\n",
      "2023-12-13 11:59:43,679 INFO     Training average negative_sample_loss at step 57100: 0.101780\n",
      "2023-12-13 11:59:43,679 INFO     Training average loss at step 57100: 0.126243\n",
      "2023-12-13 12:01:51,394 INFO     Training average positive_sample_loss at step 57200: 0.151011\n",
      "2023-12-13 12:01:51,394 INFO     Training average negative_sample_loss at step 57200: 0.102106\n",
      "2023-12-13 12:01:51,394 INFO     Training average loss at step 57200: 0.126559\n",
      "2023-12-13 12:04:03,493 INFO     Training average positive_sample_loss at step 57300: 0.151847\n",
      "2023-12-13 12:04:03,493 INFO     Training average negative_sample_loss at step 57300: 0.102104\n",
      "2023-12-13 12:04:03,493 INFO     Training average loss at step 57300: 0.126976\n",
      "2023-12-13 12:05:53,534 INFO     Training average positive_sample_loss at step 57400: 0.150791\n",
      "2023-12-13 12:05:53,534 INFO     Training average negative_sample_loss at step 57400: 0.101792\n",
      "2023-12-13 12:05:53,535 INFO     Training average loss at step 57400: 0.126292\n",
      "2023-12-13 12:07:56,366 INFO     Training average positive_sample_loss at step 57500: 0.151396\n",
      "2023-12-13 12:07:56,366 INFO     Training average negative_sample_loss at step 57500: 0.101916\n",
      "2023-12-13 12:07:56,366 INFO     Training average loss at step 57500: 0.126656\n",
      "2023-12-13 12:10:04,041 INFO     Training average positive_sample_loss at step 57600: 0.150985\n",
      "2023-12-13 12:10:04,041 INFO     Training average negative_sample_loss at step 57600: 0.101577\n",
      "2023-12-13 12:10:04,041 INFO     Training average loss at step 57600: 0.126281\n",
      "2023-12-13 12:12:01,779 INFO     Training average positive_sample_loss at step 57700: 0.151331\n",
      "2023-12-13 12:12:01,779 INFO     Training average negative_sample_loss at step 57700: 0.102083\n",
      "2023-12-13 12:12:01,779 INFO     Training average loss at step 57700: 0.126707\n",
      "2023-12-13 12:14:08,374 INFO     Training average positive_sample_loss at step 57800: 0.151611\n",
      "2023-12-13 12:14:08,374 INFO     Training average negative_sample_loss at step 57800: 0.101741\n",
      "2023-12-13 12:14:08,374 INFO     Training average loss at step 57800: 0.126676\n",
      "2023-12-13 12:16:22,201 INFO     Training average positive_sample_loss at step 57900: 0.150017\n",
      "2023-12-13 12:16:22,202 INFO     Training average negative_sample_loss at step 57900: 0.101643\n",
      "2023-12-13 12:16:22,202 INFO     Training average loss at step 57900: 0.125830\n",
      "2023-12-13 12:18:18,862 INFO     Training average positive_sample_loss at step 58000: 0.151781\n",
      "2023-12-13 12:18:18,863 INFO     Training average negative_sample_loss at step 58000: 0.101854\n",
      "2023-12-13 12:18:18,863 INFO     Training average loss at step 58000: 0.126818\n",
      "2023-12-13 12:20:27,385 INFO     Training average positive_sample_loss at step 58100: 0.150798\n",
      "2023-12-13 12:20:27,385 INFO     Training average negative_sample_loss at step 58100: 0.101362\n",
      "2023-12-13 12:20:27,385 INFO     Training average loss at step 58100: 0.126080\n",
      "2023-12-13 12:22:33,434 INFO     Training average positive_sample_loss at step 58200: 0.151042\n",
      "2023-12-13 12:22:33,435 INFO     Training average negative_sample_loss at step 58200: 0.101959\n",
      "2023-12-13 12:22:33,435 INFO     Training average loss at step 58200: 0.126501\n",
      "2023-12-13 12:24:40,153 INFO     Training average positive_sample_loss at step 58300: 0.152267\n",
      "2023-12-13 12:24:40,153 INFO     Training average negative_sample_loss at step 58300: 0.102182\n",
      "2023-12-13 12:24:40,153 INFO     Training average loss at step 58300: 0.127225\n",
      "2023-12-13 12:26:50,779 INFO     Training average positive_sample_loss at step 58400: 0.150545\n",
      "2023-12-13 12:26:50,780 INFO     Training average negative_sample_loss at step 58400: 0.102024\n",
      "2023-12-13 12:26:50,780 INFO     Training average loss at step 58400: 0.126285\n",
      "2023-12-13 12:28:48,308 INFO     Training average positive_sample_loss at step 58500: 0.150927\n",
      "2023-12-13 12:28:48,309 INFO     Training average negative_sample_loss at step 58500: 0.101321\n",
      "2023-12-13 12:28:48,309 INFO     Training average loss at step 58500: 0.126124\n",
      "2023-12-13 12:31:11,416 INFO     Training average positive_sample_loss at step 58600: 0.151365\n",
      "2023-12-13 12:31:11,416 INFO     Training average negative_sample_loss at step 58600: 0.101814\n",
      "2023-12-13 12:31:11,416 INFO     Training average loss at step 58600: 0.126590\n",
      "2023-12-13 12:33:07,704 INFO     Training average positive_sample_loss at step 58700: 0.151057\n",
      "2023-12-13 12:33:07,704 INFO     Training average negative_sample_loss at step 58700: 0.101630\n",
      "2023-12-13 12:33:07,704 INFO     Training average loss at step 58700: 0.126344\n",
      "2023-12-13 12:34:57,934 INFO     Training average positive_sample_loss at step 58800: 0.151586\n",
      "2023-12-13 12:34:57,934 INFO     Training average negative_sample_loss at step 58800: 0.101981\n",
      "2023-12-13 12:34:57,934 INFO     Training average loss at step 58800: 0.126783\n",
      "2023-12-13 12:37:14,424 INFO     Training average positive_sample_loss at step 58900: 0.150521\n",
      "2023-12-13 12:37:14,425 INFO     Training average negative_sample_loss at step 58900: 0.101973\n",
      "2023-12-13 12:37:14,425 INFO     Training average loss at step 58900: 0.126247\n",
      "2023-12-13 12:38:58,777 INFO     Training average positive_sample_loss at step 59000: 0.151267\n",
      "2023-12-13 12:38:58,778 INFO     Training average negative_sample_loss at step 59000: 0.101557\n",
      "2023-12-13 12:38:58,778 INFO     Training average loss at step 59000: 0.126412\n",
      "2023-12-13 12:41:15,960 INFO     Training average positive_sample_loss at step 59100: 0.151288\n",
      "2023-12-13 12:41:15,961 INFO     Training average negative_sample_loss at step 59100: 0.102046\n",
      "2023-12-13 12:41:15,961 INFO     Training average loss at step 59100: 0.126667\n",
      "2023-12-13 12:43:14,282 INFO     Training average positive_sample_loss at step 59200: 0.150749\n",
      "2023-12-13 12:43:14,282 INFO     Training average negative_sample_loss at step 59200: 0.101912\n",
      "2023-12-13 12:43:14,282 INFO     Training average loss at step 59200: 0.126331\n",
      "2023-12-13 12:45:13,478 INFO     Training average positive_sample_loss at step 59300: 0.151757\n",
      "2023-12-13 12:45:13,479 INFO     Training average negative_sample_loss at step 59300: 0.101434\n",
      "2023-12-13 12:45:13,479 INFO     Training average loss at step 59300: 0.126596\n",
      "2023-12-13 12:47:22,578 INFO     Training average positive_sample_loss at step 59400: 0.150274\n",
      "2023-12-13 12:47:22,578 INFO     Training average negative_sample_loss at step 59400: 0.101588\n",
      "2023-12-13 12:47:22,579 INFO     Training average loss at step 59400: 0.125931\n",
      "2023-12-13 12:49:25,043 INFO     Training average positive_sample_loss at step 59500: 0.151687\n",
      "2023-12-13 12:49:25,043 INFO     Training average negative_sample_loss at step 59500: 0.101967\n",
      "2023-12-13 12:49:25,043 INFO     Training average loss at step 59500: 0.126827\n",
      "2023-12-13 12:51:48,333 INFO     Training average positive_sample_loss at step 59600: 0.151441\n",
      "2023-12-13 12:51:48,333 INFO     Training average negative_sample_loss at step 59600: 0.101699\n",
      "2023-12-13 12:51:48,333 INFO     Training average loss at step 59600: 0.126570\n",
      "2023-12-13 12:53:37,798 INFO     Training average positive_sample_loss at step 59700: 0.149596\n",
      "2023-12-13 12:53:37,799 INFO     Training average negative_sample_loss at step 59700: 0.101627\n",
      "2023-12-13 12:53:37,799 INFO     Training average loss at step 59700: 0.125611\n",
      "2023-12-13 12:55:34,538 INFO     Training average positive_sample_loss at step 59800: 0.151874\n",
      "2023-12-13 12:55:34,538 INFO     Training average negative_sample_loss at step 59800: 0.101856\n",
      "2023-12-13 12:55:34,538 INFO     Training average loss at step 59800: 0.126865\n",
      "2023-12-13 12:57:49,282 INFO     Training average positive_sample_loss at step 59900: 0.151983\n",
      "2023-12-13 12:57:49,283 INFO     Training average negative_sample_loss at step 59900: 0.102152\n",
      "2023-12-13 12:57:49,283 INFO     Training average loss at step 59900: 0.127068\n",
      "2023-12-13 12:59:54,927 INFO     Training average positive_sample_loss at step 60000: 0.150026\n",
      "2023-12-13 12:59:54,927 INFO     Training average negative_sample_loss at step 60000: 0.101618\n",
      "2023-12-13 12:59:54,927 INFO     Training average loss at step 60000: 0.125822\n",
      "2023-12-13 12:59:54,928 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-13 12:59:55,395 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-13 13:00:19,861 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-13 13:00:35,557 INFO     Valid MRR at step 60000: 0.420275\n",
      "2023-12-13 13:00:35,558 INFO     Valid MR at step 60000: 691.667917\n",
      "2023-12-13 13:00:35,558 INFO     Valid HITS@1 at step 60000: 0.393410\n",
      "2023-12-13 13:00:35,558 INFO     Valid HITS@3 at step 60000: 0.423255\n",
      "2023-12-13 13:00:35,558 INFO     Valid HITS@10 at step 60000: 0.469677\n",
      "2023-12-13 13:02:14,806 INFO     Training average positive_sample_loss at step 60100: 0.151905\n",
      "2023-12-13 13:02:14,806 INFO     Training average negative_sample_loss at step 60100: 0.101685\n",
      "2023-12-13 13:02:14,806 INFO     Training average loss at step 60100: 0.126795\n",
      "2023-12-13 13:04:30,695 INFO     Training average positive_sample_loss at step 60200: 0.150565\n",
      "2023-12-13 13:04:30,695 INFO     Training average negative_sample_loss at step 60200: 0.102064\n",
      "2023-12-13 13:04:30,696 INFO     Training average loss at step 60200: 0.126314\n",
      "2023-12-13 13:06:44,935 INFO     Training average positive_sample_loss at step 60300: 0.150913\n",
      "2023-12-13 13:06:44,936 INFO     Training average negative_sample_loss at step 60300: 0.101356\n",
      "2023-12-13 13:06:44,936 INFO     Training average loss at step 60300: 0.126134\n",
      "2023-12-13 13:08:53,858 INFO     Training average positive_sample_loss at step 60400: 0.151478\n",
      "2023-12-13 13:08:53,859 INFO     Training average negative_sample_loss at step 60400: 0.101930\n",
      "2023-12-13 13:08:53,859 INFO     Training average loss at step 60400: 0.126704\n",
      "2023-12-13 13:10:48,107 INFO     Training average positive_sample_loss at step 60500: 0.150468\n",
      "2023-12-13 13:10:48,107 INFO     Training average negative_sample_loss at step 60500: 0.101728\n",
      "2023-12-13 13:10:48,107 INFO     Training average loss at step 60500: 0.126098\n",
      "2023-12-13 13:12:49,832 INFO     Training average positive_sample_loss at step 60600: 0.151813\n",
      "2023-12-13 13:12:49,833 INFO     Training average negative_sample_loss at step 60600: 0.101656\n",
      "2023-12-13 13:12:49,833 INFO     Training average loss at step 60600: 0.126735\n",
      "2023-12-13 13:14:58,407 INFO     Training average positive_sample_loss at step 60700: 0.151097\n",
      "2023-12-13 13:14:58,408 INFO     Training average negative_sample_loss at step 60700: 0.102161\n",
      "2023-12-13 13:14:58,408 INFO     Training average loss at step 60700: 0.126629\n",
      "2023-12-13 13:17:16,340 INFO     Training average positive_sample_loss at step 60800: 0.150333\n",
      "2023-12-13 13:17:16,340 INFO     Training average negative_sample_loss at step 60800: 0.101804\n",
      "2023-12-13 13:17:16,340 INFO     Training average loss at step 60800: 0.126068\n",
      "2023-12-13 13:19:41,216 INFO     Training average positive_sample_loss at step 60900: 0.152387\n",
      "2023-12-13 13:19:41,217 INFO     Training average negative_sample_loss at step 60900: 0.101705\n",
      "2023-12-13 13:19:41,217 INFO     Training average loss at step 60900: 0.127046\n",
      "2023-12-13 13:21:23,283 INFO     Training average positive_sample_loss at step 61000: 0.150085\n",
      "2023-12-13 13:21:23,284 INFO     Training average negative_sample_loss at step 61000: 0.101505\n",
      "2023-12-13 13:21:23,284 INFO     Training average loss at step 61000: 0.125795\n",
      "2023-12-13 13:23:22,970 INFO     Training average positive_sample_loss at step 61100: 0.151333\n",
      "2023-12-13 13:23:22,970 INFO     Training average negative_sample_loss at step 61100: 0.101643\n",
      "2023-12-13 13:23:22,970 INFO     Training average loss at step 61100: 0.126488\n",
      "2023-12-13 13:25:34,984 INFO     Training average positive_sample_loss at step 61200: 0.150507\n",
      "2023-12-13 13:25:34,985 INFO     Training average negative_sample_loss at step 61200: 0.101711\n",
      "2023-12-13 13:25:34,985 INFO     Training average loss at step 61200: 0.126109\n",
      "2023-12-13 13:27:38,736 INFO     Training average positive_sample_loss at step 61300: 0.151294\n",
      "2023-12-13 13:27:38,736 INFO     Training average negative_sample_loss at step 61300: 0.101644\n",
      "2023-12-13 13:27:38,736 INFO     Training average loss at step 61300: 0.126469\n",
      "2023-12-13 13:29:36,368 INFO     Training average positive_sample_loss at step 61400: 0.151866\n",
      "2023-12-13 13:29:36,368 INFO     Training average negative_sample_loss at step 61400: 0.101668\n",
      "2023-12-13 13:29:36,368 INFO     Training average loss at step 61400: 0.126767\n",
      "2023-12-13 13:31:48,085 INFO     Training average positive_sample_loss at step 61500: 0.149733\n",
      "2023-12-13 13:31:48,086 INFO     Training average negative_sample_loss at step 61500: 0.101304\n",
      "2023-12-13 13:31:48,086 INFO     Training average loss at step 61500: 0.125518\n",
      "2023-12-13 13:33:50,029 INFO     Training average positive_sample_loss at step 61600: 0.151679\n",
      "2023-12-13 13:33:50,029 INFO     Training average negative_sample_loss at step 61600: 0.101846\n",
      "2023-12-13 13:33:50,030 INFO     Training average loss at step 61600: 0.126763\n",
      "2023-12-13 13:36:03,415 INFO     Training average positive_sample_loss at step 61700: 0.151825\n",
      "2023-12-13 13:36:03,415 INFO     Training average negative_sample_loss at step 61700: 0.101965\n",
      "2023-12-13 13:36:03,416 INFO     Training average loss at step 61700: 0.126895\n",
      "2023-12-13 13:38:00,867 INFO     Training average positive_sample_loss at step 61800: 0.150454\n",
      "2023-12-13 13:38:00,867 INFO     Training average negative_sample_loss at step 61800: 0.101986\n",
      "2023-12-13 13:38:00,867 INFO     Training average loss at step 61800: 0.126220\n",
      "2023-12-13 13:40:01,209 INFO     Training average positive_sample_loss at step 61900: 0.151349\n",
      "2023-12-13 13:40:01,209 INFO     Training average negative_sample_loss at step 61900: 0.101461\n",
      "2023-12-13 13:40:01,209 INFO     Training average loss at step 61900: 0.126405\n",
      "2023-12-13 13:42:14,048 INFO     Training average positive_sample_loss at step 62000: 0.150582\n",
      "2023-12-13 13:42:14,049 INFO     Training average negative_sample_loss at step 62000: 0.101666\n",
      "2023-12-13 13:42:14,049 INFO     Training average loss at step 62000: 0.126124\n",
      "2023-12-13 13:44:16,927 INFO     Training average positive_sample_loss at step 62100: 0.150908\n",
      "2023-12-13 13:44:16,927 INFO     Training average negative_sample_loss at step 62100: 0.101581\n",
      "2023-12-13 13:44:16,927 INFO     Training average loss at step 62100: 0.126245\n",
      "2023-12-13 13:46:31,345 INFO     Training average positive_sample_loss at step 62200: 0.151606\n",
      "2023-12-13 13:46:31,345 INFO     Training average negative_sample_loss at step 62200: 0.102080\n",
      "2023-12-13 13:46:31,345 INFO     Training average loss at step 62200: 0.126843\n",
      "2023-12-13 13:48:28,576 INFO     Training average positive_sample_loss at step 62300: 0.150935\n",
      "2023-12-13 13:48:28,577 INFO     Training average negative_sample_loss at step 62300: 0.101692\n",
      "2023-12-13 13:48:28,577 INFO     Training average loss at step 62300: 0.126314\n",
      "2023-12-13 13:50:26,371 INFO     Training average positive_sample_loss at step 62400: 0.151094\n",
      "2023-12-13 13:50:26,372 INFO     Training average negative_sample_loss at step 62400: 0.101749\n",
      "2023-12-13 13:50:26,372 INFO     Training average loss at step 62400: 0.126421\n",
      "2023-12-13 13:52:35,098 INFO     Training average positive_sample_loss at step 62500: 0.150341\n",
      "2023-12-13 13:52:35,098 INFO     Training average negative_sample_loss at step 62500: 0.101620\n",
      "2023-12-13 13:52:35,098 INFO     Training average loss at step 62500: 0.125981\n",
      "2023-12-13 13:54:41,904 INFO     Training average positive_sample_loss at step 62600: 0.151277\n",
      "2023-12-13 13:54:41,904 INFO     Training average negative_sample_loss at step 62600: 0.101484\n",
      "2023-12-13 13:54:41,904 INFO     Training average loss at step 62600: 0.126381\n",
      "2023-12-13 13:57:06,488 INFO     Training average positive_sample_loss at step 62700: 0.151648\n",
      "2023-12-13 13:57:06,488 INFO     Training average negative_sample_loss at step 62700: 0.101622\n",
      "2023-12-13 13:57:06,488 INFO     Training average loss at step 62700: 0.126635\n",
      "2023-12-13 13:59:01,208 INFO     Training average positive_sample_loss at step 62800: 0.149874\n",
      "2023-12-13 13:59:01,209 INFO     Training average negative_sample_loss at step 62800: 0.101413\n",
      "2023-12-13 13:59:01,209 INFO     Training average loss at step 62800: 0.125643\n",
      "2023-12-13 14:00:51,075 INFO     Training average positive_sample_loss at step 62900: 0.151307\n",
      "2023-12-13 14:00:51,076 INFO     Training average negative_sample_loss at step 62900: 0.101837\n",
      "2023-12-13 14:00:51,076 INFO     Training average loss at step 62900: 0.126572\n",
      "2023-12-13 14:02:59,418 INFO     Training average positive_sample_loss at step 63000: 0.151527\n",
      "2023-12-13 14:02:59,418 INFO     Training average negative_sample_loss at step 63000: 0.101976\n",
      "2023-12-13 14:02:59,418 INFO     Training average loss at step 63000: 0.126751\n",
      "2023-12-13 14:04:53,242 INFO     Training average positive_sample_loss at step 63100: 0.150344\n",
      "2023-12-13 14:04:53,243 INFO     Training average negative_sample_loss at step 63100: 0.101266\n",
      "2023-12-13 14:04:53,243 INFO     Training average loss at step 63100: 0.125805\n",
      "2023-12-13 14:06:59,935 INFO     Training average positive_sample_loss at step 63200: 0.151847\n",
      "2023-12-13 14:06:59,936 INFO     Training average negative_sample_loss at step 63200: 0.101795\n",
      "2023-12-13 14:06:59,936 INFO     Training average loss at step 63200: 0.126821\n",
      "2023-12-13 14:09:08,024 INFO     Training average positive_sample_loss at step 63300: 0.150393\n",
      "2023-12-13 14:09:08,025 INFO     Training average negative_sample_loss at step 63300: 0.101648\n",
      "2023-12-13 14:09:08,025 INFO     Training average loss at step 63300: 0.126021\n",
      "2023-12-13 14:10:56,355 INFO     Training average positive_sample_loss at step 63400: 0.151689\n",
      "2023-12-13 14:10:56,355 INFO     Training average negative_sample_loss at step 63400: 0.101790\n",
      "2023-12-13 14:10:56,355 INFO     Training average loss at step 63400: 0.126740\n",
      "2023-12-13 14:13:15,779 INFO     Training average positive_sample_loss at step 63500: 0.150566\n",
      "2023-12-13 14:13:15,779 INFO     Training average negative_sample_loss at step 63500: 0.102040\n",
      "2023-12-13 14:13:15,780 INFO     Training average loss at step 63500: 0.126303\n",
      "2023-12-13 14:15:13,691 INFO     Training average positive_sample_loss at step 63600: 0.150523\n",
      "2023-12-13 14:15:13,691 INFO     Training average negative_sample_loss at step 63600: 0.101386\n",
      "2023-12-13 14:15:13,691 INFO     Training average loss at step 63600: 0.125954\n",
      "2023-12-13 14:17:06,540 INFO     Training average positive_sample_loss at step 63700: 0.151875\n",
      "2023-12-13 14:17:06,540 INFO     Training average negative_sample_loss at step 63700: 0.102081\n",
      "2023-12-13 14:17:06,540 INFO     Training average loss at step 63700: 0.126978\n",
      "2023-12-13 14:19:20,299 INFO     Training average positive_sample_loss at step 63800: 0.150255\n",
      "2023-12-13 14:19:20,300 INFO     Training average negative_sample_loss at step 63800: 0.101448\n",
      "2023-12-13 14:19:20,300 INFO     Training average loss at step 63800: 0.125852\n",
      "2023-12-13 14:21:24,104 INFO     Training average positive_sample_loss at step 63900: 0.151266\n",
      "2023-12-13 14:21:24,104 INFO     Training average negative_sample_loss at step 63900: 0.101723\n",
      "2023-12-13 14:21:24,104 INFO     Training average loss at step 63900: 0.126495\n",
      "2023-12-13 14:23:26,559 INFO     Training average positive_sample_loss at step 64000: 0.151410\n",
      "2023-12-13 14:23:26,560 INFO     Training average negative_sample_loss at step 64000: 0.101458\n",
      "2023-12-13 14:23:26,560 INFO     Training average loss at step 64000: 0.126434\n",
      "2023-12-13 14:25:21,574 INFO     Training average positive_sample_loss at step 64100: 0.150289\n",
      "2023-12-13 14:25:21,575 INFO     Training average negative_sample_loss at step 64100: 0.101717\n",
      "2023-12-13 14:25:21,575 INFO     Training average loss at step 64100: 0.126003\n",
      "2023-12-13 14:27:32,173 INFO     Training average positive_sample_loss at step 64200: 0.151560\n",
      "2023-12-13 14:27:32,174 INFO     Training average negative_sample_loss at step 64200: 0.101666\n",
      "2023-12-13 14:27:32,174 INFO     Training average loss at step 64200: 0.126613\n",
      "2023-12-13 14:29:51,422 INFO     Training average positive_sample_loss at step 64300: 0.150223\n",
      "2023-12-13 14:29:51,422 INFO     Training average negative_sample_loss at step 64300: 0.101429\n",
      "2023-12-13 14:29:51,422 INFO     Training average loss at step 64300: 0.125826\n",
      "2023-12-13 14:31:58,929 INFO     Training average positive_sample_loss at step 64400: 0.151449\n",
      "2023-12-13 14:31:58,929 INFO     Training average negative_sample_loss at step 64400: 0.101687\n",
      "2023-12-13 14:31:58,930 INFO     Training average loss at step 64400: 0.126568\n",
      "2023-12-13 14:34:10,094 INFO     Training average positive_sample_loss at step 64500: 0.151564\n",
      "2023-12-13 14:34:10,095 INFO     Training average negative_sample_loss at step 64500: 0.101769\n",
      "2023-12-13 14:34:10,095 INFO     Training average loss at step 64500: 0.126667\n",
      "2023-12-13 14:36:11,905 INFO     Training average positive_sample_loss at step 64600: 0.149974\n",
      "2023-12-13 14:36:11,905 INFO     Training average negative_sample_loss at step 64600: 0.101523\n",
      "2023-12-13 14:36:11,905 INFO     Training average loss at step 64600: 0.125748\n",
      "2023-12-13 14:38:16,503 INFO     Training average positive_sample_loss at step 64700: 0.151512\n",
      "2023-12-13 14:38:16,504 INFO     Training average negative_sample_loss at step 64700: 0.101790\n",
      "2023-12-13 14:38:16,504 INFO     Training average loss at step 64700: 0.126651\n",
      "2023-12-13 14:40:40,574 INFO     Training average positive_sample_loss at step 64800: 0.150747\n",
      "2023-12-13 14:40:40,574 INFO     Training average negative_sample_loss at step 64800: 0.101852\n",
      "2023-12-13 14:40:40,574 INFO     Training average loss at step 64800: 0.126300\n",
      "2023-12-13 14:42:40,973 INFO     Training average positive_sample_loss at step 64900: 0.150754\n",
      "2023-12-13 14:42:40,974 INFO     Training average negative_sample_loss at step 64900: 0.101463\n",
      "2023-12-13 14:42:40,974 INFO     Training average loss at step 64900: 0.126108\n",
      "2023-12-13 14:44:50,909 INFO     Training average positive_sample_loss at step 65000: 0.151907\n",
      "2023-12-13 14:44:50,910 INFO     Training average negative_sample_loss at step 65000: 0.101617\n",
      "2023-12-13 14:44:50,910 INFO     Training average loss at step 65000: 0.126762\n",
      "2023-12-13 14:46:53,069 INFO     Training average positive_sample_loss at step 65100: 0.150012\n",
      "2023-12-13 14:46:53,070 INFO     Training average negative_sample_loss at step 65100: 0.101440\n",
      "2023-12-13 14:46:53,070 INFO     Training average loss at step 65100: 0.125726\n",
      "2023-12-13 14:49:15,489 INFO     Training average positive_sample_loss at step 65200: 0.151048\n",
      "2023-12-13 14:49:15,489 INFO     Training average negative_sample_loss at step 65200: 0.101598\n",
      "2023-12-13 14:49:15,489 INFO     Training average loss at step 65200: 0.126323\n",
      "2023-12-13 14:51:33,838 INFO     Training average positive_sample_loss at step 65300: 0.151473\n",
      "2023-12-13 14:51:33,839 INFO     Training average negative_sample_loss at step 65300: 0.101890\n",
      "2023-12-13 14:51:33,839 INFO     Training average loss at step 65300: 0.126682\n",
      "2023-12-13 14:53:35,120 INFO     Training average positive_sample_loss at step 65400: 0.150605\n",
      "2023-12-13 14:53:35,121 INFO     Training average negative_sample_loss at step 65400: 0.101905\n",
      "2023-12-13 14:53:35,121 INFO     Training average loss at step 65400: 0.126255\n",
      "2023-12-13 14:55:32,627 INFO     Training average positive_sample_loss at step 65500: 0.151873\n",
      "2023-12-13 14:55:32,628 INFO     Training average negative_sample_loss at step 65500: 0.101891\n",
      "2023-12-13 14:55:32,628 INFO     Training average loss at step 65500: 0.126882\n",
      "2023-12-13 14:57:39,477 INFO     Training average positive_sample_loss at step 65600: 0.150080\n",
      "2023-12-13 14:57:39,477 INFO     Training average negative_sample_loss at step 65600: 0.101567\n",
      "2023-12-13 14:57:39,477 INFO     Training average loss at step 65600: 0.125823\n",
      "2023-12-13 14:59:48,811 INFO     Training average positive_sample_loss at step 65700: 0.151065\n",
      "2023-12-13 14:59:48,811 INFO     Training average negative_sample_loss at step 65700: 0.101510\n",
      "2023-12-13 14:59:48,811 INFO     Training average loss at step 65700: 0.126288\n",
      "2023-12-13 15:02:09,900 INFO     Training average positive_sample_loss at step 65800: 0.151649\n",
      "2023-12-13 15:02:09,900 INFO     Training average negative_sample_loss at step 65800: 0.101437\n",
      "2023-12-13 15:02:09,900 INFO     Training average loss at step 65800: 0.126543\n",
      "2023-12-13 15:04:08,052 INFO     Training average positive_sample_loss at step 65900: 0.150475\n",
      "2023-12-13 15:04:08,053 INFO     Training average negative_sample_loss at step 65900: 0.101854\n",
      "2023-12-13 15:04:08,053 INFO     Training average loss at step 65900: 0.126164\n",
      "2023-12-13 15:06:13,458 INFO     Training average positive_sample_loss at step 66000: 0.150611\n",
      "2023-12-13 15:06:13,458 INFO     Training average negative_sample_loss at step 66000: 0.101328\n",
      "2023-12-13 15:06:13,458 INFO     Training average loss at step 66000: 0.125969\n",
      "2023-12-13 15:08:23,233 INFO     Training average positive_sample_loss at step 66100: 0.151001\n",
      "2023-12-13 15:08:23,233 INFO     Training average negative_sample_loss at step 66100: 0.101891\n",
      "2023-12-13 15:08:23,233 INFO     Training average loss at step 66100: 0.126446\n",
      "2023-12-13 15:10:22,166 INFO     Training average positive_sample_loss at step 66200: 0.151275\n",
      "2023-12-13 15:10:22,167 INFO     Training average negative_sample_loss at step 66200: 0.101590\n",
      "2023-12-13 15:10:22,167 INFO     Training average loss at step 66200: 0.126433\n",
      "2023-12-13 15:12:24,394 INFO     Training average positive_sample_loss at step 66300: 0.151409\n",
      "2023-12-13 15:12:24,395 INFO     Training average negative_sample_loss at step 66300: 0.101617\n",
      "2023-12-13 15:12:24,395 INFO     Training average loss at step 66300: 0.126513\n",
      "2023-12-13 15:14:42,805 INFO     Training average positive_sample_loss at step 66400: 0.150125\n",
      "2023-12-13 15:14:42,805 INFO     Training average negative_sample_loss at step 66400: 0.101694\n",
      "2023-12-13 15:14:42,805 INFO     Training average loss at step 66400: 0.125909\n",
      "2023-12-13 15:16:36,502 INFO     Training average positive_sample_loss at step 66500: 0.151681\n",
      "2023-12-13 15:16:36,503 INFO     Training average negative_sample_loss at step 66500: 0.101512\n",
      "2023-12-13 15:16:36,503 INFO     Training average loss at step 66500: 0.126596\n",
      "2023-12-13 15:18:51,565 INFO     Training average positive_sample_loss at step 66600: 0.150821\n",
      "2023-12-13 15:18:51,566 INFO     Training average negative_sample_loss at step 66600: 0.101806\n",
      "2023-12-13 15:18:51,566 INFO     Training average loss at step 66600: 0.126313\n",
      "2023-12-13 15:20:51,866 INFO     Training average positive_sample_loss at step 66700: 0.150474\n",
      "2023-12-13 15:20:51,867 INFO     Training average negative_sample_loss at step 66700: 0.101386\n",
      "2023-12-13 15:20:51,867 INFO     Training average loss at step 66700: 0.125930\n",
      "2023-12-13 15:23:07,701 INFO     Training average positive_sample_loss at step 66800: 0.151630\n",
      "2023-12-13 15:23:07,701 INFO     Training average negative_sample_loss at step 66800: 0.101522\n",
      "2023-12-13 15:23:07,701 INFO     Training average loss at step 66800: 0.126576\n",
      "2023-12-13 15:25:25,933 INFO     Training average positive_sample_loss at step 66900: 0.150385\n",
      "2023-12-13 15:25:25,933 INFO     Training average negative_sample_loss at step 66900: 0.101595\n",
      "2023-12-13 15:25:25,933 INFO     Training average loss at step 66900: 0.125990\n",
      "2023-12-13 15:27:37,509 INFO     Training average positive_sample_loss at step 67000: 0.150852\n",
      "2023-12-13 15:27:37,509 INFO     Training average negative_sample_loss at step 67000: 0.101559\n",
      "2023-12-13 15:27:37,509 INFO     Training average loss at step 67000: 0.126205\n",
      "2023-12-13 15:29:52,906 INFO     Training average positive_sample_loss at step 67100: 0.151135\n",
      "2023-12-13 15:29:52,906 INFO     Training average negative_sample_loss at step 67100: 0.101540\n",
      "2023-12-13 15:29:52,906 INFO     Training average loss at step 67100: 0.126338\n",
      "2023-12-13 15:31:53,847 INFO     Training average positive_sample_loss at step 67200: 0.150806\n",
      "2023-12-13 15:31:53,847 INFO     Training average negative_sample_loss at step 67200: 0.101699\n",
      "2023-12-13 15:31:53,847 INFO     Training average loss at step 67200: 0.126253\n",
      "2023-12-13 15:33:57,603 INFO     Training average positive_sample_loss at step 67300: 0.151299\n",
      "2023-12-13 15:33:57,604 INFO     Training average negative_sample_loss at step 67300: 0.101981\n",
      "2023-12-13 15:33:57,604 INFO     Training average loss at step 67300: 0.126640\n",
      "2023-12-13 15:36:19,007 INFO     Training average positive_sample_loss at step 67400: 0.150690\n",
      "2023-12-13 15:36:19,007 INFO     Training average negative_sample_loss at step 67400: 0.101431\n",
      "2023-12-13 15:36:19,007 INFO     Training average loss at step 67400: 0.126060\n",
      "2023-12-13 15:38:17,494 INFO     Training average positive_sample_loss at step 67500: 0.151200\n",
      "2023-12-13 15:38:17,494 INFO     Training average negative_sample_loss at step 67500: 0.101672\n",
      "2023-12-13 15:38:17,495 INFO     Training average loss at step 67500: 0.126436\n",
      "2023-12-13 15:40:38,002 INFO     Training average positive_sample_loss at step 67600: 0.151045\n",
      "2023-12-13 15:40:38,003 INFO     Training average negative_sample_loss at step 67600: 0.101770\n",
      "2023-12-13 15:40:38,003 INFO     Training average loss at step 67600: 0.126408\n",
      "2023-12-13 15:42:39,044 INFO     Training average positive_sample_loss at step 67700: 0.150045\n",
      "2023-12-13 15:42:39,044 INFO     Training average negative_sample_loss at step 67700: 0.101406\n",
      "2023-12-13 15:42:39,044 INFO     Training average loss at step 67700: 0.125725\n",
      "2023-12-13 15:44:44,583 INFO     Training average positive_sample_loss at step 67800: 0.151356\n",
      "2023-12-13 15:44:44,583 INFO     Training average negative_sample_loss at step 67800: 0.101682\n",
      "2023-12-13 15:44:44,583 INFO     Training average loss at step 67800: 0.126519\n",
      "2023-12-13 15:46:58,069 INFO     Training average positive_sample_loss at step 67900: 0.150916\n",
      "2023-12-13 15:46:58,069 INFO     Training average negative_sample_loss at step 67900: 0.101560\n",
      "2023-12-13 15:46:58,069 INFO     Training average loss at step 67900: 0.126238\n",
      "2023-12-13 15:48:58,421 INFO     Training average positive_sample_loss at step 68000: 0.150179\n",
      "2023-12-13 15:48:58,421 INFO     Training average negative_sample_loss at step 68000: 0.100948\n",
      "2023-12-13 15:48:58,421 INFO     Training average loss at step 68000: 0.125563\n",
      "2023-12-13 15:50:53,632 INFO     Training average positive_sample_loss at step 68100: 0.152042\n",
      "2023-12-13 15:50:53,632 INFO     Training average negative_sample_loss at step 68100: 0.102051\n",
      "2023-12-13 15:50:53,632 INFO     Training average loss at step 68100: 0.127047\n",
      "2023-12-13 15:53:03,880 INFO     Training average positive_sample_loss at step 68200: 0.150153\n",
      "2023-12-13 15:53:03,881 INFO     Training average negative_sample_loss at step 68200: 0.101821\n",
      "2023-12-13 15:53:03,881 INFO     Training average loss at step 68200: 0.125987\n",
      "2023-12-13 15:55:20,110 INFO     Training average positive_sample_loss at step 68300: 0.151665\n",
      "2023-12-13 15:55:20,111 INFO     Training average negative_sample_loss at step 68300: 0.101782\n",
      "2023-12-13 15:55:20,111 INFO     Training average loss at step 68300: 0.126724\n",
      "2023-12-13 15:57:36,437 INFO     Training average positive_sample_loss at step 68400: 0.150728\n",
      "2023-12-13 15:57:36,438 INFO     Training average negative_sample_loss at step 68400: 0.101646\n",
      "2023-12-13 15:57:36,438 INFO     Training average loss at step 68400: 0.126187\n",
      "2023-12-13 15:59:33,451 INFO     Training average positive_sample_loss at step 68500: 0.150648\n",
      "2023-12-13 15:59:33,452 INFO     Training average negative_sample_loss at step 68500: 0.101777\n",
      "2023-12-13 15:59:33,452 INFO     Training average loss at step 68500: 0.126212\n",
      "2023-12-13 16:01:22,916 INFO     Training average positive_sample_loss at step 68600: 0.151376\n",
      "2023-12-13 16:01:22,917 INFO     Training average negative_sample_loss at step 68600: 0.101094\n",
      "2023-12-13 16:01:22,917 INFO     Training average loss at step 68600: 0.126235\n",
      "2023-12-13 16:03:38,394 INFO     Training average positive_sample_loss at step 68700: 0.149791\n",
      "2023-12-13 16:03:38,394 INFO     Training average negative_sample_loss at step 68700: 0.101510\n",
      "2023-12-13 16:03:38,394 INFO     Training average loss at step 68700: 0.125650\n",
      "2023-12-13 16:05:44,501 INFO     Training average positive_sample_loss at step 68800: 0.151377\n",
      "2023-12-13 16:05:44,502 INFO     Training average negative_sample_loss at step 68800: 0.101565\n",
      "2023-12-13 16:05:44,502 INFO     Training average loss at step 68800: 0.126471\n",
      "2023-12-13 16:08:09,618 INFO     Training average positive_sample_loss at step 68900: 0.151552\n",
      "2023-12-13 16:08:09,619 INFO     Training average negative_sample_loss at step 68900: 0.101554\n",
      "2023-12-13 16:08:09,619 INFO     Training average loss at step 68900: 0.126553\n",
      "2023-12-13 16:10:07,440 INFO     Training average positive_sample_loss at step 69000: 0.150040\n",
      "2023-12-13 16:10:07,440 INFO     Training average negative_sample_loss at step 69000: 0.101848\n",
      "2023-12-13 16:10:07,440 INFO     Training average loss at step 69000: 0.125944\n",
      "2023-12-13 16:12:03,644 INFO     Training average positive_sample_loss at step 69100: 0.151666\n",
      "2023-12-13 16:12:03,645 INFO     Training average negative_sample_loss at step 69100: 0.101357\n",
      "2023-12-13 16:12:03,645 INFO     Training average loss at step 69100: 0.126512\n",
      "2023-12-13 16:14:16,370 INFO     Training average positive_sample_loss at step 69200: 0.150611\n",
      "2023-12-13 16:14:16,371 INFO     Training average negative_sample_loss at step 69200: 0.101470\n",
      "2023-12-13 16:14:16,371 INFO     Training average loss at step 69200: 0.126041\n",
      "2023-12-13 16:16:15,764 INFO     Training average positive_sample_loss at step 69300: 0.150568\n",
      "2023-12-13 16:16:15,764 INFO     Training average negative_sample_loss at step 69300: 0.101724\n",
      "2023-12-13 16:16:15,764 INFO     Training average loss at step 69300: 0.126146\n",
      "2023-12-13 16:18:16,809 INFO     Training average positive_sample_loss at step 69400: 0.151850\n",
      "2023-12-13 16:18:16,809 INFO     Training average negative_sample_loss at step 69400: 0.101714\n",
      "2023-12-13 16:18:16,809 INFO     Training average loss at step 69400: 0.126782\n",
      "2023-12-13 16:20:31,619 INFO     Training average positive_sample_loss at step 69500: 0.149828\n",
      "2023-12-13 16:20:31,619 INFO     Training average negative_sample_loss at step 69500: 0.101438\n",
      "2023-12-13 16:20:31,619 INFO     Training average loss at step 69500: 0.125633\n",
      "2023-12-13 16:22:37,686 INFO     Training average positive_sample_loss at step 69600: 0.151457\n",
      "2023-12-13 16:22:37,686 INFO     Training average negative_sample_loss at step 69600: 0.101555\n",
      "2023-12-13 16:22:37,686 INFO     Training average loss at step 69600: 0.126506\n",
      "2023-12-13 16:24:43,530 INFO     Training average positive_sample_loss at step 69700: 0.150658\n",
      "2023-12-13 16:24:43,531 INFO     Training average negative_sample_loss at step 69700: 0.101810\n",
      "2023-12-13 16:24:43,531 INFO     Training average loss at step 69700: 0.126234\n",
      "2023-12-13 16:26:43,080 INFO     Training average positive_sample_loss at step 69800: 0.151099\n",
      "2023-12-13 16:26:43,081 INFO     Training average negative_sample_loss at step 69800: 0.101867\n",
      "2023-12-13 16:26:43,081 INFO     Training average loss at step 69800: 0.126483\n",
      "2023-12-13 16:28:51,307 INFO     Training average positive_sample_loss at step 69900: 0.151387\n",
      "2023-12-13 16:28:51,307 INFO     Training average negative_sample_loss at step 69900: 0.101271\n",
      "2023-12-13 16:28:51,307 INFO     Training average loss at step 69900: 0.126329\n",
      "2023-12-13 16:31:11,334 INFO     Training average positive_sample_loss at step 70000: 0.150187\n",
      "2023-12-13 16:31:11,334 INFO     Training average negative_sample_loss at step 70000: 0.101425\n",
      "2023-12-13 16:31:11,334 INFO     Training average loss at step 70000: 0.125806\n",
      "2023-12-13 16:31:11,334 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-13 16:31:11,886 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-13 16:31:34,746 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-13 16:31:50,189 INFO     Valid MRR at step 70000: 0.420578\n",
      "2023-12-13 16:31:50,189 INFO     Valid MR at step 70000: 691.620608\n",
      "2023-12-13 16:31:50,189 INFO     Valid HITS@1 at step 70000: 0.393513\n",
      "2023-12-13 16:31:50,189 INFO     Valid HITS@3 at step 70000: 0.423562\n",
      "2023-12-13 16:31:50,190 INFO     Valid HITS@10 at step 70000: 0.469848\n",
      "2023-12-13 16:33:21,393 INFO     Training average positive_sample_loss at step 70100: 0.150851\n",
      "2023-12-13 16:33:21,393 INFO     Training average negative_sample_loss at step 70100: 0.101577\n",
      "2023-12-13 16:33:21,393 INFO     Training average loss at step 70100: 0.126214\n",
      "2023-12-13 16:35:46,177 INFO     Training average positive_sample_loss at step 70200: 0.151443\n",
      "2023-12-13 16:35:46,178 INFO     Training average negative_sample_loss at step 70200: 0.101828\n",
      "2023-12-13 16:35:46,178 INFO     Training average loss at step 70200: 0.126635\n",
      "2023-12-13 16:37:44,040 INFO     Training average positive_sample_loss at step 70300: 0.150979\n",
      "2023-12-13 16:37:44,040 INFO     Training average negative_sample_loss at step 70300: 0.101963\n",
      "2023-12-13 16:37:44,040 INFO     Training average loss at step 70300: 0.126471\n",
      "2023-12-13 16:39:45,593 INFO     Training average positive_sample_loss at step 70400: 0.151147\n",
      "2023-12-13 16:39:45,593 INFO     Training average negative_sample_loss at step 70400: 0.101190\n",
      "2023-12-13 16:39:45,594 INFO     Training average loss at step 70400: 0.126169\n",
      "2023-12-13 16:41:56,997 INFO     Training average positive_sample_loss at step 70500: 0.150156\n",
      "2023-12-13 16:41:56,997 INFO     Training average negative_sample_loss at step 70500: 0.101309\n",
      "2023-12-13 16:41:56,997 INFO     Training average loss at step 70500: 0.125733\n",
      "2023-12-13 16:43:54,870 INFO     Training average positive_sample_loss at step 70600: 0.150069\n",
      "2023-12-13 16:43:54,871 INFO     Training average negative_sample_loss at step 70600: 0.101539\n",
      "2023-12-13 16:43:54,871 INFO     Training average loss at step 70600: 0.125804\n",
      "2023-12-13 16:46:11,169 INFO     Training average positive_sample_loss at step 70700: 0.152153\n",
      "2023-12-13 16:46:11,169 INFO     Training average negative_sample_loss at step 70700: 0.101766\n",
      "2023-12-13 16:46:11,169 INFO     Training average loss at step 70700: 0.126960\n",
      "2023-12-13 16:48:00,554 INFO     Training average positive_sample_loss at step 70800: 0.150663\n",
      "2023-12-13 16:48:00,555 INFO     Training average negative_sample_loss at step 70800: 0.101672\n",
      "2023-12-13 16:48:00,555 INFO     Training average loss at step 70800: 0.126167\n",
      "2023-12-13 16:50:05,283 INFO     Training average positive_sample_loss at step 70900: 0.150904\n",
      "2023-12-13 16:50:05,283 INFO     Training average negative_sample_loss at step 70900: 0.101605\n",
      "2023-12-13 16:50:05,283 INFO     Training average loss at step 70900: 0.126254\n",
      "2023-12-13 16:52:21,528 INFO     Training average positive_sample_loss at step 71000: 0.151032\n",
      "2023-12-13 16:52:21,529 INFO     Training average negative_sample_loss at step 71000: 0.101393\n",
      "2023-12-13 16:52:21,529 INFO     Training average loss at step 71000: 0.126213\n",
      "2023-12-13 16:54:16,030 INFO     Training average positive_sample_loss at step 71100: 0.150360\n",
      "2023-12-13 16:54:16,030 INFO     Training average negative_sample_loss at step 71100: 0.101712\n",
      "2023-12-13 16:54:16,030 INFO     Training average loss at step 71100: 0.126036\n",
      "2023-12-13 16:56:14,038 INFO     Training average positive_sample_loss at step 71200: 0.151269\n",
      "2023-12-13 16:56:14,038 INFO     Training average negative_sample_loss at step 71200: 0.101384\n",
      "2023-12-13 16:56:14,039 INFO     Training average loss at step 71200: 0.126326\n",
      "2023-12-13 16:58:37,771 INFO     Training average positive_sample_loss at step 71300: 0.150182\n",
      "2023-12-13 16:58:37,771 INFO     Training average negative_sample_loss at step 71300: 0.101656\n",
      "2023-12-13 16:58:37,771 INFO     Training average loss at step 71300: 0.125919\n",
      "2023-12-13 17:00:35,540 INFO     Training average positive_sample_loss at step 71400: 0.151531\n",
      "2023-12-13 17:00:35,540 INFO     Training average negative_sample_loss at step 71400: 0.101659\n",
      "2023-12-13 17:00:35,540 INFO     Training average loss at step 71400: 0.126595\n",
      "2023-12-13 17:02:41,370 INFO     Training average positive_sample_loss at step 71500: 0.150893\n",
      "2023-12-13 17:02:41,371 INFO     Training average negative_sample_loss at step 71500: 0.101669\n",
      "2023-12-13 17:02:41,371 INFO     Training average loss at step 71500: 0.126281\n",
      "2023-12-13 17:04:48,655 INFO     Training average positive_sample_loss at step 71600: 0.150355\n",
      "2023-12-13 17:04:48,656 INFO     Training average negative_sample_loss at step 71600: 0.101277\n",
      "2023-12-13 17:04:48,656 INFO     Training average loss at step 71600: 0.125816\n",
      "2023-12-13 17:07:03,780 INFO     Training average positive_sample_loss at step 71700: 0.151357\n",
      "2023-12-13 17:07:03,780 INFO     Training average negative_sample_loss at step 71700: 0.101824\n",
      "2023-12-13 17:07:03,780 INFO     Training average loss at step 71700: 0.126591\n",
      "2023-12-13 17:09:04,298 INFO     Training average positive_sample_loss at step 71800: 0.150369\n",
      "2023-12-13 17:09:04,299 INFO     Training average negative_sample_loss at step 71800: 0.101799\n",
      "2023-12-13 17:09:04,299 INFO     Training average loss at step 71800: 0.126084\n",
      "2023-12-13 17:11:10,449 INFO     Training average positive_sample_loss at step 71900: 0.151182\n",
      "2023-12-13 17:11:10,449 INFO     Training average negative_sample_loss at step 71900: 0.101756\n",
      "2023-12-13 17:11:10,449 INFO     Training average loss at step 71900: 0.126469\n",
      "2023-12-13 17:13:21,533 INFO     Training average positive_sample_loss at step 72000: 0.151003\n",
      "2023-12-13 17:13:21,534 INFO     Training average negative_sample_loss at step 72000: 0.101280\n",
      "2023-12-13 17:13:21,534 INFO     Training average loss at step 72000: 0.126142\n",
      "2023-12-13 17:15:20,111 INFO     Training average positive_sample_loss at step 72100: 0.150164\n",
      "2023-12-13 17:15:20,111 INFO     Training average negative_sample_loss at step 72100: 0.101277\n",
      "2023-12-13 17:15:20,111 INFO     Training average loss at step 72100: 0.125721\n",
      "2023-12-13 17:17:25,667 INFO     Training average positive_sample_loss at step 72200: 0.151269\n",
      "2023-12-13 17:17:25,668 INFO     Training average negative_sample_loss at step 72200: 0.101296\n",
      "2023-12-13 17:17:25,668 INFO     Training average loss at step 72200: 0.126282\n",
      "2023-12-13 17:19:38,241 INFO     Training average positive_sample_loss at step 72300: 0.150396\n",
      "2023-12-13 17:19:38,241 INFO     Training average negative_sample_loss at step 72300: 0.101730\n",
      "2023-12-13 17:19:38,241 INFO     Training average loss at step 72300: 0.126063\n",
      "2023-12-13 17:21:48,179 INFO     Training average positive_sample_loss at step 72400: 0.150291\n",
      "2023-12-13 17:21:48,180 INFO     Training average negative_sample_loss at step 72400: 0.101152\n",
      "2023-12-13 17:21:48,180 INFO     Training average loss at step 72400: 0.125722\n",
      "2023-12-13 17:24:01,307 INFO     Training average positive_sample_loss at step 72500: 0.152574\n",
      "2023-12-13 17:24:01,307 INFO     Training average negative_sample_loss at step 72500: 0.102005\n",
      "2023-12-13 17:24:01,308 INFO     Training average loss at step 72500: 0.127290\n",
      "2023-12-13 17:25:54,534 INFO     Training average positive_sample_loss at step 72600: 0.149966\n",
      "2023-12-13 17:25:54,535 INFO     Training average negative_sample_loss at step 72600: 0.101181\n",
      "2023-12-13 17:25:54,535 INFO     Training average loss at step 72600: 0.125573\n",
      "2023-12-13 17:28:07,197 INFO     Training average positive_sample_loss at step 72700: 0.151450\n",
      "2023-12-13 17:28:07,197 INFO     Training average negative_sample_loss at step 72700: 0.101578\n",
      "2023-12-13 17:28:07,197 INFO     Training average loss at step 72700: 0.126514\n",
      "2023-12-13 17:30:23,539 INFO     Training average positive_sample_loss at step 72800: 0.150758\n",
      "2023-12-13 17:30:23,540 INFO     Training average negative_sample_loss at step 72800: 0.101966\n",
      "2023-12-13 17:30:23,540 INFO     Training average loss at step 72800: 0.126362\n",
      "2023-12-13 17:32:33,108 INFO     Training average positive_sample_loss at step 72900: 0.150270\n",
      "2023-12-13 17:32:33,108 INFO     Training average negative_sample_loss at step 72900: 0.101135\n",
      "2023-12-13 17:32:33,108 INFO     Training average loss at step 72900: 0.125702\n",
      "2023-12-13 17:34:32,552 INFO     Training average positive_sample_loss at step 73000: 0.151737\n",
      "2023-12-13 17:34:32,552 INFO     Training average negative_sample_loss at step 73000: 0.101992\n",
      "2023-12-13 17:34:32,552 INFO     Training average loss at step 73000: 0.126864\n",
      "2023-12-13 17:36:55,346 INFO     Training average positive_sample_loss at step 73100: 0.150562\n",
      "2023-12-13 17:36:55,347 INFO     Training average negative_sample_loss at step 73100: 0.101789\n",
      "2023-12-13 17:36:55,347 INFO     Training average loss at step 73100: 0.126175\n",
      "2023-12-13 17:39:07,698 INFO     Training average positive_sample_loss at step 73200: 0.150854\n",
      "2023-12-13 17:39:07,698 INFO     Training average negative_sample_loss at step 73200: 0.101268\n",
      "2023-12-13 17:39:07,698 INFO     Training average loss at step 73200: 0.126061\n",
      "2023-12-13 17:41:21,184 INFO     Training average positive_sample_loss at step 73300: 0.150250\n",
      "2023-12-13 17:41:21,185 INFO     Training average negative_sample_loss at step 73300: 0.101571\n",
      "2023-12-13 17:41:21,185 INFO     Training average loss at step 73300: 0.125911\n",
      "2023-12-13 17:43:19,991 INFO     Training average positive_sample_loss at step 73400: 0.150112\n",
      "2023-12-13 17:43:19,991 INFO     Training average negative_sample_loss at step 73400: 0.101127\n",
      "2023-12-13 17:43:19,991 INFO     Training average loss at step 73400: 0.125620\n",
      "2023-12-13 17:45:30,097 INFO     Training average positive_sample_loss at step 73500: 0.151762\n",
      "2023-12-13 17:45:30,097 INFO     Training average negative_sample_loss at step 73500: 0.101536\n",
      "2023-12-13 17:45:30,097 INFO     Training average loss at step 73500: 0.126649\n",
      "2023-12-13 17:47:39,806 INFO     Training average positive_sample_loss at step 73600: 0.149955\n",
      "2023-12-13 17:47:39,806 INFO     Training average negative_sample_loss at step 73600: 0.101295\n",
      "2023-12-13 17:47:39,806 INFO     Training average loss at step 73600: 0.125625\n",
      "2023-12-13 17:49:46,065 INFO     Training average positive_sample_loss at step 73700: 0.151008\n",
      "2023-12-13 17:49:46,066 INFO     Training average negative_sample_loss at step 73700: 0.101456\n",
      "2023-12-13 17:49:46,066 INFO     Training average loss at step 73700: 0.126232\n",
      "2023-12-13 17:52:07,685 INFO     Training average positive_sample_loss at step 73800: 0.151900\n",
      "2023-12-13 17:52:07,686 INFO     Training average negative_sample_loss at step 73800: 0.101928\n",
      "2023-12-13 17:52:07,686 INFO     Training average loss at step 73800: 0.126914\n",
      "2023-12-13 17:53:59,136 INFO     Training average positive_sample_loss at step 73900: 0.150202\n",
      "2023-12-13 17:53:59,136 INFO     Training average negative_sample_loss at step 73900: 0.101594\n",
      "2023-12-13 17:53:59,136 INFO     Training average loss at step 73900: 0.125898\n",
      "2023-12-13 17:55:59,608 INFO     Training average positive_sample_loss at step 74000: 0.151091\n",
      "2023-12-13 17:55:59,609 INFO     Training average negative_sample_loss at step 74000: 0.101728\n",
      "2023-12-13 17:55:59,609 INFO     Training average loss at step 74000: 0.126409\n",
      "2023-12-13 17:58:26,993 INFO     Training average positive_sample_loss at step 74100: 0.151074\n",
      "2023-12-13 17:58:26,993 INFO     Training average negative_sample_loss at step 74100: 0.101637\n",
      "2023-12-13 17:58:26,993 INFO     Training average loss at step 74100: 0.126355\n",
      "2023-12-13 18:00:28,001 INFO     Training average positive_sample_loss at step 74200: 0.150357\n",
      "2023-12-13 18:00:28,001 INFO     Training average negative_sample_loss at step 74200: 0.101552\n",
      "2023-12-13 18:00:28,001 INFO     Training average loss at step 74200: 0.125955\n",
      "2023-12-13 18:02:32,465 INFO     Training average positive_sample_loss at step 74300: 0.151599\n",
      "2023-12-13 18:02:32,465 INFO     Training average negative_sample_loss at step 74300: 0.101233\n",
      "2023-12-13 18:02:32,466 INFO     Training average loss at step 74300: 0.126416\n",
      "2023-12-13 18:05:06,458 INFO     Training average positive_sample_loss at step 74400: 0.149490\n",
      "2023-12-13 18:05:06,459 INFO     Training average negative_sample_loss at step 74400: 0.101417\n",
      "2023-12-13 18:05:06,459 INFO     Training average loss at step 74400: 0.125454\n",
      "2023-12-13 18:07:16,665 INFO     Training average positive_sample_loss at step 74500: 0.151388\n",
      "2023-12-13 18:07:16,665 INFO     Training average negative_sample_loss at step 74500: 0.101548\n",
      "2023-12-13 18:07:16,665 INFO     Training average loss at step 74500: 0.126468\n",
      "2023-12-13 18:09:34,560 INFO     Training average positive_sample_loss at step 74600: 0.151805\n",
      "2023-12-13 18:09:34,561 INFO     Training average negative_sample_loss at step 74600: 0.101634\n",
      "2023-12-13 18:09:34,561 INFO     Training average loss at step 74600: 0.126719\n",
      "2023-12-13 18:11:39,988 INFO     Training average positive_sample_loss at step 74700: 0.149496\n",
      "2023-12-13 18:11:39,988 INFO     Training average negative_sample_loss at step 74700: 0.101088\n",
      "2023-12-13 18:11:39,988 INFO     Training average loss at step 74700: 0.125292\n",
      "2023-12-13 18:13:39,327 INFO     Training average positive_sample_loss at step 74800: 0.151734\n",
      "2023-12-13 18:13:39,327 INFO     Training average negative_sample_loss at step 74800: 0.101834\n",
      "2023-12-13 18:13:39,327 INFO     Training average loss at step 74800: 0.126784\n",
      "2023-12-13 18:15:51,935 INFO     Training average positive_sample_loss at step 74900: 0.149731\n",
      "2023-12-13 18:15:51,935 INFO     Training average negative_sample_loss at step 74900: 0.101333\n",
      "2023-12-13 18:15:51,935 INFO     Training average loss at step 74900: 0.125532\n",
      "2023-12-13 18:18:11,323 INFO     Training average positive_sample_loss at step 75000: 0.151109\n",
      "2023-12-13 18:18:11,323 INFO     Training average negative_sample_loss at step 75000: 0.101375\n",
      "2023-12-13 18:18:11,323 INFO     Training average loss at step 75000: 0.126242\n",
      "2023-12-13 18:20:26,465 INFO     Training average positive_sample_loss at step 75100: 0.151013\n",
      "2023-12-13 18:20:26,465 INFO     Training average negative_sample_loss at step 75100: 0.101500\n",
      "2023-12-13 18:20:26,465 INFO     Training average loss at step 75100: 0.126257\n",
      "2023-12-13 18:22:16,396 INFO     Training average positive_sample_loss at step 75200: 0.151035\n",
      "2023-12-13 18:22:16,397 INFO     Training average negative_sample_loss at step 75200: 0.101522\n",
      "2023-12-13 18:22:16,397 INFO     Training average loss at step 75200: 0.126278\n",
      "2023-12-13 18:24:24,357 INFO     Training average positive_sample_loss at step 75300: 0.150861\n",
      "2023-12-13 18:24:24,357 INFO     Training average negative_sample_loss at step 75300: 0.101622\n",
      "2023-12-13 18:24:24,357 INFO     Training average loss at step 75300: 0.126242\n",
      "2023-12-13 18:26:41,011 INFO     Training average positive_sample_loss at step 75400: 0.150062\n",
      "2023-12-13 18:26:41,011 INFO     Training average negative_sample_loss at step 75400: 0.101358\n",
      "2023-12-13 18:26:41,012 INFO     Training average loss at step 75400: 0.125710\n",
      "2023-12-13 18:28:48,826 INFO     Training average positive_sample_loss at step 75500: 0.150227\n",
      "2023-12-13 18:28:48,827 INFO     Training average negative_sample_loss at step 75500: 0.101202\n",
      "2023-12-13 18:28:48,827 INFO     Training average loss at step 75500: 0.125714\n",
      "2023-12-13 18:31:04,742 INFO     Training average positive_sample_loss at step 75600: 0.152277\n",
      "2023-12-13 18:31:04,742 INFO     Training average negative_sample_loss at step 75600: 0.101942\n",
      "2023-12-13 18:31:04,742 INFO     Training average loss at step 75600: 0.127110\n",
      "2023-12-13 18:32:56,722 INFO     Training average positive_sample_loss at step 75700: 0.149353\n",
      "2023-12-13 18:32:56,722 INFO     Training average negative_sample_loss at step 75700: 0.101135\n",
      "2023-12-13 18:32:56,722 INFO     Training average loss at step 75700: 0.125244\n",
      "2023-12-13 18:34:52,867 INFO     Training average positive_sample_loss at step 75800: 0.151671\n",
      "2023-12-13 18:34:52,868 INFO     Training average negative_sample_loss at step 75800: 0.101617\n",
      "2023-12-13 18:34:52,868 INFO     Training average loss at step 75800: 0.126644\n",
      "2023-12-13 18:37:07,137 INFO     Training average positive_sample_loss at step 75900: 0.150928\n",
      "2023-12-13 18:37:07,137 INFO     Training average negative_sample_loss at step 75900: 0.101510\n",
      "2023-12-13 18:37:07,137 INFO     Training average loss at step 75900: 0.126219\n",
      "2023-12-13 18:39:12,559 INFO     Training average positive_sample_loss at step 76000: 0.150665\n",
      "2023-12-13 18:39:12,560 INFO     Training average negative_sample_loss at step 76000: 0.101907\n",
      "2023-12-13 18:39:12,560 INFO     Training average loss at step 76000: 0.126286\n",
      "2023-12-13 18:41:21,270 INFO     Training average positive_sample_loss at step 76100: 0.151582\n",
      "2023-12-13 18:41:21,270 INFO     Training average negative_sample_loss at step 76100: 0.101463\n",
      "2023-12-13 18:41:21,270 INFO     Training average loss at step 76100: 0.126522\n",
      "2023-12-13 18:43:26,287 INFO     Training average positive_sample_loss at step 76200: 0.150380\n",
      "2023-12-13 18:43:26,287 INFO     Training average negative_sample_loss at step 76200: 0.102004\n",
      "2023-12-13 18:43:26,287 INFO     Training average loss at step 76200: 0.126192\n",
      "2023-12-13 18:45:29,049 INFO     Training average positive_sample_loss at step 76300: 0.150638\n",
      "2023-12-13 18:45:29,049 INFO     Training average negative_sample_loss at step 76300: 0.101408\n",
      "2023-12-13 18:45:29,049 INFO     Training average loss at step 76300: 0.126023\n",
      "2023-12-13 18:47:42,873 INFO     Training average positive_sample_loss at step 76400: 0.150685\n",
      "2023-12-13 18:47:42,873 INFO     Training average negative_sample_loss at step 76400: 0.101554\n",
      "2023-12-13 18:47:42,873 INFO     Training average loss at step 76400: 0.126120\n",
      "2023-12-13 18:49:32,696 INFO     Training average positive_sample_loss at step 76500: 0.150943\n",
      "2023-12-13 18:49:32,697 INFO     Training average negative_sample_loss at step 76500: 0.101517\n",
      "2023-12-13 18:49:32,697 INFO     Training average loss at step 76500: 0.126230\n",
      "2023-12-13 18:51:33,013 INFO     Training average positive_sample_loss at step 76600: 0.151202\n",
      "2023-12-13 18:51:33,014 INFO     Training average negative_sample_loss at step 76600: 0.101720\n",
      "2023-12-13 18:51:33,014 INFO     Training average loss at step 76600: 0.126461\n",
      "2023-12-13 18:53:49,846 INFO     Training average positive_sample_loss at step 76700: 0.150257\n",
      "2023-12-13 18:53:49,846 INFO     Training average negative_sample_loss at step 76700: 0.101645\n",
      "2023-12-13 18:53:49,846 INFO     Training average loss at step 76700: 0.125951\n",
      "2023-12-13 18:55:57,726 INFO     Training average positive_sample_loss at step 76800: 0.151018\n",
      "2023-12-13 18:55:57,726 INFO     Training average negative_sample_loss at step 76800: 0.101374\n",
      "2023-12-13 18:55:57,726 INFO     Training average loss at step 76800: 0.126196\n",
      "2023-12-13 18:58:12,151 INFO     Training average positive_sample_loss at step 76900: 0.150785\n",
      "2023-12-13 18:58:12,151 INFO     Training average negative_sample_loss at step 76900: 0.101668\n",
      "2023-12-13 18:58:12,151 INFO     Training average loss at step 76900: 0.126226\n",
      "2023-12-13 19:00:11,628 INFO     Training average positive_sample_loss at step 77000: 0.150371\n",
      "2023-12-13 19:00:11,629 INFO     Training average negative_sample_loss at step 77000: 0.101331\n",
      "2023-12-13 19:00:11,629 INFO     Training average loss at step 77000: 0.125851\n",
      "2023-12-13 19:02:12,528 INFO     Training average positive_sample_loss at step 77100: 0.151415\n",
      "2023-12-13 19:02:12,528 INFO     Training average negative_sample_loss at step 77100: 0.101486\n",
      "2023-12-13 19:02:12,528 INFO     Training average loss at step 77100: 0.126451\n",
      "2023-12-13 19:04:22,895 INFO     Training average positive_sample_loss at step 77200: 0.150572\n",
      "2023-12-13 19:04:22,896 INFO     Training average negative_sample_loss at step 77200: 0.101693\n",
      "2023-12-13 19:04:22,896 INFO     Training average loss at step 77200: 0.126133\n",
      "2023-12-13 19:06:32,306 INFO     Training average positive_sample_loss at step 77300: 0.150524\n",
      "2023-12-13 19:06:32,306 INFO     Training average negative_sample_loss at step 77300: 0.101394\n",
      "2023-12-13 19:06:32,306 INFO     Training average loss at step 77300: 0.125959\n",
      "2023-12-13 19:08:47,176 INFO     Training average positive_sample_loss at step 77400: 0.151237\n",
      "2023-12-13 19:08:47,177 INFO     Training average negative_sample_loss at step 77400: 0.101210\n",
      "2023-12-13 19:08:47,177 INFO     Training average loss at step 77400: 0.126224\n",
      "2023-12-13 19:10:44,457 INFO     Training average positive_sample_loss at step 77500: 0.149671\n",
      "2023-12-13 19:10:44,457 INFO     Training average negative_sample_loss at step 77500: 0.101213\n",
      "2023-12-13 19:10:44,458 INFO     Training average loss at step 77500: 0.125442\n",
      "2023-12-13 19:12:39,244 INFO     Training average positive_sample_loss at step 77600: 0.151565\n",
      "2023-12-13 19:12:39,245 INFO     Training average negative_sample_loss at step 77600: 0.101777\n",
      "2023-12-13 19:12:39,245 INFO     Training average loss at step 77600: 0.126671\n",
      "2023-12-13 19:14:53,934 INFO     Training average positive_sample_loss at step 77700: 0.150358\n",
      "2023-12-13 19:14:53,935 INFO     Training average negative_sample_loss at step 77700: 0.101217\n",
      "2023-12-13 19:14:53,935 INFO     Training average loss at step 77700: 0.125787\n",
      "2023-12-13 19:16:46,993 INFO     Training average positive_sample_loss at step 77800: 0.150675\n",
      "2023-12-13 19:16:46,993 INFO     Training average negative_sample_loss at step 77800: 0.101368\n",
      "2023-12-13 19:16:46,994 INFO     Training average loss at step 77800: 0.126021\n",
      "2023-12-13 19:18:43,626 INFO     Training average positive_sample_loss at step 77900: 0.151630\n",
      "2023-12-13 19:18:43,627 INFO     Training average negative_sample_loss at step 77900: 0.101754\n",
      "2023-12-13 19:18:43,627 INFO     Training average loss at step 77900: 0.126692\n",
      "2023-12-13 19:21:02,933 INFO     Training average positive_sample_loss at step 78000: 0.149706\n",
      "2023-12-13 19:21:02,934 INFO     Training average negative_sample_loss at step 78000: 0.101640\n",
      "2023-12-13 19:21:02,934 INFO     Training average loss at step 78000: 0.125673\n",
      "2023-12-13 19:23:13,350 INFO     Training average positive_sample_loss at step 78100: 0.151192\n",
      "2023-12-13 19:23:13,350 INFO     Training average negative_sample_loss at step 78100: 0.101502\n",
      "2023-12-13 19:23:13,350 INFO     Training average loss at step 78100: 0.126347\n",
      "2023-12-13 19:25:29,063 INFO     Training average positive_sample_loss at step 78200: 0.150847\n",
      "2023-12-13 19:25:29,063 INFO     Training average negative_sample_loss at step 78200: 0.101508\n",
      "2023-12-13 19:25:29,063 INFO     Training average loss at step 78200: 0.126177\n",
      "2023-12-13 19:27:35,064 INFO     Training average positive_sample_loss at step 78300: 0.150434\n",
      "2023-12-13 19:27:35,064 INFO     Training average negative_sample_loss at step 78300: 0.101601\n",
      "2023-12-13 19:27:35,064 INFO     Training average loss at step 78300: 0.126018\n",
      "2023-12-13 19:29:40,570 INFO     Training average positive_sample_loss at step 78400: 0.151578\n",
      "2023-12-13 19:29:40,571 INFO     Training average negative_sample_loss at step 78400: 0.101390\n",
      "2023-12-13 19:29:40,571 INFO     Training average loss at step 78400: 0.126484\n",
      "2023-12-13 19:31:53,417 INFO     Training average positive_sample_loss at step 78500: 0.150145\n",
      "2023-12-13 19:31:53,418 INFO     Training average negative_sample_loss at step 78500: 0.101259\n",
      "2023-12-13 19:31:53,418 INFO     Training average loss at step 78500: 0.125702\n",
      "2023-12-13 19:34:05,889 INFO     Training average positive_sample_loss at step 78600: 0.150883\n",
      "2023-12-13 19:34:05,890 INFO     Training average negative_sample_loss at step 78600: 0.101820\n",
      "2023-12-13 19:34:05,890 INFO     Training average loss at step 78600: 0.126351\n",
      "2023-12-13 19:36:23,133 INFO     Training average positive_sample_loss at step 78700: 0.151026\n",
      "2023-12-13 19:36:23,134 INFO     Training average negative_sample_loss at step 78700: 0.101300\n",
      "2023-12-13 19:36:23,134 INFO     Training average loss at step 78700: 0.126163\n",
      "2023-12-13 19:38:23,139 INFO     Training average positive_sample_loss at step 78800: 0.149561\n",
      "2023-12-13 19:38:23,140 INFO     Training average negative_sample_loss at step 78800: 0.100955\n",
      "2023-12-13 19:38:23,140 INFO     Training average loss at step 78800: 0.125258\n",
      "2023-12-13 19:40:31,795 INFO     Training average positive_sample_loss at step 78900: 0.151409\n",
      "2023-12-13 19:40:31,795 INFO     Training average negative_sample_loss at step 78900: 0.101488\n",
      "2023-12-13 19:40:31,795 INFO     Training average loss at step 78900: 0.126448\n",
      "2023-12-13 19:42:54,205 INFO     Training average positive_sample_loss at step 79000: 0.151196\n",
      "2023-12-13 19:42:54,205 INFO     Training average negative_sample_loss at step 79000: 0.101948\n",
      "2023-12-13 19:42:54,205 INFO     Training average loss at step 79000: 0.126572\n",
      "2023-12-13 19:44:42,942 INFO     Training average positive_sample_loss at step 79100: 0.150619\n",
      "2023-12-13 19:44:42,942 INFO     Training average negative_sample_loss at step 79100: 0.101277\n",
      "2023-12-13 19:44:42,942 INFO     Training average loss at step 79100: 0.125948\n",
      "2023-12-13 19:46:43,616 INFO     Training average positive_sample_loss at step 79200: 0.151422\n",
      "2023-12-13 19:46:43,617 INFO     Training average negative_sample_loss at step 79200: 0.101521\n",
      "2023-12-13 19:46:43,617 INFO     Training average loss at step 79200: 0.126472\n",
      "2023-12-13 19:49:02,806 INFO     Training average positive_sample_loss at step 79300: 0.149697\n",
      "2023-12-13 19:49:02,806 INFO     Training average negative_sample_loss at step 79300: 0.101174\n",
      "2023-12-13 19:49:02,806 INFO     Training average loss at step 79300: 0.125436\n",
      "2023-12-13 19:51:09,859 INFO     Training average positive_sample_loss at step 79400: 0.150876\n",
      "2023-12-13 19:51:09,860 INFO     Training average negative_sample_loss at step 79400: 0.101238\n",
      "2023-12-13 19:51:09,860 INFO     Training average loss at step 79400: 0.126057\n",
      "2023-12-13 19:53:21,502 INFO     Training average positive_sample_loss at step 79500: 0.151111\n",
      "2023-12-13 19:53:21,503 INFO     Training average negative_sample_loss at step 79500: 0.101658\n",
      "2023-12-13 19:53:21,503 INFO     Training average loss at step 79500: 0.126385\n",
      "2023-12-13 19:55:23,484 INFO     Training average positive_sample_loss at step 79600: 0.149930\n",
      "2023-12-13 19:55:23,485 INFO     Training average negative_sample_loss at step 79600: 0.101264\n",
      "2023-12-13 19:55:23,485 INFO     Training average loss at step 79600: 0.125597\n",
      "2023-12-13 19:57:30,697 INFO     Training average positive_sample_loss at step 79700: 0.151792\n",
      "2023-12-13 19:57:30,697 INFO     Training average negative_sample_loss at step 79700: 0.101682\n",
      "2023-12-13 19:57:30,697 INFO     Training average loss at step 79700: 0.126737\n",
      "2023-12-13 19:59:43,017 INFO     Training average positive_sample_loss at step 79800: 0.149567\n",
      "2023-12-13 19:59:43,017 INFO     Training average negative_sample_loss at step 79800: 0.101234\n",
      "2023-12-13 19:59:43,017 INFO     Training average loss at step 79800: 0.125401\n",
      "2023-12-13 20:01:55,500 INFO     Training average positive_sample_loss at step 79900: 0.152004\n",
      "2023-12-13 20:01:55,501 INFO     Training average negative_sample_loss at step 79900: 0.101649\n",
      "2023-12-13 20:01:55,501 INFO     Training average loss at step 79900: 0.126826\n",
      "2023-12-13 20:04:27,258 INFO     Training average positive_sample_loss at step 80000: 0.150513\n",
      "2023-12-13 20:04:27,259 INFO     Training average negative_sample_loss at step 80000: 0.101214\n",
      "2023-12-13 20:04:27,259 INFO     Training average loss at step 80000: 0.125864\n",
      "2023-12-13 20:04:27,259 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-13 20:04:27,704 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-13 20:04:51,715 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-13 20:05:08,147 INFO     Valid MRR at step 80000: 0.420619\n",
      "2023-12-13 20:05:08,147 INFO     Valid MR at step 80000: 690.367795\n",
      "2023-12-13 20:05:08,147 INFO     Valid HITS@1 at step 80000: 0.393478\n",
      "2023-12-13 20:05:08,147 INFO     Valid HITS@3 at step 80000: 0.423528\n",
      "2023-12-13 20:05:08,147 INFO     Valid HITS@10 at step 80000: 0.469780\n",
      "2023-12-13 20:06:57,883 INFO     Training average positive_sample_loss at step 80100: 0.150489\n",
      "2023-12-13 20:06:57,884 INFO     Training average negative_sample_loss at step 80100: 0.101563\n",
      "2023-12-13 20:06:57,884 INFO     Training average loss at step 80100: 0.126026\n",
      "2023-12-13 20:08:50,974 INFO     Training average positive_sample_loss at step 80200: 0.150772\n",
      "2023-12-13 20:08:50,975 INFO     Training average negative_sample_loss at step 80200: 0.101562\n",
      "2023-12-13 20:08:50,975 INFO     Training average loss at step 80200: 0.126167\n",
      "2023-12-13 20:11:01,367 INFO     Training average positive_sample_loss at step 80300: 0.149947\n",
      "2023-12-13 20:11:01,367 INFO     Training average negative_sample_loss at step 80300: 0.101333\n",
      "2023-12-13 20:11:01,367 INFO     Training average loss at step 80300: 0.125640\n",
      "2023-12-13 20:12:59,757 INFO     Training average positive_sample_loss at step 80400: 0.151265\n",
      "2023-12-13 20:12:59,757 INFO     Training average negative_sample_loss at step 80400: 0.101879\n",
      "2023-12-13 20:12:59,757 INFO     Training average loss at step 80400: 0.126572\n",
      "2023-12-13 20:15:17,937 INFO     Training average positive_sample_loss at step 80500: 0.151337\n",
      "2023-12-13 20:15:17,937 INFO     Training average negative_sample_loss at step 80500: 0.101192\n",
      "2023-12-13 20:15:17,938 INFO     Training average loss at step 80500: 0.126265\n",
      "2023-12-13 20:17:14,223 INFO     Training average positive_sample_loss at step 80600: 0.149605\n",
      "2023-12-13 20:17:14,224 INFO     Training average negative_sample_loss at step 80600: 0.101237\n",
      "2023-12-13 20:17:14,224 INFO     Training average loss at step 80600: 0.125421\n",
      "2023-12-13 20:19:18,725 INFO     Training average positive_sample_loss at step 80700: 0.151531\n",
      "2023-12-13 20:19:18,726 INFO     Training average negative_sample_loss at step 80700: 0.101444\n",
      "2023-12-13 20:19:18,726 INFO     Training average loss at step 80700: 0.126487\n",
      "2023-12-13 20:21:35,504 INFO     Training average positive_sample_loss at step 80800: 0.151013\n",
      "2023-12-13 20:21:35,504 INFO     Training average negative_sample_loss at step 80800: 0.101224\n",
      "2023-12-13 20:21:35,504 INFO     Training average loss at step 80800: 0.126119\n",
      "2023-12-13 20:23:44,676 INFO     Training average positive_sample_loss at step 80900: 0.149606\n",
      "2023-12-13 20:23:44,676 INFO     Training average negative_sample_loss at step 80900: 0.101438\n",
      "2023-12-13 20:23:44,676 INFO     Training average loss at step 80900: 0.125522\n",
      "2023-12-13 20:25:40,854 INFO     Training average positive_sample_loss at step 81000: 0.151895\n",
      "2023-12-13 20:25:40,855 INFO     Training average negative_sample_loss at step 81000: 0.101758\n",
      "2023-12-13 20:25:40,855 INFO     Training average loss at step 81000: 0.126827\n",
      "2023-12-13 20:27:50,683 INFO     Training average positive_sample_loss at step 81100: 0.149738\n",
      "2023-12-13 20:27:50,684 INFO     Training average negative_sample_loss at step 81100: 0.101162\n",
      "2023-12-13 20:27:50,684 INFO     Training average loss at step 81100: 0.125450\n",
      "2023-12-13 20:30:03,293 INFO     Training average positive_sample_loss at step 81200: 0.151552\n",
      "2023-12-13 20:30:03,293 INFO     Training average negative_sample_loss at step 81200: 0.101705\n",
      "2023-12-13 20:30:03,293 INFO     Training average loss at step 81200: 0.126628\n",
      "2023-12-13 20:32:13,262 INFO     Training average positive_sample_loss at step 81300: 0.150298\n",
      "2023-12-13 20:32:13,263 INFO     Training average negative_sample_loss at step 81300: 0.101217\n",
      "2023-12-13 20:32:13,263 INFO     Training average loss at step 81300: 0.125758\n",
      "2023-12-13 20:34:16,122 INFO     Training average positive_sample_loss at step 81400: 0.150779\n",
      "2023-12-13 20:34:16,123 INFO     Training average negative_sample_loss at step 81400: 0.101502\n",
      "2023-12-13 20:34:16,123 INFO     Training average loss at step 81400: 0.126141\n",
      "2023-12-13 20:36:26,634 INFO     Training average positive_sample_loss at step 81500: 0.151332\n",
      "2023-12-13 20:36:26,634 INFO     Training average negative_sample_loss at step 81500: 0.101554\n",
      "2023-12-13 20:36:26,635 INFO     Training average loss at step 81500: 0.126443\n",
      "2023-12-13 20:38:32,925 INFO     Training average positive_sample_loss at step 81600: 0.150270\n",
      "2023-12-13 20:38:32,926 INFO     Training average negative_sample_loss at step 81600: 0.101624\n",
      "2023-12-13 20:38:32,926 INFO     Training average loss at step 81600: 0.125947\n",
      "2023-12-13 20:40:32,058 INFO     Training average positive_sample_loss at step 81700: 0.150159\n",
      "2023-12-13 20:40:32,058 INFO     Training average negative_sample_loss at step 81700: 0.101261\n",
      "2023-12-13 20:40:32,058 INFO     Training average loss at step 81700: 0.125710\n",
      "2023-12-13 20:42:51,461 INFO     Training average positive_sample_loss at step 81800: 0.151436\n",
      "2023-12-13 20:42:51,461 INFO     Training average negative_sample_loss at step 81800: 0.101469\n",
      "2023-12-13 20:42:51,462 INFO     Training average loss at step 81800: 0.126453\n",
      "2023-12-13 20:44:37,551 INFO     Training average positive_sample_loss at step 81900: 0.149684\n",
      "2023-12-13 20:44:37,551 INFO     Training average negative_sample_loss at step 81900: 0.101347\n",
      "2023-12-13 20:44:37,551 INFO     Training average loss at step 81900: 0.125515\n",
      "2023-12-13 20:46:39,867 INFO     Training average positive_sample_loss at step 82000: 0.151311\n",
      "2023-12-13 20:46:39,868 INFO     Training average negative_sample_loss at step 82000: 0.101332\n",
      "2023-12-13 20:46:39,868 INFO     Training average loss at step 82000: 0.126321\n",
      "2023-12-13 20:48:52,103 INFO     Training average positive_sample_loss at step 82100: 0.151060\n",
      "2023-12-13 20:48:52,103 INFO     Training average negative_sample_loss at step 82100: 0.101578\n",
      "2023-12-13 20:48:52,103 INFO     Training average loss at step 82100: 0.126319\n",
      "2023-12-13 20:50:55,336 INFO     Training average positive_sample_loss at step 82200: 0.150370\n",
      "2023-12-13 20:50:55,337 INFO     Training average negative_sample_loss at step 82200: 0.101389\n",
      "2023-12-13 20:50:55,337 INFO     Training average loss at step 82200: 0.125879\n",
      "2023-12-13 20:52:52,719 INFO     Training average positive_sample_loss at step 82300: 0.151202\n",
      "2023-12-13 20:52:52,719 INFO     Training average negative_sample_loss at step 82300: 0.101423\n",
      "2023-12-13 20:52:52,719 INFO     Training average loss at step 82300: 0.126312\n",
      "2023-12-13 20:55:08,251 INFO     Training average positive_sample_loss at step 82400: 0.150054\n",
      "2023-12-13 20:55:08,251 INFO     Training average negative_sample_loss at step 82400: 0.101294\n",
      "2023-12-13 20:55:08,251 INFO     Training average loss at step 82400: 0.125674\n",
      "2023-12-13 20:57:19,932 INFO     Training average positive_sample_loss at step 82500: 0.150442\n",
      "2023-12-13 20:57:19,933 INFO     Training average negative_sample_loss at step 82500: 0.101122\n",
      "2023-12-13 20:57:19,933 INFO     Training average loss at step 82500: 0.125782\n",
      "2023-12-13 20:59:34,786 INFO     Training average positive_sample_loss at step 82600: 0.151645\n",
      "2023-12-13 20:59:34,787 INFO     Training average negative_sample_loss at step 82600: 0.101874\n",
      "2023-12-13 20:59:34,787 INFO     Training average loss at step 82600: 0.126759\n",
      "2023-12-13 21:01:31,572 INFO     Training average positive_sample_loss at step 82700: 0.150883\n",
      "2023-12-13 21:01:31,573 INFO     Training average negative_sample_loss at step 82700: 0.101202\n",
      "2023-12-13 21:01:31,573 INFO     Training average loss at step 82700: 0.126042\n",
      "2023-12-13 21:03:43,225 INFO     Training average positive_sample_loss at step 82800: 0.150347\n",
      "2023-12-13 21:03:43,226 INFO     Training average negative_sample_loss at step 82800: 0.101457\n",
      "2023-12-13 21:03:43,226 INFO     Training average loss at step 82800: 0.125902\n",
      "2023-12-13 21:05:54,366 INFO     Training average positive_sample_loss at step 82900: 0.149781\n",
      "2023-12-13 21:05:54,366 INFO     Training average negative_sample_loss at step 82900: 0.101173\n",
      "2023-12-13 21:05:54,366 INFO     Training average loss at step 82900: 0.125477\n",
      "2023-12-13 21:08:08,271 INFO     Training average positive_sample_loss at step 83000: 0.151352\n",
      "2023-12-13 21:08:08,271 INFO     Training average negative_sample_loss at step 83000: 0.101725\n",
      "2023-12-13 21:08:08,271 INFO     Training average loss at step 83000: 0.126538\n",
      "2023-12-13 21:10:28,253 INFO     Training average positive_sample_loss at step 83100: 0.151024\n",
      "2023-12-13 21:10:28,253 INFO     Training average negative_sample_loss at step 83100: 0.101274\n",
      "2023-12-13 21:10:28,253 INFO     Training average loss at step 83100: 0.126149\n",
      "2023-12-13 21:12:37,166 INFO     Training average positive_sample_loss at step 83200: 0.150623\n",
      "2023-12-13 21:12:37,166 INFO     Training average negative_sample_loss at step 83200: 0.101493\n",
      "2023-12-13 21:12:37,166 INFO     Training average loss at step 83200: 0.126058\n",
      "2023-12-13 21:14:22,799 INFO     Training average positive_sample_loss at step 83300: 0.151045\n",
      "2023-12-13 21:14:22,799 INFO     Training average negative_sample_loss at step 83300: 0.101406\n",
      "2023-12-13 21:14:22,799 INFO     Training average loss at step 83300: 0.126226\n",
      "2023-12-13 21:16:37,308 INFO     Training average positive_sample_loss at step 83400: 0.149997\n",
      "2023-12-13 21:16:37,309 INFO     Training average negative_sample_loss at step 83400: 0.101612\n",
      "2023-12-13 21:16:37,309 INFO     Training average loss at step 83400: 0.125805\n",
      "2023-12-13 21:18:32,894 INFO     Training average positive_sample_loss at step 83500: 0.150736\n",
      "2023-12-13 21:18:32,895 INFO     Training average negative_sample_loss at step 83500: 0.101273\n",
      "2023-12-13 21:18:32,895 INFO     Training average loss at step 83500: 0.126005\n",
      "2023-12-13 21:21:01,313 INFO     Training average positive_sample_loss at step 83600: 0.151176\n",
      "2023-12-13 21:21:01,313 INFO     Training average negative_sample_loss at step 83600: 0.101636\n",
      "2023-12-13 21:21:01,313 INFO     Training average loss at step 83600: 0.126406\n",
      "2023-12-13 21:23:08,181 INFO     Training average positive_sample_loss at step 83700: 0.149744\n",
      "2023-12-13 21:23:08,182 INFO     Training average negative_sample_loss at step 83700: 0.101713\n",
      "2023-12-13 21:23:08,182 INFO     Training average loss at step 83700: 0.125729\n",
      "2023-12-13 21:25:14,626 INFO     Training average positive_sample_loss at step 83800: 0.150862\n",
      "2023-12-13 21:25:14,627 INFO     Training average negative_sample_loss at step 83800: 0.101229\n",
      "2023-12-13 21:25:14,627 INFO     Training average loss at step 83800: 0.126045\n",
      "2023-12-13 21:27:26,001 INFO     Training average positive_sample_loss at step 83900: 0.150827\n",
      "2023-12-13 21:27:26,001 INFO     Training average negative_sample_loss at step 83900: 0.101508\n",
      "2023-12-13 21:27:26,001 INFO     Training average loss at step 83900: 0.126168\n",
      "2023-12-13 21:29:25,687 INFO     Training average positive_sample_loss at step 84000: 0.150592\n",
      "2023-12-13 21:29:25,687 INFO     Training average negative_sample_loss at step 84000: 0.101320\n",
      "2023-12-13 21:29:25,687 INFO     Training average loss at step 84000: 0.125956\n",
      "2023-12-13 21:31:38,821 INFO     Training average positive_sample_loss at step 84100: 0.151328\n",
      "2023-12-13 21:31:38,821 INFO     Training average negative_sample_loss at step 84100: 0.101506\n",
      "2023-12-13 21:31:38,821 INFO     Training average loss at step 84100: 0.126417\n",
      "2023-12-13 21:33:55,864 INFO     Training average positive_sample_loss at step 84200: 0.149655\n",
      "2023-12-13 21:33:55,864 INFO     Training average negative_sample_loss at step 84200: 0.101327\n",
      "2023-12-13 21:33:55,864 INFO     Training average loss at step 84200: 0.125491\n",
      "2023-12-13 21:36:10,402 INFO     Training average positive_sample_loss at step 84300: 0.150714\n",
      "2023-12-13 21:36:10,403 INFO     Training average negative_sample_loss at step 84300: 0.101270\n",
      "2023-12-13 21:36:10,403 INFO     Training average loss at step 84300: 0.125992\n",
      "2023-12-13 21:38:20,046 INFO     Training average positive_sample_loss at step 84400: 0.150750\n",
      "2023-12-13 21:38:20,046 INFO     Training average negative_sample_loss at step 84400: 0.101606\n",
      "2023-12-13 21:38:20,046 INFO     Training average loss at step 84400: 0.126178\n",
      "2023-12-13 21:40:25,195 INFO     Training average positive_sample_loss at step 84500: 0.150965\n",
      "2023-12-13 21:40:25,195 INFO     Training average negative_sample_loss at step 84500: 0.101382\n",
      "2023-12-13 21:40:25,196 INFO     Training average loss at step 84500: 0.126174\n",
      "2023-12-13 21:42:25,485 INFO     Training average positive_sample_loss at step 84600: 0.151259\n",
      "2023-12-13 21:42:25,485 INFO     Training average negative_sample_loss at step 84600: 0.101711\n",
      "2023-12-13 21:42:25,486 INFO     Training average loss at step 84600: 0.126485\n",
      "2023-12-13 21:44:43,232 INFO     Training average positive_sample_loss at step 84700: 0.149930\n",
      "2023-12-13 21:44:43,232 INFO     Training average negative_sample_loss at step 84700: 0.101044\n",
      "2023-12-13 21:44:43,232 INFO     Training average loss at step 84700: 0.125487\n",
      "2023-12-13 21:46:35,263 INFO     Training average positive_sample_loss at step 84800: 0.150850\n",
      "2023-12-13 21:46:35,263 INFO     Training average negative_sample_loss at step 84800: 0.101577\n",
      "2023-12-13 21:46:35,263 INFO     Training average loss at step 84800: 0.126214\n",
      "2023-12-13 21:48:42,622 INFO     Training average positive_sample_loss at step 84900: 0.150950\n",
      "2023-12-13 21:48:42,622 INFO     Training average negative_sample_loss at step 84900: 0.101397\n",
      "2023-12-13 21:48:42,623 INFO     Training average loss at step 84900: 0.126173\n",
      "2023-12-13 21:50:38,471 INFO     Training average positive_sample_loss at step 85000: 0.149785\n",
      "2023-12-13 21:50:38,471 INFO     Training average negative_sample_loss at step 85000: 0.101402\n",
      "2023-12-13 21:50:38,471 INFO     Training average loss at step 85000: 0.125593\n",
      "2023-12-13 21:52:40,835 INFO     Training average positive_sample_loss at step 85100: 0.151655\n",
      "2023-12-13 21:52:40,836 INFO     Training average negative_sample_loss at step 85100: 0.101920\n",
      "2023-12-13 21:52:40,836 INFO     Training average loss at step 85100: 0.126788\n",
      "2023-12-13 21:54:56,885 INFO     Training average positive_sample_loss at step 85200: 0.149966\n",
      "2023-12-13 21:54:56,886 INFO     Training average negative_sample_loss at step 85200: 0.100665\n",
      "2023-12-13 21:54:56,886 INFO     Training average loss at step 85200: 0.125316\n",
      "2023-12-13 21:56:58,581 INFO     Training average positive_sample_loss at step 85300: 0.151167\n",
      "2023-12-13 21:56:58,581 INFO     Training average negative_sample_loss at step 85300: 0.101724\n",
      "2023-12-13 21:56:58,581 INFO     Training average loss at step 85300: 0.126446\n",
      "2023-12-13 21:59:23,524 INFO     Training average positive_sample_loss at step 85400: 0.151128\n",
      "2023-12-13 21:59:23,524 INFO     Training average negative_sample_loss at step 85400: 0.101433\n",
      "2023-12-13 21:59:23,525 INFO     Training average loss at step 85400: 0.126281\n",
      "2023-12-13 22:01:09,730 INFO     Training average positive_sample_loss at step 85500: 0.149803\n",
      "2023-12-13 22:01:09,731 INFO     Training average negative_sample_loss at step 85500: 0.101258\n",
      "2023-12-13 22:01:09,731 INFO     Training average loss at step 85500: 0.125530\n",
      "2023-12-13 22:03:16,027 INFO     Training average positive_sample_loss at step 85600: 0.151122\n",
      "2023-12-13 22:03:16,028 INFO     Training average negative_sample_loss at step 85600: 0.101374\n",
      "2023-12-13 22:03:16,028 INFO     Training average loss at step 85600: 0.126248\n",
      "2023-12-13 22:05:46,206 INFO     Training average positive_sample_loss at step 85700: 0.150720\n",
      "2023-12-13 22:05:46,207 INFO     Training average negative_sample_loss at step 85700: 0.101663\n",
      "2023-12-13 22:05:46,207 INFO     Training average loss at step 85700: 0.126192\n",
      "2023-12-13 22:07:40,299 INFO     Training average positive_sample_loss at step 85800: 0.150540\n",
      "2023-12-13 22:07:40,299 INFO     Training average negative_sample_loss at step 85800: 0.101619\n",
      "2023-12-13 22:07:40,299 INFO     Training average loss at step 85800: 0.126079\n",
      "2023-12-13 22:09:31,395 INFO     Training average positive_sample_loss at step 85900: 0.151581\n",
      "2023-12-13 22:09:31,395 INFO     Training average negative_sample_loss at step 85900: 0.101373\n",
      "2023-12-13 22:09:31,396 INFO     Training average loss at step 85900: 0.126477\n",
      "2023-12-13 22:11:39,505 INFO     Training average positive_sample_loss at step 86000: 0.149686\n",
      "2023-12-13 22:11:39,505 INFO     Training average negative_sample_loss at step 86000: 0.101452\n",
      "2023-12-13 22:11:39,505 INFO     Training average loss at step 86000: 0.125569\n",
      "2023-12-13 22:13:38,836 INFO     Training average positive_sample_loss at step 86100: 0.150744\n",
      "2023-12-13 22:13:38,837 INFO     Training average negative_sample_loss at step 86100: 0.101043\n",
      "2023-12-13 22:13:38,837 INFO     Training average loss at step 86100: 0.125894\n",
      "2023-12-13 22:15:49,894 INFO     Training average positive_sample_loss at step 86200: 0.151067\n",
      "2023-12-13 22:15:49,895 INFO     Training average negative_sample_loss at step 86200: 0.101558\n",
      "2023-12-13 22:15:49,895 INFO     Training average loss at step 86200: 0.126313\n",
      "2023-12-13 22:17:53,838 INFO     Training average positive_sample_loss at step 86300: 0.150098\n",
      "2023-12-13 22:17:53,838 INFO     Training average negative_sample_loss at step 86300: 0.101379\n",
      "2023-12-13 22:17:53,838 INFO     Training average loss at step 86300: 0.125739\n",
      "2023-12-13 22:20:09,156 INFO     Training average positive_sample_loss at step 86400: 0.151445\n",
      "2023-12-13 22:20:09,156 INFO     Training average negative_sample_loss at step 86400: 0.101363\n",
      "2023-12-13 22:20:09,156 INFO     Training average loss at step 86400: 0.126404\n",
      "2023-12-13 22:22:23,864 INFO     Training average positive_sample_loss at step 86500: 0.149908\n",
      "2023-12-13 22:22:23,865 INFO     Training average negative_sample_loss at step 86500: 0.101382\n",
      "2023-12-13 22:22:23,865 INFO     Training average loss at step 86500: 0.125645\n",
      "2023-12-13 22:24:36,314 INFO     Training average positive_sample_loss at step 86600: 0.150350\n",
      "2023-12-13 22:24:36,314 INFO     Training average negative_sample_loss at step 86600: 0.101117\n",
      "2023-12-13 22:24:36,314 INFO     Training average loss at step 86600: 0.125733\n",
      "2023-12-13 22:27:01,220 INFO     Training average positive_sample_loss at step 86700: 0.151744\n",
      "2023-12-13 22:27:01,221 INFO     Training average negative_sample_loss at step 86700: 0.101904\n",
      "2023-12-13 22:27:01,221 INFO     Training average loss at step 86700: 0.126824\n",
      "2023-12-13 22:29:00,795 INFO     Training average positive_sample_loss at step 86800: 0.150542\n",
      "2023-12-13 22:29:00,796 INFO     Training average negative_sample_loss at step 86800: 0.101410\n",
      "2023-12-13 22:29:00,796 INFO     Training average loss at step 86800: 0.125976\n",
      "2023-12-13 22:31:09,378 INFO     Training average positive_sample_loss at step 86900: 0.150439\n",
      "2023-12-13 22:31:09,379 INFO     Training average negative_sample_loss at step 86900: 0.101020\n",
      "2023-12-13 22:31:09,379 INFO     Training average loss at step 86900: 0.125730\n",
      "2023-12-13 22:33:20,658 INFO     Training average positive_sample_loss at step 87000: 0.150328\n",
      "2023-12-13 22:33:20,658 INFO     Training average negative_sample_loss at step 87000: 0.101196\n",
      "2023-12-13 22:33:20,658 INFO     Training average loss at step 87000: 0.125762\n",
      "2023-12-13 22:35:16,227 INFO     Training average positive_sample_loss at step 87100: 0.150438\n",
      "2023-12-13 22:35:16,228 INFO     Training average negative_sample_loss at step 87100: 0.101189\n",
      "2023-12-13 22:35:16,228 INFO     Training average loss at step 87100: 0.125813\n",
      "2023-12-13 22:37:18,963 INFO     Training average positive_sample_loss at step 87200: 0.151655\n",
      "2023-12-13 22:37:18,964 INFO     Training average negative_sample_loss at step 87200: 0.101374\n",
      "2023-12-13 22:37:18,964 INFO     Training average loss at step 87200: 0.126515\n",
      "2023-12-13 22:39:34,001 INFO     Training average positive_sample_loss at step 87300: 0.149037\n",
      "2023-12-13 22:39:34,002 INFO     Training average negative_sample_loss at step 87300: 0.101197\n",
      "2023-12-13 22:39:34,002 INFO     Training average loss at step 87300: 0.125117\n",
      "2023-12-13 22:41:37,683 INFO     Training average positive_sample_loss at step 87400: 0.151892\n",
      "2023-12-13 22:41:37,684 INFO     Training average negative_sample_loss at step 87400: 0.101662\n",
      "2023-12-13 22:41:37,684 INFO     Training average loss at step 87400: 0.126777\n",
      "2023-12-13 22:43:55,128 INFO     Training average positive_sample_loss at step 87500: 0.151036\n",
      "2023-12-13 22:43:55,128 INFO     Training average negative_sample_loss at step 87500: 0.101419\n",
      "2023-12-13 22:43:55,128 INFO     Training average loss at step 87500: 0.126228\n",
      "2023-12-13 22:45:49,984 INFO     Training average positive_sample_loss at step 87600: 0.149858\n",
      "2023-12-13 22:45:49,984 INFO     Training average negative_sample_loss at step 87600: 0.101261\n",
      "2023-12-13 22:45:49,984 INFO     Training average loss at step 87600: 0.125559\n",
      "2023-12-13 22:47:46,308 INFO     Training average positive_sample_loss at step 87700: 0.151351\n",
      "2023-12-13 22:47:46,308 INFO     Training average negative_sample_loss at step 87700: 0.101328\n",
      "2023-12-13 22:47:46,308 INFO     Training average loss at step 87700: 0.126339\n",
      "2023-12-13 22:50:02,899 INFO     Training average positive_sample_loss at step 87800: 0.149371\n",
      "2023-12-13 22:50:02,900 INFO     Training average negative_sample_loss at step 87800: 0.100743\n",
      "2023-12-13 22:50:02,900 INFO     Training average loss at step 87800: 0.125057\n",
      "2023-12-13 22:52:05,936 INFO     Training average positive_sample_loss at step 87900: 0.150615\n",
      "2023-12-13 22:52:05,937 INFO     Training average negative_sample_loss at step 87900: 0.101331\n",
      "2023-12-13 22:52:05,937 INFO     Training average loss at step 87900: 0.125973\n",
      "2023-12-13 22:54:34,162 INFO     Training average positive_sample_loss at step 88000: 0.151854\n",
      "2023-12-13 22:54:34,163 INFO     Training average negative_sample_loss at step 88000: 0.101629\n",
      "2023-12-13 22:54:34,163 INFO     Training average loss at step 88000: 0.126741\n",
      "2023-12-13 22:56:31,331 INFO     Training average positive_sample_loss at step 88100: 0.151111\n",
      "2023-12-13 22:56:31,332 INFO     Training average negative_sample_loss at step 88100: 0.101866\n",
      "2023-12-13 22:56:31,332 INFO     Training average loss at step 88100: 0.126488\n",
      "2023-12-13 22:58:29,325 INFO     Training average positive_sample_loss at step 88200: 0.150066\n",
      "2023-12-13 22:58:29,325 INFO     Training average negative_sample_loss at step 88200: 0.101401\n",
      "2023-12-13 22:58:29,325 INFO     Training average loss at step 88200: 0.125734\n",
      "2023-12-13 23:00:51,027 INFO     Training average positive_sample_loss at step 88300: 0.149999\n",
      "2023-12-13 23:00:51,028 INFO     Training average negative_sample_loss at step 88300: 0.100907\n",
      "2023-12-13 23:00:51,028 INFO     Training average loss at step 88300: 0.125453\n",
      "2023-12-13 23:02:45,624 INFO     Training average positive_sample_loss at step 88400: 0.149848\n",
      "2023-12-13 23:02:45,625 INFO     Training average negative_sample_loss at step 88400: 0.101007\n",
      "2023-12-13 23:02:45,625 INFO     Training average loss at step 88400: 0.125428\n",
      "2023-12-13 23:05:07,931 INFO     Training average positive_sample_loss at step 88500: 0.152110\n",
      "2023-12-13 23:05:07,931 INFO     Training average negative_sample_loss at step 88500: 0.101864\n",
      "2023-12-13 23:05:07,931 INFO     Training average loss at step 88500: 0.126987\n",
      "2023-12-13 23:07:05,030 INFO     Training average positive_sample_loss at step 88600: 0.149533\n",
      "2023-12-13 23:07:05,031 INFO     Training average negative_sample_loss at step 88600: 0.101374\n",
      "2023-12-13 23:07:05,031 INFO     Training average loss at step 88600: 0.125454\n",
      "2023-12-13 23:09:03,298 INFO     Training average positive_sample_loss at step 88700: 0.151237\n",
      "2023-12-13 23:09:03,298 INFO     Training average negative_sample_loss at step 88700: 0.101423\n",
      "2023-12-13 23:09:03,298 INFO     Training average loss at step 88700: 0.126330\n",
      "2023-12-13 23:11:16,622 INFO     Training average positive_sample_loss at step 88800: 0.150228\n",
      "2023-12-13 23:11:16,623 INFO     Training average negative_sample_loss at step 88800: 0.101055\n",
      "2023-12-13 23:11:16,623 INFO     Training average loss at step 88800: 0.125641\n",
      "2023-12-13 23:13:17,537 INFO     Training average positive_sample_loss at step 88900: 0.150045\n",
      "2023-12-13 23:13:17,537 INFO     Training average negative_sample_loss at step 88900: 0.101113\n",
      "2023-12-13 23:13:17,537 INFO     Training average loss at step 88900: 0.125579\n",
      "2023-12-13 23:15:19,979 INFO     Training average positive_sample_loss at step 89000: 0.152150\n",
      "2023-12-13 23:15:19,979 INFO     Training average negative_sample_loss at step 89000: 0.101766\n",
      "2023-12-13 23:15:19,979 INFO     Training average loss at step 89000: 0.126958\n",
      "2023-12-13 23:17:36,001 INFO     Training average positive_sample_loss at step 89100: 0.149339\n",
      "2023-12-13 23:17:36,002 INFO     Training average negative_sample_loss at step 89100: 0.101202\n",
      "2023-12-13 23:17:36,002 INFO     Training average loss at step 89100: 0.125270\n",
      "2023-12-13 23:19:32,340 INFO     Training average positive_sample_loss at step 89200: 0.151090\n",
      "2023-12-13 23:19:32,340 INFO     Training average negative_sample_loss at step 89200: 0.101354\n",
      "2023-12-13 23:19:32,340 INFO     Training average loss at step 89200: 0.126222\n",
      "2023-12-13 23:21:54,818 INFO     Training average positive_sample_loss at step 89300: 0.150627\n",
      "2023-12-13 23:21:54,819 INFO     Training average negative_sample_loss at step 89300: 0.101266\n",
      "2023-12-13 23:21:54,819 INFO     Training average loss at step 89300: 0.125947\n",
      "2023-12-13 23:23:56,821 INFO     Training average positive_sample_loss at step 89400: 0.150297\n",
      "2023-12-13 23:23:56,822 INFO     Training average negative_sample_loss at step 89400: 0.101485\n",
      "2023-12-13 23:23:56,822 INFO     Training average loss at step 89400: 0.125891\n",
      "2023-12-13 23:25:55,111 INFO     Training average positive_sample_loss at step 89500: 0.151232\n",
      "2023-12-13 23:25:55,112 INFO     Training average negative_sample_loss at step 89500: 0.101424\n",
      "2023-12-13 23:25:55,112 INFO     Training average loss at step 89500: 0.126328\n",
      "2023-12-13 23:28:11,607 INFO     Training average positive_sample_loss at step 89600: 0.149805\n",
      "2023-12-13 23:28:11,607 INFO     Training average negative_sample_loss at step 89600: 0.101553\n",
      "2023-12-13 23:28:11,607 INFO     Training average loss at step 89600: 0.125679\n",
      "2023-12-13 23:30:18,969 INFO     Training average positive_sample_loss at step 89700: 0.150778\n",
      "2023-12-13 23:30:18,969 INFO     Training average negative_sample_loss at step 89700: 0.101111\n",
      "2023-12-13 23:30:18,969 INFO     Training average loss at step 89700: 0.125944\n",
      "2023-12-13 23:32:30,444 INFO     Training average positive_sample_loss at step 89800: 0.151744\n",
      "2023-12-13 23:32:30,444 INFO     Training average negative_sample_loss at step 89800: 0.101359\n",
      "2023-12-13 23:32:30,444 INFO     Training average loss at step 89800: 0.126551\n",
      "2023-12-13 23:34:28,093 INFO     Training average positive_sample_loss at step 89900: 0.149522\n",
      "2023-12-13 23:34:28,094 INFO     Training average negative_sample_loss at step 89900: 0.101128\n",
      "2023-12-13 23:34:28,094 INFO     Training average loss at step 89900: 0.125325\n",
      "2023-12-13 23:36:38,056 INFO     Training average positive_sample_loss at step 90000: 0.151289\n",
      "2023-12-13 23:36:38,056 INFO     Training average negative_sample_loss at step 90000: 0.101481\n",
      "2023-12-13 23:36:38,057 INFO     Training average loss at step 90000: 0.126385\n",
      "2023-12-13 23:36:38,057 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-13 23:36:38,719 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-13 23:37:04,805 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-13 23:37:22,759 INFO     Valid MRR at step 90000: 0.420952\n",
      "2023-12-13 23:37:22,760 INFO     Valid MR at step 90000: 690.029402\n",
      "2023-12-13 23:37:22,760 INFO     Valid HITS@1 at step 90000: 0.393751\n",
      "2023-12-13 23:37:22,760 INFO     Valid HITS@3 at step 90000: 0.424006\n",
      "2023-12-13 23:37:22,760 INFO     Valid HITS@10 at step 90000: 0.470325\n",
      "2023-12-13 23:39:18,464 INFO     Training average positive_sample_loss at step 90100: 0.150706\n",
      "2023-12-13 23:39:18,464 INFO     Training average negative_sample_loss at step 90100: 0.101374\n",
      "2023-12-13 23:39:18,464 INFO     Training average loss at step 90100: 0.126040\n",
      "2023-12-13 23:41:32,725 INFO     Training average positive_sample_loss at step 90200: 0.150381\n",
      "2023-12-13 23:41:32,725 INFO     Training average negative_sample_loss at step 90200: 0.101443\n",
      "2023-12-13 23:41:32,725 INFO     Training average loss at step 90200: 0.125912\n",
      "2023-12-13 23:43:45,674 INFO     Training average positive_sample_loss at step 90300: 0.151162\n",
      "2023-12-13 23:43:45,674 INFO     Training average negative_sample_loss at step 90300: 0.101338\n",
      "2023-12-13 23:43:45,674 INFO     Training average loss at step 90300: 0.126250\n",
      "2023-12-13 23:45:42,860 INFO     Training average positive_sample_loss at step 90400: 0.150143\n",
      "2023-12-13 23:45:42,861 INFO     Training average negative_sample_loss at step 90400: 0.101229\n",
      "2023-12-13 23:45:42,861 INFO     Training average loss at step 90400: 0.125686\n",
      "2023-12-13 23:47:39,054 INFO     Training average positive_sample_loss at step 90500: 0.150084\n",
      "2023-12-13 23:47:39,054 INFO     Training average negative_sample_loss at step 90500: 0.101328\n",
      "2023-12-13 23:47:39,055 INFO     Training average loss at step 90500: 0.125706\n",
      "2023-12-13 23:49:47,419 INFO     Training average positive_sample_loss at step 90600: 0.150637\n",
      "2023-12-13 23:49:47,419 INFO     Training average negative_sample_loss at step 90600: 0.101309\n",
      "2023-12-13 23:49:47,419 INFO     Training average loss at step 90600: 0.125973\n",
      "2023-12-13 23:51:55,323 INFO     Training average positive_sample_loss at step 90700: 0.150534\n",
      "2023-12-13 23:51:55,324 INFO     Training average negative_sample_loss at step 90700: 0.101382\n",
      "2023-12-13 23:51:55,324 INFO     Training average loss at step 90700: 0.125958\n",
      "2023-12-13 23:54:03,318 INFO     Training average positive_sample_loss at step 90800: 0.151514\n",
      "2023-12-13 23:54:03,318 INFO     Training average negative_sample_loss at step 90800: 0.101162\n",
      "2023-12-13 23:54:03,319 INFO     Training average loss at step 90800: 0.126338\n",
      "2023-12-13 23:56:14,944 INFO     Training average positive_sample_loss at step 90900: 0.150529\n",
      "2023-12-13 23:56:14,945 INFO     Training average negative_sample_loss at step 90900: 0.101467\n",
      "2023-12-13 23:56:14,945 INFO     Training average loss at step 90900: 0.125998\n",
      "2023-12-13 23:58:23,426 INFO     Training average positive_sample_loss at step 91000: 0.150183\n",
      "2023-12-13 23:58:23,427 INFO     Training average negative_sample_loss at step 91000: 0.101058\n",
      "2023-12-13 23:58:23,427 INFO     Training average loss at step 91000: 0.125620\n",
      "2023-12-14 00:00:38,222 INFO     Training average positive_sample_loss at step 91100: 0.150711\n",
      "2023-12-14 00:00:38,222 INFO     Training average negative_sample_loss at step 91100: 0.101573\n",
      "2023-12-14 00:00:38,223 INFO     Training average loss at step 91100: 0.126142\n",
      "2023-12-14 00:02:42,321 INFO     Training average positive_sample_loss at step 91200: 0.149859\n",
      "2023-12-14 00:02:42,321 INFO     Training average negative_sample_loss at step 91200: 0.101258\n",
      "2023-12-14 00:02:42,321 INFO     Training average loss at step 91200: 0.125558\n",
      "2023-12-14 00:04:47,696 INFO     Training average positive_sample_loss at step 91300: 0.151172\n",
      "2023-12-14 00:04:47,697 INFO     Training average negative_sample_loss at step 91300: 0.101055\n",
      "2023-12-14 00:04:47,697 INFO     Training average loss at step 91300: 0.126113\n",
      "2023-12-14 00:06:54,246 INFO     Training average positive_sample_loss at step 91400: 0.150306\n",
      "2023-12-14 00:06:54,247 INFO     Training average negative_sample_loss at step 91400: 0.101686\n",
      "2023-12-14 00:06:54,247 INFO     Training average loss at step 91400: 0.125996\n",
      "2023-12-14 00:08:46,982 INFO     Training average positive_sample_loss at step 91500: 0.150497\n",
      "2023-12-14 00:08:46,983 INFO     Training average negative_sample_loss at step 91500: 0.101323\n",
      "2023-12-14 00:08:46,983 INFO     Training average loss at step 91500: 0.125910\n",
      "2023-12-14 00:10:49,515 INFO     Training average positive_sample_loss at step 91600: 0.151308\n",
      "2023-12-14 00:10:49,515 INFO     Training average negative_sample_loss at step 91600: 0.100895\n",
      "2023-12-14 00:10:49,515 INFO     Training average loss at step 91600: 0.126101\n",
      "2023-12-14 00:12:59,260 INFO     Training average positive_sample_loss at step 91700: 0.149964\n",
      "2023-12-14 00:12:59,260 INFO     Training average negative_sample_loss at step 91700: 0.101145\n",
      "2023-12-14 00:12:59,260 INFO     Training average loss at step 91700: 0.125555\n",
      "2023-12-14 00:15:03,595 INFO     Training average positive_sample_loss at step 91800: 0.150467\n",
      "2023-12-14 00:15:03,595 INFO     Training average negative_sample_loss at step 91800: 0.101345\n",
      "2023-12-14 00:15:03,595 INFO     Training average loss at step 91800: 0.125906\n",
      "2023-12-14 00:17:09,962 INFO     Training average positive_sample_loss at step 91900: 0.150323\n",
      "2023-12-14 00:17:09,963 INFO     Training average negative_sample_loss at step 91900: 0.101038\n",
      "2023-12-14 00:17:09,963 INFO     Training average loss at step 91900: 0.125681\n",
      "2023-12-14 00:19:15,803 INFO     Training average positive_sample_loss at step 92000: 0.150704\n",
      "2023-12-14 00:19:15,804 INFO     Training average negative_sample_loss at step 92000: 0.101587\n",
      "2023-12-14 00:19:15,804 INFO     Training average loss at step 92000: 0.126145\n",
      "2023-12-14 00:21:15,234 INFO     Training average positive_sample_loss at step 92100: 0.151424\n",
      "2023-12-14 00:21:15,234 INFO     Training average negative_sample_loss at step 92100: 0.101256\n",
      "2023-12-14 00:21:15,234 INFO     Training average loss at step 92100: 0.126340\n",
      "2023-12-14 00:23:30,757 INFO     Training average positive_sample_loss at step 92200: 0.149451\n",
      "2023-12-14 00:23:30,758 INFO     Training average negative_sample_loss at step 92200: 0.101147\n",
      "2023-12-14 00:23:30,758 INFO     Training average loss at step 92200: 0.125299\n",
      "2023-12-14 00:25:34,414 INFO     Training average positive_sample_loss at step 92300: 0.151281\n",
      "2023-12-14 00:25:34,415 INFO     Training average negative_sample_loss at step 92300: 0.101524\n",
      "2023-12-14 00:25:34,415 INFO     Training average loss at step 92300: 0.126403\n",
      "2023-12-14 00:27:47,123 INFO     Training average positive_sample_loss at step 92400: 0.150663\n",
      "2023-12-14 00:27:47,124 INFO     Training average negative_sample_loss at step 92400: 0.101265\n",
      "2023-12-14 00:27:47,124 INFO     Training average loss at step 92400: 0.125964\n",
      "2023-12-14 00:29:55,053 INFO     Training average positive_sample_loss at step 92500: 0.149660\n",
      "2023-12-14 00:29:55,054 INFO     Training average negative_sample_loss at step 92500: 0.100820\n",
      "2023-12-14 00:29:55,054 INFO     Training average loss at step 92500: 0.125240\n",
      "2023-12-14 00:32:14,862 INFO     Training average positive_sample_loss at step 92600: 0.151883\n",
      "2023-12-14 00:32:14,863 INFO     Training average negative_sample_loss at step 92600: 0.101630\n",
      "2023-12-14 00:32:14,863 INFO     Training average loss at step 92600: 0.126756\n",
      "2023-12-14 00:34:22,843 INFO     Training average positive_sample_loss at step 92700: 0.150204\n",
      "2023-12-14 00:34:22,844 INFO     Training average negative_sample_loss at step 92700: 0.101503\n",
      "2023-12-14 00:34:22,844 INFO     Training average loss at step 92700: 0.125853\n",
      "2023-12-14 00:36:20,691 INFO     Training average positive_sample_loss at step 92800: 0.150320\n",
      "2023-12-14 00:36:20,692 INFO     Training average negative_sample_loss at step 92800: 0.101201\n",
      "2023-12-14 00:36:20,692 INFO     Training average loss at step 92800: 0.125761\n",
      "2023-12-14 00:38:34,939 INFO     Training average positive_sample_loss at step 92900: 0.150929\n",
      "2023-12-14 00:38:34,940 INFO     Training average negative_sample_loss at step 92900: 0.101267\n",
      "2023-12-14 00:38:34,940 INFO     Training average loss at step 92900: 0.126098\n",
      "2023-12-14 00:40:32,704 INFO     Training average positive_sample_loss at step 93000: 0.150410\n",
      "2023-12-14 00:40:32,705 INFO     Training average negative_sample_loss at step 93000: 0.101631\n",
      "2023-12-14 00:40:32,705 INFO     Training average loss at step 93000: 0.126020\n",
      "2023-12-14 00:42:36,391 INFO     Training average positive_sample_loss at step 93100: 0.151187\n",
      "2023-12-14 00:42:36,391 INFO     Training average negative_sample_loss at step 93100: 0.101366\n",
      "2023-12-14 00:42:36,391 INFO     Training average loss at step 93100: 0.126276\n",
      "2023-12-14 00:44:55,827 INFO     Training average positive_sample_loss at step 93200: 0.150007\n",
      "2023-12-14 00:44:55,827 INFO     Training average negative_sample_loss at step 93200: 0.101459\n",
      "2023-12-14 00:44:55,827 INFO     Training average loss at step 93200: 0.125733\n",
      "2023-12-14 00:46:54,897 INFO     Training average positive_sample_loss at step 93300: 0.149828\n",
      "2023-12-14 00:46:54,897 INFO     Training average negative_sample_loss at step 93300: 0.101095\n",
      "2023-12-14 00:46:54,897 INFO     Training average loss at step 93300: 0.125462\n",
      "2023-12-14 00:49:08,886 INFO     Training average positive_sample_loss at step 93400: 0.151903\n",
      "2023-12-14 00:49:08,886 INFO     Training average negative_sample_loss at step 93400: 0.101671\n",
      "2023-12-14 00:49:08,886 INFO     Training average loss at step 93400: 0.126787\n",
      "2023-12-14 00:51:07,652 INFO     Training average positive_sample_loss at step 93500: 0.149981\n",
      "2023-12-14 00:51:07,652 INFO     Training average negative_sample_loss at step 93500: 0.101194\n",
      "2023-12-14 00:51:07,652 INFO     Training average loss at step 93500: 0.125587\n",
      "2023-12-14 00:53:06,165 INFO     Training average positive_sample_loss at step 93600: 0.150966\n",
      "2023-12-14 00:53:06,166 INFO     Training average negative_sample_loss at step 93600: 0.101300\n",
      "2023-12-14 00:53:06,166 INFO     Training average loss at step 93600: 0.126133\n",
      "2023-12-14 00:55:21,794 INFO     Training average positive_sample_loss at step 93700: 0.150108\n",
      "2023-12-14 00:55:21,794 INFO     Training average negative_sample_loss at step 93700: 0.101691\n",
      "2023-12-14 00:55:21,794 INFO     Training average loss at step 93700: 0.125900\n",
      "2023-12-14 00:57:21,901 INFO     Training average positive_sample_loss at step 93800: 0.150292\n",
      "2023-12-14 00:57:21,902 INFO     Training average negative_sample_loss at step 93800: 0.101298\n",
      "2023-12-14 00:57:21,902 INFO     Training average loss at step 93800: 0.125795\n",
      "2023-12-14 00:59:25,998 INFO     Training average positive_sample_loss at step 93900: 0.151487\n",
      "2023-12-14 00:59:25,998 INFO     Training average negative_sample_loss at step 93900: 0.101277\n",
      "2023-12-14 00:59:25,998 INFO     Training average loss at step 93900: 0.126382\n",
      "2023-12-14 01:01:33,506 INFO     Training average positive_sample_loss at step 94000: 0.149300\n",
      "2023-12-14 01:01:33,506 INFO     Training average negative_sample_loss at step 94000: 0.101003\n",
      "2023-12-14 01:01:33,506 INFO     Training average loss at step 94000: 0.125151\n",
      "2023-12-14 01:03:24,976 INFO     Training average positive_sample_loss at step 94100: 0.151109\n",
      "2023-12-14 01:03:24,977 INFO     Training average negative_sample_loss at step 94100: 0.101539\n",
      "2023-12-14 01:03:24,977 INFO     Training average loss at step 94100: 0.126324\n",
      "2023-12-14 01:05:34,869 INFO     Training average positive_sample_loss at step 94200: 0.150766\n",
      "2023-12-14 01:05:34,869 INFO     Training average negative_sample_loss at step 94200: 0.100998\n",
      "2023-12-14 01:05:34,869 INFO     Training average loss at step 94200: 0.125882\n",
      "2023-12-14 01:07:32,560 INFO     Training average positive_sample_loss at step 94300: 0.150006\n",
      "2023-12-14 01:07:32,561 INFO     Training average negative_sample_loss at step 94300: 0.101465\n",
      "2023-12-14 01:07:32,561 INFO     Training average loss at step 94300: 0.125736\n",
      "2023-12-14 01:09:33,925 INFO     Training average positive_sample_loss at step 94400: 0.150880\n",
      "2023-12-14 01:09:33,926 INFO     Training average negative_sample_loss at step 94400: 0.101568\n",
      "2023-12-14 01:09:33,926 INFO     Training average loss at step 94400: 0.126224\n",
      "2023-12-14 01:11:47,801 INFO     Training average positive_sample_loss at step 94500: 0.150729\n",
      "2023-12-14 01:11:47,802 INFO     Training average negative_sample_loss at step 94500: 0.101322\n",
      "2023-12-14 01:11:47,802 INFO     Training average loss at step 94500: 0.126025\n",
      "2023-12-14 01:13:32,835 INFO     Training average positive_sample_loss at step 94600: 0.150471\n",
      "2023-12-14 01:13:32,835 INFO     Training average negative_sample_loss at step 94600: 0.101410\n",
      "2023-12-14 01:13:32,835 INFO     Training average loss at step 94600: 0.125940\n",
      "2023-12-14 01:15:49,330 INFO     Training average positive_sample_loss at step 94700: 0.151116\n",
      "2023-12-14 01:15:49,330 INFO     Training average negative_sample_loss at step 94700: 0.101482\n",
      "2023-12-14 01:15:49,330 INFO     Training average loss at step 94700: 0.126299\n",
      "2023-12-14 01:17:46,063 INFO     Training average positive_sample_loss at step 94800: 0.149878\n",
      "2023-12-14 01:17:46,063 INFO     Training average negative_sample_loss at step 94800: 0.101138\n",
      "2023-12-14 01:17:46,063 INFO     Training average loss at step 94800: 0.125508\n",
      "2023-12-14 01:19:46,585 INFO     Training average positive_sample_loss at step 94900: 0.151235\n",
      "2023-12-14 01:19:46,586 INFO     Training average negative_sample_loss at step 94900: 0.101695\n",
      "2023-12-14 01:19:46,586 INFO     Training average loss at step 94900: 0.126465\n",
      "2023-12-14 01:22:02,729 INFO     Training average positive_sample_loss at step 95000: 0.150112\n",
      "2023-12-14 01:22:02,730 INFO     Training average negative_sample_loss at step 95000: 0.101437\n",
      "2023-12-14 01:22:02,730 INFO     Training average loss at step 95000: 0.125775\n",
      "2023-12-14 01:24:15,634 INFO     Training average positive_sample_loss at step 95100: 0.150183\n",
      "2023-12-14 01:24:15,635 INFO     Training average negative_sample_loss at step 95100: 0.100930\n",
      "2023-12-14 01:24:15,635 INFO     Training average loss at step 95100: 0.125556\n",
      "2023-12-14 01:26:34,928 INFO     Training average positive_sample_loss at step 95200: 0.151459\n",
      "2023-12-14 01:26:34,928 INFO     Training average negative_sample_loss at step 95200: 0.101167\n",
      "2023-12-14 01:26:34,928 INFO     Training average loss at step 95200: 0.126313\n",
      "2023-12-14 01:28:43,981 INFO     Training average positive_sample_loss at step 95300: 0.149595\n",
      "2023-12-14 01:28:43,981 INFO     Training average negative_sample_loss at step 95300: 0.101078\n",
      "2023-12-14 01:28:43,981 INFO     Training average loss at step 95300: 0.125337\n",
      "2023-12-14 01:30:40,930 INFO     Training average positive_sample_loss at step 95400: 0.150496\n",
      "2023-12-14 01:30:40,930 INFO     Training average negative_sample_loss at step 95400: 0.101507\n",
      "2023-12-14 01:30:40,931 INFO     Training average loss at step 95400: 0.126001\n",
      "2023-12-14 01:32:49,192 INFO     Training average positive_sample_loss at step 95500: 0.151602\n",
      "2023-12-14 01:32:49,193 INFO     Training average negative_sample_loss at step 95500: 0.101787\n",
      "2023-12-14 01:32:49,193 INFO     Training average loss at step 95500: 0.126695\n",
      "2023-12-14 01:34:48,291 INFO     Training average positive_sample_loss at step 95600: 0.150058\n",
      "2023-12-14 01:34:48,291 INFO     Training average negative_sample_loss at step 95600: 0.101467\n",
      "2023-12-14 01:34:48,292 INFO     Training average loss at step 95600: 0.125762\n",
      "2023-12-14 01:36:53,999 INFO     Training average positive_sample_loss at step 95700: 0.150805\n",
      "2023-12-14 01:36:53,999 INFO     Training average negative_sample_loss at step 95700: 0.100964\n",
      "2023-12-14 01:36:53,999 INFO     Training average loss at step 95700: 0.125885\n",
      "2023-12-14 01:38:59,630 INFO     Training average positive_sample_loss at step 95800: 0.150110\n",
      "2023-12-14 01:38:59,631 INFO     Training average negative_sample_loss at step 95800: 0.101733\n",
      "2023-12-14 01:38:59,631 INFO     Training average loss at step 95800: 0.125922\n",
      "2023-12-14 01:41:10,717 INFO     Training average positive_sample_loss at step 95900: 0.150507\n",
      "2023-12-14 01:41:10,717 INFO     Training average negative_sample_loss at step 95900: 0.101311\n",
      "2023-12-14 01:41:10,717 INFO     Training average loss at step 95900: 0.125909\n",
      "2023-12-14 01:43:18,970 INFO     Training average positive_sample_loss at step 96000: 0.151170\n",
      "2023-12-14 01:43:18,970 INFO     Training average negative_sample_loss at step 96000: 0.101285\n",
      "2023-12-14 01:43:18,970 INFO     Training average loss at step 96000: 0.126228\n",
      "2023-12-14 01:45:22,510 INFO     Training average positive_sample_loss at step 96100: 0.150541\n",
      "2023-12-14 01:45:22,510 INFO     Training average negative_sample_loss at step 96100: 0.101394\n",
      "2023-12-14 01:45:22,511 INFO     Training average loss at step 96100: 0.125967\n",
      "2023-12-14 01:47:33,357 INFO     Training average positive_sample_loss at step 96200: 0.150480\n",
      "2023-12-14 01:47:33,358 INFO     Training average negative_sample_loss at step 96200: 0.101139\n",
      "2023-12-14 01:47:33,358 INFO     Training average loss at step 96200: 0.125809\n",
      "2023-12-14 01:49:53,096 INFO     Training average positive_sample_loss at step 96300: 0.149645\n",
      "2023-12-14 01:49:53,096 INFO     Training average negative_sample_loss at step 96300: 0.101176\n",
      "2023-12-14 01:49:53,096 INFO     Training average loss at step 96300: 0.125410\n",
      "2023-12-14 01:51:50,169 INFO     Training average positive_sample_loss at step 96400: 0.150690\n",
      "2023-12-14 01:51:50,170 INFO     Training average negative_sample_loss at step 96400: 0.101189\n",
      "2023-12-14 01:51:50,170 INFO     Training average loss at step 96400: 0.125940\n",
      "2023-12-14 01:53:56,884 INFO     Training average positive_sample_loss at step 96500: 0.151493\n",
      "2023-12-14 01:53:56,884 INFO     Training average negative_sample_loss at step 96500: 0.101368\n",
      "2023-12-14 01:53:56,884 INFO     Training average loss at step 96500: 0.126431\n",
      "2023-12-14 01:56:00,746 INFO     Training average positive_sample_loss at step 96600: 0.149951\n",
      "2023-12-14 01:56:00,746 INFO     Training average negative_sample_loss at step 96600: 0.100915\n",
      "2023-12-14 01:56:00,746 INFO     Training average loss at step 96600: 0.125433\n",
      "2023-12-14 01:58:03,329 INFO     Training average positive_sample_loss at step 96700: 0.150339\n",
      "2023-12-14 01:58:03,329 INFO     Training average negative_sample_loss at step 96700: 0.101207\n",
      "2023-12-14 01:58:03,329 INFO     Training average loss at step 96700: 0.125773\n",
      "2023-12-14 02:00:07,439 INFO     Training average positive_sample_loss at step 96800: 0.150579\n",
      "2023-12-14 02:00:07,439 INFO     Training average negative_sample_loss at step 96800: 0.101368\n",
      "2023-12-14 02:00:07,439 INFO     Training average loss at step 96800: 0.125974\n",
      "2023-12-14 02:02:06,464 INFO     Training average positive_sample_loss at step 96900: 0.150154\n",
      "2023-12-14 02:02:06,465 INFO     Training average negative_sample_loss at step 96900: 0.101475\n",
      "2023-12-14 02:02:06,465 INFO     Training average loss at step 96900: 0.125814\n",
      "2023-12-14 02:04:01,242 INFO     Training average positive_sample_loss at step 97000: 0.151689\n",
      "2023-12-14 02:04:01,242 INFO     Training average negative_sample_loss at step 97000: 0.101580\n",
      "2023-12-14 02:04:01,242 INFO     Training average loss at step 97000: 0.126635\n",
      "2023-12-14 02:06:18,522 INFO     Training average positive_sample_loss at step 97100: 0.150353\n",
      "2023-12-14 02:06:18,523 INFO     Training average negative_sample_loss at step 97100: 0.101378\n",
      "2023-12-14 02:06:18,523 INFO     Training average loss at step 97100: 0.125866\n",
      "2023-12-14 02:08:27,945 INFO     Training average positive_sample_loss at step 97200: 0.150002\n",
      "2023-12-14 02:08:27,946 INFO     Training average negative_sample_loss at step 97200: 0.101019\n",
      "2023-12-14 02:08:27,946 INFO     Training average loss at step 97200: 0.125510\n",
      "2023-12-14 02:10:43,319 INFO     Training average positive_sample_loss at step 97300: 0.150777\n",
      "2023-12-14 02:10:43,320 INFO     Training average negative_sample_loss at step 97300: 0.101602\n",
      "2023-12-14 02:10:43,320 INFO     Training average loss at step 97300: 0.126190\n",
      "2023-12-14 02:13:01,386 INFO     Training average positive_sample_loss at step 97400: 0.149724\n",
      "2023-12-14 02:13:01,386 INFO     Training average negative_sample_loss at step 97400: 0.101290\n",
      "2023-12-14 02:13:01,386 INFO     Training average loss at step 97400: 0.125507\n",
      "2023-12-14 02:15:06,892 INFO     Training average positive_sample_loss at step 97500: 0.151673\n",
      "2023-12-14 02:15:06,892 INFO     Training average negative_sample_loss at step 97500: 0.101221\n",
      "2023-12-14 02:15:06,892 INFO     Training average loss at step 97500: 0.126447\n",
      "2023-12-14 02:17:13,822 INFO     Training average positive_sample_loss at step 97600: 0.150289\n",
      "2023-12-14 02:17:13,823 INFO     Training average negative_sample_loss at step 97600: 0.101396\n",
      "2023-12-14 02:17:13,823 INFO     Training average loss at step 97600: 0.125842\n",
      "2023-12-14 02:19:08,708 INFO     Training average positive_sample_loss at step 97700: 0.150329\n",
      "2023-12-14 02:19:08,709 INFO     Training average negative_sample_loss at step 97700: 0.101054\n",
      "2023-12-14 02:19:08,709 INFO     Training average loss at step 97700: 0.125691\n",
      "2023-12-14 02:21:15,480 INFO     Training average positive_sample_loss at step 97800: 0.151013\n",
      "2023-12-14 02:21:15,480 INFO     Training average negative_sample_loss at step 97800: 0.101493\n",
      "2023-12-14 02:21:15,480 INFO     Training average loss at step 97800: 0.126253\n",
      "2023-12-14 02:23:13,759 INFO     Training average positive_sample_loss at step 97900: 0.149970\n",
      "2023-12-14 02:23:13,760 INFO     Training average negative_sample_loss at step 97900: 0.101251\n",
      "2023-12-14 02:23:13,760 INFO     Training average loss at step 97900: 0.125611\n",
      "2023-12-14 02:25:18,935 INFO     Training average positive_sample_loss at step 98000: 0.150609\n",
      "2023-12-14 02:25:18,935 INFO     Training average negative_sample_loss at step 98000: 0.101166\n",
      "2023-12-14 02:25:18,935 INFO     Training average loss at step 98000: 0.125887\n",
      "2023-12-14 02:27:34,905 INFO     Training average positive_sample_loss at step 98100: 0.150246\n",
      "2023-12-14 02:27:34,906 INFO     Training average negative_sample_loss at step 98100: 0.101381\n",
      "2023-12-14 02:27:34,906 INFO     Training average loss at step 98100: 0.125814\n",
      "2023-12-14 02:29:33,028 INFO     Training average positive_sample_loss at step 98200: 0.150509\n",
      "2023-12-14 02:29:33,029 INFO     Training average negative_sample_loss at step 98200: 0.101372\n",
      "2023-12-14 02:29:33,029 INFO     Training average loss at step 98200: 0.125941\n",
      "2023-12-14 02:31:57,797 INFO     Training average positive_sample_loss at step 98300: 0.151183\n",
      "2023-12-14 02:31:57,798 INFO     Training average negative_sample_loss at step 98300: 0.101367\n",
      "2023-12-14 02:31:57,798 INFO     Training average loss at step 98300: 0.126275\n",
      "2023-12-14 02:33:53,204 INFO     Training average positive_sample_loss at step 98400: 0.149592\n",
      "2023-12-14 02:33:53,204 INFO     Training average negative_sample_loss at step 98400: 0.100765\n",
      "2023-12-14 02:33:53,204 INFO     Training average loss at step 98400: 0.125179\n",
      "2023-12-14 02:35:44,980 INFO     Training average positive_sample_loss at step 98500: 0.151257\n",
      "2023-12-14 02:35:44,980 INFO     Training average negative_sample_loss at step 98500: 0.101350\n",
      "2023-12-14 02:35:44,980 INFO     Training average loss at step 98500: 0.126303\n",
      "2023-12-14 02:38:07,849 INFO     Training average positive_sample_loss at step 98600: 0.150171\n",
      "2023-12-14 02:38:07,850 INFO     Training average negative_sample_loss at step 98600: 0.101309\n",
      "2023-12-14 02:38:07,850 INFO     Training average loss at step 98600: 0.125740\n",
      "2023-12-14 02:40:01,404 INFO     Training average positive_sample_loss at step 98700: 0.149914\n",
      "2023-12-14 02:40:01,404 INFO     Training average negative_sample_loss at step 98700: 0.100917\n",
      "2023-12-14 02:40:01,404 INFO     Training average loss at step 98700: 0.125416\n",
      "2023-12-14 02:42:01,197 INFO     Training average positive_sample_loss at step 98800: 0.151216\n",
      "2023-12-14 02:42:01,197 INFO     Training average negative_sample_loss at step 98800: 0.101498\n",
      "2023-12-14 02:42:01,197 INFO     Training average loss at step 98800: 0.126357\n",
      "2023-12-14 02:44:12,812 INFO     Training average positive_sample_loss at step 98900: 0.150457\n",
      "2023-12-14 02:44:12,813 INFO     Training average negative_sample_loss at step 98900: 0.101616\n",
      "2023-12-14 02:44:12,813 INFO     Training average loss at step 98900: 0.126037\n",
      "2023-12-14 02:46:10,985 INFO     Training average positive_sample_loss at step 99000: 0.150503\n",
      "2023-12-14 02:46:10,986 INFO     Training average negative_sample_loss at step 99000: 0.101426\n",
      "2023-12-14 02:46:10,986 INFO     Training average loss at step 99000: 0.125964\n",
      "2023-12-14 02:48:14,462 INFO     Training average positive_sample_loss at step 99100: 0.150926\n",
      "2023-12-14 02:48:14,462 INFO     Training average negative_sample_loss at step 99100: 0.100887\n",
      "2023-12-14 02:48:14,462 INFO     Training average loss at step 99100: 0.125907\n",
      "2023-12-14 02:50:15,862 INFO     Training average positive_sample_loss at step 99200: 0.149867\n",
      "2023-12-14 02:50:15,863 INFO     Training average negative_sample_loss at step 99200: 0.101302\n",
      "2023-12-14 02:50:15,863 INFO     Training average loss at step 99200: 0.125585\n",
      "2023-12-14 02:52:18,703 INFO     Training average positive_sample_loss at step 99300: 0.150706\n",
      "2023-12-14 02:52:18,703 INFO     Training average negative_sample_loss at step 99300: 0.101186\n",
      "2023-12-14 02:52:18,703 INFO     Training average loss at step 99300: 0.125946\n",
      "2023-12-14 02:54:20,208 INFO     Training average positive_sample_loss at step 99400: 0.149605\n",
      "2023-12-14 02:54:20,209 INFO     Training average negative_sample_loss at step 99400: 0.101421\n",
      "2023-12-14 02:54:20,209 INFO     Training average loss at step 99400: 0.125513\n",
      "2023-12-14 02:56:17,241 INFO     Training average positive_sample_loss at step 99500: 0.150689\n",
      "2023-12-14 02:56:17,242 INFO     Training average negative_sample_loss at step 99500: 0.101394\n",
      "2023-12-14 02:56:17,242 INFO     Training average loss at step 99500: 0.126042\n",
      "2023-12-14 02:58:42,390 INFO     Training average positive_sample_loss at step 99600: 0.151672\n",
      "2023-12-14 02:58:42,390 INFO     Training average negative_sample_loss at step 99600: 0.101257\n",
      "2023-12-14 02:58:42,390 INFO     Training average loss at step 99600: 0.126464\n",
      "2023-12-14 03:00:38,441 INFO     Training average positive_sample_loss at step 99700: 0.149452\n",
      "2023-12-14 03:00:38,442 INFO     Training average negative_sample_loss at step 99700: 0.101142\n",
      "2023-12-14 03:00:38,442 INFO     Training average loss at step 99700: 0.125297\n",
      "2023-12-14 03:02:50,060 INFO     Training average positive_sample_loss at step 99800: 0.151351\n",
      "2023-12-14 03:02:50,061 INFO     Training average negative_sample_loss at step 99800: 0.101219\n",
      "2023-12-14 03:02:50,061 INFO     Training average loss at step 99800: 0.126285\n",
      "2023-12-14 03:05:10,303 INFO     Training average positive_sample_loss at step 99900: 0.150060\n",
      "2023-12-14 03:05:10,303 INFO     Training average negative_sample_loss at step 99900: 0.101430\n",
      "2023-12-14 03:05:10,303 INFO     Training average loss at step 99900: 0.125745\n",
      "2023-12-14 03:07:19,007 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-14 03:07:19,583 INFO     Evaluating the model... (0/1834)\n",
      "2023-12-14 03:07:44,292 INFO     Evaluating the model... (1000/1834)\n",
      "2023-12-14 03:08:00,474 INFO     Valid MRR at step 99999: 0.421055\n",
      "2023-12-14 03:08:00,475 INFO     Valid MR at step 99999: 689.840473\n",
      "2023-12-14 03:08:00,475 INFO     Valid HITS@1 at step 99999: 0.393751\n",
      "2023-12-14 03:08:00,475 INFO     Valid HITS@3 at step 99999: 0.423972\n",
      "2023-12-14 03:08:00,475 INFO     Valid HITS@10 at step 99999: 0.470496\n",
      "2023-12-14 03:08:00,475 INFO     Evaluating on Test Dataset...\n",
      "2023-12-14 03:08:00,943 INFO     Evaluating the model... (0/4582)\n",
      "2023-12-14 03:08:25,707 INFO     Evaluating the model... (1000/4582)\n",
      "2023-12-14 03:08:51,939 INFO     Evaluating the model... (2000/4582)\n",
      "2023-12-14 03:09:14,245 INFO     Evaluating the model... (3000/4582)\n",
      "2023-12-14 03:09:34,665 INFO     Evaluating the model... (4000/4582)\n",
      "2023-12-14 03:09:47,013 INFO     Test MRR at step 99999: 0.420198\n",
      "2023-12-14 03:09:47,014 INFO     Test MR at step 99999: 665.478046\n",
      "2023-12-14 03:09:47,014 INFO     Test HITS@1 at step 99999: 0.393587\n",
      "2023-12-14 03:09:47,014 INFO     Test HITS@3 at step 99999: 0.422172\n",
      "2023-12-14 03:09:47,014 INFO     Test HITS@10 at step 99999: 0.469409\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE DBpedia15K 0 0 1024 256 1000 9.0 1.0 0.00005 100000 16 -de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con variante NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd KnowledgeGraphEmbedding_variant_NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu118\n",
      "Start Training......\n",
      "2024-03-02 19:02:45,074 INFO     Model: RotatE\n",
      "2024-03-02 19:02:45,074 INFO     Data Path: data/DBpedia15K\n",
      "2024-03-02 19:02:45,074 INFO     #entity: 12863\n",
      "2024-03-02 19:02:45,074 INFO     #relation: 279\n",
      "2024-03-02 19:02:45,290 INFO     #train: 131918\n",
      "2024-03-02 19:02:45,359 INFO     #valid: 14659\n",
      "2024-03-02 19:02:45,456 INFO     #test: 36645\n",
      "2024-03-02 19:02:45,602 INFO     Model Parameter Configuration:\n",
      "2024-03-02 19:02:45,603 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2024-03-02 19:02:45,603 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2024-03-02 19:02:45,603 INFO     Parameter entity_embedding: torch.Size([12863, 2000]), require_grad = True\n",
      "2024-03-02 19:02:45,603 INFO     Parameter relation_embedding: torch.Size([279, 1000]), require_grad = True\n",
      "2024-03-02 19:02:47,239 INFO     Ramdomly Initializing RotatE Model...\n",
      "2024-03-02 19:02:47,239 INFO     Start Training...\n",
      "2024-03-02 19:02:47,239 INFO     init_step = 0\n",
      "2024-03-02 19:02:47,239 INFO     batch_size = 1024\n",
      "2024-03-02 19:02:47,239 INFO     negative_adversarial_sampling = 1\n",
      "2024-03-02 19:02:47,239 INFO     hidden_dim = 1000\n",
      "2024-03-02 19:02:47,239 INFO     gamma = 9.000000\n",
      "2024-03-02 19:02:47,239 INFO     negative_adversarial_sampling = True\n",
      "2024-03-02 19:02:47,239 INFO     adversarial_temperature = 1.000000\n",
      "2024-03-02 19:02:47,240 INFO     learning_rate = 0\n",
      "2024-03-02 19:02:50,728 INFO     Training average positive_sample_loss at step 0: 2.554491\n",
      "2024-03-02 19:02:50,728 INFO     Training average negative_sample_loss at step 0: 0.083325\n",
      "2024-03-02 19:02:50,729 INFO     Training average loss at step 0: 1.318908\n",
      "2024-03-02 19:02:50,729 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-02 19:02:51,237 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-02 19:03:19,735 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-02 19:03:41,300 INFO     Valid MRR at step 0: 0.006298\n",
      "2024-03-02 19:03:41,300 INFO     Valid MR at step 0: 5366.827512\n",
      "2024-03-02 19:03:41,300 INFO     Valid HITS@1 at step 0: 0.004980\n",
      "2024-03-02 19:03:41,300 INFO     Valid HITS@3 at step 0: 0.005867\n",
      "2024-03-02 19:03:41,300 INFO     Valid HITS@10 at step 0: 0.007129\n",
      "2024-03-02 19:04:06,060 INFO     Training average positive_sample_loss at step 100: 2.073753\n",
      "2024-03-02 19:04:06,061 INFO     Training average negative_sample_loss at step 100: 0.185935\n",
      "2024-03-02 19:04:06,061 INFO     Training average loss at step 100: 1.129844\n",
      "2024-03-02 19:04:29,613 INFO     Training average positive_sample_loss at step 200: 1.198797\n",
      "2024-03-02 19:04:29,614 INFO     Training average negative_sample_loss at step 200: 0.391546\n",
      "2024-03-02 19:04:29,614 INFO     Training average loss at step 200: 0.795171\n",
      "2024-03-02 19:04:58,572 INFO     Training average positive_sample_loss at step 300: 0.799501\n",
      "2024-03-02 19:04:58,573 INFO     Training average negative_sample_loss at step 300: 0.494625\n",
      "2024-03-02 19:04:58,573 INFO     Training average loss at step 300: 0.647063\n",
      "2024-03-02 19:05:21,798 INFO     Training average positive_sample_loss at step 400: 0.651572\n",
      "2024-03-02 19:05:21,799 INFO     Training average negative_sample_loss at step 400: 0.501358\n",
      "2024-03-02 19:05:21,799 INFO     Training average loss at step 400: 0.576465\n",
      "2024-03-02 19:05:45,484 INFO     Training average positive_sample_loss at step 500: 0.604598\n",
      "2024-03-02 19:05:45,484 INFO     Training average negative_sample_loss at step 500: 0.498828\n",
      "2024-03-02 19:05:45,485 INFO     Training average loss at step 500: 0.551713\n",
      "2024-03-02 19:06:12,868 INFO     Training average positive_sample_loss at step 600: 0.525060\n",
      "2024-03-02 19:06:12,868 INFO     Training average negative_sample_loss at step 600: 0.475246\n",
      "2024-03-02 19:06:12,868 INFO     Training average loss at step 600: 0.500153\n",
      "2024-03-02 19:06:37,004 INFO     Training average positive_sample_loss at step 700: 0.519270\n",
      "2024-03-02 19:06:37,004 INFO     Training average negative_sample_loss at step 700: 0.445440\n",
      "2024-03-02 19:06:37,004 INFO     Training average loss at step 700: 0.482355\n",
      "2024-03-02 19:07:03,745 INFO     Training average positive_sample_loss at step 800: 0.491481\n",
      "2024-03-02 19:07:03,746 INFO     Training average negative_sample_loss at step 800: 0.427661\n",
      "2024-03-02 19:07:03,746 INFO     Training average loss at step 800: 0.459571\n",
      "2024-03-02 19:07:27,780 INFO     Training average positive_sample_loss at step 900: 0.459068\n",
      "2024-03-02 19:07:27,780 INFO     Training average negative_sample_loss at step 900: 0.393471\n",
      "2024-03-02 19:07:27,780 INFO     Training average loss at step 900: 0.426270\n",
      "2024-03-02 19:07:51,507 INFO     Training average positive_sample_loss at step 1000: 0.458185\n",
      "2024-03-02 19:07:51,507 INFO     Training average negative_sample_loss at step 1000: 0.377026\n",
      "2024-03-02 19:07:51,507 INFO     Training average loss at step 1000: 0.417606\n",
      "2024-03-02 19:08:18,078 INFO     Training average positive_sample_loss at step 1100: 0.420096\n",
      "2024-03-02 19:08:18,079 INFO     Training average negative_sample_loss at step 1100: 0.355539\n",
      "2024-03-02 19:08:18,079 INFO     Training average loss at step 1100: 0.387817\n",
      "2024-03-02 19:08:41,675 INFO     Training average positive_sample_loss at step 1200: 0.415235\n",
      "2024-03-02 19:08:41,675 INFO     Training average negative_sample_loss at step 1200: 0.332649\n",
      "2024-03-02 19:08:41,675 INFO     Training average loss at step 1200: 0.373942\n",
      "2024-03-02 19:09:08,001 INFO     Training average positive_sample_loss at step 1300: 0.404083\n",
      "2024-03-02 19:09:08,001 INFO     Training average negative_sample_loss at step 1300: 0.321809\n",
      "2024-03-02 19:09:08,001 INFO     Training average loss at step 1300: 0.362946\n",
      "2024-03-02 19:09:32,448 INFO     Training average positive_sample_loss at step 1400: 0.372215\n",
      "2024-03-02 19:09:32,448 INFO     Training average negative_sample_loss at step 1400: 0.299321\n",
      "2024-03-02 19:09:32,448 INFO     Training average loss at step 1400: 0.335768\n",
      "2024-03-02 19:09:56,510 INFO     Training average positive_sample_loss at step 1500: 0.374997\n",
      "2024-03-02 19:09:56,511 INFO     Training average negative_sample_loss at step 1500: 0.287917\n",
      "2024-03-02 19:09:56,511 INFO     Training average loss at step 1500: 0.331457\n",
      "2024-03-02 19:10:24,491 INFO     Training average positive_sample_loss at step 1600: 0.349473\n",
      "2024-03-02 19:10:24,491 INFO     Training average negative_sample_loss at step 1600: 0.275197\n",
      "2024-03-02 19:10:24,491 INFO     Training average loss at step 1600: 0.312335\n",
      "2024-03-02 19:10:47,470 INFO     Training average positive_sample_loss at step 1700: 0.343424\n",
      "2024-03-02 19:10:47,471 INFO     Training average negative_sample_loss at step 1700: 0.259649\n",
      "2024-03-02 19:10:47,471 INFO     Training average loss at step 1700: 0.301537\n",
      "2024-03-02 19:11:10,495 INFO     Training average positive_sample_loss at step 1800: 0.340113\n",
      "2024-03-02 19:11:10,496 INFO     Training average negative_sample_loss at step 1800: 0.252867\n",
      "2024-03-02 19:11:10,496 INFO     Training average loss at step 1800: 0.296490\n",
      "2024-03-02 19:11:40,268 INFO     Training average positive_sample_loss at step 1900: 0.309086\n",
      "2024-03-02 19:11:40,269 INFO     Training average negative_sample_loss at step 1900: 0.239282\n",
      "2024-03-02 19:11:40,269 INFO     Training average loss at step 1900: 0.274184\n",
      "2024-03-02 19:12:05,830 INFO     Training average positive_sample_loss at step 2000: 0.315379\n",
      "2024-03-02 19:12:05,831 INFO     Training average negative_sample_loss at step 2000: 0.230168\n",
      "2024-03-02 19:12:05,831 INFO     Training average loss at step 2000: 0.272774\n",
      "2024-03-02 19:12:33,771 INFO     Training average positive_sample_loss at step 2100: 0.299945\n",
      "2024-03-02 19:12:33,772 INFO     Training average negative_sample_loss at step 2100: 0.224225\n",
      "2024-03-02 19:12:33,772 INFO     Training average loss at step 2100: 0.262085\n",
      "2024-03-02 19:12:58,990 INFO     Training average positive_sample_loss at step 2200: 0.288677\n",
      "2024-03-02 19:12:58,991 INFO     Training average negative_sample_loss at step 2200: 0.212249\n",
      "2024-03-02 19:12:58,991 INFO     Training average loss at step 2200: 0.250463\n",
      "2024-03-02 19:13:24,477 INFO     Training average positive_sample_loss at step 2300: 0.289558\n",
      "2024-03-02 19:13:24,477 INFO     Training average negative_sample_loss at step 2300: 0.208175\n",
      "2024-03-02 19:13:24,477 INFO     Training average loss at step 2300: 0.248867\n",
      "2024-03-02 19:13:52,959 INFO     Training average positive_sample_loss at step 2400: 0.268659\n",
      "2024-03-02 19:13:52,960 INFO     Training average negative_sample_loss at step 2400: 0.200040\n",
      "2024-03-02 19:13:52,960 INFO     Training average loss at step 2400: 0.234350\n",
      "2024-03-02 19:14:18,422 INFO     Training average positive_sample_loss at step 2500: 0.270687\n",
      "2024-03-02 19:14:18,422 INFO     Training average negative_sample_loss at step 2500: 0.192667\n",
      "2024-03-02 19:14:18,422 INFO     Training average loss at step 2500: 0.231677\n",
      "2024-03-02 19:14:46,201 INFO     Training average positive_sample_loss at step 2600: 0.263176\n",
      "2024-03-02 19:14:46,201 INFO     Training average negative_sample_loss at step 2600: 0.190900\n",
      "2024-03-02 19:14:46,201 INFO     Training average loss at step 2600: 0.227038\n",
      "2024-03-02 19:15:09,777 INFO     Training average positive_sample_loss at step 2700: 0.249684\n",
      "2024-03-02 19:15:09,777 INFO     Training average negative_sample_loss at step 2700: 0.180373\n",
      "2024-03-02 19:15:09,777 INFO     Training average loss at step 2700: 0.215029\n",
      "2024-03-02 19:15:33,376 INFO     Training average positive_sample_loss at step 2800: 0.254291\n",
      "2024-03-02 19:15:33,376 INFO     Training average negative_sample_loss at step 2800: 0.178726\n",
      "2024-03-02 19:15:33,376 INFO     Training average loss at step 2800: 0.216508\n",
      "2024-03-02 19:16:01,701 INFO     Training average positive_sample_loss at step 2900: 0.238511\n",
      "2024-03-02 19:16:01,702 INFO     Training average negative_sample_loss at step 2900: 0.174250\n",
      "2024-03-02 19:16:01,702 INFO     Training average loss at step 2900: 0.206380\n",
      "2024-03-02 19:16:24,585 INFO     Training average positive_sample_loss at step 3000: 0.238322\n",
      "2024-03-02 19:16:24,586 INFO     Training average negative_sample_loss at step 3000: 0.168082\n",
      "2024-03-02 19:16:24,586 INFO     Training average loss at step 3000: 0.203202\n",
      "2024-03-02 19:16:52,683 INFO     Training average positive_sample_loss at step 3100: 0.238249\n",
      "2024-03-02 19:16:52,684 INFO     Training average negative_sample_loss at step 3100: 0.166777\n",
      "2024-03-02 19:16:52,684 INFO     Training average loss at step 3100: 0.202513\n",
      "2024-03-02 19:17:16,331 INFO     Training average positive_sample_loss at step 3200: 0.220093\n",
      "2024-03-02 19:17:16,331 INFO     Training average negative_sample_loss at step 3200: 0.160293\n",
      "2024-03-02 19:17:16,331 INFO     Training average loss at step 3200: 0.190193\n",
      "2024-03-02 19:17:41,078 INFO     Training average positive_sample_loss at step 3300: 0.227594\n",
      "2024-03-02 19:17:41,078 INFO     Training average negative_sample_loss at step 3300: 0.157925\n",
      "2024-03-02 19:17:41,078 INFO     Training average loss at step 3300: 0.192759\n",
      "2024-03-02 19:18:09,068 INFO     Training average positive_sample_loss at step 3400: 0.216586\n",
      "2024-03-02 19:18:09,068 INFO     Training average negative_sample_loss at step 3400: 0.156430\n",
      "2024-03-02 19:18:09,068 INFO     Training average loss at step 3400: 0.186508\n",
      "2024-03-02 19:18:34,261 INFO     Training average positive_sample_loss at step 3500: 0.214350\n",
      "2024-03-02 19:18:34,262 INFO     Training average negative_sample_loss at step 3500: 0.150134\n",
      "2024-03-02 19:18:34,262 INFO     Training average loss at step 3500: 0.182242\n",
      "2024-03-02 19:18:59,443 INFO     Training average positive_sample_loss at step 3600: 0.217907\n",
      "2024-03-02 19:18:59,444 INFO     Training average negative_sample_loss at step 3600: 0.151194\n",
      "2024-03-02 19:18:59,444 INFO     Training average loss at step 3600: 0.184550\n",
      "2024-03-02 19:19:27,907 INFO     Training average positive_sample_loss at step 3700: 0.200709\n",
      "2024-03-02 19:19:27,907 INFO     Training average negative_sample_loss at step 3700: 0.146610\n",
      "2024-03-02 19:19:27,907 INFO     Training average loss at step 3700: 0.173660\n",
      "2024-03-02 19:19:51,534 INFO     Training average positive_sample_loss at step 3800: 0.207186\n",
      "2024-03-02 19:19:51,535 INFO     Training average negative_sample_loss at step 3800: 0.143593\n",
      "2024-03-02 19:19:51,535 INFO     Training average loss at step 3800: 0.175390\n",
      "2024-03-02 19:20:17,970 INFO     Training average positive_sample_loss at step 3900: 0.201333\n",
      "2024-03-02 19:20:17,970 INFO     Training average negative_sample_loss at step 3900: 0.144264\n",
      "2024-03-02 19:20:17,970 INFO     Training average loss at step 3900: 0.172798\n",
      "2024-03-02 19:20:43,779 INFO     Training average positive_sample_loss at step 4000: 0.195444\n",
      "2024-03-02 19:20:43,779 INFO     Training average negative_sample_loss at step 4000: 0.138160\n",
      "2024-03-02 19:20:43,779 INFO     Training average loss at step 4000: 0.166802\n",
      "2024-03-02 19:21:09,447 INFO     Training average positive_sample_loss at step 4100: 0.200424\n",
      "2024-03-02 19:21:09,448 INFO     Training average negative_sample_loss at step 4100: 0.138709\n",
      "2024-03-02 19:21:09,448 INFO     Training average loss at step 4100: 0.169566\n",
      "2024-03-02 19:21:39,031 INFO     Training average positive_sample_loss at step 4200: 0.188006\n",
      "2024-03-02 19:21:39,032 INFO     Training average negative_sample_loss at step 4200: 0.136422\n",
      "2024-03-02 19:21:39,032 INFO     Training average loss at step 4200: 0.162214\n",
      "2024-03-02 19:22:04,328 INFO     Training average positive_sample_loss at step 4300: 0.191987\n",
      "2024-03-02 19:22:04,328 INFO     Training average negative_sample_loss at step 4300: 0.133934\n",
      "2024-03-02 19:22:04,328 INFO     Training average loss at step 4300: 0.162960\n",
      "2024-03-02 19:22:32,320 INFO     Training average positive_sample_loss at step 4400: 0.189749\n",
      "2024-03-02 19:22:32,321 INFO     Training average negative_sample_loss at step 4400: 0.134509\n",
      "2024-03-02 19:22:32,321 INFO     Training average loss at step 4400: 0.162129\n",
      "2024-03-02 19:22:56,537 INFO     Training average positive_sample_loss at step 4500: 0.180841\n",
      "2024-03-02 19:22:56,537 INFO     Training average negative_sample_loss at step 4500: 0.129726\n",
      "2024-03-02 19:22:56,537 INFO     Training average loss at step 4500: 0.155283\n",
      "2024-03-02 19:23:21,154 INFO     Training average positive_sample_loss at step 4600: 0.187087\n",
      "2024-03-02 19:23:21,154 INFO     Training average negative_sample_loss at step 4600: 0.130375\n",
      "2024-03-02 19:23:21,154 INFO     Training average loss at step 4600: 0.158731\n",
      "2024-03-02 19:23:49,039 INFO     Training average positive_sample_loss at step 4700: 0.177810\n",
      "2024-03-02 19:23:49,040 INFO     Training average negative_sample_loss at step 4700: 0.128633\n",
      "2024-03-02 19:23:49,040 INFO     Training average loss at step 4700: 0.153221\n",
      "2024-03-02 19:24:13,295 INFO     Training average positive_sample_loss at step 4800: 0.179225\n",
      "2024-03-02 19:24:13,295 INFO     Training average negative_sample_loss at step 4800: 0.126138\n",
      "2024-03-02 19:24:13,295 INFO     Training average loss at step 4800: 0.152681\n",
      "2024-03-02 19:24:36,621 INFO     Training average positive_sample_loss at step 4900: 0.182184\n",
      "2024-03-02 19:24:36,621 INFO     Training average negative_sample_loss at step 4900: 0.127185\n",
      "2024-03-02 19:24:36,621 INFO     Training average loss at step 4900: 0.154684\n",
      "2024-03-02 19:25:03,174 INFO     Training average positive_sample_loss at step 5000: 0.169322\n",
      "2024-03-02 19:25:03,175 INFO     Training average negative_sample_loss at step 5000: 0.123752\n",
      "2024-03-02 19:25:03,175 INFO     Training average loss at step 5000: 0.146537\n",
      "2024-03-02 19:25:26,105 INFO     Training average positive_sample_loss at step 5100: 0.176126\n",
      "2024-03-02 19:25:26,106 INFO     Training average negative_sample_loss at step 5100: 0.123224\n",
      "2024-03-02 19:25:26,106 INFO     Training average loss at step 5100: 0.149675\n",
      "2024-03-02 19:25:53,095 INFO     Training average positive_sample_loss at step 5200: 0.170721\n",
      "2024-03-02 19:25:53,095 INFO     Training average negative_sample_loss at step 5200: 0.124001\n",
      "2024-03-02 19:25:53,095 INFO     Training average loss at step 5200: 0.147361\n",
      "2024-03-02 19:26:16,537 INFO     Training average positive_sample_loss at step 5300: 0.169346\n",
      "2024-03-02 19:26:16,537 INFO     Training average negative_sample_loss at step 5300: 0.120324\n",
      "2024-03-02 19:26:16,537 INFO     Training average loss at step 5300: 0.144835\n",
      "2024-03-02 19:26:40,222 INFO     Training average positive_sample_loss at step 5400: 0.173637\n",
      "2024-03-02 19:26:40,223 INFO     Training average negative_sample_loss at step 5400: 0.121959\n",
      "2024-03-02 19:26:40,223 INFO     Training average loss at step 5400: 0.147798\n",
      "2024-03-02 19:27:07,972 INFO     Training average positive_sample_loss at step 5500: 0.162604\n",
      "2024-03-02 19:27:07,972 INFO     Training average negative_sample_loss at step 5500: 0.119289\n",
      "2024-03-02 19:27:07,972 INFO     Training average loss at step 5500: 0.140947\n",
      "2024-03-02 19:27:30,967 INFO     Training average positive_sample_loss at step 5600: 0.168579\n",
      "2024-03-02 19:27:30,968 INFO     Training average negative_sample_loss at step 5600: 0.118412\n",
      "2024-03-02 19:27:30,968 INFO     Training average loss at step 5600: 0.143496\n",
      "2024-03-02 19:27:57,678 INFO     Training average positive_sample_loss at step 5700: 0.164761\n",
      "2024-03-02 19:27:57,678 INFO     Training average negative_sample_loss at step 5700: 0.119363\n",
      "2024-03-02 19:27:57,678 INFO     Training average loss at step 5700: 0.142062\n",
      "2024-03-02 19:28:21,070 INFO     Training average positive_sample_loss at step 5800: 0.160968\n",
      "2024-03-02 19:28:21,070 INFO     Training average negative_sample_loss at step 5800: 0.116200\n",
      "2024-03-02 19:28:21,070 INFO     Training average loss at step 5800: 0.138584\n",
      "2024-03-02 19:28:44,049 INFO     Training average positive_sample_loss at step 5900: 0.166618\n",
      "2024-03-02 19:28:44,049 INFO     Training average negative_sample_loss at step 5900: 0.117578\n",
      "2024-03-02 19:28:44,050 INFO     Training average loss at step 5900: 0.142098\n",
      "2024-03-02 19:29:10,724 INFO     Training average positive_sample_loss at step 6000: 0.158019\n",
      "2024-03-02 19:29:10,725 INFO     Training average negative_sample_loss at step 6000: 0.116717\n",
      "2024-03-02 19:29:10,725 INFO     Training average loss at step 6000: 0.137368\n",
      "2024-03-02 19:29:33,913 INFO     Training average positive_sample_loss at step 6100: 0.161549\n",
      "2024-03-02 19:29:33,914 INFO     Training average negative_sample_loss at step 6100: 0.115132\n",
      "2024-03-02 19:29:33,914 INFO     Training average loss at step 6100: 0.138340\n",
      "2024-03-02 19:30:00,082 INFO     Training average positive_sample_loss at step 6200: 0.162283\n",
      "2024-03-02 19:30:00,083 INFO     Training average negative_sample_loss at step 6200: 0.115910\n",
      "2024-03-02 19:30:00,083 INFO     Training average loss at step 6200: 0.139096\n",
      "2024-03-02 19:30:23,669 INFO     Training average positive_sample_loss at step 6300: 0.153750\n",
      "2024-03-02 19:30:23,670 INFO     Training average negative_sample_loss at step 6300: 0.113233\n",
      "2024-03-02 19:30:23,670 INFO     Training average loss at step 6300: 0.133492\n",
      "2024-03-02 19:30:46,547 INFO     Training average positive_sample_loss at step 6400: 0.161036\n",
      "2024-03-02 19:30:46,547 INFO     Training average negative_sample_loss at step 6400: 0.113543\n",
      "2024-03-02 19:30:46,547 INFO     Training average loss at step 6400: 0.137290\n",
      "2024-03-02 19:31:13,117 INFO     Training average positive_sample_loss at step 6500: 0.154601\n",
      "2024-03-02 19:31:13,118 INFO     Training average negative_sample_loss at step 6500: 0.114255\n",
      "2024-03-02 19:31:13,118 INFO     Training average loss at step 6500: 0.134428\n",
      "2024-03-02 19:31:36,607 INFO     Training average positive_sample_loss at step 6600: 0.155618\n",
      "2024-03-02 19:31:36,608 INFO     Training average negative_sample_loss at step 6600: 0.111353\n",
      "2024-03-02 19:31:36,608 INFO     Training average loss at step 6600: 0.133485\n",
      "2024-03-02 19:32:00,695 INFO     Training average positive_sample_loss at step 6700: 0.158864\n",
      "2024-03-02 19:32:00,695 INFO     Training average negative_sample_loss at step 6700: 0.112843\n",
      "2024-03-02 19:32:00,695 INFO     Training average loss at step 6700: 0.135854\n",
      "2024-03-02 19:32:29,021 INFO     Training average positive_sample_loss at step 6800: 0.149349\n",
      "2024-03-02 19:32:29,021 INFO     Training average negative_sample_loss at step 6800: 0.111903\n",
      "2024-03-02 19:32:29,021 INFO     Training average loss at step 6800: 0.130626\n",
      "2024-03-02 19:32:54,540 INFO     Training average positive_sample_loss at step 6900: 0.155716\n",
      "2024-03-02 19:32:54,540 INFO     Training average negative_sample_loss at step 6900: 0.110942\n",
      "2024-03-02 19:32:54,541 INFO     Training average loss at step 6900: 0.133329\n",
      "2024-03-02 19:33:24,022 INFO     Training average positive_sample_loss at step 7000: 0.152007\n",
      "2024-03-02 19:33:24,022 INFO     Training average negative_sample_loss at step 7000: 0.111284\n",
      "2024-03-02 19:33:24,022 INFO     Training average loss at step 7000: 0.131646\n",
      "2024-03-02 19:33:47,086 INFO     Training average positive_sample_loss at step 7100: 0.151121\n",
      "2024-03-02 19:33:47,086 INFO     Training average negative_sample_loss at step 7100: 0.109351\n",
      "2024-03-02 19:33:47,086 INFO     Training average loss at step 7100: 0.130236\n",
      "2024-03-02 19:34:10,206 INFO     Training average positive_sample_loss at step 7200: 0.154641\n",
      "2024-03-02 19:34:10,206 INFO     Training average negative_sample_loss at step 7200: 0.110598\n",
      "2024-03-02 19:34:10,206 INFO     Training average loss at step 7200: 0.132620\n",
      "2024-03-02 19:34:37,556 INFO     Training average positive_sample_loss at step 7300: 0.146166\n",
      "2024-03-02 19:34:37,557 INFO     Training average negative_sample_loss at step 7300: 0.109046\n",
      "2024-03-02 19:34:37,557 INFO     Training average loss at step 7300: 0.127606\n",
      "2024-03-02 19:35:00,631 INFO     Training average positive_sample_loss at step 7400: 0.151867\n",
      "2024-03-02 19:35:00,632 INFO     Training average negative_sample_loss at step 7400: 0.108804\n",
      "2024-03-02 19:35:00,632 INFO     Training average loss at step 7400: 0.130336\n",
      "2024-03-02 19:35:27,160 INFO     Training average positive_sample_loss at step 7500: 0.151123\n",
      "2024-03-02 19:35:27,160 INFO     Training average negative_sample_loss at step 7500: 0.110195\n",
      "2024-03-02 19:35:27,160 INFO     Training average loss at step 7500: 0.130659\n",
      "2024-03-02 19:35:50,612 INFO     Training average positive_sample_loss at step 7600: 0.146230\n",
      "2024-03-02 19:35:50,612 INFO     Training average negative_sample_loss at step 7600: 0.107059\n",
      "2024-03-02 19:35:50,612 INFO     Training average loss at step 7600: 0.126644\n",
      "2024-03-02 19:36:13,840 INFO     Training average positive_sample_loss at step 7700: 0.151271\n",
      "2024-03-02 19:36:13,841 INFO     Training average negative_sample_loss at step 7700: 0.108223\n",
      "2024-03-02 19:36:13,841 INFO     Training average loss at step 7700: 0.129747\n",
      "2024-03-02 19:36:40,912 INFO     Training average positive_sample_loss at step 7800: 0.145160\n",
      "2024-03-02 19:36:40,913 INFO     Training average negative_sample_loss at step 7800: 0.108142\n",
      "2024-03-02 19:36:40,913 INFO     Training average loss at step 7800: 0.126651\n",
      "2024-03-02 19:37:04,645 INFO     Training average positive_sample_loss at step 7900: 0.147727\n",
      "2024-03-02 19:37:04,646 INFO     Training average negative_sample_loss at step 7900: 0.106295\n",
      "2024-03-02 19:37:04,646 INFO     Training average loss at step 7900: 0.127011\n",
      "2024-03-02 19:37:33,398 INFO     Training average positive_sample_loss at step 8000: 0.150076\n",
      "2024-03-02 19:37:33,399 INFO     Training average negative_sample_loss at step 8000: 0.108667\n",
      "2024-03-02 19:37:33,399 INFO     Training average loss at step 8000: 0.129371\n",
      "2024-03-02 19:37:57,255 INFO     Training average positive_sample_loss at step 8100: 0.141998\n",
      "2024-03-02 19:37:57,256 INFO     Training average negative_sample_loss at step 8100: 0.105701\n",
      "2024-03-02 19:37:57,256 INFO     Training average loss at step 8100: 0.123850\n",
      "2024-03-02 19:38:23,214 INFO     Training average positive_sample_loss at step 8200: 0.148069\n",
      "2024-03-02 19:38:23,215 INFO     Training average negative_sample_loss at step 8200: 0.105952\n",
      "2024-03-02 19:38:23,215 INFO     Training average loss at step 8200: 0.127011\n",
      "2024-03-02 19:38:51,021 INFO     Training average positive_sample_loss at step 8300: 0.143855\n",
      "2024-03-02 19:38:51,021 INFO     Training average negative_sample_loss at step 8300: 0.107504\n",
      "2024-03-02 19:38:51,021 INFO     Training average loss at step 8300: 0.125679\n",
      "2024-03-02 19:39:15,101 INFO     Training average positive_sample_loss at step 8400: 0.145046\n",
      "2024-03-02 19:39:15,101 INFO     Training average negative_sample_loss at step 8400: 0.104585\n",
      "2024-03-02 19:39:15,102 INFO     Training average loss at step 8400: 0.124816\n",
      "2024-03-02 19:39:38,589 INFO     Training average positive_sample_loss at step 8500: 0.148087\n",
      "2024-03-02 19:39:38,589 INFO     Training average negative_sample_loss at step 8500: 0.107198\n",
      "2024-03-02 19:39:38,589 INFO     Training average loss at step 8500: 0.127643\n",
      "2024-03-02 19:40:05,537 INFO     Training average positive_sample_loss at step 8600: 0.140041\n",
      "2024-03-02 19:40:05,538 INFO     Training average negative_sample_loss at step 8600: 0.104891\n",
      "2024-03-02 19:40:05,538 INFO     Training average loss at step 8600: 0.122466\n",
      "2024-03-02 19:40:29,895 INFO     Training average positive_sample_loss at step 8700: 0.145515\n",
      "2024-03-02 19:40:29,895 INFO     Training average negative_sample_loss at step 8700: 0.104686\n",
      "2024-03-02 19:40:29,895 INFO     Training average loss at step 8700: 0.125101\n",
      "2024-03-02 19:40:56,938 INFO     Training average positive_sample_loss at step 8800: 0.143224\n",
      "2024-03-02 19:40:56,938 INFO     Training average negative_sample_loss at step 8800: 0.106138\n",
      "2024-03-02 19:40:56,938 INFO     Training average loss at step 8800: 0.124681\n",
      "2024-03-02 19:41:20,815 INFO     Training average positive_sample_loss at step 8900: 0.141459\n",
      "2024-03-02 19:41:20,815 INFO     Training average negative_sample_loss at step 8900: 0.104169\n",
      "2024-03-02 19:41:20,815 INFO     Training average loss at step 8900: 0.122814\n",
      "2024-03-02 19:41:43,697 INFO     Training average positive_sample_loss at step 9000: 0.146290\n",
      "2024-03-02 19:41:43,697 INFO     Training average negative_sample_loss at step 9000: 0.105981\n",
      "2024-03-02 19:41:43,697 INFO     Training average loss at step 9000: 0.126136\n",
      "2024-03-02 19:42:09,673 INFO     Training average positive_sample_loss at step 9100: 0.139378\n",
      "2024-03-02 19:42:09,674 INFO     Training average negative_sample_loss at step 9100: 0.104783\n",
      "2024-03-02 19:42:09,674 INFO     Training average loss at step 9100: 0.122080\n",
      "2024-03-02 19:42:32,694 INFO     Training average positive_sample_loss at step 9200: 0.143237\n",
      "2024-03-02 19:42:32,694 INFO     Training average negative_sample_loss at step 9200: 0.103059\n",
      "2024-03-02 19:42:32,694 INFO     Training average loss at step 9200: 0.123148\n",
      "2024-03-02 19:43:00,844 INFO     Training average positive_sample_loss at step 9300: 0.143320\n",
      "2024-03-02 19:43:00,845 INFO     Training average negative_sample_loss at step 9300: 0.105033\n",
      "2024-03-02 19:43:00,845 INFO     Training average loss at step 9300: 0.124176\n",
      "2024-03-02 19:43:24,023 INFO     Training average positive_sample_loss at step 9400: 0.138559\n",
      "2024-03-02 19:43:24,023 INFO     Training average negative_sample_loss at step 9400: 0.103246\n",
      "2024-03-02 19:43:24,023 INFO     Training average loss at step 9400: 0.120902\n",
      "2024-03-02 19:43:48,105 INFO     Training average positive_sample_loss at step 9500: 0.143265\n",
      "2024-03-02 19:43:48,105 INFO     Training average negative_sample_loss at step 9500: 0.103596\n",
      "2024-03-02 19:43:48,105 INFO     Training average loss at step 9500: 0.123430\n",
      "2024-03-02 19:44:15,979 INFO     Training average positive_sample_loss at step 9600: 0.138182\n",
      "2024-03-02 19:44:15,979 INFO     Training average negative_sample_loss at step 9600: 0.103752\n",
      "2024-03-02 19:44:15,979 INFO     Training average loss at step 9600: 0.120967\n",
      "2024-03-02 19:44:39,191 INFO     Training average positive_sample_loss at step 9700: 0.141237\n",
      "2024-03-02 19:44:39,191 INFO     Training average negative_sample_loss at step 9700: 0.102093\n",
      "2024-03-02 19:44:39,192 INFO     Training average loss at step 9700: 0.121665\n",
      "2024-03-02 19:45:02,708 INFO     Training average positive_sample_loss at step 9800: 0.143472\n",
      "2024-03-02 19:45:02,709 INFO     Training average negative_sample_loss at step 9800: 0.103629\n",
      "2024-03-02 19:45:02,709 INFO     Training average loss at step 9800: 0.123551\n",
      "2024-03-02 19:45:29,458 INFO     Training average positive_sample_loss at step 9900: 0.135209\n",
      "2024-03-02 19:45:29,459 INFO     Training average negative_sample_loss at step 9900: 0.102186\n",
      "2024-03-02 19:45:29,459 INFO     Training average loss at step 9900: 0.118697\n",
      "2024-03-02 19:45:57,156 INFO     Training average positive_sample_loss at step 10000: 0.141554\n",
      "2024-03-02 19:45:57,156 INFO     Training average negative_sample_loss at step 10000: 0.102435\n",
      "2024-03-02 19:45:57,156 INFO     Training average loss at step 10000: 0.121995\n",
      "2024-03-02 19:45:57,157 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-02 19:45:57,806 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-02 19:46:29,996 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-02 19:46:51,365 INFO     Valid MRR at step 10000: 0.620876\n",
      "2024-03-02 19:46:51,366 INFO     Valid MR at step 10000: 269.982229\n",
      "2024-03-02 19:46:51,366 INFO     Valid HITS@1 at step 10000: 0.557337\n",
      "2024-03-02 19:46:51,366 INFO     Valid HITS@3 at step 10000: 0.669043\n",
      "2024-03-02 19:46:51,366 INFO     Valid HITS@10 at step 10000: 0.730336\n",
      "2024-03-02 19:47:15,179 INFO     Training average positive_sample_loss at step 10100: 0.138394\n",
      "2024-03-02 19:47:15,180 INFO     Training average negative_sample_loss at step 10100: 0.102955\n",
      "2024-03-02 19:47:15,180 INFO     Training average loss at step 10100: 0.120675\n",
      "2024-03-02 19:47:38,884 INFO     Training average positive_sample_loss at step 10200: 0.137915\n",
      "2024-03-02 19:47:38,884 INFO     Training average negative_sample_loss at step 10200: 0.100998\n",
      "2024-03-02 19:47:38,884 INFO     Training average loss at step 10200: 0.119456\n",
      "2024-03-02 19:48:02,286 INFO     Training average positive_sample_loss at step 10300: 0.142804\n",
      "2024-03-02 19:48:02,286 INFO     Training average negative_sample_loss at step 10300: 0.102599\n",
      "2024-03-02 19:48:02,286 INFO     Training average loss at step 10300: 0.122701\n",
      "2024-03-02 19:48:28,978 INFO     Training average positive_sample_loss at step 10400: 0.134358\n",
      "2024-03-02 19:48:28,978 INFO     Training average negative_sample_loss at step 10400: 0.101399\n",
      "2024-03-02 19:48:28,978 INFO     Training average loss at step 10400: 0.117879\n",
      "2024-03-02 19:48:52,238 INFO     Training average positive_sample_loss at step 10500: 0.140061\n",
      "2024-03-02 19:48:52,239 INFO     Training average negative_sample_loss at step 10500: 0.101464\n",
      "2024-03-02 19:48:52,239 INFO     Training average loss at step 10500: 0.120762\n",
      "2024-03-02 19:49:20,646 INFO     Training average positive_sample_loss at step 10600: 0.138946\n",
      "2024-03-02 19:49:20,646 INFO     Training average negative_sample_loss at step 10600: 0.102672\n",
      "2024-03-02 19:49:20,646 INFO     Training average loss at step 10600: 0.120809\n",
      "2024-03-02 19:49:44,113 INFO     Training average positive_sample_loss at step 10700: 0.135752\n",
      "2024-03-02 19:49:44,114 INFO     Training average negative_sample_loss at step 10700: 0.100758\n",
      "2024-03-02 19:49:44,114 INFO     Training average loss at step 10700: 0.118255\n",
      "2024-03-02 19:50:09,979 INFO     Training average positive_sample_loss at step 10800: 0.140261\n",
      "2024-03-02 19:50:09,979 INFO     Training average negative_sample_loss at step 10800: 0.100929\n",
      "2024-03-02 19:50:09,980 INFO     Training average loss at step 10800: 0.120595\n",
      "2024-03-02 19:50:39,290 INFO     Training average positive_sample_loss at step 10900: 0.134466\n",
      "2024-03-02 19:50:39,291 INFO     Training average negative_sample_loss at step 10900: 0.101597\n",
      "2024-03-02 19:50:39,291 INFO     Training average loss at step 10900: 0.118032\n",
      "2024-03-02 19:51:03,866 INFO     Training average positive_sample_loss at step 11000: 0.138642\n",
      "2024-03-02 19:51:03,866 INFO     Training average negative_sample_loss at step 11000: 0.100715\n",
      "2024-03-02 19:51:03,866 INFO     Training average loss at step 11000: 0.119678\n",
      "2024-03-02 19:51:31,144 INFO     Training average positive_sample_loss at step 11100: 0.139077\n",
      "2024-03-02 19:51:31,144 INFO     Training average negative_sample_loss at step 11100: 0.102390\n",
      "2024-03-02 19:51:31,144 INFO     Training average loss at step 11100: 0.120734\n",
      "2024-03-02 19:51:55,278 INFO     Training average positive_sample_loss at step 11200: 0.132910\n",
      "2024-03-02 19:51:55,279 INFO     Training average negative_sample_loss at step 11200: 0.099161\n",
      "2024-03-02 19:51:55,279 INFO     Training average loss at step 11200: 0.116036\n",
      "2024-03-02 19:52:18,760 INFO     Training average positive_sample_loss at step 11300: 0.139658\n",
      "2024-03-02 19:52:18,760 INFO     Training average negative_sample_loss at step 11300: 0.100915\n",
      "2024-03-02 19:52:18,760 INFO     Training average loss at step 11300: 0.120286\n",
      "2024-03-02 19:52:45,964 INFO     Training average positive_sample_loss at step 11400: 0.134509\n",
      "2024-03-02 19:52:45,964 INFO     Training average negative_sample_loss at step 11400: 0.101338\n",
      "2024-03-02 19:52:45,964 INFO     Training average loss at step 11400: 0.117924\n",
      "2024-03-02 19:53:09,346 INFO     Training average positive_sample_loss at step 11500: 0.136086\n",
      "2024-03-02 19:53:09,347 INFO     Training average negative_sample_loss at step 11500: 0.099021\n",
      "2024-03-02 19:53:09,347 INFO     Training average loss at step 11500: 0.117553\n",
      "2024-03-02 19:53:33,253 INFO     Training average positive_sample_loss at step 11600: 0.139392\n",
      "2024-03-02 19:53:33,254 INFO     Training average negative_sample_loss at step 11600: 0.101200\n",
      "2024-03-02 19:53:33,254 INFO     Training average loss at step 11600: 0.120296\n",
      "2024-03-02 19:54:01,652 INFO     Training average positive_sample_loss at step 11700: 0.132296\n",
      "2024-03-02 19:54:01,652 INFO     Training average negative_sample_loss at step 11700: 0.100022\n",
      "2024-03-02 19:54:01,652 INFO     Training average loss at step 11700: 0.116159\n",
      "2024-03-02 19:54:25,628 INFO     Training average positive_sample_loss at step 11800: 0.137379\n",
      "2024-03-02 19:54:25,629 INFO     Training average negative_sample_loss at step 11800: 0.099610\n",
      "2024-03-02 19:54:25,629 INFO     Training average loss at step 11800: 0.118495\n",
      "2024-03-02 19:54:54,286 INFO     Training average positive_sample_loss at step 11900: 0.135263\n",
      "2024-03-02 19:54:54,287 INFO     Training average negative_sample_loss at step 11900: 0.101072\n",
      "2024-03-02 19:54:54,287 INFO     Training average loss at step 11900: 0.118168\n",
      "2024-03-02 19:55:17,512 INFO     Training average positive_sample_loss at step 12000: 0.134038\n",
      "2024-03-02 19:55:17,512 INFO     Training average negative_sample_loss at step 12000: 0.099174\n",
      "2024-03-02 19:55:17,512 INFO     Training average loss at step 12000: 0.116606\n",
      "2024-03-02 19:55:41,394 INFO     Training average positive_sample_loss at step 12100: 0.138255\n",
      "2024-03-02 19:55:41,395 INFO     Training average negative_sample_loss at step 12100: 0.100544\n",
      "2024-03-02 19:55:41,395 INFO     Training average loss at step 12100: 0.119400\n",
      "2024-03-02 19:56:08,000 INFO     Training average positive_sample_loss at step 12200: 0.131321\n",
      "2024-03-02 19:56:08,001 INFO     Training average negative_sample_loss at step 12200: 0.099040\n",
      "2024-03-02 19:56:08,001 INFO     Training average loss at step 12200: 0.115180\n",
      "2024-03-02 19:56:33,203 INFO     Training average positive_sample_loss at step 12300: 0.136289\n",
      "2024-03-02 19:56:33,204 INFO     Training average negative_sample_loss at step 12300: 0.099062\n",
      "2024-03-02 19:56:33,204 INFO     Training average loss at step 12300: 0.117675\n",
      "2024-03-02 19:57:03,048 INFO     Training average positive_sample_loss at step 12400: 0.135633\n",
      "2024-03-02 19:57:03,049 INFO     Training average negative_sample_loss at step 12400: 0.100616\n",
      "2024-03-02 19:57:03,049 INFO     Training average loss at step 12400: 0.118125\n",
      "2024-03-02 19:57:26,200 INFO     Training average positive_sample_loss at step 12500: 0.132037\n",
      "2024-03-02 19:57:26,201 INFO     Training average negative_sample_loss at step 12500: 0.098056\n",
      "2024-03-02 19:57:26,201 INFO     Training average loss at step 12500: 0.115046\n",
      "2024-03-02 19:57:49,457 INFO     Training average positive_sample_loss at step 12600: 0.137312\n",
      "2024-03-02 19:57:49,458 INFO     Training average negative_sample_loss at step 12600: 0.099332\n",
      "2024-03-02 19:57:49,458 INFO     Training average loss at step 12600: 0.118322\n",
      "2024-03-02 19:58:16,775 INFO     Training average positive_sample_loss at step 12700: 0.131455\n",
      "2024-03-02 19:58:16,775 INFO     Training average negative_sample_loss at step 12700: 0.099637\n",
      "2024-03-02 19:58:16,775 INFO     Training average loss at step 12700: 0.115546\n",
      "2024-03-02 19:58:40,402 INFO     Training average positive_sample_loss at step 12800: 0.135255\n",
      "2024-03-02 19:58:40,402 INFO     Training average negative_sample_loss at step 12800: 0.098516\n",
      "2024-03-02 19:58:40,403 INFO     Training average loss at step 12800: 0.116886\n",
      "2024-03-02 19:59:05,881 INFO     Training average positive_sample_loss at step 12900: 0.136819\n",
      "2024-03-02 19:59:05,882 INFO     Training average negative_sample_loss at step 12900: 0.100256\n",
      "2024-03-02 19:59:05,882 INFO     Training average loss at step 12900: 0.118537\n",
      "2024-03-02 19:59:30,336 INFO     Training average positive_sample_loss at step 13000: 0.129582\n",
      "2024-03-02 19:59:30,336 INFO     Training average negative_sample_loss at step 13000: 0.098147\n",
      "2024-03-02 19:59:30,336 INFO     Training average loss at step 13000: 0.113865\n",
      "2024-03-02 19:59:54,031 INFO     Training average positive_sample_loss at step 13100: 0.135978\n",
      "2024-03-02 19:59:54,031 INFO     Training average negative_sample_loss at step 13100: 0.098692\n",
      "2024-03-02 19:59:54,031 INFO     Training average loss at step 13100: 0.117335\n",
      "2024-03-02 20:00:22,631 INFO     Training average positive_sample_loss at step 13200: 0.132374\n",
      "2024-03-02 20:00:22,631 INFO     Training average negative_sample_loss at step 13200: 0.099889\n",
      "2024-03-02 20:00:22,631 INFO     Training average loss at step 13200: 0.116131\n",
      "2024-03-02 20:00:45,744 INFO     Training average positive_sample_loss at step 13300: 0.133253\n",
      "2024-03-02 20:00:45,744 INFO     Training average negative_sample_loss at step 13300: 0.097899\n",
      "2024-03-02 20:00:45,744 INFO     Training average loss at step 13300: 0.115576\n",
      "2024-03-02 20:01:08,966 INFO     Training average positive_sample_loss at step 13400: 0.136551\n",
      "2024-03-02 20:01:08,966 INFO     Training average negative_sample_loss at step 13400: 0.099155\n",
      "2024-03-02 20:01:08,966 INFO     Training average loss at step 13400: 0.117853\n",
      "2024-03-02 20:01:36,199 INFO     Training average positive_sample_loss at step 13500: 0.128993\n",
      "2024-03-02 20:01:36,200 INFO     Training average negative_sample_loss at step 13500: 0.097653\n",
      "2024-03-02 20:01:36,200 INFO     Training average loss at step 13500: 0.113323\n",
      "2024-03-02 20:01:59,595 INFO     Training average positive_sample_loss at step 13600: 0.135101\n",
      "2024-03-02 20:01:59,596 INFO     Training average negative_sample_loss at step 13600: 0.097662\n",
      "2024-03-02 20:01:59,596 INFO     Training average loss at step 13600: 0.116382\n",
      "2024-03-02 20:02:26,772 INFO     Training average positive_sample_loss at step 13700: 0.132909\n",
      "2024-03-02 20:02:26,772 INFO     Training average negative_sample_loss at step 13700: 0.099521\n",
      "2024-03-02 20:02:26,772 INFO     Training average loss at step 13700: 0.116215\n",
      "2024-03-02 20:02:50,688 INFO     Training average positive_sample_loss at step 13800: 0.131358\n",
      "2024-03-02 20:02:50,688 INFO     Training average negative_sample_loss at step 13800: 0.097884\n",
      "2024-03-02 20:02:50,688 INFO     Training average loss at step 13800: 0.114621\n",
      "2024-03-02 20:03:13,970 INFO     Training average positive_sample_loss at step 13900: 0.135683\n",
      "2024-03-02 20:03:13,970 INFO     Training average negative_sample_loss at step 13900: 0.097894\n",
      "2024-03-02 20:03:13,970 INFO     Training average loss at step 13900: 0.116789\n",
      "2024-03-02 20:03:40,990 INFO     Training average positive_sample_loss at step 14000: 0.129335\n",
      "2024-03-02 20:03:40,990 INFO     Training average negative_sample_loss at step 14000: 0.097858\n",
      "2024-03-02 20:03:40,990 INFO     Training average loss at step 14000: 0.113597\n",
      "2024-03-02 20:04:04,716 INFO     Training average positive_sample_loss at step 14100: 0.133151\n",
      "2024-03-02 20:04:04,716 INFO     Training average negative_sample_loss at step 14100: 0.097430\n",
      "2024-03-02 20:04:04,716 INFO     Training average loss at step 14100: 0.115290\n",
      "2024-03-02 20:04:32,025 INFO     Training average positive_sample_loss at step 14200: 0.134206\n",
      "2024-03-02 20:04:32,025 INFO     Training average negative_sample_loss at step 14200: 0.098659\n",
      "2024-03-02 20:04:32,025 INFO     Training average loss at step 14200: 0.116433\n",
      "2024-03-02 20:04:56,239 INFO     Training average positive_sample_loss at step 14300: 0.129720\n",
      "2024-03-02 20:04:56,239 INFO     Training average negative_sample_loss at step 14300: 0.097109\n",
      "2024-03-02 20:04:56,239 INFO     Training average loss at step 14300: 0.113414\n",
      "2024-03-02 20:05:19,196 INFO     Training average positive_sample_loss at step 14400: 0.134650\n",
      "2024-03-02 20:05:19,196 INFO     Training average negative_sample_loss at step 14400: 0.097754\n",
      "2024-03-02 20:05:19,196 INFO     Training average loss at step 14400: 0.116202\n",
      "2024-03-02 20:05:48,389 INFO     Training average positive_sample_loss at step 14500: 0.129094\n",
      "2024-03-02 20:05:48,390 INFO     Training average negative_sample_loss at step 14500: 0.097854\n",
      "2024-03-02 20:05:48,390 INFO     Training average loss at step 14500: 0.113474\n",
      "2024-03-02 20:06:12,502 INFO     Training average positive_sample_loss at step 14600: 0.132430\n",
      "2024-03-02 20:06:12,502 INFO     Training average negative_sample_loss at step 14600: 0.096308\n",
      "2024-03-02 20:06:12,502 INFO     Training average loss at step 14600: 0.114369\n",
      "2024-03-02 20:06:35,463 INFO     Training average positive_sample_loss at step 14700: 0.135511\n",
      "2024-03-02 20:06:35,463 INFO     Training average negative_sample_loss at step 14700: 0.098611\n",
      "2024-03-02 20:06:35,463 INFO     Training average loss at step 14700: 0.117061\n",
      "2024-03-02 20:07:02,701 INFO     Training average positive_sample_loss at step 14800: 0.127266\n",
      "2024-03-02 20:07:02,701 INFO     Training average negative_sample_loss at step 14800: 0.096664\n",
      "2024-03-02 20:07:02,701 INFO     Training average loss at step 14800: 0.111965\n",
      "2024-03-02 20:07:26,764 INFO     Training average positive_sample_loss at step 14900: 0.133674\n",
      "2024-03-02 20:07:26,764 INFO     Training average negative_sample_loss at step 14900: 0.097325\n",
      "2024-03-02 20:07:26,764 INFO     Training average loss at step 14900: 0.115499\n",
      "2024-03-02 20:07:53,359 INFO     Training average positive_sample_loss at step 15000: 0.131191\n",
      "2024-03-02 20:07:53,360 INFO     Training average negative_sample_loss at step 15000: 0.098701\n",
      "2024-03-02 20:07:53,360 INFO     Training average loss at step 15000: 0.114946\n",
      "2024-03-02 20:08:18,067 INFO     Training average positive_sample_loss at step 15100: 0.130849\n",
      "2024-03-02 20:08:18,067 INFO     Training average negative_sample_loss at step 15100: 0.096291\n",
      "2024-03-02 20:08:18,067 INFO     Training average loss at step 15100: 0.113570\n",
      "2024-03-02 20:08:41,637 INFO     Training average positive_sample_loss at step 15200: 0.134483\n",
      "2024-03-02 20:08:41,638 INFO     Training average negative_sample_loss at step 15200: 0.098102\n",
      "2024-03-02 20:08:41,638 INFO     Training average loss at step 15200: 0.116293\n",
      "2024-03-02 20:09:08,591 INFO     Training average positive_sample_loss at step 15300: 0.127451\n",
      "2024-03-02 20:09:08,591 INFO     Training average negative_sample_loss at step 15300: 0.096961\n",
      "2024-03-02 20:09:08,592 INFO     Training average loss at step 15300: 0.112206\n",
      "2024-03-02 20:09:32,373 INFO     Training average positive_sample_loss at step 15400: 0.132399\n",
      "2024-03-02 20:09:32,373 INFO     Training average negative_sample_loss at step 15400: 0.096444\n",
      "2024-03-02 20:09:32,373 INFO     Training average loss at step 15400: 0.114421\n",
      "2024-03-02 20:09:59,226 INFO     Training average positive_sample_loss at step 15500: 0.131875\n",
      "2024-03-02 20:09:59,226 INFO     Training average negative_sample_loss at step 15500: 0.097960\n",
      "2024-03-02 20:09:59,226 INFO     Training average loss at step 15500: 0.114918\n",
      "2024-03-02 20:10:22,462 INFO     Training average positive_sample_loss at step 15600: 0.129150\n",
      "2024-03-02 20:10:22,463 INFO     Training average negative_sample_loss at step 15600: 0.096267\n",
      "2024-03-02 20:10:22,463 INFO     Training average loss at step 15600: 0.112708\n",
      "2024-03-02 20:10:47,170 INFO     Training average positive_sample_loss at step 15700: 0.133619\n",
      "2024-03-02 20:10:47,170 INFO     Training average negative_sample_loss at step 15700: 0.097043\n",
      "2024-03-02 20:10:47,170 INFO     Training average loss at step 15700: 0.115331\n",
      "2024-03-02 20:11:15,433 INFO     Training average positive_sample_loss at step 15800: 0.127696\n",
      "2024-03-02 20:11:15,434 INFO     Training average negative_sample_loss at step 15800: 0.096685\n",
      "2024-03-02 20:11:15,434 INFO     Training average loss at step 15800: 0.112191\n",
      "2024-03-02 20:11:38,159 INFO     Training average positive_sample_loss at step 15900: 0.131369\n",
      "2024-03-02 20:11:38,160 INFO     Training average negative_sample_loss at step 15900: 0.095601\n",
      "2024-03-02 20:11:38,160 INFO     Training average loss at step 15900: 0.113485\n",
      "2024-03-02 20:12:06,994 INFO     Training average positive_sample_loss at step 16000: 0.133063\n",
      "2024-03-02 20:12:06,994 INFO     Training average negative_sample_loss at step 16000: 0.097801\n",
      "2024-03-02 20:12:06,994 INFO     Training average loss at step 16000: 0.115432\n",
      "2024-03-02 20:12:30,312 INFO     Training average positive_sample_loss at step 16100: 0.126830\n",
      "2024-03-02 20:12:30,313 INFO     Training average negative_sample_loss at step 16100: 0.095359\n",
      "2024-03-02 20:12:30,313 INFO     Training average loss at step 16100: 0.111094\n",
      "2024-03-02 20:12:54,533 INFO     Training average positive_sample_loss at step 16200: 0.132857\n",
      "2024-03-02 20:12:54,533 INFO     Training average negative_sample_loss at step 16200: 0.096788\n",
      "2024-03-02 20:12:54,533 INFO     Training average loss at step 16200: 0.114822\n",
      "2024-03-02 20:13:23,272 INFO     Training average positive_sample_loss at step 16300: 0.128354\n",
      "2024-03-02 20:13:23,272 INFO     Training average negative_sample_loss at step 16300: 0.096628\n",
      "2024-03-02 20:13:23,272 INFO     Training average loss at step 16300: 0.112491\n",
      "2024-03-02 20:13:47,326 INFO     Training average positive_sample_loss at step 16400: 0.130493\n",
      "2024-03-02 20:13:47,326 INFO     Training average negative_sample_loss at step 16400: 0.095044\n",
      "2024-03-02 20:13:47,326 INFO     Training average loss at step 16400: 0.112769\n",
      "2024-03-02 20:14:12,933 INFO     Training average positive_sample_loss at step 16500: 0.133136\n",
      "2024-03-02 20:14:12,933 INFO     Training average negative_sample_loss at step 16500: 0.097657\n",
      "2024-03-02 20:14:12,933 INFO     Training average loss at step 16500: 0.115397\n",
      "2024-03-02 20:14:39,684 INFO     Training average positive_sample_loss at step 16600: 0.125887\n",
      "2024-03-02 20:14:39,684 INFO     Training average negative_sample_loss at step 16600: 0.095101\n",
      "2024-03-02 20:14:39,685 INFO     Training average loss at step 16600: 0.110494\n",
      "2024-03-02 20:15:03,138 INFO     Training average positive_sample_loss at step 16700: 0.132141\n",
      "2024-03-02 20:15:03,138 INFO     Training average negative_sample_loss at step 16700: 0.095903\n",
      "2024-03-02 20:15:03,139 INFO     Training average loss at step 16700: 0.114022\n",
      "2024-03-02 20:15:29,613 INFO     Training average positive_sample_loss at step 16800: 0.130256\n",
      "2024-03-02 20:15:29,613 INFO     Training average negative_sample_loss at step 16800: 0.097743\n",
      "2024-03-02 20:15:29,613 INFO     Training average loss at step 16800: 0.114000\n",
      "2024-03-02 20:15:53,305 INFO     Training average positive_sample_loss at step 16900: 0.129072\n",
      "2024-03-02 20:15:53,305 INFO     Training average negative_sample_loss at step 16900: 0.095519\n",
      "2024-03-02 20:15:53,305 INFO     Training average loss at step 16900: 0.112296\n",
      "2024-03-02 20:16:16,754 INFO     Training average positive_sample_loss at step 17000: 0.132412\n",
      "2024-03-02 20:16:16,755 INFO     Training average negative_sample_loss at step 17000: 0.096635\n",
      "2024-03-02 20:16:16,755 INFO     Training average loss at step 17000: 0.114524\n",
      "2024-03-02 20:16:44,858 INFO     Training average positive_sample_loss at step 17100: 0.126403\n",
      "2024-03-02 20:16:44,859 INFO     Training average negative_sample_loss at step 17100: 0.095301\n",
      "2024-03-02 20:16:44,859 INFO     Training average loss at step 17100: 0.110852\n",
      "2024-03-02 20:17:08,102 INFO     Training average positive_sample_loss at step 17200: 0.130834\n",
      "2024-03-02 20:17:08,102 INFO     Training average negative_sample_loss at step 17200: 0.095507\n",
      "2024-03-02 20:17:08,102 INFO     Training average loss at step 17200: 0.113170\n",
      "2024-03-02 20:17:35,944 INFO     Training average positive_sample_loss at step 17300: 0.131185\n",
      "2024-03-02 20:17:35,944 INFO     Training average negative_sample_loss at step 17300: 0.096697\n",
      "2024-03-02 20:17:35,944 INFO     Training average loss at step 17300: 0.113941\n",
      "2024-03-02 20:18:00,293 INFO     Training average positive_sample_loss at step 17400: 0.127275\n",
      "2024-03-02 20:18:00,293 INFO     Training average negative_sample_loss at step 17400: 0.095965\n",
      "2024-03-02 20:18:00,293 INFO     Training average loss at step 17400: 0.111620\n",
      "2024-03-02 20:18:24,222 INFO     Training average positive_sample_loss at step 17500: 0.131532\n",
      "2024-03-02 20:18:24,222 INFO     Training average negative_sample_loss at step 17500: 0.095322\n",
      "2024-03-02 20:18:24,222 INFO     Training average loss at step 17500: 0.113427\n",
      "2024-03-02 20:18:50,519 INFO     Training average positive_sample_loss at step 17600: 0.127040\n",
      "2024-03-02 20:18:50,519 INFO     Training average negative_sample_loss at step 17600: 0.095846\n",
      "2024-03-02 20:18:50,519 INFO     Training average loss at step 17600: 0.111443\n",
      "2024-03-02 20:19:14,319 INFO     Training average positive_sample_loss at step 17700: 0.130121\n",
      "2024-03-02 20:19:14,319 INFO     Training average negative_sample_loss at step 17700: 0.094532\n",
      "2024-03-02 20:19:14,319 INFO     Training average loss at step 17700: 0.112326\n",
      "2024-03-02 20:19:37,970 INFO     Training average positive_sample_loss at step 17800: 0.132106\n",
      "2024-03-02 20:19:37,970 INFO     Training average negative_sample_loss at step 17800: 0.095955\n",
      "2024-03-02 20:19:37,970 INFO     Training average loss at step 17800: 0.114031\n",
      "2024-03-02 20:20:05,266 INFO     Training average positive_sample_loss at step 17900: 0.124968\n",
      "2024-03-02 20:20:05,267 INFO     Training average negative_sample_loss at step 17900: 0.094838\n",
      "2024-03-02 20:20:05,267 INFO     Training average loss at step 17900: 0.109903\n",
      "2024-03-02 20:20:28,606 INFO     Training average positive_sample_loss at step 18000: 0.131251\n",
      "2024-03-02 20:20:28,606 INFO     Training average negative_sample_loss at step 18000: 0.094764\n",
      "2024-03-02 20:20:28,606 INFO     Training average loss at step 18000: 0.113008\n",
      "2024-03-02 20:20:55,624 INFO     Training average positive_sample_loss at step 18100: 0.127950\n",
      "2024-03-02 20:20:55,625 INFO     Training average negative_sample_loss at step 18100: 0.096765\n",
      "2024-03-02 20:20:55,625 INFO     Training average loss at step 18100: 0.112357\n",
      "2024-03-02 20:21:19,825 INFO     Training average positive_sample_loss at step 18200: 0.128763\n",
      "2024-03-02 20:21:19,825 INFO     Training average negative_sample_loss at step 18200: 0.094506\n",
      "2024-03-02 20:21:19,825 INFO     Training average loss at step 18200: 0.111634\n",
      "2024-03-02 20:21:43,896 INFO     Training average positive_sample_loss at step 18300: 0.131652\n",
      "2024-03-02 20:21:43,897 INFO     Training average negative_sample_loss at step 18300: 0.095732\n",
      "2024-03-02 20:21:43,897 INFO     Training average loss at step 18300: 0.113692\n",
      "2024-03-02 20:22:13,294 INFO     Training average positive_sample_loss at step 18400: 0.125054\n",
      "2024-03-02 20:22:13,294 INFO     Training average negative_sample_loss at step 18400: 0.094817\n",
      "2024-03-02 20:22:13,294 INFO     Training average loss at step 18400: 0.109935\n",
      "2024-03-02 20:22:37,008 INFO     Training average positive_sample_loss at step 18500: 0.130193\n",
      "2024-03-02 20:22:37,008 INFO     Training average negative_sample_loss at step 18500: 0.095336\n",
      "2024-03-02 20:22:37,009 INFO     Training average loss at step 18500: 0.112764\n",
      "2024-03-02 20:23:04,097 INFO     Training average positive_sample_loss at step 18600: 0.129176\n",
      "2024-03-02 20:23:04,098 INFO     Training average negative_sample_loss at step 18600: 0.095793\n",
      "2024-03-02 20:23:04,098 INFO     Training average loss at step 18600: 0.112485\n",
      "2024-03-02 20:23:27,964 INFO     Training average positive_sample_loss at step 18700: 0.127282\n",
      "2024-03-02 20:23:27,964 INFO     Training average negative_sample_loss at step 18700: 0.094306\n",
      "2024-03-02 20:23:27,964 INFO     Training average loss at step 18700: 0.110794\n",
      "2024-03-02 20:23:52,869 INFO     Training average positive_sample_loss at step 18800: 0.131146\n",
      "2024-03-02 20:23:52,870 INFO     Training average negative_sample_loss at step 18800: 0.095850\n",
      "2024-03-02 20:23:52,870 INFO     Training average loss at step 18800: 0.113498\n",
      "2024-03-02 20:24:19,737 INFO     Training average positive_sample_loss at step 18900: 0.126148\n",
      "2024-03-02 20:24:19,738 INFO     Training average negative_sample_loss at step 18900: 0.095773\n",
      "2024-03-02 20:24:19,738 INFO     Training average loss at step 18900: 0.110961\n",
      "2024-03-02 20:24:43,266 INFO     Training average positive_sample_loss at step 19000: 0.129766\n",
      "2024-03-02 20:24:43,266 INFO     Training average negative_sample_loss at step 19000: 0.094788\n",
      "2024-03-02 20:24:43,266 INFO     Training average loss at step 19000: 0.112277\n",
      "2024-03-02 20:25:11,180 INFO     Training average positive_sample_loss at step 19100: 0.130523\n",
      "2024-03-02 20:25:11,180 INFO     Training average negative_sample_loss at step 19100: 0.096351\n",
      "2024-03-02 20:25:11,180 INFO     Training average loss at step 19100: 0.113437\n",
      "2024-03-02 20:25:36,039 INFO     Training average positive_sample_loss at step 19200: 0.125803\n",
      "2024-03-02 20:25:36,040 INFO     Training average negative_sample_loss at step 19200: 0.094107\n",
      "2024-03-02 20:25:36,040 INFO     Training average loss at step 19200: 0.109955\n",
      "2024-03-02 20:26:01,255 INFO     Training average positive_sample_loss at step 19300: 0.130700\n",
      "2024-03-02 20:26:01,256 INFO     Training average negative_sample_loss at step 19300: 0.095172\n",
      "2024-03-02 20:26:01,256 INFO     Training average loss at step 19300: 0.112936\n",
      "2024-03-02 20:26:28,815 INFO     Training average positive_sample_loss at step 19400: 0.125745\n",
      "2024-03-02 20:26:28,815 INFO     Training average negative_sample_loss at step 19400: 0.095106\n",
      "2024-03-02 20:26:28,815 INFO     Training average loss at step 19400: 0.110426\n",
      "2024-03-02 20:26:53,942 INFO     Training average positive_sample_loss at step 19500: 0.128228\n",
      "2024-03-02 20:26:53,943 INFO     Training average negative_sample_loss at step 19500: 0.094195\n",
      "2024-03-02 20:26:53,943 INFO     Training average loss at step 19500: 0.111211\n",
      "2024-03-02 20:27:17,311 INFO     Training average positive_sample_loss at step 19600: 0.131583\n",
      "2024-03-02 20:27:17,311 INFO     Training average negative_sample_loss at step 19600: 0.096080\n",
      "2024-03-02 20:27:17,311 INFO     Training average loss at step 19600: 0.113831\n",
      "2024-03-02 20:27:46,374 INFO     Training average positive_sample_loss at step 19700: 0.124609\n",
      "2024-03-02 20:27:46,374 INFO     Training average negative_sample_loss at step 19700: 0.094330\n",
      "2024-03-02 20:27:46,374 INFO     Training average loss at step 19700: 0.109470\n",
      "2024-03-02 20:28:09,660 INFO     Training average positive_sample_loss at step 19800: 0.129984\n",
      "2024-03-02 20:28:09,661 INFO     Training average negative_sample_loss at step 19800: 0.094235\n",
      "2024-03-02 20:28:09,661 INFO     Training average loss at step 19800: 0.112109\n",
      "2024-03-02 20:28:38,062 INFO     Training average positive_sample_loss at step 19900: 0.127367\n",
      "2024-03-02 20:28:38,062 INFO     Training average negative_sample_loss at step 19900: 0.095869\n",
      "2024-03-02 20:28:38,062 INFO     Training average loss at step 19900: 0.111618\n",
      "2024-03-02 20:29:05,294 INFO     Training average positive_sample_loss at step 20000: 0.126706\n",
      "2024-03-02 20:29:05,295 INFO     Training average negative_sample_loss at step 20000: 0.093588\n",
      "2024-03-02 20:29:05,295 INFO     Training average loss at step 20000: 0.110147\n",
      "2024-03-02 20:29:05,295 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-02 20:29:05,773 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-02 20:29:33,950 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-02 20:29:57,088 INFO     Valid MRR at step 20000: 0.623550\n",
      "2024-03-02 20:29:57,088 INFO     Valid MR at step 20000: 245.141619\n",
      "2024-03-02 20:29:57,088 INFO     Valid HITS@1 at step 20000: 0.562487\n",
      "2024-03-02 20:29:57,088 INFO     Valid HITS@3 at step 20000: 0.659731\n",
      "2024-03-02 20:29:57,088 INFO     Valid HITS@10 at step 20000: 0.737294\n",
      "2024-03-02 20:30:16,939 INFO     Training average positive_sample_loss at step 20100: 0.131254\n",
      "2024-03-02 20:30:16,940 INFO     Training average negative_sample_loss at step 20100: 0.095297\n",
      "2024-03-02 20:30:16,940 INFO     Training average loss at step 20100: 0.113276\n",
      "2024-03-02 20:30:46,714 INFO     Training average positive_sample_loss at step 20200: 0.124418\n",
      "2024-03-02 20:30:46,714 INFO     Training average negative_sample_loss at step 20200: 0.094990\n",
      "2024-03-02 20:30:46,714 INFO     Training average loss at step 20200: 0.109704\n",
      "2024-03-02 20:31:12,012 INFO     Training average positive_sample_loss at step 20300: 0.130234\n",
      "2024-03-02 20:31:12,012 INFO     Training average negative_sample_loss at step 20300: 0.094557\n",
      "2024-03-02 20:31:12,012 INFO     Training average loss at step 20300: 0.112396\n",
      "2024-03-02 20:31:40,329 INFO     Training average positive_sample_loss at step 20400: 0.127888\n",
      "2024-03-02 20:31:40,329 INFO     Training average negative_sample_loss at step 20400: 0.095369\n",
      "2024-03-02 20:31:40,329 INFO     Training average loss at step 20400: 0.111628\n",
      "2024-03-02 20:32:05,467 INFO     Training average positive_sample_loss at step 20500: 0.126042\n",
      "2024-03-02 20:32:05,467 INFO     Training average negative_sample_loss at step 20500: 0.094042\n",
      "2024-03-02 20:32:05,467 INFO     Training average loss at step 20500: 0.110042\n",
      "2024-03-02 20:32:30,999 INFO     Training average positive_sample_loss at step 20600: 0.130080\n",
      "2024-03-02 20:32:30,999 INFO     Training average negative_sample_loss at step 20600: 0.094676\n",
      "2024-03-02 20:32:30,999 INFO     Training average loss at step 20600: 0.112378\n",
      "2024-03-02 20:32:57,527 INFO     Training average positive_sample_loss at step 20700: 0.124300\n",
      "2024-03-02 20:32:57,527 INFO     Training average negative_sample_loss at step 20700: 0.094217\n",
      "2024-03-02 20:32:57,527 INFO     Training average loss at step 20700: 0.109259\n",
      "2024-03-02 20:33:21,385 INFO     Training average positive_sample_loss at step 20800: 0.128879\n",
      "2024-03-02 20:33:21,386 INFO     Training average negative_sample_loss at step 20800: 0.093099\n",
      "2024-03-02 20:33:21,386 INFO     Training average loss at step 20800: 0.110989\n",
      "2024-03-02 20:33:50,837 INFO     Training average positive_sample_loss at step 20900: 0.130164\n",
      "2024-03-02 20:33:50,838 INFO     Training average negative_sample_loss at step 20900: 0.095588\n",
      "2024-03-02 20:33:50,838 INFO     Training average loss at step 20900: 0.112876\n",
      "2024-03-02 20:34:14,299 INFO     Training average positive_sample_loss at step 21000: 0.123491\n",
      "2024-03-02 20:34:14,300 INFO     Training average negative_sample_loss at step 21000: 0.093411\n",
      "2024-03-02 20:34:14,300 INFO     Training average loss at step 21000: 0.108451\n",
      "2024-03-02 20:34:38,338 INFO     Training average positive_sample_loss at step 21100: 0.129687\n",
      "2024-03-02 20:34:38,339 INFO     Training average negative_sample_loss at step 21100: 0.093553\n",
      "2024-03-02 20:34:38,339 INFO     Training average loss at step 21100: 0.111620\n",
      "2024-03-02 20:35:04,870 INFO     Training average positive_sample_loss at step 21200: 0.126346\n",
      "2024-03-02 20:35:04,870 INFO     Training average negative_sample_loss at step 21200: 0.096000\n",
      "2024-03-02 20:35:04,870 INFO     Training average loss at step 21200: 0.111173\n",
      "2024-03-02 20:35:29,209 INFO     Training average positive_sample_loss at step 21300: 0.127534\n",
      "2024-03-02 20:35:29,210 INFO     Training average negative_sample_loss at step 21300: 0.093337\n",
      "2024-03-02 20:35:29,210 INFO     Training average loss at step 21300: 0.110435\n",
      "2024-03-02 20:35:52,385 INFO     Training average positive_sample_loss at step 21400: 0.129756\n",
      "2024-03-02 20:35:52,386 INFO     Training average negative_sample_loss at step 21400: 0.095413\n",
      "2024-03-02 20:35:52,386 INFO     Training average loss at step 21400: 0.112585\n",
      "2024-03-02 20:36:20,421 INFO     Training average positive_sample_loss at step 21500: 0.123647\n",
      "2024-03-02 20:36:20,421 INFO     Training average negative_sample_loss at step 21500: 0.093526\n",
      "2024-03-02 20:36:20,421 INFO     Training average loss at step 21500: 0.108586\n",
      "2024-03-02 20:36:46,048 INFO     Training average positive_sample_loss at step 21600: 0.128878\n",
      "2024-03-02 20:36:46,049 INFO     Training average negative_sample_loss at step 21600: 0.093976\n",
      "2024-03-02 20:36:46,049 INFO     Training average loss at step 21600: 0.111427\n",
      "2024-03-02 20:37:14,256 INFO     Training average positive_sample_loss at step 21700: 0.127819\n",
      "2024-03-02 20:37:14,256 INFO     Training average negative_sample_loss at step 21700: 0.095475\n",
      "2024-03-02 20:37:14,256 INFO     Training average loss at step 21700: 0.111647\n",
      "2024-03-02 20:37:40,271 INFO     Training average positive_sample_loss at step 21800: 0.125550\n",
      "2024-03-02 20:37:40,271 INFO     Training average negative_sample_loss at step 21800: 0.092673\n",
      "2024-03-02 20:37:40,272 INFO     Training average loss at step 21800: 0.109111\n",
      "2024-03-02 20:38:04,556 INFO     Training average positive_sample_loss at step 21900: 0.129269\n",
      "2024-03-02 20:38:04,556 INFO     Training average negative_sample_loss at step 21900: 0.094345\n",
      "2024-03-02 20:38:04,556 INFO     Training average loss at step 21900: 0.111807\n",
      "2024-03-02 20:38:32,387 INFO     Training average positive_sample_loss at step 22000: 0.124727\n",
      "2024-03-02 20:38:32,387 INFO     Training average negative_sample_loss at step 22000: 0.094035\n",
      "2024-03-02 20:38:32,387 INFO     Training average loss at step 22000: 0.109381\n",
      "2024-03-02 20:38:55,785 INFO     Training average positive_sample_loss at step 22100: 0.128459\n",
      "2024-03-02 20:38:55,786 INFO     Training average negative_sample_loss at step 22100: 0.093512\n",
      "2024-03-02 20:38:55,786 INFO     Training average loss at step 22100: 0.110986\n",
      "2024-03-02 20:39:25,655 INFO     Training average positive_sample_loss at step 22200: 0.128266\n",
      "2024-03-02 20:39:25,656 INFO     Training average negative_sample_loss at step 22200: 0.095578\n",
      "2024-03-02 20:39:25,656 INFO     Training average loss at step 22200: 0.111922\n",
      "2024-03-02 20:39:48,928 INFO     Training average positive_sample_loss at step 22300: 0.124823\n",
      "2024-03-02 20:39:48,928 INFO     Training average negative_sample_loss at step 22300: 0.092892\n",
      "2024-03-02 20:39:48,928 INFO     Training average loss at step 22300: 0.108858\n",
      "2024-03-02 20:40:13,491 INFO     Training average positive_sample_loss at step 22400: 0.129258\n",
      "2024-03-02 20:40:13,492 INFO     Training average negative_sample_loss at step 22400: 0.094608\n",
      "2024-03-02 20:40:13,492 INFO     Training average loss at step 22400: 0.111933\n",
      "2024-03-02 20:40:40,935 INFO     Training average positive_sample_loss at step 22500: 0.124657\n",
      "2024-03-02 20:40:40,935 INFO     Training average negative_sample_loss at step 22500: 0.094250\n",
      "2024-03-02 20:40:40,936 INFO     Training average loss at step 22500: 0.109454\n",
      "2024-03-02 20:41:04,046 INFO     Training average positive_sample_loss at step 22600: 0.127699\n",
      "2024-03-02 20:41:04,047 INFO     Training average negative_sample_loss at step 22600: 0.092998\n",
      "2024-03-02 20:41:04,047 INFO     Training average loss at step 22600: 0.110349\n",
      "2024-03-02 20:41:27,995 INFO     Training average positive_sample_loss at step 22700: 0.129574\n",
      "2024-03-02 20:41:27,996 INFO     Training average negative_sample_loss at step 22700: 0.094843\n",
      "2024-03-02 20:41:27,996 INFO     Training average loss at step 22700: 0.112208\n",
      "2024-03-02 20:41:54,783 INFO     Training average positive_sample_loss at step 22800: 0.122905\n",
      "2024-03-02 20:41:54,783 INFO     Training average negative_sample_loss at step 22800: 0.092800\n",
      "2024-03-02 20:41:54,783 INFO     Training average loss at step 22800: 0.107853\n",
      "2024-03-02 20:42:20,193 INFO     Training average positive_sample_loss at step 22900: 0.128545\n",
      "2024-03-02 20:42:20,194 INFO     Training average negative_sample_loss at step 22900: 0.093278\n",
      "2024-03-02 20:42:20,194 INFO     Training average loss at step 22900: 0.110911\n",
      "2024-03-02 20:42:47,418 INFO     Training average positive_sample_loss at step 23000: 0.125994\n",
      "2024-03-02 20:42:47,418 INFO     Training average negative_sample_loss at step 23000: 0.094979\n",
      "2024-03-02 20:42:47,418 INFO     Training average loss at step 23000: 0.110487\n",
      "2024-03-02 20:43:11,809 INFO     Training average positive_sample_loss at step 23100: 0.126455\n",
      "2024-03-02 20:43:11,810 INFO     Training average negative_sample_loss at step 23100: 0.093441\n",
      "2024-03-02 20:43:11,810 INFO     Training average loss at step 23100: 0.109948\n",
      "2024-03-02 20:43:37,576 INFO     Training average positive_sample_loss at step 23200: 0.129192\n",
      "2024-03-02 20:43:37,576 INFO     Training average negative_sample_loss at step 23200: 0.093415\n",
      "2024-03-02 20:43:37,576 INFO     Training average loss at step 23200: 0.111303\n",
      "2024-03-02 20:44:05,168 INFO     Training average positive_sample_loss at step 23300: 0.123114\n",
      "2024-03-02 20:44:05,168 INFO     Training average negative_sample_loss at step 23300: 0.093622\n",
      "2024-03-02 20:44:05,168 INFO     Training average loss at step 23300: 0.108368\n",
      "2024-03-02 20:44:31,044 INFO     Training average positive_sample_loss at step 23400: 0.128057\n",
      "2024-03-02 20:44:31,044 INFO     Training average negative_sample_loss at step 23400: 0.093279\n",
      "2024-03-02 20:44:31,044 INFO     Training average loss at step 23400: 0.110668\n",
      "2024-03-02 20:44:58,574 INFO     Training average positive_sample_loss at step 23500: 0.126792\n",
      "2024-03-02 20:44:58,574 INFO     Training average negative_sample_loss at step 23500: 0.095268\n",
      "2024-03-02 20:44:58,574 INFO     Training average loss at step 23500: 0.111030\n",
      "2024-03-02 20:45:21,554 INFO     Training average positive_sample_loss at step 23600: 0.124953\n",
      "2024-03-02 20:45:21,555 INFO     Training average negative_sample_loss at step 23600: 0.091962\n",
      "2024-03-02 20:45:21,555 INFO     Training average loss at step 23600: 0.108457\n",
      "2024-03-02 20:45:45,074 INFO     Training average positive_sample_loss at step 23700: 0.129111\n",
      "2024-03-02 20:45:45,074 INFO     Training average negative_sample_loss at step 23700: 0.093740\n",
      "2024-03-02 20:45:45,074 INFO     Training average loss at step 23700: 0.111426\n",
      "2024-03-02 20:46:14,339 INFO     Training average positive_sample_loss at step 23800: 0.124412\n",
      "2024-03-02 20:46:14,340 INFO     Training average negative_sample_loss at step 23800: 0.094492\n",
      "2024-03-02 20:46:14,340 INFO     Training average loss at step 23800: 0.109452\n",
      "2024-03-02 20:46:39,172 INFO     Training average positive_sample_loss at step 23900: 0.127038\n",
      "2024-03-02 20:46:39,172 INFO     Training average negative_sample_loss at step 23900: 0.092647\n",
      "2024-03-02 20:46:39,172 INFO     Training average loss at step 23900: 0.109842\n",
      "2024-03-02 20:47:05,979 INFO     Training average positive_sample_loss at step 24000: 0.128300\n",
      "2024-03-02 20:47:05,979 INFO     Training average negative_sample_loss at step 24000: 0.093835\n",
      "2024-03-02 20:47:05,980 INFO     Training average loss at step 24000: 0.111068\n",
      "2024-03-02 20:47:31,051 INFO     Training average positive_sample_loss at step 24100: 0.123260\n",
      "2024-03-02 20:47:31,051 INFO     Training average negative_sample_loss at step 24100: 0.093270\n",
      "2024-03-02 20:47:31,051 INFO     Training average loss at step 24100: 0.108265\n",
      "2024-03-02 20:47:56,337 INFO     Training average positive_sample_loss at step 24200: 0.128194\n",
      "2024-03-02 20:47:56,337 INFO     Training average negative_sample_loss at step 24200: 0.093393\n",
      "2024-03-02 20:47:56,338 INFO     Training average loss at step 24200: 0.110794\n",
      "2024-03-02 20:48:24,216 INFO     Training average positive_sample_loss at step 24300: 0.124849\n",
      "2024-03-02 20:48:24,217 INFO     Training average negative_sample_loss at step 24300: 0.093989\n",
      "2024-03-02 20:48:24,217 INFO     Training average loss at step 24300: 0.109419\n",
      "2024-03-02 20:48:50,113 INFO     Training average positive_sample_loss at step 24400: 0.126430\n",
      "2024-03-02 20:48:50,113 INFO     Training average negative_sample_loss at step 24400: 0.092843\n",
      "2024-03-02 20:48:50,113 INFO     Training average loss at step 24400: 0.109636\n",
      "2024-03-02 20:49:15,321 INFO     Training average positive_sample_loss at step 24500: 0.129275\n",
      "2024-03-02 20:49:15,322 INFO     Training average negative_sample_loss at step 24500: 0.093655\n",
      "2024-03-02 20:49:15,322 INFO     Training average loss at step 24500: 0.111465\n",
      "2024-03-02 20:49:43,933 INFO     Training average positive_sample_loss at step 24600: 0.122083\n",
      "2024-03-02 20:49:43,933 INFO     Training average negative_sample_loss at step 24600: 0.092961\n",
      "2024-03-02 20:49:43,933 INFO     Training average loss at step 24600: 0.107522\n",
      "2024-03-02 20:50:07,128 INFO     Training average positive_sample_loss at step 24700: 0.128157\n",
      "2024-03-02 20:50:07,129 INFO     Training average negative_sample_loss at step 24700: 0.092566\n",
      "2024-03-02 20:50:07,129 INFO     Training average loss at step 24700: 0.110362\n",
      "2024-03-02 20:50:34,775 INFO     Training average positive_sample_loss at step 24800: 0.125453\n",
      "2024-03-02 20:50:34,776 INFO     Training average negative_sample_loss at step 24800: 0.094112\n",
      "2024-03-02 20:50:34,776 INFO     Training average loss at step 24800: 0.109783\n",
      "2024-03-02 20:50:58,338 INFO     Training average positive_sample_loss at step 24900: 0.124948\n",
      "2024-03-02 20:50:58,338 INFO     Training average negative_sample_loss at step 24900: 0.092330\n",
      "2024-03-02 20:50:58,338 INFO     Training average loss at step 24900: 0.108639\n",
      "2024-03-02 20:51:21,531 INFO     Training average positive_sample_loss at step 25000: 0.129170\n",
      "2024-03-02 20:51:21,532 INFO     Training average negative_sample_loss at step 25000: 0.093863\n",
      "2024-03-02 20:51:21,532 INFO     Training average loss at step 25000: 0.111516\n",
      "2024-03-02 20:51:48,713 INFO     Training average positive_sample_loss at step 25100: 0.122360\n",
      "2024-03-02 20:51:48,713 INFO     Training average negative_sample_loss at step 25100: 0.092258\n",
      "2024-03-02 20:51:48,713 INFO     Training average loss at step 25100: 0.107309\n",
      "2024-03-02 20:52:11,902 INFO     Training average positive_sample_loss at step 25200: 0.126804\n",
      "2024-03-02 20:52:11,903 INFO     Training average negative_sample_loss at step 25200: 0.092864\n",
      "2024-03-02 20:52:11,903 INFO     Training average loss at step 25200: 0.109834\n",
      "2024-03-02 20:52:39,336 INFO     Training average positive_sample_loss at step 25300: 0.127840\n",
      "2024-03-02 20:52:39,336 INFO     Training average negative_sample_loss at step 25300: 0.094505\n",
      "2024-03-02 20:52:39,337 INFO     Training average loss at step 25300: 0.111173\n",
      "2024-03-02 20:53:02,403 INFO     Training average positive_sample_loss at step 25400: 0.123491\n",
      "2024-03-02 20:53:02,403 INFO     Training average negative_sample_loss at step 25400: 0.091963\n",
      "2024-03-02 20:53:02,403 INFO     Training average loss at step 25400: 0.107727\n",
      "2024-03-02 20:53:26,206 INFO     Training average positive_sample_loss at step 25500: 0.128286\n",
      "2024-03-02 20:53:26,207 INFO     Training average negative_sample_loss at step 25500: 0.093351\n",
      "2024-03-02 20:53:26,207 INFO     Training average loss at step 25500: 0.110818\n",
      "2024-03-02 20:53:52,381 INFO     Training average positive_sample_loss at step 25600: 0.123424\n",
      "2024-03-02 20:53:52,381 INFO     Training average negative_sample_loss at step 25600: 0.093409\n",
      "2024-03-02 20:53:52,381 INFO     Training average loss at step 25600: 0.108416\n",
      "2024-03-02 20:54:15,648 INFO     Training average positive_sample_loss at step 25700: 0.126763\n",
      "2024-03-02 20:54:15,648 INFO     Training average negative_sample_loss at step 25700: 0.091826\n",
      "2024-03-02 20:54:15,649 INFO     Training average loss at step 25700: 0.109295\n",
      "2024-03-02 20:54:41,146 INFO     Training average positive_sample_loss at step 25800: 0.128403\n",
      "2024-03-02 20:54:41,146 INFO     Training average negative_sample_loss at step 25800: 0.093811\n",
      "2024-03-02 20:54:41,146 INFO     Training average loss at step 25800: 0.111107\n",
      "2024-03-02 20:55:06,730 INFO     Training average positive_sample_loss at step 25900: 0.121703\n",
      "2024-03-02 20:55:06,731 INFO     Training average negative_sample_loss at step 25900: 0.092259\n",
      "2024-03-02 20:55:06,731 INFO     Training average loss at step 25900: 0.106981\n",
      "2024-03-02 20:55:33,349 INFO     Training average positive_sample_loss at step 26000: 0.128014\n",
      "2024-03-02 20:55:33,350 INFO     Training average negative_sample_loss at step 26000: 0.092758\n",
      "2024-03-02 20:55:33,350 INFO     Training average loss at step 26000: 0.110386\n",
      "2024-03-02 20:55:59,939 INFO     Training average positive_sample_loss at step 26100: 0.124240\n",
      "2024-03-02 20:55:59,940 INFO     Training average negative_sample_loss at step 26100: 0.093833\n",
      "2024-03-02 20:55:59,940 INFO     Training average loss at step 26100: 0.109037\n",
      "2024-03-02 20:56:23,450 INFO     Training average positive_sample_loss at step 26200: 0.125632\n",
      "2024-03-02 20:56:23,451 INFO     Training average negative_sample_loss at step 26200: 0.092081\n",
      "2024-03-02 20:56:23,451 INFO     Training average loss at step 26200: 0.108856\n",
      "2024-03-02 20:56:47,512 INFO     Training average positive_sample_loss at step 26300: 0.128599\n",
      "2024-03-02 20:56:47,513 INFO     Training average negative_sample_loss at step 26300: 0.094133\n",
      "2024-03-02 20:56:47,513 INFO     Training average loss at step 26300: 0.111366\n",
      "2024-03-02 20:57:14,249 INFO     Training average positive_sample_loss at step 26400: 0.122193\n",
      "2024-03-02 20:57:14,249 INFO     Training average negative_sample_loss at step 26400: 0.092394\n",
      "2024-03-02 20:57:14,249 INFO     Training average loss at step 26400: 0.107293\n",
      "2024-03-02 20:57:37,012 INFO     Training average positive_sample_loss at step 26500: 0.127174\n",
      "2024-03-02 20:57:37,012 INFO     Training average negative_sample_loss at step 26500: 0.092772\n",
      "2024-03-02 20:57:37,013 INFO     Training average loss at step 26500: 0.109973\n",
      "2024-03-02 20:58:03,510 INFO     Training average positive_sample_loss at step 26600: 0.125697\n",
      "2024-03-02 20:58:03,511 INFO     Training average negative_sample_loss at step 26600: 0.093805\n",
      "2024-03-02 20:58:03,511 INFO     Training average loss at step 26600: 0.109751\n",
      "2024-03-02 20:58:28,361 INFO     Training average positive_sample_loss at step 26700: 0.123759\n",
      "2024-03-02 20:58:28,361 INFO     Training average negative_sample_loss at step 26700: 0.091669\n",
      "2024-03-02 20:58:28,361 INFO     Training average loss at step 26700: 0.107714\n",
      "2024-03-02 20:58:52,751 INFO     Training average positive_sample_loss at step 26800: 0.128312\n",
      "2024-03-02 20:58:52,751 INFO     Training average negative_sample_loss at step 26800: 0.093357\n",
      "2024-03-02 20:58:52,751 INFO     Training average loss at step 26800: 0.110835\n",
      "2024-03-02 20:59:20,101 INFO     Training average positive_sample_loss at step 26900: 0.122314\n",
      "2024-03-02 20:59:20,102 INFO     Training average negative_sample_loss at step 26900: 0.092719\n",
      "2024-03-02 20:59:20,102 INFO     Training average loss at step 26900: 0.107517\n",
      "2024-03-02 20:59:43,068 INFO     Training average positive_sample_loss at step 27000: 0.126230\n",
      "2024-03-02 20:59:43,069 INFO     Training average negative_sample_loss at step 27000: 0.092662\n",
      "2024-03-02 20:59:43,069 INFO     Training average loss at step 27000: 0.109446\n",
      "2024-03-02 21:00:09,310 INFO     Training average positive_sample_loss at step 27100: 0.128397\n",
      "2024-03-02 21:00:09,311 INFO     Training average negative_sample_loss at step 27100: 0.093589\n",
      "2024-03-02 21:00:09,311 INFO     Training average loss at step 27100: 0.110993\n",
      "2024-03-02 21:00:34,789 INFO     Training average positive_sample_loss at step 27200: 0.122279\n",
      "2024-03-02 21:00:34,790 INFO     Training average negative_sample_loss at step 27200: 0.092210\n",
      "2024-03-02 21:00:34,790 INFO     Training average loss at step 27200: 0.107244\n",
      "2024-03-02 21:01:00,680 INFO     Training average positive_sample_loss at step 27300: 0.127530\n",
      "2024-03-02 21:01:00,680 INFO     Training average negative_sample_loss at step 27300: 0.092448\n",
      "2024-03-02 21:01:00,681 INFO     Training average loss at step 27300: 0.109989\n",
      "2024-03-02 21:01:27,894 INFO     Training average positive_sample_loss at step 27400: 0.123716\n",
      "2024-03-02 21:01:27,894 INFO     Training average negative_sample_loss at step 27400: 0.093420\n",
      "2024-03-02 21:01:27,894 INFO     Training average loss at step 27400: 0.108568\n",
      "2024-03-02 21:01:51,285 INFO     Training average positive_sample_loss at step 27500: 0.125251\n",
      "2024-03-02 21:01:51,285 INFO     Training average negative_sample_loss at step 27500: 0.091931\n",
      "2024-03-02 21:01:51,285 INFO     Training average loss at step 27500: 0.108591\n",
      "2024-03-02 21:02:15,504 INFO     Training average positive_sample_loss at step 27600: 0.128702\n",
      "2024-03-02 21:02:15,504 INFO     Training average negative_sample_loss at step 27600: 0.093735\n",
      "2024-03-02 21:02:15,504 INFO     Training average loss at step 27600: 0.111218\n",
      "2024-03-02 21:02:44,837 INFO     Training average positive_sample_loss at step 27700: 0.121646\n",
      "2024-03-02 21:02:44,837 INFO     Training average negative_sample_loss at step 27700: 0.092119\n",
      "2024-03-02 21:02:44,837 INFO     Training average loss at step 27700: 0.106883\n",
      "2024-03-02 21:03:10,191 INFO     Training average positive_sample_loss at step 27800: 0.127037\n",
      "2024-03-02 21:03:10,192 INFO     Training average negative_sample_loss at step 27800: 0.092705\n",
      "2024-03-02 21:03:10,192 INFO     Training average loss at step 27800: 0.109871\n",
      "2024-03-02 21:03:37,828 INFO     Training average positive_sample_loss at step 27900: 0.124254\n",
      "2024-03-02 21:03:37,828 INFO     Training average negative_sample_loss at step 27900: 0.093382\n",
      "2024-03-02 21:03:37,828 INFO     Training average loss at step 27900: 0.108818\n",
      "2024-03-02 21:04:01,780 INFO     Training average positive_sample_loss at step 28000: 0.124491\n",
      "2024-03-02 21:04:01,780 INFO     Training average negative_sample_loss at step 28000: 0.091756\n",
      "2024-03-02 21:04:01,780 INFO     Training average loss at step 28000: 0.108124\n",
      "2024-03-02 21:04:26,320 INFO     Training average positive_sample_loss at step 28100: 0.128267\n",
      "2024-03-02 21:04:26,320 INFO     Training average negative_sample_loss at step 28100: 0.093614\n",
      "2024-03-02 21:04:26,320 INFO     Training average loss at step 28100: 0.110940\n",
      "2024-03-02 21:04:54,322 INFO     Training average positive_sample_loss at step 28200: 0.122065\n",
      "2024-03-02 21:04:54,323 INFO     Training average negative_sample_loss at step 28200: 0.092477\n",
      "2024-03-02 21:04:54,323 INFO     Training average loss at step 28200: 0.107271\n",
      "2024-03-02 21:05:18,066 INFO     Training average positive_sample_loss at step 28300: 0.126931\n",
      "2024-03-02 21:05:18,067 INFO     Training average negative_sample_loss at step 28300: 0.092487\n",
      "2024-03-02 21:05:18,067 INFO     Training average loss at step 28300: 0.109709\n",
      "2024-03-02 21:05:46,227 INFO     Training average positive_sample_loss at step 28400: 0.125594\n",
      "2024-03-02 21:05:46,227 INFO     Training average negative_sample_loss at step 28400: 0.093212\n",
      "2024-03-02 21:05:46,228 INFO     Training average loss at step 28400: 0.109403\n",
      "2024-03-02 21:06:10,161 INFO     Training average positive_sample_loss at step 28500: 0.123398\n",
      "2024-03-02 21:06:10,162 INFO     Training average negative_sample_loss at step 28500: 0.091843\n",
      "2024-03-02 21:06:10,162 INFO     Training average loss at step 28500: 0.107620\n",
      "2024-03-02 21:06:34,717 INFO     Training average positive_sample_loss at step 28600: 0.127692\n",
      "2024-03-02 21:06:34,718 INFO     Training average negative_sample_loss at step 28600: 0.092873\n",
      "2024-03-02 21:06:34,718 INFO     Training average loss at step 28600: 0.110283\n",
      "2024-03-02 21:07:03,138 INFO     Training average positive_sample_loss at step 28700: 0.122511\n",
      "2024-03-02 21:07:03,139 INFO     Training average negative_sample_loss at step 28700: 0.092942\n",
      "2024-03-02 21:07:03,139 INFO     Training average loss at step 28700: 0.107726\n",
      "2024-03-02 21:07:26,470 INFO     Training average positive_sample_loss at step 28800: 0.125982\n",
      "2024-03-02 21:07:26,470 INFO     Training average negative_sample_loss at step 28800: 0.091765\n",
      "2024-03-02 21:07:26,470 INFO     Training average loss at step 28800: 0.108873\n",
      "2024-03-02 21:07:54,903 INFO     Training average positive_sample_loss at step 28900: 0.126829\n",
      "2024-03-02 21:07:54,904 INFO     Training average negative_sample_loss at step 28900: 0.092873\n",
      "2024-03-02 21:07:54,904 INFO     Training average loss at step 28900: 0.109851\n",
      "2024-03-02 21:08:18,612 INFO     Training average positive_sample_loss at step 29000: 0.121198\n",
      "2024-03-02 21:08:18,613 INFO     Training average negative_sample_loss at step 29000: 0.091700\n",
      "2024-03-02 21:08:18,613 INFO     Training average loss at step 29000: 0.106449\n",
      "2024-03-02 21:08:42,477 INFO     Training average positive_sample_loss at step 29100: 0.127372\n",
      "2024-03-02 21:08:42,478 INFO     Training average negative_sample_loss at step 29100: 0.092364\n",
      "2024-03-02 21:08:42,478 INFO     Training average loss at step 29100: 0.109868\n",
      "2024-03-02 21:09:09,379 INFO     Training average positive_sample_loss at step 29200: 0.123592\n",
      "2024-03-02 21:09:09,379 INFO     Training average negative_sample_loss at step 29200: 0.093614\n",
      "2024-03-02 21:09:09,379 INFO     Training average loss at step 29200: 0.108603\n",
      "2024-03-02 21:09:33,886 INFO     Training average positive_sample_loss at step 29300: 0.125108\n",
      "2024-03-02 21:09:33,887 INFO     Training average negative_sample_loss at step 29300: 0.092255\n",
      "2024-03-02 21:09:33,887 INFO     Training average loss at step 29300: 0.108681\n",
      "2024-03-02 21:09:59,383 INFO     Training average positive_sample_loss at step 29400: 0.128126\n",
      "2024-03-02 21:09:59,384 INFO     Training average negative_sample_loss at step 29400: 0.093173\n",
      "2024-03-02 21:09:59,384 INFO     Training average loss at step 29400: 0.110650\n",
      "2024-03-02 21:10:26,328 INFO     Training average positive_sample_loss at step 29500: 0.121090\n",
      "2024-03-02 21:10:26,329 INFO     Training average negative_sample_loss at step 29500: 0.091580\n",
      "2024-03-02 21:10:26,329 INFO     Training average loss at step 29500: 0.106335\n",
      "2024-03-02 21:10:49,891 INFO     Training average positive_sample_loss at step 29600: 0.126499\n",
      "2024-03-02 21:10:49,892 INFO     Training average negative_sample_loss at step 29600: 0.091573\n",
      "2024-03-02 21:10:49,892 INFO     Training average loss at step 29600: 0.109036\n",
      "2024-03-02 21:11:16,608 INFO     Training average positive_sample_loss at step 29700: 0.124251\n",
      "2024-03-02 21:11:16,608 INFO     Training average negative_sample_loss at step 29700: 0.093196\n",
      "2024-03-02 21:11:16,608 INFO     Training average loss at step 29700: 0.108724\n",
      "2024-03-02 21:11:40,115 INFO     Training average positive_sample_loss at step 29800: 0.123917\n",
      "2024-03-02 21:11:40,116 INFO     Training average negative_sample_loss at step 29800: 0.091092\n",
      "2024-03-02 21:11:40,116 INFO     Training average loss at step 29800: 0.107504\n",
      "2024-03-02 21:12:03,532 INFO     Training average positive_sample_loss at step 29900: 0.127235\n",
      "2024-03-02 21:12:03,533 INFO     Training average negative_sample_loss at step 29900: 0.092466\n",
      "2024-03-02 21:12:03,533 INFO     Training average loss at step 29900: 0.109851\n",
      "2024-03-02 21:12:32,917 INFO     Training average positive_sample_loss at step 30000: 0.121786\n",
      "2024-03-02 21:12:32,917 INFO     Training average negative_sample_loss at step 30000: 0.092639\n",
      "2024-03-02 21:12:32,917 INFO     Training average loss at step 30000: 0.107213\n",
      "2024-03-02 21:12:32,917 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-02 21:12:33,552 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-02 21:13:16,292 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-02 21:13:52,779 INFO     Valid MRR at step 30000: 0.633979\n",
      "2024-03-02 21:13:52,780 INFO     Valid MR at step 30000: 241.568081\n",
      "2024-03-02 21:13:52,780 INFO     Valid HITS@1 at step 30000: 0.577393\n",
      "2024-03-02 21:13:52,780 INFO     Valid HITS@3 at step 30000: 0.659424\n",
      "2024-03-02 21:13:52,780 INFO     Valid HITS@10 at step 30000: 0.743877\n",
      "2024-03-02 21:14:13,282 INFO     Training average positive_sample_loss at step 30100: 0.126287\n",
      "2024-03-02 21:14:13,282 INFO     Training average negative_sample_loss at step 30100: 0.091655\n",
      "2024-03-02 21:14:13,282 INFO     Training average loss at step 30100: 0.108971\n",
      "2024-03-02 21:14:40,633 INFO     Training average positive_sample_loss at step 30200: 0.125520\n",
      "2024-03-02 21:14:40,634 INFO     Training average negative_sample_loss at step 30200: 0.093139\n",
      "2024-03-02 21:14:40,634 INFO     Training average loss at step 30200: 0.109329\n",
      "2024-03-02 21:15:03,921 INFO     Training average positive_sample_loss at step 30300: 0.122418\n",
      "2024-03-02 21:15:03,921 INFO     Training average negative_sample_loss at step 30300: 0.091155\n",
      "2024-03-02 21:15:03,921 INFO     Training average loss at step 30300: 0.106786\n",
      "2024-03-02 21:15:26,694 INFO     Training average positive_sample_loss at step 30400: 0.126986\n",
      "2024-03-02 21:15:26,695 INFO     Training average negative_sample_loss at step 30400: 0.092248\n",
      "2024-03-02 21:15:26,695 INFO     Training average loss at step 30400: 0.109617\n",
      "2024-03-02 21:15:53,292 INFO     Training average positive_sample_loss at step 30500: 0.122463\n",
      "2024-03-02 21:15:53,293 INFO     Training average negative_sample_loss at step 30500: 0.093690\n",
      "2024-03-02 21:15:53,293 INFO     Training average loss at step 30500: 0.108077\n",
      "2024-03-02 21:16:16,502 INFO     Training average positive_sample_loss at step 30600: 0.125498\n",
      "2024-03-02 21:16:16,502 INFO     Training average negative_sample_loss at step 30600: 0.091704\n",
      "2024-03-02 21:16:16,502 INFO     Training average loss at step 30600: 0.108601\n",
      "2024-03-02 21:16:40,378 INFO     Training average positive_sample_loss at step 30700: 0.127625\n",
      "2024-03-02 21:16:40,378 INFO     Training average negative_sample_loss at step 30700: 0.093000\n",
      "2024-03-02 21:16:40,378 INFO     Training average loss at step 30700: 0.110312\n",
      "2024-03-02 21:17:07,054 INFO     Training average positive_sample_loss at step 30800: 0.120693\n",
      "2024-03-02 21:17:07,054 INFO     Training average negative_sample_loss at step 30800: 0.091808\n",
      "2024-03-02 21:17:07,054 INFO     Training average loss at step 30800: 0.106250\n",
      "2024-03-02 21:17:30,722 INFO     Training average positive_sample_loss at step 30900: 0.126417\n",
      "2024-03-02 21:17:30,722 INFO     Training average negative_sample_loss at step 30900: 0.091535\n",
      "2024-03-02 21:17:30,722 INFO     Training average loss at step 30900: 0.108976\n",
      "2024-03-02 21:17:56,738 INFO     Training average positive_sample_loss at step 31000: 0.123755\n",
      "2024-03-02 21:17:56,738 INFO     Training average negative_sample_loss at step 31000: 0.093224\n",
      "2024-03-02 21:17:56,738 INFO     Training average loss at step 31000: 0.108489\n",
      "2024-03-02 21:18:20,649 INFO     Training average positive_sample_loss at step 31100: 0.124414\n",
      "2024-03-02 21:18:20,649 INFO     Training average negative_sample_loss at step 31100: 0.090601\n",
      "2024-03-02 21:18:20,649 INFO     Training average loss at step 31100: 0.107507\n",
      "2024-03-02 21:18:43,632 INFO     Training average positive_sample_loss at step 31200: 0.126984\n",
      "2024-03-02 21:18:43,633 INFO     Training average negative_sample_loss at step 31200: 0.092174\n",
      "2024-03-02 21:18:43,633 INFO     Training average loss at step 31200: 0.109579\n",
      "2024-03-02 21:19:12,572 INFO     Training average positive_sample_loss at step 31300: 0.121007\n",
      "2024-03-02 21:19:12,573 INFO     Training average negative_sample_loss at step 31300: 0.091707\n",
      "2024-03-02 21:19:12,573 INFO     Training average loss at step 31300: 0.106357\n",
      "2024-03-02 21:19:35,947 INFO     Training average positive_sample_loss at step 31400: 0.126634\n",
      "2024-03-02 21:19:35,947 INFO     Training average negative_sample_loss at step 31400: 0.091897\n",
      "2024-03-02 21:19:35,947 INFO     Training average loss at step 31400: 0.109266\n",
      "2024-03-02 21:20:02,358 INFO     Training average positive_sample_loss at step 31500: 0.123837\n",
      "2024-03-02 21:20:02,358 INFO     Training average negative_sample_loss at step 31500: 0.092373\n",
      "2024-03-02 21:20:02,358 INFO     Training average loss at step 31500: 0.108105\n",
      "2024-03-02 21:20:26,141 INFO     Training average positive_sample_loss at step 31600: 0.123080\n",
      "2024-03-02 21:20:26,142 INFO     Training average negative_sample_loss at step 31600: 0.090991\n",
      "2024-03-02 21:20:26,142 INFO     Training average loss at step 31600: 0.107035\n",
      "2024-03-02 21:20:49,630 INFO     Training average positive_sample_loss at step 31700: 0.126477\n",
      "2024-03-02 21:20:49,631 INFO     Training average negative_sample_loss at step 31700: 0.092157\n",
      "2024-03-02 21:20:49,631 INFO     Training average loss at step 31700: 0.109317\n",
      "2024-03-02 21:21:16,074 INFO     Training average positive_sample_loss at step 31800: 0.122418\n",
      "2024-03-02 21:21:16,075 INFO     Training average negative_sample_loss at step 31800: 0.092434\n",
      "2024-03-02 21:21:16,075 INFO     Training average loss at step 31800: 0.107426\n",
      "2024-03-02 21:21:39,688 INFO     Training average positive_sample_loss at step 31900: 0.125110\n",
      "2024-03-02 21:21:39,688 INFO     Training average negative_sample_loss at step 31900: 0.091014\n",
      "2024-03-02 21:21:39,688 INFO     Training average loss at step 31900: 0.108062\n",
      "2024-03-02 21:22:06,612 INFO     Training average positive_sample_loss at step 32000: 0.126414\n",
      "2024-03-02 21:22:06,613 INFO     Training average negative_sample_loss at step 32000: 0.092719\n",
      "2024-03-02 21:22:06,613 INFO     Training average loss at step 32000: 0.109567\n",
      "2024-03-02 21:22:30,073 INFO     Training average positive_sample_loss at step 32100: 0.121697\n",
      "2024-03-02 21:22:30,073 INFO     Training average negative_sample_loss at step 32100: 0.091498\n",
      "2024-03-02 21:22:30,073 INFO     Training average loss at step 32100: 0.106598\n",
      "2024-03-02 21:22:53,249 INFO     Training average positive_sample_loss at step 32200: 0.126174\n",
      "2024-03-02 21:22:53,249 INFO     Training average negative_sample_loss at step 32200: 0.091795\n",
      "2024-03-02 21:22:53,249 INFO     Training average loss at step 32200: 0.108985\n",
      "2024-03-02 21:23:19,963 INFO     Training average positive_sample_loss at step 32300: 0.122244\n",
      "2024-03-02 21:23:19,964 INFO     Training average negative_sample_loss at step 32300: 0.092380\n",
      "2024-03-02 21:23:19,964 INFO     Training average loss at step 32300: 0.107312\n",
      "2024-03-02 21:23:43,810 INFO     Training average positive_sample_loss at step 32400: 0.124866\n",
      "2024-03-02 21:23:43,810 INFO     Training average negative_sample_loss at step 32400: 0.091076\n",
      "2024-03-02 21:23:43,810 INFO     Training average loss at step 32400: 0.107971\n",
      "2024-03-02 21:24:07,294 INFO     Training average positive_sample_loss at step 32500: 0.127131\n",
      "2024-03-02 21:24:07,294 INFO     Training average negative_sample_loss at step 32500: 0.092760\n",
      "2024-03-02 21:24:07,294 INFO     Training average loss at step 32500: 0.109945\n",
      "2024-03-02 21:24:35,996 INFO     Training average positive_sample_loss at step 32600: 0.120697\n",
      "2024-03-02 21:24:35,997 INFO     Training average negative_sample_loss at step 32600: 0.091538\n",
      "2024-03-02 21:24:35,997 INFO     Training average loss at step 32600: 0.106118\n",
      "2024-03-02 21:24:59,664 INFO     Training average positive_sample_loss at step 32700: 0.125575\n",
      "2024-03-02 21:24:59,665 INFO     Training average negative_sample_loss at step 32700: 0.091083\n",
      "2024-03-02 21:24:59,665 INFO     Training average loss at step 32700: 0.108329\n",
      "2024-03-02 21:25:26,141 INFO     Training average positive_sample_loss at step 32800: 0.124179\n",
      "2024-03-02 21:25:26,141 INFO     Training average negative_sample_loss at step 32800: 0.092688\n",
      "2024-03-02 21:25:26,141 INFO     Training average loss at step 32800: 0.108434\n",
      "2024-03-02 21:25:49,177 INFO     Training average positive_sample_loss at step 32900: 0.122998\n",
      "2024-03-02 21:25:49,178 INFO     Training average negative_sample_loss at step 32900: 0.090752\n",
      "2024-03-02 21:25:49,178 INFO     Training average loss at step 32900: 0.106875\n",
      "2024-03-02 21:26:12,241 INFO     Training average positive_sample_loss at step 33000: 0.126920\n",
      "2024-03-02 21:26:12,241 INFO     Training average negative_sample_loss at step 33000: 0.092466\n",
      "2024-03-02 21:26:12,241 INFO     Training average loss at step 33000: 0.109693\n",
      "2024-03-02 21:26:39,979 INFO     Training average positive_sample_loss at step 33100: 0.120838\n",
      "2024-03-02 21:26:39,979 INFO     Training average negative_sample_loss at step 33100: 0.091248\n",
      "2024-03-02 21:26:39,979 INFO     Training average loss at step 33100: 0.106043\n",
      "2024-03-02 21:27:03,565 INFO     Training average positive_sample_loss at step 33200: 0.126016\n",
      "2024-03-02 21:27:03,566 INFO     Training average negative_sample_loss at step 33200: 0.091801\n",
      "2024-03-02 21:27:03,566 INFO     Training average loss at step 33200: 0.108908\n",
      "2024-03-02 21:27:30,522 INFO     Training average positive_sample_loss at step 33300: 0.124378\n",
      "2024-03-02 21:27:30,522 INFO     Training average negative_sample_loss at step 33300: 0.093156\n",
      "2024-03-02 21:27:30,522 INFO     Training average loss at step 33300: 0.108767\n",
      "2024-03-02 21:27:54,286 INFO     Training average positive_sample_loss at step 33400: 0.121855\n",
      "2024-03-02 21:27:54,287 INFO     Training average negative_sample_loss at step 33400: 0.089907\n",
      "2024-03-02 21:27:54,287 INFO     Training average loss at step 33400: 0.105881\n",
      "2024-03-02 21:28:17,603 INFO     Training average positive_sample_loss at step 33500: 0.126939\n",
      "2024-03-02 21:28:17,604 INFO     Training average negative_sample_loss at step 33500: 0.092282\n",
      "2024-03-02 21:28:17,604 INFO     Training average loss at step 33500: 0.109610\n",
      "2024-03-02 21:28:43,844 INFO     Training average positive_sample_loss at step 33600: 0.121975\n",
      "2024-03-02 21:28:43,844 INFO     Training average negative_sample_loss at step 33600: 0.091771\n",
      "2024-03-02 21:28:43,845 INFO     Training average loss at step 33600: 0.106873\n",
      "2024-03-02 21:29:07,759 INFO     Training average positive_sample_loss at step 33700: 0.124194\n",
      "2024-03-02 21:29:07,759 INFO     Training average negative_sample_loss at step 33700: 0.090998\n",
      "2024-03-02 21:29:07,759 INFO     Training average loss at step 33700: 0.107596\n",
      "2024-03-02 21:29:37,065 INFO     Training average positive_sample_loss at step 33800: 0.126716\n",
      "2024-03-02 21:29:37,065 INFO     Training average negative_sample_loss at step 33800: 0.092936\n",
      "2024-03-02 21:29:37,065 INFO     Training average loss at step 33800: 0.109826\n",
      "2024-03-02 21:30:00,459 INFO     Training average positive_sample_loss at step 33900: 0.120793\n",
      "2024-03-02 21:30:00,459 INFO     Training average negative_sample_loss at step 33900: 0.091207\n",
      "2024-03-02 21:30:00,459 INFO     Training average loss at step 33900: 0.106000\n",
      "2024-03-02 21:30:23,456 INFO     Training average positive_sample_loss at step 34000: 0.126371\n",
      "2024-03-02 21:30:23,458 INFO     Training average negative_sample_loss at step 34000: 0.091803\n",
      "2024-03-02 21:30:23,458 INFO     Training average loss at step 34000: 0.109087\n",
      "2024-03-02 21:30:50,462 INFO     Training average positive_sample_loss at step 34100: 0.122615\n",
      "2024-03-02 21:30:50,463 INFO     Training average negative_sample_loss at step 34100: 0.092053\n",
      "2024-03-02 21:30:50,463 INFO     Training average loss at step 34100: 0.107334\n",
      "2024-03-02 21:31:13,698 INFO     Training average positive_sample_loss at step 34200: 0.123560\n",
      "2024-03-02 21:31:13,698 INFO     Training average negative_sample_loss at step 34200: 0.090202\n",
      "2024-03-02 21:31:13,698 INFO     Training average loss at step 34200: 0.106881\n",
      "2024-03-02 21:31:36,919 INFO     Training average positive_sample_loss at step 34300: 0.126461\n",
      "2024-03-02 21:31:36,920 INFO     Training average negative_sample_loss at step 34300: 0.092687\n",
      "2024-03-02 21:31:36,920 INFO     Training average loss at step 34300: 0.109574\n",
      "2024-03-02 21:32:04,063 INFO     Training average positive_sample_loss at step 34400: 0.120320\n",
      "2024-03-02 21:32:04,064 INFO     Training average negative_sample_loss at step 34400: 0.090836\n",
      "2024-03-02 21:32:04,064 INFO     Training average loss at step 34400: 0.105578\n",
      "2024-03-02 21:32:27,066 INFO     Training average positive_sample_loss at step 34500: 0.125834\n",
      "2024-03-02 21:32:27,067 INFO     Training average negative_sample_loss at step 34500: 0.091517\n",
      "2024-03-02 21:32:27,067 INFO     Training average loss at step 34500: 0.108676\n",
      "2024-03-02 21:32:53,436 INFO     Training average positive_sample_loss at step 34600: 0.123666\n",
      "2024-03-02 21:32:53,437 INFO     Training average negative_sample_loss at step 34600: 0.092441\n",
      "2024-03-02 21:32:53,437 INFO     Training average loss at step 34600: 0.108054\n",
      "2024-03-02 21:33:16,770 INFO     Training average positive_sample_loss at step 34700: 0.122916\n",
      "2024-03-02 21:33:16,770 INFO     Training average negative_sample_loss at step 34700: 0.090653\n",
      "2024-03-02 21:33:16,770 INFO     Training average loss at step 34700: 0.106785\n",
      "2024-03-02 21:33:39,780 INFO     Training average positive_sample_loss at step 34800: 0.125970\n",
      "2024-03-02 21:33:39,781 INFO     Training average negative_sample_loss at step 34800: 0.091728\n",
      "2024-03-02 21:33:39,781 INFO     Training average loss at step 34800: 0.108849\n",
      "2024-03-02 21:34:06,616 INFO     Training average positive_sample_loss at step 34900: 0.121492\n",
      "2024-03-02 21:34:06,616 INFO     Training average negative_sample_loss at step 34900: 0.091408\n",
      "2024-03-02 21:34:06,616 INFO     Training average loss at step 34900: 0.106450\n",
      "2024-03-02 21:34:29,849 INFO     Training average positive_sample_loss at step 35000: 0.124648\n",
      "2024-03-02 21:34:29,849 INFO     Training average negative_sample_loss at step 35000: 0.090650\n",
      "2024-03-02 21:34:29,849 INFO     Training average loss at step 35000: 0.107649\n",
      "2024-03-02 21:34:58,208 INFO     Training average positive_sample_loss at step 35100: 0.124976\n",
      "2024-03-02 21:34:58,208 INFO     Training average negative_sample_loss at step 35100: 0.092716\n",
      "2024-03-02 21:34:58,208 INFO     Training average loss at step 35100: 0.108846\n",
      "2024-03-02 21:35:21,669 INFO     Training average positive_sample_loss at step 35200: 0.121783\n",
      "2024-03-02 21:35:21,670 INFO     Training average negative_sample_loss at step 35200: 0.090140\n",
      "2024-03-02 21:35:21,670 INFO     Training average loss at step 35200: 0.105962\n",
      "2024-03-02 21:35:44,775 INFO     Training average positive_sample_loss at step 35300: 0.125993\n",
      "2024-03-02 21:35:44,776 INFO     Training average negative_sample_loss at step 35300: 0.091467\n",
      "2024-03-02 21:35:44,776 INFO     Training average loss at step 35300: 0.108730\n",
      "2024-03-02 21:36:11,554 INFO     Training average positive_sample_loss at step 35400: 0.121470\n",
      "2024-03-02 21:36:11,555 INFO     Training average negative_sample_loss at step 35400: 0.091617\n",
      "2024-03-02 21:36:11,555 INFO     Training average loss at step 35400: 0.106543\n",
      "2024-03-02 21:36:35,883 INFO     Training average positive_sample_loss at step 35500: 0.124615\n",
      "2024-03-02 21:36:35,884 INFO     Training average negative_sample_loss at step 35500: 0.090889\n",
      "2024-03-02 21:36:35,884 INFO     Training average loss at step 35500: 0.107752\n",
      "2024-03-02 21:36:59,169 INFO     Training average positive_sample_loss at step 35600: 0.126314\n",
      "2024-03-02 21:36:59,169 INFO     Training average negative_sample_loss at step 35600: 0.092263\n",
      "2024-03-02 21:36:59,169 INFO     Training average loss at step 35600: 0.109289\n",
      "2024-03-02 21:37:26,610 INFO     Training average positive_sample_loss at step 35700: 0.119674\n",
      "2024-03-02 21:37:26,611 INFO     Training average negative_sample_loss at step 35700: 0.090207\n",
      "2024-03-02 21:37:26,611 INFO     Training average loss at step 35700: 0.104940\n",
      "2024-03-02 21:37:50,455 INFO     Training average positive_sample_loss at step 35800: 0.125841\n",
      "2024-03-02 21:37:50,455 INFO     Training average negative_sample_loss at step 35800: 0.091872\n",
      "2024-03-02 21:37:50,456 INFO     Training average loss at step 35800: 0.108857\n",
      "2024-03-02 21:38:17,670 INFO     Training average positive_sample_loss at step 35900: 0.122813\n",
      "2024-03-02 21:38:17,670 INFO     Training average negative_sample_loss at step 35900: 0.092317\n",
      "2024-03-02 21:38:17,670 INFO     Training average loss at step 35900: 0.107565\n",
      "2024-03-02 21:38:41,134 INFO     Training average positive_sample_loss at step 36000: 0.123483\n",
      "2024-03-02 21:38:41,135 INFO     Training average negative_sample_loss at step 36000: 0.091349\n",
      "2024-03-02 21:38:41,135 INFO     Training average loss at step 36000: 0.107416\n",
      "2024-03-02 21:39:04,886 INFO     Training average positive_sample_loss at step 36100: 0.126405\n",
      "2024-03-02 21:39:04,887 INFO     Training average negative_sample_loss at step 36100: 0.091613\n",
      "2024-03-02 21:39:04,887 INFO     Training average loss at step 36100: 0.109009\n",
      "2024-03-02 21:39:31,543 INFO     Training average positive_sample_loss at step 36200: 0.120494\n",
      "2024-03-02 21:39:31,544 INFO     Training average negative_sample_loss at step 36200: 0.091515\n",
      "2024-03-02 21:39:31,544 INFO     Training average loss at step 36200: 0.106004\n",
      "2024-03-02 21:39:55,325 INFO     Training average positive_sample_loss at step 36300: 0.124809\n",
      "2024-03-02 21:39:55,326 INFO     Training average negative_sample_loss at step 36300: 0.090798\n",
      "2024-03-02 21:39:55,326 INFO     Training average loss at step 36300: 0.107803\n",
      "2024-03-02 21:40:23,920 INFO     Training average positive_sample_loss at step 36400: 0.124811\n",
      "2024-03-02 21:40:23,920 INFO     Training average negative_sample_loss at step 36400: 0.093620\n",
      "2024-03-02 21:40:23,920 INFO     Training average loss at step 36400: 0.109215\n",
      "2024-03-02 21:40:47,359 INFO     Training average positive_sample_loss at step 36500: 0.122312\n",
      "2024-03-02 21:40:47,359 INFO     Training average negative_sample_loss at step 36500: 0.090063\n",
      "2024-03-02 21:40:47,359 INFO     Training average loss at step 36500: 0.106188\n",
      "2024-03-02 21:41:10,887 INFO     Training average positive_sample_loss at step 36600: 0.126076\n",
      "2024-03-02 21:41:10,887 INFO     Training average negative_sample_loss at step 36600: 0.092151\n",
      "2024-03-02 21:41:10,887 INFO     Training average loss at step 36600: 0.109113\n",
      "2024-03-02 21:41:37,053 INFO     Training average positive_sample_loss at step 36700: 0.120653\n",
      "2024-03-02 21:41:37,054 INFO     Training average negative_sample_loss at step 36700: 0.091365\n",
      "2024-03-02 21:41:37,054 INFO     Training average loss at step 36700: 0.106009\n",
      "2024-03-02 21:42:00,246 INFO     Training average positive_sample_loss at step 36800: 0.124794\n",
      "2024-03-02 21:42:00,247 INFO     Training average negative_sample_loss at step 36800: 0.090431\n",
      "2024-03-02 21:42:00,247 INFO     Training average loss at step 36800: 0.107612\n",
      "2024-03-02 21:42:28,083 INFO     Training average positive_sample_loss at step 36900: 0.125348\n",
      "2024-03-02 21:42:28,084 INFO     Training average negative_sample_loss at step 36900: 0.091989\n",
      "2024-03-02 21:42:28,084 INFO     Training average loss at step 36900: 0.108668\n",
      "2024-03-02 21:42:51,625 INFO     Training average positive_sample_loss at step 37000: 0.120836\n",
      "2024-03-02 21:42:51,626 INFO     Training average negative_sample_loss at step 37000: 0.090447\n",
      "2024-03-02 21:42:51,626 INFO     Training average loss at step 37000: 0.105642\n",
      "2024-03-02 21:43:15,465 INFO     Training average positive_sample_loss at step 37100: 0.125300\n",
      "2024-03-02 21:43:15,465 INFO     Training average negative_sample_loss at step 37100: 0.091905\n",
      "2024-03-02 21:43:15,465 INFO     Training average loss at step 37100: 0.108603\n",
      "2024-03-02 21:43:42,438 INFO     Training average positive_sample_loss at step 37200: 0.122270\n",
      "2024-03-02 21:43:42,439 INFO     Training average negative_sample_loss at step 37200: 0.091708\n",
      "2024-03-02 21:43:42,439 INFO     Training average loss at step 37200: 0.106989\n",
      "2024-03-02 21:44:06,123 INFO     Training average positive_sample_loss at step 37300: 0.123674\n",
      "2024-03-02 21:44:06,123 INFO     Training average negative_sample_loss at step 37300: 0.090614\n",
      "2024-03-02 21:44:06,123 INFO     Training average loss at step 37300: 0.107144\n",
      "2024-03-02 21:44:30,309 INFO     Training average positive_sample_loss at step 37400: 0.125557\n",
      "2024-03-02 21:44:30,310 INFO     Training average negative_sample_loss at step 37400: 0.091232\n",
      "2024-03-02 21:44:30,310 INFO     Training average loss at step 37400: 0.108394\n",
      "2024-03-02 21:44:57,112 INFO     Training average positive_sample_loss at step 37500: 0.120347\n",
      "2024-03-02 21:44:57,113 INFO     Training average negative_sample_loss at step 37500: 0.091767\n",
      "2024-03-02 21:44:57,113 INFO     Training average loss at step 37500: 0.106057\n",
      "2024-03-02 21:45:20,774 INFO     Training average positive_sample_loss at step 37600: 0.125612\n",
      "2024-03-02 21:45:20,775 INFO     Training average negative_sample_loss at step 37600: 0.091655\n",
      "2024-03-02 21:45:20,775 INFO     Training average loss at step 37600: 0.108633\n",
      "2024-03-02 21:45:49,179 INFO     Training average positive_sample_loss at step 37700: 0.122846\n",
      "2024-03-02 21:45:49,179 INFO     Training average negative_sample_loss at step 37700: 0.091782\n",
      "2024-03-02 21:45:49,179 INFO     Training average loss at step 37700: 0.107314\n",
      "2024-03-02 21:46:12,675 INFO     Training average positive_sample_loss at step 37800: 0.122996\n",
      "2024-03-02 21:46:12,676 INFO     Training average negative_sample_loss at step 37800: 0.090076\n",
      "2024-03-02 21:46:12,676 INFO     Training average loss at step 37800: 0.106536\n",
      "2024-03-02 21:46:35,965 INFO     Training average positive_sample_loss at step 37900: 0.125544\n",
      "2024-03-02 21:46:35,965 INFO     Training average negative_sample_loss at step 37900: 0.092117\n",
      "2024-03-02 21:46:35,965 INFO     Training average loss at step 37900: 0.108831\n",
      "2024-03-02 21:47:03,647 INFO     Training average positive_sample_loss at step 38000: 0.120234\n",
      "2024-03-02 21:47:03,648 INFO     Training average negative_sample_loss at step 38000: 0.090471\n",
      "2024-03-02 21:47:03,648 INFO     Training average loss at step 38000: 0.105353\n",
      "2024-03-02 21:47:28,202 INFO     Training average positive_sample_loss at step 38100: 0.125196\n",
      "2024-03-02 21:47:28,203 INFO     Training average negative_sample_loss at step 38100: 0.091524\n",
      "2024-03-02 21:47:28,203 INFO     Training average loss at step 38100: 0.108360\n",
      "2024-03-02 21:47:54,781 INFO     Training average positive_sample_loss at step 38200: 0.124131\n",
      "2024-03-02 21:47:54,782 INFO     Training average negative_sample_loss at step 38200: 0.092304\n",
      "2024-03-02 21:47:54,782 INFO     Training average loss at step 38200: 0.108218\n",
      "2024-03-02 21:48:18,480 INFO     Training average positive_sample_loss at step 38300: 0.121224\n",
      "2024-03-02 21:48:18,480 INFO     Training average negative_sample_loss at step 38300: 0.089741\n",
      "2024-03-02 21:48:18,480 INFO     Training average loss at step 38300: 0.105482\n",
      "2024-03-02 21:48:42,236 INFO     Training average positive_sample_loss at step 38400: 0.125739\n",
      "2024-03-02 21:48:42,236 INFO     Training average negative_sample_loss at step 38400: 0.090998\n",
      "2024-03-02 21:48:42,236 INFO     Training average loss at step 38400: 0.108369\n",
      "2024-03-02 21:49:08,568 INFO     Training average positive_sample_loss at step 38500: 0.121130\n",
      "2024-03-02 21:49:08,569 INFO     Training average negative_sample_loss at step 38500: 0.091311\n",
      "2024-03-02 21:49:08,569 INFO     Training average loss at step 38500: 0.106220\n",
      "2024-03-02 21:49:31,769 INFO     Training average positive_sample_loss at step 38600: 0.124045\n",
      "2024-03-02 21:49:31,770 INFO     Training average negative_sample_loss at step 38600: 0.090564\n",
      "2024-03-02 21:49:31,770 INFO     Training average loss at step 38600: 0.107305\n",
      "2024-03-02 21:49:57,056 INFO     Training average positive_sample_loss at step 38700: 0.125858\n",
      "2024-03-02 21:49:57,057 INFO     Training average negative_sample_loss at step 38700: 0.092299\n",
      "2024-03-02 21:49:57,057 INFO     Training average loss at step 38700: 0.109078\n",
      "2024-03-02 21:50:20,922 INFO     Training average positive_sample_loss at step 38800: 0.120079\n",
      "2024-03-02 21:50:20,923 INFO     Training average negative_sample_loss at step 38800: 0.090573\n",
      "2024-03-02 21:50:20,923 INFO     Training average loss at step 38800: 0.105326\n",
      "2024-03-02 21:50:43,927 INFO     Training average positive_sample_loss at step 38900: 0.125525\n",
      "2024-03-02 21:50:43,927 INFO     Training average negative_sample_loss at step 38900: 0.091461\n",
      "2024-03-02 21:50:43,927 INFO     Training average loss at step 38900: 0.108493\n",
      "2024-03-02 21:51:12,364 INFO     Training average positive_sample_loss at step 39000: 0.122061\n",
      "2024-03-02 21:51:12,365 INFO     Training average negative_sample_loss at step 39000: 0.091687\n",
      "2024-03-02 21:51:12,365 INFO     Training average loss at step 39000: 0.106874\n",
      "2024-03-02 21:51:35,741 INFO     Training average positive_sample_loss at step 39100: 0.122876\n",
      "2024-03-02 21:51:35,741 INFO     Training average negative_sample_loss at step 39100: 0.090056\n",
      "2024-03-02 21:51:35,741 INFO     Training average loss at step 39100: 0.106466\n",
      "2024-03-02 21:51:59,362 INFO     Training average positive_sample_loss at step 39200: 0.125841\n",
      "2024-03-02 21:51:59,362 INFO     Training average negative_sample_loss at step 39200: 0.091552\n",
      "2024-03-02 21:51:59,363 INFO     Training average loss at step 39200: 0.108696\n",
      "2024-03-02 21:52:26,131 INFO     Training average positive_sample_loss at step 39300: 0.120394\n",
      "2024-03-02 21:52:26,131 INFO     Training average negative_sample_loss at step 39300: 0.091299\n",
      "2024-03-02 21:52:26,131 INFO     Training average loss at step 39300: 0.105847\n",
      "2024-03-02 21:52:49,181 INFO     Training average positive_sample_loss at step 39400: 0.124746\n",
      "2024-03-02 21:52:49,182 INFO     Training average negative_sample_loss at step 39400: 0.090953\n",
      "2024-03-02 21:52:49,182 INFO     Training average loss at step 39400: 0.107850\n",
      "2024-03-02 21:53:15,539 INFO     Training average positive_sample_loss at step 39500: 0.123120\n",
      "2024-03-02 21:53:15,540 INFO     Training average negative_sample_loss at step 39500: 0.091561\n",
      "2024-03-02 21:53:15,540 INFO     Training average loss at step 39500: 0.107340\n",
      "2024-03-02 21:53:39,208 INFO     Training average positive_sample_loss at step 39600: 0.121821\n",
      "2024-03-02 21:53:39,208 INFO     Training average negative_sample_loss at step 39600: 0.089341\n",
      "2024-03-02 21:53:39,208 INFO     Training average loss at step 39600: 0.105581\n",
      "2024-03-02 21:54:02,735 INFO     Training average positive_sample_loss at step 39700: 0.125449\n",
      "2024-03-02 21:54:02,736 INFO     Training average negative_sample_loss at step 39700: 0.091130\n",
      "2024-03-02 21:54:02,736 INFO     Training average loss at step 39700: 0.108290\n",
      "2024-03-02 21:54:29,330 INFO     Training average positive_sample_loss at step 39800: 0.120467\n",
      "2024-03-02 21:54:29,331 INFO     Training average negative_sample_loss at step 39800: 0.091370\n",
      "2024-03-02 21:54:29,331 INFO     Training average loss at step 39800: 0.105919\n",
      "2024-03-02 21:54:53,064 INFO     Training average positive_sample_loss at step 39900: 0.124577\n",
      "2024-03-02 21:54:53,065 INFO     Training average negative_sample_loss at step 39900: 0.091293\n",
      "2024-03-02 21:54:53,065 INFO     Training average loss at step 39900: 0.107935\n",
      "2024-03-02 21:55:20,571 INFO     Training average positive_sample_loss at step 40000: 0.125041\n",
      "2024-03-02 21:55:20,571 INFO     Training average negative_sample_loss at step 40000: 0.091751\n",
      "2024-03-02 21:55:20,571 INFO     Training average loss at step 40000: 0.108396\n",
      "2024-03-02 21:55:20,572 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-02 21:55:21,124 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-02 21:55:49,550 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-02 21:56:11,116 INFO     Valid MRR at step 40000: 0.629079\n",
      "2024-03-02 21:56:11,116 INFO     Valid MR at step 40000: 239.496384\n",
      "2024-03-02 21:56:11,116 INFO     Valid HITS@1 at step 40000: 0.571219\n",
      "2024-03-02 21:56:11,116 INFO     Valid HITS@3 at step 40000: 0.654649\n",
      "2024-03-02 21:56:11,116 INFO     Valid HITS@10 at step 40000: 0.741149\n",
      "2024-03-02 21:56:31,256 INFO     Training average positive_sample_loss at step 40100: 0.120973\n",
      "2024-03-02 21:56:31,256 INFO     Training average negative_sample_loss at step 40100: 0.090778\n",
      "2024-03-02 21:56:31,256 INFO     Training average loss at step 40100: 0.105876\n",
      "2024-03-02 21:56:55,292 INFO     Training average positive_sample_loss at step 40200: 0.124755\n",
      "2024-03-02 21:56:55,292 INFO     Training average negative_sample_loss at step 40200: 0.090559\n",
      "2024-03-02 21:56:55,292 INFO     Training average loss at step 40200: 0.107657\n",
      "2024-03-02 21:57:23,323 INFO     Training average positive_sample_loss at step 40300: 0.120899\n",
      "2024-03-02 21:57:23,324 INFO     Training average negative_sample_loss at step 40300: 0.090957\n",
      "2024-03-02 21:57:23,324 INFO     Training average loss at step 40300: 0.105928\n",
      "2024-03-02 21:57:46,457 INFO     Training average positive_sample_loss at step 40400: 0.123998\n",
      "2024-03-02 21:57:46,457 INFO     Training average negative_sample_loss at step 40400: 0.090495\n",
      "2024-03-02 21:57:46,457 INFO     Training average loss at step 40400: 0.107246\n",
      "2024-03-02 21:58:09,249 INFO     Training average positive_sample_loss at step 40500: 0.125537\n",
      "2024-03-02 21:58:09,249 INFO     Training average negative_sample_loss at step 40500: 0.091875\n",
      "2024-03-02 21:58:09,249 INFO     Training average loss at step 40500: 0.108706\n",
      "2024-03-02 21:58:37,221 INFO     Training average positive_sample_loss at step 40600: 0.119861\n",
      "2024-03-02 21:58:37,221 INFO     Training average negative_sample_loss at step 40600: 0.090701\n",
      "2024-03-02 21:58:37,221 INFO     Training average loss at step 40600: 0.105281\n",
      "2024-03-02 21:59:00,729 INFO     Training average positive_sample_loss at step 40700: 0.124749\n",
      "2024-03-02 21:59:00,730 INFO     Training average negative_sample_loss at step 40700: 0.090256\n",
      "2024-03-02 21:59:00,730 INFO     Training average loss at step 40700: 0.107503\n",
      "2024-03-02 21:59:27,564 INFO     Training average positive_sample_loss at step 40800: 0.122443\n",
      "2024-03-02 21:59:27,565 INFO     Training average negative_sample_loss at step 40800: 0.091462\n",
      "2024-03-02 21:59:27,565 INFO     Training average loss at step 40800: 0.106953\n",
      "2024-03-02 21:59:50,630 INFO     Training average positive_sample_loss at step 40900: 0.122633\n",
      "2024-03-02 21:59:50,630 INFO     Training average negative_sample_loss at step 40900: 0.090057\n",
      "2024-03-02 21:59:50,630 INFO     Training average loss at step 40900: 0.106345\n",
      "2024-03-02 22:00:14,463 INFO     Training average positive_sample_loss at step 41000: 0.125011\n",
      "2024-03-02 22:00:14,464 INFO     Training average negative_sample_loss at step 41000: 0.090844\n",
      "2024-03-02 22:00:14,464 INFO     Training average loss at step 41000: 0.107928\n",
      "2024-03-02 22:00:41,259 INFO     Training average positive_sample_loss at step 41100: 0.120299\n",
      "2024-03-02 22:00:41,260 INFO     Training average negative_sample_loss at step 41100: 0.090697\n",
      "2024-03-02 22:00:41,260 INFO     Training average loss at step 41100: 0.105498\n",
      "2024-03-02 22:01:04,715 INFO     Training average positive_sample_loss at step 41200: 0.124215\n",
      "2024-03-02 22:01:04,716 INFO     Training average negative_sample_loss at step 41200: 0.090458\n",
      "2024-03-02 22:01:04,716 INFO     Training average loss at step 41200: 0.107337\n",
      "2024-03-02 22:01:31,505 INFO     Training average positive_sample_loss at step 41300: 0.123192\n",
      "2024-03-02 22:01:31,505 INFO     Training average negative_sample_loss at step 41300: 0.091674\n",
      "2024-03-02 22:01:31,505 INFO     Training average loss at step 41300: 0.107433\n",
      "2024-03-02 22:01:55,145 INFO     Training average positive_sample_loss at step 41400: 0.121797\n",
      "2024-03-02 22:01:55,146 INFO     Training average negative_sample_loss at step 41400: 0.090139\n",
      "2024-03-02 22:01:55,146 INFO     Training average loss at step 41400: 0.105968\n",
      "2024-03-02 22:02:17,961 INFO     Training average positive_sample_loss at step 41500: 0.125239\n",
      "2024-03-02 22:02:17,961 INFO     Training average negative_sample_loss at step 41500: 0.091574\n",
      "2024-03-02 22:02:17,962 INFO     Training average loss at step 41500: 0.108407\n",
      "2024-03-02 22:02:46,044 INFO     Training average positive_sample_loss at step 41600: 0.120416\n",
      "2024-03-02 22:02:46,044 INFO     Training average negative_sample_loss at step 41600: 0.091045\n",
      "2024-03-02 22:02:46,044 INFO     Training average loss at step 41600: 0.105731\n",
      "2024-03-02 22:03:09,759 INFO     Training average positive_sample_loss at step 41700: 0.124115\n",
      "2024-03-02 22:03:09,759 INFO     Training average negative_sample_loss at step 41700: 0.089923\n",
      "2024-03-02 22:03:09,760 INFO     Training average loss at step 41700: 0.107019\n",
      "2024-03-02 22:03:37,274 INFO     Training average positive_sample_loss at step 41800: 0.125393\n",
      "2024-03-02 22:03:37,275 INFO     Training average negative_sample_loss at step 41800: 0.092198\n",
      "2024-03-02 22:03:37,275 INFO     Training average loss at step 41800: 0.108795\n",
      "2024-03-02 22:04:01,150 INFO     Training average positive_sample_loss at step 41900: 0.120137\n",
      "2024-03-02 22:04:01,150 INFO     Training average negative_sample_loss at step 41900: 0.090891\n",
      "2024-03-02 22:04:01,150 INFO     Training average loss at step 41900: 0.105514\n",
      "2024-03-02 22:04:24,450 INFO     Training average positive_sample_loss at step 42000: 0.125192\n",
      "2024-03-02 22:04:24,450 INFO     Training average negative_sample_loss at step 42000: 0.091295\n",
      "2024-03-02 22:04:24,450 INFO     Training average loss at step 42000: 0.108244\n",
      "2024-03-02 22:04:50,842 INFO     Training average positive_sample_loss at step 42100: 0.121164\n",
      "2024-03-02 22:04:50,843 INFO     Training average negative_sample_loss at step 42100: 0.091241\n",
      "2024-03-02 22:04:50,843 INFO     Training average loss at step 42100: 0.106202\n",
      "2024-03-02 22:05:14,211 INFO     Training average positive_sample_loss at step 42200: 0.122839\n",
      "2024-03-02 22:05:14,211 INFO     Training average negative_sample_loss at step 42200: 0.089961\n",
      "2024-03-02 22:05:14,211 INFO     Training average loss at step 42200: 0.106400\n",
      "2024-03-02 22:05:37,417 INFO     Training average positive_sample_loss at step 42300: 0.126010\n",
      "2024-03-02 22:05:37,418 INFO     Training average negative_sample_loss at step 42300: 0.091564\n",
      "2024-03-02 22:05:37,418 INFO     Training average loss at step 42300: 0.108787\n",
      "2024-03-02 22:06:03,988 INFO     Training average positive_sample_loss at step 42400: 0.119996\n",
      "2024-03-02 22:06:03,989 INFO     Training average negative_sample_loss at step 42400: 0.090622\n",
      "2024-03-02 22:06:03,989 INFO     Training average loss at step 42400: 0.105309\n",
      "2024-03-02 22:06:27,772 INFO     Training average positive_sample_loss at step 42500: 0.124290\n",
      "2024-03-02 22:06:27,772 INFO     Training average negative_sample_loss at step 42500: 0.090861\n",
      "2024-03-02 22:06:27,772 INFO     Training average loss at step 42500: 0.107575\n",
      "2024-03-02 22:06:54,889 INFO     Training average positive_sample_loss at step 42600: 0.122534\n",
      "2024-03-02 22:06:54,889 INFO     Training average negative_sample_loss at step 42600: 0.091722\n",
      "2024-03-02 22:06:54,889 INFO     Training average loss at step 42600: 0.107128\n",
      "2024-03-02 22:07:18,215 INFO     Training average positive_sample_loss at step 42700: 0.121673\n",
      "2024-03-02 22:07:18,215 INFO     Training average negative_sample_loss at step 42700: 0.089282\n",
      "2024-03-02 22:07:18,215 INFO     Training average loss at step 42700: 0.105477\n",
      "2024-03-02 22:07:41,161 INFO     Training average positive_sample_loss at step 42800: 0.125200\n",
      "2024-03-02 22:07:41,161 INFO     Training average negative_sample_loss at step 42800: 0.091071\n",
      "2024-03-02 22:07:41,161 INFO     Training average loss at step 42800: 0.108136\n",
      "2024-03-02 22:08:10,235 INFO     Training average positive_sample_loss at step 42900: 0.120203\n",
      "2024-03-02 22:08:10,236 INFO     Training average negative_sample_loss at step 42900: 0.090556\n",
      "2024-03-02 22:08:10,236 INFO     Training average loss at step 42900: 0.105380\n",
      "2024-03-02 22:08:33,535 INFO     Training average positive_sample_loss at step 43000: 0.124365\n",
      "2024-03-02 22:08:33,535 INFO     Training average negative_sample_loss at step 43000: 0.090739\n",
      "2024-03-02 22:08:33,535 INFO     Training average loss at step 43000: 0.107552\n",
      "2024-03-02 22:09:00,230 INFO     Training average positive_sample_loss at step 43100: 0.123418\n",
      "2024-03-02 22:09:00,231 INFO     Training average negative_sample_loss at step 43100: 0.091760\n",
      "2024-03-02 22:09:00,231 INFO     Training average loss at step 43100: 0.107589\n",
      "2024-03-02 22:09:24,000 INFO     Training average positive_sample_loss at step 43200: 0.120822\n",
      "2024-03-02 22:09:24,000 INFO     Training average negative_sample_loss at step 43200: 0.090248\n",
      "2024-03-02 22:09:24,000 INFO     Training average loss at step 43200: 0.105535\n",
      "2024-03-02 22:09:47,278 INFO     Training average positive_sample_loss at step 43300: 0.124614\n",
      "2024-03-02 22:09:47,279 INFO     Training average negative_sample_loss at step 43300: 0.090209\n",
      "2024-03-02 22:09:47,279 INFO     Training average loss at step 43300: 0.107412\n",
      "2024-03-02 22:10:14,521 INFO     Training average positive_sample_loss at step 43400: 0.121003\n",
      "2024-03-02 22:10:14,522 INFO     Training average negative_sample_loss at step 43400: 0.091255\n",
      "2024-03-02 22:10:14,522 INFO     Training average loss at step 43400: 0.106129\n",
      "2024-03-02 22:10:37,980 INFO     Training average positive_sample_loss at step 43500: 0.123292\n",
      "2024-03-02 22:10:37,980 INFO     Training average negative_sample_loss at step 43500: 0.089852\n",
      "2024-03-02 22:10:37,980 INFO     Training average loss at step 43500: 0.106572\n",
      "2024-03-02 22:11:01,062 INFO     Training average positive_sample_loss at step 43600: 0.125622\n",
      "2024-03-02 22:11:01,063 INFO     Training average negative_sample_loss at step 43600: 0.091449\n",
      "2024-03-02 22:11:01,063 INFO     Training average loss at step 43600: 0.108535\n",
      "2024-03-02 22:11:27,453 INFO     Training average positive_sample_loss at step 43700: 0.119406\n",
      "2024-03-02 22:11:27,453 INFO     Training average negative_sample_loss at step 43700: 0.090512\n",
      "2024-03-02 22:11:27,453 INFO     Training average loss at step 43700: 0.104959\n",
      "2024-03-02 22:11:50,738 INFO     Training average positive_sample_loss at step 43800: 0.124596\n",
      "2024-03-02 22:11:50,739 INFO     Training average negative_sample_loss at step 43800: 0.090482\n",
      "2024-03-02 22:11:50,739 INFO     Training average loss at step 43800: 0.107539\n",
      "2024-03-02 22:12:17,700 INFO     Training average positive_sample_loss at step 43900: 0.121692\n",
      "2024-03-02 22:12:17,700 INFO     Training average negative_sample_loss at step 43900: 0.090828\n",
      "2024-03-02 22:12:17,700 INFO     Training average loss at step 43900: 0.106260\n",
      "2024-03-02 22:12:41,994 INFO     Training average positive_sample_loss at step 44000: 0.122646\n",
      "2024-03-02 22:12:41,995 INFO     Training average negative_sample_loss at step 44000: 0.089593\n",
      "2024-03-02 22:12:41,995 INFO     Training average loss at step 44000: 0.106120\n",
      "2024-03-02 22:13:06,309 INFO     Training average positive_sample_loss at step 44100: 0.124929\n",
      "2024-03-02 22:13:06,310 INFO     Training average negative_sample_loss at step 44100: 0.091392\n",
      "2024-03-02 22:13:06,310 INFO     Training average loss at step 44100: 0.108160\n",
      "2024-03-02 22:13:34,631 INFO     Training average positive_sample_loss at step 44200: 0.119144\n",
      "2024-03-02 22:13:34,631 INFO     Training average negative_sample_loss at step 44200: 0.089831\n",
      "2024-03-02 22:13:34,631 INFO     Training average loss at step 44200: 0.104488\n",
      "2024-03-02 22:13:58,099 INFO     Training average positive_sample_loss at step 44300: 0.123961\n",
      "2024-03-02 22:13:58,100 INFO     Training average negative_sample_loss at step 44300: 0.089627\n",
      "2024-03-02 22:13:58,100 INFO     Training average loss at step 44300: 0.106794\n",
      "2024-03-02 22:14:25,140 INFO     Training average positive_sample_loss at step 44400: 0.122735\n",
      "2024-03-02 22:14:25,140 INFO     Training average negative_sample_loss at step 44400: 0.092370\n",
      "2024-03-02 22:14:25,140 INFO     Training average loss at step 44400: 0.107552\n",
      "2024-03-02 22:14:49,856 INFO     Training average positive_sample_loss at step 44500: 0.121670\n",
      "2024-03-02 22:14:49,857 INFO     Training average negative_sample_loss at step 44500: 0.088872\n",
      "2024-03-02 22:14:49,857 INFO     Training average loss at step 44500: 0.105271\n",
      "2024-03-02 22:15:13,422 INFO     Training average positive_sample_loss at step 44600: 0.125325\n",
      "2024-03-02 22:15:13,423 INFO     Training average negative_sample_loss at step 44600: 0.090760\n",
      "2024-03-02 22:15:13,423 INFO     Training average loss at step 44600: 0.108043\n",
      "2024-03-02 22:15:40,073 INFO     Training average positive_sample_loss at step 44700: 0.119286\n",
      "2024-03-02 22:15:40,074 INFO     Training average negative_sample_loss at step 44700: 0.090000\n",
      "2024-03-02 22:15:40,074 INFO     Training average loss at step 44700: 0.104643\n",
      "2024-03-02 22:16:03,624 INFO     Training average positive_sample_loss at step 44800: 0.123652\n",
      "2024-03-02 22:16:03,624 INFO     Training average negative_sample_loss at step 44800: 0.089911\n",
      "2024-03-02 22:16:03,624 INFO     Training average loss at step 44800: 0.106782\n",
      "2024-03-02 22:16:30,020 INFO     Training average positive_sample_loss at step 44900: 0.124664\n",
      "2024-03-02 22:16:30,021 INFO     Training average negative_sample_loss at step 44900: 0.091159\n",
      "2024-03-02 22:16:30,021 INFO     Training average loss at step 44900: 0.107911\n",
      "2024-03-02 22:16:53,316 INFO     Training average positive_sample_loss at step 45000: 0.119695\n",
      "2024-03-02 22:16:53,317 INFO     Training average negative_sample_loss at step 45000: 0.089541\n",
      "2024-03-02 22:16:53,317 INFO     Training average loss at step 45000: 0.104618\n",
      "2024-03-02 22:17:17,509 INFO     Training average positive_sample_loss at step 45100: 0.124722\n",
      "2024-03-02 22:17:17,510 INFO     Training average negative_sample_loss at step 45100: 0.090840\n",
      "2024-03-02 22:17:17,510 INFO     Training average loss at step 45100: 0.107781\n",
      "2024-03-02 22:17:44,710 INFO     Training average positive_sample_loss at step 45200: 0.121130\n",
      "2024-03-02 22:17:44,711 INFO     Training average negative_sample_loss at step 45200: 0.090822\n",
      "2024-03-02 22:17:44,711 INFO     Training average loss at step 45200: 0.105976\n",
      "2024-03-02 22:18:08,320 INFO     Training average positive_sample_loss at step 45300: 0.122979\n",
      "2024-03-02 22:18:08,321 INFO     Training average negative_sample_loss at step 45300: 0.088921\n",
      "2024-03-02 22:18:08,321 INFO     Training average loss at step 45300: 0.105950\n",
      "2024-03-02 22:18:31,113 INFO     Training average positive_sample_loss at step 45400: 0.124680\n",
      "2024-03-02 22:18:31,113 INFO     Training average negative_sample_loss at step 45400: 0.091306\n",
      "2024-03-02 22:18:31,114 INFO     Training average loss at step 45400: 0.107993\n",
      "2024-03-02 22:18:59,949 INFO     Training average positive_sample_loss at step 45500: 0.118891\n",
      "2024-03-02 22:18:59,949 INFO     Training average negative_sample_loss at step 45500: 0.089856\n",
      "2024-03-02 22:18:59,949 INFO     Training average loss at step 45500: 0.104373\n",
      "2024-03-02 22:19:23,766 INFO     Training average positive_sample_loss at step 45600: 0.124540\n",
      "2024-03-02 22:19:23,767 INFO     Training average negative_sample_loss at step 45600: 0.090228\n",
      "2024-03-02 22:19:23,767 INFO     Training average loss at step 45600: 0.107384\n",
      "2024-03-02 22:19:50,423 INFO     Training average positive_sample_loss at step 45700: 0.122121\n",
      "2024-03-02 22:19:50,423 INFO     Training average negative_sample_loss at step 45700: 0.091292\n",
      "2024-03-02 22:19:50,423 INFO     Training average loss at step 45700: 0.106707\n",
      "2024-03-02 22:20:13,286 INFO     Training average positive_sample_loss at step 45800: 0.121443\n",
      "2024-03-02 22:20:13,287 INFO     Training average negative_sample_loss at step 45800: 0.089709\n",
      "2024-03-02 22:20:13,287 INFO     Training average loss at step 45800: 0.105576\n",
      "2024-03-02 22:20:36,257 INFO     Training average positive_sample_loss at step 45900: 0.125058\n",
      "2024-03-02 22:20:36,258 INFO     Training average negative_sample_loss at step 45900: 0.090537\n",
      "2024-03-02 22:20:36,258 INFO     Training average loss at step 45900: 0.107797\n",
      "2024-03-02 22:21:03,635 INFO     Training average positive_sample_loss at step 46000: 0.119946\n",
      "2024-03-02 22:21:03,636 INFO     Training average negative_sample_loss at step 46000: 0.091091\n",
      "2024-03-02 22:21:03,636 INFO     Training average loss at step 46000: 0.105519\n",
      "2024-03-02 22:21:27,432 INFO     Training average positive_sample_loss at step 46100: 0.123908\n",
      "2024-03-02 22:21:27,432 INFO     Training average negative_sample_loss at step 46100: 0.089934\n",
      "2024-03-02 22:21:27,432 INFO     Training average loss at step 46100: 0.106921\n",
      "2024-03-02 22:21:54,292 INFO     Training average positive_sample_loss at step 46200: 0.122949\n",
      "2024-03-02 22:21:54,292 INFO     Training average negative_sample_loss at step 46200: 0.091683\n",
      "2024-03-02 22:21:54,292 INFO     Training average loss at step 46200: 0.107316\n",
      "2024-03-02 22:22:17,838 INFO     Training average positive_sample_loss at step 46300: 0.120931\n",
      "2024-03-02 22:22:17,838 INFO     Training average negative_sample_loss at step 46300: 0.089657\n",
      "2024-03-02 22:22:17,838 INFO     Training average loss at step 46300: 0.105294\n",
      "2024-03-02 22:22:41,241 INFO     Training average positive_sample_loss at step 46400: 0.124773\n",
      "2024-03-02 22:22:41,241 INFO     Training average negative_sample_loss at step 46400: 0.090946\n",
      "2024-03-02 22:22:41,241 INFO     Training average loss at step 46400: 0.107859\n",
      "2024-03-02 22:23:07,992 INFO     Training average positive_sample_loss at step 46500: 0.120733\n",
      "2024-03-02 22:23:07,992 INFO     Training average negative_sample_loss at step 46500: 0.090925\n",
      "2024-03-02 22:23:07,992 INFO     Training average loss at step 46500: 0.105829\n",
      "2024-03-02 22:23:32,132 INFO     Training average positive_sample_loss at step 46600: 0.123023\n",
      "2024-03-02 22:23:32,132 INFO     Training average negative_sample_loss at step 46600: 0.090151\n",
      "2024-03-02 22:23:32,132 INFO     Training average loss at step 46600: 0.106587\n",
      "2024-03-02 22:24:00,215 INFO     Training average positive_sample_loss at step 46700: 0.124977\n",
      "2024-03-02 22:24:00,215 INFO     Training average negative_sample_loss at step 46700: 0.091423\n",
      "2024-03-02 22:24:00,215 INFO     Training average loss at step 46700: 0.108200\n",
      "2024-03-02 22:24:23,587 INFO     Training average positive_sample_loss at step 46800: 0.118547\n",
      "2024-03-02 22:24:23,588 INFO     Training average negative_sample_loss at step 46800: 0.089473\n",
      "2024-03-02 22:24:23,588 INFO     Training average loss at step 46800: 0.104010\n",
      "2024-03-02 22:24:46,388 INFO     Training average positive_sample_loss at step 46900: 0.124909\n",
      "2024-03-02 22:24:46,388 INFO     Training average negative_sample_loss at step 46900: 0.090225\n",
      "2024-03-02 22:24:46,388 INFO     Training average loss at step 46900: 0.107567\n",
      "2024-03-02 22:25:13,303 INFO     Training average positive_sample_loss at step 47000: 0.120682\n",
      "2024-03-02 22:25:13,303 INFO     Training average negative_sample_loss at step 47000: 0.090816\n",
      "2024-03-02 22:25:13,303 INFO     Training average loss at step 47000: 0.105749\n",
      "2024-03-02 22:25:36,102 INFO     Training average positive_sample_loss at step 47100: 0.122163\n",
      "2024-03-02 22:25:36,102 INFO     Training average negative_sample_loss at step 47100: 0.088977\n",
      "2024-03-02 22:25:36,102 INFO     Training average loss at step 47100: 0.105570\n",
      "2024-03-02 22:25:58,950 INFO     Training average positive_sample_loss at step 47200: 0.125267\n",
      "2024-03-02 22:25:58,950 INFO     Training average negative_sample_loss at step 47200: 0.091017\n",
      "2024-03-02 22:25:58,950 INFO     Training average loss at step 47200: 0.108142\n",
      "2024-03-02 22:26:25,666 INFO     Training average positive_sample_loss at step 47300: 0.119255\n",
      "2024-03-02 22:26:25,667 INFO     Training average negative_sample_loss at step 47300: 0.090006\n",
      "2024-03-02 22:26:25,667 INFO     Training average loss at step 47300: 0.104631\n",
      "2024-03-02 22:26:49,857 INFO     Training average positive_sample_loss at step 47400: 0.123997\n",
      "2024-03-02 22:26:49,857 INFO     Training average negative_sample_loss at step 47400: 0.090030\n",
      "2024-03-02 22:26:49,857 INFO     Training average loss at step 47400: 0.107014\n",
      "2024-03-02 22:27:16,117 INFO     Training average positive_sample_loss at step 47500: 0.122101\n",
      "2024-03-02 22:27:16,117 INFO     Training average negative_sample_loss at step 47500: 0.091208\n",
      "2024-03-02 22:27:16,117 INFO     Training average loss at step 47500: 0.106654\n",
      "2024-03-02 22:27:39,618 INFO     Training average positive_sample_loss at step 47600: 0.121018\n",
      "2024-03-02 22:27:39,619 INFO     Training average negative_sample_loss at step 47600: 0.088937\n",
      "2024-03-02 22:27:39,619 INFO     Training average loss at step 47600: 0.104978\n",
      "2024-03-02 22:28:03,445 INFO     Training average positive_sample_loss at step 47700: 0.124914\n",
      "2024-03-02 22:28:03,445 INFO     Training average negative_sample_loss at step 47700: 0.090861\n",
      "2024-03-02 22:28:03,445 INFO     Training average loss at step 47700: 0.107888\n",
      "2024-03-02 22:28:29,858 INFO     Training average positive_sample_loss at step 47800: 0.119927\n",
      "2024-03-02 22:28:29,859 INFO     Training average negative_sample_loss at step 47800: 0.090607\n",
      "2024-03-02 22:28:29,859 INFO     Training average loss at step 47800: 0.105267\n",
      "2024-03-02 22:28:53,834 INFO     Training average positive_sample_loss at step 47900: 0.123727\n",
      "2024-03-02 22:28:53,835 INFO     Training average negative_sample_loss at step 47900: 0.090407\n",
      "2024-03-02 22:28:53,835 INFO     Training average loss at step 47900: 0.107067\n",
      "2024-03-02 22:29:22,396 INFO     Training average positive_sample_loss at step 48000: 0.123567\n",
      "2024-03-02 22:29:22,396 INFO     Training average negative_sample_loss at step 48000: 0.090750\n",
      "2024-03-02 22:29:22,396 INFO     Training average loss at step 48000: 0.107158\n",
      "2024-03-02 22:29:46,563 INFO     Training average positive_sample_loss at step 48100: 0.120215\n",
      "2024-03-02 22:29:46,564 INFO     Training average negative_sample_loss at step 48100: 0.089637\n",
      "2024-03-02 22:29:46,564 INFO     Training average loss at step 48100: 0.104926\n",
      "2024-03-02 22:30:10,078 INFO     Training average positive_sample_loss at step 48200: 0.124752\n",
      "2024-03-02 22:30:10,079 INFO     Training average negative_sample_loss at step 48200: 0.091124\n",
      "2024-03-02 22:30:10,079 INFO     Training average loss at step 48200: 0.107938\n",
      "2024-03-02 22:30:36,773 INFO     Training average positive_sample_loss at step 48300: 0.119664\n",
      "2024-03-02 22:30:36,774 INFO     Training average negative_sample_loss at step 48300: 0.089866\n",
      "2024-03-02 22:30:36,774 INFO     Training average loss at step 48300: 0.104765\n",
      "2024-03-02 22:30:59,993 INFO     Training average positive_sample_loss at step 48400: 0.122825\n",
      "2024-03-02 22:30:59,993 INFO     Training average negative_sample_loss at step 48400: 0.089549\n",
      "2024-03-02 22:30:59,993 INFO     Training average loss at step 48400: 0.106187\n",
      "2024-03-02 22:31:22,967 INFO     Training average positive_sample_loss at step 48500: 0.125195\n",
      "2024-03-02 22:31:22,967 INFO     Training average negative_sample_loss at step 48500: 0.091132\n",
      "2024-03-02 22:31:22,967 INFO     Training average loss at step 48500: 0.108163\n",
      "2024-03-02 22:31:49,890 INFO     Training average positive_sample_loss at step 48600: 0.119100\n",
      "2024-03-02 22:31:49,890 INFO     Training average negative_sample_loss at step 48600: 0.089726\n",
      "2024-03-02 22:31:49,890 INFO     Training average loss at step 48600: 0.104413\n",
      "2024-03-02 22:32:13,077 INFO     Training average positive_sample_loss at step 48700: 0.123993\n",
      "2024-03-02 22:32:13,077 INFO     Training average negative_sample_loss at step 48700: 0.090483\n",
      "2024-03-02 22:32:13,077 INFO     Training average loss at step 48700: 0.107238\n",
      "2024-03-02 22:32:40,200 INFO     Training average positive_sample_loss at step 48800: 0.121711\n",
      "2024-03-02 22:32:40,200 INFO     Training average negative_sample_loss at step 48800: 0.091618\n",
      "2024-03-02 22:32:40,200 INFO     Training average loss at step 48800: 0.106665\n",
      "2024-03-02 22:33:03,631 INFO     Training average positive_sample_loss at step 48900: 0.122768\n",
      "2024-03-02 22:33:03,631 INFO     Training average negative_sample_loss at step 48900: 0.089974\n",
      "2024-03-02 22:33:03,631 INFO     Training average loss at step 48900: 0.106371\n",
      "2024-03-02 22:33:27,187 INFO     Training average positive_sample_loss at step 49000: 0.124314\n",
      "2024-03-02 22:33:27,188 INFO     Training average negative_sample_loss at step 49000: 0.090480\n",
      "2024-03-02 22:33:27,188 INFO     Training average loss at step 49000: 0.107397\n",
      "2024-03-02 22:33:53,714 INFO     Training average positive_sample_loss at step 49100: 0.118853\n",
      "2024-03-02 22:33:53,715 INFO     Training average negative_sample_loss at step 49100: 0.089842\n",
      "2024-03-02 22:33:53,715 INFO     Training average loss at step 49100: 0.104347\n",
      "2024-03-02 22:34:17,688 INFO     Training average positive_sample_loss at step 49200: 0.124089\n",
      "2024-03-02 22:34:17,688 INFO     Training average negative_sample_loss at step 49200: 0.089963\n",
      "2024-03-02 22:34:17,688 INFO     Training average loss at step 49200: 0.107026\n",
      "2024-03-02 22:34:46,310 INFO     Training average positive_sample_loss at step 49300: 0.121974\n",
      "2024-03-02 22:34:46,311 INFO     Training average negative_sample_loss at step 49300: 0.090837\n",
      "2024-03-02 22:34:46,311 INFO     Training average loss at step 49300: 0.106405\n",
      "2024-03-02 22:35:09,148 INFO     Training average positive_sample_loss at step 49400: 0.120725\n",
      "2024-03-02 22:35:09,148 INFO     Training average negative_sample_loss at step 49400: 0.088985\n",
      "2024-03-02 22:35:09,148 INFO     Training average loss at step 49400: 0.104855\n",
      "2024-03-02 22:35:32,158 INFO     Training average positive_sample_loss at step 49500: 0.124852\n",
      "2024-03-02 22:35:32,158 INFO     Training average negative_sample_loss at step 49500: 0.090691\n",
      "2024-03-02 22:35:32,158 INFO     Training average loss at step 49500: 0.107771\n",
      "2024-03-02 22:35:59,907 INFO     Training average positive_sample_loss at step 49600: 0.120304\n",
      "2024-03-02 22:35:59,907 INFO     Training average negative_sample_loss at step 49600: 0.090265\n",
      "2024-03-02 22:35:59,907 INFO     Training average loss at step 49600: 0.105285\n",
      "2024-03-02 22:36:22,896 INFO     Training average positive_sample_loss at step 49700: 0.122816\n",
      "2024-03-02 22:36:22,897 INFO     Training average negative_sample_loss at step 49700: 0.089395\n",
      "2024-03-02 22:36:22,897 INFO     Training average loss at step 49700: 0.106106\n",
      "2024-03-02 22:36:50,002 INFO     Training average positive_sample_loss at step 49800: 0.123821\n",
      "2024-03-02 22:36:50,002 INFO     Training average negative_sample_loss at step 49800: 0.091075\n",
      "2024-03-02 22:36:50,002 INFO     Training average loss at step 49800: 0.107448\n",
      "2024-03-02 22:37:13,434 INFO     Training average positive_sample_loss at step 49900: 0.119195\n",
      "2024-03-02 22:37:13,435 INFO     Training average negative_sample_loss at step 49900: 0.089377\n",
      "2024-03-02 22:37:13,435 INFO     Training average loss at step 49900: 0.104286\n",
      "2024-03-02 22:37:37,639 INFO     Change learning_rate to 0.000005 at step 50000\n",
      "2024-03-02 22:37:38,762 INFO     Training average positive_sample_loss at step 50000: 0.124723\n",
      "2024-03-02 22:37:38,762 INFO     Training average negative_sample_loss at step 50000: 0.090556\n",
      "2024-03-02 22:37:38,762 INFO     Training average loss at step 50000: 0.107640\n",
      "2024-03-02 22:37:38,762 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-02 22:37:39,366 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-02 22:38:07,494 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-02 22:38:29,087 INFO     Valid MRR at step 50000: 0.626757\n",
      "2024-03-02 22:38:29,087 INFO     Valid MR at step 50000: 238.682857\n",
      "2024-03-02 22:38:29,088 INFO     Valid HITS@1 at step 50000: 0.567433\n",
      "2024-03-02 22:38:29,088 INFO     Valid HITS@3 at step 50000: 0.649601\n",
      "2024-03-02 22:38:29,088 INFO     Valid HITS@10 at step 50000: 0.747698\n",
      "2024-03-02 22:38:53,433 INFO     Training average positive_sample_loss at step 50100: 0.120064\n",
      "2024-03-02 22:38:53,434 INFO     Training average negative_sample_loss at step 50100: 0.089647\n",
      "2024-03-02 22:38:53,434 INFO     Training average loss at step 50100: 0.104856\n",
      "2024-03-02 22:39:16,894 INFO     Training average positive_sample_loss at step 50200: 0.114256\n",
      "2024-03-02 22:39:16,895 INFO     Training average negative_sample_loss at step 50200: 0.088261\n",
      "2024-03-02 22:39:16,895 INFO     Training average loss at step 50200: 0.101258\n",
      "2024-03-02 22:39:40,773 INFO     Training average positive_sample_loss at step 50300: 0.114730\n",
      "2024-03-02 22:39:40,774 INFO     Training average negative_sample_loss at step 50300: 0.087525\n",
      "2024-03-02 22:39:40,774 INFO     Training average loss at step 50300: 0.101127\n",
      "2024-03-02 22:40:07,267 INFO     Training average positive_sample_loss at step 50400: 0.113285\n",
      "2024-03-02 22:40:07,268 INFO     Training average negative_sample_loss at step 50400: 0.087087\n",
      "2024-03-02 22:40:07,268 INFO     Training average loss at step 50400: 0.100186\n",
      "2024-03-02 22:40:30,459 INFO     Training average positive_sample_loss at step 50500: 0.113678\n",
      "2024-03-02 22:40:30,460 INFO     Training average negative_sample_loss at step 50500: 0.086936\n",
      "2024-03-02 22:40:30,460 INFO     Training average loss at step 50500: 0.100307\n",
      "2024-03-02 22:40:58,831 INFO     Training average positive_sample_loss at step 50600: 0.113495\n",
      "2024-03-02 22:40:58,832 INFO     Training average negative_sample_loss at step 50600: 0.087366\n",
      "2024-03-02 22:40:58,832 INFO     Training average loss at step 50600: 0.100431\n",
      "2024-03-02 22:41:22,778 INFO     Training average positive_sample_loss at step 50700: 0.113211\n",
      "2024-03-02 22:41:22,778 INFO     Training average negative_sample_loss at step 50700: 0.086697\n",
      "2024-03-02 22:41:22,778 INFO     Training average loss at step 50700: 0.099954\n",
      "2024-03-02 22:41:46,626 INFO     Training average positive_sample_loss at step 50800: 0.113979\n",
      "2024-03-02 22:41:46,626 INFO     Training average negative_sample_loss at step 50800: 0.086285\n",
      "2024-03-02 22:41:46,626 INFO     Training average loss at step 50800: 0.100132\n",
      "2024-03-02 22:42:13,043 INFO     Training average positive_sample_loss at step 50900: 0.112799\n",
      "2024-03-02 22:42:13,044 INFO     Training average negative_sample_loss at step 50900: 0.086711\n",
      "2024-03-02 22:42:13,044 INFO     Training average loss at step 50900: 0.099755\n",
      "2024-03-02 22:42:35,804 INFO     Training average positive_sample_loss at step 51000: 0.113318\n",
      "2024-03-02 22:42:35,804 INFO     Training average negative_sample_loss at step 51000: 0.086045\n",
      "2024-03-02 22:42:35,804 INFO     Training average loss at step 51000: 0.099681\n",
      "2024-03-02 22:43:04,204 INFO     Training average positive_sample_loss at step 51100: 0.113694\n",
      "2024-03-02 22:43:04,205 INFO     Training average negative_sample_loss at step 51100: 0.087063\n",
      "2024-03-02 22:43:04,205 INFO     Training average loss at step 51100: 0.100378\n",
      "2024-03-02 22:43:27,673 INFO     Training average positive_sample_loss at step 51200: 0.112291\n",
      "2024-03-02 22:43:27,673 INFO     Training average negative_sample_loss at step 51200: 0.085676\n",
      "2024-03-02 22:43:27,673 INFO     Training average loss at step 51200: 0.098984\n",
      "2024-03-02 22:43:51,545 INFO     Training average positive_sample_loss at step 51300: 0.113885\n",
      "2024-03-02 22:43:51,546 INFO     Training average negative_sample_loss at step 51300: 0.086405\n",
      "2024-03-02 22:43:51,546 INFO     Training average loss at step 51300: 0.100145\n",
      "2024-03-02 22:44:18,318 INFO     Training average positive_sample_loss at step 51400: 0.112952\n",
      "2024-03-02 22:44:18,319 INFO     Training average negative_sample_loss at step 51400: 0.086559\n",
      "2024-03-02 22:44:18,319 INFO     Training average loss at step 51400: 0.099755\n",
      "2024-03-02 22:44:41,945 INFO     Training average positive_sample_loss at step 51500: 0.113049\n",
      "2024-03-02 22:44:41,946 INFO     Training average negative_sample_loss at step 51500: 0.086102\n",
      "2024-03-02 22:44:41,946 INFO     Training average loss at step 51500: 0.099576\n",
      "2024-03-02 22:45:07,646 INFO     Training average positive_sample_loss at step 51600: 0.114383\n",
      "2024-03-02 22:45:07,646 INFO     Training average negative_sample_loss at step 51600: 0.086133\n",
      "2024-03-02 22:45:07,646 INFO     Training average loss at step 51600: 0.100258\n",
      "2024-03-02 22:45:31,883 INFO     Training average positive_sample_loss at step 51700: 0.111981\n",
      "2024-03-02 22:45:31,884 INFO     Training average negative_sample_loss at step 51700: 0.085620\n",
      "2024-03-02 22:45:31,884 INFO     Training average loss at step 51700: 0.098801\n",
      "2024-03-02 22:45:55,883 INFO     Training average positive_sample_loss at step 51800: 0.113801\n",
      "2024-03-02 22:45:55,884 INFO     Training average negative_sample_loss at step 51800: 0.085143\n",
      "2024-03-02 22:45:55,884 INFO     Training average loss at step 51800: 0.099472\n",
      "2024-03-02 22:46:24,386 INFO     Training average positive_sample_loss at step 51900: 0.113785\n",
      "2024-03-02 22:46:24,387 INFO     Training average negative_sample_loss at step 51900: 0.086655\n",
      "2024-03-02 22:46:24,387 INFO     Training average loss at step 51900: 0.100220\n",
      "2024-03-02 22:46:47,695 INFO     Training average positive_sample_loss at step 52000: 0.112835\n",
      "2024-03-02 22:46:47,695 INFO     Training average negative_sample_loss at step 52000: 0.085800\n",
      "2024-03-02 22:46:47,695 INFO     Training average loss at step 52000: 0.099317\n",
      "2024-03-02 22:47:11,609 INFO     Training average positive_sample_loss at step 52100: 0.113747\n",
      "2024-03-02 22:47:11,610 INFO     Training average negative_sample_loss at step 52100: 0.085866\n",
      "2024-03-02 22:47:11,610 INFO     Training average loss at step 52100: 0.099807\n",
      "2024-03-02 22:47:38,343 INFO     Training average positive_sample_loss at step 52200: 0.112478\n",
      "2024-03-02 22:47:38,343 INFO     Training average negative_sample_loss at step 52200: 0.085732\n",
      "2024-03-02 22:47:38,343 INFO     Training average loss at step 52200: 0.099105\n",
      "2024-03-02 22:48:01,549 INFO     Training average positive_sample_loss at step 52300: 0.114133\n",
      "2024-03-02 22:48:01,549 INFO     Training average negative_sample_loss at step 52300: 0.085896\n",
      "2024-03-02 22:48:01,550 INFO     Training average loss at step 52300: 0.100015\n",
      "2024-03-02 22:48:27,985 INFO     Training average positive_sample_loss at step 52400: 0.113284\n",
      "2024-03-02 22:48:27,986 INFO     Training average negative_sample_loss at step 52400: 0.085876\n",
      "2024-03-02 22:48:27,986 INFO     Training average loss at step 52400: 0.099580\n",
      "2024-03-02 22:48:52,773 INFO     Training average positive_sample_loss at step 52500: 0.112668\n",
      "2024-03-02 22:48:52,773 INFO     Training average negative_sample_loss at step 52500: 0.085321\n",
      "2024-03-02 22:48:52,774 INFO     Training average loss at step 52500: 0.098994\n",
      "2024-03-02 22:49:16,222 INFO     Training average positive_sample_loss at step 52600: 0.113877\n",
      "2024-03-02 22:49:16,223 INFO     Training average negative_sample_loss at step 52600: 0.084792\n",
      "2024-03-02 22:49:16,223 INFO     Training average loss at step 52600: 0.099335\n",
      "2024-03-02 22:49:43,210 INFO     Training average positive_sample_loss at step 52700: 0.112849\n",
      "2024-03-02 22:49:43,211 INFO     Training average negative_sample_loss at step 52700: 0.085341\n",
      "2024-03-02 22:49:43,211 INFO     Training average loss at step 52700: 0.099095\n",
      "2024-03-02 22:50:07,862 INFO     Training average positive_sample_loss at step 52800: 0.113245\n",
      "2024-03-02 22:50:07,862 INFO     Training average negative_sample_loss at step 52800: 0.085107\n",
      "2024-03-02 22:50:07,862 INFO     Training average loss at step 52800: 0.099176\n",
      "2024-03-02 22:50:34,521 INFO     Training average positive_sample_loss at step 52900: 0.113917\n",
      "2024-03-02 22:50:34,521 INFO     Training average negative_sample_loss at step 52900: 0.085351\n",
      "2024-03-02 22:50:34,521 INFO     Training average loss at step 52900: 0.099634\n",
      "2024-03-02 22:50:58,028 INFO     Training average positive_sample_loss at step 53000: 0.112701\n",
      "2024-03-02 22:50:58,029 INFO     Training average negative_sample_loss at step 53000: 0.085168\n",
      "2024-03-02 22:50:58,029 INFO     Training average loss at step 53000: 0.098934\n",
      "2024-03-02 22:51:21,144 INFO     Training average positive_sample_loss at step 53100: 0.113597\n",
      "2024-03-02 22:51:21,144 INFO     Training average negative_sample_loss at step 53100: 0.085723\n",
      "2024-03-02 22:51:21,144 INFO     Training average loss at step 53100: 0.099660\n",
      "2024-03-02 22:51:49,210 INFO     Training average positive_sample_loss at step 53200: 0.113120\n",
      "2024-03-02 22:51:49,210 INFO     Training average negative_sample_loss at step 53200: 0.085158\n",
      "2024-03-02 22:51:49,210 INFO     Training average loss at step 53200: 0.099139\n",
      "2024-03-02 22:52:12,302 INFO     Training average positive_sample_loss at step 53300: 0.113367\n",
      "2024-03-02 22:52:12,303 INFO     Training average negative_sample_loss at step 53300: 0.084677\n",
      "2024-03-02 22:52:12,303 INFO     Training average loss at step 53300: 0.099022\n",
      "2024-03-02 22:52:35,457 INFO     Training average positive_sample_loss at step 53400: 0.113880\n",
      "2024-03-02 22:52:35,457 INFO     Training average negative_sample_loss at step 53400: 0.084781\n",
      "2024-03-02 22:52:35,457 INFO     Training average loss at step 53400: 0.099330\n",
      "2024-03-02 22:53:02,431 INFO     Training average positive_sample_loss at step 53500: 0.112594\n",
      "2024-03-02 22:53:02,431 INFO     Training average negative_sample_loss at step 53500: 0.085086\n",
      "2024-03-02 22:53:02,431 INFO     Training average loss at step 53500: 0.098840\n",
      "2024-03-02 22:53:26,138 INFO     Training average positive_sample_loss at step 53600: 0.113674\n",
      "2024-03-02 22:53:26,139 INFO     Training average negative_sample_loss at step 53600: 0.084936\n",
      "2024-03-02 22:53:26,139 INFO     Training average loss at step 53600: 0.099305\n",
      "2024-03-02 22:53:53,223 INFO     Training average positive_sample_loss at step 53700: 0.113179\n",
      "2024-03-02 22:53:53,223 INFO     Training average negative_sample_loss at step 53700: 0.085195\n",
      "2024-03-02 22:53:53,224 INFO     Training average loss at step 53700: 0.099187\n",
      "2024-03-02 22:54:17,122 INFO     Training average positive_sample_loss at step 53800: 0.112797\n",
      "2024-03-02 22:54:17,123 INFO     Training average negative_sample_loss at step 53800: 0.084408\n",
      "2024-03-02 22:54:17,123 INFO     Training average loss at step 53800: 0.098602\n",
      "2024-03-02 22:54:40,924 INFO     Training average positive_sample_loss at step 53900: 0.113849\n",
      "2024-03-02 22:54:40,925 INFO     Training average negative_sample_loss at step 53900: 0.085200\n",
      "2024-03-02 22:54:40,925 INFO     Training average loss at step 53900: 0.099524\n",
      "2024-03-02 22:55:07,807 INFO     Training average positive_sample_loss at step 54000: 0.112747\n",
      "2024-03-02 22:55:07,808 INFO     Training average negative_sample_loss at step 54000: 0.084742\n",
      "2024-03-02 22:55:07,808 INFO     Training average loss at step 54000: 0.098744\n",
      "2024-03-02 22:55:32,095 INFO     Training average positive_sample_loss at step 54100: 0.113372\n",
      "2024-03-02 22:55:32,095 INFO     Training average negative_sample_loss at step 54100: 0.085605\n",
      "2024-03-02 22:55:32,095 INFO     Training average loss at step 54100: 0.099488\n",
      "2024-03-02 22:55:59,156 INFO     Training average positive_sample_loss at step 54200: 0.113777\n",
      "2024-03-02 22:55:59,156 INFO     Training average negative_sample_loss at step 54200: 0.085545\n",
      "2024-03-02 22:55:59,156 INFO     Training average loss at step 54200: 0.099661\n",
      "2024-03-02 22:56:22,993 INFO     Training average positive_sample_loss at step 54300: 0.112615\n",
      "2024-03-02 22:56:22,994 INFO     Training average negative_sample_loss at step 54300: 0.084411\n",
      "2024-03-02 22:56:22,994 INFO     Training average loss at step 54300: 0.098513\n",
      "2024-03-02 22:56:46,642 INFO     Training average positive_sample_loss at step 54400: 0.113312\n",
      "2024-03-02 22:56:46,642 INFO     Training average negative_sample_loss at step 54400: 0.084595\n",
      "2024-03-02 22:56:46,643 INFO     Training average loss at step 54400: 0.098953\n",
      "2024-03-02 22:57:15,615 INFO     Training average positive_sample_loss at step 54500: 0.113491\n",
      "2024-03-02 22:57:15,616 INFO     Training average negative_sample_loss at step 54500: 0.084962\n",
      "2024-03-02 22:57:15,616 INFO     Training average loss at step 54500: 0.099227\n",
      "2024-03-02 22:57:39,194 INFO     Training average positive_sample_loss at step 54600: 0.113367\n",
      "2024-03-02 22:57:39,195 INFO     Training average negative_sample_loss at step 54600: 0.084986\n",
      "2024-03-02 22:57:39,195 INFO     Training average loss at step 54600: 0.099177\n",
      "2024-03-02 22:58:05,832 INFO     Training average positive_sample_loss at step 54700: 0.113502\n",
      "2024-03-02 22:58:05,832 INFO     Training average negative_sample_loss at step 54700: 0.084893\n",
      "2024-03-02 22:58:05,833 INFO     Training average loss at step 54700: 0.099197\n",
      "2024-03-02 22:58:29,580 INFO     Training average positive_sample_loss at step 54800: 0.112227\n",
      "2024-03-02 22:58:29,581 INFO     Training average negative_sample_loss at step 54800: 0.085412\n",
      "2024-03-02 22:58:29,581 INFO     Training average loss at step 54800: 0.098819\n",
      "2024-03-02 22:58:52,924 INFO     Training average positive_sample_loss at step 54900: 0.113870\n",
      "2024-03-02 22:58:52,925 INFO     Training average negative_sample_loss at step 54900: 0.085155\n",
      "2024-03-02 22:58:52,925 INFO     Training average loss at step 54900: 0.099512\n",
      "2024-03-02 22:59:19,141 INFO     Training average positive_sample_loss at step 55000: 0.113241\n",
      "2024-03-02 22:59:19,141 INFO     Training average negative_sample_loss at step 55000: 0.084255\n",
      "2024-03-02 22:59:19,142 INFO     Training average loss at step 55000: 0.098748\n",
      "2024-03-02 22:59:43,054 INFO     Training average positive_sample_loss at step 55100: 0.113187\n",
      "2024-03-02 22:59:43,054 INFO     Training average negative_sample_loss at step 55100: 0.084429\n",
      "2024-03-02 22:59:43,055 INFO     Training average loss at step 55100: 0.098808\n",
      "2024-03-02 23:00:06,665 INFO     Training average positive_sample_loss at step 55200: 0.113667\n",
      "2024-03-02 23:00:06,665 INFO     Training average negative_sample_loss at step 55200: 0.084585\n",
      "2024-03-02 23:00:06,665 INFO     Training average loss at step 55200: 0.099126\n",
      "2024-03-02 23:00:33,230 INFO     Training average positive_sample_loss at step 55300: 0.112484\n",
      "2024-03-02 23:00:33,230 INFO     Training average negative_sample_loss at step 55300: 0.085062\n",
      "2024-03-02 23:00:33,230 INFO     Training average loss at step 55300: 0.098773\n",
      "2024-03-02 23:00:56,837 INFO     Training average positive_sample_loss at step 55400: 0.113269\n",
      "2024-03-02 23:00:56,837 INFO     Training average negative_sample_loss at step 55400: 0.084830\n",
      "2024-03-02 23:00:56,837 INFO     Training average loss at step 55400: 0.099050\n",
      "2024-03-02 23:01:23,178 INFO     Training average positive_sample_loss at step 55500: 0.114070\n",
      "2024-03-02 23:01:23,178 INFO     Training average negative_sample_loss at step 55500: 0.084647\n",
      "2024-03-02 23:01:23,178 INFO     Training average loss at step 55500: 0.099359\n",
      "2024-03-02 23:01:46,003 INFO     Training average positive_sample_loss at step 55600: 0.112654\n",
      "2024-03-02 23:01:46,004 INFO     Training average negative_sample_loss at step 55600: 0.084953\n",
      "2024-03-02 23:01:46,004 INFO     Training average loss at step 55600: 0.098804\n",
      "2024-03-02 23:02:09,510 INFO     Training average positive_sample_loss at step 55700: 0.113655\n",
      "2024-03-02 23:02:09,511 INFO     Training average negative_sample_loss at step 55700: 0.084738\n",
      "2024-03-02 23:02:09,511 INFO     Training average loss at step 55700: 0.099197\n",
      "2024-03-02 23:02:37,974 INFO     Training average positive_sample_loss at step 55800: 0.112481\n",
      "2024-03-02 23:02:37,975 INFO     Training average negative_sample_loss at step 55800: 0.084301\n",
      "2024-03-02 23:02:37,975 INFO     Training average loss at step 55800: 0.098391\n",
      "2024-03-02 23:03:00,814 INFO     Training average positive_sample_loss at step 55900: 0.113285\n",
      "2024-03-02 23:03:00,815 INFO     Training average negative_sample_loss at step 55900: 0.084891\n",
      "2024-03-02 23:03:00,815 INFO     Training average loss at step 55900: 0.099088\n",
      "2024-03-02 23:03:27,301 INFO     Training average positive_sample_loss at step 56000: 0.114027\n",
      "2024-03-02 23:03:27,301 INFO     Training average negative_sample_loss at step 56000: 0.084958\n",
      "2024-03-02 23:03:27,301 INFO     Training average loss at step 56000: 0.099493\n",
      "2024-03-02 23:03:50,383 INFO     Training average positive_sample_loss at step 56100: 0.112427\n",
      "2024-03-02 23:03:50,383 INFO     Training average negative_sample_loss at step 56100: 0.084569\n",
      "2024-03-02 23:03:50,384 INFO     Training average loss at step 56100: 0.098498\n",
      "2024-03-02 23:04:13,543 INFO     Training average positive_sample_loss at step 56200: 0.113675\n",
      "2024-03-02 23:04:13,543 INFO     Training average negative_sample_loss at step 56200: 0.085101\n",
      "2024-03-02 23:04:13,543 INFO     Training average loss at step 56200: 0.099388\n",
      "2024-03-02 23:04:40,772 INFO     Training average positive_sample_loss at step 56300: 0.113075\n",
      "2024-03-02 23:04:40,773 INFO     Training average negative_sample_loss at step 56300: 0.084661\n",
      "2024-03-02 23:04:40,773 INFO     Training average loss at step 56300: 0.098868\n",
      "2024-03-02 23:05:03,797 INFO     Training average positive_sample_loss at step 56400: 0.112985\n",
      "2024-03-02 23:05:03,797 INFO     Training average negative_sample_loss at step 56400: 0.084091\n",
      "2024-03-02 23:05:03,797 INFO     Training average loss at step 56400: 0.098538\n",
      "2024-03-02 23:05:26,808 INFO     Training average positive_sample_loss at step 56500: 0.113749\n",
      "2024-03-02 23:05:26,809 INFO     Training average negative_sample_loss at step 56500: 0.084920\n",
      "2024-03-02 23:05:26,809 INFO     Training average loss at step 56500: 0.099334\n",
      "2024-03-02 23:05:53,762 INFO     Training average positive_sample_loss at step 56600: 0.112596\n",
      "2024-03-02 23:05:53,762 INFO     Training average negative_sample_loss at step 56600: 0.084633\n",
      "2024-03-02 23:05:53,762 INFO     Training average loss at step 56600: 0.098615\n",
      "2024-03-02 23:06:17,337 INFO     Training average positive_sample_loss at step 56700: 0.113739\n",
      "2024-03-02 23:06:17,337 INFO     Training average negative_sample_loss at step 56700: 0.084875\n",
      "2024-03-02 23:06:17,337 INFO     Training average loss at step 56700: 0.099307\n",
      "2024-03-02 23:06:44,137 INFO     Training average positive_sample_loss at step 56800: 0.112905\n",
      "2024-03-02 23:06:44,138 INFO     Training average negative_sample_loss at step 56800: 0.084470\n",
      "2024-03-02 23:06:44,138 INFO     Training average loss at step 56800: 0.098687\n",
      "2024-03-02 23:07:07,791 INFO     Training average positive_sample_loss at step 56900: 0.113225\n",
      "2024-03-02 23:07:07,791 INFO     Training average negative_sample_loss at step 56900: 0.085428\n",
      "2024-03-02 23:07:07,791 INFO     Training average loss at step 56900: 0.099327\n",
      "2024-03-02 23:07:31,053 INFO     Training average positive_sample_loss at step 57000: 0.113295\n",
      "2024-03-02 23:07:31,053 INFO     Training average negative_sample_loss at step 57000: 0.083824\n",
      "2024-03-02 23:07:31,054 INFO     Training average loss at step 57000: 0.098560\n",
      "2024-03-02 23:07:59,664 INFO     Training average positive_sample_loss at step 57100: 0.112938\n",
      "2024-03-02 23:07:59,665 INFO     Training average negative_sample_loss at step 57100: 0.084883\n",
      "2024-03-02 23:07:59,665 INFO     Training average loss at step 57100: 0.098911\n",
      "2024-03-02 23:08:23,942 INFO     Training average positive_sample_loss at step 57200: 0.113212\n",
      "2024-03-02 23:08:23,942 INFO     Training average negative_sample_loss at step 57200: 0.085225\n",
      "2024-03-02 23:08:23,942 INFO     Training average loss at step 57200: 0.099219\n",
      "2024-03-02 23:08:50,739 INFO     Training average positive_sample_loss at step 57300: 0.113420\n",
      "2024-03-02 23:08:50,740 INFO     Training average negative_sample_loss at step 57300: 0.085549\n",
      "2024-03-02 23:08:50,740 INFO     Training average loss at step 57300: 0.099485\n",
      "2024-03-02 23:09:14,438 INFO     Training average positive_sample_loss at step 57400: 0.113048\n",
      "2024-03-02 23:09:14,439 INFO     Training average negative_sample_loss at step 57400: 0.083851\n",
      "2024-03-02 23:09:14,439 INFO     Training average loss at step 57400: 0.098449\n",
      "2024-03-02 23:09:38,233 INFO     Training average positive_sample_loss at step 57500: 0.113435\n",
      "2024-03-02 23:09:38,234 INFO     Training average negative_sample_loss at step 57500: 0.085155\n",
      "2024-03-02 23:09:38,234 INFO     Training average loss at step 57500: 0.099295\n",
      "2024-03-02 23:10:05,036 INFO     Training average positive_sample_loss at step 57600: 0.113068\n",
      "2024-03-02 23:10:05,036 INFO     Training average negative_sample_loss at step 57600: 0.084883\n",
      "2024-03-02 23:10:05,036 INFO     Training average loss at step 57600: 0.098976\n",
      "2024-03-02 23:10:28,331 INFO     Training average positive_sample_loss at step 57700: 0.112410\n",
      "2024-03-02 23:10:28,332 INFO     Training average negative_sample_loss at step 57700: 0.083785\n",
      "2024-03-02 23:10:28,332 INFO     Training average loss at step 57700: 0.098098\n",
      "2024-03-02 23:10:55,078 INFO     Training average positive_sample_loss at step 57800: 0.114231\n",
      "2024-03-02 23:10:55,079 INFO     Training average negative_sample_loss at step 57800: 0.084867\n",
      "2024-03-02 23:10:55,079 INFO     Training average loss at step 57800: 0.099549\n",
      "2024-03-02 23:11:19,024 INFO     Training average positive_sample_loss at step 57900: 0.112712\n",
      "2024-03-02 23:11:19,024 INFO     Training average negative_sample_loss at step 57900: 0.084655\n",
      "2024-03-02 23:11:19,024 INFO     Training average loss at step 57900: 0.098683\n",
      "2024-03-02 23:11:42,796 INFO     Training average positive_sample_loss at step 58000: 0.112952\n",
      "2024-03-02 23:11:42,797 INFO     Training average negative_sample_loss at step 58000: 0.084039\n",
      "2024-03-02 23:11:42,797 INFO     Training average loss at step 58000: 0.098495\n",
      "2024-03-02 23:12:09,928 INFO     Training average positive_sample_loss at step 58100: 0.113411\n",
      "2024-03-02 23:12:09,928 INFO     Training average negative_sample_loss at step 58100: 0.084613\n",
      "2024-03-02 23:12:09,928 INFO     Training average loss at step 58100: 0.099012\n",
      "2024-03-02 23:12:33,403 INFO     Training average positive_sample_loss at step 58200: 0.112901\n",
      "2024-03-02 23:12:33,404 INFO     Training average negative_sample_loss at step 58200: 0.084558\n",
      "2024-03-02 23:12:33,404 INFO     Training average loss at step 58200: 0.098729\n",
      "2024-03-02 23:12:57,312 INFO     Training average positive_sample_loss at step 58300: 0.113752\n",
      "2024-03-02 23:12:57,312 INFO     Training average negative_sample_loss at step 58300: 0.085123\n",
      "2024-03-02 23:12:57,312 INFO     Training average loss at step 58300: 0.099438\n",
      "2024-03-02 23:13:26,033 INFO     Training average positive_sample_loss at step 58400: 0.112638\n",
      "2024-03-02 23:13:26,033 INFO     Training average negative_sample_loss at step 58400: 0.084672\n",
      "2024-03-02 23:13:26,033 INFO     Training average loss at step 58400: 0.098655\n",
      "2024-03-02 23:13:49,816 INFO     Training average positive_sample_loss at step 58500: 0.113253\n",
      "2024-03-02 23:13:49,817 INFO     Training average negative_sample_loss at step 58500: 0.083580\n",
      "2024-03-02 23:13:49,817 INFO     Training average loss at step 58500: 0.098417\n",
      "2024-03-02 23:14:17,251 INFO     Training average positive_sample_loss at step 58600: 0.113561\n",
      "2024-03-02 23:14:17,251 INFO     Training average negative_sample_loss at step 58600: 0.085590\n",
      "2024-03-02 23:14:17,251 INFO     Training average loss at step 58600: 0.099576\n",
      "2024-03-02 23:14:40,583 INFO     Training average positive_sample_loss at step 58700: 0.112699\n",
      "2024-03-02 23:14:40,584 INFO     Training average negative_sample_loss at step 58700: 0.085215\n",
      "2024-03-02 23:14:40,584 INFO     Training average loss at step 58700: 0.098957\n",
      "2024-03-02 23:15:03,935 INFO     Training average positive_sample_loss at step 58800: 0.113457\n",
      "2024-03-02 23:15:03,936 INFO     Training average negative_sample_loss at step 58800: 0.084522\n",
      "2024-03-02 23:15:03,936 INFO     Training average loss at step 58800: 0.098990\n",
      "2024-03-02 23:15:30,601 INFO     Training average positive_sample_loss at step 58900: 0.113188\n",
      "2024-03-02 23:15:30,602 INFO     Training average negative_sample_loss at step 58900: 0.084625\n",
      "2024-03-02 23:15:30,602 INFO     Training average loss at step 58900: 0.098907\n",
      "2024-03-02 23:15:53,729 INFO     Training average positive_sample_loss at step 59000: 0.113163\n",
      "2024-03-02 23:15:53,730 INFO     Training average negative_sample_loss at step 59000: 0.084237\n",
      "2024-03-02 23:15:53,730 INFO     Training average loss at step 59000: 0.098700\n",
      "2024-03-02 23:16:20,222 INFO     Training average positive_sample_loss at step 59100: 0.113315\n",
      "2024-03-02 23:16:20,222 INFO     Training average negative_sample_loss at step 59100: 0.084361\n",
      "2024-03-02 23:16:20,222 INFO     Training average loss at step 59100: 0.098838\n",
      "2024-03-02 23:16:43,486 INFO     Training average positive_sample_loss at step 59200: 0.113096\n",
      "2024-03-02 23:16:43,486 INFO     Training average negative_sample_loss at step 59200: 0.085574\n",
      "2024-03-02 23:16:43,486 INFO     Training average loss at step 59200: 0.099335\n",
      "2024-03-02 23:17:06,911 INFO     Training average positive_sample_loss at step 59300: 0.113311\n",
      "2024-03-02 23:17:06,911 INFO     Training average negative_sample_loss at step 59300: 0.084089\n",
      "2024-03-02 23:17:06,912 INFO     Training average loss at step 59300: 0.098700\n",
      "2024-03-02 23:17:33,261 INFO     Training average positive_sample_loss at step 59400: 0.113194\n",
      "2024-03-02 23:17:33,262 INFO     Training average negative_sample_loss at step 59400: 0.085094\n",
      "2024-03-02 23:17:33,262 INFO     Training average loss at step 59400: 0.099144\n",
      "2024-03-02 23:17:56,998 INFO     Training average positive_sample_loss at step 59500: 0.112813\n",
      "2024-03-02 23:17:56,999 INFO     Training average negative_sample_loss at step 59500: 0.084337\n",
      "2024-03-02 23:17:56,999 INFO     Training average loss at step 59500: 0.098575\n",
      "2024-03-02 23:18:25,520 INFO     Training average positive_sample_loss at step 59600: 0.113635\n",
      "2024-03-02 23:18:25,521 INFO     Training average negative_sample_loss at step 59600: 0.084886\n",
      "2024-03-02 23:18:25,521 INFO     Training average loss at step 59600: 0.099260\n",
      "2024-03-02 23:18:49,471 INFO     Training average positive_sample_loss at step 59700: 0.112595\n",
      "2024-03-02 23:18:49,472 INFO     Training average negative_sample_loss at step 59700: 0.083838\n",
      "2024-03-02 23:18:49,472 INFO     Training average loss at step 59700: 0.098216\n",
      "2024-03-02 23:19:12,510 INFO     Training average positive_sample_loss at step 59800: 0.113044\n",
      "2024-03-02 23:19:12,511 INFO     Training average negative_sample_loss at step 59800: 0.085514\n",
      "2024-03-02 23:19:12,511 INFO     Training average loss at step 59800: 0.099279\n",
      "2024-03-02 23:19:39,467 INFO     Training average positive_sample_loss at step 59900: 0.113473\n",
      "2024-03-02 23:19:39,467 INFO     Training average negative_sample_loss at step 59900: 0.085735\n",
      "2024-03-02 23:19:39,468 INFO     Training average loss at step 59900: 0.099604\n",
      "2024-03-02 23:20:05,221 INFO     Training average positive_sample_loss at step 60000: 0.113395\n",
      "2024-03-02 23:20:05,222 INFO     Training average negative_sample_loss at step 60000: 0.084579\n",
      "2024-03-02 23:20:05,222 INFO     Training average loss at step 60000: 0.098987\n",
      "2024-03-02 23:20:05,222 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-02 23:20:06,069 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-02 23:20:33,298 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-02 23:20:54,473 INFO     Valid MRR at step 60000: 0.642302\n",
      "2024-03-02 23:20:54,474 INFO     Valid MR at step 60000: 236.379085\n",
      "2024-03-02 23:20:54,474 INFO     Valid HITS@1 at step 60000: 0.587182\n",
      "2024-03-02 23:20:54,474 INFO     Valid HITS@3 at step 60000: 0.661539\n",
      "2024-03-02 23:20:54,474 INFO     Valid HITS@10 at step 60000: 0.755202\n",
      "2024-03-02 23:21:14,119 INFO     Training average positive_sample_loss at step 60100: 0.113288\n",
      "2024-03-02 23:21:14,120 INFO     Training average negative_sample_loss at step 60100: 0.084446\n",
      "2024-03-02 23:21:14,120 INFO     Training average loss at step 60100: 0.098867\n",
      "2024-03-02 23:21:41,910 INFO     Training average positive_sample_loss at step 60200: 0.112300\n",
      "2024-03-02 23:21:41,910 INFO     Training average negative_sample_loss at step 60200: 0.084783\n",
      "2024-03-02 23:21:41,910 INFO     Training average loss at step 60200: 0.098542\n",
      "2024-03-02 23:22:05,466 INFO     Training average positive_sample_loss at step 60300: 0.114003\n",
      "2024-03-02 23:22:05,466 INFO     Training average negative_sample_loss at step 60300: 0.084933\n",
      "2024-03-02 23:22:05,466 INFO     Training average loss at step 60300: 0.099468\n",
      "2024-03-02 23:22:31,881 INFO     Training average positive_sample_loss at step 60400: 0.113198\n",
      "2024-03-02 23:22:31,882 INFO     Training average negative_sample_loss at step 60400: 0.084973\n",
      "2024-03-02 23:22:31,882 INFO     Training average loss at step 60400: 0.099085\n",
      "2024-03-02 23:22:55,522 INFO     Training average positive_sample_loss at step 60500: 0.112470\n",
      "2024-03-02 23:22:55,523 INFO     Training average negative_sample_loss at step 60500: 0.083741\n",
      "2024-03-02 23:22:55,523 INFO     Training average loss at step 60500: 0.098105\n",
      "2024-03-02 23:23:18,982 INFO     Training average positive_sample_loss at step 60600: 0.113438\n",
      "2024-03-02 23:23:18,983 INFO     Training average negative_sample_loss at step 60600: 0.084794\n",
      "2024-03-02 23:23:18,983 INFO     Training average loss at step 60600: 0.099116\n",
      "2024-03-02 23:23:45,528 INFO     Training average positive_sample_loss at step 60700: 0.113022\n",
      "2024-03-02 23:23:45,528 INFO     Training average negative_sample_loss at step 60700: 0.084388\n",
      "2024-03-02 23:23:45,528 INFO     Training average loss at step 60700: 0.098705\n",
      "2024-03-02 23:24:09,122 INFO     Training average positive_sample_loss at step 60800: 0.113517\n",
      "2024-03-02 23:24:09,122 INFO     Training average negative_sample_loss at step 60800: 0.084860\n",
      "2024-03-02 23:24:09,122 INFO     Training average loss at step 60800: 0.099189\n",
      "2024-03-02 23:24:37,180 INFO     Training average positive_sample_loss at step 60900: 0.113342\n",
      "2024-03-02 23:24:37,181 INFO     Training average negative_sample_loss at step 60900: 0.084181\n",
      "2024-03-02 23:24:37,181 INFO     Training average loss at step 60900: 0.098761\n",
      "2024-03-02 23:25:00,360 INFO     Training average positive_sample_loss at step 61000: 0.112386\n",
      "2024-03-02 23:25:00,361 INFO     Training average negative_sample_loss at step 61000: 0.083908\n",
      "2024-03-02 23:25:00,361 INFO     Training average loss at step 61000: 0.098147\n",
      "2024-03-02 23:25:23,366 INFO     Training average positive_sample_loss at step 61100: 0.113785\n",
      "2024-03-02 23:25:23,366 INFO     Training average negative_sample_loss at step 61100: 0.084766\n",
      "2024-03-02 23:25:23,366 INFO     Training average loss at step 61100: 0.099275\n",
      "2024-03-02 23:25:50,264 INFO     Training average positive_sample_loss at step 61200: 0.112984\n",
      "2024-03-02 23:25:50,265 INFO     Training average negative_sample_loss at step 61200: 0.084595\n",
      "2024-03-02 23:25:50,265 INFO     Training average loss at step 61200: 0.098789\n",
      "2024-03-02 23:26:14,092 INFO     Training average positive_sample_loss at step 61300: 0.112380\n",
      "2024-03-02 23:26:14,093 INFO     Training average negative_sample_loss at step 61300: 0.084303\n",
      "2024-03-02 23:26:14,093 INFO     Training average loss at step 61300: 0.098341\n",
      "2024-03-02 23:26:37,852 INFO     Training average positive_sample_loss at step 61400: 0.114020\n",
      "2024-03-02 23:26:37,853 INFO     Training average negative_sample_loss at step 61400: 0.084338\n",
      "2024-03-02 23:26:37,853 INFO     Training average loss at step 61400: 0.099179\n",
      "2024-03-02 23:27:04,495 INFO     Training average positive_sample_loss at step 61500: 0.111870\n",
      "2024-03-02 23:27:04,496 INFO     Training average negative_sample_loss at step 61500: 0.085021\n",
      "2024-03-02 23:27:04,496 INFO     Training average loss at step 61500: 0.098445\n",
      "2024-03-02 23:27:28,059 INFO     Training average positive_sample_loss at step 61600: 0.113696\n",
      "2024-03-02 23:27:28,060 INFO     Training average negative_sample_loss at step 61600: 0.084760\n",
      "2024-03-02 23:27:28,060 INFO     Training average loss at step 61600: 0.099228\n",
      "2024-03-02 23:27:55,082 INFO     Training average positive_sample_loss at step 61700: 0.113310\n",
      "2024-03-02 23:27:55,083 INFO     Training average negative_sample_loss at step 61700: 0.084301\n",
      "2024-03-02 23:27:55,083 INFO     Training average loss at step 61700: 0.098805\n",
      "2024-03-02 23:28:19,079 INFO     Training average positive_sample_loss at step 61800: 0.112782\n",
      "2024-03-02 23:28:19,079 INFO     Training average negative_sample_loss at step 61800: 0.085046\n",
      "2024-03-02 23:28:19,079 INFO     Training average loss at step 61800: 0.098914\n",
      "2024-03-02 23:28:42,862 INFO     Training average positive_sample_loss at step 61900: 0.113574\n",
      "2024-03-02 23:28:42,863 INFO     Training average negative_sample_loss at step 61900: 0.084566\n",
      "2024-03-02 23:28:42,863 INFO     Training average loss at step 61900: 0.099070\n",
      "2024-03-02 23:29:09,677 INFO     Training average positive_sample_loss at step 62000: 0.112260\n",
      "2024-03-02 23:29:09,677 INFO     Training average negative_sample_loss at step 62000: 0.084638\n",
      "2024-03-02 23:29:09,677 INFO     Training average loss at step 62000: 0.098449\n",
      "2024-03-02 23:29:33,674 INFO     Training average positive_sample_loss at step 62100: 0.113147\n",
      "2024-03-02 23:29:33,674 INFO     Training average negative_sample_loss at step 62100: 0.083977\n",
      "2024-03-02 23:29:33,674 INFO     Training average loss at step 62100: 0.098562\n",
      "2024-03-02 23:30:02,385 INFO     Training average positive_sample_loss at step 62200: 0.114112\n",
      "2024-03-02 23:30:02,385 INFO     Training average negative_sample_loss at step 62200: 0.084812\n",
      "2024-03-02 23:30:02,385 INFO     Training average loss at step 62200: 0.099462\n",
      "2024-03-02 23:30:25,561 INFO     Training average positive_sample_loss at step 62300: 0.112311\n",
      "2024-03-02 23:30:25,561 INFO     Training average negative_sample_loss at step 62300: 0.084208\n",
      "2024-03-02 23:30:25,561 INFO     Training average loss at step 62300: 0.098259\n",
      "2024-03-02 23:30:49,007 INFO     Training average positive_sample_loss at step 62400: 0.113482\n",
      "2024-03-02 23:30:49,008 INFO     Training average negative_sample_loss at step 62400: 0.084868\n",
      "2024-03-02 23:30:49,008 INFO     Training average loss at step 62400: 0.099175\n",
      "2024-03-02 23:31:16,024 INFO     Training average positive_sample_loss at step 62500: 0.112873\n",
      "2024-03-02 23:31:16,025 INFO     Training average negative_sample_loss at step 62500: 0.084335\n",
      "2024-03-02 23:31:16,025 INFO     Training average loss at step 62500: 0.098604\n",
      "2024-03-02 23:31:39,881 INFO     Training average positive_sample_loss at step 62600: 0.113253\n",
      "2024-03-02 23:31:39,882 INFO     Training average negative_sample_loss at step 62600: 0.084510\n",
      "2024-03-02 23:31:39,882 INFO     Training average loss at step 62600: 0.098881\n",
      "2024-03-02 23:32:06,515 INFO     Training average positive_sample_loss at step 62700: 0.113298\n",
      "2024-03-02 23:32:06,516 INFO     Training average negative_sample_loss at step 62700: 0.084900\n",
      "2024-03-02 23:32:06,516 INFO     Training average loss at step 62700: 0.099099\n",
      "2024-03-02 23:32:29,871 INFO     Training average positive_sample_loss at step 62800: 0.112173\n",
      "2024-03-02 23:32:29,872 INFO     Training average negative_sample_loss at step 62800: 0.084789\n",
      "2024-03-02 23:32:29,872 INFO     Training average loss at step 62800: 0.098481\n",
      "2024-03-02 23:32:53,066 INFO     Training average positive_sample_loss at step 62900: 0.113400\n",
      "2024-03-02 23:32:53,067 INFO     Training average negative_sample_loss at step 62900: 0.084352\n",
      "2024-03-02 23:32:53,067 INFO     Training average loss at step 62900: 0.098876\n",
      "2024-03-02 23:33:19,324 INFO     Training average positive_sample_loss at step 63000: 0.113152\n",
      "2024-03-02 23:33:19,325 INFO     Training average negative_sample_loss at step 63000: 0.084397\n",
      "2024-03-02 23:33:19,325 INFO     Training average loss at step 63000: 0.098775\n",
      "2024-03-02 23:33:43,047 INFO     Training average positive_sample_loss at step 63100: 0.112794\n",
      "2024-03-02 23:33:43,048 INFO     Training average negative_sample_loss at step 63100: 0.084035\n",
      "2024-03-02 23:33:43,048 INFO     Training average loss at step 63100: 0.098415\n",
      "2024-03-02 23:34:06,644 INFO     Training average positive_sample_loss at step 63200: 0.113937\n",
      "2024-03-02 23:34:06,644 INFO     Training average negative_sample_loss at step 63200: 0.084593\n",
      "2024-03-02 23:34:06,644 INFO     Training average loss at step 63200: 0.099265\n",
      "2024-03-02 23:34:33,731 INFO     Training average positive_sample_loss at step 63300: 0.111952\n",
      "2024-03-02 23:34:33,731 INFO     Training average negative_sample_loss at step 63300: 0.084647\n",
      "2024-03-02 23:34:33,731 INFO     Training average loss at step 63300: 0.098300\n",
      "2024-03-02 23:34:57,231 INFO     Training average positive_sample_loss at step 63400: 0.113402\n",
      "2024-03-02 23:34:57,232 INFO     Training average negative_sample_loss at step 63400: 0.083926\n",
      "2024-03-02 23:34:57,232 INFO     Training average loss at step 63400: 0.098664\n",
      "2024-03-02 23:35:25,320 INFO     Training average positive_sample_loss at step 63500: 0.113321\n",
      "2024-03-02 23:35:25,320 INFO     Training average negative_sample_loss at step 63500: 0.085127\n",
      "2024-03-02 23:35:25,320 INFO     Training average loss at step 63500: 0.099224\n",
      "2024-03-02 23:35:48,173 INFO     Training average positive_sample_loss at step 63600: 0.113027\n",
      "2024-03-02 23:35:48,173 INFO     Training average negative_sample_loss at step 63600: 0.084967\n",
      "2024-03-02 23:35:48,173 INFO     Training average loss at step 63600: 0.098997\n",
      "2024-03-02 23:36:11,542 INFO     Training average positive_sample_loss at step 63700: 0.113518\n",
      "2024-03-02 23:36:11,543 INFO     Training average negative_sample_loss at step 63700: 0.084533\n",
      "2024-03-02 23:36:11,543 INFO     Training average loss at step 63700: 0.099026\n",
      "2024-03-02 23:36:39,750 INFO     Training average positive_sample_loss at step 63800: 0.111868\n",
      "2024-03-02 23:36:39,751 INFO     Training average negative_sample_loss at step 63800: 0.084069\n",
      "2024-03-02 23:36:39,751 INFO     Training average loss at step 63800: 0.097968\n",
      "2024-03-02 23:37:02,717 INFO     Training average positive_sample_loss at step 63900: 0.113242\n",
      "2024-03-02 23:37:02,717 INFO     Training average negative_sample_loss at step 63900: 0.084631\n",
      "2024-03-02 23:37:02,717 INFO     Training average loss at step 63900: 0.098937\n",
      "2024-03-02 23:37:30,355 INFO     Training average positive_sample_loss at step 64000: 0.113872\n",
      "2024-03-02 23:37:30,356 INFO     Training average negative_sample_loss at step 64000: 0.084617\n",
      "2024-03-02 23:37:30,356 INFO     Training average loss at step 64000: 0.099244\n",
      "2024-03-02 23:37:54,051 INFO     Training average positive_sample_loss at step 64100: 0.112910\n",
      "2024-03-02 23:37:54,051 INFO     Training average negative_sample_loss at step 64100: 0.084457\n",
      "2024-03-02 23:37:54,051 INFO     Training average loss at step 64100: 0.098684\n",
      "2024-03-02 23:38:18,094 INFO     Training average positive_sample_loss at step 64200: 0.113228\n",
      "2024-03-02 23:38:18,095 INFO     Training average negative_sample_loss at step 64200: 0.083567\n",
      "2024-03-02 23:38:18,095 INFO     Training average loss at step 64200: 0.098397\n",
      "2024-03-02 23:38:45,080 INFO     Training average positive_sample_loss at step 64300: 0.112467\n",
      "2024-03-02 23:38:45,081 INFO     Training average negative_sample_loss at step 64300: 0.084580\n",
      "2024-03-02 23:38:45,081 INFO     Training average loss at step 64300: 0.098524\n",
      "2024-03-02 23:39:08,967 INFO     Training average positive_sample_loss at step 64400: 0.113283\n",
      "2024-03-02 23:39:08,967 INFO     Training average negative_sample_loss at step 64400: 0.084227\n",
      "2024-03-02 23:39:08,967 INFO     Training average loss at step 64400: 0.098755\n",
      "2024-03-02 23:39:34,803 INFO     Training average positive_sample_loss at step 64500: 0.113531\n",
      "2024-03-02 23:39:34,804 INFO     Training average negative_sample_loss at step 64500: 0.084485\n",
      "2024-03-02 23:39:34,804 INFO     Training average loss at step 64500: 0.099008\n",
      "2024-03-02 23:39:59,138 INFO     Training average positive_sample_loss at step 64600: 0.112428\n",
      "2024-03-02 23:39:59,138 INFO     Training average negative_sample_loss at step 64600: 0.083564\n",
      "2024-03-02 23:39:59,138 INFO     Training average loss at step 64600: 0.097996\n",
      "2024-03-02 23:40:22,417 INFO     Training average positive_sample_loss at step 64700: 0.113323\n",
      "2024-03-02 23:40:22,418 INFO     Training average negative_sample_loss at step 64700: 0.085238\n",
      "2024-03-02 23:40:22,418 INFO     Training average loss at step 64700: 0.099281\n",
      "2024-03-02 23:40:50,957 INFO     Training average positive_sample_loss at step 64800: 0.112501\n",
      "2024-03-02 23:40:50,958 INFO     Training average negative_sample_loss at step 64800: 0.084095\n",
      "2024-03-02 23:40:50,958 INFO     Training average loss at step 64800: 0.098298\n",
      "2024-03-02 23:41:13,910 INFO     Training average positive_sample_loss at step 64900: 0.113590\n",
      "2024-03-02 23:41:13,910 INFO     Training average negative_sample_loss at step 64900: 0.084689\n",
      "2024-03-02 23:41:13,910 INFO     Training average loss at step 64900: 0.099139\n",
      "2024-03-02 23:41:36,995 INFO     Training average positive_sample_loss at step 65000: 0.112941\n",
      "2024-03-02 23:41:36,995 INFO     Training average negative_sample_loss at step 65000: 0.083884\n",
      "2024-03-02 23:41:36,995 INFO     Training average loss at step 65000: 0.098412\n",
      "2024-03-02 23:42:04,965 INFO     Training average positive_sample_loss at step 65100: 0.112954\n",
      "2024-03-02 23:42:04,965 INFO     Training average negative_sample_loss at step 65100: 0.084525\n",
      "2024-03-02 23:42:04,965 INFO     Training average loss at step 65100: 0.098739\n",
      "2024-03-02 23:42:27,961 INFO     Training average positive_sample_loss at step 65200: 0.112928\n",
      "2024-03-02 23:42:27,961 INFO     Training average negative_sample_loss at step 65200: 0.085026\n",
      "2024-03-02 23:42:27,961 INFO     Training average loss at step 65200: 0.098977\n",
      "2024-03-02 23:42:54,775 INFO     Training average positive_sample_loss at step 65300: 0.113021\n",
      "2024-03-02 23:42:54,776 INFO     Training average negative_sample_loss at step 65300: 0.084097\n",
      "2024-03-02 23:42:54,776 INFO     Training average loss at step 65300: 0.098559\n",
      "2024-03-02 23:43:17,952 INFO     Training average positive_sample_loss at step 65400: 0.112580\n",
      "2024-03-02 23:43:17,952 INFO     Training average negative_sample_loss at step 65400: 0.083990\n",
      "2024-03-02 23:43:17,952 INFO     Training average loss at step 65400: 0.098285\n",
      "2024-03-02 23:43:41,057 INFO     Training average positive_sample_loss at step 65500: 0.113560\n",
      "2024-03-02 23:43:41,057 INFO     Training average negative_sample_loss at step 65500: 0.084529\n",
      "2024-03-02 23:43:41,057 INFO     Training average loss at step 65500: 0.099044\n",
      "2024-03-02 23:44:07,783 INFO     Training average positive_sample_loss at step 65600: 0.112658\n",
      "2024-03-02 23:44:07,784 INFO     Training average negative_sample_loss at step 65600: 0.084739\n",
      "2024-03-02 23:44:07,784 INFO     Training average loss at step 65600: 0.098699\n",
      "2024-03-02 23:44:31,515 INFO     Training average positive_sample_loss at step 65700: 0.113267\n",
      "2024-03-02 23:44:31,516 INFO     Training average negative_sample_loss at step 65700: 0.083925\n",
      "2024-03-02 23:44:31,516 INFO     Training average loss at step 65700: 0.098596\n",
      "2024-03-02 23:44:58,052 INFO     Training average positive_sample_loss at step 65800: 0.113265\n",
      "2024-03-02 23:44:58,052 INFO     Training average negative_sample_loss at step 65800: 0.085251\n",
      "2024-03-02 23:44:58,052 INFO     Training average loss at step 65800: 0.099258\n",
      "2024-03-02 23:45:22,252 INFO     Training average positive_sample_loss at step 65900: 0.112552\n",
      "2024-03-02 23:45:22,252 INFO     Training average negative_sample_loss at step 65900: 0.084441\n",
      "2024-03-02 23:45:22,252 INFO     Training average loss at step 65900: 0.098496\n",
      "2024-03-02 23:45:45,392 INFO     Training average positive_sample_loss at step 66000: 0.113283\n",
      "2024-03-02 23:45:45,393 INFO     Training average negative_sample_loss at step 66000: 0.084139\n",
      "2024-03-02 23:45:45,393 INFO     Training average loss at step 66000: 0.098711\n",
      "2024-03-02 23:46:13,867 INFO     Training average positive_sample_loss at step 66100: 0.112661\n",
      "2024-03-02 23:46:13,868 INFO     Training average negative_sample_loss at step 66100: 0.084099\n",
      "2024-03-02 23:46:13,868 INFO     Training average loss at step 66100: 0.098380\n",
      "2024-03-02 23:46:36,960 INFO     Training average positive_sample_loss at step 66200: 0.113293\n",
      "2024-03-02 23:46:36,961 INFO     Training average negative_sample_loss at step 66200: 0.084934\n",
      "2024-03-02 23:46:36,961 INFO     Training average loss at step 66200: 0.099113\n",
      "2024-03-02 23:47:00,267 INFO     Training average positive_sample_loss at step 66300: 0.113392\n",
      "2024-03-02 23:47:00,268 INFO     Training average negative_sample_loss at step 66300: 0.084286\n",
      "2024-03-02 23:47:00,268 INFO     Training average loss at step 66300: 0.098839\n",
      "2024-03-02 23:47:27,987 INFO     Training average positive_sample_loss at step 66400: 0.112501\n",
      "2024-03-02 23:47:27,988 INFO     Training average negative_sample_loss at step 66400: 0.085130\n",
      "2024-03-02 23:47:27,988 INFO     Training average loss at step 66400: 0.098815\n",
      "2024-03-02 23:47:51,522 INFO     Training average positive_sample_loss at step 66500: 0.113481\n",
      "2024-03-02 23:47:51,522 INFO     Training average negative_sample_loss at step 66500: 0.084071\n",
      "2024-03-02 23:47:51,522 INFO     Training average loss at step 66500: 0.098776\n",
      "2024-03-02 23:48:18,156 INFO     Training average positive_sample_loss at step 66600: 0.112722\n",
      "2024-03-02 23:48:18,156 INFO     Training average negative_sample_loss at step 66600: 0.084506\n",
      "2024-03-02 23:48:18,157 INFO     Training average loss at step 66600: 0.098614\n",
      "2024-03-02 23:48:41,561 INFO     Training average positive_sample_loss at step 66700: 0.112718\n",
      "2024-03-02 23:48:41,561 INFO     Training average negative_sample_loss at step 66700: 0.084364\n",
      "2024-03-02 23:48:41,561 INFO     Training average loss at step 66700: 0.098541\n",
      "2024-03-02 23:49:05,109 INFO     Training average positive_sample_loss at step 66800: 0.113747\n",
      "2024-03-02 23:49:05,109 INFO     Training average negative_sample_loss at step 66800: 0.084854\n",
      "2024-03-02 23:49:05,109 INFO     Training average loss at step 66800: 0.099301\n",
      "2024-03-02 23:49:31,761 INFO     Training average positive_sample_loss at step 66900: 0.112706\n",
      "2024-03-02 23:49:31,762 INFO     Training average negative_sample_loss at step 66900: 0.084739\n",
      "2024-03-02 23:49:31,762 INFO     Training average loss at step 66900: 0.098723\n",
      "2024-03-02 23:49:55,223 INFO     Training average positive_sample_loss at step 67000: 0.112409\n",
      "2024-03-02 23:49:55,224 INFO     Training average negative_sample_loss at step 67000: 0.083745\n",
      "2024-03-02 23:49:55,224 INFO     Training average loss at step 67000: 0.098077\n",
      "2024-03-02 23:50:21,862 INFO     Training average positive_sample_loss at step 67100: 0.113583\n",
      "2024-03-02 23:50:21,862 INFO     Training average negative_sample_loss at step 67100: 0.084431\n",
      "2024-03-02 23:50:21,862 INFO     Training average loss at step 67100: 0.099007\n",
      "2024-03-02 23:50:46,329 INFO     Training average positive_sample_loss at step 67200: 0.112821\n",
      "2024-03-02 23:50:46,330 INFO     Training average negative_sample_loss at step 67200: 0.084752\n",
      "2024-03-02 23:50:46,330 INFO     Training average loss at step 67200: 0.098787\n",
      "2024-03-02 23:51:10,054 INFO     Training average positive_sample_loss at step 67300: 0.113387\n",
      "2024-03-02 23:51:10,054 INFO     Training average negative_sample_loss at step 67300: 0.084259\n",
      "2024-03-02 23:51:10,055 INFO     Training average loss at step 67300: 0.098823\n",
      "2024-03-02 23:51:39,147 INFO     Training average positive_sample_loss at step 67400: 0.112686\n",
      "2024-03-02 23:51:39,147 INFO     Training average negative_sample_loss at step 67400: 0.085216\n",
      "2024-03-02 23:51:39,148 INFO     Training average loss at step 67400: 0.098951\n",
      "2024-03-02 23:52:02,271 INFO     Training average positive_sample_loss at step 67500: 0.113143\n",
      "2024-03-02 23:52:02,271 INFO     Training average negative_sample_loss at step 67500: 0.083785\n",
      "2024-03-02 23:52:02,271 INFO     Training average loss at step 67500: 0.098464\n",
      "2024-03-02 23:52:28,386 INFO     Training average positive_sample_loss at step 67600: 0.113387\n",
      "2024-03-02 23:52:28,387 INFO     Training average negative_sample_loss at step 67600: 0.084197\n",
      "2024-03-02 23:52:28,387 INFO     Training average loss at step 67600: 0.098792\n",
      "2024-03-02 23:52:51,508 INFO     Training average positive_sample_loss at step 67700: 0.112496\n",
      "2024-03-02 23:52:51,509 INFO     Training average negative_sample_loss at step 67700: 0.084198\n",
      "2024-03-02 23:52:51,509 INFO     Training average loss at step 67700: 0.098347\n",
      "2024-03-02 23:53:15,142 INFO     Training average positive_sample_loss at step 67800: 0.113148\n",
      "2024-03-02 23:53:15,143 INFO     Training average negative_sample_loss at step 67800: 0.083843\n",
      "2024-03-02 23:53:15,143 INFO     Training average loss at step 67800: 0.098496\n",
      "2024-03-02 23:53:41,569 INFO     Training average positive_sample_loss at step 67900: 0.112796\n",
      "2024-03-02 23:53:41,569 INFO     Training average negative_sample_loss at step 67900: 0.084760\n",
      "2024-03-02 23:53:41,569 INFO     Training average loss at step 67900: 0.098778\n",
      "2024-03-02 23:54:04,992 INFO     Training average positive_sample_loss at step 68000: 0.112730\n",
      "2024-03-02 23:54:04,992 INFO     Training average negative_sample_loss at step 68000: 0.084645\n",
      "2024-03-02 23:54:04,992 INFO     Training average loss at step 68000: 0.098687\n",
      "2024-03-02 23:54:28,025 INFO     Training average positive_sample_loss at step 68100: 0.113928\n",
      "2024-03-02 23:54:28,026 INFO     Training average negative_sample_loss at step 68100: 0.084945\n",
      "2024-03-02 23:54:28,026 INFO     Training average loss at step 68100: 0.099437\n",
      "2024-03-02 23:54:54,447 INFO     Training average positive_sample_loss at step 68200: 0.112653\n",
      "2024-03-02 23:54:54,448 INFO     Training average negative_sample_loss at step 68200: 0.084867\n",
      "2024-03-02 23:54:54,448 INFO     Training average loss at step 68200: 0.098760\n",
      "2024-03-02 23:55:17,610 INFO     Training average positive_sample_loss at step 68300: 0.112780\n",
      "2024-03-02 23:55:17,611 INFO     Training average negative_sample_loss at step 68300: 0.084258\n",
      "2024-03-02 23:55:17,611 INFO     Training average loss at step 68300: 0.098519\n",
      "2024-03-02 23:55:44,295 INFO     Training average positive_sample_loss at step 68400: 0.113552\n",
      "2024-03-02 23:55:44,295 INFO     Training average negative_sample_loss at step 68400: 0.084223\n",
      "2024-03-02 23:55:44,295 INFO     Training average loss at step 68400: 0.098888\n",
      "2024-03-02 23:56:08,257 INFO     Training average positive_sample_loss at step 68500: 0.112044\n",
      "2024-03-02 23:56:08,257 INFO     Training average negative_sample_loss at step 68500: 0.084520\n",
      "2024-03-02 23:56:08,257 INFO     Training average loss at step 68500: 0.098282\n",
      "2024-03-02 23:56:32,567 INFO     Training average positive_sample_loss at step 68600: 0.113893\n",
      "2024-03-02 23:56:32,567 INFO     Training average negative_sample_loss at step 68600: 0.084782\n",
      "2024-03-02 23:56:32,567 INFO     Training average loss at step 68600: 0.099337\n",
      "2024-03-02 23:57:01,119 INFO     Training average positive_sample_loss at step 68700: 0.112357\n",
      "2024-03-02 23:57:01,120 INFO     Training average negative_sample_loss at step 68700: 0.084601\n",
      "2024-03-02 23:57:01,120 INFO     Training average loss at step 68700: 0.098479\n",
      "2024-03-02 23:57:24,724 INFO     Training average positive_sample_loss at step 68800: 0.113103\n",
      "2024-03-02 23:57:24,725 INFO     Training average negative_sample_loss at step 68800: 0.084201\n",
      "2024-03-02 23:57:24,725 INFO     Training average loss at step 68800: 0.098652\n",
      "2024-03-02 23:57:51,853 INFO     Training average positive_sample_loss at step 68900: 0.113554\n",
      "2024-03-02 23:57:51,853 INFO     Training average negative_sample_loss at step 68900: 0.084537\n",
      "2024-03-02 23:57:51,853 INFO     Training average loss at step 68900: 0.099046\n",
      "2024-03-02 23:58:15,487 INFO     Training average positive_sample_loss at step 69000: 0.112378\n",
      "2024-03-02 23:58:15,487 INFO     Training average negative_sample_loss at step 69000: 0.084756\n",
      "2024-03-02 23:58:15,487 INFO     Training average loss at step 69000: 0.098567\n",
      "2024-03-02 23:58:38,865 INFO     Training average positive_sample_loss at step 69100: 0.113270\n",
      "2024-03-02 23:58:38,866 INFO     Training average negative_sample_loss at step 69100: 0.084526\n",
      "2024-03-02 23:58:38,866 INFO     Training average loss at step 69100: 0.098898\n",
      "2024-03-02 23:59:05,851 INFO     Training average positive_sample_loss at step 69200: 0.112635\n",
      "2024-03-02 23:59:05,851 INFO     Training average negative_sample_loss at step 69200: 0.083697\n",
      "2024-03-02 23:59:05,851 INFO     Training average loss at step 69200: 0.098166\n",
      "2024-03-02 23:59:29,795 INFO     Training average positive_sample_loss at step 69300: 0.113120\n",
      "2024-03-02 23:59:29,796 INFO     Training average negative_sample_loss at step 69300: 0.084638\n",
      "2024-03-02 23:59:29,796 INFO     Training average loss at step 69300: 0.098879\n",
      "2024-03-02 23:59:52,805 INFO     Training average positive_sample_loss at step 69400: 0.113604\n",
      "2024-03-02 23:59:52,805 INFO     Training average negative_sample_loss at step 69400: 0.084374\n",
      "2024-03-02 23:59:52,805 INFO     Training average loss at step 69400: 0.098989\n",
      "2024-03-03 00:00:20,010 INFO     Training average positive_sample_loss at step 69500: 0.112369\n",
      "2024-03-03 00:00:20,011 INFO     Training average negative_sample_loss at step 69500: 0.084095\n",
      "2024-03-03 00:00:20,011 INFO     Training average loss at step 69500: 0.098232\n",
      "2024-03-03 00:00:43,767 INFO     Training average positive_sample_loss at step 69600: 0.112957\n",
      "2024-03-03 00:00:43,767 INFO     Training average negative_sample_loss at step 69600: 0.084488\n",
      "2024-03-03 00:00:43,767 INFO     Training average loss at step 69600: 0.098723\n",
      "2024-03-03 00:01:09,953 INFO     Training average positive_sample_loss at step 69700: 0.112857\n",
      "2024-03-03 00:01:09,954 INFO     Training average negative_sample_loss at step 69700: 0.084083\n",
      "2024-03-03 00:01:09,954 INFO     Training average loss at step 69700: 0.098470\n",
      "2024-03-03 00:01:33,931 INFO     Training average positive_sample_loss at step 69800: 0.112843\n",
      "2024-03-03 00:01:33,932 INFO     Training average negative_sample_loss at step 69800: 0.084121\n",
      "2024-03-03 00:01:33,932 INFO     Training average loss at step 69800: 0.098482\n",
      "2024-03-03 00:01:58,172 INFO     Training average positive_sample_loss at step 69900: 0.113349\n",
      "2024-03-03 00:01:58,173 INFO     Training average negative_sample_loss at step 69900: 0.084071\n",
      "2024-03-03 00:01:58,173 INFO     Training average loss at step 69900: 0.098710\n",
      "2024-03-03 00:02:28,440 INFO     Training average positive_sample_loss at step 70000: 0.112427\n",
      "2024-03-03 00:02:28,440 INFO     Training average negative_sample_loss at step 70000: 0.084269\n",
      "2024-03-03 00:02:28,440 INFO     Training average loss at step 70000: 0.098348\n",
      "2024-03-03 00:02:28,440 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-03 00:02:28,987 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-03 00:02:57,472 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-03 00:03:19,141 INFO     Valid MRR at step 70000: 0.644230\n",
      "2024-03-03 00:03:19,142 INFO     Valid MR at step 70000: 237.424586\n",
      "2024-03-03 00:03:19,142 INFO     Valid HITS@1 at step 70000: 0.589433\n",
      "2024-03-03 00:03:19,142 INFO     Valid HITS@3 at step 70000: 0.665973\n",
      "2024-03-03 00:03:19,142 INFO     Valid HITS@10 at step 70000: 0.756020\n",
      "2024-03-03 00:03:38,265 INFO     Training average positive_sample_loss at step 70100: 0.113044\n",
      "2024-03-03 00:03:38,266 INFO     Training average negative_sample_loss at step 70100: 0.083948\n",
      "2024-03-03 00:03:38,266 INFO     Training average loss at step 70100: 0.098496\n",
      "2024-03-03 00:04:06,271 INFO     Training average positive_sample_loss at step 70200: 0.113603\n",
      "2024-03-03 00:04:06,271 INFO     Training average negative_sample_loss at step 70200: 0.084862\n",
      "2024-03-03 00:04:06,271 INFO     Training average loss at step 70200: 0.099232\n",
      "2024-03-03 00:04:29,818 INFO     Training average positive_sample_loss at step 70300: 0.112225\n",
      "2024-03-03 00:04:29,818 INFO     Training average negative_sample_loss at step 70300: 0.084244\n",
      "2024-03-03 00:04:29,818 INFO     Training average loss at step 70300: 0.098235\n",
      "2024-03-03 00:04:53,301 INFO     Training average positive_sample_loss at step 70400: 0.113653\n",
      "2024-03-03 00:04:53,301 INFO     Training average negative_sample_loss at step 70400: 0.084615\n",
      "2024-03-03 00:04:53,301 INFO     Training average loss at step 70400: 0.099134\n",
      "2024-03-03 00:05:20,498 INFO     Training average positive_sample_loss at step 70500: 0.111625\n",
      "2024-03-03 00:05:20,498 INFO     Training average negative_sample_loss at step 70500: 0.084018\n",
      "2024-03-03 00:05:20,498 INFO     Training average loss at step 70500: 0.097821\n",
      "2024-03-03 00:05:43,871 INFO     Training average positive_sample_loss at step 70600: 0.113496\n",
      "2024-03-03 00:05:43,872 INFO     Training average negative_sample_loss at step 70600: 0.085437\n",
      "2024-03-03 00:05:43,872 INFO     Training average loss at step 70600: 0.099467\n",
      "2024-03-03 00:06:10,151 INFO     Training average positive_sample_loss at step 70700: 0.113684\n",
      "2024-03-03 00:06:10,151 INFO     Training average negative_sample_loss at step 70700: 0.084988\n",
      "2024-03-03 00:06:10,151 INFO     Training average loss at step 70700: 0.099336\n",
      "2024-03-03 00:06:33,622 INFO     Training average positive_sample_loss at step 70800: 0.112614\n",
      "2024-03-03 00:06:33,623 INFO     Training average negative_sample_loss at step 70800: 0.083893\n",
      "2024-03-03 00:06:33,623 INFO     Training average loss at step 70800: 0.098254\n",
      "2024-03-03 00:06:57,343 INFO     Training average positive_sample_loss at step 70900: 0.112931\n",
      "2024-03-03 00:06:57,343 INFO     Training average negative_sample_loss at step 70900: 0.084407\n",
      "2024-03-03 00:06:57,343 INFO     Training average loss at step 70900: 0.098669\n",
      "2024-03-03 00:07:23,674 INFO     Training average positive_sample_loss at step 71000: 0.113274\n",
      "2024-03-03 00:07:23,675 INFO     Training average negative_sample_loss at step 71000: 0.084873\n",
      "2024-03-03 00:07:23,675 INFO     Training average loss at step 71000: 0.099073\n",
      "2024-03-03 00:07:46,793 INFO     Training average positive_sample_loss at step 71100: 0.112777\n",
      "2024-03-03 00:07:46,793 INFO     Training average negative_sample_loss at step 71100: 0.084048\n",
      "2024-03-03 00:07:46,793 INFO     Training average loss at step 71100: 0.098412\n",
      "2024-03-03 00:08:10,736 INFO     Training average positive_sample_loss at step 71200: 0.113240\n",
      "2024-03-03 00:08:10,736 INFO     Training average negative_sample_loss at step 71200: 0.084194\n",
      "2024-03-03 00:08:10,736 INFO     Training average loss at step 71200: 0.098717\n",
      "2024-03-03 00:08:38,594 INFO     Training average positive_sample_loss at step 71300: 0.112802\n",
      "2024-03-03 00:08:38,594 INFO     Training average negative_sample_loss at step 71300: 0.083717\n",
      "2024-03-03 00:08:38,594 INFO     Training average loss at step 71300: 0.098259\n",
      "2024-03-03 00:09:01,917 INFO     Training average positive_sample_loss at step 71400: 0.113015\n",
      "2024-03-03 00:09:01,917 INFO     Training average negative_sample_loss at step 71400: 0.084620\n",
      "2024-03-03 00:09:01,917 INFO     Training average loss at step 71400: 0.098818\n",
      "2024-03-03 00:09:30,673 INFO     Training average positive_sample_loss at step 71500: 0.112770\n",
      "2024-03-03 00:09:30,673 INFO     Training average negative_sample_loss at step 71500: 0.084926\n",
      "2024-03-03 00:09:30,673 INFO     Training average loss at step 71500: 0.098848\n",
      "2024-03-03 00:09:54,333 INFO     Training average positive_sample_loss at step 71600: 0.112805\n",
      "2024-03-03 00:09:54,334 INFO     Training average negative_sample_loss at step 71600: 0.084463\n",
      "2024-03-03 00:09:54,334 INFO     Training average loss at step 71600: 0.098634\n",
      "2024-03-03 00:10:18,420 INFO     Training average positive_sample_loss at step 71700: 0.113189\n",
      "2024-03-03 00:10:18,421 INFO     Training average negative_sample_loss at step 71700: 0.083475\n",
      "2024-03-03 00:10:18,421 INFO     Training average loss at step 71700: 0.098332\n",
      "2024-03-03 00:10:45,854 INFO     Training average positive_sample_loss at step 71800: 0.112354\n",
      "2024-03-03 00:10:45,854 INFO     Training average negative_sample_loss at step 71800: 0.085224\n",
      "2024-03-03 00:10:45,854 INFO     Training average loss at step 71800: 0.098789\n",
      "2024-03-03 00:11:09,398 INFO     Training average positive_sample_loss at step 71900: 0.113000\n",
      "2024-03-03 00:11:09,398 INFO     Training average negative_sample_loss at step 71900: 0.085106\n",
      "2024-03-03 00:11:09,398 INFO     Training average loss at step 71900: 0.099053\n",
      "2024-03-03 00:11:35,723 INFO     Training average positive_sample_loss at step 72000: 0.113707\n",
      "2024-03-03 00:11:35,724 INFO     Training average negative_sample_loss at step 72000: 0.084162\n",
      "2024-03-03 00:11:35,724 INFO     Training average loss at step 72000: 0.098934\n",
      "2024-03-03 00:11:58,802 INFO     Training average positive_sample_loss at step 72100: 0.112299\n",
      "2024-03-03 00:11:58,803 INFO     Training average negative_sample_loss at step 72100: 0.084460\n",
      "2024-03-03 00:11:58,803 INFO     Training average loss at step 72100: 0.098379\n",
      "2024-03-03 00:12:23,319 INFO     Training average positive_sample_loss at step 72200: 0.113727\n",
      "2024-03-03 00:12:23,320 INFO     Training average negative_sample_loss at step 72200: 0.084079\n",
      "2024-03-03 00:12:23,320 INFO     Training average loss at step 72200: 0.098903\n",
      "2024-03-03 00:12:50,306 INFO     Training average positive_sample_loss at step 72300: 0.112233\n",
      "2024-03-03 00:12:50,306 INFO     Training average negative_sample_loss at step 72300: 0.084299\n",
      "2024-03-03 00:12:50,306 INFO     Training average loss at step 72300: 0.098266\n",
      "2024-03-03 00:13:13,712 INFO     Training average positive_sample_loss at step 72400: 0.113256\n",
      "2024-03-03 00:13:13,713 INFO     Training average negative_sample_loss at step 72400: 0.084289\n",
      "2024-03-03 00:13:13,713 INFO     Training average loss at step 72400: 0.098773\n",
      "2024-03-03 00:13:42,525 INFO     Training average positive_sample_loss at step 72500: 0.113485\n",
      "2024-03-03 00:13:42,526 INFO     Training average negative_sample_loss at step 72500: 0.084964\n",
      "2024-03-03 00:13:42,526 INFO     Training average loss at step 72500: 0.099225\n",
      "2024-03-03 00:14:05,542 INFO     Training average positive_sample_loss at step 72600: 0.112134\n",
      "2024-03-03 00:14:05,543 INFO     Training average negative_sample_loss at step 72600: 0.084245\n",
      "2024-03-03 00:14:05,543 INFO     Training average loss at step 72600: 0.098190\n",
      "2024-03-03 00:14:29,575 INFO     Training average positive_sample_loss at step 72700: 0.113717\n",
      "2024-03-03 00:14:29,575 INFO     Training average negative_sample_loss at step 72700: 0.084021\n",
      "2024-03-03 00:14:29,576 INFO     Training average loss at step 72700: 0.098869\n",
      "2024-03-03 00:14:57,511 INFO     Training average positive_sample_loss at step 72800: 0.112515\n",
      "2024-03-03 00:14:57,511 INFO     Training average negative_sample_loss at step 72800: 0.083650\n",
      "2024-03-03 00:14:57,512 INFO     Training average loss at step 72800: 0.098083\n",
      "2024-03-03 00:15:20,510 INFO     Training average positive_sample_loss at step 72900: 0.112876\n",
      "2024-03-03 00:15:20,510 INFO     Training average negative_sample_loss at step 72900: 0.084695\n",
      "2024-03-03 00:15:20,510 INFO     Training average loss at step 72900: 0.098786\n",
      "2024-03-03 00:15:43,810 INFO     Training average positive_sample_loss at step 73000: 0.113320\n",
      "2024-03-03 00:15:43,811 INFO     Training average negative_sample_loss at step 73000: 0.084653\n",
      "2024-03-03 00:15:43,811 INFO     Training average loss at step 73000: 0.098986\n",
      "2024-03-03 00:16:10,861 INFO     Training average positive_sample_loss at step 73100: 0.113008\n",
      "2024-03-03 00:16:10,861 INFO     Training average negative_sample_loss at step 73100: 0.084797\n",
      "2024-03-03 00:16:10,861 INFO     Training average loss at step 73100: 0.098902\n",
      "2024-03-03 00:16:34,567 INFO     Training average positive_sample_loss at step 73200: 0.112883\n",
      "2024-03-03 00:16:34,567 INFO     Training average negative_sample_loss at step 73200: 0.084700\n",
      "2024-03-03 00:16:34,567 INFO     Training average loss at step 73200: 0.098792\n",
      "2024-03-03 00:17:01,275 INFO     Training average positive_sample_loss at step 73300: 0.112851\n",
      "2024-03-03 00:17:01,275 INFO     Training average negative_sample_loss at step 73300: 0.084585\n",
      "2024-03-03 00:17:01,275 INFO     Training average loss at step 73300: 0.098718\n",
      "2024-03-03 00:17:25,238 INFO     Training average positive_sample_loss at step 73400: 0.112200\n",
      "2024-03-03 00:17:25,238 INFO     Training average negative_sample_loss at step 73400: 0.084495\n",
      "2024-03-03 00:17:25,239 INFO     Training average loss at step 73400: 0.098348\n",
      "2024-03-03 00:17:49,125 INFO     Training average positive_sample_loss at step 73500: 0.113783\n",
      "2024-03-03 00:17:49,126 INFO     Training average negative_sample_loss at step 73500: 0.083845\n",
      "2024-03-03 00:17:49,126 INFO     Training average loss at step 73500: 0.098814\n",
      "2024-03-03 00:18:16,036 INFO     Training average positive_sample_loss at step 73600: 0.112579\n",
      "2024-03-03 00:18:16,037 INFO     Training average negative_sample_loss at step 73600: 0.085403\n",
      "2024-03-03 00:18:16,037 INFO     Training average loss at step 73600: 0.098991\n",
      "2024-03-03 00:18:39,892 INFO     Training average positive_sample_loss at step 73700: 0.113181\n",
      "2024-03-03 00:18:39,892 INFO     Training average negative_sample_loss at step 73700: 0.084170\n",
      "2024-03-03 00:18:39,892 INFO     Training average loss at step 73700: 0.098676\n",
      "2024-03-03 00:19:08,716 INFO     Training average positive_sample_loss at step 73800: 0.113222\n",
      "2024-03-03 00:19:08,717 INFO     Training average negative_sample_loss at step 73800: 0.084156\n",
      "2024-03-03 00:19:08,717 INFO     Training average loss at step 73800: 0.098689\n",
      "2024-03-03 00:19:32,108 INFO     Training average positive_sample_loss at step 73900: 0.112519\n",
      "2024-03-03 00:19:32,109 INFO     Training average negative_sample_loss at step 73900: 0.083779\n",
      "2024-03-03 00:19:32,109 INFO     Training average loss at step 73900: 0.098149\n",
      "2024-03-03 00:19:55,087 INFO     Training average positive_sample_loss at step 74000: 0.113547\n",
      "2024-03-03 00:19:55,087 INFO     Training average negative_sample_loss at step 74000: 0.085049\n",
      "2024-03-03 00:19:55,087 INFO     Training average loss at step 74000: 0.099298\n",
      "2024-03-03 00:20:23,254 INFO     Training average positive_sample_loss at step 74100: 0.112726\n",
      "2024-03-03 00:20:23,254 INFO     Training average negative_sample_loss at step 74100: 0.084827\n",
      "2024-03-03 00:20:23,254 INFO     Training average loss at step 74100: 0.098776\n",
      "2024-03-03 00:20:46,902 INFO     Training average positive_sample_loss at step 74200: 0.113245\n",
      "2024-03-03 00:20:46,902 INFO     Training average negative_sample_loss at step 74200: 0.083646\n",
      "2024-03-03 00:20:46,902 INFO     Training average loss at step 74200: 0.098446\n",
      "2024-03-03 00:21:10,651 INFO     Training average positive_sample_loss at step 74300: 0.112994\n",
      "2024-03-03 00:21:10,651 INFO     Training average negative_sample_loss at step 74300: 0.084698\n",
      "2024-03-03 00:21:10,651 INFO     Training average loss at step 74300: 0.098846\n",
      "2024-03-03 00:21:37,371 INFO     Training average positive_sample_loss at step 74400: 0.112582\n",
      "2024-03-03 00:21:37,372 INFO     Training average negative_sample_loss at step 74400: 0.084519\n",
      "2024-03-03 00:21:37,372 INFO     Training average loss at step 74400: 0.098551\n",
      "2024-03-03 00:22:00,496 INFO     Training average positive_sample_loss at step 74500: 0.112960\n",
      "2024-03-03 00:22:00,496 INFO     Training average negative_sample_loss at step 74500: 0.084366\n",
      "2024-03-03 00:22:00,496 INFO     Training average loss at step 74500: 0.098663\n",
      "2024-03-03 00:22:27,525 INFO     Training average positive_sample_loss at step 74600: 0.112648\n",
      "2024-03-03 00:22:27,525 INFO     Training average negative_sample_loss at step 74600: 0.084150\n",
      "2024-03-03 00:22:27,525 INFO     Training average loss at step 74600: 0.098399\n",
      "2024-03-03 00:22:51,484 INFO     Training average positive_sample_loss at step 74700: 0.112242\n",
      "2024-03-03 00:22:51,485 INFO     Training average negative_sample_loss at step 74700: 0.083943\n",
      "2024-03-03 00:22:51,485 INFO     Training average loss at step 74700: 0.098093\n",
      "2024-03-03 00:23:14,852 INFO     Training average positive_sample_loss at step 74800: 0.113853\n",
      "2024-03-03 00:23:14,852 INFO     Training average negative_sample_loss at step 74800: 0.084461\n",
      "2024-03-03 00:23:14,852 INFO     Training average loss at step 74800: 0.099157\n",
      "2024-03-03 00:23:42,066 INFO     Training average positive_sample_loss at step 74900: 0.112594\n",
      "2024-03-03 00:23:42,067 INFO     Training average negative_sample_loss at step 74900: 0.084481\n",
      "2024-03-03 00:23:42,067 INFO     Training average loss at step 74900: 0.098537\n",
      "2024-03-03 00:24:05,541 INFO     Training average positive_sample_loss at step 75000: 0.113091\n",
      "2024-03-03 00:24:05,542 INFO     Training average negative_sample_loss at step 75000: 0.084874\n",
      "2024-03-03 00:24:05,542 INFO     Training average loss at step 75000: 0.098983\n",
      "2024-03-03 00:24:34,276 INFO     Training average positive_sample_loss at step 75100: 0.112942\n",
      "2024-03-03 00:24:34,277 INFO     Training average negative_sample_loss at step 75100: 0.084176\n",
      "2024-03-03 00:24:34,277 INFO     Training average loss at step 75100: 0.098559\n",
      "2024-03-03 00:24:57,533 INFO     Training average positive_sample_loss at step 75200: 0.112466\n",
      "2024-03-03 00:24:57,533 INFO     Training average negative_sample_loss at step 75200: 0.085105\n",
      "2024-03-03 00:24:57,534 INFO     Training average loss at step 75200: 0.098786\n",
      "2024-03-03 00:25:21,291 INFO     Training average positive_sample_loss at step 75300: 0.113335\n",
      "2024-03-03 00:25:21,291 INFO     Training average negative_sample_loss at step 75300: 0.084334\n",
      "2024-03-03 00:25:21,291 INFO     Training average loss at step 75300: 0.098835\n",
      "2024-03-03 00:25:48,260 INFO     Training average positive_sample_loss at step 75400: 0.113226\n",
      "2024-03-03 00:25:48,260 INFO     Training average negative_sample_loss at step 75400: 0.084627\n",
      "2024-03-03 00:25:48,260 INFO     Training average loss at step 75400: 0.098926\n",
      "2024-03-03 00:26:11,707 INFO     Training average positive_sample_loss at step 75500: 0.112619\n",
      "2024-03-03 00:26:11,708 INFO     Training average negative_sample_loss at step 75500: 0.083875\n",
      "2024-03-03 00:26:11,708 INFO     Training average loss at step 75500: 0.098247\n",
      "2024-03-03 00:26:38,916 INFO     Training average positive_sample_loss at step 75600: 0.113188\n",
      "2024-03-03 00:26:38,917 INFO     Training average negative_sample_loss at step 75600: 0.084343\n",
      "2024-03-03 00:26:38,917 INFO     Training average loss at step 75600: 0.098766\n",
      "2024-03-03 00:27:02,460 INFO     Training average positive_sample_loss at step 75700: 0.112315\n",
      "2024-03-03 00:27:02,460 INFO     Training average negative_sample_loss at step 75700: 0.083884\n",
      "2024-03-03 00:27:02,460 INFO     Training average loss at step 75700: 0.098099\n",
      "2024-03-03 00:27:26,421 INFO     Training average positive_sample_loss at step 75800: 0.113292\n",
      "2024-03-03 00:27:26,422 INFO     Training average negative_sample_loss at step 75800: 0.083505\n",
      "2024-03-03 00:27:26,422 INFO     Training average loss at step 75800: 0.098399\n",
      "2024-03-03 00:27:53,620 INFO     Training average positive_sample_loss at step 75900: 0.112351\n",
      "2024-03-03 00:27:53,620 INFO     Training average negative_sample_loss at step 75900: 0.083980\n",
      "2024-03-03 00:27:53,620 INFO     Training average loss at step 75900: 0.098165\n",
      "2024-03-03 00:28:16,941 INFO     Training average positive_sample_loss at step 76000: 0.112410\n",
      "2024-03-03 00:28:16,941 INFO     Training average negative_sample_loss at step 76000: 0.083935\n",
      "2024-03-03 00:28:16,941 INFO     Training average loss at step 76000: 0.098172\n",
      "2024-03-03 00:28:40,803 INFO     Training average positive_sample_loss at step 76100: 0.113747\n",
      "2024-03-03 00:28:40,804 INFO     Training average negative_sample_loss at step 76100: 0.085331\n",
      "2024-03-03 00:28:40,804 INFO     Training average loss at step 76100: 0.099539\n",
      "2024-03-03 00:29:06,983 INFO     Training average positive_sample_loss at step 76200: 0.112649\n",
      "2024-03-03 00:29:06,984 INFO     Training average negative_sample_loss at step 76200: 0.083550\n",
      "2024-03-03 00:29:06,984 INFO     Training average loss at step 76200: 0.098100\n",
      "2024-03-03 00:29:30,469 INFO     Training average positive_sample_loss at step 76300: 0.112805\n",
      "2024-03-03 00:29:30,469 INFO     Training average negative_sample_loss at step 76300: 0.085100\n",
      "2024-03-03 00:29:30,469 INFO     Training average loss at step 76300: 0.098952\n",
      "2024-03-03 00:29:59,153 INFO     Training average positive_sample_loss at step 76400: 0.113137\n",
      "2024-03-03 00:29:59,154 INFO     Training average negative_sample_loss at step 76400: 0.083706\n",
      "2024-03-03 00:29:59,154 INFO     Training average loss at step 76400: 0.098422\n",
      "2024-03-03 00:30:23,146 INFO     Training average positive_sample_loss at step 76500: 0.112811\n",
      "2024-03-03 00:30:23,146 INFO     Training average negative_sample_loss at step 76500: 0.084578\n",
      "2024-03-03 00:30:23,146 INFO     Training average loss at step 76500: 0.098694\n",
      "2024-03-03 00:30:47,251 INFO     Training average positive_sample_loss at step 76600: 0.113100\n",
      "2024-03-03 00:30:47,252 INFO     Training average negative_sample_loss at step 76600: 0.084425\n",
      "2024-03-03 00:30:47,252 INFO     Training average loss at step 76600: 0.098762\n",
      "2024-03-03 00:31:14,322 INFO     Training average positive_sample_loss at step 76700: 0.112174\n",
      "2024-03-03 00:31:14,323 INFO     Training average negative_sample_loss at step 76700: 0.083491\n",
      "2024-03-03 00:31:14,323 INFO     Training average loss at step 76700: 0.097832\n",
      "2024-03-03 00:31:38,218 INFO     Training average positive_sample_loss at step 76800: 0.113207\n",
      "2024-03-03 00:31:38,218 INFO     Training average negative_sample_loss at step 76800: 0.084658\n",
      "2024-03-03 00:31:38,218 INFO     Training average loss at step 76800: 0.098932\n",
      "2024-03-03 00:32:04,668 INFO     Training average positive_sample_loss at step 76900: 0.113051\n",
      "2024-03-03 00:32:04,669 INFO     Training average negative_sample_loss at step 76900: 0.084598\n",
      "2024-03-03 00:32:04,669 INFO     Training average loss at step 76900: 0.098824\n",
      "2024-03-03 00:32:28,454 INFO     Training average positive_sample_loss at step 77000: 0.112681\n",
      "2024-03-03 00:32:28,454 INFO     Training average negative_sample_loss at step 77000: 0.084582\n",
      "2024-03-03 00:32:28,454 INFO     Training average loss at step 77000: 0.098631\n",
      "2024-03-03 00:32:51,614 INFO     Training average positive_sample_loss at step 77100: 0.113104\n",
      "2024-03-03 00:32:51,615 INFO     Training average negative_sample_loss at step 77100: 0.084094\n",
      "2024-03-03 00:32:51,615 INFO     Training average loss at step 77100: 0.098599\n",
      "2024-03-03 00:33:18,293 INFO     Training average positive_sample_loss at step 77200: 0.112920\n",
      "2024-03-03 00:33:18,293 INFO     Training average negative_sample_loss at step 77200: 0.084929\n",
      "2024-03-03 00:33:18,293 INFO     Training average loss at step 77200: 0.098924\n",
      "2024-03-03 00:33:41,773 INFO     Training average positive_sample_loss at step 77300: 0.113165\n",
      "2024-03-03 00:33:41,774 INFO     Training average negative_sample_loss at step 77300: 0.085331\n",
      "2024-03-03 00:33:41,774 INFO     Training average loss at step 77300: 0.099248\n",
      "2024-03-03 00:34:07,823 INFO     Training average positive_sample_loss at step 77400: 0.113008\n",
      "2024-03-03 00:34:07,824 INFO     Training average negative_sample_loss at step 77400: 0.084073\n",
      "2024-03-03 00:34:07,824 INFO     Training average loss at step 77400: 0.098541\n",
      "2024-03-03 00:34:32,302 INFO     Training average positive_sample_loss at step 77500: 0.112285\n",
      "2024-03-03 00:34:32,302 INFO     Training average negative_sample_loss at step 77500: 0.084909\n",
      "2024-03-03 00:34:32,302 INFO     Training average loss at step 77500: 0.098597\n",
      "2024-03-03 00:34:55,202 INFO     Training average positive_sample_loss at step 77600: 0.113270\n",
      "2024-03-03 00:34:55,202 INFO     Training average negative_sample_loss at step 77600: 0.083753\n",
      "2024-03-03 00:34:55,202 INFO     Training average loss at step 77600: 0.098512\n",
      "2024-03-03 00:35:23,321 INFO     Training average positive_sample_loss at step 77700: 0.112758\n",
      "2024-03-03 00:35:23,322 INFO     Training average negative_sample_loss at step 77700: 0.083894\n",
      "2024-03-03 00:35:23,322 INFO     Training average loss at step 77700: 0.098326\n",
      "2024-03-03 00:35:46,098 INFO     Training average positive_sample_loss at step 77800: 0.112611\n",
      "2024-03-03 00:35:46,099 INFO     Training average negative_sample_loss at step 77800: 0.084178\n",
      "2024-03-03 00:35:46,099 INFO     Training average loss at step 77800: 0.098395\n",
      "2024-03-03 00:36:09,067 INFO     Training average positive_sample_loss at step 77900: 0.113610\n",
      "2024-03-03 00:36:09,067 INFO     Training average negative_sample_loss at step 77900: 0.084533\n",
      "2024-03-03 00:36:09,067 INFO     Training average loss at step 77900: 0.099071\n",
      "2024-03-03 00:36:35,863 INFO     Training average positive_sample_loss at step 78000: 0.112234\n",
      "2024-03-03 00:36:35,863 INFO     Training average negative_sample_loss at step 78000: 0.084789\n",
      "2024-03-03 00:36:35,863 INFO     Training average loss at step 78000: 0.098511\n",
      "2024-03-03 00:36:58,828 INFO     Training average positive_sample_loss at step 78100: 0.113087\n",
      "2024-03-03 00:36:58,829 INFO     Training average negative_sample_loss at step 78100: 0.084171\n",
      "2024-03-03 00:36:58,829 INFO     Training average loss at step 78100: 0.098629\n",
      "2024-03-03 00:37:25,023 INFO     Training average positive_sample_loss at step 78200: 0.113585\n",
      "2024-03-03 00:37:25,024 INFO     Training average negative_sample_loss at step 78200: 0.085201\n",
      "2024-03-03 00:37:25,024 INFO     Training average loss at step 78200: 0.099393\n",
      "2024-03-03 00:37:48,897 INFO     Training average positive_sample_loss at step 78300: 0.112576\n",
      "2024-03-03 00:37:48,898 INFO     Training average negative_sample_loss at step 78300: 0.084618\n",
      "2024-03-03 00:37:48,898 INFO     Training average loss at step 78300: 0.098597\n",
      "2024-03-03 00:38:11,837 INFO     Training average positive_sample_loss at step 78400: 0.113009\n",
      "2024-03-03 00:38:11,838 INFO     Training average negative_sample_loss at step 78400: 0.084750\n",
      "2024-03-03 00:38:11,838 INFO     Training average loss at step 78400: 0.098879\n",
      "2024-03-03 00:38:38,323 INFO     Training average positive_sample_loss at step 78500: 0.112643\n",
      "2024-03-03 00:38:38,323 INFO     Training average negative_sample_loss at step 78500: 0.084692\n",
      "2024-03-03 00:38:38,323 INFO     Training average loss at step 78500: 0.098668\n",
      "2024-03-03 00:39:02,201 INFO     Training average positive_sample_loss at step 78600: 0.112763\n",
      "2024-03-03 00:39:02,202 INFO     Training average negative_sample_loss at step 78600: 0.085050\n",
      "2024-03-03 00:39:02,202 INFO     Training average loss at step 78600: 0.098907\n",
      "2024-03-03 00:39:28,844 INFO     Training average positive_sample_loss at step 78700: 0.113569\n",
      "2024-03-03 00:39:28,844 INFO     Training average negative_sample_loss at step 78700: 0.083764\n",
      "2024-03-03 00:39:28,844 INFO     Training average loss at step 78700: 0.098666\n",
      "2024-03-03 00:39:52,217 INFO     Training average positive_sample_loss at step 78800: 0.112330\n",
      "2024-03-03 00:39:52,217 INFO     Training average negative_sample_loss at step 78800: 0.084513\n",
      "2024-03-03 00:39:52,217 INFO     Training average loss at step 78800: 0.098421\n",
      "2024-03-03 00:40:15,695 INFO     Training average positive_sample_loss at step 78900: 0.113223\n",
      "2024-03-03 00:40:15,695 INFO     Training average negative_sample_loss at step 78900: 0.084579\n",
      "2024-03-03 00:40:15,695 INFO     Training average loss at step 78900: 0.098901\n",
      "2024-03-03 00:40:44,245 INFO     Training average positive_sample_loss at step 79000: 0.113054\n",
      "2024-03-03 00:40:44,246 INFO     Training average negative_sample_loss at step 79000: 0.084196\n",
      "2024-03-03 00:40:44,246 INFO     Training average loss at step 79000: 0.098625\n",
      "2024-03-03 00:41:07,730 INFO     Training average positive_sample_loss at step 79100: 0.112214\n",
      "2024-03-03 00:41:07,730 INFO     Training average negative_sample_loss at step 79100: 0.083587\n",
      "2024-03-03 00:41:07,730 INFO     Training average loss at step 79100: 0.097900\n",
      "2024-03-03 00:41:31,128 INFO     Training average positive_sample_loss at step 79200: 0.114083\n",
      "2024-03-03 00:41:31,129 INFO     Training average negative_sample_loss at step 79200: 0.084414\n",
      "2024-03-03 00:41:31,129 INFO     Training average loss at step 79200: 0.099248\n",
      "2024-03-03 00:41:57,677 INFO     Training average positive_sample_loss at step 79300: 0.112098\n",
      "2024-03-03 00:41:57,678 INFO     Training average negative_sample_loss at step 79300: 0.084588\n",
      "2024-03-03 00:41:57,678 INFO     Training average loss at step 79300: 0.098343\n",
      "2024-03-03 00:42:21,116 INFO     Training average positive_sample_loss at step 79400: 0.113183\n",
      "2024-03-03 00:42:21,117 INFO     Training average negative_sample_loss at step 79400: 0.083715\n",
      "2024-03-03 00:42:21,117 INFO     Training average loss at step 79400: 0.098449\n",
      "2024-03-03 00:42:48,253 INFO     Training average positive_sample_loss at step 79500: 0.112851\n",
      "2024-03-03 00:42:48,253 INFO     Training average negative_sample_loss at step 79500: 0.084827\n",
      "2024-03-03 00:42:48,253 INFO     Training average loss at step 79500: 0.098839\n",
      "2024-03-03 00:43:12,186 INFO     Training average positive_sample_loss at step 79600: 0.112228\n",
      "2024-03-03 00:43:12,187 INFO     Training average negative_sample_loss at step 79600: 0.084879\n",
      "2024-03-03 00:43:12,187 INFO     Training average loss at step 79600: 0.098554\n",
      "2024-03-03 00:43:35,757 INFO     Training average positive_sample_loss at step 79700: 0.113796\n",
      "2024-03-03 00:43:35,757 INFO     Training average negative_sample_loss at step 79700: 0.083998\n",
      "2024-03-03 00:43:35,757 INFO     Training average loss at step 79700: 0.098897\n",
      "2024-03-03 00:44:02,680 INFO     Training average positive_sample_loss at step 79800: 0.112345\n",
      "2024-03-03 00:44:02,681 INFO     Training average negative_sample_loss at step 79800: 0.084333\n",
      "2024-03-03 00:44:02,681 INFO     Training average loss at step 79800: 0.098339\n",
      "2024-03-03 00:44:25,827 INFO     Training average positive_sample_loss at step 79900: 0.113222\n",
      "2024-03-03 00:44:25,827 INFO     Training average negative_sample_loss at step 79900: 0.084147\n",
      "2024-03-03 00:44:25,827 INFO     Training average loss at step 79900: 0.098684\n",
      "2024-03-03 00:44:53,467 INFO     Training average positive_sample_loss at step 80000: 0.113095\n",
      "2024-03-03 00:44:53,467 INFO     Training average negative_sample_loss at step 80000: 0.084424\n",
      "2024-03-03 00:44:53,467 INFO     Training average loss at step 80000: 0.098760\n",
      "2024-03-03 00:44:53,467 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-03 00:44:53,991 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-03 00:45:23,964 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-03 00:45:45,404 INFO     Valid MRR at step 80000: 0.645050\n",
      "2024-03-03 00:45:45,405 INFO     Valid MR at step 80000: 237.562248\n",
      "2024-03-03 00:45:45,405 INFO     Valid HITS@1 at step 80000: 0.591002\n",
      "2024-03-03 00:45:45,405 INFO     Valid HITS@3 at step 80000: 0.664882\n",
      "2024-03-03 00:45:45,405 INFO     Valid HITS@10 at step 80000: 0.756907\n",
      "2024-03-03 00:46:06,256 INFO     Training average positive_sample_loss at step 80100: 0.112904\n",
      "2024-03-03 00:46:06,256 INFO     Training average negative_sample_loss at step 80100: 0.084502\n",
      "2024-03-03 00:46:06,256 INFO     Training average loss at step 80100: 0.098703\n",
      "2024-03-03 00:46:29,480 INFO     Training average positive_sample_loss at step 80200: 0.112722\n",
      "2024-03-03 00:46:29,481 INFO     Training average negative_sample_loss at step 80200: 0.083496\n",
      "2024-03-03 00:46:29,481 INFO     Training average loss at step 80200: 0.098109\n",
      "2024-03-03 00:46:57,798 INFO     Training average positive_sample_loss at step 80300: 0.112424\n",
      "2024-03-03 00:46:57,798 INFO     Training average negative_sample_loss at step 80300: 0.084305\n",
      "2024-03-03 00:46:57,798 INFO     Training average loss at step 80300: 0.098364\n",
      "2024-03-03 00:47:20,918 INFO     Training average positive_sample_loss at step 80400: 0.112698\n",
      "2024-03-03 00:47:20,919 INFO     Training average negative_sample_loss at step 80400: 0.084278\n",
      "2024-03-03 00:47:20,919 INFO     Training average loss at step 80400: 0.098488\n",
      "2024-03-03 00:47:47,317 INFO     Training average positive_sample_loss at step 80500: 0.113649\n",
      "2024-03-03 00:47:47,317 INFO     Training average negative_sample_loss at step 80500: 0.084584\n",
      "2024-03-03 00:47:47,317 INFO     Training average loss at step 80500: 0.099117\n",
      "2024-03-03 00:48:10,489 INFO     Training average positive_sample_loss at step 80600: 0.112250\n",
      "2024-03-03 00:48:10,489 INFO     Training average negative_sample_loss at step 80600: 0.084076\n",
      "2024-03-03 00:48:10,489 INFO     Training average loss at step 80600: 0.098163\n",
      "2024-03-03 00:48:33,734 INFO     Training average positive_sample_loss at step 80700: 0.113669\n",
      "2024-03-03 00:48:33,735 INFO     Training average negative_sample_loss at step 80700: 0.084391\n",
      "2024-03-03 00:48:33,735 INFO     Training average loss at step 80700: 0.099030\n",
      "2024-03-03 00:49:01,326 INFO     Training average positive_sample_loss at step 80800: 0.111998\n",
      "2024-03-03 00:49:01,326 INFO     Training average negative_sample_loss at step 80800: 0.084316\n",
      "2024-03-03 00:49:01,326 INFO     Training average loss at step 80800: 0.098157\n",
      "2024-03-03 00:49:24,146 INFO     Training average positive_sample_loss at step 80900: 0.112978\n",
      "2024-03-03 00:49:24,147 INFO     Training average negative_sample_loss at step 80900: 0.084484\n",
      "2024-03-03 00:49:24,147 INFO     Training average loss at step 80900: 0.098731\n",
      "2024-03-03 00:49:47,133 INFO     Training average positive_sample_loss at step 81000: 0.113424\n",
      "2024-03-03 00:49:47,134 INFO     Training average negative_sample_loss at step 81000: 0.084537\n",
      "2024-03-03 00:49:47,134 INFO     Training average loss at step 81000: 0.098981\n",
      "2024-03-03 00:50:14,369 INFO     Training average positive_sample_loss at step 81100: 0.112069\n",
      "2024-03-03 00:50:14,370 INFO     Training average negative_sample_loss at step 81100: 0.083793\n",
      "2024-03-03 00:50:14,370 INFO     Training average loss at step 81100: 0.097931\n",
      "2024-03-03 00:50:37,682 INFO     Training average positive_sample_loss at step 81200: 0.113142\n",
      "2024-03-03 00:50:37,682 INFO     Training average negative_sample_loss at step 81200: 0.083871\n",
      "2024-03-03 00:50:37,682 INFO     Training average loss at step 81200: 0.098507\n",
      "2024-03-03 00:51:04,245 INFO     Training average positive_sample_loss at step 81300: 0.113008\n",
      "2024-03-03 00:51:04,246 INFO     Training average negative_sample_loss at step 81300: 0.084544\n",
      "2024-03-03 00:51:04,246 INFO     Training average loss at step 81300: 0.098776\n",
      "2024-03-03 00:51:27,687 INFO     Training average positive_sample_loss at step 81400: 0.112376\n",
      "2024-03-03 00:51:27,688 INFO     Training average negative_sample_loss at step 81400: 0.084626\n",
      "2024-03-03 00:51:27,688 INFO     Training average loss at step 81400: 0.098501\n",
      "2024-03-03 00:51:51,285 INFO     Training average positive_sample_loss at step 81500: 0.113623\n",
      "2024-03-03 00:51:51,286 INFO     Training average negative_sample_loss at step 81500: 0.084230\n",
      "2024-03-03 00:51:51,286 INFO     Training average loss at step 81500: 0.098926\n",
      "2024-03-03 00:52:20,224 INFO     Training average positive_sample_loss at step 81600: 0.112065\n",
      "2024-03-03 00:52:20,224 INFO     Training average negative_sample_loss at step 81600: 0.084282\n",
      "2024-03-03 00:52:20,224 INFO     Training average loss at step 81600: 0.098173\n",
      "2024-03-03 00:52:43,316 INFO     Training average positive_sample_loss at step 81700: 0.112996\n",
      "2024-03-03 00:52:43,317 INFO     Training average negative_sample_loss at step 81700: 0.084677\n",
      "2024-03-03 00:52:43,317 INFO     Training average loss at step 81700: 0.098837\n",
      "2024-03-03 00:53:09,690 INFO     Training average positive_sample_loss at step 81800: 0.113415\n",
      "2024-03-03 00:53:09,690 INFO     Training average negative_sample_loss at step 81800: 0.084208\n",
      "2024-03-03 00:53:09,690 INFO     Training average loss at step 81800: 0.098811\n",
      "2024-03-03 00:53:33,624 INFO     Training average positive_sample_loss at step 81900: 0.112641\n",
      "2024-03-03 00:53:33,624 INFO     Training average negative_sample_loss at step 81900: 0.084211\n",
      "2024-03-03 00:53:33,624 INFO     Training average loss at step 81900: 0.098426\n",
      "2024-03-03 00:53:57,291 INFO     Training average positive_sample_loss at step 82000: 0.112990\n",
      "2024-03-03 00:53:57,292 INFO     Training average negative_sample_loss at step 82000: 0.084225\n",
      "2024-03-03 00:53:57,292 INFO     Training average loss at step 82000: 0.098607\n",
      "2024-03-03 00:54:24,064 INFO     Training average positive_sample_loss at step 82100: 0.112787\n",
      "2024-03-03 00:54:24,065 INFO     Training average negative_sample_loss at step 82100: 0.084472\n",
      "2024-03-03 00:54:24,065 INFO     Training average loss at step 82100: 0.098629\n",
      "2024-03-03 00:54:47,291 INFO     Training average positive_sample_loss at step 82200: 0.112565\n",
      "2024-03-03 00:54:47,292 INFO     Training average negative_sample_loss at step 82200: 0.083363\n",
      "2024-03-03 00:54:47,292 INFO     Training average loss at step 82200: 0.097964\n",
      "2024-03-03 00:55:10,495 INFO     Training average positive_sample_loss at step 82300: 0.113513\n",
      "2024-03-03 00:55:10,495 INFO     Training average negative_sample_loss at step 82300: 0.084114\n",
      "2024-03-03 00:55:10,495 INFO     Training average loss at step 82300: 0.098814\n",
      "2024-03-03 00:55:37,519 INFO     Training average positive_sample_loss at step 82400: 0.111904\n",
      "2024-03-03 00:55:37,519 INFO     Training average negative_sample_loss at step 82400: 0.083878\n",
      "2024-03-03 00:55:37,519 INFO     Training average loss at step 82400: 0.097891\n",
      "2024-03-03 00:56:00,843 INFO     Training average positive_sample_loss at step 82500: 0.113507\n",
      "2024-03-03 00:56:00,843 INFO     Training average negative_sample_loss at step 82500: 0.084994\n",
      "2024-03-03 00:56:00,844 INFO     Training average loss at step 82500: 0.099250\n",
      "2024-03-03 00:56:27,047 INFO     Training average positive_sample_loss at step 82600: 0.112649\n",
      "2024-03-03 00:56:27,047 INFO     Training average negative_sample_loss at step 82600: 0.083393\n",
      "2024-03-03 00:56:27,047 INFO     Training average loss at step 82600: 0.098021\n",
      "2024-03-03 00:56:51,493 INFO     Training average positive_sample_loss at step 82700: 0.112118\n",
      "2024-03-03 00:56:51,493 INFO     Training average negative_sample_loss at step 82700: 0.083933\n",
      "2024-03-03 00:56:51,494 INFO     Training average loss at step 82700: 0.098026\n",
      "2024-03-03 00:57:15,024 INFO     Training average positive_sample_loss at step 82800: 0.113954\n",
      "2024-03-03 00:57:15,025 INFO     Training average negative_sample_loss at step 82800: 0.084387\n",
      "2024-03-03 00:57:15,025 INFO     Training average loss at step 82800: 0.099171\n",
      "2024-03-03 00:57:43,223 INFO     Training average positive_sample_loss at step 82900: 0.112128\n",
      "2024-03-03 00:57:43,223 INFO     Training average negative_sample_loss at step 82900: 0.084496\n",
      "2024-03-03 00:57:43,223 INFO     Training average loss at step 82900: 0.098312\n",
      "2024-03-03 00:58:06,940 INFO     Training average positive_sample_loss at step 83000: 0.113072\n",
      "2024-03-03 00:58:06,940 INFO     Training average negative_sample_loss at step 83000: 0.084024\n",
      "2024-03-03 00:58:06,940 INFO     Training average loss at step 83000: 0.098548\n",
      "2024-03-03 00:58:33,402 INFO     Training average positive_sample_loss at step 83100: 0.113009\n",
      "2024-03-03 00:58:33,402 INFO     Training average negative_sample_loss at step 83100: 0.084373\n",
      "2024-03-03 00:58:33,402 INFO     Training average loss at step 83100: 0.098691\n",
      "2024-03-03 00:58:57,276 INFO     Training average positive_sample_loss at step 83200: 0.112305\n",
      "2024-03-03 00:58:57,276 INFO     Training average negative_sample_loss at step 83200: 0.084215\n",
      "2024-03-03 00:58:57,276 INFO     Training average loss at step 83200: 0.098260\n",
      "2024-03-03 00:59:20,654 INFO     Training average positive_sample_loss at step 83300: 0.113621\n",
      "2024-03-03 00:59:20,654 INFO     Training average negative_sample_loss at step 83300: 0.084421\n",
      "2024-03-03 00:59:20,654 INFO     Training average loss at step 83300: 0.099021\n",
      "2024-03-03 00:59:47,198 INFO     Training average positive_sample_loss at step 83400: 0.112548\n",
      "2024-03-03 00:59:47,198 INFO     Training average negative_sample_loss at step 83400: 0.084347\n",
      "2024-03-03 00:59:47,198 INFO     Training average loss at step 83400: 0.098447\n",
      "2024-03-03 01:00:11,231 INFO     Training average positive_sample_loss at step 83500: 0.113119\n",
      "2024-03-03 01:00:11,232 INFO     Training average negative_sample_loss at step 83500: 0.084943\n",
      "2024-03-03 01:00:11,232 INFO     Training average loss at step 83500: 0.099031\n",
      "2024-03-03 01:00:37,269 INFO     Training average positive_sample_loss at step 83600: 0.112872\n",
      "2024-03-03 01:00:37,269 INFO     Training average negative_sample_loss at step 83600: 0.083158\n",
      "2024-03-03 01:00:37,269 INFO     Training average loss at step 83600: 0.098015\n",
      "2024-03-03 01:01:00,886 INFO     Training average positive_sample_loss at step 83700: 0.112290\n",
      "2024-03-03 01:01:00,887 INFO     Training average negative_sample_loss at step 83700: 0.084679\n",
      "2024-03-03 01:01:00,887 INFO     Training average loss at step 83700: 0.098484\n",
      "2024-03-03 01:01:24,426 INFO     Training average positive_sample_loss at step 83800: 0.113194\n",
      "2024-03-03 01:01:24,427 INFO     Training average negative_sample_loss at step 83800: 0.084020\n",
      "2024-03-03 01:01:24,427 INFO     Training average loss at step 83800: 0.098607\n",
      "2024-03-03 01:01:50,764 INFO     Training average positive_sample_loss at step 83900: 0.112727\n",
      "2024-03-03 01:01:50,765 INFO     Training average negative_sample_loss at step 83900: 0.084650\n",
      "2024-03-03 01:01:50,765 INFO     Training average loss at step 83900: 0.098689\n",
      "2024-03-03 01:02:14,150 INFO     Training average positive_sample_loss at step 84000: 0.112651\n",
      "2024-03-03 01:02:14,151 INFO     Training average negative_sample_loss at step 84000: 0.084363\n",
      "2024-03-03 01:02:14,151 INFO     Training average loss at step 84000: 0.098507\n",
      "2024-03-03 01:02:37,124 INFO     Training average positive_sample_loss at step 84100: 0.113352\n",
      "2024-03-03 01:02:37,124 INFO     Training average negative_sample_loss at step 84100: 0.084307\n",
      "2024-03-03 01:02:37,124 INFO     Training average loss at step 84100: 0.098830\n",
      "2024-03-03 01:03:05,236 INFO     Training average positive_sample_loss at step 84200: 0.111574\n",
      "2024-03-03 01:03:05,236 INFO     Training average negative_sample_loss at step 84200: 0.084537\n",
      "2024-03-03 01:03:05,236 INFO     Training average loss at step 84200: 0.098056\n",
      "2024-03-03 01:03:28,736 INFO     Training average positive_sample_loss at step 84300: 0.113084\n",
      "2024-03-03 01:03:28,737 INFO     Training average negative_sample_loss at step 84300: 0.084180\n",
      "2024-03-03 01:03:28,737 INFO     Training average loss at step 84300: 0.098632\n",
      "2024-03-03 01:03:56,799 INFO     Training average positive_sample_loss at step 84400: 0.113982\n",
      "2024-03-03 01:03:56,800 INFO     Training average negative_sample_loss at step 84400: 0.084862\n",
      "2024-03-03 01:03:56,800 INFO     Training average loss at step 84400: 0.099422\n",
      "2024-03-03 01:04:20,648 INFO     Training average positive_sample_loss at step 84500: 0.112371\n",
      "2024-03-03 01:04:20,648 INFO     Training average negative_sample_loss at step 84500: 0.084468\n",
      "2024-03-03 01:04:20,649 INFO     Training average loss at step 84500: 0.098419\n",
      "2024-03-03 01:04:43,625 INFO     Training average positive_sample_loss at step 84600: 0.113155\n",
      "2024-03-03 01:04:43,625 INFO     Training average negative_sample_loss at step 84600: 0.084183\n",
      "2024-03-03 01:04:43,625 INFO     Training average loss at step 84600: 0.098669\n",
      "2024-03-03 01:05:10,334 INFO     Training average positive_sample_loss at step 84700: 0.112581\n",
      "2024-03-03 01:05:10,334 INFO     Training average negative_sample_loss at step 84700: 0.084783\n",
      "2024-03-03 01:05:10,334 INFO     Training average loss at step 84700: 0.098682\n",
      "2024-03-03 01:05:33,828 INFO     Training average positive_sample_loss at step 84800: 0.112774\n",
      "2024-03-03 01:05:33,828 INFO     Training average negative_sample_loss at step 84800: 0.083696\n",
      "2024-03-03 01:05:33,828 INFO     Training average loss at step 84800: 0.098235\n",
      "2024-03-03 01:06:00,331 INFO     Training average positive_sample_loss at step 84900: 0.113211\n",
      "2024-03-03 01:06:00,332 INFO     Training average negative_sample_loss at step 84900: 0.084097\n",
      "2024-03-03 01:06:00,332 INFO     Training average loss at step 84900: 0.098654\n",
      "2024-03-03 01:06:23,873 INFO     Training average positive_sample_loss at step 85000: 0.112363\n",
      "2024-03-03 01:06:23,874 INFO     Training average negative_sample_loss at step 85000: 0.084303\n",
      "2024-03-03 01:06:23,874 INFO     Training average loss at step 85000: 0.098333\n",
      "2024-03-03 01:06:46,971 INFO     Training average positive_sample_loss at step 85100: 0.113216\n",
      "2024-03-03 01:06:46,971 INFO     Training average negative_sample_loss at step 85100: 0.084161\n",
      "2024-03-03 01:06:46,971 INFO     Training average loss at step 85100: 0.098688\n",
      "2024-03-03 01:07:13,446 INFO     Training average positive_sample_loss at step 85200: 0.112638\n",
      "2024-03-03 01:07:13,446 INFO     Training average negative_sample_loss at step 85200: 0.084393\n",
      "2024-03-03 01:07:13,446 INFO     Training average loss at step 85200: 0.098515\n",
      "2024-03-03 01:07:37,289 INFO     Training average positive_sample_loss at step 85300: 0.112307\n",
      "2024-03-03 01:07:37,290 INFO     Training average negative_sample_loss at step 85300: 0.084484\n",
      "2024-03-03 01:07:37,290 INFO     Training average loss at step 85300: 0.098395\n",
      "2024-03-03 01:08:05,384 INFO     Training average positive_sample_loss at step 85400: 0.113933\n",
      "2024-03-03 01:08:05,385 INFO     Training average negative_sample_loss at step 85400: 0.085486\n",
      "2024-03-03 01:08:05,385 INFO     Training average loss at step 85400: 0.099709\n",
      "2024-03-03 01:08:28,560 INFO     Training average positive_sample_loss at step 85500: 0.112577\n",
      "2024-03-03 01:08:28,560 INFO     Training average negative_sample_loss at step 85500: 0.084794\n",
      "2024-03-03 01:08:28,560 INFO     Training average loss at step 85500: 0.098686\n",
      "2024-03-03 01:08:52,221 INFO     Training average positive_sample_loss at step 85600: 0.112481\n",
      "2024-03-03 01:08:52,222 INFO     Training average negative_sample_loss at step 85600: 0.084488\n",
      "2024-03-03 01:08:52,222 INFO     Training average loss at step 85600: 0.098485\n",
      "2024-03-03 01:09:18,815 INFO     Training average positive_sample_loss at step 85700: 0.112808\n",
      "2024-03-03 01:09:18,816 INFO     Training average negative_sample_loss at step 85700: 0.083712\n",
      "2024-03-03 01:09:18,816 INFO     Training average loss at step 85700: 0.098260\n",
      "2024-03-03 01:09:42,392 INFO     Training average positive_sample_loss at step 85800: 0.112454\n",
      "2024-03-03 01:09:42,393 INFO     Training average negative_sample_loss at step 85800: 0.084851\n",
      "2024-03-03 01:09:42,393 INFO     Training average loss at step 85800: 0.098652\n",
      "2024-03-03 01:10:05,647 INFO     Training average positive_sample_loss at step 85900: 0.113943\n",
      "2024-03-03 01:10:05,647 INFO     Training average negative_sample_loss at step 85900: 0.084240\n",
      "2024-03-03 01:10:05,647 INFO     Training average loss at step 85900: 0.099091\n",
      "2024-03-03 01:10:32,545 INFO     Training average positive_sample_loss at step 86000: 0.112815\n",
      "2024-03-03 01:10:32,545 INFO     Training average negative_sample_loss at step 86000: 0.085041\n",
      "2024-03-03 01:10:32,545 INFO     Training average loss at step 86000: 0.098928\n",
      "2024-03-03 01:10:56,355 INFO     Training average positive_sample_loss at step 86100: 0.112448\n",
      "2024-03-03 01:10:56,356 INFO     Training average negative_sample_loss at step 86100: 0.083453\n",
      "2024-03-03 01:10:56,356 INFO     Training average loss at step 86100: 0.097950\n",
      "2024-03-03 01:11:23,046 INFO     Training average positive_sample_loss at step 86200: 0.113162\n",
      "2024-03-03 01:11:23,047 INFO     Training average negative_sample_loss at step 86200: 0.084796\n",
      "2024-03-03 01:11:23,047 INFO     Training average loss at step 86200: 0.098979\n",
      "2024-03-03 01:11:46,321 INFO     Training average positive_sample_loss at step 86300: 0.112608\n",
      "2024-03-03 01:11:46,322 INFO     Training average negative_sample_loss at step 86300: 0.084372\n",
      "2024-03-03 01:11:46,322 INFO     Training average loss at step 86300: 0.098490\n",
      "2024-03-03 01:12:09,289 INFO     Training average positive_sample_loss at step 86400: 0.113269\n",
      "2024-03-03 01:12:09,290 INFO     Training average negative_sample_loss at step 86400: 0.084107\n",
      "2024-03-03 01:12:09,290 INFO     Training average loss at step 86400: 0.098688\n",
      "2024-03-03 01:12:36,262 INFO     Training average positive_sample_loss at step 86500: 0.112308\n",
      "2024-03-03 01:12:36,263 INFO     Training average negative_sample_loss at step 86500: 0.083948\n",
      "2024-03-03 01:12:36,263 INFO     Training average loss at step 86500: 0.098128\n",
      "2024-03-03 01:13:00,005 INFO     Training average positive_sample_loss at step 86600: 0.113044\n",
      "2024-03-03 01:13:00,005 INFO     Training average negative_sample_loss at step 86600: 0.084341\n",
      "2024-03-03 01:13:00,005 INFO     Training average loss at step 86600: 0.098693\n",
      "2024-03-03 01:13:28,233 INFO     Training average positive_sample_loss at step 86700: 0.113129\n",
      "2024-03-03 01:13:28,233 INFO     Training average negative_sample_loss at step 86700: 0.084215\n",
      "2024-03-03 01:13:28,233 INFO     Training average loss at step 86700: 0.098672\n",
      "2024-03-03 01:13:51,930 INFO     Training average positive_sample_loss at step 86800: 0.112384\n",
      "2024-03-03 01:13:51,930 INFO     Training average negative_sample_loss at step 86800: 0.084324\n",
      "2024-03-03 01:13:51,930 INFO     Training average loss at step 86800: 0.098354\n",
      "2024-03-03 01:14:15,303 INFO     Training average positive_sample_loss at step 86900: 0.112970\n",
      "2024-03-03 01:14:15,304 INFO     Training average negative_sample_loss at step 86900: 0.084499\n",
      "2024-03-03 01:14:15,304 INFO     Training average loss at step 86900: 0.098734\n",
      "2024-03-03 01:14:42,100 INFO     Training average positive_sample_loss at step 87000: 0.112730\n",
      "2024-03-03 01:14:42,100 INFO     Training average negative_sample_loss at step 87000: 0.083802\n",
      "2024-03-03 01:14:42,100 INFO     Training average loss at step 87000: 0.098266\n",
      "2024-03-03 01:15:06,143 INFO     Training average positive_sample_loss at step 87100: 0.112770\n",
      "2024-03-03 01:15:06,143 INFO     Training average negative_sample_loss at step 87100: 0.084014\n",
      "2024-03-03 01:15:06,143 INFO     Training average loss at step 87100: 0.098392\n",
      "2024-03-03 01:15:29,554 INFO     Training average positive_sample_loss at step 87200: 0.113415\n",
      "2024-03-03 01:15:29,555 INFO     Training average negative_sample_loss at step 87200: 0.084825\n",
      "2024-03-03 01:15:29,555 INFO     Training average loss at step 87200: 0.099120\n",
      "2024-03-03 01:15:56,235 INFO     Training average positive_sample_loss at step 87300: 0.111830\n",
      "2024-03-03 01:15:56,236 INFO     Training average negative_sample_loss at step 87300: 0.083958\n",
      "2024-03-03 01:15:56,236 INFO     Training average loss at step 87300: 0.097894\n",
      "2024-03-03 01:16:19,352 INFO     Training average positive_sample_loss at step 87400: 0.113426\n",
      "2024-03-03 01:16:19,353 INFO     Training average negative_sample_loss at step 87400: 0.084870\n",
      "2024-03-03 01:16:19,353 INFO     Training average loss at step 87400: 0.099148\n",
      "2024-03-03 01:16:45,725 INFO     Training average positive_sample_loss at step 87500: 0.112711\n",
      "2024-03-03 01:16:45,726 INFO     Training average negative_sample_loss at step 87500: 0.084554\n",
      "2024-03-03 01:16:45,726 INFO     Training average loss at step 87500: 0.098633\n",
      "2024-03-03 01:17:08,830 INFO     Training average positive_sample_loss at step 87600: 0.112714\n",
      "2024-03-03 01:17:08,830 INFO     Training average negative_sample_loss at step 87600: 0.083659\n",
      "2024-03-03 01:17:08,830 INFO     Training average loss at step 87600: 0.098187\n",
      "2024-03-03 01:17:32,978 INFO     Training average positive_sample_loss at step 87700: 0.113411\n",
      "2024-03-03 01:17:32,978 INFO     Training average negative_sample_loss at step 87700: 0.084886\n",
      "2024-03-03 01:17:32,978 INFO     Training average loss at step 87700: 0.099148\n",
      "2024-03-03 01:17:59,468 INFO     Training average positive_sample_loss at step 87800: 0.112560\n",
      "2024-03-03 01:17:59,469 INFO     Training average negative_sample_loss at step 87800: 0.083981\n",
      "2024-03-03 01:17:59,469 INFO     Training average loss at step 87800: 0.098271\n",
      "2024-03-03 01:18:22,627 INFO     Training average positive_sample_loss at step 87900: 0.112856\n",
      "2024-03-03 01:18:22,627 INFO     Training average negative_sample_loss at step 87900: 0.083408\n",
      "2024-03-03 01:18:22,627 INFO     Training average loss at step 87900: 0.098132\n",
      "2024-03-03 01:18:50,943 INFO     Training average positive_sample_loss at step 88000: 0.112632\n",
      "2024-03-03 01:18:50,943 INFO     Training average negative_sample_loss at step 88000: 0.084605\n",
      "2024-03-03 01:18:50,943 INFO     Training average loss at step 88000: 0.098618\n",
      "2024-03-03 01:19:14,426 INFO     Training average positive_sample_loss at step 88100: 0.112587\n",
      "2024-03-03 01:19:14,427 INFO     Training average negative_sample_loss at step 88100: 0.084109\n",
      "2024-03-03 01:19:14,427 INFO     Training average loss at step 88100: 0.098348\n",
      "2024-03-03 01:19:38,031 INFO     Training average positive_sample_loss at step 88200: 0.113620\n",
      "2024-03-03 01:19:38,032 INFO     Training average negative_sample_loss at step 88200: 0.084487\n",
      "2024-03-03 01:19:38,032 INFO     Training average loss at step 88200: 0.099053\n",
      "2024-03-03 01:20:04,681 INFO     Training average positive_sample_loss at step 88300: 0.112312\n",
      "2024-03-03 01:20:04,682 INFO     Training average negative_sample_loss at step 88300: 0.084078\n",
      "2024-03-03 01:20:04,682 INFO     Training average loss at step 88300: 0.098195\n",
      "2024-03-03 01:20:28,352 INFO     Training average positive_sample_loss at step 88400: 0.112592\n",
      "2024-03-03 01:20:28,356 INFO     Training average negative_sample_loss at step 88400: 0.084030\n",
      "2024-03-03 01:20:28,356 INFO     Training average loss at step 88400: 0.098311\n",
      "2024-03-03 01:20:56,285 INFO     Training average positive_sample_loss at step 88500: 0.113469\n",
      "2024-03-03 01:20:56,285 INFO     Training average negative_sample_loss at step 88500: 0.084219\n",
      "2024-03-03 01:20:56,285 INFO     Training average loss at step 88500: 0.098844\n",
      "2024-03-03 01:21:20,085 INFO     Training average positive_sample_loss at step 88600: 0.112487\n",
      "2024-03-03 01:21:20,085 INFO     Training average negative_sample_loss at step 88600: 0.084355\n",
      "2024-03-03 01:21:20,085 INFO     Training average loss at step 88600: 0.098421\n",
      "2024-03-03 01:21:43,559 INFO     Training average positive_sample_loss at step 88700: 0.113127\n",
      "2024-03-03 01:21:43,560 INFO     Training average negative_sample_loss at step 88700: 0.083926\n",
      "2024-03-03 01:21:43,560 INFO     Training average loss at step 88700: 0.098526\n",
      "2024-03-03 01:22:10,099 INFO     Training average positive_sample_loss at step 88800: 0.112452\n",
      "2024-03-03 01:22:10,099 INFO     Training average negative_sample_loss at step 88800: 0.084860\n",
      "2024-03-03 01:22:10,099 INFO     Training average loss at step 88800: 0.098656\n",
      "2024-03-03 01:22:33,254 INFO     Training average positive_sample_loss at step 88900: 0.112123\n",
      "2024-03-03 01:22:33,254 INFO     Training average negative_sample_loss at step 88900: 0.084721\n",
      "2024-03-03 01:22:33,254 INFO     Training average loss at step 88900: 0.098422\n",
      "2024-03-03 01:22:56,616 INFO     Training average positive_sample_loss at step 89000: 0.114273\n",
      "2024-03-03 01:22:56,616 INFO     Training average negative_sample_loss at step 89000: 0.084554\n",
      "2024-03-03 01:22:56,616 INFO     Training average loss at step 89000: 0.099414\n",
      "2024-03-03 01:23:23,788 INFO     Training average positive_sample_loss at step 89100: 0.112757\n",
      "2024-03-03 01:23:23,788 INFO     Training average negative_sample_loss at step 89100: 0.083871\n",
      "2024-03-03 01:23:23,788 INFO     Training average loss at step 89100: 0.098314\n",
      "2024-03-03 01:23:47,701 INFO     Training average positive_sample_loss at step 89200: 0.113008\n",
      "2024-03-03 01:23:47,701 INFO     Training average negative_sample_loss at step 89200: 0.085059\n",
      "2024-03-03 01:23:47,702 INFO     Training average loss at step 89200: 0.099034\n",
      "2024-03-03 01:24:15,618 INFO     Training average positive_sample_loss at step 89300: 0.112192\n",
      "2024-03-03 01:24:15,619 INFO     Training average negative_sample_loss at step 89300: 0.083637\n",
      "2024-03-03 01:24:15,619 INFO     Training average loss at step 89300: 0.097914\n",
      "2024-03-03 01:24:39,445 INFO     Training average positive_sample_loss at step 89400: 0.112748\n",
      "2024-03-03 01:24:39,446 INFO     Training average negative_sample_loss at step 89400: 0.084156\n",
      "2024-03-03 01:24:39,446 INFO     Training average loss at step 89400: 0.098452\n",
      "2024-03-03 01:25:02,907 INFO     Training average positive_sample_loss at step 89500: 0.113255\n",
      "2024-03-03 01:25:02,908 INFO     Training average negative_sample_loss at step 89500: 0.083888\n",
      "2024-03-03 01:25:02,908 INFO     Training average loss at step 89500: 0.098571\n",
      "2024-03-03 01:25:29,960 INFO     Training average positive_sample_loss at step 89600: 0.112619\n",
      "2024-03-03 01:25:29,961 INFO     Training average negative_sample_loss at step 89600: 0.084378\n",
      "2024-03-03 01:25:29,961 INFO     Training average loss at step 89600: 0.098499\n",
      "2024-03-03 01:25:53,727 INFO     Training average positive_sample_loss at step 89700: 0.112659\n",
      "2024-03-03 01:25:53,727 INFO     Training average negative_sample_loss at step 89700: 0.083873\n",
      "2024-03-03 01:25:53,727 INFO     Training average loss at step 89700: 0.098266\n",
      "2024-03-03 01:26:20,273 INFO     Training average positive_sample_loss at step 89800: 0.113093\n",
      "2024-03-03 01:26:20,273 INFO     Training average negative_sample_loss at step 89800: 0.085056\n",
      "2024-03-03 01:26:20,273 INFO     Training average loss at step 89800: 0.099074\n",
      "2024-03-03 01:26:43,853 INFO     Training average positive_sample_loss at step 89900: 0.112922\n",
      "2024-03-03 01:26:43,854 INFO     Training average negative_sample_loss at step 89900: 0.084539\n",
      "2024-03-03 01:26:43,854 INFO     Training average loss at step 89900: 0.098731\n",
      "2024-03-03 01:27:07,929 INFO     Training average positive_sample_loss at step 90000: 0.112814\n",
      "2024-03-03 01:27:07,929 INFO     Training average negative_sample_loss at step 90000: 0.084249\n",
      "2024-03-03 01:27:07,929 INFO     Training average loss at step 90000: 0.098532\n",
      "2024-03-03 01:27:07,929 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-03 01:27:08,427 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-03 01:27:36,438 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-03 01:27:56,143 INFO     Valid MRR at step 90000: 0.641650\n",
      "2024-03-03 01:27:56,144 INFO     Valid MR at step 90000: 237.863872\n",
      "2024-03-03 01:27:56,144 INFO     Valid HITS@1 at step 90000: 0.586125\n",
      "2024-03-03 01:27:56,144 INFO     Valid HITS@3 at step 90000: 0.662358\n",
      "2024-03-03 01:27:56,144 INFO     Valid HITS@10 at step 90000: 0.756839\n",
      "2024-03-03 01:28:20,210 INFO     Training average positive_sample_loss at step 90100: 0.112373\n",
      "2024-03-03 01:28:20,210 INFO     Training average negative_sample_loss at step 90100: 0.084007\n",
      "2024-03-03 01:28:20,211 INFO     Training average loss at step 90100: 0.098190\n",
      "2024-03-03 01:28:44,049 INFO     Training average positive_sample_loss at step 90200: 0.112852\n",
      "2024-03-03 01:28:44,050 INFO     Training average negative_sample_loss at step 90200: 0.084208\n",
      "2024-03-03 01:28:44,050 INFO     Training average loss at step 90200: 0.098530\n",
      "2024-03-03 01:29:10,085 INFO     Training average positive_sample_loss at step 90300: 0.113565\n",
      "2024-03-03 01:29:10,085 INFO     Training average negative_sample_loss at step 90300: 0.084336\n",
      "2024-03-03 01:29:10,085 INFO     Training average loss at step 90300: 0.098951\n",
      "2024-03-03 01:29:36,060 INFO     Training average positive_sample_loss at step 90400: 0.111942\n",
      "2024-03-03 01:29:36,061 INFO     Training average negative_sample_loss at step 90400: 0.083702\n",
      "2024-03-03 01:29:36,061 INFO     Training average loss at step 90400: 0.097822\n",
      "2024-03-03 01:29:59,527 INFO     Training average positive_sample_loss at step 90500: 0.113265\n",
      "2024-03-03 01:29:59,528 INFO     Training average negative_sample_loss at step 90500: 0.083852\n",
      "2024-03-03 01:29:59,528 INFO     Training average loss at step 90500: 0.098558\n",
      "2024-03-03 01:30:27,822 INFO     Training average positive_sample_loss at step 90600: 0.112910\n",
      "2024-03-03 01:30:27,823 INFO     Training average negative_sample_loss at step 90600: 0.084530\n",
      "2024-03-03 01:30:27,823 INFO     Training average loss at step 90600: 0.098720\n",
      "2024-03-03 01:30:51,426 INFO     Training average positive_sample_loss at step 90700: 0.112314\n",
      "2024-03-03 01:30:51,426 INFO     Training average negative_sample_loss at step 90700: 0.083867\n",
      "2024-03-03 01:30:51,427 INFO     Training average loss at step 90700: 0.098090\n",
      "2024-03-03 01:31:14,496 INFO     Training average positive_sample_loss at step 90800: 0.113379\n",
      "2024-03-03 01:31:14,497 INFO     Training average negative_sample_loss at step 90800: 0.085047\n",
      "2024-03-03 01:31:14,497 INFO     Training average loss at step 90800: 0.099213\n",
      "2024-03-03 01:31:41,477 INFO     Training average positive_sample_loss at step 90900: 0.112231\n",
      "2024-03-03 01:31:41,478 INFO     Training average negative_sample_loss at step 90900: 0.083360\n",
      "2024-03-03 01:31:41,478 INFO     Training average loss at step 90900: 0.097796\n",
      "2024-03-03 01:32:05,324 INFO     Training average positive_sample_loss at step 91000: 0.113151\n",
      "2024-03-03 01:32:05,325 INFO     Training average negative_sample_loss at step 91000: 0.085027\n",
      "2024-03-03 01:32:05,325 INFO     Training average loss at step 91000: 0.099089\n",
      "2024-03-03 01:32:32,034 INFO     Training average positive_sample_loss at step 91100: 0.113157\n",
      "2024-03-03 01:32:32,034 INFO     Training average negative_sample_loss at step 91100: 0.083814\n",
      "2024-03-03 01:32:32,034 INFO     Training average loss at step 91100: 0.098485\n",
      "2024-03-03 01:32:55,772 INFO     Training average positive_sample_loss at step 91200: 0.112503\n",
      "2024-03-03 01:32:55,773 INFO     Training average negative_sample_loss at step 91200: 0.084143\n",
      "2024-03-03 01:32:55,773 INFO     Training average loss at step 91200: 0.098323\n",
      "2024-03-03 01:33:19,555 INFO     Training average positive_sample_loss at step 91300: 0.112985\n",
      "2024-03-03 01:33:19,555 INFO     Training average negative_sample_loss at step 91300: 0.084867\n",
      "2024-03-03 01:33:19,555 INFO     Training average loss at step 91300: 0.098926\n",
      "2024-03-03 01:33:47,072 INFO     Training average positive_sample_loss at step 91400: 0.112648\n",
      "2024-03-03 01:33:47,072 INFO     Training average negative_sample_loss at step 91400: 0.083884\n",
      "2024-03-03 01:33:47,072 INFO     Training average loss at step 91400: 0.098266\n",
      "2024-03-03 01:34:10,375 INFO     Training average positive_sample_loss at step 91500: 0.112721\n",
      "2024-03-03 01:34:10,376 INFO     Training average negative_sample_loss at step 91500: 0.084532\n",
      "2024-03-03 01:34:10,376 INFO     Training average loss at step 91500: 0.098627\n",
      "2024-03-03 01:34:37,161 INFO     Training average positive_sample_loss at step 91600: 0.112996\n",
      "2024-03-03 01:34:37,162 INFO     Training average negative_sample_loss at step 91600: 0.083382\n",
      "2024-03-03 01:34:37,162 INFO     Training average loss at step 91600: 0.098189\n",
      "2024-03-03 01:35:01,440 INFO     Training average positive_sample_loss at step 91700: 0.112420\n",
      "2024-03-03 01:35:01,440 INFO     Training average negative_sample_loss at step 91700: 0.084932\n",
      "2024-03-03 01:35:01,440 INFO     Training average loss at step 91700: 0.098676\n",
      "2024-03-03 01:35:25,161 INFO     Training average positive_sample_loss at step 91800: 0.112854\n",
      "2024-03-03 01:35:25,162 INFO     Training average negative_sample_loss at step 91800: 0.083683\n",
      "2024-03-03 01:35:25,162 INFO     Training average loss at step 91800: 0.098268\n",
      "2024-03-03 01:35:53,287 INFO     Training average positive_sample_loss at step 91900: 0.112526\n",
      "2024-03-03 01:35:53,287 INFO     Training average negative_sample_loss at step 91900: 0.084317\n",
      "2024-03-03 01:35:53,287 INFO     Training average loss at step 91900: 0.098421\n",
      "2024-03-03 01:36:16,648 INFO     Training average positive_sample_loss at step 92000: 0.112863\n",
      "2024-03-03 01:36:16,648 INFO     Training average negative_sample_loss at step 92000: 0.084434\n",
      "2024-03-03 01:36:16,648 INFO     Training average loss at step 92000: 0.098649\n",
      "2024-03-03 01:36:40,090 INFO     Training average positive_sample_loss at step 92100: 0.113185\n",
      "2024-03-03 01:36:40,090 INFO     Training average negative_sample_loss at step 92100: 0.083815\n",
      "2024-03-03 01:36:40,090 INFO     Training average loss at step 92100: 0.098500\n",
      "2024-03-03 01:37:07,245 INFO     Training average positive_sample_loss at step 92200: 0.112078\n",
      "2024-03-03 01:37:07,246 INFO     Training average negative_sample_loss at step 92200: 0.084099\n",
      "2024-03-03 01:37:07,246 INFO     Training average loss at step 92200: 0.098089\n",
      "2024-03-03 01:37:31,678 INFO     Training average positive_sample_loss at step 92300: 0.112820\n",
      "2024-03-03 01:37:31,679 INFO     Training average negative_sample_loss at step 92300: 0.084195\n",
      "2024-03-03 01:37:31,679 INFO     Training average loss at step 92300: 0.098508\n",
      "2024-03-03 01:38:00,948 INFO     Training average positive_sample_loss at step 92400: 0.113495\n",
      "2024-03-03 01:38:00,948 INFO     Training average negative_sample_loss at step 92400: 0.084765\n",
      "2024-03-03 01:38:00,948 INFO     Training average loss at step 92400: 0.099130\n",
      "2024-03-03 01:38:24,779 INFO     Training average positive_sample_loss at step 92500: 0.112373\n",
      "2024-03-03 01:38:24,779 INFO     Training average negative_sample_loss at step 92500: 0.084154\n",
      "2024-03-03 01:38:24,779 INFO     Training average loss at step 92500: 0.098263\n",
      "2024-03-03 01:38:48,201 INFO     Training average positive_sample_loss at step 92600: 0.113208\n",
      "2024-03-03 01:38:48,201 INFO     Training average negative_sample_loss at step 92600: 0.083846\n",
      "2024-03-03 01:38:48,201 INFO     Training average loss at step 92600: 0.098527\n",
      "2024-03-03 01:39:15,475 INFO     Training average positive_sample_loss at step 92700: 0.112184\n",
      "2024-03-03 01:39:15,475 INFO     Training average negative_sample_loss at step 92700: 0.085071\n",
      "2024-03-03 01:39:15,475 INFO     Training average loss at step 92700: 0.098627\n",
      "2024-03-03 01:39:39,697 INFO     Training average positive_sample_loss at step 92800: 0.112958\n",
      "2024-03-03 01:39:39,697 INFO     Training average negative_sample_loss at step 92800: 0.084637\n",
      "2024-03-03 01:39:39,697 INFO     Training average loss at step 92800: 0.098798\n",
      "2024-03-03 01:40:06,123 INFO     Training average positive_sample_loss at step 92900: 0.112913\n",
      "2024-03-03 01:40:06,124 INFO     Training average negative_sample_loss at step 92900: 0.083815\n",
      "2024-03-03 01:40:06,124 INFO     Training average loss at step 92900: 0.098364\n",
      "2024-03-03 01:40:29,474 INFO     Training average positive_sample_loss at step 93000: 0.112095\n",
      "2024-03-03 01:40:29,475 INFO     Training average negative_sample_loss at step 93000: 0.084119\n",
      "2024-03-03 01:40:29,475 INFO     Training average loss at step 93000: 0.098107\n",
      "2024-03-03 01:40:52,540 INFO     Training average positive_sample_loss at step 93100: 0.113483\n",
      "2024-03-03 01:40:52,541 INFO     Training average negative_sample_loss at step 93100: 0.083916\n",
      "2024-03-03 01:40:52,541 INFO     Training average loss at step 93100: 0.098699\n",
      "2024-03-03 01:41:21,224 INFO     Training average positive_sample_loss at step 93200: 0.112655\n",
      "2024-03-03 01:41:21,225 INFO     Training average negative_sample_loss at step 93200: 0.084427\n",
      "2024-03-03 01:41:21,225 INFO     Training average loss at step 93200: 0.098541\n",
      "2024-03-03 01:41:44,817 INFO     Training average positive_sample_loss at step 93300: 0.112703\n",
      "2024-03-03 01:41:44,817 INFO     Training average negative_sample_loss at step 93300: 0.084561\n",
      "2024-03-03 01:41:44,817 INFO     Training average loss at step 93300: 0.098632\n",
      "2024-03-03 01:42:13,312 INFO     Training average positive_sample_loss at step 93400: 0.113314\n",
      "2024-03-03 01:42:13,313 INFO     Training average negative_sample_loss at step 93400: 0.084053\n",
      "2024-03-03 01:42:13,313 INFO     Training average loss at step 93400: 0.098683\n",
      "2024-03-03 01:42:37,693 INFO     Training average positive_sample_loss at step 93500: 0.112592\n",
      "2024-03-03 01:42:37,693 INFO     Training average negative_sample_loss at step 93500: 0.083887\n",
      "2024-03-03 01:42:37,693 INFO     Training average loss at step 93500: 0.098239\n",
      "2024-03-03 01:43:01,161 INFO     Training average positive_sample_loss at step 93600: 0.112523\n",
      "2024-03-03 01:43:01,161 INFO     Training average negative_sample_loss at step 93600: 0.084329\n",
      "2024-03-03 01:43:01,162 INFO     Training average loss at step 93600: 0.098426\n",
      "2024-03-03 01:43:27,664 INFO     Training average positive_sample_loss at step 93700: 0.112625\n",
      "2024-03-03 01:43:27,665 INFO     Training average negative_sample_loss at step 93700: 0.084015\n",
      "2024-03-03 01:43:27,665 INFO     Training average loss at step 93700: 0.098320\n",
      "2024-03-03 01:43:51,079 INFO     Training average positive_sample_loss at step 93800: 0.112876\n",
      "2024-03-03 01:43:51,079 INFO     Training average negative_sample_loss at step 93800: 0.085006\n",
      "2024-03-03 01:43:51,079 INFO     Training average loss at step 93800: 0.098941\n",
      "2024-03-03 01:44:14,687 INFO     Training average positive_sample_loss at step 93900: 0.113132\n",
      "2024-03-03 01:44:14,687 INFO     Training average negative_sample_loss at step 93900: 0.083355\n",
      "2024-03-03 01:44:14,687 INFO     Training average loss at step 93900: 0.098244\n",
      "2024-03-03 01:44:41,701 INFO     Training average positive_sample_loss at step 94000: 0.112330\n",
      "2024-03-03 01:44:41,701 INFO     Training average negative_sample_loss at step 94000: 0.084355\n",
      "2024-03-03 01:44:41,701 INFO     Training average loss at step 94000: 0.098343\n",
      "2024-03-03 01:45:05,337 INFO     Training average positive_sample_loss at step 94100: 0.112326\n",
      "2024-03-03 01:45:05,338 INFO     Training average negative_sample_loss at step 94100: 0.083812\n",
      "2024-03-03 01:45:05,338 INFO     Training average loss at step 94100: 0.098069\n",
      "2024-03-03 01:45:32,418 INFO     Training average positive_sample_loss at step 94200: 0.113549\n",
      "2024-03-03 01:45:32,418 INFO     Training average negative_sample_loss at step 94200: 0.084832\n",
      "2024-03-03 01:45:32,418 INFO     Training average loss at step 94200: 0.099191\n",
      "2024-03-03 01:45:56,200 INFO     Training average positive_sample_loss at step 94300: 0.112771\n",
      "2024-03-03 01:45:56,201 INFO     Training average negative_sample_loss at step 94300: 0.084571\n",
      "2024-03-03 01:45:56,201 INFO     Training average loss at step 94300: 0.098671\n",
      "2024-03-03 01:46:19,847 INFO     Training average positive_sample_loss at step 94400: 0.112575\n",
      "2024-03-03 01:46:19,847 INFO     Training average negative_sample_loss at step 94400: 0.084859\n",
      "2024-03-03 01:46:19,847 INFO     Training average loss at step 94400: 0.098717\n",
      "2024-03-03 01:46:48,110 INFO     Training average positive_sample_loss at step 94500: 0.112457\n",
      "2024-03-03 01:46:48,110 INFO     Training average negative_sample_loss at step 94500: 0.084354\n",
      "2024-03-03 01:46:48,110 INFO     Training average loss at step 94500: 0.098405\n",
      "2024-03-03 01:47:11,791 INFO     Training average positive_sample_loss at step 94600: 0.113018\n",
      "2024-03-03 01:47:11,792 INFO     Training average negative_sample_loss at step 94600: 0.084172\n",
      "2024-03-03 01:47:11,792 INFO     Training average loss at step 94600: 0.098595\n",
      "2024-03-03 01:47:38,320 INFO     Training average positive_sample_loss at step 94700: 0.112991\n",
      "2024-03-03 01:47:38,320 INFO     Training average negative_sample_loss at step 94700: 0.084075\n",
      "2024-03-03 01:47:38,320 INFO     Training average loss at step 94700: 0.098533\n",
      "2024-03-03 01:48:02,246 INFO     Training average positive_sample_loss at step 94800: 0.111734\n",
      "2024-03-03 01:48:02,247 INFO     Training average negative_sample_loss at step 94800: 0.084371\n",
      "2024-03-03 01:48:02,247 INFO     Training average loss at step 94800: 0.098053\n",
      "2024-03-03 01:48:26,115 INFO     Training average positive_sample_loss at step 94900: 0.113333\n",
      "2024-03-03 01:48:26,116 INFO     Training average negative_sample_loss at step 94900: 0.084155\n",
      "2024-03-03 01:48:26,116 INFO     Training average loss at step 94900: 0.098744\n",
      "2024-03-03 01:48:52,930 INFO     Training average positive_sample_loss at step 95000: 0.113002\n",
      "2024-03-03 01:48:52,930 INFO     Training average negative_sample_loss at step 95000: 0.085348\n",
      "2024-03-03 01:48:52,930 INFO     Training average loss at step 95000: 0.099175\n",
      "2024-03-03 01:49:16,512 INFO     Training average positive_sample_loss at step 95100: 0.112279\n",
      "2024-03-03 01:49:16,512 INFO     Training average negative_sample_loss at step 95100: 0.083747\n",
      "2024-03-03 01:49:16,512 INFO     Training average loss at step 95100: 0.098013\n",
      "2024-03-03 01:49:40,282 INFO     Training average positive_sample_loss at step 95200: 0.113639\n",
      "2024-03-03 01:49:40,283 INFO     Training average negative_sample_loss at step 95200: 0.084027\n",
      "2024-03-03 01:49:40,283 INFO     Training average loss at step 95200: 0.098833\n",
      "2024-03-03 01:50:06,814 INFO     Training average positive_sample_loss at step 95300: 0.111946\n",
      "2024-03-03 01:50:06,815 INFO     Training average negative_sample_loss at step 95300: 0.083642\n",
      "2024-03-03 01:50:06,815 INFO     Training average loss at step 95300: 0.097794\n",
      "2024-03-03 01:50:30,909 INFO     Training average positive_sample_loss at step 95400: 0.112879\n",
      "2024-03-03 01:50:30,910 INFO     Training average negative_sample_loss at step 95400: 0.084721\n",
      "2024-03-03 01:50:30,910 INFO     Training average loss at step 95400: 0.098800\n",
      "2024-03-03 01:50:58,150 INFO     Training average positive_sample_loss at step 95500: 0.113195\n",
      "2024-03-03 01:50:58,151 INFO     Training average negative_sample_loss at step 95500: 0.084153\n",
      "2024-03-03 01:50:58,151 INFO     Training average loss at step 95500: 0.098674\n",
      "2024-03-03 01:51:21,690 INFO     Training average positive_sample_loss at step 95600: 0.112500\n",
      "2024-03-03 01:51:21,690 INFO     Training average negative_sample_loss at step 95600: 0.085173\n",
      "2024-03-03 01:51:21,690 INFO     Training average loss at step 95600: 0.098836\n",
      "2024-03-03 01:51:44,597 INFO     Training average positive_sample_loss at step 95700: 0.112901\n",
      "2024-03-03 01:51:44,597 INFO     Training average negative_sample_loss at step 95700: 0.084105\n",
      "2024-03-03 01:51:44,597 INFO     Training average loss at step 95700: 0.098503\n",
      "2024-03-03 01:52:12,784 INFO     Training average positive_sample_loss at step 95800: 0.112861\n",
      "2024-03-03 01:52:12,784 INFO     Training average negative_sample_loss at step 95800: 0.085215\n",
      "2024-03-03 01:52:12,784 INFO     Training average loss at step 95800: 0.099038\n",
      "2024-03-03 01:52:36,815 INFO     Training average positive_sample_loss at step 95900: 0.112843\n",
      "2024-03-03 01:52:36,815 INFO     Training average negative_sample_loss at step 95900: 0.084087\n",
      "2024-03-03 01:52:36,815 INFO     Training average loss at step 95900: 0.098465\n",
      "2024-03-03 01:53:03,283 INFO     Training average positive_sample_loss at step 96000: 0.112313\n",
      "2024-03-03 01:53:03,283 INFO     Training average negative_sample_loss at step 96000: 0.084107\n",
      "2024-03-03 01:53:03,283 INFO     Training average loss at step 96000: 0.098210\n",
      "2024-03-03 01:53:26,931 INFO     Training average positive_sample_loss at step 96100: 0.112251\n",
      "2024-03-03 01:53:26,931 INFO     Training average negative_sample_loss at step 96100: 0.084267\n",
      "2024-03-03 01:53:26,931 INFO     Training average loss at step 96100: 0.098259\n",
      "2024-03-03 01:53:49,736 INFO     Training average positive_sample_loss at step 96200: 0.113492\n",
      "2024-03-03 01:53:49,736 INFO     Training average negative_sample_loss at step 96200: 0.083735\n",
      "2024-03-03 01:53:49,737 INFO     Training average loss at step 96200: 0.098614\n",
      "2024-03-03 01:54:17,516 INFO     Training average positive_sample_loss at step 96300: 0.112971\n",
      "2024-03-03 01:54:17,516 INFO     Training average negative_sample_loss at step 96300: 0.084433\n",
      "2024-03-03 01:54:17,516 INFO     Training average loss at step 96300: 0.098702\n",
      "2024-03-03 01:54:41,563 INFO     Training average positive_sample_loss at step 96400: 0.112272\n",
      "2024-03-03 01:54:41,563 INFO     Training average negative_sample_loss at step 96400: 0.084122\n",
      "2024-03-03 01:54:41,563 INFO     Training average loss at step 96400: 0.098197\n",
      "2024-03-03 01:55:08,338 INFO     Training average positive_sample_loss at step 96500: 0.113284\n",
      "2024-03-03 01:55:08,339 INFO     Training average negative_sample_loss at step 96500: 0.084018\n",
      "2024-03-03 01:55:08,339 INFO     Training average loss at step 96500: 0.098651\n",
      "2024-03-03 01:55:32,165 INFO     Training average positive_sample_loss at step 96600: 0.111655\n",
      "2024-03-03 01:55:32,165 INFO     Training average negative_sample_loss at step 96600: 0.084737\n",
      "2024-03-03 01:55:32,165 INFO     Training average loss at step 96600: 0.098196\n",
      "2024-03-03 01:55:55,428 INFO     Training average positive_sample_loss at step 96700: 0.113618\n",
      "2024-03-03 01:55:55,429 INFO     Training average negative_sample_loss at step 96700: 0.084056\n",
      "2024-03-03 01:55:55,429 INFO     Training average loss at step 96700: 0.098837\n",
      "2024-03-03 01:56:21,885 INFO     Training average positive_sample_loss at step 96800: 0.112765\n",
      "2024-03-03 01:56:21,886 INFO     Training average negative_sample_loss at step 96800: 0.084413\n",
      "2024-03-03 01:56:21,886 INFO     Training average loss at step 96800: 0.098589\n",
      "2024-03-03 01:56:45,089 INFO     Training average positive_sample_loss at step 96900: 0.112576\n",
      "2024-03-03 01:56:45,089 INFO     Training average negative_sample_loss at step 96900: 0.084509\n",
      "2024-03-03 01:56:45,089 INFO     Training average loss at step 96900: 0.098542\n",
      "2024-03-03 01:57:08,194 INFO     Training average positive_sample_loss at step 97000: 0.113442\n",
      "2024-03-03 01:57:08,194 INFO     Training average negative_sample_loss at step 97000: 0.083884\n",
      "2024-03-03 01:57:08,194 INFO     Training average loss at step 97000: 0.098663\n",
      "2024-03-03 01:57:37,178 INFO     Training average positive_sample_loss at step 97100: 0.111887\n",
      "2024-03-03 01:57:37,179 INFO     Training average negative_sample_loss at step 97100: 0.084417\n",
      "2024-03-03 01:57:37,179 INFO     Training average loss at step 97100: 0.098152\n",
      "2024-03-03 01:58:01,296 INFO     Training average positive_sample_loss at step 97200: 0.113189\n",
      "2024-03-03 01:58:01,297 INFO     Training average negative_sample_loss at step 97200: 0.084110\n",
      "2024-03-03 01:58:01,297 INFO     Training average loss at step 97200: 0.098649\n",
      "2024-03-03 01:58:28,618 INFO     Training average positive_sample_loss at step 97300: 0.113020\n",
      "2024-03-03 01:58:28,618 INFO     Training average negative_sample_loss at step 97300: 0.084098\n",
      "2024-03-03 01:58:28,618 INFO     Training average loss at step 97300: 0.098559\n",
      "2024-03-03 01:58:53,005 INFO     Training average positive_sample_loss at step 97400: 0.112462\n",
      "2024-03-03 01:58:53,006 INFO     Training average negative_sample_loss at step 97400: 0.084189\n",
      "2024-03-03 01:58:53,006 INFO     Training average loss at step 97400: 0.098326\n",
      "2024-03-03 01:59:16,239 INFO     Training average positive_sample_loss at step 97500: 0.113064\n",
      "2024-03-03 01:59:16,239 INFO     Training average negative_sample_loss at step 97500: 0.084528\n",
      "2024-03-03 01:59:16,239 INFO     Training average loss at step 97500: 0.098796\n",
      "2024-03-03 01:59:43,653 INFO     Training average positive_sample_loss at step 97600: 0.111877\n",
      "2024-03-03 01:59:43,653 INFO     Training average negative_sample_loss at step 97600: 0.083882\n",
      "2024-03-03 01:59:43,653 INFO     Training average loss at step 97600: 0.097880\n",
      "2024-03-03 02:00:07,683 INFO     Training average positive_sample_loss at step 97700: 0.113208\n",
      "2024-03-03 02:00:07,684 INFO     Training average negative_sample_loss at step 97700: 0.084109\n",
      "2024-03-03 02:00:07,684 INFO     Training average loss at step 97700: 0.098658\n",
      "2024-03-03 02:00:34,644 INFO     Training average positive_sample_loss at step 97800: 0.113237\n",
      "2024-03-03 02:00:34,644 INFO     Training average negative_sample_loss at step 97800: 0.083702\n",
      "2024-03-03 02:00:34,645 INFO     Training average loss at step 97800: 0.098469\n",
      "2024-03-03 02:00:58,543 INFO     Training average positive_sample_loss at step 97900: 0.112081\n",
      "2024-03-03 02:00:58,543 INFO     Training average negative_sample_loss at step 97900: 0.083937\n",
      "2024-03-03 02:00:58,543 INFO     Training average loss at step 97900: 0.098009\n",
      "2024-03-03 02:01:21,858 INFO     Training average positive_sample_loss at step 98000: 0.112904\n",
      "2024-03-03 02:01:21,859 INFO     Training average negative_sample_loss at step 98000: 0.083567\n",
      "2024-03-03 02:01:21,859 INFO     Training average loss at step 98000: 0.098236\n",
      "2024-03-03 02:01:48,571 INFO     Training average positive_sample_loss at step 98100: 0.112451\n",
      "2024-03-03 02:01:48,572 INFO     Training average negative_sample_loss at step 98100: 0.084306\n",
      "2024-03-03 02:01:48,572 INFO     Training average loss at step 98100: 0.098379\n",
      "2024-03-03 02:02:12,232 INFO     Training average positive_sample_loss at step 98200: 0.113167\n",
      "2024-03-03 02:02:12,232 INFO     Training average negative_sample_loss at step 98200: 0.083471\n",
      "2024-03-03 02:02:12,232 INFO     Training average loss at step 98200: 0.098319\n",
      "2024-03-03 02:02:40,444 INFO     Training average positive_sample_loss at step 98300: 0.113107\n",
      "2024-03-03 02:02:40,445 INFO     Training average negative_sample_loss at step 98300: 0.084699\n",
      "2024-03-03 02:02:40,445 INFO     Training average loss at step 98300: 0.098903\n",
      "2024-03-03 02:03:03,792 INFO     Training average positive_sample_loss at step 98400: 0.111864\n",
      "2024-03-03 02:03:03,793 INFO     Training average negative_sample_loss at step 98400: 0.083720\n",
      "2024-03-03 02:03:03,793 INFO     Training average loss at step 98400: 0.097792\n",
      "2024-03-03 02:03:27,642 INFO     Training average positive_sample_loss at step 98500: 0.113014\n",
      "2024-03-03 02:03:27,643 INFO     Training average negative_sample_loss at step 98500: 0.084580\n",
      "2024-03-03 02:03:27,643 INFO     Training average loss at step 98500: 0.098797\n",
      "2024-03-03 02:03:55,131 INFO     Training average positive_sample_loss at step 98600: 0.113104\n",
      "2024-03-03 02:03:55,131 INFO     Training average negative_sample_loss at step 98600: 0.084627\n",
      "2024-03-03 02:03:55,131 INFO     Training average loss at step 98600: 0.098865\n",
      "2024-03-03 02:04:18,723 INFO     Training average positive_sample_loss at step 98700: 0.112575\n",
      "2024-03-03 02:04:18,724 INFO     Training average negative_sample_loss at step 98700: 0.083769\n",
      "2024-03-03 02:04:18,724 INFO     Training average loss at step 98700: 0.098172\n",
      "2024-03-03 02:04:42,141 INFO     Training average positive_sample_loss at step 98800: 0.112881\n",
      "2024-03-03 02:04:42,141 INFO     Training average negative_sample_loss at step 98800: 0.084646\n",
      "2024-03-03 02:04:42,141 INFO     Training average loss at step 98800: 0.098764\n",
      "2024-03-03 02:05:09,557 INFO     Training average positive_sample_loss at step 98900: 0.112464\n",
      "2024-03-03 02:05:09,557 INFO     Training average negative_sample_loss at step 98900: 0.084682\n",
      "2024-03-03 02:05:09,558 INFO     Training average loss at step 98900: 0.098573\n",
      "2024-03-03 02:05:32,661 INFO     Training average positive_sample_loss at step 99000: 0.112948\n",
      "2024-03-03 02:05:32,661 INFO     Training average negative_sample_loss at step 99000: 0.084262\n",
      "2024-03-03 02:05:32,661 INFO     Training average loss at step 99000: 0.098605\n",
      "2024-03-03 02:05:59,517 INFO     Training average positive_sample_loss at step 99100: 0.112909\n",
      "2024-03-03 02:05:59,518 INFO     Training average negative_sample_loss at step 99100: 0.083817\n",
      "2024-03-03 02:05:59,518 INFO     Training average loss at step 99100: 0.098363\n",
      "2024-03-03 02:06:23,022 INFO     Training average positive_sample_loss at step 99200: 0.112337\n",
      "2024-03-03 02:06:23,022 INFO     Training average negative_sample_loss at step 99200: 0.084402\n",
      "2024-03-03 02:06:23,022 INFO     Training average loss at step 99200: 0.098370\n",
      "2024-03-03 02:06:45,897 INFO     Training average positive_sample_loss at step 99300: 0.112899\n",
      "2024-03-03 02:06:45,898 INFO     Training average negative_sample_loss at step 99300: 0.084439\n",
      "2024-03-03 02:06:45,898 INFO     Training average loss at step 99300: 0.098669\n",
      "2024-03-03 02:07:12,699 INFO     Training average positive_sample_loss at step 99400: 0.112295\n",
      "2024-03-03 02:07:12,699 INFO     Training average negative_sample_loss at step 99400: 0.083939\n",
      "2024-03-03 02:07:12,699 INFO     Training average loss at step 99400: 0.098117\n",
      "2024-03-03 02:07:35,789 INFO     Training average positive_sample_loss at step 99500: 0.112301\n",
      "2024-03-03 02:07:35,789 INFO     Training average negative_sample_loss at step 99500: 0.084012\n",
      "2024-03-03 02:07:35,790 INFO     Training average loss at step 99500: 0.098157\n",
      "2024-03-03 02:08:03,655 INFO     Training average positive_sample_loss at step 99600: 0.114132\n",
      "2024-03-03 02:08:03,655 INFO     Training average negative_sample_loss at step 99600: 0.084649\n",
      "2024-03-03 02:08:03,655 INFO     Training average loss at step 99600: 0.099390\n",
      "2024-03-03 02:08:26,945 INFO     Training average positive_sample_loss at step 99700: 0.112359\n",
      "2024-03-03 02:08:26,945 INFO     Training average negative_sample_loss at step 99700: 0.084573\n",
      "2024-03-03 02:08:26,945 INFO     Training average loss at step 99700: 0.098466\n",
      "2024-03-03 02:08:50,246 INFO     Training average positive_sample_loss at step 99800: 0.112624\n",
      "2024-03-03 02:08:50,246 INFO     Training average negative_sample_loss at step 99800: 0.083970\n",
      "2024-03-03 02:08:50,246 INFO     Training average loss at step 99800: 0.098297\n",
      "2024-03-03 02:09:17,254 INFO     Training average positive_sample_loss at step 99900: 0.112502\n",
      "2024-03-03 02:09:17,254 INFO     Training average negative_sample_loss at step 99900: 0.083796\n",
      "2024-03-03 02:09:17,254 INFO     Training average loss at step 99900: 0.098149\n",
      "2024-03-03 02:09:44,197 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-03 02:09:44,710 INFO     Evaluating the model... (0/1834)\n",
      "2024-03-03 02:10:13,553 INFO     Evaluating the model... (1000/1834)\n",
      "2024-03-03 02:10:34,575 INFO     Valid MRR at step 99999: 0.644175\n",
      "2024-03-03 02:10:34,576 INFO     Valid MR at step 99999: 237.949280\n",
      "2024-03-03 02:10:34,576 INFO     Valid HITS@1 at step 99999: 0.589501\n",
      "2024-03-03 02:10:34,576 INFO     Valid HITS@3 at step 99999: 0.663210\n",
      "2024-03-03 02:10:34,576 INFO     Valid HITS@10 at step 99999: 0.756975\n",
      "2024-03-03 02:10:34,576 INFO     Evaluating on Test Dataset...\n",
      "2024-03-03 02:10:35,035 INFO     Evaluating the model... (0/4582)\n",
      "2024-03-03 02:11:02,562 INFO     Evaluating the model... (1000/4582)\n",
      "2024-03-03 02:11:29,702 INFO     Evaluating the model... (2000/4582)\n",
      "2024-03-03 02:11:55,312 INFO     Evaluating the model... (3000/4582)\n",
      "2024-03-03 02:12:20,641 INFO     Evaluating the model... (4000/4582)\n",
      "2024-03-03 02:12:35,783 INFO     Test MRR at step 99999: 0.642378\n",
      "2024-03-03 02:12:35,784 INFO     Test MR at step 99999: 220.041834\n",
      "2024-03-03 02:12:35,784 INFO     Test HITS@1 at step 99999: 0.587352\n",
      "2024-03-03 02:12:35,784 INFO     Test HITS@3 at step 99999: 0.661536\n",
      "2024-03-03 02:12:35,784 INFO     Test HITS@10 at step 99999: 0.756515\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE DBpedia15K 0 0 1024 256 1000 9.0 1.0 0.00005 100000 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
