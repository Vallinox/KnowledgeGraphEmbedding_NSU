{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con Self. Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-04 17:54:42,976 INFO     Model: RotatE\n",
      "2023-12-04 17:54:42,976 INFO     Data Path: data/FB15k-237\n",
      "2023-12-04 17:54:42,976 INFO     #entity: 14541\n",
      "2023-12-04 17:54:42,976 INFO     #relation: 237\n",
      "2023-12-04 17:54:44,183 INFO     #train: 272115\n",
      "2023-12-04 17:54:44,227 INFO     #valid: 17535\n",
      "2023-12-04 17:54:44,524 INFO     #test: 20466\n",
      "2023-12-04 17:54:44,712 INFO     Model Parameter Configuration:\n",
      "2023-12-04 17:54:44,714 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-04 17:54:44,714 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-04 17:54:44,714 INFO     Parameter entity_embedding: torch.Size([14541, 2000]), require_grad = True\n",
      "2023-12-04 17:54:44,715 INFO     Parameter relation_embedding: torch.Size([237, 1000]), require_grad = True\n",
      "2023-12-04 17:54:47,928 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-04 17:54:47,928 INFO     Start Training...\n",
      "2023-12-04 17:54:47,928 INFO     init_step = 0\n",
      "2023-12-04 17:54:47,928 INFO     batch_size = 1024\n",
      "2023-12-04 17:54:47,928 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-04 17:54:47,928 INFO     hidden_dim = 1000\n",
      "2023-12-04 17:54:47,928 INFO     gamma = 9.000000\n",
      "2023-12-04 17:54:47,928 INFO     negative_adversarial_sampling = True\n",
      "2023-12-04 17:54:47,928 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-04 17:54:47,928 INFO     learning_rate = 0\n",
      "2023-12-04 17:54:56,762 INFO     Training average positive_sample_loss at step 0: 2.536761\n",
      "2023-12-04 17:54:56,762 INFO     Training average negative_sample_loss at step 0: 0.083630\n",
      "2023-12-04 17:54:56,762 INFO     Training average loss at step 0: 1.310195\n",
      "2023-12-04 17:54:56,762 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 17:54:57,365 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 17:55:24,730 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 17:55:46,810 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 17:55:50,467 INFO     Valid MRR at step 0: 0.005366\n",
      "2023-12-04 17:55:50,468 INFO     Valid MR at step 0: 6842.255632\n",
      "2023-12-04 17:55:50,468 INFO     Valid HITS@1 at step 0: 0.004391\n",
      "2023-12-04 17:55:50,468 INFO     Valid HITS@3 at step 0: 0.004990\n",
      "2023-12-04 17:55:50,468 INFO     Valid HITS@10 at step 0: 0.005845\n",
      "2023-12-04 17:55:56,020 INFO     Training average positive_sample_loss at step 100: 2.091509\n",
      "2023-12-04 17:55:56,020 INFO     Training average negative_sample_loss at step 100: 0.162566\n",
      "2023-12-04 17:55:56,020 INFO     Training average loss at step 100: 1.127037\n",
      "2023-12-04 17:56:01,233 INFO     Training average positive_sample_loss at step 200: 1.160658\n",
      "2023-12-04 17:56:01,233 INFO     Training average negative_sample_loss at step 200: 0.433642\n",
      "2023-12-04 17:56:01,233 INFO     Training average loss at step 200: 0.797150\n",
      "2023-12-04 17:56:06,454 INFO     Training average positive_sample_loss at step 300: 0.856378\n",
      "2023-12-04 17:56:06,454 INFO     Training average negative_sample_loss at step 300: 0.558360\n",
      "2023-12-04 17:56:06,454 INFO     Training average loss at step 300: 0.707369\n",
      "2023-12-04 17:56:11,684 INFO     Training average positive_sample_loss at step 400: 0.742293\n",
      "2023-12-04 17:56:11,684 INFO     Training average negative_sample_loss at step 400: 0.594359\n",
      "2023-12-04 17:56:11,684 INFO     Training average loss at step 400: 0.668326\n",
      "2023-12-04 17:56:16,882 INFO     Training average positive_sample_loss at step 500: 0.684949\n",
      "2023-12-04 17:56:16,883 INFO     Training average negative_sample_loss at step 500: 0.601919\n",
      "2023-12-04 17:56:16,883 INFO     Training average loss at step 500: 0.643434\n",
      "2023-12-04 17:56:22,857 INFO     Training average positive_sample_loss at step 600: 0.598176\n",
      "2023-12-04 17:56:22,858 INFO     Training average negative_sample_loss at step 600: 0.584572\n",
      "2023-12-04 17:56:22,858 INFO     Training average loss at step 600: 0.591374\n",
      "2023-12-04 17:56:28,072 INFO     Training average positive_sample_loss at step 700: 0.582474\n",
      "2023-12-04 17:56:28,073 INFO     Training average negative_sample_loss at step 700: 0.550027\n",
      "2023-12-04 17:56:28,073 INFO     Training average loss at step 700: 0.566250\n",
      "2023-12-04 17:56:33,270 INFO     Training average positive_sample_loss at step 800: 0.572715\n",
      "2023-12-04 17:56:33,270 INFO     Training average negative_sample_loss at step 800: 0.534410\n",
      "2023-12-04 17:56:33,270 INFO     Training average loss at step 800: 0.553562\n",
      "2023-12-04 17:56:38,501 INFO     Training average positive_sample_loss at step 900: 0.557930\n",
      "2023-12-04 17:56:38,501 INFO     Training average negative_sample_loss at step 900: 0.519118\n",
      "2023-12-04 17:56:38,501 INFO     Training average loss at step 900: 0.538524\n",
      "2023-12-04 17:56:43,703 INFO     Training average positive_sample_loss at step 1000: 0.542685\n",
      "2023-12-04 17:56:43,704 INFO     Training average negative_sample_loss at step 1000: 0.504079\n",
      "2023-12-04 17:56:43,704 INFO     Training average loss at step 1000: 0.523382\n",
      "2023-12-04 17:56:49,634 INFO     Training average positive_sample_loss at step 1100: 0.504481\n",
      "2023-12-04 17:56:49,635 INFO     Training average negative_sample_loss at step 1100: 0.483327\n",
      "2023-12-04 17:56:49,635 INFO     Training average loss at step 1100: 0.493904\n",
      "2023-12-04 17:56:54,815 INFO     Training average positive_sample_loss at step 1200: 0.476365\n",
      "2023-12-04 17:56:54,815 INFO     Training average negative_sample_loss at step 1200: 0.444326\n",
      "2023-12-04 17:56:54,815 INFO     Training average loss at step 1200: 0.460346\n",
      "2023-12-04 17:56:59,996 INFO     Training average positive_sample_loss at step 1300: 0.473651\n",
      "2023-12-04 17:56:59,997 INFO     Training average negative_sample_loss at step 1300: 0.425521\n",
      "2023-12-04 17:56:59,997 INFO     Training average loss at step 1300: 0.449586\n",
      "2023-12-04 17:57:05,185 INFO     Training average positive_sample_loss at step 1400: 0.463578\n",
      "2023-12-04 17:57:05,186 INFO     Training average negative_sample_loss at step 1400: 0.412035\n",
      "2023-12-04 17:57:05,186 INFO     Training average loss at step 1400: 0.437807\n",
      "2023-12-04 17:57:10,343 INFO     Training average positive_sample_loss at step 1500: 0.452043\n",
      "2023-12-04 17:57:10,343 INFO     Training average negative_sample_loss at step 1500: 0.398958\n",
      "2023-12-04 17:57:10,343 INFO     Training average loss at step 1500: 0.425500\n",
      "2023-12-04 17:57:16,245 INFO     Training average positive_sample_loss at step 1600: 0.438499\n",
      "2023-12-04 17:57:16,245 INFO     Training average negative_sample_loss at step 1600: 0.386953\n",
      "2023-12-04 17:57:16,245 INFO     Training average loss at step 1600: 0.412726\n",
      "2023-12-04 17:57:21,424 INFO     Training average positive_sample_loss at step 1700: 0.391449\n",
      "2023-12-04 17:57:21,424 INFO     Training average negative_sample_loss at step 1700: 0.358689\n",
      "2023-12-04 17:57:21,424 INFO     Training average loss at step 1700: 0.375069\n",
      "2023-12-04 17:57:26,599 INFO     Training average positive_sample_loss at step 1800: 0.395440\n",
      "2023-12-04 17:57:26,599 INFO     Training average negative_sample_loss at step 1800: 0.341060\n",
      "2023-12-04 17:57:26,599 INFO     Training average loss at step 1800: 0.368250\n",
      "2023-12-04 17:57:31,808 INFO     Training average positive_sample_loss at step 1900: 0.389916\n",
      "2023-12-04 17:57:31,809 INFO     Training average negative_sample_loss at step 1900: 0.331609\n",
      "2023-12-04 17:57:31,809 INFO     Training average loss at step 1900: 0.360762\n",
      "2023-12-04 17:57:36,999 INFO     Training average positive_sample_loss at step 2000: 0.381061\n",
      "2023-12-04 17:57:36,999 INFO     Training average negative_sample_loss at step 2000: 0.324138\n",
      "2023-12-04 17:57:36,999 INFO     Training average loss at step 2000: 0.352600\n",
      "2023-12-04 17:57:42,168 INFO     Training average positive_sample_loss at step 2100: 0.370847\n",
      "2023-12-04 17:57:42,169 INFO     Training average negative_sample_loss at step 2100: 0.314804\n",
      "2023-12-04 17:57:42,169 INFO     Training average loss at step 2100: 0.342826\n",
      "2023-12-04 17:57:48,090 INFO     Training average positive_sample_loss at step 2200: 0.335131\n",
      "2023-12-04 17:57:48,090 INFO     Training average negative_sample_loss at step 2200: 0.299999\n",
      "2023-12-04 17:57:48,090 INFO     Training average loss at step 2200: 0.317565\n",
      "2023-12-04 17:57:53,293 INFO     Training average positive_sample_loss at step 2300: 0.332730\n",
      "2023-12-04 17:57:53,293 INFO     Training average negative_sample_loss at step 2300: 0.282438\n",
      "2023-12-04 17:57:53,294 INFO     Training average loss at step 2300: 0.307584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 17:57:58,485 INFO     Training average positive_sample_loss at step 2400: 0.328985\n",
      "2023-12-04 17:57:58,485 INFO     Training average negative_sample_loss at step 2400: 0.275978\n",
      "2023-12-04 17:57:58,485 INFO     Training average loss at step 2400: 0.302482\n",
      "2023-12-04 17:58:03,704 INFO     Training average positive_sample_loss at step 2500: 0.324058\n",
      "2023-12-04 17:58:03,704 INFO     Training average negative_sample_loss at step 2500: 0.272295\n",
      "2023-12-04 17:58:03,704 INFO     Training average loss at step 2500: 0.298177\n",
      "2023-12-04 17:58:08,924 INFO     Training average positive_sample_loss at step 2600: 0.316502\n",
      "2023-12-04 17:58:08,924 INFO     Training average negative_sample_loss at step 2600: 0.267041\n",
      "2023-12-04 17:58:08,924 INFO     Training average loss at step 2600: 0.291772\n",
      "2023-12-04 17:58:14,847 INFO     Training average positive_sample_loss at step 2700: 0.294728\n",
      "2023-12-04 17:58:14,847 INFO     Training average negative_sample_loss at step 2700: 0.261574\n",
      "2023-12-04 17:58:14,848 INFO     Training average loss at step 2700: 0.278151\n",
      "2023-12-04 17:58:20,077 INFO     Training average positive_sample_loss at step 2800: 0.282586\n",
      "2023-12-04 17:58:20,077 INFO     Training average negative_sample_loss at step 2800: 0.246214\n",
      "2023-12-04 17:58:20,077 INFO     Training average loss at step 2800: 0.264400\n",
      "2023-12-04 17:58:25,289 INFO     Training average positive_sample_loss at step 2900: 0.284734\n",
      "2023-12-04 17:58:25,289 INFO     Training average negative_sample_loss at step 2900: 0.242596\n",
      "2023-12-04 17:58:25,289 INFO     Training average loss at step 2900: 0.263665\n",
      "2023-12-04 17:58:30,517 INFO     Training average positive_sample_loss at step 3000: 0.281604\n",
      "2023-12-04 17:58:30,518 INFO     Training average negative_sample_loss at step 3000: 0.240620\n",
      "2023-12-04 17:58:30,518 INFO     Training average loss at step 3000: 0.261112\n",
      "2023-12-04 17:58:36,053 INFO     Training average positive_sample_loss at step 3100: 0.277798\n",
      "2023-12-04 17:58:36,053 INFO     Training average negative_sample_loss at step 3100: 0.238324\n",
      "2023-12-04 17:58:36,053 INFO     Training average loss at step 3100: 0.258061\n",
      "2023-12-04 17:58:44,226 INFO     Training average positive_sample_loss at step 3200: 0.269943\n",
      "2023-12-04 17:58:44,226 INFO     Training average negative_sample_loss at step 3200: 0.237628\n",
      "2023-12-04 17:58:44,226 INFO     Training average loss at step 3200: 0.253786\n",
      "2023-12-04 17:58:50,693 INFO     Training average positive_sample_loss at step 3300: 0.247233\n",
      "2023-12-04 17:58:50,694 INFO     Training average negative_sample_loss at step 3300: 0.226639\n",
      "2023-12-04 17:58:50,694 INFO     Training average loss at step 3300: 0.236936\n",
      "2023-12-04 17:58:58,651 INFO     Training average positive_sample_loss at step 3400: 0.253724\n",
      "2023-12-04 17:58:58,652 INFO     Training average negative_sample_loss at step 3400: 0.222747\n",
      "2023-12-04 17:58:58,652 INFO     Training average loss at step 3400: 0.238235\n",
      "2023-12-04 17:59:07,078 INFO     Training average positive_sample_loss at step 3500: 0.253736\n",
      "2023-12-04 17:59:07,078 INFO     Training average negative_sample_loss at step 3500: 0.221697\n",
      "2023-12-04 17:59:07,078 INFO     Training average loss at step 3500: 0.237717\n",
      "2023-12-04 17:59:15,577 INFO     Training average positive_sample_loss at step 3600: 0.251023\n",
      "2023-12-04 17:59:15,578 INFO     Training average negative_sample_loss at step 3600: 0.221712\n",
      "2023-12-04 17:59:15,578 INFO     Training average loss at step 3600: 0.236367\n",
      "2023-12-04 17:59:24,159 INFO     Training average positive_sample_loss at step 3700: 0.249837\n",
      "2023-12-04 17:59:24,159 INFO     Training average negative_sample_loss at step 3700: 0.221885\n",
      "2023-12-04 17:59:24,159 INFO     Training average loss at step 3700: 0.235861\n",
      "2023-12-04 17:59:33,368 INFO     Training average positive_sample_loss at step 3800: 0.229430\n",
      "2023-12-04 17:59:33,368 INFO     Training average negative_sample_loss at step 3800: 0.216925\n",
      "2023-12-04 17:59:33,368 INFO     Training average loss at step 3800: 0.223178\n",
      "2023-12-04 17:59:42,384 INFO     Training average positive_sample_loss at step 3900: 0.233673\n",
      "2023-12-04 17:59:42,385 INFO     Training average negative_sample_loss at step 3900: 0.210786\n",
      "2023-12-04 17:59:42,385 INFO     Training average loss at step 3900: 0.222229\n",
      "2023-12-04 17:59:51,150 INFO     Training average positive_sample_loss at step 4000: 0.236070\n",
      "2023-12-04 17:59:51,151 INFO     Training average negative_sample_loss at step 4000: 0.211391\n",
      "2023-12-04 17:59:51,151 INFO     Training average loss at step 4000: 0.223731\n",
      "2023-12-04 17:59:59,493 INFO     Training average positive_sample_loss at step 4100: 0.235608\n",
      "2023-12-04 17:59:59,493 INFO     Training average negative_sample_loss at step 4100: 0.210861\n",
      "2023-12-04 17:59:59,493 INFO     Training average loss at step 4100: 0.223234\n",
      "2023-12-04 18:00:11,152 INFO     Training average positive_sample_loss at step 4200: 0.234239\n",
      "2023-12-04 18:00:11,152 INFO     Training average negative_sample_loss at step 4200: 0.211908\n",
      "2023-12-04 18:00:11,152 INFO     Training average loss at step 4200: 0.223074\n",
      "2023-12-04 18:00:23,220 INFO     Training average positive_sample_loss at step 4300: 0.222250\n",
      "2023-12-04 18:00:23,221 INFO     Training average negative_sample_loss at step 4300: 0.210965\n",
      "2023-12-04 18:00:23,221 INFO     Training average loss at step 4300: 0.216608\n",
      "2023-12-04 18:00:34,810 INFO     Training average positive_sample_loss at step 4400: 0.219287\n",
      "2023-12-04 18:00:34,811 INFO     Training average negative_sample_loss at step 4400: 0.204155\n",
      "2023-12-04 18:00:34,811 INFO     Training average loss at step 4400: 0.211721\n",
      "2023-12-04 18:00:46,484 INFO     Training average positive_sample_loss at step 4500: 0.224928\n",
      "2023-12-04 18:00:46,484 INFO     Training average negative_sample_loss at step 4500: 0.203708\n",
      "2023-12-04 18:00:46,484 INFO     Training average loss at step 4500: 0.214318\n",
      "2023-12-04 18:00:58,336 INFO     Training average positive_sample_loss at step 4600: 0.225473\n",
      "2023-12-04 18:00:58,336 INFO     Training average negative_sample_loss at step 4600: 0.205419\n",
      "2023-12-04 18:00:58,336 INFO     Training average loss at step 4600: 0.215446\n",
      "2023-12-04 18:01:07,254 INFO     Training average positive_sample_loss at step 4700: 0.225189\n",
      "2023-12-04 18:01:07,255 INFO     Training average negative_sample_loss at step 4700: 0.206308\n",
      "2023-12-04 18:01:07,255 INFO     Training average loss at step 4700: 0.215749\n",
      "2023-12-04 18:01:18,942 INFO     Training average positive_sample_loss at step 4800: 0.221186\n",
      "2023-12-04 18:01:18,942 INFO     Training average negative_sample_loss at step 4800: 0.207071\n",
      "2023-12-04 18:01:18,942 INFO     Training average loss at step 4800: 0.214128\n",
      "2023-12-04 18:01:30,522 INFO     Training average positive_sample_loss at step 4900: 0.208774\n",
      "2023-12-04 18:01:30,522 INFO     Training average negative_sample_loss at step 4900: 0.199993\n",
      "2023-12-04 18:01:30,522 INFO     Training average loss at step 4900: 0.204383\n",
      "2023-12-04 18:01:42,387 INFO     Training average positive_sample_loss at step 5000: 0.216062\n",
      "2023-12-04 18:01:42,387 INFO     Training average negative_sample_loss at step 5000: 0.199288\n",
      "2023-12-04 18:01:42,387 INFO     Training average loss at step 5000: 0.207675\n",
      "2023-12-04 18:01:54,194 INFO     Training average positive_sample_loss at step 5100: 0.218469\n",
      "2023-12-04 18:01:54,194 INFO     Training average negative_sample_loss at step 5100: 0.201036\n",
      "2023-12-04 18:01:54,194 INFO     Training average loss at step 5100: 0.209753\n",
      "2023-12-04 18:02:05,940 INFO     Training average positive_sample_loss at step 5200: 0.220143\n",
      "2023-12-04 18:02:05,940 INFO     Training average negative_sample_loss at step 5200: 0.201416\n",
      "2023-12-04 18:02:05,940 INFO     Training average loss at step 5200: 0.210780\n",
      "2023-12-04 18:02:16,489 INFO     Training average positive_sample_loss at step 5300: 0.219336\n",
      "2023-12-04 18:02:16,489 INFO     Training average negative_sample_loss at step 5300: 0.203132\n",
      "2023-12-04 18:02:16,489 INFO     Training average loss at step 5300: 0.211234\n",
      "2023-12-04 18:02:27,225 INFO     Training average positive_sample_loss at step 5400: 0.204425\n",
      "2023-12-04 18:02:27,225 INFO     Training average negative_sample_loss at step 5400: 0.199960\n",
      "2023-12-04 18:02:27,225 INFO     Training average loss at step 5400: 0.202192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:02:38,963 INFO     Training average positive_sample_loss at step 5500: 0.209874\n",
      "2023-12-04 18:02:38,963 INFO     Training average negative_sample_loss at step 5500: 0.195081\n",
      "2023-12-04 18:02:38,964 INFO     Training average loss at step 5500: 0.202477\n",
      "2023-12-04 18:02:50,867 INFO     Training average positive_sample_loss at step 5600: 0.213675\n",
      "2023-12-04 18:02:50,867 INFO     Training average negative_sample_loss at step 5600: 0.196021\n",
      "2023-12-04 18:02:50,867 INFO     Training average loss at step 5600: 0.204848\n",
      "2023-12-04 18:03:02,920 INFO     Training average positive_sample_loss at step 5700: 0.214735\n",
      "2023-12-04 18:03:02,920 INFO     Training average negative_sample_loss at step 5700: 0.197467\n",
      "2023-12-04 18:03:02,920 INFO     Training average loss at step 5700: 0.206101\n",
      "2023-12-04 18:03:15,007 INFO     Training average positive_sample_loss at step 5800: 0.215391\n",
      "2023-12-04 18:03:15,007 INFO     Training average negative_sample_loss at step 5800: 0.199643\n",
      "2023-12-04 18:03:15,007 INFO     Training average loss at step 5800: 0.207517\n",
      "2023-12-04 18:03:26,433 INFO     Training average positive_sample_loss at step 5900: 0.205625\n",
      "2023-12-04 18:03:26,434 INFO     Training average negative_sample_loss at step 5900: 0.199006\n",
      "2023-12-04 18:03:26,434 INFO     Training average loss at step 5900: 0.202316\n",
      "2023-12-04 18:03:35,679 INFO     Training average positive_sample_loss at step 6000: 0.205480\n",
      "2023-12-04 18:03:35,679 INFO     Training average negative_sample_loss at step 6000: 0.191294\n",
      "2023-12-04 18:03:35,679 INFO     Training average loss at step 6000: 0.198387\n",
      "2023-12-04 18:03:47,336 INFO     Training average positive_sample_loss at step 6100: 0.210035\n",
      "2023-12-04 18:03:47,337 INFO     Training average negative_sample_loss at step 6100: 0.193948\n",
      "2023-12-04 18:03:47,337 INFO     Training average loss at step 6100: 0.201991\n",
      "2023-12-04 18:03:59,167 INFO     Training average positive_sample_loss at step 6200: 0.211585\n",
      "2023-12-04 18:03:59,167 INFO     Training average negative_sample_loss at step 6200: 0.195714\n",
      "2023-12-04 18:03:59,167 INFO     Training average loss at step 6200: 0.203649\n",
      "2023-12-04 18:04:11,143 INFO     Training average positive_sample_loss at step 6300: 0.212398\n",
      "2023-12-04 18:04:11,143 INFO     Training average negative_sample_loss at step 6300: 0.196947\n",
      "2023-12-04 18:04:11,143 INFO     Training average loss at step 6300: 0.204672\n",
      "2023-12-04 18:04:23,800 INFO     Training average positive_sample_loss at step 6400: 0.208535\n",
      "2023-12-04 18:04:23,801 INFO     Training average negative_sample_loss at step 6400: 0.197049\n",
      "2023-12-04 18:04:23,801 INFO     Training average loss at step 6400: 0.202792\n",
      "2023-12-04 18:04:35,384 INFO     Training average positive_sample_loss at step 6500: 0.200452\n",
      "2023-12-04 18:04:35,385 INFO     Training average negative_sample_loss at step 6500: 0.192681\n",
      "2023-12-04 18:04:35,385 INFO     Training average loss at step 6500: 0.196566\n",
      "2023-12-04 18:04:43,524 INFO     Training average positive_sample_loss at step 6600: 0.207207\n",
      "2023-12-04 18:04:43,525 INFO     Training average negative_sample_loss at step 6600: 0.191390\n",
      "2023-12-04 18:04:43,525 INFO     Training average loss at step 6600: 0.199299\n",
      "2023-12-04 18:04:55,134 INFO     Training average positive_sample_loss at step 6700: 0.209359\n",
      "2023-12-04 18:04:55,135 INFO     Training average negative_sample_loss at step 6700: 0.192435\n",
      "2023-12-04 18:04:55,135 INFO     Training average loss at step 6700: 0.200897\n",
      "2023-12-04 18:05:07,002 INFO     Training average positive_sample_loss at step 6800: 0.210894\n",
      "2023-12-04 18:05:07,002 INFO     Training average negative_sample_loss at step 6800: 0.195433\n",
      "2023-12-04 18:05:07,002 INFO     Training average loss at step 6800: 0.203164\n",
      "2023-12-04 18:05:18,946 INFO     Training average positive_sample_loss at step 6900: 0.210589\n",
      "2023-12-04 18:05:18,946 INFO     Training average negative_sample_loss at step 6900: 0.195771\n",
      "2023-12-04 18:05:18,946 INFO     Training average loss at step 6900: 0.203180\n",
      "2023-12-04 18:05:31,235 INFO     Training average positive_sample_loss at step 7000: 0.197618\n",
      "2023-12-04 18:05:31,236 INFO     Training average negative_sample_loss at step 7000: 0.192163\n",
      "2023-12-04 18:05:31,236 INFO     Training average loss at step 7000: 0.194891\n",
      "2023-12-04 18:05:43,002 INFO     Training average positive_sample_loss at step 7100: 0.204739\n",
      "2023-12-04 18:05:43,002 INFO     Training average negative_sample_loss at step 7100: 0.189758\n",
      "2023-12-04 18:05:43,002 INFO     Training average loss at step 7100: 0.197249\n",
      "2023-12-04 18:05:51,400 INFO     Training average positive_sample_loss at step 7200: 0.206957\n",
      "2023-12-04 18:05:51,401 INFO     Training average negative_sample_loss at step 7200: 0.191514\n",
      "2023-12-04 18:05:51,401 INFO     Training average loss at step 7200: 0.199235\n",
      "2023-12-04 18:06:03,022 INFO     Training average positive_sample_loss at step 7300: 0.208436\n",
      "2023-12-04 18:06:03,022 INFO     Training average negative_sample_loss at step 7300: 0.193094\n",
      "2023-12-04 18:06:03,023 INFO     Training average loss at step 7300: 0.200765\n",
      "2023-12-04 18:06:14,793 INFO     Training average positive_sample_loss at step 7400: 0.210285\n",
      "2023-12-04 18:06:14,794 INFO     Training average negative_sample_loss at step 7400: 0.193457\n",
      "2023-12-04 18:06:14,794 INFO     Training average loss at step 7400: 0.201871\n",
      "2023-12-04 18:06:27,183 INFO     Training average positive_sample_loss at step 7500: 0.199772\n",
      "2023-12-04 18:06:27,183 INFO     Training average negative_sample_loss at step 7500: 0.193547\n",
      "2023-12-04 18:06:27,183 INFO     Training average loss at step 7500: 0.196660\n",
      "2023-12-04 18:06:38,730 INFO     Training average positive_sample_loss at step 7600: 0.201119\n",
      "2023-12-04 18:06:38,730 INFO     Training average negative_sample_loss at step 7600: 0.188772\n",
      "2023-12-04 18:06:38,730 INFO     Training average loss at step 7600: 0.194946\n",
      "2023-12-04 18:06:50,525 INFO     Training average positive_sample_loss at step 7700: 0.206390\n",
      "2023-12-04 18:06:50,525 INFO     Training average negative_sample_loss at step 7700: 0.189192\n",
      "2023-12-04 18:06:50,525 INFO     Training average loss at step 7700: 0.197791\n",
      "2023-12-04 18:06:59,560 INFO     Training average positive_sample_loss at step 7800: 0.206715\n",
      "2023-12-04 18:06:59,560 INFO     Training average negative_sample_loss at step 7800: 0.190451\n",
      "2023-12-04 18:06:59,560 INFO     Training average loss at step 7800: 0.198583\n",
      "2023-12-04 18:07:10,411 INFO     Training average positive_sample_loss at step 7900: 0.208677\n",
      "2023-12-04 18:07:10,412 INFO     Training average negative_sample_loss at step 7900: 0.192750\n",
      "2023-12-04 18:07:10,412 INFO     Training average loss at step 7900: 0.200713\n",
      "2023-12-04 18:07:22,824 INFO     Training average positive_sample_loss at step 8000: 0.203995\n",
      "2023-12-04 18:07:22,825 INFO     Training average negative_sample_loss at step 8000: 0.193195\n",
      "2023-12-04 18:07:22,825 INFO     Training average loss at step 8000: 0.198595\n",
      "2023-12-04 18:07:34,490 INFO     Training average positive_sample_loss at step 8100: 0.196363\n",
      "2023-12-04 18:07:34,490 INFO     Training average negative_sample_loss at step 8100: 0.186896\n",
      "2023-12-04 18:07:34,490 INFO     Training average loss at step 8100: 0.191630\n",
      "2023-12-04 18:07:46,356 INFO     Training average positive_sample_loss at step 8200: 0.204639\n",
      "2023-12-04 18:07:46,356 INFO     Training average negative_sample_loss at step 8200: 0.187563\n",
      "2023-12-04 18:07:46,356 INFO     Training average loss at step 8200: 0.196101\n",
      "2023-12-04 18:07:58,347 INFO     Training average positive_sample_loss at step 8300: 0.206038\n",
      "2023-12-04 18:07:58,348 INFO     Training average negative_sample_loss at step 8300: 0.189318\n",
      "2023-12-04 18:07:58,348 INFO     Training average loss at step 8300: 0.197678\n",
      "2023-12-04 18:08:08,700 INFO     Training average positive_sample_loss at step 8400: 0.207574\n",
      "2023-12-04 18:08:08,701 INFO     Training average negative_sample_loss at step 8400: 0.190778\n",
      "2023-12-04 18:08:08,701 INFO     Training average loss at step 8400: 0.199176\n",
      "2023-12-04 18:08:18,419 INFO     Training average positive_sample_loss at step 8500: 0.207450\n",
      "2023-12-04 18:08:18,420 INFO     Training average negative_sample_loss at step 8500: 0.191992\n",
      "2023-12-04 18:08:18,420 INFO     Training average loss at step 8500: 0.199721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:08:30,380 INFO     Training average positive_sample_loss at step 8600: 0.194893\n",
      "2023-12-04 18:08:30,380 INFO     Training average negative_sample_loss at step 8600: 0.188683\n",
      "2023-12-04 18:08:30,380 INFO     Training average loss at step 8600: 0.191788\n",
      "2023-12-04 18:08:42,012 INFO     Training average positive_sample_loss at step 8700: 0.201453\n",
      "2023-12-04 18:08:42,012 INFO     Training average negative_sample_loss at step 8700: 0.185340\n",
      "2023-12-04 18:08:42,012 INFO     Training average loss at step 8700: 0.193396\n",
      "2023-12-04 18:08:53,882 INFO     Training average positive_sample_loss at step 8800: 0.204122\n",
      "2023-12-04 18:08:53,882 INFO     Training average negative_sample_loss at step 8800: 0.187775\n",
      "2023-12-04 18:08:53,882 INFO     Training average loss at step 8800: 0.195949\n",
      "2023-12-04 18:09:05,852 INFO     Training average positive_sample_loss at step 8900: 0.206620\n",
      "2023-12-04 18:09:05,852 INFO     Training average negative_sample_loss at step 8900: 0.190239\n",
      "2023-12-04 18:09:05,852 INFO     Training average loss at step 8900: 0.198430\n",
      "2023-12-04 18:09:17,856 INFO     Training average positive_sample_loss at step 9000: 0.206907\n",
      "2023-12-04 18:09:17,857 INFO     Training average negative_sample_loss at step 9000: 0.191384\n",
      "2023-12-04 18:09:17,857 INFO     Training average loss at step 9000: 0.199145\n",
      "2023-12-04 18:09:27,570 INFO     Training average positive_sample_loss at step 9100: 0.197677\n",
      "2023-12-04 18:09:27,571 INFO     Training average negative_sample_loss at step 9100: 0.190025\n",
      "2023-12-04 18:09:27,571 INFO     Training average loss at step 9100: 0.193851\n",
      "2023-12-04 18:09:39,251 INFO     Training average positive_sample_loss at step 9200: 0.199616\n",
      "2023-12-04 18:09:39,251 INFO     Training average negative_sample_loss at step 9200: 0.185537\n",
      "2023-12-04 18:09:39,251 INFO     Training average loss at step 9200: 0.192577\n",
      "2023-12-04 18:09:51,141 INFO     Training average positive_sample_loss at step 9300: 0.203068\n",
      "2023-12-04 18:09:51,142 INFO     Training average negative_sample_loss at step 9300: 0.184706\n",
      "2023-12-04 18:09:51,142 INFO     Training average loss at step 9300: 0.193887\n",
      "2023-12-04 18:10:03,117 INFO     Training average positive_sample_loss at step 9400: 0.205423\n",
      "2023-12-04 18:10:03,117 INFO     Training average negative_sample_loss at step 9400: 0.188750\n",
      "2023-12-04 18:10:03,118 INFO     Training average loss at step 9400: 0.197086\n",
      "2023-12-04 18:10:15,189 INFO     Training average positive_sample_loss at step 9500: 0.206132\n",
      "2023-12-04 18:10:15,189 INFO     Training average negative_sample_loss at step 9500: 0.189645\n",
      "2023-12-04 18:10:15,189 INFO     Training average loss at step 9500: 0.197888\n",
      "2023-12-04 18:10:27,748 INFO     Training average positive_sample_loss at step 9600: 0.200474\n",
      "2023-12-04 18:10:27,748 INFO     Training average negative_sample_loss at step 9600: 0.190209\n",
      "2023-12-04 18:10:27,748 INFO     Training average loss at step 9600: 0.195341\n",
      "2023-12-04 18:10:35,895 INFO     Training average positive_sample_loss at step 9700: 0.196514\n",
      "2023-12-04 18:10:35,895 INFO     Training average negative_sample_loss at step 9700: 0.185168\n",
      "2023-12-04 18:10:35,895 INFO     Training average loss at step 9700: 0.190841\n",
      "2023-12-04 18:10:47,553 INFO     Training average positive_sample_loss at step 9800: 0.201591\n",
      "2023-12-04 18:10:47,553 INFO     Training average negative_sample_loss at step 9800: 0.184381\n",
      "2023-12-04 18:10:47,553 INFO     Training average loss at step 9800: 0.192986\n",
      "2023-12-04 18:10:59,445 INFO     Training average positive_sample_loss at step 9900: 0.205055\n",
      "2023-12-04 18:10:59,445 INFO     Training average negative_sample_loss at step 9900: 0.188227\n",
      "2023-12-04 18:10:59,445 INFO     Training average loss at step 9900: 0.196641\n",
      "2023-12-04 18:11:23,017 INFO     Training average positive_sample_loss at step 10000: 0.204909\n",
      "2023-12-04 18:11:23,018 INFO     Training average negative_sample_loss at step 10000: 0.188153\n",
      "2023-12-04 18:11:23,018 INFO     Training average loss at step 10000: 0.196531\n",
      "2023-12-04 18:11:23,018 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 18:11:23,675 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 18:12:10,889 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 18:12:58,499 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 18:13:07,344 INFO     Valid MRR at step 10000: 0.331068\n",
      "2023-12-04 18:13:07,344 INFO     Valid MR at step 10000: 188.525891\n",
      "2023-12-04 18:13:07,344 INFO     Valid HITS@1 at step 10000: 0.237668\n",
      "2023-12-04 18:13:07,344 INFO     Valid HITS@3 at step 10000: 0.365726\n",
      "2023-12-04 18:13:07,344 INFO     Valid HITS@10 at step 10000: 0.518734\n",
      "2023-12-04 18:13:18,981 INFO     Training average positive_sample_loss at step 10100: 0.205715\n",
      "2023-12-04 18:13:18,981 INFO     Training average negative_sample_loss at step 10100: 0.189583\n",
      "2023-12-04 18:13:18,981 INFO     Training average loss at step 10100: 0.197649\n",
      "2023-12-04 18:13:31,087 INFO     Training average positive_sample_loss at step 10200: 0.192426\n",
      "2023-12-04 18:13:31,087 INFO     Training average negative_sample_loss at step 10200: 0.185641\n",
      "2023-12-04 18:13:31,087 INFO     Training average loss at step 10200: 0.189034\n",
      "2023-12-04 18:13:42,915 INFO     Training average positive_sample_loss at step 10300: 0.200682\n",
      "2023-12-04 18:13:42,915 INFO     Training average negative_sample_loss at step 10300: 0.183996\n",
      "2023-12-04 18:13:42,915 INFO     Training average loss at step 10300: 0.192339\n",
      "2023-12-04 18:13:54,688 INFO     Training average positive_sample_loss at step 10400: 0.203645\n",
      "2023-12-04 18:13:54,689 INFO     Training average negative_sample_loss at step 10400: 0.185319\n",
      "2023-12-04 18:13:54,689 INFO     Training average loss at step 10400: 0.194482\n",
      "2023-12-04 18:14:02,831 INFO     Training average positive_sample_loss at step 10500: 0.204782\n",
      "2023-12-04 18:14:02,832 INFO     Training average negative_sample_loss at step 10500: 0.187705\n",
      "2023-12-04 18:14:02,832 INFO     Training average loss at step 10500: 0.196243\n",
      "2023-12-04 18:14:14,582 INFO     Training average positive_sample_loss at step 10600: 0.204884\n",
      "2023-12-04 18:14:14,582 INFO     Training average negative_sample_loss at step 10600: 0.188495\n",
      "2023-12-04 18:14:14,582 INFO     Training average loss at step 10600: 0.196689\n",
      "2023-12-04 18:14:26,851 INFO     Training average positive_sample_loss at step 10700: 0.195210\n",
      "2023-12-04 18:14:26,852 INFO     Training average negative_sample_loss at step 10700: 0.186742\n",
      "2023-12-04 18:14:26,852 INFO     Training average loss at step 10700: 0.190976\n",
      "2023-12-04 18:14:38,774 INFO     Training average positive_sample_loss at step 10800: 0.197205\n",
      "2023-12-04 18:14:38,774 INFO     Training average negative_sample_loss at step 10800: 0.181464\n",
      "2023-12-04 18:14:38,774 INFO     Training average loss at step 10800: 0.189335\n",
      "2023-12-04 18:14:50,692 INFO     Training average positive_sample_loss at step 10900: 0.202484\n",
      "2023-12-04 18:14:50,692 INFO     Training average negative_sample_loss at step 10900: 0.184789\n",
      "2023-12-04 18:14:50,692 INFO     Training average loss at step 10900: 0.193637\n",
      "2023-12-04 18:15:02,768 INFO     Training average positive_sample_loss at step 11000: 0.203629\n",
      "2023-12-04 18:15:02,769 INFO     Training average negative_sample_loss at step 11000: 0.186480\n",
      "2023-12-04 18:15:02,769 INFO     Training average loss at step 11000: 0.195054\n",
      "2023-12-04 18:15:11,075 INFO     Training average positive_sample_loss at step 11100: 0.204778\n",
      "2023-12-04 18:15:11,076 INFO     Training average negative_sample_loss at step 11100: 0.188213\n",
      "2023-12-04 18:15:11,076 INFO     Training average loss at step 11100: 0.196496\n",
      "2023-12-04 18:15:23,198 INFO     Training average positive_sample_loss at step 11200: 0.200119\n",
      "2023-12-04 18:15:23,198 INFO     Training average negative_sample_loss at step 11200: 0.187660\n",
      "2023-12-04 18:15:23,198 INFO     Training average loss at step 11200: 0.193890\n",
      "2023-12-04 18:15:34,752 INFO     Training average positive_sample_loss at step 11300: 0.194757\n",
      "2023-12-04 18:15:34,752 INFO     Training average negative_sample_loss at step 11300: 0.182873\n",
      "2023-12-04 18:15:34,752 INFO     Training average loss at step 11300: 0.188815\n",
      "2023-12-04 18:15:46,456 INFO     Training average positive_sample_loss at step 11400: 0.201076\n",
      "2023-12-04 18:15:46,457 INFO     Training average negative_sample_loss at step 11400: 0.182541\n",
      "2023-12-04 18:15:46,457 INFO     Training average loss at step 11400: 0.191809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:15:58,124 INFO     Training average positive_sample_loss at step 11500: 0.203623\n",
      "2023-12-04 18:15:58,124 INFO     Training average negative_sample_loss at step 11500: 0.185273\n",
      "2023-12-04 18:15:58,124 INFO     Training average loss at step 11500: 0.194448\n",
      "2023-12-04 18:16:09,928 INFO     Training average positive_sample_loss at step 11600: 0.204133\n",
      "2023-12-04 18:16:09,928 INFO     Training average negative_sample_loss at step 11600: 0.187200\n",
      "2023-12-04 18:16:09,928 INFO     Training average loss at step 11600: 0.195667\n",
      "2023-12-04 18:16:19,449 INFO     Training average positive_sample_loss at step 11700: 0.204100\n",
      "2023-12-04 18:16:19,449 INFO     Training average negative_sample_loss at step 11700: 0.187637\n",
      "2023-12-04 18:16:19,449 INFO     Training average loss at step 11700: 0.195868\n",
      "2023-12-04 18:16:31,351 INFO     Training average positive_sample_loss at step 11800: 0.191360\n",
      "2023-12-04 18:16:31,351 INFO     Training average negative_sample_loss at step 11800: 0.183224\n",
      "2023-12-04 18:16:31,351 INFO     Training average loss at step 11800: 0.187292\n",
      "2023-12-04 18:16:42,987 INFO     Training average positive_sample_loss at step 11900: 0.199042\n",
      "2023-12-04 18:16:42,987 INFO     Training average negative_sample_loss at step 11900: 0.182432\n",
      "2023-12-04 18:16:42,987 INFO     Training average loss at step 11900: 0.190737\n",
      "2023-12-04 18:16:54,853 INFO     Training average positive_sample_loss at step 12000: 0.203281\n",
      "2023-12-04 18:16:54,854 INFO     Training average negative_sample_loss at step 12000: 0.185676\n",
      "2023-12-04 18:16:54,854 INFO     Training average loss at step 12000: 0.194478\n",
      "2023-12-04 18:17:06,807 INFO     Training average positive_sample_loss at step 12100: 0.204057\n",
      "2023-12-04 18:17:06,807 INFO     Training average negative_sample_loss at step 12100: 0.185865\n",
      "2023-12-04 18:17:06,807 INFO     Training average loss at step 12100: 0.194961\n",
      "2023-12-04 18:17:18,747 INFO     Training average positive_sample_loss at step 12200: 0.203788\n",
      "2023-12-04 18:17:18,747 INFO     Training average negative_sample_loss at step 12200: 0.186681\n",
      "2023-12-04 18:17:18,748 INFO     Training average loss at step 12200: 0.195235\n",
      "2023-12-04 18:17:29,324 INFO     Training average positive_sample_loss at step 12300: 0.194739\n",
      "2023-12-04 18:17:29,324 INFO     Training average negative_sample_loss at step 12300: 0.185846\n",
      "2023-12-04 18:17:29,324 INFO     Training average loss at step 12300: 0.190293\n",
      "2023-12-04 18:17:39,146 INFO     Training average positive_sample_loss at step 12400: 0.197203\n",
      "2023-12-04 18:17:39,147 INFO     Training average negative_sample_loss at step 12400: 0.180227\n",
      "2023-12-04 18:17:39,147 INFO     Training average loss at step 12400: 0.188715\n",
      "2023-12-04 18:17:50,845 INFO     Training average positive_sample_loss at step 12500: 0.201462\n",
      "2023-12-04 18:17:50,846 INFO     Training average negative_sample_loss at step 12500: 0.183894\n",
      "2023-12-04 18:17:50,846 INFO     Training average loss at step 12500: 0.192678\n",
      "2023-12-04 18:18:02,619 INFO     Training average positive_sample_loss at step 12600: 0.203297\n",
      "2023-12-04 18:18:02,619 INFO     Training average negative_sample_loss at step 12600: 0.184713\n",
      "2023-12-04 18:18:02,620 INFO     Training average loss at step 12600: 0.194005\n",
      "2023-12-04 18:18:14,533 INFO     Training average positive_sample_loss at step 12700: 0.203688\n",
      "2023-12-04 18:18:14,533 INFO     Training average negative_sample_loss at step 12700: 0.185944\n",
      "2023-12-04 18:18:14,533 INFO     Training average loss at step 12700: 0.194816\n",
      "2023-12-04 18:18:26,957 INFO     Training average positive_sample_loss at step 12800: 0.197466\n",
      "2023-12-04 18:18:26,957 INFO     Training average negative_sample_loss at step 12800: 0.185208\n",
      "2023-12-04 18:18:26,957 INFO     Training average loss at step 12800: 0.191337\n",
      "2023-12-04 18:18:38,484 INFO     Training average positive_sample_loss at step 12900: 0.194723\n",
      "2023-12-04 18:18:38,484 INFO     Training average negative_sample_loss at step 12900: 0.180977\n",
      "2023-12-04 18:18:38,484 INFO     Training average loss at step 12900: 0.187850\n",
      "2023-12-04 18:18:46,723 INFO     Training average positive_sample_loss at step 13000: 0.200147\n",
      "2023-12-04 18:18:46,723 INFO     Training average negative_sample_loss at step 13000: 0.181587\n",
      "2023-12-04 18:18:46,723 INFO     Training average loss at step 13000: 0.190867\n",
      "2023-12-04 18:18:58,382 INFO     Training average positive_sample_loss at step 13100: 0.202553\n",
      "2023-12-04 18:18:58,382 INFO     Training average negative_sample_loss at step 13100: 0.184547\n",
      "2023-12-04 18:18:58,382 INFO     Training average loss at step 13100: 0.193550\n",
      "2023-12-04 18:19:10,114 INFO     Training average positive_sample_loss at step 13200: 0.202778\n",
      "2023-12-04 18:19:10,114 INFO     Training average negative_sample_loss at step 13200: 0.184265\n",
      "2023-12-04 18:19:10,114 INFO     Training average loss at step 13200: 0.193522\n",
      "2023-12-04 18:19:22,252 INFO     Training average positive_sample_loss at step 13300: 0.203737\n",
      "2023-12-04 18:19:22,252 INFO     Training average negative_sample_loss at step 13300: 0.187420\n",
      "2023-12-04 18:19:22,252 INFO     Training average loss at step 13300: 0.195578\n",
      "2023-12-04 18:19:34,005 INFO     Training average positive_sample_loss at step 13400: 0.190879\n",
      "2023-12-04 18:19:34,005 INFO     Training average negative_sample_loss at step 13400: 0.182871\n",
      "2023-12-04 18:19:34,005 INFO     Training average loss at step 13400: 0.186875\n",
      "2023-12-04 18:19:45,941 INFO     Training average positive_sample_loss at step 13500: 0.199059\n",
      "2023-12-04 18:19:45,941 INFO     Training average negative_sample_loss at step 13500: 0.181244\n",
      "2023-12-04 18:19:45,941 INFO     Training average loss at step 13500: 0.190152\n",
      "2023-12-04 18:19:54,347 INFO     Training average positive_sample_loss at step 13600: 0.201996\n",
      "2023-12-04 18:19:54,348 INFO     Training average negative_sample_loss at step 13600: 0.182367\n",
      "2023-12-04 18:19:54,348 INFO     Training average loss at step 13600: 0.192182\n",
      "2023-12-04 18:20:05,835 INFO     Training average positive_sample_loss at step 13700: 0.202570\n",
      "2023-12-04 18:20:05,835 INFO     Training average negative_sample_loss at step 13700: 0.184015\n",
      "2023-12-04 18:20:05,835 INFO     Training average loss at step 13700: 0.193293\n",
      "2023-12-04 18:20:17,733 INFO     Training average positive_sample_loss at step 13800: 0.203959\n",
      "2023-12-04 18:20:17,733 INFO     Training average negative_sample_loss at step 13800: 0.186792\n",
      "2023-12-04 18:20:17,733 INFO     Training average loss at step 13800: 0.195375\n",
      "2023-12-04 18:20:29,880 INFO     Training average positive_sample_loss at step 13900: 0.193051\n",
      "2023-12-04 18:20:29,880 INFO     Training average negative_sample_loss at step 13900: 0.182491\n",
      "2023-12-04 18:20:29,880 INFO     Training average loss at step 13900: 0.187771\n",
      "2023-12-04 18:20:41,632 INFO     Training average positive_sample_loss at step 14000: 0.196792\n",
      "2023-12-04 18:20:41,632 INFO     Training average negative_sample_loss at step 14000: 0.180086\n",
      "2023-12-04 18:20:41,633 INFO     Training average loss at step 14000: 0.188439\n",
      "2023-12-04 18:20:53,380 INFO     Training average positive_sample_loss at step 14100: 0.200980\n",
      "2023-12-04 18:20:53,381 INFO     Training average negative_sample_loss at step 14100: 0.181969\n",
      "2023-12-04 18:20:53,381 INFO     Training average loss at step 14100: 0.191474\n",
      "2023-12-04 18:21:02,724 INFO     Training average positive_sample_loss at step 14200: 0.202108\n",
      "2023-12-04 18:21:02,725 INFO     Training average negative_sample_loss at step 14200: 0.183930\n",
      "2023-12-04 18:21:02,725 INFO     Training average loss at step 14200: 0.193019\n",
      "2023-12-04 18:21:09,895 INFO     Training average positive_sample_loss at step 14300: 0.202943\n",
      "2023-12-04 18:21:09,895 INFO     Training average negative_sample_loss at step 14300: 0.184685\n",
      "2023-12-04 18:21:09,895 INFO     Training average loss at step 14300: 0.193814\n",
      "2023-12-04 18:21:17,897 INFO     Training average positive_sample_loss at step 14400: 0.196562\n",
      "2023-12-04 18:21:17,897 INFO     Training average negative_sample_loss at step 14400: 0.185595\n",
      "2023-12-04 18:21:17,897 INFO     Training average loss at step 14400: 0.191078\n",
      "2023-12-04 18:21:27,972 INFO     Training average positive_sample_loss at step 14500: 0.194724\n",
      "2023-12-04 18:21:27,972 INFO     Training average negative_sample_loss at step 14500: 0.179668\n",
      "2023-12-04 18:21:27,972 INFO     Training average loss at step 14500: 0.187196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:21:36,279 INFO     Training average positive_sample_loss at step 14600: 0.199200\n",
      "2023-12-04 18:21:36,279 INFO     Training average negative_sample_loss at step 14600: 0.180248\n",
      "2023-12-04 18:21:36,279 INFO     Training average loss at step 14600: 0.189724\n",
      "2023-12-04 18:21:45,397 INFO     Training average positive_sample_loss at step 14700: 0.201537\n",
      "2023-12-04 18:21:45,397 INFO     Training average negative_sample_loss at step 14700: 0.182203\n",
      "2023-12-04 18:21:45,397 INFO     Training average loss at step 14700: 0.191870\n",
      "2023-12-04 18:21:54,048 INFO     Training average positive_sample_loss at step 14800: 0.203096\n",
      "2023-12-04 18:21:54,049 INFO     Training average negative_sample_loss at step 14800: 0.184538\n",
      "2023-12-04 18:21:54,049 INFO     Training average loss at step 14800: 0.193817\n",
      "2023-12-04 18:22:03,118 INFO     Training average positive_sample_loss at step 14900: 0.202207\n",
      "2023-12-04 18:22:03,118 INFO     Training average negative_sample_loss at step 14900: 0.185531\n",
      "2023-12-04 18:22:03,118 INFO     Training average loss at step 14900: 0.193869\n",
      "2023-12-04 18:22:11,812 INFO     Training average positive_sample_loss at step 15000: 0.190755\n",
      "2023-12-04 18:22:11,812 INFO     Training average negative_sample_loss at step 15000: 0.180650\n",
      "2023-12-04 18:22:11,812 INFO     Training average loss at step 15000: 0.185702\n",
      "2023-12-04 18:22:20,554 INFO     Training average positive_sample_loss at step 15100: 0.198759\n",
      "2023-12-04 18:22:20,554 INFO     Training average negative_sample_loss at step 15100: 0.179959\n",
      "2023-12-04 18:22:20,554 INFO     Training average loss at step 15100: 0.189359\n",
      "2023-12-04 18:22:31,347 INFO     Training average positive_sample_loss at step 15200: 0.201578\n",
      "2023-12-04 18:22:31,347 INFO     Training average negative_sample_loss at step 15200: 0.182785\n",
      "2023-12-04 18:22:31,347 INFO     Training average loss at step 15200: 0.192181\n",
      "2023-12-04 18:22:43,296 INFO     Training average positive_sample_loss at step 15300: 0.202084\n",
      "2023-12-04 18:22:43,297 INFO     Training average negative_sample_loss at step 15300: 0.183315\n",
      "2023-12-04 18:22:43,297 INFO     Training average loss at step 15300: 0.192699\n",
      "2023-12-04 18:22:55,161 INFO     Training average positive_sample_loss at step 15400: 0.202612\n",
      "2023-12-04 18:22:55,161 INFO     Training average negative_sample_loss at step 15400: 0.185437\n",
      "2023-12-04 18:22:55,161 INFO     Training average loss at step 15400: 0.194024\n",
      "2023-12-04 18:23:07,360 INFO     Training average positive_sample_loss at step 15500: 0.192738\n",
      "2023-12-04 18:23:07,361 INFO     Training average negative_sample_loss at step 15500: 0.182981\n",
      "2023-12-04 18:23:07,361 INFO     Training average loss at step 15500: 0.187860\n",
      "2023-12-04 18:23:19,051 INFO     Training average positive_sample_loss at step 15600: 0.196948\n",
      "2023-12-04 18:23:19,051 INFO     Training average negative_sample_loss at step 15600: 0.179454\n",
      "2023-12-04 18:23:19,051 INFO     Training average loss at step 15600: 0.188201\n",
      "2023-12-04 18:23:28,981 INFO     Training average positive_sample_loss at step 15700: 0.201003\n",
      "2023-12-04 18:23:28,982 INFO     Training average negative_sample_loss at step 15700: 0.182040\n",
      "2023-12-04 18:23:28,982 INFO     Training average loss at step 15700: 0.191521\n",
      "2023-12-04 18:23:38,990 INFO     Training average positive_sample_loss at step 15800: 0.201803\n",
      "2023-12-04 18:23:38,991 INFO     Training average negative_sample_loss at step 15800: 0.182903\n",
      "2023-12-04 18:23:38,991 INFO     Training average loss at step 15800: 0.192353\n",
      "2023-12-04 18:23:50,743 INFO     Training average positive_sample_loss at step 15900: 0.202582\n",
      "2023-12-04 18:23:50,744 INFO     Training average negative_sample_loss at step 15900: 0.184851\n",
      "2023-12-04 18:23:50,744 INFO     Training average loss at step 15900: 0.193716\n",
      "2023-12-04 18:24:03,212 INFO     Training average positive_sample_loss at step 16000: 0.195947\n",
      "2023-12-04 18:24:03,213 INFO     Training average negative_sample_loss at step 16000: 0.184145\n",
      "2023-12-04 18:24:03,213 INFO     Training average loss at step 16000: 0.190046\n",
      "2023-12-04 18:24:15,065 INFO     Training average positive_sample_loss at step 16100: 0.194785\n",
      "2023-12-04 18:24:15,066 INFO     Training average negative_sample_loss at step 16100: 0.180260\n",
      "2023-12-04 18:24:15,066 INFO     Training average loss at step 16100: 0.187522\n",
      "2023-12-04 18:24:27,055 INFO     Training average positive_sample_loss at step 16200: 0.199820\n",
      "2023-12-04 18:24:27,056 INFO     Training average negative_sample_loss at step 16200: 0.179879\n",
      "2023-12-04 18:24:27,056 INFO     Training average loss at step 16200: 0.189849\n",
      "2023-12-04 18:24:38,162 INFO     Training average positive_sample_loss at step 16300: 0.201761\n",
      "2023-12-04 18:24:38,162 INFO     Training average negative_sample_loss at step 16300: 0.183441\n",
      "2023-12-04 18:24:38,162 INFO     Training average loss at step 16300: 0.192601\n",
      "2023-12-04 18:24:47,192 INFO     Training average positive_sample_loss at step 16400: 0.202565\n",
      "2023-12-04 18:24:47,192 INFO     Training average negative_sample_loss at step 16400: 0.183535\n",
      "2023-12-04 18:24:47,192 INFO     Training average loss at step 16400: 0.193050\n",
      "2023-12-04 18:24:59,579 INFO     Training average positive_sample_loss at step 16500: 0.200116\n",
      "2023-12-04 18:24:59,579 INFO     Training average negative_sample_loss at step 16500: 0.184591\n",
      "2023-12-04 18:24:59,579 INFO     Training average loss at step 16500: 0.192354\n",
      "2023-12-04 18:25:11,024 INFO     Training average positive_sample_loss at step 16600: 0.191571\n",
      "2023-12-04 18:25:11,024 INFO     Training average negative_sample_loss at step 16600: 0.180043\n",
      "2023-12-04 18:25:11,024 INFO     Training average loss at step 16600: 0.185807\n",
      "2023-12-04 18:25:22,877 INFO     Training average positive_sample_loss at step 16700: 0.198572\n",
      "2023-12-04 18:25:22,878 INFO     Training average negative_sample_loss at step 16700: 0.180121\n",
      "2023-12-04 18:25:22,878 INFO     Training average loss at step 16700: 0.189347\n",
      "2023-12-04 18:25:34,924 INFO     Training average positive_sample_loss at step 16800: 0.201397\n",
      "2023-12-04 18:25:34,925 INFO     Training average negative_sample_loss at step 16800: 0.181437\n",
      "2023-12-04 18:25:34,925 INFO     Training average loss at step 16800: 0.191417\n",
      "2023-12-04 18:25:46,942 INFO     Training average positive_sample_loss at step 16900: 0.202315\n",
      "2023-12-04 18:25:46,942 INFO     Training average negative_sample_loss at step 16900: 0.185246\n",
      "2023-12-04 18:25:46,942 INFO     Training average loss at step 16900: 0.193780\n",
      "2023-12-04 18:25:55,150 INFO     Training average positive_sample_loss at step 17000: 0.202269\n",
      "2023-12-04 18:25:55,150 INFO     Training average negative_sample_loss at step 17000: 0.183600\n",
      "2023-12-04 18:25:55,150 INFO     Training average loss at step 17000: 0.192935\n",
      "2023-12-04 18:26:07,235 INFO     Training average positive_sample_loss at step 17100: 0.191863\n",
      "2023-12-04 18:26:07,236 INFO     Training average negative_sample_loss at step 17100: 0.182390\n",
      "2023-12-04 18:26:07,236 INFO     Training average loss at step 17100: 0.187126\n",
      "2023-12-04 18:26:19,037 INFO     Training average positive_sample_loss at step 17200: 0.197607\n",
      "2023-12-04 18:26:19,037 INFO     Training average negative_sample_loss at step 17200: 0.178443\n",
      "2023-12-04 18:26:19,037 INFO     Training average loss at step 17200: 0.188025\n",
      "2023-12-04 18:26:30,959 INFO     Training average positive_sample_loss at step 17300: 0.199622\n",
      "2023-12-04 18:26:30,959 INFO     Training average negative_sample_loss at step 17300: 0.180328\n",
      "2023-12-04 18:26:30,959 INFO     Training average loss at step 17300: 0.189975\n",
      "2023-12-04 18:26:42,939 INFO     Training average positive_sample_loss at step 17400: 0.201212\n",
      "2023-12-04 18:26:42,940 INFO     Training average negative_sample_loss at step 17400: 0.182590\n",
      "2023-12-04 18:26:42,940 INFO     Training average loss at step 17400: 0.191901\n",
      "2023-12-04 18:26:54,781 INFO     Training average positive_sample_loss at step 17500: 0.201802\n",
      "2023-12-04 18:26:54,781 INFO     Training average negative_sample_loss at step 17500: 0.182794\n",
      "2023-12-04 18:26:54,781 INFO     Training average loss at step 17500: 0.192298\n",
      "2023-12-04 18:27:04,797 INFO     Training average positive_sample_loss at step 17600: 0.194854\n",
      "2023-12-04 18:27:04,798 INFO     Training average negative_sample_loss at step 17600: 0.183188\n",
      "2023-12-04 18:27:04,798 INFO     Training average loss at step 17600: 0.189021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:27:16,474 INFO     Training average positive_sample_loss at step 17700: 0.194654\n",
      "2023-12-04 18:27:16,475 INFO     Training average negative_sample_loss at step 17700: 0.178825\n",
      "2023-12-04 18:27:16,475 INFO     Training average loss at step 17700: 0.186740\n",
      "2023-12-04 18:27:28,434 INFO     Training average positive_sample_loss at step 17800: 0.199374\n",
      "2023-12-04 18:27:28,435 INFO     Training average negative_sample_loss at step 17800: 0.180296\n",
      "2023-12-04 18:27:28,435 INFO     Training average loss at step 17800: 0.189835\n",
      "2023-12-04 18:27:40,255 INFO     Training average positive_sample_loss at step 17900: 0.201369\n",
      "2023-12-04 18:27:40,255 INFO     Training average negative_sample_loss at step 17900: 0.181930\n",
      "2023-12-04 18:27:40,255 INFO     Training average loss at step 17900: 0.191649\n",
      "2023-12-04 18:27:52,011 INFO     Training average positive_sample_loss at step 18000: 0.202292\n",
      "2023-12-04 18:27:52,011 INFO     Training average negative_sample_loss at step 18000: 0.182516\n",
      "2023-12-04 18:27:52,011 INFO     Training average loss at step 18000: 0.192404\n",
      "2023-12-04 18:28:04,418 INFO     Training average positive_sample_loss at step 18100: 0.199288\n",
      "2023-12-04 18:28:04,419 INFO     Training average negative_sample_loss at step 18100: 0.182967\n",
      "2023-12-04 18:28:04,419 INFO     Training average loss at step 18100: 0.191128\n",
      "2023-12-04 18:28:12,481 INFO     Training average positive_sample_loss at step 18200: 0.191372\n",
      "2023-12-04 18:28:12,482 INFO     Training average negative_sample_loss at step 18200: 0.179757\n",
      "2023-12-04 18:28:12,482 INFO     Training average loss at step 18200: 0.185565\n",
      "2023-12-04 18:28:24,055 INFO     Training average positive_sample_loss at step 18300: 0.198071\n",
      "2023-12-04 18:28:24,056 INFO     Training average negative_sample_loss at step 18300: 0.178260\n",
      "2023-12-04 18:28:24,056 INFO     Training average loss at step 18300: 0.188166\n",
      "2023-12-04 18:28:35,675 INFO     Training average positive_sample_loss at step 18400: 0.200926\n",
      "2023-12-04 18:28:35,676 INFO     Training average negative_sample_loss at step 18400: 0.180570\n",
      "2023-12-04 18:28:35,676 INFO     Training average loss at step 18400: 0.190748\n",
      "2023-12-04 18:28:47,450 INFO     Training average positive_sample_loss at step 18500: 0.201423\n",
      "2023-12-04 18:28:47,450 INFO     Training average negative_sample_loss at step 18500: 0.181750\n",
      "2023-12-04 18:28:47,450 INFO     Training average loss at step 18500: 0.191586\n",
      "2023-12-04 18:28:59,515 INFO     Training average positive_sample_loss at step 18600: 0.201844\n",
      "2023-12-04 18:28:59,516 INFO     Training average negative_sample_loss at step 18600: 0.184654\n",
      "2023-12-04 18:28:59,516 INFO     Training average loss at step 18600: 0.193249\n",
      "2023-12-04 18:29:11,806 INFO     Training average positive_sample_loss at step 18700: 0.191056\n",
      "2023-12-04 18:29:11,806 INFO     Training average negative_sample_loss at step 18700: 0.180163\n",
      "2023-12-04 18:29:11,806 INFO     Training average loss at step 18700: 0.185609\n",
      "2023-12-04 18:29:21,289 INFO     Training average positive_sample_loss at step 18800: 0.196948\n",
      "2023-12-04 18:29:21,290 INFO     Training average negative_sample_loss at step 18800: 0.178333\n",
      "2023-12-04 18:29:21,290 INFO     Training average loss at step 18800: 0.187640\n",
      "2023-12-04 18:29:31,643 INFO     Training average positive_sample_loss at step 18900: 0.200211\n",
      "2023-12-04 18:29:31,644 INFO     Training average negative_sample_loss at step 18900: 0.179514\n",
      "2023-12-04 18:29:31,644 INFO     Training average loss at step 18900: 0.189863\n",
      "2023-12-04 18:29:43,438 INFO     Training average positive_sample_loss at step 19000: 0.200308\n",
      "2023-12-04 18:29:43,438 INFO     Training average negative_sample_loss at step 19000: 0.181395\n",
      "2023-12-04 18:29:43,438 INFO     Training average loss at step 19000: 0.190851\n",
      "2023-12-04 18:29:55,563 INFO     Training average positive_sample_loss at step 19100: 0.202207\n",
      "2023-12-04 18:29:55,563 INFO     Training average negative_sample_loss at step 19100: 0.183508\n",
      "2023-12-04 18:29:55,563 INFO     Training average loss at step 19100: 0.192858\n",
      "2023-12-04 18:30:08,066 INFO     Training average positive_sample_loss at step 19200: 0.193730\n",
      "2023-12-04 18:30:08,066 INFO     Training average negative_sample_loss at step 19200: 0.182360\n",
      "2023-12-04 18:30:08,066 INFO     Training average loss at step 19200: 0.188045\n",
      "2023-12-04 18:30:19,906 INFO     Training average positive_sample_loss at step 19300: 0.194770\n",
      "2023-12-04 18:30:19,907 INFO     Training average negative_sample_loss at step 19300: 0.178249\n",
      "2023-12-04 18:30:19,907 INFO     Training average loss at step 19300: 0.186509\n",
      "2023-12-04 18:30:30,533 INFO     Training average positive_sample_loss at step 19400: 0.199348\n",
      "2023-12-04 18:30:30,534 INFO     Training average negative_sample_loss at step 19400: 0.179542\n",
      "2023-12-04 18:30:30,534 INFO     Training average loss at step 19400: 0.189445\n",
      "2023-12-04 18:30:39,925 INFO     Training average positive_sample_loss at step 19500: 0.201406\n",
      "2023-12-04 18:30:39,926 INFO     Training average negative_sample_loss at step 19500: 0.182237\n",
      "2023-12-04 18:30:39,926 INFO     Training average loss at step 19500: 0.191822\n",
      "2023-12-04 18:30:51,559 INFO     Training average positive_sample_loss at step 19600: 0.202053\n",
      "2023-12-04 18:30:51,560 INFO     Training average negative_sample_loss at step 19600: 0.181831\n",
      "2023-12-04 18:30:51,560 INFO     Training average loss at step 19600: 0.191942\n",
      "2023-12-04 18:31:04,101 INFO     Training average positive_sample_loss at step 19700: 0.199163\n",
      "2023-12-04 18:31:04,101 INFO     Training average negative_sample_loss at step 19700: 0.182927\n",
      "2023-12-04 18:31:04,101 INFO     Training average loss at step 19700: 0.191045\n",
      "2023-12-04 18:31:15,689 INFO     Training average positive_sample_loss at step 19800: 0.191574\n",
      "2023-12-04 18:31:15,689 INFO     Training average negative_sample_loss at step 19800: 0.178149\n",
      "2023-12-04 18:31:15,689 INFO     Training average loss at step 19800: 0.184862\n",
      "2023-12-04 18:31:27,544 INFO     Training average positive_sample_loss at step 19900: 0.197714\n",
      "2023-12-04 18:31:27,544 INFO     Training average negative_sample_loss at step 19900: 0.178369\n",
      "2023-12-04 18:31:27,544 INFO     Training average loss at step 19900: 0.188041\n",
      "2023-12-04 18:31:49,995 INFO     Training average positive_sample_loss at step 20000: 0.200638\n",
      "2023-12-04 18:31:49,996 INFO     Training average negative_sample_loss at step 20000: 0.181273\n",
      "2023-12-04 18:31:49,996 INFO     Training average loss at step 20000: 0.190956\n",
      "2023-12-04 18:31:49,996 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 18:31:50,651 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 18:32:41,498 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 18:33:29,084 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 18:33:37,746 INFO     Valid MRR at step 20000: 0.334283\n",
      "2023-12-04 18:33:37,746 INFO     Valid MR at step 20000: 175.788594\n",
      "2023-12-04 18:33:37,747 INFO     Valid HITS@1 at step 20000: 0.237896\n",
      "2023-12-04 18:33:37,747 INFO     Valid HITS@3 at step 20000: 0.370801\n",
      "2023-12-04 18:33:37,747 INFO     Valid HITS@10 at step 20000: 0.527431\n",
      "2023-12-04 18:33:49,116 INFO     Training average positive_sample_loss at step 20100: 0.200861\n",
      "2023-12-04 18:33:49,116 INFO     Training average negative_sample_loss at step 20100: 0.181170\n",
      "2023-12-04 18:33:49,116 INFO     Training average loss at step 20100: 0.191016\n",
      "2023-12-04 18:34:00,431 INFO     Training average positive_sample_loss at step 20200: 0.201554\n",
      "2023-12-04 18:34:00,431 INFO     Training average negative_sample_loss at step 20200: 0.183842\n",
      "2023-12-04 18:34:00,431 INFO     Training average loss at step 20200: 0.192698\n",
      "2023-12-04 18:34:10,865 INFO     Training average positive_sample_loss at step 20300: 0.191051\n",
      "2023-12-04 18:34:10,866 INFO     Training average negative_sample_loss at step 20300: 0.180339\n",
      "2023-12-04 18:34:10,866 INFO     Training average loss at step 20300: 0.185695\n",
      "2023-12-04 18:34:22,583 INFO     Training average positive_sample_loss at step 20400: 0.197540\n",
      "2023-12-04 18:34:22,583 INFO     Training average negative_sample_loss at step 20400: 0.178111\n",
      "2023-12-04 18:34:22,583 INFO     Training average loss at step 20400: 0.187825\n",
      "2023-12-04 18:34:34,542 INFO     Training average positive_sample_loss at step 20500: 0.199915\n",
      "2023-12-04 18:34:34,543 INFO     Training average negative_sample_loss at step 20500: 0.180400\n",
      "2023-12-04 18:34:34,543 INFO     Training average loss at step 20500: 0.190157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:34:46,246 INFO     Training average positive_sample_loss at step 20600: 0.201179\n",
      "2023-12-04 18:34:46,246 INFO     Training average negative_sample_loss at step 20600: 0.181554\n",
      "2023-12-04 18:34:46,246 INFO     Training average loss at step 20600: 0.191366\n",
      "2023-12-04 18:34:58,008 INFO     Training average positive_sample_loss at step 20700: 0.200561\n",
      "2023-12-04 18:34:58,009 INFO     Training average negative_sample_loss at step 20700: 0.181398\n",
      "2023-12-04 18:34:58,009 INFO     Training average loss at step 20700: 0.190979\n",
      "2023-12-04 18:35:10,461 INFO     Training average positive_sample_loss at step 20800: 0.194209\n",
      "2023-12-04 18:35:10,461 INFO     Training average negative_sample_loss at step 20800: 0.182655\n",
      "2023-12-04 18:35:10,461 INFO     Training average loss at step 20800: 0.188432\n",
      "2023-12-04 18:35:18,533 INFO     Training average positive_sample_loss at step 20900: 0.194766\n",
      "2023-12-04 18:35:18,534 INFO     Training average negative_sample_loss at step 20900: 0.176618\n",
      "2023-12-04 18:35:18,534 INFO     Training average loss at step 20900: 0.185692\n",
      "2023-12-04 18:35:30,141 INFO     Training average positive_sample_loss at step 21000: 0.198901\n",
      "2023-12-04 18:35:30,141 INFO     Training average negative_sample_loss at step 21000: 0.179138\n",
      "2023-12-04 18:35:30,141 INFO     Training average loss at step 21000: 0.189019\n",
      "2023-12-04 18:35:41,941 INFO     Training average positive_sample_loss at step 21100: 0.200468\n",
      "2023-12-04 18:35:41,942 INFO     Training average negative_sample_loss at step 21100: 0.180768\n",
      "2023-12-04 18:35:41,942 INFO     Training average loss at step 21100: 0.190618\n",
      "2023-12-04 18:35:53,733 INFO     Training average positive_sample_loss at step 21200: 0.200487\n",
      "2023-12-04 18:35:53,733 INFO     Training average negative_sample_loss at step 21200: 0.180297\n",
      "2023-12-04 18:35:53,733 INFO     Training average loss at step 21200: 0.190392\n",
      "2023-12-04 18:36:06,471 INFO     Training average positive_sample_loss at step 21300: 0.198201\n",
      "2023-12-04 18:36:06,471 INFO     Training average negative_sample_loss at step 21300: 0.182571\n",
      "2023-12-04 18:36:06,471 INFO     Training average loss at step 21300: 0.190386\n",
      "2023-12-04 18:36:18,129 INFO     Training average positive_sample_loss at step 21400: 0.191662\n",
      "2023-12-04 18:36:18,129 INFO     Training average negative_sample_loss at step 21400: 0.177516\n",
      "2023-12-04 18:36:18,129 INFO     Training average loss at step 21400: 0.184589\n",
      "2023-12-04 18:36:26,423 INFO     Training average positive_sample_loss at step 21500: 0.198365\n",
      "2023-12-04 18:36:26,424 INFO     Training average negative_sample_loss at step 21500: 0.177493\n",
      "2023-12-04 18:36:26,424 INFO     Training average loss at step 21500: 0.187929\n",
      "2023-12-04 18:36:38,046 INFO     Training average positive_sample_loss at step 21600: 0.200209\n",
      "2023-12-04 18:36:38,046 INFO     Training average negative_sample_loss at step 21600: 0.180852\n",
      "2023-12-04 18:36:38,046 INFO     Training average loss at step 21600: 0.190531\n",
      "2023-12-04 18:36:49,803 INFO     Training average positive_sample_loss at step 21700: 0.200409\n",
      "2023-12-04 18:36:49,803 INFO     Training average negative_sample_loss at step 21700: 0.180917\n",
      "2023-12-04 18:36:49,803 INFO     Training average loss at step 21700: 0.190663\n",
      "2023-12-04 18:37:01,659 INFO     Training average positive_sample_loss at step 21800: 0.201101\n",
      "2023-12-04 18:37:01,659 INFO     Training average negative_sample_loss at step 21800: 0.182079\n",
      "2023-12-04 18:37:01,659 INFO     Training average loss at step 21800: 0.191590\n",
      "2023-12-04 18:37:13,604 INFO     Training average positive_sample_loss at step 21900: 0.190151\n",
      "2023-12-04 18:37:13,604 INFO     Training average negative_sample_loss at step 21900: 0.178452\n",
      "2023-12-04 18:37:13,604 INFO     Training average loss at step 21900: 0.184302\n",
      "2023-12-04 18:37:25,388 INFO     Training average positive_sample_loss at step 22000: 0.197282\n",
      "2023-12-04 18:37:25,389 INFO     Training average negative_sample_loss at step 22000: 0.177627\n",
      "2023-12-04 18:37:25,389 INFO     Training average loss at step 22000: 0.187455\n",
      "2023-12-04 18:37:34,496 INFO     Training average positive_sample_loss at step 22100: 0.199748\n",
      "2023-12-04 18:37:34,496 INFO     Training average negative_sample_loss at step 22100: 0.180126\n",
      "2023-12-04 18:37:34,496 INFO     Training average loss at step 22100: 0.189937\n",
      "2023-12-04 18:37:45,449 INFO     Training average positive_sample_loss at step 22200: 0.199530\n",
      "2023-12-04 18:37:45,449 INFO     Training average negative_sample_loss at step 22200: 0.179949\n",
      "2023-12-04 18:37:45,449 INFO     Training average loss at step 22200: 0.189739\n",
      "2023-12-04 18:37:57,332 INFO     Training average positive_sample_loss at step 22300: 0.201769\n",
      "2023-12-04 18:37:57,333 INFO     Training average negative_sample_loss at step 22300: 0.182381\n",
      "2023-12-04 18:37:57,333 INFO     Training average loss at step 22300: 0.192075\n",
      "2023-12-04 18:38:09,668 INFO     Training average positive_sample_loss at step 22400: 0.193031\n",
      "2023-12-04 18:38:09,668 INFO     Training average negative_sample_loss at step 22400: 0.180135\n",
      "2023-12-04 18:38:09,669 INFO     Training average loss at step 22400: 0.186583\n",
      "2023-12-04 18:38:21,501 INFO     Training average positive_sample_loss at step 22500: 0.194414\n",
      "2023-12-04 18:38:21,501 INFO     Training average negative_sample_loss at step 22500: 0.176025\n",
      "2023-12-04 18:38:21,501 INFO     Training average loss at step 22500: 0.185220\n",
      "2023-12-04 18:38:33,581 INFO     Training average positive_sample_loss at step 22600: 0.198504\n",
      "2023-12-04 18:38:33,582 INFO     Training average negative_sample_loss at step 22600: 0.177288\n",
      "2023-12-04 18:38:33,582 INFO     Training average loss at step 22600: 0.187896\n",
      "2023-12-04 18:38:43,660 INFO     Training average positive_sample_loss at step 22700: 0.200665\n",
      "2023-12-04 18:38:43,660 INFO     Training average negative_sample_loss at step 22700: 0.180436\n",
      "2023-12-04 18:38:43,660 INFO     Training average loss at step 22700: 0.190551\n",
      "2023-12-04 18:38:53,850 INFO     Training average positive_sample_loss at step 22800: 0.201092\n",
      "2023-12-04 18:38:53,850 INFO     Training average negative_sample_loss at step 22800: 0.181111\n",
      "2023-12-04 18:38:53,850 INFO     Training average loss at step 22800: 0.191102\n",
      "2023-12-04 18:39:06,347 INFO     Training average positive_sample_loss at step 22900: 0.197353\n",
      "2023-12-04 18:39:06,347 INFO     Training average negative_sample_loss at step 22900: 0.182536\n",
      "2023-12-04 18:39:06,348 INFO     Training average loss at step 22900: 0.189945\n",
      "2023-12-04 18:39:17,841 INFO     Training average positive_sample_loss at step 23000: 0.192093\n",
      "2023-12-04 18:39:17,842 INFO     Training average negative_sample_loss at step 23000: 0.177652\n",
      "2023-12-04 18:39:17,842 INFO     Training average loss at step 23000: 0.184872\n",
      "2023-12-04 18:39:29,789 INFO     Training average positive_sample_loss at step 23100: 0.197792\n",
      "2023-12-04 18:39:29,790 INFO     Training average negative_sample_loss at step 23100: 0.176711\n",
      "2023-12-04 18:39:29,790 INFO     Training average loss at step 23100: 0.187252\n",
      "2023-12-04 18:39:41,685 INFO     Training average positive_sample_loss at step 23200: 0.199903\n",
      "2023-12-04 18:39:41,685 INFO     Training average negative_sample_loss at step 23200: 0.179409\n",
      "2023-12-04 18:39:41,685 INFO     Training average loss at step 23200: 0.189656\n",
      "2023-12-04 18:39:52,812 INFO     Training average positive_sample_loss at step 23300: 0.200690\n",
      "2023-12-04 18:39:52,812 INFO     Training average negative_sample_loss at step 23300: 0.181099\n",
      "2023-12-04 18:39:52,813 INFO     Training average loss at step 23300: 0.190895\n",
      "2023-12-04 18:40:01,877 INFO     Training average positive_sample_loss at step 23400: 0.201747\n",
      "2023-12-04 18:40:01,878 INFO     Training average negative_sample_loss at step 23400: 0.181851\n",
      "2023-12-04 18:40:01,878 INFO     Training average loss at step 23400: 0.191799\n",
      "2023-12-04 18:40:14,090 INFO     Training average positive_sample_loss at step 23500: 0.189674\n",
      "2023-12-04 18:40:14,090 INFO     Training average negative_sample_loss at step 23500: 0.179627\n",
      "2023-12-04 18:40:14,091 INFO     Training average loss at step 23500: 0.184650\n",
      "2023-12-04 18:40:25,764 INFO     Training average positive_sample_loss at step 23600: 0.196452\n",
      "2023-12-04 18:40:25,764 INFO     Training average negative_sample_loss at step 23600: 0.175852\n",
      "2023-12-04 18:40:25,764 INFO     Training average loss at step 23600: 0.186152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:40:37,495 INFO     Training average positive_sample_loss at step 23700: 0.198935\n",
      "2023-12-04 18:40:37,495 INFO     Training average negative_sample_loss at step 23700: 0.178118\n",
      "2023-12-04 18:40:37,495 INFO     Training average loss at step 23700: 0.188526\n",
      "2023-12-04 18:40:49,473 INFO     Training average positive_sample_loss at step 23800: 0.201274\n",
      "2023-12-04 18:40:49,473 INFO     Training average negative_sample_loss at step 23800: 0.181121\n",
      "2023-12-04 18:40:49,473 INFO     Training average loss at step 23800: 0.191198\n",
      "2023-12-04 18:41:01,441 INFO     Training average positive_sample_loss at step 23900: 0.201011\n",
      "2023-12-04 18:41:01,442 INFO     Training average negative_sample_loss at step 23900: 0.181582\n",
      "2023-12-04 18:41:01,442 INFO     Training average loss at step 23900: 0.191297\n",
      "2023-12-04 18:41:11,100 INFO     Training average positive_sample_loss at step 24000: 0.192190\n",
      "2023-12-04 18:41:11,100 INFO     Training average negative_sample_loss at step 24000: 0.181223\n",
      "2023-12-04 18:41:11,100 INFO     Training average loss at step 24000: 0.186707\n",
      "2023-12-04 18:41:22,786 INFO     Training average positive_sample_loss at step 24100: 0.195008\n",
      "2023-12-04 18:41:22,786 INFO     Training average negative_sample_loss at step 24100: 0.175062\n",
      "2023-12-04 18:41:22,786 INFO     Training average loss at step 24100: 0.185035\n",
      "2023-12-04 18:41:34,620 INFO     Training average positive_sample_loss at step 24200: 0.198758\n",
      "2023-12-04 18:41:34,620 INFO     Training average negative_sample_loss at step 24200: 0.178636\n",
      "2023-12-04 18:41:34,620 INFO     Training average loss at step 24200: 0.188697\n",
      "2023-12-04 18:41:46,551 INFO     Training average positive_sample_loss at step 24300: 0.200717\n",
      "2023-12-04 18:41:46,552 INFO     Training average negative_sample_loss at step 24300: 0.180241\n",
      "2023-12-04 18:41:46,552 INFO     Training average loss at step 24300: 0.190479\n",
      "2023-12-04 18:41:58,525 INFO     Training average positive_sample_loss at step 24400: 0.200562\n",
      "2023-12-04 18:41:58,526 INFO     Training average negative_sample_loss at step 24400: 0.181614\n",
      "2023-12-04 18:41:58,526 INFO     Training average loss at step 24400: 0.191088\n",
      "2023-12-04 18:42:10,954 INFO     Training average positive_sample_loss at step 24500: 0.196166\n",
      "2023-12-04 18:42:10,954 INFO     Training average negative_sample_loss at step 24500: 0.181852\n",
      "2023-12-04 18:42:10,954 INFO     Training average loss at step 24500: 0.189009\n",
      "2023-12-04 18:42:19,254 INFO     Training average positive_sample_loss at step 24600: 0.192794\n",
      "2023-12-04 18:42:19,254 INFO     Training average negative_sample_loss at step 24600: 0.176117\n",
      "2023-12-04 18:42:19,255 INFO     Training average loss at step 24600: 0.184456\n",
      "2023-12-04 18:42:30,936 INFO     Training average positive_sample_loss at step 24700: 0.198299\n",
      "2023-12-04 18:42:30,937 INFO     Training average negative_sample_loss at step 24700: 0.178418\n",
      "2023-12-04 18:42:30,937 INFO     Training average loss at step 24700: 0.188358\n",
      "2023-12-04 18:42:42,805 INFO     Training average positive_sample_loss at step 24800: 0.200537\n",
      "2023-12-04 18:42:42,805 INFO     Training average negative_sample_loss at step 24800: 0.179963\n",
      "2023-12-04 18:42:42,805 INFO     Training average loss at step 24800: 0.190250\n",
      "2023-12-04 18:42:54,820 INFO     Training average positive_sample_loss at step 24900: 0.200182\n",
      "2023-12-04 18:42:54,821 INFO     Training average negative_sample_loss at step 24900: 0.179956\n",
      "2023-12-04 18:42:54,821 INFO     Training average loss at step 24900: 0.190069\n",
      "2023-12-04 18:43:06,902 INFO     Training average positive_sample_loss at step 25000: 0.201050\n",
      "2023-12-04 18:43:06,902 INFO     Training average negative_sample_loss at step 25000: 0.182124\n",
      "2023-12-04 18:43:06,903 INFO     Training average loss at step 25000: 0.191587\n",
      "2023-12-04 18:43:19,092 INFO     Training average positive_sample_loss at step 25100: 0.189685\n",
      "2023-12-04 18:43:19,092 INFO     Training average negative_sample_loss at step 25100: 0.177874\n",
      "2023-12-04 18:43:19,092 INFO     Training average loss at step 25100: 0.183780\n",
      "2023-12-04 18:43:27,342 INFO     Training average positive_sample_loss at step 25200: 0.197331\n",
      "2023-12-04 18:43:27,342 INFO     Training average negative_sample_loss at step 25200: 0.176512\n",
      "2023-12-04 18:43:27,342 INFO     Training average loss at step 25200: 0.186921\n",
      "2023-12-04 18:43:36,231 INFO     Training average positive_sample_loss at step 25300: 0.199307\n",
      "2023-12-04 18:43:36,231 INFO     Training average negative_sample_loss at step 25300: 0.179766\n",
      "2023-12-04 18:43:36,231 INFO     Training average loss at step 25300: 0.189537\n",
      "2023-12-04 18:43:43,791 INFO     Training average positive_sample_loss at step 25400: 0.200920\n",
      "2023-12-04 18:43:43,791 INFO     Training average negative_sample_loss at step 25400: 0.181123\n",
      "2023-12-04 18:43:43,791 INFO     Training average loss at step 25400: 0.191021\n",
      "2023-12-04 18:43:51,454 INFO     Training average positive_sample_loss at step 25500: 0.200364\n",
      "2023-12-04 18:43:51,454 INFO     Training average negative_sample_loss at step 25500: 0.181494\n",
      "2023-12-04 18:43:51,454 INFO     Training average loss at step 25500: 0.190929\n",
      "2023-12-04 18:44:01,494 INFO     Training average positive_sample_loss at step 25600: 0.191904\n",
      "2023-12-04 18:44:01,494 INFO     Training average negative_sample_loss at step 25600: 0.179561\n",
      "2023-12-04 18:44:01,494 INFO     Training average loss at step 25600: 0.185732\n",
      "2023-12-04 18:44:10,327 INFO     Training average positive_sample_loss at step 25700: 0.195535\n",
      "2023-12-04 18:44:10,327 INFO     Training average negative_sample_loss at step 25700: 0.176084\n",
      "2023-12-04 18:44:10,327 INFO     Training average loss at step 25700: 0.185809\n",
      "2023-12-04 18:44:19,264 INFO     Training average positive_sample_loss at step 25800: 0.199405\n",
      "2023-12-04 18:44:19,264 INFO     Training average negative_sample_loss at step 25800: 0.178357\n",
      "2023-12-04 18:44:19,265 INFO     Training average loss at step 25800: 0.188881\n",
      "2023-12-04 18:44:27,736 INFO     Training average positive_sample_loss at step 25900: 0.199562\n",
      "2023-12-04 18:44:27,736 INFO     Training average negative_sample_loss at step 25900: 0.180071\n",
      "2023-12-04 18:44:27,736 INFO     Training average loss at step 25900: 0.189817\n",
      "2023-12-04 18:44:36,526 INFO     Training average positive_sample_loss at step 26000: 0.201463\n",
      "2023-12-04 18:44:36,526 INFO     Training average negative_sample_loss at step 26000: 0.180991\n",
      "2023-12-04 18:44:36,526 INFO     Training average loss at step 26000: 0.191227\n",
      "2023-12-04 18:44:46,042 INFO     Training average positive_sample_loss at step 26100: 0.195121\n",
      "2023-12-04 18:44:46,043 INFO     Training average negative_sample_loss at step 26100: 0.180442\n",
      "2023-12-04 18:44:46,043 INFO     Training average loss at step 26100: 0.187781\n",
      "2023-12-04 18:44:55,882 INFO     Training average positive_sample_loss at step 26200: 0.193133\n",
      "2023-12-04 18:44:55,882 INFO     Training average negative_sample_loss at step 26200: 0.177588\n",
      "2023-12-04 18:44:55,882 INFO     Training average loss at step 26200: 0.185360\n",
      "2023-12-04 18:45:07,633 INFO     Training average positive_sample_loss at step 26300: 0.198603\n",
      "2023-12-04 18:45:07,633 INFO     Training average negative_sample_loss at step 26300: 0.178372\n",
      "2023-12-04 18:45:07,633 INFO     Training average loss at step 26300: 0.188488\n",
      "2023-12-04 18:45:19,546 INFO     Training average positive_sample_loss at step 26400: 0.200066\n",
      "2023-12-04 18:45:19,547 INFO     Training average negative_sample_loss at step 26400: 0.177866\n",
      "2023-12-04 18:45:19,547 INFO     Training average loss at step 26400: 0.188966\n",
      "2023-12-04 18:45:31,540 INFO     Training average positive_sample_loss at step 26500: 0.199563\n",
      "2023-12-04 18:45:31,540 INFO     Training average negative_sample_loss at step 26500: 0.179830\n",
      "2023-12-04 18:45:31,540 INFO     Training average loss at step 26500: 0.189696\n",
      "2023-12-04 18:45:43,864 INFO     Training average positive_sample_loss at step 26600: 0.200553\n",
      "2023-12-04 18:45:43,864 INFO     Training average negative_sample_loss at step 26600: 0.182280\n",
      "2023-12-04 18:45:43,864 INFO     Training average loss at step 26600: 0.191417\n",
      "2023-12-04 18:45:54,042 INFO     Training average positive_sample_loss at step 26700: 0.189270\n",
      "2023-12-04 18:45:54,042 INFO     Training average negative_sample_loss at step 26700: 0.177908\n",
      "2023-12-04 18:45:54,042 INFO     Training average loss at step 26700: 0.183589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:46:03,945 INFO     Training average positive_sample_loss at step 26800: 0.197997\n",
      "2023-12-04 18:46:03,945 INFO     Training average negative_sample_loss at step 26800: 0.176812\n",
      "2023-12-04 18:46:03,945 INFO     Training average loss at step 26800: 0.187404\n",
      "2023-12-04 18:46:15,617 INFO     Training average positive_sample_loss at step 26900: 0.199529\n",
      "2023-12-04 18:46:15,618 INFO     Training average negative_sample_loss at step 26900: 0.178176\n",
      "2023-12-04 18:46:15,618 INFO     Training average loss at step 26900: 0.188852\n",
      "2023-12-04 18:46:27,561 INFO     Training average positive_sample_loss at step 27000: 0.199461\n",
      "2023-12-04 18:46:27,561 INFO     Training average negative_sample_loss at step 27000: 0.179328\n",
      "2023-12-04 18:46:27,561 INFO     Training average loss at step 27000: 0.189394\n",
      "2023-12-04 18:46:39,412 INFO     Training average positive_sample_loss at step 27100: 0.200828\n",
      "2023-12-04 18:46:39,412 INFO     Training average negative_sample_loss at step 27100: 0.181849\n",
      "2023-12-04 18:46:39,412 INFO     Training average loss at step 27100: 0.191339\n",
      "2023-12-04 18:46:51,718 INFO     Training average positive_sample_loss at step 27200: 0.191567\n",
      "2023-12-04 18:46:51,719 INFO     Training average negative_sample_loss at step 27200: 0.179291\n",
      "2023-12-04 18:46:51,719 INFO     Training average loss at step 27200: 0.185429\n",
      "2023-12-04 18:47:03,321 INFO     Training average positive_sample_loss at step 27300: 0.195053\n",
      "2023-12-04 18:47:03,321 INFO     Training average negative_sample_loss at step 27300: 0.175449\n",
      "2023-12-04 18:47:03,321 INFO     Training average loss at step 27300: 0.185251\n",
      "2023-12-04 18:47:11,655 INFO     Training average positive_sample_loss at step 27400: 0.199477\n",
      "2023-12-04 18:47:11,656 INFO     Training average negative_sample_loss at step 27400: 0.178632\n",
      "2023-12-04 18:47:11,656 INFO     Training average loss at step 27400: 0.189055\n",
      "2023-12-04 18:47:23,336 INFO     Training average positive_sample_loss at step 27500: 0.200140\n",
      "2023-12-04 18:47:23,337 INFO     Training average negative_sample_loss at step 27500: 0.179086\n",
      "2023-12-04 18:47:23,337 INFO     Training average loss at step 27500: 0.189613\n",
      "2023-12-04 18:47:35,280 INFO     Training average positive_sample_loss at step 27600: 0.200639\n",
      "2023-12-04 18:47:35,281 INFO     Training average negative_sample_loss at step 27600: 0.180855\n",
      "2023-12-04 18:47:35,281 INFO     Training average loss at step 27600: 0.190747\n",
      "2023-12-04 18:47:47,831 INFO     Training average positive_sample_loss at step 27700: 0.194995\n",
      "2023-12-04 18:47:47,831 INFO     Training average negative_sample_loss at step 27700: 0.180862\n",
      "2023-12-04 18:47:47,831 INFO     Training average loss at step 27700: 0.187928\n",
      "2023-12-04 18:47:59,418 INFO     Training average positive_sample_loss at step 27800: 0.193717\n",
      "2023-12-04 18:47:59,418 INFO     Training average negative_sample_loss at step 27800: 0.175259\n",
      "2023-12-04 18:47:59,418 INFO     Training average loss at step 27800: 0.184488\n",
      "2023-12-04 18:48:11,314 INFO     Training average positive_sample_loss at step 27900: 0.197493\n",
      "2023-12-04 18:48:11,315 INFO     Training average negative_sample_loss at step 27900: 0.177422\n",
      "2023-12-04 18:48:11,315 INFO     Training average loss at step 27900: 0.187457\n",
      "2023-12-04 18:48:19,481 INFO     Training average positive_sample_loss at step 28000: 0.199055\n",
      "2023-12-04 18:48:19,481 INFO     Training average negative_sample_loss at step 28000: 0.177954\n",
      "2023-12-04 18:48:19,482 INFO     Training average loss at step 28000: 0.188504\n",
      "2023-12-04 18:48:31,109 INFO     Training average positive_sample_loss at step 28100: 0.200654\n",
      "2023-12-04 18:48:31,110 INFO     Training average negative_sample_loss at step 28100: 0.179753\n",
      "2023-12-04 18:48:31,110 INFO     Training average loss at step 28100: 0.190204\n",
      "2023-12-04 18:48:43,599 INFO     Training average positive_sample_loss at step 28200: 0.200226\n",
      "2023-12-04 18:48:43,599 INFO     Training average negative_sample_loss at step 28200: 0.182213\n",
      "2023-12-04 18:48:43,599 INFO     Training average loss at step 28200: 0.191220\n",
      "2023-12-04 18:48:55,097 INFO     Training average positive_sample_loss at step 28300: 0.189633\n",
      "2023-12-04 18:48:55,098 INFO     Training average negative_sample_loss at step 28300: 0.178256\n",
      "2023-12-04 18:48:55,098 INFO     Training average loss at step 28300: 0.183945\n",
      "2023-12-04 18:49:06,997 INFO     Training average positive_sample_loss at step 28400: 0.196796\n",
      "2023-12-04 18:49:06,998 INFO     Training average negative_sample_loss at step 28400: 0.175468\n",
      "2023-12-04 18:49:06,998 INFO     Training average loss at step 28400: 0.186132\n",
      "2023-12-04 18:49:19,078 INFO     Training average positive_sample_loss at step 28500: 0.199433\n",
      "2023-12-04 18:49:19,079 INFO     Training average negative_sample_loss at step 28500: 0.178944\n",
      "2023-12-04 18:49:19,079 INFO     Training average loss at step 28500: 0.189188\n",
      "2023-12-04 18:49:27,553 INFO     Training average positive_sample_loss at step 28600: 0.199959\n",
      "2023-12-04 18:49:27,553 INFO     Training average negative_sample_loss at step 28600: 0.179275\n",
      "2023-12-04 18:49:27,553 INFO     Training average loss at step 28600: 0.189617\n",
      "2023-12-04 18:49:39,135 INFO     Training average positive_sample_loss at step 28700: 0.201301\n",
      "2023-12-04 18:49:39,135 INFO     Training average negative_sample_loss at step 28700: 0.182067\n",
      "2023-12-04 18:49:39,135 INFO     Training average loss at step 28700: 0.191684\n",
      "2023-12-04 18:49:51,288 INFO     Training average positive_sample_loss at step 28800: 0.192107\n",
      "2023-12-04 18:49:51,289 INFO     Training average negative_sample_loss at step 28800: 0.179168\n",
      "2023-12-04 18:49:51,289 INFO     Training average loss at step 28800: 0.185638\n",
      "2023-12-04 18:50:03,031 INFO     Training average positive_sample_loss at step 28900: 0.195310\n",
      "2023-12-04 18:50:03,031 INFO     Training average negative_sample_loss at step 28900: 0.177177\n",
      "2023-12-04 18:50:03,031 INFO     Training average loss at step 28900: 0.186244\n",
      "2023-12-04 18:50:14,902 INFO     Training average positive_sample_loss at step 29000: 0.199100\n",
      "2023-12-04 18:50:14,903 INFO     Training average negative_sample_loss at step 29000: 0.176681\n",
      "2023-12-04 18:50:14,903 INFO     Training average loss at step 29000: 0.187891\n",
      "2023-12-04 18:50:26,994 INFO     Training average positive_sample_loss at step 29100: 0.200220\n",
      "2023-12-04 18:50:26,995 INFO     Training average negative_sample_loss at step 29100: 0.179276\n",
      "2023-12-04 18:50:26,995 INFO     Training average loss at step 29100: 0.189748\n",
      "2023-12-04 18:50:36,715 INFO     Training average positive_sample_loss at step 29200: 0.200623\n",
      "2023-12-04 18:50:36,716 INFO     Training average negative_sample_loss at step 29200: 0.181309\n",
      "2023-12-04 18:50:36,716 INFO     Training average loss at step 29200: 0.190966\n",
      "2023-12-04 18:50:47,294 INFO     Training average positive_sample_loss at step 29300: 0.194086\n",
      "2023-12-04 18:50:47,294 INFO     Training average negative_sample_loss at step 29300: 0.181013\n",
      "2023-12-04 18:50:47,294 INFO     Training average loss at step 29300: 0.187550\n",
      "2023-12-04 18:50:58,964 INFO     Training average positive_sample_loss at step 29400: 0.193623\n",
      "2023-12-04 18:50:58,965 INFO     Training average negative_sample_loss at step 29400: 0.174968\n",
      "2023-12-04 18:50:58,965 INFO     Training average loss at step 29400: 0.184296\n",
      "2023-12-04 18:51:10,916 INFO     Training average positive_sample_loss at step 29500: 0.198200\n",
      "2023-12-04 18:51:10,916 INFO     Training average negative_sample_loss at step 29500: 0.177326\n",
      "2023-12-04 18:51:10,916 INFO     Training average loss at step 29500: 0.187763\n",
      "2023-12-04 18:51:23,045 INFO     Training average positive_sample_loss at step 29600: 0.199086\n",
      "2023-12-04 18:51:23,046 INFO     Training average negative_sample_loss at step 29600: 0.177960\n",
      "2023-12-04 18:51:23,046 INFO     Training average loss at step 29600: 0.188523\n",
      "2023-12-04 18:51:34,978 INFO     Training average positive_sample_loss at step 29700: 0.200940\n",
      "2023-12-04 18:51:34,978 INFO     Training average negative_sample_loss at step 29700: 0.180817\n",
      "2023-12-04 18:51:34,978 INFO     Training average loss at step 29700: 0.190878\n",
      "2023-12-04 18:51:46,902 INFO     Training average positive_sample_loss at step 29800: 0.199234\n",
      "2023-12-04 18:51:46,903 INFO     Training average negative_sample_loss at step 29800: 0.181504\n",
      "2023-12-04 18:51:46,903 INFO     Training average loss at step 29800: 0.190369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:51:56,706 INFO     Training average positive_sample_loss at step 29900: 0.190885\n",
      "2023-12-04 18:51:56,706 INFO     Training average negative_sample_loss at step 29900: 0.176047\n",
      "2023-12-04 18:51:56,706 INFO     Training average loss at step 29900: 0.183466\n",
      "2023-12-04 18:52:17,678 INFO     Training average positive_sample_loss at step 30000: 0.197089\n",
      "2023-12-04 18:52:17,678 INFO     Training average negative_sample_loss at step 30000: 0.176540\n",
      "2023-12-04 18:52:17,678 INFO     Training average loss at step 30000: 0.186814\n",
      "2023-12-04 18:52:17,678 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 18:52:18,236 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 18:53:04,181 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 18:53:51,133 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 18:54:00,246 INFO     Valid MRR at step 30000: 0.336101\n",
      "2023-12-04 18:54:00,247 INFO     Valid MR at step 30000: 171.565127\n",
      "2023-12-04 18:54:00,247 INFO     Valid HITS@1 at step 30000: 0.240605\n",
      "2023-12-04 18:54:00,247 INFO     Valid HITS@3 at step 30000: 0.371457\n",
      "2023-12-04 18:54:00,247 INFO     Valid HITS@10 at step 30000: 0.528457\n",
      "2023-12-04 18:54:08,274 INFO     Training average positive_sample_loss at step 30100: 0.198879\n",
      "2023-12-04 18:54:08,274 INFO     Training average negative_sample_loss at step 30100: 0.177711\n",
      "2023-12-04 18:54:08,274 INFO     Training average loss at step 30100: 0.188295\n",
      "2023-12-04 18:54:19,556 INFO     Training average positive_sample_loss at step 30200: 0.200066\n",
      "2023-12-04 18:54:19,557 INFO     Training average negative_sample_loss at step 30200: 0.180132\n",
      "2023-12-04 18:54:19,557 INFO     Training average loss at step 30200: 0.190099\n",
      "2023-12-04 18:54:31,307 INFO     Training average positive_sample_loss at step 30300: 0.200184\n",
      "2023-12-04 18:54:31,307 INFO     Training average negative_sample_loss at step 30300: 0.181545\n",
      "2023-12-04 18:54:31,307 INFO     Training average loss at step 30300: 0.190865\n",
      "2023-12-04 18:54:43,534 INFO     Training average positive_sample_loss at step 30400: 0.191113\n",
      "2023-12-04 18:54:43,534 INFO     Training average negative_sample_loss at step 30400: 0.178245\n",
      "2023-12-04 18:54:43,534 INFO     Training average loss at step 30400: 0.184679\n",
      "2023-12-04 18:54:55,250 INFO     Training average positive_sample_loss at step 30500: 0.195737\n",
      "2023-12-04 18:54:55,251 INFO     Training average negative_sample_loss at step 30500: 0.175512\n",
      "2023-12-04 18:54:55,251 INFO     Training average loss at step 30500: 0.185625\n",
      "2023-12-04 18:55:07,182 INFO     Training average positive_sample_loss at step 30600: 0.198745\n",
      "2023-12-04 18:55:07,182 INFO     Training average negative_sample_loss at step 30600: 0.178245\n",
      "2023-12-04 18:55:07,182 INFO     Training average loss at step 30600: 0.188495\n",
      "2023-12-04 18:55:17,464 INFO     Training average positive_sample_loss at step 30700: 0.200348\n",
      "2023-12-04 18:55:17,464 INFO     Training average negative_sample_loss at step 30700: 0.178749\n",
      "2023-12-04 18:55:17,464 INFO     Training average loss at step 30700: 0.189548\n",
      "2023-12-04 18:55:26,950 INFO     Training average positive_sample_loss at step 30800: 0.200252\n",
      "2023-12-04 18:55:26,950 INFO     Training average negative_sample_loss at step 30800: 0.180039\n",
      "2023-12-04 18:55:26,950 INFO     Training average loss at step 30800: 0.190145\n",
      "2023-12-04 18:55:39,195 INFO     Training average positive_sample_loss at step 30900: 0.193848\n",
      "2023-12-04 18:55:39,195 INFO     Training average negative_sample_loss at step 30900: 0.179607\n",
      "2023-12-04 18:55:39,195 INFO     Training average loss at step 30900: 0.186727\n",
      "2023-12-04 18:55:50,748 INFO     Training average positive_sample_loss at step 31000: 0.193606\n",
      "2023-12-04 18:55:50,748 INFO     Training average negative_sample_loss at step 31000: 0.176337\n",
      "2023-12-04 18:55:50,748 INFO     Training average loss at step 31000: 0.184971\n",
      "2023-12-04 18:56:02,547 INFO     Training average positive_sample_loss at step 31100: 0.198287\n",
      "2023-12-04 18:56:02,548 INFO     Training average negative_sample_loss at step 31100: 0.176567\n",
      "2023-12-04 18:56:02,548 INFO     Training average loss at step 31100: 0.187427\n",
      "2023-12-04 18:56:14,444 INFO     Training average positive_sample_loss at step 31200: 0.199445\n",
      "2023-12-04 18:56:14,444 INFO     Training average negative_sample_loss at step 31200: 0.178320\n",
      "2023-12-04 18:56:14,444 INFO     Training average loss at step 31200: 0.188883\n",
      "2023-12-04 18:56:26,426 INFO     Training average positive_sample_loss at step 31300: 0.200682\n",
      "2023-12-04 18:56:26,427 INFO     Training average negative_sample_loss at step 31300: 0.179729\n",
      "2023-12-04 18:56:26,427 INFO     Training average loss at step 31300: 0.190206\n",
      "2023-12-04 18:56:35,105 INFO     Training average positive_sample_loss at step 31400: 0.198061\n",
      "2023-12-04 18:56:35,105 INFO     Training average negative_sample_loss at step 31400: 0.181657\n",
      "2023-12-04 18:56:35,105 INFO     Training average loss at step 31400: 0.189859\n",
      "2023-12-04 18:56:46,625 INFO     Training average positive_sample_loss at step 31500: 0.190968\n",
      "2023-12-04 18:56:46,625 INFO     Training average negative_sample_loss at step 31500: 0.176498\n",
      "2023-12-04 18:56:46,625 INFO     Training average loss at step 31500: 0.183733\n",
      "2023-12-04 18:56:58,427 INFO     Training average positive_sample_loss at step 31600: 0.197166\n",
      "2023-12-04 18:56:58,428 INFO     Training average negative_sample_loss at step 31600: 0.175478\n",
      "2023-12-04 18:56:58,428 INFO     Training average loss at step 31600: 0.186322\n",
      "2023-12-04 18:57:10,377 INFO     Training average positive_sample_loss at step 31700: 0.199250\n",
      "2023-12-04 18:57:10,378 INFO     Training average negative_sample_loss at step 31700: 0.178504\n",
      "2023-12-04 18:57:10,378 INFO     Training average loss at step 31700: 0.188877\n",
      "2023-12-04 18:57:22,264 INFO     Training average positive_sample_loss at step 31800: 0.199506\n",
      "2023-12-04 18:57:22,264 INFO     Training average negative_sample_loss at step 31800: 0.178740\n",
      "2023-12-04 18:57:22,264 INFO     Training average loss at step 31800: 0.189123\n",
      "2023-12-04 18:57:34,329 INFO     Training average positive_sample_loss at step 31900: 0.201233\n",
      "2023-12-04 18:57:34,330 INFO     Training average negative_sample_loss at step 31900: 0.181228\n",
      "2023-12-04 18:57:34,330 INFO     Training average loss at step 31900: 0.191231\n",
      "2023-12-04 18:57:43,552 INFO     Training average positive_sample_loss at step 32000: 0.190583\n",
      "2023-12-04 18:57:43,553 INFO     Training average negative_sample_loss at step 32000: 0.178041\n",
      "2023-12-04 18:57:43,553 INFO     Training average loss at step 32000: 0.184312\n",
      "2023-12-04 18:57:55,161 INFO     Training average positive_sample_loss at step 32100: 0.195470\n",
      "2023-12-04 18:57:55,162 INFO     Training average negative_sample_loss at step 32100: 0.175771\n",
      "2023-12-04 18:57:55,162 INFO     Training average loss at step 32100: 0.185620\n",
      "2023-12-04 18:58:06,869 INFO     Training average positive_sample_loss at step 32200: 0.198580\n",
      "2023-12-04 18:58:06,869 INFO     Training average negative_sample_loss at step 32200: 0.176370\n",
      "2023-12-04 18:58:06,869 INFO     Training average loss at step 32200: 0.187475\n",
      "2023-12-04 18:58:18,676 INFO     Training average positive_sample_loss at step 32300: 0.200432\n",
      "2023-12-04 18:58:18,677 INFO     Training average negative_sample_loss at step 32300: 0.180148\n",
      "2023-12-04 18:58:18,677 INFO     Training average loss at step 32300: 0.190290\n",
      "2023-12-04 18:58:30,419 INFO     Training average positive_sample_loss at step 32400: 0.201612\n",
      "2023-12-04 18:58:30,419 INFO     Training average negative_sample_loss at step 32400: 0.180964\n",
      "2023-12-04 18:58:30,419 INFO     Training average loss at step 32400: 0.191288\n",
      "2023-12-04 18:58:42,700 INFO     Training average positive_sample_loss at step 32500: 0.193150\n",
      "2023-12-04 18:58:42,701 INFO     Training average negative_sample_loss at step 32500: 0.179154\n",
      "2023-12-04 18:58:42,701 INFO     Training average loss at step 32500: 0.186152\n",
      "2023-12-04 18:58:51,046 INFO     Training average positive_sample_loss at step 32600: 0.194747\n",
      "2023-12-04 18:58:51,047 INFO     Training average negative_sample_loss at step 32600: 0.175804\n",
      "2023-12-04 18:58:51,047 INFO     Training average loss at step 32600: 0.185275\n",
      "2023-12-04 18:59:02,592 INFO     Training average positive_sample_loss at step 32700: 0.197640\n",
      "2023-12-04 18:59:02,592 INFO     Training average negative_sample_loss at step 32700: 0.175629\n",
      "2023-12-04 18:59:02,592 INFO     Training average loss at step 32700: 0.186634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:59:14,312 INFO     Training average positive_sample_loss at step 32800: 0.199452\n",
      "2023-12-04 18:59:14,312 INFO     Training average negative_sample_loss at step 32800: 0.177782\n",
      "2023-12-04 18:59:14,312 INFO     Training average loss at step 32800: 0.188617\n",
      "2023-12-04 18:59:26,099 INFO     Training average positive_sample_loss at step 32900: 0.199703\n",
      "2023-12-04 18:59:26,099 INFO     Training average negative_sample_loss at step 32900: 0.179204\n",
      "2023-12-04 18:59:26,099 INFO     Training average loss at step 32900: 0.189453\n",
      "2023-12-04 18:59:38,439 INFO     Training average positive_sample_loss at step 33000: 0.196944\n",
      "2023-12-04 18:59:38,439 INFO     Training average negative_sample_loss at step 33000: 0.180937\n",
      "2023-12-04 18:59:38,439 INFO     Training average loss at step 33000: 0.188940\n",
      "2023-12-04 18:59:49,977 INFO     Training average positive_sample_loss at step 33100: 0.192073\n",
      "2023-12-04 18:59:49,977 INFO     Training average negative_sample_loss at step 33100: 0.175995\n",
      "2023-12-04 18:59:49,977 INFO     Training average loss at step 33100: 0.184034\n",
      "2023-12-04 19:00:00,309 INFO     Training average positive_sample_loss at step 33200: 0.197030\n",
      "2023-12-04 19:00:00,309 INFO     Training average negative_sample_loss at step 33200: 0.176570\n",
      "2023-12-04 19:00:00,309 INFO     Training average loss at step 33200: 0.186800\n",
      "2023-12-04 19:00:09,915 INFO     Training average positive_sample_loss at step 33300: 0.199098\n",
      "2023-12-04 19:00:09,916 INFO     Training average negative_sample_loss at step 33300: 0.178020\n",
      "2023-12-04 19:00:09,916 INFO     Training average loss at step 33300: 0.188559\n",
      "2023-12-04 19:00:21,666 INFO     Training average positive_sample_loss at step 33400: 0.199796\n",
      "2023-12-04 19:00:21,666 INFO     Training average negative_sample_loss at step 33400: 0.178360\n",
      "2023-12-04 19:00:21,666 INFO     Training average loss at step 33400: 0.189078\n",
      "2023-12-04 19:00:33,662 INFO     Training average positive_sample_loss at step 33500: 0.199981\n",
      "2023-12-04 19:00:33,662 INFO     Training average negative_sample_loss at step 33500: 0.180387\n",
      "2023-12-04 19:00:33,663 INFO     Training average loss at step 33500: 0.190184\n",
      "2023-12-04 19:00:45,668 INFO     Training average positive_sample_loss at step 33600: 0.189465\n",
      "2023-12-04 19:00:45,669 INFO     Training average negative_sample_loss at step 33600: 0.177328\n",
      "2023-12-04 19:00:45,669 INFO     Training average loss at step 33600: 0.183397\n",
      "2023-12-04 19:00:57,464 INFO     Training average positive_sample_loss at step 33700: 0.196691\n",
      "2023-12-04 19:00:57,464 INFO     Training average negative_sample_loss at step 33700: 0.176776\n",
      "2023-12-04 19:00:57,464 INFO     Training average loss at step 33700: 0.186734\n",
      "2023-12-04 19:01:09,384 INFO     Training average positive_sample_loss at step 33800: 0.198659\n",
      "2023-12-04 19:01:09,384 INFO     Training average negative_sample_loss at step 33800: 0.176619\n",
      "2023-12-04 19:01:09,384 INFO     Training average loss at step 33800: 0.187639\n",
      "2023-12-04 19:01:17,524 INFO     Training average positive_sample_loss at step 33900: 0.199859\n",
      "2023-12-04 19:01:17,524 INFO     Training average negative_sample_loss at step 33900: 0.179191\n",
      "2023-12-04 19:01:17,524 INFO     Training average loss at step 33900: 0.189525\n",
      "2023-12-04 19:01:29,201 INFO     Training average positive_sample_loss at step 34000: 0.200648\n",
      "2023-12-04 19:01:29,202 INFO     Training average negative_sample_loss at step 34000: 0.179432\n",
      "2023-12-04 19:01:29,202 INFO     Training average loss at step 34000: 0.190040\n",
      "2023-12-04 19:01:41,500 INFO     Training average positive_sample_loss at step 34100: 0.193058\n",
      "2023-12-04 19:01:41,501 INFO     Training average negative_sample_loss at step 34100: 0.179307\n",
      "2023-12-04 19:01:41,501 INFO     Training average loss at step 34100: 0.186182\n",
      "2023-12-04 19:01:53,119 INFO     Training average positive_sample_loss at step 34200: 0.194521\n",
      "2023-12-04 19:01:53,120 INFO     Training average negative_sample_loss at step 34200: 0.175697\n",
      "2023-12-04 19:01:53,120 INFO     Training average loss at step 34200: 0.185109\n",
      "2023-12-04 19:02:04,974 INFO     Training average positive_sample_loss at step 34300: 0.198090\n",
      "2023-12-04 19:02:04,975 INFO     Training average negative_sample_loss at step 34300: 0.177102\n",
      "2023-12-04 19:02:04,975 INFO     Training average loss at step 34300: 0.187596\n",
      "2023-12-04 19:02:16,864 INFO     Training average positive_sample_loss at step 34400: 0.199598\n",
      "2023-12-04 19:02:16,864 INFO     Training average negative_sample_loss at step 34400: 0.178446\n",
      "2023-12-04 19:02:16,864 INFO     Training average loss at step 34400: 0.189022\n",
      "2023-12-04 19:02:25,172 INFO     Training average positive_sample_loss at step 34500: 0.200336\n",
      "2023-12-04 19:02:25,172 INFO     Training average negative_sample_loss at step 34500: 0.179541\n",
      "2023-12-04 19:02:25,172 INFO     Training average loss at step 34500: 0.189938\n",
      "2023-12-04 19:02:37,395 INFO     Training average positive_sample_loss at step 34600: 0.196625\n",
      "2023-12-04 19:02:37,396 INFO     Training average negative_sample_loss at step 34600: 0.179810\n",
      "2023-12-04 19:02:37,396 INFO     Training average loss at step 34600: 0.188218\n",
      "2023-12-04 19:02:48,854 INFO     Training average positive_sample_loss at step 34700: 0.191441\n",
      "2023-12-04 19:02:48,855 INFO     Training average negative_sample_loss at step 34700: 0.175561\n",
      "2023-12-04 19:02:48,855 INFO     Training average loss at step 34700: 0.183501\n",
      "2023-12-04 19:03:00,583 INFO     Training average positive_sample_loss at step 34800: 0.198010\n",
      "2023-12-04 19:03:00,583 INFO     Training average negative_sample_loss at step 34800: 0.176461\n",
      "2023-12-04 19:03:00,584 INFO     Training average loss at step 34800: 0.187235\n",
      "2023-12-04 19:03:12,496 INFO     Training average positive_sample_loss at step 34900: 0.199208\n",
      "2023-12-04 19:03:12,496 INFO     Training average negative_sample_loss at step 34900: 0.178365\n",
      "2023-12-04 19:03:12,496 INFO     Training average loss at step 34900: 0.188786\n",
      "2023-12-04 19:03:24,459 INFO     Training average positive_sample_loss at step 35000: 0.199329\n",
      "2023-12-04 19:03:24,459 INFO     Training average negative_sample_loss at step 35000: 0.178258\n",
      "2023-12-04 19:03:24,459 INFO     Training average loss at step 35000: 0.188793\n",
      "2023-12-04 19:03:33,474 INFO     Training average positive_sample_loss at step 35100: 0.200376\n",
      "2023-12-04 19:03:33,474 INFO     Training average negative_sample_loss at step 35100: 0.180191\n",
      "2023-12-04 19:03:33,474 INFO     Training average loss at step 35100: 0.190283\n",
      "2023-12-04 19:03:45,083 INFO     Training average positive_sample_loss at step 35200: 0.189670\n",
      "2023-12-04 19:03:45,083 INFO     Training average negative_sample_loss at step 35200: 0.177374\n",
      "2023-12-04 19:03:45,083 INFO     Training average loss at step 35200: 0.183522\n",
      "2023-12-04 19:03:56,803 INFO     Training average positive_sample_loss at step 35300: 0.196361\n",
      "2023-12-04 19:03:56,803 INFO     Training average negative_sample_loss at step 35300: 0.175146\n",
      "2023-12-04 19:03:56,803 INFO     Training average loss at step 35300: 0.185754\n",
      "2023-12-04 19:04:08,668 INFO     Training average positive_sample_loss at step 35400: 0.198985\n",
      "2023-12-04 19:04:08,668 INFO     Training average negative_sample_loss at step 35400: 0.176875\n",
      "2023-12-04 19:04:08,668 INFO     Training average loss at step 35400: 0.187930\n",
      "2023-12-04 19:04:20,739 INFO     Training average positive_sample_loss at step 35500: 0.199786\n",
      "2023-12-04 19:04:20,739 INFO     Training average negative_sample_loss at step 35500: 0.179445\n",
      "2023-12-04 19:04:20,739 INFO     Training average loss at step 35500: 0.189615\n",
      "2023-12-04 19:04:32,570 INFO     Training average positive_sample_loss at step 35600: 0.200303\n",
      "2023-12-04 19:04:32,571 INFO     Training average negative_sample_loss at step 35600: 0.180001\n",
      "2023-12-04 19:04:32,571 INFO     Training average loss at step 35600: 0.190152\n",
      "2023-12-04 19:04:42,925 INFO     Training average positive_sample_loss at step 35700: 0.192826\n",
      "2023-12-04 19:04:42,926 INFO     Training average negative_sample_loss at step 35700: 0.179706\n",
      "2023-12-04 19:04:42,926 INFO     Training average loss at step 35700: 0.186266\n",
      "2023-12-04 19:04:53,328 INFO     Training average positive_sample_loss at step 35800: 0.194262\n",
      "2023-12-04 19:04:53,328 INFO     Training average negative_sample_loss at step 35800: 0.174745\n",
      "2023-12-04 19:04:53,328 INFO     Training average loss at step 35800: 0.184504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:05:05,044 INFO     Training average positive_sample_loss at step 35900: 0.198400\n",
      "2023-12-04 19:05:05,044 INFO     Training average negative_sample_loss at step 35900: 0.177588\n",
      "2023-12-04 19:05:05,044 INFO     Training average loss at step 35900: 0.187994\n",
      "2023-12-04 19:05:16,790 INFO     Training average positive_sample_loss at step 36000: 0.199962\n",
      "2023-12-04 19:05:16,790 INFO     Training average negative_sample_loss at step 36000: 0.177908\n",
      "2023-12-04 19:05:16,790 INFO     Training average loss at step 36000: 0.188935\n",
      "2023-12-04 19:05:28,829 INFO     Training average positive_sample_loss at step 36100: 0.200106\n",
      "2023-12-04 19:05:28,829 INFO     Training average negative_sample_loss at step 36100: 0.178730\n",
      "2023-12-04 19:05:28,829 INFO     Training average loss at step 36100: 0.189418\n",
      "2023-12-04 19:05:41,317 INFO     Training average positive_sample_loss at step 36200: 0.195723\n",
      "2023-12-04 19:05:41,318 INFO     Training average negative_sample_loss at step 36200: 0.179703\n",
      "2023-12-04 19:05:41,318 INFO     Training average loss at step 36200: 0.187713\n",
      "2023-12-04 19:05:52,134 INFO     Training average positive_sample_loss at step 36300: 0.191848\n",
      "2023-12-04 19:05:52,134 INFO     Training average negative_sample_loss at step 36300: 0.175353\n",
      "2023-12-04 19:05:52,134 INFO     Training average loss at step 36300: 0.183600\n",
      "2023-12-04 19:06:00,947 INFO     Training average positive_sample_loss at step 36400: 0.197425\n",
      "2023-12-04 19:06:00,948 INFO     Training average negative_sample_loss at step 36400: 0.175674\n",
      "2023-12-04 19:06:00,948 INFO     Training average loss at step 36400: 0.186550\n",
      "2023-12-04 19:06:10,311 INFO     Training average positive_sample_loss at step 36500: 0.198542\n",
      "2023-12-04 19:06:10,312 INFO     Training average negative_sample_loss at step 36500: 0.176449\n",
      "2023-12-04 19:06:10,312 INFO     Training average loss at step 36500: 0.187495\n",
      "2023-12-04 19:06:16,802 INFO     Training average positive_sample_loss at step 36600: 0.199528\n",
      "2023-12-04 19:06:16,802 INFO     Training average negative_sample_loss at step 36600: 0.179463\n",
      "2023-12-04 19:06:16,802 INFO     Training average loss at step 36600: 0.189496\n",
      "2023-12-04 19:06:24,758 INFO     Training average positive_sample_loss at step 36700: 0.201207\n",
      "2023-12-04 19:06:24,758 INFO     Training average negative_sample_loss at step 36700: 0.180686\n",
      "2023-12-04 19:06:24,758 INFO     Training average loss at step 36700: 0.190947\n",
      "2023-12-04 19:06:34,808 INFO     Training average positive_sample_loss at step 36800: 0.189658\n",
      "2023-12-04 19:06:34,808 INFO     Training average negative_sample_loss at step 36800: 0.176023\n",
      "2023-12-04 19:06:34,808 INFO     Training average loss at step 36800: 0.182840\n",
      "2023-12-04 19:06:43,890 INFO     Training average positive_sample_loss at step 36900: 0.196466\n",
      "2023-12-04 19:06:43,890 INFO     Training average negative_sample_loss at step 36900: 0.175889\n",
      "2023-12-04 19:06:43,890 INFO     Training average loss at step 36900: 0.186177\n",
      "2023-12-04 19:06:52,586 INFO     Training average positive_sample_loss at step 37000: 0.199018\n",
      "2023-12-04 19:06:52,586 INFO     Training average negative_sample_loss at step 37000: 0.176903\n",
      "2023-12-04 19:06:52,586 INFO     Training average loss at step 37000: 0.187960\n",
      "2023-12-04 19:07:01,588 INFO     Training average positive_sample_loss at step 37100: 0.199171\n",
      "2023-12-04 19:07:01,588 INFO     Training average negative_sample_loss at step 37100: 0.177779\n",
      "2023-12-04 19:07:01,588 INFO     Training average loss at step 37100: 0.188475\n",
      "2023-12-04 19:07:10,446 INFO     Training average positive_sample_loss at step 37200: 0.199913\n",
      "2023-12-04 19:07:10,446 INFO     Training average negative_sample_loss at step 37200: 0.178504\n",
      "2023-12-04 19:07:10,447 INFO     Training average loss at step 37200: 0.189209\n",
      "2023-12-04 19:07:20,033 INFO     Training average positive_sample_loss at step 37300: 0.192301\n",
      "2023-12-04 19:07:20,033 INFO     Training average negative_sample_loss at step 37300: 0.178479\n",
      "2023-12-04 19:07:20,033 INFO     Training average loss at step 37300: 0.185390\n",
      "2023-12-04 19:07:31,555 INFO     Training average positive_sample_loss at step 37400: 0.194244\n",
      "2023-12-04 19:07:31,555 INFO     Training average negative_sample_loss at step 37400: 0.174701\n",
      "2023-12-04 19:07:31,555 INFO     Training average loss at step 37400: 0.184472\n",
      "2023-12-04 19:07:43,488 INFO     Training average positive_sample_loss at step 37500: 0.198352\n",
      "2023-12-04 19:07:43,489 INFO     Training average negative_sample_loss at step 37500: 0.177151\n",
      "2023-12-04 19:07:43,489 INFO     Training average loss at step 37500: 0.187751\n",
      "2023-12-04 19:07:55,308 INFO     Training average positive_sample_loss at step 37600: 0.199210\n",
      "2023-12-04 19:07:55,309 INFO     Training average negative_sample_loss at step 37600: 0.177014\n",
      "2023-12-04 19:07:55,309 INFO     Training average loss at step 37600: 0.188112\n",
      "2023-12-04 19:08:07,150 INFO     Training average positive_sample_loss at step 37700: 0.200185\n",
      "2023-12-04 19:08:07,150 INFO     Training average negative_sample_loss at step 37700: 0.180158\n",
      "2023-12-04 19:08:07,151 INFO     Training average loss at step 37700: 0.190172\n",
      "2023-12-04 19:08:18,600 INFO     Training average positive_sample_loss at step 37800: 0.195555\n",
      "2023-12-04 19:08:18,600 INFO     Training average negative_sample_loss at step 37800: 0.179405\n",
      "2023-12-04 19:08:18,600 INFO     Training average loss at step 37800: 0.187480\n",
      "2023-12-04 19:08:27,774 INFO     Training average positive_sample_loss at step 37900: 0.192582\n",
      "2023-12-04 19:08:27,775 INFO     Training average negative_sample_loss at step 37900: 0.175575\n",
      "2023-12-04 19:08:27,775 INFO     Training average loss at step 37900: 0.184078\n",
      "2023-12-04 19:08:39,465 INFO     Training average positive_sample_loss at step 38000: 0.197243\n",
      "2023-12-04 19:08:39,465 INFO     Training average negative_sample_loss at step 38000: 0.175424\n",
      "2023-12-04 19:08:39,465 INFO     Training average loss at step 38000: 0.186334\n",
      "2023-12-04 19:08:51,424 INFO     Training average positive_sample_loss at step 38100: 0.199452\n",
      "2023-12-04 19:08:51,425 INFO     Training average negative_sample_loss at step 38100: 0.177303\n",
      "2023-12-04 19:08:51,425 INFO     Training average loss at step 38100: 0.188378\n",
      "2023-12-04 19:09:03,389 INFO     Training average positive_sample_loss at step 38200: 0.199095\n",
      "2023-12-04 19:09:03,389 INFO     Training average negative_sample_loss at step 38200: 0.177661\n",
      "2023-12-04 19:09:03,389 INFO     Training average loss at step 38200: 0.188378\n",
      "2023-12-04 19:09:15,471 INFO     Training average positive_sample_loss at step 38300: 0.200394\n",
      "2023-12-04 19:09:15,472 INFO     Training average negative_sample_loss at step 38300: 0.180376\n",
      "2023-12-04 19:09:15,472 INFO     Training average loss at step 38300: 0.190385\n",
      "2023-12-04 19:09:27,642 INFO     Training average positive_sample_loss at step 38400: 0.189036\n",
      "2023-12-04 19:09:27,642 INFO     Training average negative_sample_loss at step 38400: 0.176396\n",
      "2023-12-04 19:09:27,642 INFO     Training average loss at step 38400: 0.182716\n",
      "2023-12-04 19:09:35,875 INFO     Training average positive_sample_loss at step 38500: 0.196050\n",
      "2023-12-04 19:09:35,875 INFO     Training average negative_sample_loss at step 38500: 0.174712\n",
      "2023-12-04 19:09:35,875 INFO     Training average loss at step 38500: 0.185381\n",
      "2023-12-04 19:09:47,582 INFO     Training average positive_sample_loss at step 38600: 0.199201\n",
      "2023-12-04 19:09:47,582 INFO     Training average negative_sample_loss at step 38600: 0.177033\n",
      "2023-12-04 19:09:47,582 INFO     Training average loss at step 38600: 0.188117\n",
      "2023-12-04 19:09:59,366 INFO     Training average positive_sample_loss at step 38700: 0.199158\n",
      "2023-12-04 19:09:59,367 INFO     Training average negative_sample_loss at step 38700: 0.179366\n",
      "2023-12-04 19:09:59,367 INFO     Training average loss at step 38700: 0.189262\n",
      "2023-12-04 19:10:11,282 INFO     Training average positive_sample_loss at step 38800: 0.201107\n",
      "2023-12-04 19:10:11,282 INFO     Training average negative_sample_loss at step 38800: 0.180487\n",
      "2023-12-04 19:10:11,282 INFO     Training average loss at step 38800: 0.190797\n",
      "2023-12-04 19:10:23,605 INFO     Training average positive_sample_loss at step 38900: 0.191705\n",
      "2023-12-04 19:10:23,605 INFO     Training average negative_sample_loss at step 38900: 0.177908\n",
      "2023-12-04 19:10:23,605 INFO     Training average loss at step 38900: 0.184806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:10:35,425 INFO     Training average positive_sample_loss at step 39000: 0.194898\n",
      "2023-12-04 19:10:35,426 INFO     Training average negative_sample_loss at step 39000: 0.174332\n",
      "2023-12-04 19:10:35,426 INFO     Training average loss at step 39000: 0.184615\n",
      "2023-12-04 19:10:43,679 INFO     Training average positive_sample_loss at step 39100: 0.197939\n",
      "2023-12-04 19:10:43,680 INFO     Training average negative_sample_loss at step 39100: 0.176391\n",
      "2023-12-04 19:10:43,680 INFO     Training average loss at step 39100: 0.187165\n",
      "2023-12-04 19:10:55,297 INFO     Training average positive_sample_loss at step 39200: 0.199243\n",
      "2023-12-04 19:10:55,297 INFO     Training average negative_sample_loss at step 39200: 0.178129\n",
      "2023-12-04 19:10:55,297 INFO     Training average loss at step 39200: 0.188686\n",
      "2023-12-04 19:11:07,135 INFO     Training average positive_sample_loss at step 39300: 0.199903\n",
      "2023-12-04 19:11:07,135 INFO     Training average negative_sample_loss at step 39300: 0.179274\n",
      "2023-12-04 19:11:07,135 INFO     Training average loss at step 39300: 0.189588\n",
      "2023-12-04 19:11:19,631 INFO     Training average positive_sample_loss at step 39400: 0.195774\n",
      "2023-12-04 19:11:19,632 INFO     Training average negative_sample_loss at step 39400: 0.180164\n",
      "2023-12-04 19:11:19,632 INFO     Training average loss at step 39400: 0.187969\n",
      "2023-12-04 19:11:31,269 INFO     Training average positive_sample_loss at step 39500: 0.192998\n",
      "2023-12-04 19:11:31,269 INFO     Training average negative_sample_loss at step 39500: 0.174772\n",
      "2023-12-04 19:11:31,270 INFO     Training average loss at step 39500: 0.183885\n",
      "2023-12-04 19:11:43,159 INFO     Training average positive_sample_loss at step 39600: 0.197659\n",
      "2023-12-04 19:11:43,160 INFO     Training average negative_sample_loss at step 39600: 0.175632\n",
      "2023-12-04 19:11:43,160 INFO     Training average loss at step 39600: 0.186646\n",
      "2023-12-04 19:11:51,583 INFO     Training average positive_sample_loss at step 39700: 0.199343\n",
      "2023-12-04 19:11:51,584 INFO     Training average negative_sample_loss at step 39700: 0.176832\n",
      "2023-12-04 19:11:51,584 INFO     Training average loss at step 39700: 0.188087\n",
      "2023-12-04 19:12:03,104 INFO     Training average positive_sample_loss at step 39800: 0.199769\n",
      "2023-12-04 19:12:03,105 INFO     Training average negative_sample_loss at step 39800: 0.179009\n",
      "2023-12-04 19:12:03,105 INFO     Training average loss at step 39800: 0.189389\n",
      "2023-12-04 19:12:15,189 INFO     Training average positive_sample_loss at step 39900: 0.199421\n",
      "2023-12-04 19:12:15,190 INFO     Training average negative_sample_loss at step 39900: 0.180049\n",
      "2023-12-04 19:12:15,190 INFO     Training average loss at step 39900: 0.189735\n",
      "2023-12-04 19:12:37,672 INFO     Training average positive_sample_loss at step 40000: 0.188853\n",
      "2023-12-04 19:12:37,673 INFO     Training average negative_sample_loss at step 40000: 0.175903\n",
      "2023-12-04 19:12:37,673 INFO     Training average loss at step 40000: 0.182378\n",
      "2023-12-04 19:12:37,673 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 19:12:38,621 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 19:13:24,981 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 19:14:09,173 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 19:14:18,068 INFO     Valid MRR at step 40000: 0.337589\n",
      "2023-12-04 19:14:18,068 INFO     Valid MR at step 40000: 169.108127\n",
      "2023-12-04 19:14:18,068 INFO     Valid HITS@1 at step 40000: 0.241545\n",
      "2023-12-04 19:14:18,069 INFO     Valid HITS@3 at step 40000: 0.375250\n",
      "2023-12-04 19:14:18,069 INFO     Valid HITS@10 at step 40000: 0.529769\n",
      "2023-12-04 19:14:29,542 INFO     Training average positive_sample_loss at step 40100: 0.196437\n",
      "2023-12-04 19:14:29,542 INFO     Training average negative_sample_loss at step 40100: 0.175201\n",
      "2023-12-04 19:14:29,542 INFO     Training average loss at step 40100: 0.185819\n",
      "2023-12-04 19:14:41,316 INFO     Training average positive_sample_loss at step 40200: 0.199626\n",
      "2023-12-04 19:14:41,317 INFO     Training average negative_sample_loss at step 40200: 0.177176\n",
      "2023-12-04 19:14:41,317 INFO     Training average loss at step 40200: 0.188401\n",
      "2023-12-04 19:14:53,198 INFO     Training average positive_sample_loss at step 40300: 0.199556\n",
      "2023-12-04 19:14:53,199 INFO     Training average negative_sample_loss at step 40300: 0.177667\n",
      "2023-12-04 19:14:53,199 INFO     Training average loss at step 40300: 0.188611\n",
      "2023-12-04 19:15:05,138 INFO     Training average positive_sample_loss at step 40400: 0.199999\n",
      "2023-12-04 19:15:05,138 INFO     Training average negative_sample_loss at step 40400: 0.179337\n",
      "2023-12-04 19:15:05,138 INFO     Training average loss at step 40400: 0.189668\n",
      "2023-12-04 19:15:17,148 INFO     Training average positive_sample_loss at step 40500: 0.191188\n",
      "2023-12-04 19:15:17,149 INFO     Training average negative_sample_loss at step 40500: 0.177623\n",
      "2023-12-04 19:15:17,149 INFO     Training average loss at step 40500: 0.184405\n",
      "2023-12-04 19:15:25,616 INFO     Training average positive_sample_loss at step 40600: 0.195596\n",
      "2023-12-04 19:15:25,617 INFO     Training average negative_sample_loss at step 40600: 0.174687\n",
      "2023-12-04 19:15:25,617 INFO     Training average loss at step 40600: 0.185142\n",
      "2023-12-04 19:15:37,422 INFO     Training average positive_sample_loss at step 40700: 0.197238\n",
      "2023-12-04 19:15:37,422 INFO     Training average negative_sample_loss at step 40700: 0.175605\n",
      "2023-12-04 19:15:37,422 INFO     Training average loss at step 40700: 0.186421\n",
      "2023-12-04 19:15:49,340 INFO     Training average positive_sample_loss at step 40800: 0.199648\n",
      "2023-12-04 19:15:49,341 INFO     Training average negative_sample_loss at step 40800: 0.177703\n",
      "2023-12-04 19:15:49,341 INFO     Training average loss at step 40800: 0.188675\n",
      "2023-12-04 19:16:01,438 INFO     Training average positive_sample_loss at step 40900: 0.199555\n",
      "2023-12-04 19:16:01,438 INFO     Training average negative_sample_loss at step 40900: 0.178989\n",
      "2023-12-04 19:16:01,438 INFO     Training average loss at step 40900: 0.189272\n",
      "2023-12-04 19:16:13,911 INFO     Training average positive_sample_loss at step 41000: 0.194239\n",
      "2023-12-04 19:16:13,911 INFO     Training average negative_sample_loss at step 41000: 0.178865\n",
      "2023-12-04 19:16:13,911 INFO     Training average loss at step 41000: 0.186552\n",
      "2023-12-04 19:16:25,617 INFO     Training average positive_sample_loss at step 41100: 0.193080\n",
      "2023-12-04 19:16:25,617 INFO     Training average negative_sample_loss at step 41100: 0.175089\n",
      "2023-12-04 19:16:25,618 INFO     Training average loss at step 41100: 0.184084\n",
      "2023-12-04 19:16:34,047 INFO     Training average positive_sample_loss at step 41200: 0.197985\n",
      "2023-12-04 19:16:34,048 INFO     Training average negative_sample_loss at step 41200: 0.175592\n",
      "2023-12-04 19:16:34,048 INFO     Training average loss at step 41200: 0.186789\n",
      "2023-12-04 19:16:45,673 INFO     Training average positive_sample_loss at step 41300: 0.199179\n",
      "2023-12-04 19:16:45,673 INFO     Training average negative_sample_loss at step 41300: 0.178059\n",
      "2023-12-04 19:16:45,673 INFO     Training average loss at step 41300: 0.188619\n",
      "2023-12-04 19:16:57,353 INFO     Training average positive_sample_loss at step 41400: 0.200001\n",
      "2023-12-04 19:16:57,353 INFO     Training average negative_sample_loss at step 41400: 0.178489\n",
      "2023-12-04 19:16:57,353 INFO     Training average loss at step 41400: 0.189245\n",
      "2023-12-04 19:17:09,825 INFO     Training average positive_sample_loss at step 41500: 0.198373\n",
      "2023-12-04 19:17:09,826 INFO     Training average negative_sample_loss at step 41500: 0.178583\n",
      "2023-12-04 19:17:09,826 INFO     Training average loss at step 41500: 0.188478\n",
      "2023-12-04 19:17:21,154 INFO     Training average positive_sample_loss at step 41600: 0.189252\n",
      "2023-12-04 19:17:21,154 INFO     Training average negative_sample_loss at step 41600: 0.175342\n",
      "2023-12-04 19:17:21,154 INFO     Training average loss at step 41600: 0.182297\n",
      "2023-12-04 19:17:33,000 INFO     Training average positive_sample_loss at step 41700: 0.196372\n",
      "2023-12-04 19:17:33,001 INFO     Training average negative_sample_loss at step 41700: 0.174074\n",
      "2023-12-04 19:17:33,001 INFO     Training average loss at step 41700: 0.185223\n",
      "2023-12-04 19:17:41,268 INFO     Training average positive_sample_loss at step 41800: 0.198687\n",
      "2023-12-04 19:17:41,268 INFO     Training average negative_sample_loss at step 41800: 0.176555\n",
      "2023-12-04 19:17:41,268 INFO     Training average loss at step 41800: 0.187621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:17:52,874 INFO     Training average positive_sample_loss at step 41900: 0.199770\n",
      "2023-12-04 19:17:52,874 INFO     Training average negative_sample_loss at step 41900: 0.177852\n",
      "2023-12-04 19:17:52,874 INFO     Training average loss at step 41900: 0.188811\n",
      "2023-12-04 19:18:04,862 INFO     Training average positive_sample_loss at step 42000: 0.200364\n",
      "2023-12-04 19:18:04,863 INFO     Training average negative_sample_loss at step 42000: 0.179961\n",
      "2023-12-04 19:18:04,863 INFO     Training average loss at step 42000: 0.190162\n",
      "2023-12-04 19:18:17,194 INFO     Training average positive_sample_loss at step 42100: 0.190792\n",
      "2023-12-04 19:18:17,194 INFO     Training average negative_sample_loss at step 42100: 0.177005\n",
      "2023-12-04 19:18:17,194 INFO     Training average loss at step 42100: 0.183899\n",
      "2023-12-04 19:18:29,097 INFO     Training average positive_sample_loss at step 42200: 0.195451\n",
      "2023-12-04 19:18:29,097 INFO     Training average negative_sample_loss at step 42200: 0.174674\n",
      "2023-12-04 19:18:29,097 INFO     Training average loss at step 42200: 0.185062\n",
      "2023-12-04 19:18:40,853 INFO     Training average positive_sample_loss at step 42300: 0.197658\n",
      "2023-12-04 19:18:40,853 INFO     Training average negative_sample_loss at step 42300: 0.176156\n",
      "2023-12-04 19:18:40,853 INFO     Training average loss at step 42300: 0.186907\n",
      "2023-12-04 19:18:50,157 INFO     Training average positive_sample_loss at step 42400: 0.199265\n",
      "2023-12-04 19:18:50,157 INFO     Training average negative_sample_loss at step 42400: 0.177570\n",
      "2023-12-04 19:18:50,157 INFO     Training average loss at step 42400: 0.188418\n",
      "2023-12-04 19:19:00,972 INFO     Training average positive_sample_loss at step 42500: 0.199591\n",
      "2023-12-04 19:19:00,972 INFO     Training average negative_sample_loss at step 42500: 0.178654\n",
      "2023-12-04 19:19:00,972 INFO     Training average loss at step 42500: 0.189122\n",
      "2023-12-04 19:19:13,269 INFO     Training average positive_sample_loss at step 42600: 0.194291\n",
      "2023-12-04 19:19:13,270 INFO     Training average negative_sample_loss at step 42600: 0.179176\n",
      "2023-12-04 19:19:13,270 INFO     Training average loss at step 42600: 0.186733\n",
      "2023-12-04 19:19:24,960 INFO     Training average positive_sample_loss at step 42700: 0.193339\n",
      "2023-12-04 19:19:24,960 INFO     Training average negative_sample_loss at step 42700: 0.174224\n",
      "2023-12-04 19:19:24,960 INFO     Training average loss at step 42700: 0.183781\n",
      "2023-12-04 19:19:36,890 INFO     Training average positive_sample_loss at step 42800: 0.197863\n",
      "2023-12-04 19:19:36,890 INFO     Training average negative_sample_loss at step 42800: 0.175869\n",
      "2023-12-04 19:19:36,891 INFO     Training average loss at step 42800: 0.186866\n",
      "2023-12-04 19:19:48,813 INFO     Training average positive_sample_loss at step 42900: 0.198880\n",
      "2023-12-04 19:19:48,814 INFO     Training average negative_sample_loss at step 42900: 0.176986\n",
      "2023-12-04 19:19:48,814 INFO     Training average loss at step 42900: 0.187933\n",
      "2023-12-04 19:19:59,328 INFO     Training average positive_sample_loss at step 43000: 0.199917\n",
      "2023-12-04 19:19:59,329 INFO     Training average negative_sample_loss at step 43000: 0.178033\n",
      "2023-12-04 19:19:59,329 INFO     Training average loss at step 43000: 0.188975\n",
      "2023-12-04 19:20:09,320 INFO     Training average positive_sample_loss at step 43100: 0.198853\n",
      "2023-12-04 19:20:09,321 INFO     Training average negative_sample_loss at step 43100: 0.180051\n",
      "2023-12-04 19:20:09,321 INFO     Training average loss at step 43100: 0.189452\n",
      "2023-12-04 19:20:20,707 INFO     Training average positive_sample_loss at step 43200: 0.189819\n",
      "2023-12-04 19:20:20,708 INFO     Training average negative_sample_loss at step 43200: 0.174457\n",
      "2023-12-04 19:20:20,708 INFO     Training average loss at step 43200: 0.182138\n",
      "2023-12-04 19:20:32,491 INFO     Training average positive_sample_loss at step 43300: 0.196534\n",
      "2023-12-04 19:20:32,491 INFO     Training average negative_sample_loss at step 43300: 0.175052\n",
      "2023-12-04 19:20:32,491 INFO     Training average loss at step 43300: 0.185793\n",
      "2023-12-04 19:20:44,354 INFO     Training average positive_sample_loss at step 43400: 0.198110\n",
      "2023-12-04 19:20:44,354 INFO     Training average negative_sample_loss at step 43400: 0.176732\n",
      "2023-12-04 19:20:44,354 INFO     Training average loss at step 43400: 0.187421\n",
      "2023-12-04 19:20:56,267 INFO     Training average positive_sample_loss at step 43500: 0.199951\n",
      "2023-12-04 19:20:56,267 INFO     Training average negative_sample_loss at step 43500: 0.178289\n",
      "2023-12-04 19:20:56,267 INFO     Training average loss at step 43500: 0.189120\n",
      "2023-12-04 19:21:08,362 INFO     Training average positive_sample_loss at step 43600: 0.200621\n",
      "2023-12-04 19:21:08,363 INFO     Training average negative_sample_loss at step 43600: 0.179164\n",
      "2023-12-04 19:21:08,363 INFO     Training average loss at step 43600: 0.189892\n",
      "2023-12-04 19:21:18,200 INFO     Training average positive_sample_loss at step 43700: 0.190412\n",
      "2023-12-04 19:21:18,200 INFO     Training average negative_sample_loss at step 43700: 0.176599\n",
      "2023-12-04 19:21:18,200 INFO     Training average loss at step 43700: 0.183505\n",
      "2023-12-04 19:21:29,866 INFO     Training average positive_sample_loss at step 43800: 0.195121\n",
      "2023-12-04 19:21:29,866 INFO     Training average negative_sample_loss at step 43800: 0.174416\n",
      "2023-12-04 19:21:29,866 INFO     Training average loss at step 43800: 0.184768\n",
      "2023-12-04 19:21:41,712 INFO     Training average positive_sample_loss at step 43900: 0.198082\n",
      "2023-12-04 19:21:41,712 INFO     Training average negative_sample_loss at step 43900: 0.176915\n",
      "2023-12-04 19:21:41,712 INFO     Training average loss at step 43900: 0.187498\n",
      "2023-12-04 19:21:53,385 INFO     Training average positive_sample_loss at step 44000: 0.199422\n",
      "2023-12-04 19:21:53,385 INFO     Training average negative_sample_loss at step 44000: 0.177711\n",
      "2023-12-04 19:21:53,385 INFO     Training average loss at step 44000: 0.188566\n",
      "2023-12-04 19:22:04,995 INFO     Training average positive_sample_loss at step 44100: 0.200280\n",
      "2023-12-04 19:22:04,995 INFO     Training average negative_sample_loss at step 44100: 0.179045\n",
      "2023-12-04 19:22:04,995 INFO     Training average loss at step 44100: 0.189663\n",
      "2023-12-04 19:22:17,182 INFO     Training average positive_sample_loss at step 44200: 0.193686\n",
      "2023-12-04 19:22:17,183 INFO     Training average negative_sample_loss at step 44200: 0.179311\n",
      "2023-12-04 19:22:17,183 INFO     Training average loss at step 44200: 0.186499\n",
      "2023-12-04 19:22:25,355 INFO     Training average positive_sample_loss at step 44300: 0.193540\n",
      "2023-12-04 19:22:25,355 INFO     Training average negative_sample_loss at step 44300: 0.173444\n",
      "2023-12-04 19:22:25,355 INFO     Training average loss at step 44300: 0.183492\n",
      "2023-12-04 19:22:36,874 INFO     Training average positive_sample_loss at step 44400: 0.198159\n",
      "2023-12-04 19:22:36,875 INFO     Training average negative_sample_loss at step 44400: 0.175873\n",
      "2023-12-04 19:22:36,875 INFO     Training average loss at step 44400: 0.187016\n",
      "2023-12-04 19:22:48,651 INFO     Training average positive_sample_loss at step 44500: 0.199205\n",
      "2023-12-04 19:22:48,651 INFO     Training average negative_sample_loss at step 44500: 0.178155\n",
      "2023-12-04 19:22:48,652 INFO     Training average loss at step 44500: 0.188680\n",
      "2023-12-04 19:23:00,733 INFO     Training average positive_sample_loss at step 44600: 0.199260\n",
      "2023-12-04 19:23:00,734 INFO     Training average negative_sample_loss at step 44600: 0.178688\n",
      "2023-12-04 19:23:00,734 INFO     Training average loss at step 44600: 0.188974\n",
      "2023-12-04 19:23:13,412 INFO     Training average positive_sample_loss at step 44700: 0.197769\n",
      "2023-12-04 19:23:13,412 INFO     Training average negative_sample_loss at step 44700: 0.179263\n",
      "2023-12-04 19:23:13,412 INFO     Training average loss at step 44700: 0.188516\n",
      "2023-12-04 19:23:24,905 INFO     Training average positive_sample_loss at step 44800: 0.190851\n",
      "2023-12-04 19:23:24,905 INFO     Training average negative_sample_loss at step 44800: 0.174450\n",
      "2023-12-04 19:23:24,905 INFO     Training average loss at step 44800: 0.182650\n",
      "2023-12-04 19:23:33,160 INFO     Training average positive_sample_loss at step 44900: 0.196359\n",
      "2023-12-04 19:23:33,160 INFO     Training average negative_sample_loss at step 44900: 0.174839\n",
      "2023-12-04 19:23:33,160 INFO     Training average loss at step 44900: 0.185599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:23:44,658 INFO     Training average positive_sample_loss at step 45000: 0.199307\n",
      "2023-12-04 19:23:44,658 INFO     Training average negative_sample_loss at step 45000: 0.176841\n",
      "2023-12-04 19:23:44,658 INFO     Training average loss at step 45000: 0.188074\n",
      "2023-12-04 19:23:56,559 INFO     Training average positive_sample_loss at step 45100: 0.199152\n",
      "2023-12-04 19:23:56,559 INFO     Training average negative_sample_loss at step 45100: 0.177410\n",
      "2023-12-04 19:23:56,559 INFO     Training average loss at step 45100: 0.188281\n",
      "2023-12-04 19:24:08,552 INFO     Training average positive_sample_loss at step 45200: 0.200101\n",
      "2023-12-04 19:24:08,553 INFO     Training average negative_sample_loss at step 45200: 0.179025\n",
      "2023-12-04 19:24:08,553 INFO     Training average loss at step 45200: 0.189563\n",
      "2023-12-04 19:24:20,775 INFO     Training average positive_sample_loss at step 45300: 0.189707\n",
      "2023-12-04 19:24:20,775 INFO     Training average negative_sample_loss at step 45300: 0.175336\n",
      "2023-12-04 19:24:20,775 INFO     Training average loss at step 45300: 0.182521\n",
      "2023-12-04 19:24:32,826 INFO     Training average positive_sample_loss at step 45400: 0.194981\n",
      "2023-12-04 19:24:32,826 INFO     Training average negative_sample_loss at step 45400: 0.174555\n",
      "2023-12-04 19:24:32,826 INFO     Training average loss at step 45400: 0.184768\n",
      "2023-12-04 19:24:42,440 INFO     Training average positive_sample_loss at step 45500: 0.198418\n",
      "2023-12-04 19:24:42,441 INFO     Training average negative_sample_loss at step 45500: 0.176412\n",
      "2023-12-04 19:24:42,441 INFO     Training average loss at step 45500: 0.187415\n",
      "2023-12-04 19:24:52,492 INFO     Training average positive_sample_loss at step 45600: 0.199638\n",
      "2023-12-04 19:24:52,492 INFO     Training average negative_sample_loss at step 45600: 0.177500\n",
      "2023-12-04 19:24:52,492 INFO     Training average loss at step 45600: 0.188569\n",
      "2023-12-04 19:25:04,176 INFO     Training average positive_sample_loss at step 45700: 0.200368\n",
      "2023-12-04 19:25:04,176 INFO     Training average negative_sample_loss at step 45700: 0.178310\n",
      "2023-12-04 19:25:04,176 INFO     Training average loss at step 45700: 0.189339\n",
      "2023-12-04 19:25:16,589 INFO     Training average positive_sample_loss at step 45800: 0.192638\n",
      "2023-12-04 19:25:16,589 INFO     Training average negative_sample_loss at step 45800: 0.178808\n",
      "2023-12-04 19:25:16,589 INFO     Training average loss at step 45800: 0.185723\n",
      "2023-12-04 19:25:28,287 INFO     Training average positive_sample_loss at step 45900: 0.193792\n",
      "2023-12-04 19:25:28,288 INFO     Training average negative_sample_loss at step 45900: 0.174302\n",
      "2023-12-04 19:25:28,288 INFO     Training average loss at step 45900: 0.184047\n",
      "2023-12-04 19:25:40,273 INFO     Training average positive_sample_loss at step 46000: 0.198116\n",
      "2023-12-04 19:25:40,274 INFO     Training average negative_sample_loss at step 46000: 0.176617\n",
      "2023-12-04 19:25:40,274 INFO     Training average loss at step 46000: 0.187367\n",
      "2023-12-04 19:25:51,516 INFO     Training average positive_sample_loss at step 46100: 0.199100\n",
      "2023-12-04 19:25:51,517 INFO     Training average negative_sample_loss at step 46100: 0.176425\n",
      "2023-12-04 19:25:51,517 INFO     Training average loss at step 46100: 0.187763\n",
      "2023-12-04 19:26:00,383 INFO     Training average positive_sample_loss at step 46200: 0.200659\n",
      "2023-12-04 19:26:00,383 INFO     Training average negative_sample_loss at step 46200: 0.179506\n",
      "2023-12-04 19:26:00,383 INFO     Training average loss at step 46200: 0.190083\n",
      "2023-12-04 19:26:12,763 INFO     Training average positive_sample_loss at step 46300: 0.197296\n",
      "2023-12-04 19:26:12,764 INFO     Training average negative_sample_loss at step 46300: 0.180334\n",
      "2023-12-04 19:26:12,764 INFO     Training average loss at step 46300: 0.188815\n",
      "2023-12-04 19:26:24,433 INFO     Training average positive_sample_loss at step 46400: 0.190856\n",
      "2023-12-04 19:26:24,433 INFO     Training average negative_sample_loss at step 46400: 0.173696\n",
      "2023-12-04 19:26:24,433 INFO     Training average loss at step 46400: 0.182276\n",
      "2023-12-04 19:26:36,516 INFO     Training average positive_sample_loss at step 46500: 0.197807\n",
      "2023-12-04 19:26:36,517 INFO     Training average negative_sample_loss at step 46500: 0.174849\n",
      "2023-12-04 19:26:36,517 INFO     Training average loss at step 46500: 0.186328\n",
      "2023-12-04 19:26:48,562 INFO     Training average positive_sample_loss at step 46600: 0.197871\n",
      "2023-12-04 19:26:48,562 INFO     Training average negative_sample_loss at step 46600: 0.176286\n",
      "2023-12-04 19:26:48,562 INFO     Training average loss at step 46600: 0.187078\n",
      "2023-12-04 19:27:00,620 INFO     Training average positive_sample_loss at step 46700: 0.199741\n",
      "2023-12-04 19:27:00,620 INFO     Training average negative_sample_loss at step 46700: 0.179195\n",
      "2023-12-04 19:27:00,620 INFO     Training average loss at step 46700: 0.189468\n",
      "2023-12-04 19:27:08,836 INFO     Training average positive_sample_loss at step 46800: 0.200393\n",
      "2023-12-04 19:27:08,836 INFO     Training average negative_sample_loss at step 46800: 0.178811\n",
      "2023-12-04 19:27:08,836 INFO     Training average loss at step 46800: 0.189602\n",
      "2023-12-04 19:27:20,779 INFO     Training average positive_sample_loss at step 46900: 0.189241\n",
      "2023-12-04 19:27:20,780 INFO     Training average negative_sample_loss at step 46900: 0.176083\n",
      "2023-12-04 19:27:20,780 INFO     Training average loss at step 46900: 0.182662\n",
      "2023-12-04 19:27:32,443 INFO     Training average positive_sample_loss at step 47000: 0.196804\n",
      "2023-12-04 19:27:32,443 INFO     Training average negative_sample_loss at step 47000: 0.175527\n",
      "2023-12-04 19:27:32,443 INFO     Training average loss at step 47000: 0.186166\n",
      "2023-12-04 19:27:44,381 INFO     Training average positive_sample_loss at step 47100: 0.197862\n",
      "2023-12-04 19:27:44,382 INFO     Training average negative_sample_loss at step 47100: 0.175470\n",
      "2023-12-04 19:27:44,382 INFO     Training average loss at step 47100: 0.186666\n",
      "2023-12-04 19:27:56,362 INFO     Training average positive_sample_loss at step 47200: 0.199962\n",
      "2023-12-04 19:27:56,362 INFO     Training average negative_sample_loss at step 47200: 0.178298\n",
      "2023-12-04 19:27:56,362 INFO     Training average loss at step 47200: 0.189130\n",
      "2023-12-04 19:28:08,401 INFO     Training average positive_sample_loss at step 47300: 0.200001\n",
      "2023-12-04 19:28:08,401 INFO     Training average negative_sample_loss at step 47300: 0.178684\n",
      "2023-12-04 19:28:08,401 INFO     Training average loss at step 47300: 0.189343\n",
      "2023-12-04 19:28:18,089 INFO     Training average positive_sample_loss at step 47400: 0.192097\n",
      "2023-12-04 19:28:18,089 INFO     Training average negative_sample_loss at step 47400: 0.178329\n",
      "2023-12-04 19:28:18,089 INFO     Training average loss at step 47400: 0.185213\n",
      "2023-12-04 19:28:29,019 INFO     Training average positive_sample_loss at step 47500: 0.194595\n",
      "2023-12-04 19:28:29,020 INFO     Training average negative_sample_loss at step 47500: 0.173583\n",
      "2023-12-04 19:28:29,020 INFO     Training average loss at step 47500: 0.184089\n",
      "2023-12-04 19:28:35,574 INFO     Training average positive_sample_loss at step 47600: 0.197148\n",
      "2023-12-04 19:28:35,574 INFO     Training average negative_sample_loss at step 47600: 0.175385\n",
      "2023-12-04 19:28:35,574 INFO     Training average loss at step 47600: 0.186267\n",
      "2023-12-04 19:28:43,329 INFO     Training average positive_sample_loss at step 47700: 0.199166\n",
      "2023-12-04 19:28:43,329 INFO     Training average negative_sample_loss at step 47700: 0.176828\n",
      "2023-12-04 19:28:43,329 INFO     Training average loss at step 47700: 0.187997\n",
      "2023-12-04 19:28:52,264 INFO     Training average positive_sample_loss at step 47800: 0.200461\n",
      "2023-12-04 19:28:52,264 INFO     Training average negative_sample_loss at step 47800: 0.178634\n",
      "2023-12-04 19:28:52,264 INFO     Training average loss at step 47800: 0.189547\n",
      "2023-12-04 19:29:01,773 INFO     Training average positive_sample_loss at step 47900: 0.196535\n",
      "2023-12-04 19:29:01,773 INFO     Training average negative_sample_loss at step 47900: 0.179130\n",
      "2023-12-04 19:29:01,773 INFO     Training average loss at step 47900: 0.187832\n",
      "2023-12-04 19:29:09,966 INFO     Training average positive_sample_loss at step 48000: 0.191023\n",
      "2023-12-04 19:29:09,966 INFO     Training average negative_sample_loss at step 48000: 0.174659\n",
      "2023-12-04 19:29:09,966 INFO     Training average loss at step 48000: 0.182841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:29:18,520 INFO     Training average positive_sample_loss at step 48100: 0.196935\n",
      "2023-12-04 19:29:18,520 INFO     Training average negative_sample_loss at step 48100: 0.174505\n",
      "2023-12-04 19:29:18,520 INFO     Training average loss at step 48100: 0.185720\n",
      "2023-12-04 19:29:27,661 INFO     Training average positive_sample_loss at step 48200: 0.198576\n",
      "2023-12-04 19:29:27,662 INFO     Training average negative_sample_loss at step 48200: 0.175999\n",
      "2023-12-04 19:29:27,662 INFO     Training average loss at step 48200: 0.187287\n",
      "2023-12-04 19:29:36,703 INFO     Training average positive_sample_loss at step 48300: 0.199650\n",
      "2023-12-04 19:29:36,703 INFO     Training average negative_sample_loss at step 48300: 0.177013\n",
      "2023-12-04 19:29:36,703 INFO     Training average loss at step 48300: 0.188331\n",
      "2023-12-04 19:29:48,274 INFO     Training average positive_sample_loss at step 48400: 0.200030\n",
      "2023-12-04 19:29:48,274 INFO     Training average negative_sample_loss at step 48400: 0.179978\n",
      "2023-12-04 19:29:48,274 INFO     Training average loss at step 48400: 0.190004\n",
      "2023-12-04 19:30:00,469 INFO     Training average positive_sample_loss at step 48500: 0.189112\n",
      "2023-12-04 19:30:00,469 INFO     Training average negative_sample_loss at step 48500: 0.175381\n",
      "2023-12-04 19:30:00,469 INFO     Training average loss at step 48500: 0.182246\n",
      "2023-12-04 19:30:12,376 INFO     Training average positive_sample_loss at step 48600: 0.195707\n",
      "2023-12-04 19:30:12,376 INFO     Training average negative_sample_loss at step 48600: 0.173965\n",
      "2023-12-04 19:30:12,376 INFO     Training average loss at step 48600: 0.184836\n",
      "2023-12-04 19:30:24,312 INFO     Training average positive_sample_loss at step 48700: 0.198857\n",
      "2023-12-04 19:30:24,313 INFO     Training average negative_sample_loss at step 48700: 0.176616\n",
      "2023-12-04 19:30:24,313 INFO     Training average loss at step 48700: 0.187736\n",
      "2023-12-04 19:30:33,429 INFO     Training average positive_sample_loss at step 48800: 0.198731\n",
      "2023-12-04 19:30:33,429 INFO     Training average negative_sample_loss at step 48800: 0.177171\n",
      "2023-12-04 19:30:33,429 INFO     Training average loss at step 48800: 0.187951\n",
      "2023-12-04 19:30:44,423 INFO     Training average positive_sample_loss at step 48900: 0.200812\n",
      "2023-12-04 19:30:44,423 INFO     Training average negative_sample_loss at step 48900: 0.178888\n",
      "2023-12-04 19:30:44,423 INFO     Training average loss at step 48900: 0.189850\n",
      "2023-12-04 19:30:56,851 INFO     Training average positive_sample_loss at step 49000: 0.191959\n",
      "2023-12-04 19:30:56,851 INFO     Training average negative_sample_loss at step 49000: 0.177047\n",
      "2023-12-04 19:30:56,851 INFO     Training average loss at step 49000: 0.184503\n",
      "2023-12-04 19:31:08,647 INFO     Training average positive_sample_loss at step 49100: 0.194301\n",
      "2023-12-04 19:31:08,647 INFO     Training average negative_sample_loss at step 49100: 0.173679\n",
      "2023-12-04 19:31:08,647 INFO     Training average loss at step 49100: 0.183990\n",
      "2023-12-04 19:31:20,671 INFO     Training average positive_sample_loss at step 49200: 0.197108\n",
      "2023-12-04 19:31:20,672 INFO     Training average negative_sample_loss at step 49200: 0.174171\n",
      "2023-12-04 19:31:20,672 INFO     Training average loss at step 49200: 0.185640\n",
      "2023-12-04 19:31:32,815 INFO     Training average positive_sample_loss at step 49300: 0.198981\n",
      "2023-12-04 19:31:32,816 INFO     Training average negative_sample_loss at step 49300: 0.177805\n",
      "2023-12-04 19:31:32,816 INFO     Training average loss at step 49300: 0.188393\n",
      "2023-12-04 19:31:42,719 INFO     Training average positive_sample_loss at step 49400: 0.199792\n",
      "2023-12-04 19:31:42,719 INFO     Training average negative_sample_loss at step 49400: 0.178356\n",
      "2023-12-04 19:31:42,719 INFO     Training average loss at step 49400: 0.189074\n",
      "2023-12-04 19:31:53,279 INFO     Training average positive_sample_loss at step 49500: 0.195377\n",
      "2023-12-04 19:31:53,279 INFO     Training average negative_sample_loss at step 49500: 0.177390\n",
      "2023-12-04 19:31:53,279 INFO     Training average loss at step 49500: 0.186383\n",
      "2023-12-04 19:32:04,930 INFO     Training average positive_sample_loss at step 49600: 0.191841\n",
      "2023-12-04 19:32:04,930 INFO     Training average negative_sample_loss at step 49600: 0.175101\n",
      "2023-12-04 19:32:04,930 INFO     Training average loss at step 49600: 0.183471\n",
      "2023-12-04 19:32:16,815 INFO     Training average positive_sample_loss at step 49700: 0.197415\n",
      "2023-12-04 19:32:16,816 INFO     Training average negative_sample_loss at step 49700: 0.174207\n",
      "2023-12-04 19:32:16,816 INFO     Training average loss at step 49700: 0.185811\n",
      "2023-12-04 19:32:28,855 INFO     Training average positive_sample_loss at step 49800: 0.198656\n",
      "2023-12-04 19:32:28,856 INFO     Training average negative_sample_loss at step 49800: 0.176905\n",
      "2023-12-04 19:32:28,856 INFO     Training average loss at step 49800: 0.187780\n",
      "2023-12-04 19:32:40,944 INFO     Training average positive_sample_loss at step 49900: 0.199569\n",
      "2023-12-04 19:32:40,944 INFO     Training average negative_sample_loss at step 49900: 0.177184\n",
      "2023-12-04 19:32:40,944 INFO     Training average loss at step 49900: 0.188377\n",
      "2023-12-04 19:32:51,983 INFO     Change learning_rate to 0.000005 at step 50000\n",
      "2023-12-04 19:32:57,556 INFO     Training average positive_sample_loss at step 50000: 0.199687\n",
      "2023-12-04 19:32:58,117 INFO     Training average negative_sample_loss at step 50000: 0.179526\n",
      "2023-12-04 19:32:58,117 INFO     Training average loss at step 50000: 0.189606\n",
      "2023-12-04 19:32:58,117 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 19:32:58,752 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 19:33:48,239 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 19:34:35,238 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 19:34:45,835 INFO     Valid MRR at step 50000: 0.337670\n",
      "2023-12-04 19:34:45,836 INFO     Valid MR at step 50000: 169.323952\n",
      "2023-12-04 19:34:45,836 INFO     Valid HITS@1 at step 50000: 0.242059\n",
      "2023-12-04 19:34:45,836 INFO     Valid HITS@3 at step 50000: 0.373881\n",
      "2023-12-04 19:34:45,836 INFO     Valid HITS@10 at step 50000: 0.530425\n",
      "2023-12-04 19:34:57,598 INFO     Training average positive_sample_loss at step 50100: 0.184833\n",
      "2023-12-04 19:34:57,600 INFO     Training average negative_sample_loss at step 50100: 0.176099\n",
      "2023-12-04 19:34:57,600 INFO     Training average loss at step 50100: 0.180466\n",
      "2023-12-04 19:35:09,286 INFO     Training average positive_sample_loss at step 50200: 0.184495\n",
      "2023-12-04 19:35:09,287 INFO     Training average negative_sample_loss at step 50200: 0.175824\n",
      "2023-12-04 19:35:09,287 INFO     Training average loss at step 50200: 0.180159\n",
      "2023-12-04 19:35:17,419 INFO     Training average positive_sample_loss at step 50300: 0.184821\n",
      "2023-12-04 19:35:17,419 INFO     Training average negative_sample_loss at step 50300: 0.174946\n",
      "2023-12-04 19:35:17,419 INFO     Training average loss at step 50300: 0.179883\n",
      "2023-12-04 19:35:29,198 INFO     Training average positive_sample_loss at step 50400: 0.185760\n",
      "2023-12-04 19:35:29,198 INFO     Training average negative_sample_loss at step 50400: 0.173615\n",
      "2023-12-04 19:35:29,198 INFO     Training average loss at step 50400: 0.179687\n",
      "2023-12-04 19:35:41,129 INFO     Training average positive_sample_loss at step 50500: 0.185751\n",
      "2023-12-04 19:35:41,129 INFO     Training average negative_sample_loss at step 50500: 0.174936\n",
      "2023-12-04 19:35:41,130 INFO     Training average loss at step 50500: 0.180343\n",
      "2023-12-04 19:35:53,567 INFO     Training average positive_sample_loss at step 50600: 0.183044\n",
      "2023-12-04 19:35:53,568 INFO     Training average negative_sample_loss at step 50600: 0.173315\n",
      "2023-12-04 19:35:53,568 INFO     Training average loss at step 50600: 0.178180\n",
      "2023-12-04 19:36:05,396 INFO     Training average positive_sample_loss at step 50700: 0.183383\n",
      "2023-12-04 19:36:05,396 INFO     Training average negative_sample_loss at step 50700: 0.171971\n",
      "2023-12-04 19:36:05,396 INFO     Training average loss at step 50700: 0.177677\n",
      "2023-12-04 19:36:17,358 INFO     Training average positive_sample_loss at step 50800: 0.184724\n",
      "2023-12-04 19:36:17,358 INFO     Training average negative_sample_loss at step 50800: 0.172250\n",
      "2023-12-04 19:36:17,358 INFO     Training average loss at step 50800: 0.178487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:36:25,640 INFO     Training average positive_sample_loss at step 50900: 0.184669\n",
      "2023-12-04 19:36:25,640 INFO     Training average negative_sample_loss at step 50900: 0.171370\n",
      "2023-12-04 19:36:25,640 INFO     Training average loss at step 50900: 0.178020\n",
      "2023-12-04 19:36:37,382 INFO     Training average positive_sample_loss at step 51000: 0.183886\n",
      "2023-12-04 19:36:37,383 INFO     Training average negative_sample_loss at step 51000: 0.171488\n",
      "2023-12-04 19:36:37,383 INFO     Training average loss at step 51000: 0.177687\n",
      "2023-12-04 19:36:49,808 INFO     Training average positive_sample_loss at step 51100: 0.184933\n",
      "2023-12-04 19:36:49,809 INFO     Training average negative_sample_loss at step 51100: 0.171005\n",
      "2023-12-04 19:36:49,809 INFO     Training average loss at step 51100: 0.177969\n",
      "2023-12-04 19:37:01,663 INFO     Training average positive_sample_loss at step 51200: 0.182832\n",
      "2023-12-04 19:37:01,663 INFO     Training average negative_sample_loss at step 51200: 0.170841\n",
      "2023-12-04 19:37:01,663 INFO     Training average loss at step 51200: 0.176837\n",
      "2023-12-04 19:37:13,636 INFO     Training average positive_sample_loss at step 51300: 0.183184\n",
      "2023-12-04 19:37:13,637 INFO     Training average negative_sample_loss at step 51300: 0.170962\n",
      "2023-12-04 19:37:13,637 INFO     Training average loss at step 51300: 0.177073\n",
      "2023-12-04 19:37:25,594 INFO     Training average positive_sample_loss at step 51400: 0.184018\n",
      "2023-12-04 19:37:25,595 INFO     Training average negative_sample_loss at step 51400: 0.169445\n",
      "2023-12-04 19:37:25,595 INFO     Training average loss at step 51400: 0.176731\n",
      "2023-12-04 19:37:33,879 INFO     Training average positive_sample_loss at step 51500: 0.184334\n",
      "2023-12-04 19:37:33,879 INFO     Training average negative_sample_loss at step 51500: 0.171879\n",
      "2023-12-04 19:37:33,879 INFO     Training average loss at step 51500: 0.178107\n",
      "2023-12-04 19:37:45,624 INFO     Training average positive_sample_loss at step 51600: 0.185250\n",
      "2023-12-04 19:37:45,625 INFO     Training average negative_sample_loss at step 51600: 0.169689\n",
      "2023-12-04 19:37:45,625 INFO     Training average loss at step 51600: 0.177469\n",
      "2023-12-04 19:37:57,739 INFO     Training average positive_sample_loss at step 51700: 0.181991\n",
      "2023-12-04 19:37:57,740 INFO     Training average negative_sample_loss at step 51700: 0.169204\n",
      "2023-12-04 19:37:57,740 INFO     Training average loss at step 51700: 0.175598\n",
      "2023-12-04 19:38:09,473 INFO     Training average positive_sample_loss at step 51800: 0.183278\n",
      "2023-12-04 19:38:09,473 INFO     Training average negative_sample_loss at step 51800: 0.170487\n",
      "2023-12-04 19:38:09,473 INFO     Training average loss at step 51800: 0.176883\n",
      "2023-12-04 19:38:21,452 INFO     Training average positive_sample_loss at step 51900: 0.184032\n",
      "2023-12-04 19:38:21,453 INFO     Training average negative_sample_loss at step 51900: 0.169762\n",
      "2023-12-04 19:38:21,453 INFO     Training average loss at step 51900: 0.176897\n",
      "2023-12-04 19:38:33,512 INFO     Training average positive_sample_loss at step 52000: 0.185291\n",
      "2023-12-04 19:38:33,513 INFO     Training average negative_sample_loss at step 52000: 0.170836\n",
      "2023-12-04 19:38:33,513 INFO     Training average loss at step 52000: 0.178064\n",
      "2023-12-04 19:38:42,287 INFO     Training average positive_sample_loss at step 52100: 0.184862\n",
      "2023-12-04 19:38:42,287 INFO     Training average negative_sample_loss at step 52100: 0.169438\n",
      "2023-12-04 19:38:42,287 INFO     Training average loss at step 52100: 0.177150\n",
      "2023-12-04 19:38:53,638 INFO     Training average positive_sample_loss at step 52200: 0.183629\n",
      "2023-12-04 19:38:53,638 INFO     Training average negative_sample_loss at step 52200: 0.170066\n",
      "2023-12-04 19:38:53,638 INFO     Training average loss at step 52200: 0.176848\n",
      "2023-12-04 19:39:05,276 INFO     Training average positive_sample_loss at step 52300: 0.182609\n",
      "2023-12-04 19:39:05,276 INFO     Training average negative_sample_loss at step 52300: 0.170385\n",
      "2023-12-04 19:39:05,276 INFO     Training average loss at step 52300: 0.176497\n",
      "2023-12-04 19:39:17,108 INFO     Training average positive_sample_loss at step 52400: 0.183966\n",
      "2023-12-04 19:39:17,108 INFO     Training average negative_sample_loss at step 52400: 0.168996\n",
      "2023-12-04 19:39:17,109 INFO     Training average loss at step 52400: 0.176481\n",
      "2023-12-04 19:39:28,875 INFO     Training average positive_sample_loss at step 52500: 0.184941\n",
      "2023-12-04 19:39:28,875 INFO     Training average negative_sample_loss at step 52500: 0.168793\n",
      "2023-12-04 19:39:28,875 INFO     Training average loss at step 52500: 0.176867\n",
      "2023-12-04 19:39:40,644 INFO     Training average positive_sample_loss at step 52600: 0.185173\n",
      "2023-12-04 19:39:40,645 INFO     Training average negative_sample_loss at step 52600: 0.169309\n",
      "2023-12-04 19:39:40,645 INFO     Training average loss at step 52600: 0.177241\n",
      "2023-12-04 19:39:51,467 INFO     Training average positive_sample_loss at step 52700: 0.183954\n",
      "2023-12-04 19:39:51,468 INFO     Training average negative_sample_loss at step 52700: 0.168390\n",
      "2023-12-04 19:39:51,468 INFO     Training average loss at step 52700: 0.176172\n",
      "2023-12-04 19:40:01,009 INFO     Training average positive_sample_loss at step 52800: 0.182552\n",
      "2023-12-04 19:40:01,009 INFO     Training average negative_sample_loss at step 52800: 0.168633\n",
      "2023-12-04 19:40:01,009 INFO     Training average loss at step 52800: 0.175592\n",
      "2023-12-04 19:40:12,861 INFO     Training average positive_sample_loss at step 52900: 0.183625\n",
      "2023-12-04 19:40:12,862 INFO     Training average negative_sample_loss at step 52900: 0.168655\n",
      "2023-12-04 19:40:12,862 INFO     Training average loss at step 52900: 0.176140\n",
      "2023-12-04 19:40:24,734 INFO     Training average positive_sample_loss at step 53000: 0.184671\n",
      "2023-12-04 19:40:24,735 INFO     Training average negative_sample_loss at step 53000: 0.168676\n",
      "2023-12-04 19:40:24,735 INFO     Training average loss at step 53000: 0.176674\n",
      "2023-12-04 19:40:36,646 INFO     Training average positive_sample_loss at step 53100: 0.185792\n",
      "2023-12-04 19:40:36,647 INFO     Training average negative_sample_loss at step 53100: 0.169370\n",
      "2023-12-04 19:40:36,647 INFO     Training average loss at step 53100: 0.177581\n",
      "2023-12-04 19:40:49,021 INFO     Training average positive_sample_loss at step 53200: 0.185362\n",
      "2023-12-04 19:40:49,022 INFO     Training average negative_sample_loss at step 53200: 0.167864\n",
      "2023-12-04 19:40:49,022 INFO     Training average loss at step 53200: 0.176613\n",
      "2023-12-04 19:41:00,775 INFO     Training average positive_sample_loss at step 53300: 0.182071\n",
      "2023-12-04 19:41:00,775 INFO     Training average negative_sample_loss at step 53300: 0.167590\n",
      "2023-12-04 19:41:00,776 INFO     Training average loss at step 53300: 0.174831\n",
      "2023-12-04 19:41:08,972 INFO     Training average positive_sample_loss at step 53400: 0.183185\n",
      "2023-12-04 19:41:08,972 INFO     Training average negative_sample_loss at step 53400: 0.168544\n",
      "2023-12-04 19:41:08,972 INFO     Training average loss at step 53400: 0.175864\n",
      "2023-12-04 19:41:20,538 INFO     Training average positive_sample_loss at step 53500: 0.184350\n",
      "2023-12-04 19:41:20,538 INFO     Training average negative_sample_loss at step 53500: 0.168593\n",
      "2023-12-04 19:41:20,538 INFO     Training average loss at step 53500: 0.176472\n",
      "2023-12-04 19:41:32,343 INFO     Training average positive_sample_loss at step 53600: 0.185275\n",
      "2023-12-04 19:41:32,344 INFO     Training average negative_sample_loss at step 53600: 0.167979\n",
      "2023-12-04 19:41:32,344 INFO     Training average loss at step 53600: 0.176627\n",
      "2023-12-04 19:41:44,265 INFO     Training average positive_sample_loss at step 53700: 0.185122\n",
      "2023-12-04 19:41:44,266 INFO     Training average negative_sample_loss at step 53700: 0.168675\n",
      "2023-12-04 19:41:44,266 INFO     Training average loss at step 53700: 0.176899\n",
      "2023-12-04 19:41:56,592 INFO     Training average positive_sample_loss at step 53800: 0.182672\n",
      "2023-12-04 19:41:56,592 INFO     Training average negative_sample_loss at step 53800: 0.167857\n",
      "2023-12-04 19:41:56,593 INFO     Training average loss at step 53800: 0.175264\n",
      "2023-12-04 19:42:08,576 INFO     Training average positive_sample_loss at step 53900: 0.184222\n",
      "2023-12-04 19:42:08,577 INFO     Training average negative_sample_loss at step 53900: 0.169001\n",
      "2023-12-04 19:42:08,577 INFO     Training average loss at step 53900: 0.176611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:42:16,855 INFO     Training average positive_sample_loss at step 54000: 0.183585\n",
      "2023-12-04 19:42:16,855 INFO     Training average negative_sample_loss at step 54000: 0.166868\n",
      "2023-12-04 19:42:16,855 INFO     Training average loss at step 54000: 0.175226\n",
      "2023-12-04 19:42:28,533 INFO     Training average positive_sample_loss at step 54100: 0.184142\n",
      "2023-12-04 19:42:28,534 INFO     Training average negative_sample_loss at step 54100: 0.166636\n",
      "2023-12-04 19:42:28,534 INFO     Training average loss at step 54100: 0.175389\n",
      "2023-12-04 19:42:40,371 INFO     Training average positive_sample_loss at step 54200: 0.185072\n",
      "2023-12-04 19:42:40,371 INFO     Training average negative_sample_loss at step 54200: 0.168443\n",
      "2023-12-04 19:42:40,371 INFO     Training average loss at step 54200: 0.176757\n",
      "2023-12-04 19:42:52,805 INFO     Training average positive_sample_loss at step 54300: 0.184163\n",
      "2023-12-04 19:42:52,805 INFO     Training average negative_sample_loss at step 54300: 0.168281\n",
      "2023-12-04 19:42:52,805 INFO     Training average loss at step 54300: 0.176222\n",
      "2023-12-04 19:43:04,495 INFO     Training average positive_sample_loss at step 54400: 0.182877\n",
      "2023-12-04 19:43:04,495 INFO     Training average negative_sample_loss at step 54400: 0.167355\n",
      "2023-12-04 19:43:04,495 INFO     Training average loss at step 54400: 0.175116\n",
      "2023-12-04 19:43:16,391 INFO     Training average positive_sample_loss at step 54500: 0.183545\n",
      "2023-12-04 19:43:16,392 INFO     Training average negative_sample_loss at step 54500: 0.168425\n",
      "2023-12-04 19:43:16,392 INFO     Training average loss at step 54500: 0.175985\n",
      "2023-12-04 19:43:24,790 INFO     Training average positive_sample_loss at step 54600: 0.184172\n",
      "2023-12-04 19:43:24,790 INFO     Training average negative_sample_loss at step 54600: 0.167554\n",
      "2023-12-04 19:43:24,790 INFO     Training average loss at step 54600: 0.175863\n",
      "2023-12-04 19:43:36,337 INFO     Training average positive_sample_loss at step 54700: 0.185213\n",
      "2023-12-04 19:43:36,337 INFO     Training average negative_sample_loss at step 54700: 0.168427\n",
      "2023-12-04 19:43:36,337 INFO     Training average loss at step 54700: 0.176820\n",
      "2023-12-04 19:43:48,768 INFO     Training average positive_sample_loss at step 54800: 0.185239\n",
      "2023-12-04 19:43:48,768 INFO     Training average negative_sample_loss at step 54800: 0.167793\n",
      "2023-12-04 19:43:48,768 INFO     Training average loss at step 54800: 0.176516\n",
      "2023-12-04 19:44:00,266 INFO     Training average positive_sample_loss at step 54900: 0.182610\n",
      "2023-12-04 19:44:00,266 INFO     Training average negative_sample_loss at step 54900: 0.168268\n",
      "2023-12-04 19:44:00,266 INFO     Training average loss at step 54900: 0.175439\n",
      "2023-12-04 19:44:12,039 INFO     Training average positive_sample_loss at step 55000: 0.183637\n",
      "2023-12-04 19:44:12,039 INFO     Training average negative_sample_loss at step 55000: 0.167429\n",
      "2023-12-04 19:44:12,039 INFO     Training average loss at step 55000: 0.175533\n",
      "2023-12-04 19:44:24,014 INFO     Training average positive_sample_loss at step 55100: 0.184215\n",
      "2023-12-04 19:44:24,014 INFO     Training average negative_sample_loss at step 55100: 0.167945\n",
      "2023-12-04 19:44:24,014 INFO     Training average loss at step 55100: 0.176080\n",
      "2023-12-04 19:44:33,935 INFO     Training average positive_sample_loss at step 55200: 0.184658\n",
      "2023-12-04 19:44:33,935 INFO     Training average negative_sample_loss at step 55200: 0.168240\n",
      "2023-12-04 19:44:33,935 INFO     Training average loss at step 55200: 0.176449\n",
      "2023-12-04 19:44:43,969 INFO     Training average positive_sample_loss at step 55300: 0.184849\n",
      "2023-12-04 19:44:43,969 INFO     Training average negative_sample_loss at step 55300: 0.167882\n",
      "2023-12-04 19:44:43,970 INFO     Training average loss at step 55300: 0.176366\n",
      "2023-12-04 19:44:55,825 INFO     Training average positive_sample_loss at step 55400: 0.183196\n",
      "2023-12-04 19:44:55,825 INFO     Training average negative_sample_loss at step 55400: 0.167774\n",
      "2023-12-04 19:44:55,825 INFO     Training average loss at step 55400: 0.175485\n",
      "2023-12-04 19:45:07,603 INFO     Training average positive_sample_loss at step 55500: 0.183521\n",
      "2023-12-04 19:45:07,604 INFO     Training average negative_sample_loss at step 55500: 0.167023\n",
      "2023-12-04 19:45:07,604 INFO     Training average loss at step 55500: 0.175272\n",
      "2023-12-04 19:45:19,580 INFO     Training average positive_sample_loss at step 55600: 0.183981\n",
      "2023-12-04 19:45:19,581 INFO     Training average negative_sample_loss at step 55600: 0.167738\n",
      "2023-12-04 19:45:19,581 INFO     Training average loss at step 55600: 0.175859\n",
      "2023-12-04 19:45:31,579 INFO     Training average positive_sample_loss at step 55700: 0.184301\n",
      "2023-12-04 19:45:31,580 INFO     Training average negative_sample_loss at step 55700: 0.167868\n",
      "2023-12-04 19:45:31,580 INFO     Training average loss at step 55700: 0.176084\n",
      "2023-12-04 19:45:43,176 INFO     Training average positive_sample_loss at step 55800: 0.185742\n",
      "2023-12-04 19:45:43,176 INFO     Training average negative_sample_loss at step 55800: 0.167150\n",
      "2023-12-04 19:45:43,176 INFO     Training average loss at step 55800: 0.176446\n",
      "2023-12-04 19:45:51,860 INFO     Training average positive_sample_loss at step 55900: 0.183866\n",
      "2023-12-04 19:45:51,861 INFO     Training average negative_sample_loss at step 55900: 0.167688\n",
      "2023-12-04 19:45:51,861 INFO     Training average loss at step 55900: 0.175777\n",
      "2023-12-04 19:46:03,402 INFO     Training average positive_sample_loss at step 56000: 0.182480\n",
      "2023-12-04 19:46:03,403 INFO     Training average negative_sample_loss at step 56000: 0.167380\n",
      "2023-12-04 19:46:03,403 INFO     Training average loss at step 56000: 0.174930\n",
      "2023-12-04 19:46:15,274 INFO     Training average positive_sample_loss at step 56100: 0.183977\n",
      "2023-12-04 19:46:15,274 INFO     Training average negative_sample_loss at step 56100: 0.167051\n",
      "2023-12-04 19:46:15,274 INFO     Training average loss at step 56100: 0.175514\n",
      "2023-12-04 19:46:27,266 INFO     Training average positive_sample_loss at step 56200: 0.184327\n",
      "2023-12-04 19:46:27,266 INFO     Training average negative_sample_loss at step 56200: 0.167217\n",
      "2023-12-04 19:46:27,266 INFO     Training average loss at step 56200: 0.175772\n",
      "2023-12-04 19:46:38,960 INFO     Training average positive_sample_loss at step 56300: 0.184603\n",
      "2023-12-04 19:46:38,961 INFO     Training average negative_sample_loss at step 56300: 0.166627\n",
      "2023-12-04 19:46:38,961 INFO     Training average loss at step 56300: 0.175615\n",
      "2023-12-04 19:46:51,439 INFO     Training average positive_sample_loss at step 56400: 0.185522\n",
      "2023-12-04 19:46:51,440 INFO     Training average negative_sample_loss at step 56400: 0.169056\n",
      "2023-12-04 19:46:51,440 INFO     Training average loss at step 56400: 0.177289\n",
      "2023-12-04 19:46:59,620 INFO     Training average positive_sample_loss at step 56500: 0.182488\n",
      "2023-12-04 19:46:59,621 INFO     Training average negative_sample_loss at step 56500: 0.166226\n",
      "2023-12-04 19:46:59,621 INFO     Training average loss at step 56500: 0.174357\n",
      "2023-12-04 19:47:11,253 INFO     Training average positive_sample_loss at step 56600: 0.183495\n",
      "2023-12-04 19:47:11,254 INFO     Training average negative_sample_loss at step 56600: 0.166578\n",
      "2023-12-04 19:47:11,254 INFO     Training average loss at step 56600: 0.175037\n",
      "2023-12-04 19:47:23,141 INFO     Training average positive_sample_loss at step 56700: 0.184362\n",
      "2023-12-04 19:47:23,141 INFO     Training average negative_sample_loss at step 56700: 0.167816\n",
      "2023-12-04 19:47:23,141 INFO     Training average loss at step 56700: 0.176089\n",
      "2023-12-04 19:47:35,145 INFO     Training average positive_sample_loss at step 56800: 0.184629\n",
      "2023-12-04 19:47:35,145 INFO     Training average negative_sample_loss at step 56800: 0.167033\n",
      "2023-12-04 19:47:35,145 INFO     Training average loss at step 56800: 0.175831\n",
      "2023-12-04 19:47:47,239 INFO     Training average positive_sample_loss at step 56900: 0.184606\n",
      "2023-12-04 19:47:47,240 INFO     Training average negative_sample_loss at step 56900: 0.168219\n",
      "2023-12-04 19:47:47,240 INFO     Training average loss at step 56900: 0.176412\n",
      "2023-12-04 19:47:59,741 INFO     Training average positive_sample_loss at step 57000: 0.183301\n",
      "2023-12-04 19:47:59,741 INFO     Training average negative_sample_loss at step 57000: 0.167620\n",
      "2023-12-04 19:47:59,741 INFO     Training average loss at step 57000: 0.175461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:48:07,826 INFO     Training average positive_sample_loss at step 57100: 0.182857\n",
      "2023-12-04 19:48:07,827 INFO     Training average negative_sample_loss at step 57100: 0.167486\n",
      "2023-12-04 19:48:07,827 INFO     Training average loss at step 57100: 0.175172\n",
      "2023-12-04 19:48:19,404 INFO     Training average positive_sample_loss at step 57200: 0.184019\n",
      "2023-12-04 19:48:19,404 INFO     Training average negative_sample_loss at step 57200: 0.166658\n",
      "2023-12-04 19:48:19,404 INFO     Training average loss at step 57200: 0.175339\n",
      "2023-12-04 19:48:31,102 INFO     Training average positive_sample_loss at step 57300: 0.184741\n",
      "2023-12-04 19:48:31,102 INFO     Training average negative_sample_loss at step 57300: 0.167281\n",
      "2023-12-04 19:48:31,102 INFO     Training average loss at step 57300: 0.176011\n",
      "2023-12-04 19:48:42,986 INFO     Training average positive_sample_loss at step 57400: 0.184986\n",
      "2023-12-04 19:48:42,986 INFO     Training average negative_sample_loss at step 57400: 0.167060\n",
      "2023-12-04 19:48:42,986 INFO     Training average loss at step 57400: 0.176023\n",
      "2023-12-04 19:48:55,410 INFO     Training average positive_sample_loss at step 57500: 0.184769\n",
      "2023-12-04 19:48:55,411 INFO     Training average negative_sample_loss at step 57500: 0.168489\n",
      "2023-12-04 19:48:55,411 INFO     Training average loss at step 57500: 0.176629\n",
      "2023-12-04 19:49:07,090 INFO     Training average positive_sample_loss at step 57600: 0.182883\n",
      "2023-12-04 19:49:07,091 INFO     Training average negative_sample_loss at step 57600: 0.166494\n",
      "2023-12-04 19:49:07,091 INFO     Training average loss at step 57600: 0.174689\n",
      "2023-12-04 19:49:16,341 INFO     Training average positive_sample_loss at step 57700: 0.183462\n",
      "2023-12-04 19:49:16,341 INFO     Training average negative_sample_loss at step 57700: 0.168420\n",
      "2023-12-04 19:49:16,341 INFO     Training average loss at step 57700: 0.175941\n",
      "2023-12-04 19:49:27,181 INFO     Training average positive_sample_loss at step 57800: 0.184981\n",
      "2023-12-04 19:49:27,181 INFO     Training average negative_sample_loss at step 57800: 0.166473\n",
      "2023-12-04 19:49:27,181 INFO     Training average loss at step 57800: 0.175727\n",
      "2023-12-04 19:49:38,878 INFO     Training average positive_sample_loss at step 57900: 0.184844\n",
      "2023-12-04 19:49:38,879 INFO     Training average negative_sample_loss at step 57900: 0.166483\n",
      "2023-12-04 19:49:38,879 INFO     Training average loss at step 57900: 0.175663\n",
      "2023-12-04 19:49:51,228 INFO     Training average positive_sample_loss at step 58000: 0.184404\n",
      "2023-12-04 19:49:51,228 INFO     Training average negative_sample_loss at step 58000: 0.167359\n",
      "2023-12-04 19:49:51,228 INFO     Training average loss at step 58000: 0.175881\n",
      "2023-12-04 19:50:02,802 INFO     Training average positive_sample_loss at step 58100: 0.182886\n",
      "2023-12-04 19:50:02,803 INFO     Training average negative_sample_loss at step 58100: 0.167294\n",
      "2023-12-04 19:50:02,803 INFO     Training average loss at step 58100: 0.175090\n",
      "2023-12-04 19:50:14,633 INFO     Training average positive_sample_loss at step 58200: 0.183272\n",
      "2023-12-04 19:50:14,633 INFO     Training average negative_sample_loss at step 58200: 0.167152\n",
      "2023-12-04 19:50:14,633 INFO     Training average loss at step 58200: 0.175212\n",
      "2023-12-04 19:50:25,474 INFO     Training average positive_sample_loss at step 58300: 0.184188\n",
      "2023-12-04 19:50:25,474 INFO     Training average negative_sample_loss at step 58300: 0.167011\n",
      "2023-12-04 19:50:25,475 INFO     Training average loss at step 58300: 0.175600\n",
      "2023-12-04 19:50:34,770 INFO     Training average positive_sample_loss at step 58400: 0.184403\n",
      "2023-12-04 19:50:34,770 INFO     Training average negative_sample_loss at step 58400: 0.166987\n",
      "2023-12-04 19:50:34,770 INFO     Training average loss at step 58400: 0.175695\n",
      "2023-12-04 19:50:46,530 INFO     Training average positive_sample_loss at step 58500: 0.185368\n",
      "2023-12-04 19:50:46,530 INFO     Training average negative_sample_loss at step 58500: 0.167539\n",
      "2023-12-04 19:50:46,531 INFO     Training average loss at step 58500: 0.176453\n",
      "2023-12-04 19:50:54,693 INFO     Training average positive_sample_loss at step 58600: 0.182949\n",
      "2023-12-04 19:50:54,693 INFO     Training average negative_sample_loss at step 58600: 0.168177\n",
      "2023-12-04 19:50:54,693 INFO     Training average loss at step 58600: 0.175563\n",
      "2023-12-04 19:51:01,303 INFO     Training average positive_sample_loss at step 58700: 0.183059\n",
      "2023-12-04 19:51:01,785 INFO     Training average negative_sample_loss at step 58700: 0.167434\n",
      "2023-12-04 19:51:01,785 INFO     Training average loss at step 58700: 0.175246\n",
      "2023-12-04 19:51:10,611 INFO     Training average positive_sample_loss at step 58800: 0.184040\n",
      "2023-12-04 19:51:10,612 INFO     Training average negative_sample_loss at step 58800: 0.167350\n",
      "2023-12-04 19:51:10,612 INFO     Training average loss at step 58800: 0.175695\n",
      "2023-12-04 19:51:19,559 INFO     Training average positive_sample_loss at step 58900: 0.184929\n",
      "2023-12-04 19:51:19,560 INFO     Training average negative_sample_loss at step 58900: 0.166811\n",
      "2023-12-04 19:51:19,560 INFO     Training average loss at step 58900: 0.175870\n",
      "2023-12-04 19:51:28,736 INFO     Training average positive_sample_loss at step 59000: 0.185510\n",
      "2023-12-04 19:51:28,737 INFO     Training average negative_sample_loss at step 59000: 0.166372\n",
      "2023-12-04 19:51:28,737 INFO     Training average loss at step 59000: 0.175941\n",
      "2023-12-04 19:51:37,649 INFO     Training average positive_sample_loss at step 59100: 0.183799\n",
      "2023-12-04 19:51:37,649 INFO     Training average negative_sample_loss at step 59100: 0.165878\n",
      "2023-12-04 19:51:37,649 INFO     Training average loss at step 59100: 0.174838\n",
      "2023-12-04 19:51:46,571 INFO     Training average positive_sample_loss at step 59200: 0.182400\n",
      "2023-12-04 19:51:46,571 INFO     Training average negative_sample_loss at step 59200: 0.166965\n",
      "2023-12-04 19:51:46,571 INFO     Training average loss at step 59200: 0.174682\n",
      "2023-12-04 19:51:55,465 INFO     Training average positive_sample_loss at step 59300: 0.184566\n",
      "2023-12-04 19:51:55,465 INFO     Training average negative_sample_loss at step 59300: 0.167680\n",
      "2023-12-04 19:51:55,466 INFO     Training average loss at step 59300: 0.176123\n",
      "2023-12-04 19:52:06,118 INFO     Training average positive_sample_loss at step 59400: 0.184693\n",
      "2023-12-04 19:52:06,118 INFO     Training average negative_sample_loss at step 59400: 0.167793\n",
      "2023-12-04 19:52:06,118 INFO     Training average loss at step 59400: 0.176243\n",
      "2023-12-04 19:52:18,144 INFO     Training average positive_sample_loss at step 59500: 0.184453\n",
      "2023-12-04 19:52:18,145 INFO     Training average negative_sample_loss at step 59500: 0.168384\n",
      "2023-12-04 19:52:18,145 INFO     Training average loss at step 59500: 0.176419\n",
      "2023-12-04 19:52:30,537 INFO     Training average positive_sample_loss at step 59600: 0.184826\n",
      "2023-12-04 19:52:30,538 INFO     Training average negative_sample_loss at step 59600: 0.167428\n",
      "2023-12-04 19:52:30,538 INFO     Training average loss at step 59600: 0.176127\n",
      "2023-12-04 19:52:41,937 INFO     Training average positive_sample_loss at step 59700: 0.182622\n",
      "2023-12-04 19:52:41,937 INFO     Training average negative_sample_loss at step 59700: 0.168962\n",
      "2023-12-04 19:52:41,937 INFO     Training average loss at step 59700: 0.175792\n",
      "2023-12-04 19:52:51,491 INFO     Training average positive_sample_loss at step 59800: 0.183193\n",
      "2023-12-04 19:52:51,491 INFO     Training average negative_sample_loss at step 59800: 0.166301\n",
      "2023-12-04 19:52:51,491 INFO     Training average loss at step 59800: 0.174747\n",
      "2023-12-04 19:53:01,833 INFO     Training average positive_sample_loss at step 59900: 0.184769\n",
      "2023-12-04 19:53:01,834 INFO     Training average negative_sample_loss at step 59900: 0.167204\n",
      "2023-12-04 19:53:01,834 INFO     Training average loss at step 59900: 0.175987\n",
      "2023-12-04 19:53:25,594 INFO     Training average positive_sample_loss at step 60000: 0.184984\n",
      "2023-12-04 19:53:25,594 INFO     Training average negative_sample_loss at step 60000: 0.167674\n",
      "2023-12-04 19:53:25,594 INFO     Training average loss at step 60000: 0.176329\n",
      "2023-12-04 19:53:25,595 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 19:53:26,215 INFO     Evaluating the model... (0/2192)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:54:12,570 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 19:55:02,389 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 19:55:09,632 INFO     Valid MRR at step 60000: 0.343521\n",
      "2023-12-04 19:55:09,632 INFO     Valid MR at step 60000: 164.194040\n",
      "2023-12-04 19:55:09,632 INFO     Valid HITS@1 at step 60000: 0.247591\n",
      "2023-12-04 19:55:09,632 INFO     Valid HITS@3 at step 60000: 0.380724\n",
      "2023-12-04 19:55:09,632 INFO     Valid HITS@10 at step 60000: 0.536270\n",
      "2023-12-04 19:55:21,347 INFO     Training average positive_sample_loss at step 60100: 0.185014\n",
      "2023-12-04 19:55:21,348 INFO     Training average negative_sample_loss at step 60100: 0.166090\n",
      "2023-12-04 19:55:21,348 INFO     Training average loss at step 60100: 0.175552\n",
      "2023-12-04 19:55:33,659 INFO     Training average positive_sample_loss at step 60200: 0.182892\n",
      "2023-12-04 19:55:33,659 INFO     Training average negative_sample_loss at step 60200: 0.167823\n",
      "2023-12-04 19:55:33,659 INFO     Training average loss at step 60200: 0.175357\n",
      "2023-12-04 19:55:45,470 INFO     Training average positive_sample_loss at step 60300: 0.183012\n",
      "2023-12-04 19:55:45,471 INFO     Training average negative_sample_loss at step 60300: 0.168150\n",
      "2023-12-04 19:55:45,471 INFO     Training average loss at step 60300: 0.175581\n",
      "2023-12-04 19:55:57,385 INFO     Training average positive_sample_loss at step 60400: 0.184472\n",
      "2023-12-04 19:55:57,386 INFO     Training average negative_sample_loss at step 60400: 0.166797\n",
      "2023-12-04 19:55:57,386 INFO     Training average loss at step 60400: 0.175635\n",
      "2023-12-04 19:56:09,370 INFO     Training average positive_sample_loss at step 60500: 0.184762\n",
      "2023-12-04 19:56:09,370 INFO     Training average negative_sample_loss at step 60500: 0.167874\n",
      "2023-12-04 19:56:09,371 INFO     Training average loss at step 60500: 0.176318\n",
      "2023-12-04 19:56:18,787 INFO     Training average positive_sample_loss at step 60600: 0.186012\n",
      "2023-12-04 19:56:18,787 INFO     Training average negative_sample_loss at step 60600: 0.166180\n",
      "2023-12-04 19:56:18,787 INFO     Training average loss at step 60600: 0.176096\n",
      "2023-12-04 19:56:29,352 INFO     Training average positive_sample_loss at step 60700: 0.183706\n",
      "2023-12-04 19:56:29,352 INFO     Training average negative_sample_loss at step 60700: 0.167532\n",
      "2023-12-04 19:56:29,352 INFO     Training average loss at step 60700: 0.175619\n",
      "2023-12-04 19:56:41,037 INFO     Training average positive_sample_loss at step 60800: 0.182298\n",
      "2023-12-04 19:56:41,038 INFO     Training average negative_sample_loss at step 60800: 0.166356\n",
      "2023-12-04 19:56:41,038 INFO     Training average loss at step 60800: 0.174327\n",
      "2023-12-04 19:56:52,940 INFO     Training average positive_sample_loss at step 60900: 0.184083\n",
      "2023-12-04 19:56:52,940 INFO     Training average negative_sample_loss at step 60900: 0.167147\n",
      "2023-12-04 19:56:52,940 INFO     Training average loss at step 60900: 0.175615\n",
      "2023-12-04 19:57:04,817 INFO     Training average positive_sample_loss at step 61000: 0.184863\n",
      "2023-12-04 19:57:04,817 INFO     Training average negative_sample_loss at step 61000: 0.167237\n",
      "2023-12-04 19:57:04,817 INFO     Training average loss at step 61000: 0.176050\n",
      "2023-12-04 19:57:16,676 INFO     Training average positive_sample_loss at step 61100: 0.185175\n",
      "2023-12-04 19:57:16,676 INFO     Training average negative_sample_loss at step 61100: 0.166671\n",
      "2023-12-04 19:57:16,676 INFO     Training average loss at step 61100: 0.175923\n",
      "2023-12-04 19:57:27,939 INFO     Training average positive_sample_loss at step 61200: 0.184573\n",
      "2023-12-04 19:57:27,939 INFO     Training average negative_sample_loss at step 61200: 0.167425\n",
      "2023-12-04 19:57:27,939 INFO     Training average loss at step 61200: 0.175999\n",
      "2023-12-04 19:57:37,261 INFO     Training average positive_sample_loss at step 61300: 0.182980\n",
      "2023-12-04 19:57:37,261 INFO     Training average negative_sample_loss at step 61300: 0.168043\n",
      "2023-12-04 19:57:37,261 INFO     Training average loss at step 61300: 0.175512\n",
      "2023-12-04 19:57:48,829 INFO     Training average positive_sample_loss at step 61400: 0.183498\n",
      "2023-12-04 19:57:48,829 INFO     Training average negative_sample_loss at step 61400: 0.165648\n",
      "2023-12-04 19:57:48,829 INFO     Training average loss at step 61400: 0.174573\n",
      "2023-12-04 19:58:00,635 INFO     Training average positive_sample_loss at step 61500: 0.184448\n",
      "2023-12-04 19:58:00,635 INFO     Training average negative_sample_loss at step 61500: 0.167514\n",
      "2023-12-04 19:58:00,635 INFO     Training average loss at step 61500: 0.175981\n",
      "2023-12-04 19:58:12,426 INFO     Training average positive_sample_loss at step 61600: 0.184544\n",
      "2023-12-04 19:58:12,427 INFO     Training average negative_sample_loss at step 61600: 0.166147\n",
      "2023-12-04 19:58:12,427 INFO     Training average loss at step 61600: 0.175346\n",
      "2023-12-04 19:58:24,339 INFO     Training average positive_sample_loss at step 61700: 0.185240\n",
      "2023-12-04 19:58:24,340 INFO     Training average negative_sample_loss at step 61700: 0.168077\n",
      "2023-12-04 19:58:24,340 INFO     Training average loss at step 61700: 0.176658\n",
      "2023-12-04 19:58:36,533 INFO     Training average positive_sample_loss at step 61800: 0.182983\n",
      "2023-12-04 19:58:36,534 INFO     Training average negative_sample_loss at step 61800: 0.166083\n",
      "2023-12-04 19:58:36,534 INFO     Training average loss at step 61800: 0.174533\n",
      "2023-12-04 19:58:44,720 INFO     Training average positive_sample_loss at step 61900: 0.183659\n",
      "2023-12-04 19:58:44,721 INFO     Training average negative_sample_loss at step 61900: 0.167300\n",
      "2023-12-04 19:58:44,721 INFO     Training average loss at step 61900: 0.175479\n",
      "2023-12-04 19:58:56,326 INFO     Training average positive_sample_loss at step 62000: 0.183095\n",
      "2023-12-04 19:58:56,326 INFO     Training average negative_sample_loss at step 62000: 0.167581\n",
      "2023-12-04 19:58:56,326 INFO     Training average loss at step 62000: 0.175338\n",
      "2023-12-04 19:59:08,156 INFO     Training average positive_sample_loss at step 62100: 0.185147\n",
      "2023-12-04 19:59:08,156 INFO     Training average negative_sample_loss at step 62100: 0.168787\n",
      "2023-12-04 19:59:08,156 INFO     Training average loss at step 62100: 0.176967\n",
      "2023-12-04 19:59:19,976 INFO     Training average positive_sample_loss at step 62200: 0.185256\n",
      "2023-12-04 19:59:19,977 INFO     Training average negative_sample_loss at step 62200: 0.168059\n",
      "2023-12-04 19:59:19,977 INFO     Training average loss at step 62200: 0.176657\n",
      "2023-12-04 19:59:32,298 INFO     Training average positive_sample_loss at step 62300: 0.183963\n",
      "2023-12-04 19:59:32,298 INFO     Training average negative_sample_loss at step 62300: 0.167069\n",
      "2023-12-04 19:59:32,298 INFO     Training average loss at step 62300: 0.175516\n",
      "2023-12-04 19:59:44,152 INFO     Training average positive_sample_loss at step 62400: 0.182326\n",
      "2023-12-04 19:59:44,153 INFO     Training average negative_sample_loss at step 62400: 0.166021\n",
      "2023-12-04 19:59:44,153 INFO     Training average loss at step 62400: 0.174174\n",
      "2023-12-04 19:59:52,534 INFO     Training average positive_sample_loss at step 62500: 0.184216\n",
      "2023-12-04 19:59:52,535 INFO     Training average negative_sample_loss at step 62500: 0.166167\n",
      "2023-12-04 19:59:52,535 INFO     Training average loss at step 62500: 0.175191\n",
      "2023-12-04 20:00:04,212 INFO     Training average positive_sample_loss at step 62600: 0.184461\n",
      "2023-12-04 20:00:04,212 INFO     Training average negative_sample_loss at step 62600: 0.167491\n",
      "2023-12-04 20:00:04,212 INFO     Training average loss at step 62600: 0.175976\n",
      "2023-12-04 20:00:16,116 INFO     Training average positive_sample_loss at step 62700: 0.185001\n",
      "2023-12-04 20:00:16,117 INFO     Training average negative_sample_loss at step 62700: 0.168028\n",
      "2023-12-04 20:00:16,117 INFO     Training average loss at step 62700: 0.176515\n",
      "2023-12-04 20:00:28,589 INFO     Training average positive_sample_loss at step 62800: 0.184374\n",
      "2023-12-04 20:00:28,589 INFO     Training average negative_sample_loss at step 62800: 0.166317\n",
      "2023-12-04 20:00:28,589 INFO     Training average loss at step 62800: 0.175346\n",
      "2023-12-04 20:00:40,246 INFO     Training average positive_sample_loss at step 62900: 0.182819\n",
      "2023-12-04 20:00:40,247 INFO     Training average negative_sample_loss at step 62900: 0.166990\n",
      "2023-12-04 20:00:40,247 INFO     Training average loss at step 62900: 0.174905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:00:52,254 INFO     Training average positive_sample_loss at step 63000: 0.184240\n",
      "2023-12-04 20:00:52,255 INFO     Training average negative_sample_loss at step 63000: 0.168247\n",
      "2023-12-04 20:00:52,255 INFO     Training average loss at step 63000: 0.176244\n",
      "2023-12-04 20:01:01,049 INFO     Training average positive_sample_loss at step 63100: 0.184436\n",
      "2023-12-04 20:01:01,049 INFO     Training average negative_sample_loss at step 63100: 0.166714\n",
      "2023-12-04 20:01:01,049 INFO     Training average loss at step 63100: 0.175575\n",
      "2023-12-04 20:01:12,123 INFO     Training average positive_sample_loss at step 63200: 0.184376\n",
      "2023-12-04 20:01:12,124 INFO     Training average negative_sample_loss at step 63200: 0.166021\n",
      "2023-12-04 20:01:12,124 INFO     Training average loss at step 63200: 0.175198\n",
      "2023-12-04 20:01:23,916 INFO     Training average positive_sample_loss at step 63300: 0.185327\n",
      "2023-12-04 20:01:23,916 INFO     Training average negative_sample_loss at step 63300: 0.167234\n",
      "2023-12-04 20:01:23,916 INFO     Training average loss at step 63300: 0.176280\n",
      "2023-12-04 20:01:36,123 INFO     Training average positive_sample_loss at step 63400: 0.182963\n",
      "2023-12-04 20:01:36,123 INFO     Training average negative_sample_loss at step 63400: 0.168146\n",
      "2023-12-04 20:01:36,123 INFO     Training average loss at step 63400: 0.175554\n",
      "2023-12-04 20:01:48,173 INFO     Training average positive_sample_loss at step 63500: 0.183554\n",
      "2023-12-04 20:01:48,174 INFO     Training average negative_sample_loss at step 63500: 0.166923\n",
      "2023-12-04 20:01:48,174 INFO     Training average loss at step 63500: 0.175238\n",
      "2023-12-04 20:02:00,079 INFO     Training average positive_sample_loss at step 63600: 0.184251\n",
      "2023-12-04 20:02:00,079 INFO     Training average negative_sample_loss at step 63600: 0.167308\n",
      "2023-12-04 20:02:00,079 INFO     Training average loss at step 63600: 0.175779\n",
      "2023-12-04 20:02:10,231 INFO     Training average positive_sample_loss at step 63700: 0.184621\n",
      "2023-12-04 20:02:10,232 INFO     Training average negative_sample_loss at step 63700: 0.167318\n",
      "2023-12-04 20:02:10,232 INFO     Training average loss at step 63700: 0.175970\n",
      "2023-12-04 20:02:20,167 INFO     Training average positive_sample_loss at step 63800: 0.185056\n",
      "2023-12-04 20:02:20,167 INFO     Training average negative_sample_loss at step 63800: 0.166870\n",
      "2023-12-04 20:02:20,167 INFO     Training average loss at step 63800: 0.175963\n",
      "2023-12-04 20:02:32,239 INFO     Training average positive_sample_loss at step 63900: 0.183257\n",
      "2023-12-04 20:02:32,240 INFO     Training average negative_sample_loss at step 63900: 0.166991\n",
      "2023-12-04 20:02:32,240 INFO     Training average loss at step 63900: 0.175124\n",
      "2023-12-04 20:02:43,814 INFO     Training average positive_sample_loss at step 64000: 0.183135\n",
      "2023-12-04 20:02:43,814 INFO     Training average negative_sample_loss at step 64000: 0.166357\n",
      "2023-12-04 20:02:43,814 INFO     Training average loss at step 64000: 0.174746\n",
      "2023-12-04 20:02:55,629 INFO     Training average positive_sample_loss at step 64100: 0.183886\n",
      "2023-12-04 20:02:55,629 INFO     Training average negative_sample_loss at step 64100: 0.166697\n",
      "2023-12-04 20:02:55,629 INFO     Training average loss at step 64100: 0.175292\n",
      "2023-12-04 20:03:07,428 INFO     Training average positive_sample_loss at step 64200: 0.184230\n",
      "2023-12-04 20:03:07,429 INFO     Training average negative_sample_loss at step 64200: 0.166460\n",
      "2023-12-04 20:03:07,429 INFO     Training average loss at step 64200: 0.175345\n",
      "2023-12-04 20:03:19,276 INFO     Training average positive_sample_loss at step 64300: 0.185377\n",
      "2023-12-04 20:03:19,276 INFO     Training average negative_sample_loss at step 64300: 0.168110\n",
      "2023-12-04 20:03:19,276 INFO     Training average loss at step 64300: 0.176743\n",
      "2023-12-04 20:03:28,134 INFO     Training average positive_sample_loss at step 64400: 0.184698\n",
      "2023-12-04 20:03:28,135 INFO     Training average negative_sample_loss at step 64400: 0.168618\n",
      "2023-12-04 20:03:28,135 INFO     Training average loss at step 64400: 0.176658\n",
      "2023-12-04 20:03:39,771 INFO     Training average positive_sample_loss at step 64500: 0.183150\n",
      "2023-12-04 20:03:39,771 INFO     Training average negative_sample_loss at step 64500: 0.167122\n",
      "2023-12-04 20:03:39,771 INFO     Training average loss at step 64500: 0.175136\n",
      "2023-12-04 20:03:51,575 INFO     Training average positive_sample_loss at step 64600: 0.184161\n",
      "2023-12-04 20:03:51,575 INFO     Training average negative_sample_loss at step 64600: 0.167699\n",
      "2023-12-04 20:03:51,575 INFO     Training average loss at step 64600: 0.175930\n",
      "2023-12-04 20:04:03,510 INFO     Training average positive_sample_loss at step 64700: 0.184554\n",
      "2023-12-04 20:04:03,510 INFO     Training average negative_sample_loss at step 64700: 0.166827\n",
      "2023-12-04 20:04:03,510 INFO     Training average loss at step 64700: 0.175690\n",
      "2023-12-04 20:04:15,524 INFO     Training average positive_sample_loss at step 64800: 0.184578\n",
      "2023-12-04 20:04:15,525 INFO     Training average negative_sample_loss at step 64800: 0.167471\n",
      "2023-12-04 20:04:15,525 INFO     Training average loss at step 64800: 0.176025\n",
      "2023-12-04 20:04:27,389 INFO     Training average positive_sample_loss at step 64900: 0.185403\n",
      "2023-12-04 20:04:27,389 INFO     Training average negative_sample_loss at step 64900: 0.167747\n",
      "2023-12-04 20:04:27,389 INFO     Training average loss at step 64900: 0.176575\n",
      "2023-12-04 20:04:36,334 INFO     Training average positive_sample_loss at step 65000: 0.182976\n",
      "2023-12-04 20:04:36,334 INFO     Training average negative_sample_loss at step 65000: 0.166611\n",
      "2023-12-04 20:04:36,334 INFO     Training average loss at step 65000: 0.174794\n",
      "2023-12-04 20:04:47,976 INFO     Training average positive_sample_loss at step 65100: 0.182974\n",
      "2023-12-04 20:04:47,976 INFO     Training average negative_sample_loss at step 65100: 0.167475\n",
      "2023-12-04 20:04:47,976 INFO     Training average loss at step 65100: 0.175225\n",
      "2023-12-04 20:04:59,836 INFO     Training average positive_sample_loss at step 65200: 0.184198\n",
      "2023-12-04 20:04:59,836 INFO     Training average negative_sample_loss at step 65200: 0.165187\n",
      "2023-12-04 20:04:59,836 INFO     Training average loss at step 65200: 0.174693\n",
      "2023-12-04 20:05:11,725 INFO     Training average positive_sample_loss at step 65300: 0.184659\n",
      "2023-12-04 20:05:11,725 INFO     Training average negative_sample_loss at step 65300: 0.166660\n",
      "2023-12-04 20:05:11,725 INFO     Training average loss at step 65300: 0.175660\n",
      "2023-12-04 20:05:23,458 INFO     Training average positive_sample_loss at step 65400: 0.185521\n",
      "2023-12-04 20:05:23,458 INFO     Training average negative_sample_loss at step 65400: 0.166700\n",
      "2023-12-04 20:05:23,458 INFO     Training average loss at step 65400: 0.176110\n",
      "2023-12-04 20:05:35,638 INFO     Training average positive_sample_loss at step 65500: 0.183259\n",
      "2023-12-04 20:05:35,638 INFO     Training average negative_sample_loss at step 65500: 0.166398\n",
      "2023-12-04 20:05:35,638 INFO     Training average loss at step 65500: 0.174828\n",
      "2023-12-04 20:05:43,890 INFO     Training average positive_sample_loss at step 65600: 0.183489\n",
      "2023-12-04 20:05:43,890 INFO     Training average negative_sample_loss at step 65600: 0.167926\n",
      "2023-12-04 20:05:43,890 INFO     Training average loss at step 65600: 0.175708\n",
      "2023-12-04 20:05:55,451 INFO     Training average positive_sample_loss at step 65700: 0.183845\n",
      "2023-12-04 20:05:55,452 INFO     Training average negative_sample_loss at step 65700: 0.166753\n",
      "2023-12-04 20:05:55,452 INFO     Training average loss at step 65700: 0.175299\n",
      "2023-12-04 20:06:07,231 INFO     Training average positive_sample_loss at step 65800: 0.184488\n",
      "2023-12-04 20:06:07,231 INFO     Training average negative_sample_loss at step 65800: 0.167031\n",
      "2023-12-04 20:06:07,231 INFO     Training average loss at step 65800: 0.175760\n",
      "2023-12-04 20:06:19,255 INFO     Training average positive_sample_loss at step 65900: 0.185218\n",
      "2023-12-04 20:06:19,255 INFO     Training average negative_sample_loss at step 65900: 0.165686\n",
      "2023-12-04 20:06:19,255 INFO     Training average loss at step 65900: 0.175452\n",
      "2023-12-04 20:06:31,668 INFO     Training average positive_sample_loss at step 66000: 0.184537\n",
      "2023-12-04 20:06:31,668 INFO     Training average negative_sample_loss at step 66000: 0.166190\n",
      "2023-12-04 20:06:31,668 INFO     Training average loss at step 66000: 0.175363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:06:43,256 INFO     Training average positive_sample_loss at step 66100: 0.182658\n",
      "2023-12-04 20:06:43,256 INFO     Training average negative_sample_loss at step 66100: 0.167235\n",
      "2023-12-04 20:06:43,256 INFO     Training average loss at step 66100: 0.174946\n",
      "2023-12-04 20:06:52,997 INFO     Training average positive_sample_loss at step 66200: 0.183828\n",
      "2023-12-04 20:06:52,997 INFO     Training average negative_sample_loss at step 66200: 0.167288\n",
      "2023-12-04 20:06:52,997 INFO     Training average loss at step 66200: 0.175558\n",
      "2023-12-04 20:07:03,012 INFO     Training average positive_sample_loss at step 66300: 0.183757\n",
      "2023-12-04 20:07:03,013 INFO     Training average negative_sample_loss at step 66300: 0.166178\n",
      "2023-12-04 20:07:03,013 INFO     Training average loss at step 66300: 0.174968\n",
      "2023-12-04 20:07:14,609 INFO     Training average positive_sample_loss at step 66400: 0.184959\n",
      "2023-12-04 20:07:14,609 INFO     Training average negative_sample_loss at step 66400: 0.167016\n",
      "2023-12-04 20:07:14,609 INFO     Training average loss at step 66400: 0.175987\n",
      "2023-12-04 20:07:26,591 INFO     Training average positive_sample_loss at step 66500: 0.185356\n",
      "2023-12-04 20:07:26,591 INFO     Training average negative_sample_loss at step 66500: 0.166387\n",
      "2023-12-04 20:07:26,591 INFO     Training average loss at step 66500: 0.175872\n",
      "2023-12-04 20:07:38,490 INFO     Training average positive_sample_loss at step 66600: 0.182841\n",
      "2023-12-04 20:07:38,490 INFO     Training average negative_sample_loss at step 66600: 0.167316\n",
      "2023-12-04 20:07:38,490 INFO     Training average loss at step 66600: 0.175078\n",
      "2023-12-04 20:07:50,306 INFO     Training average positive_sample_loss at step 66700: 0.183475\n",
      "2023-12-04 20:07:50,306 INFO     Training average negative_sample_loss at step 66700: 0.166914\n",
      "2023-12-04 20:07:50,306 INFO     Training average loss at step 66700: 0.175194\n",
      "2023-12-04 20:08:01,956 INFO     Training average positive_sample_loss at step 66800: 0.183962\n",
      "2023-12-04 20:08:01,956 INFO     Training average negative_sample_loss at step 66800: 0.167088\n",
      "2023-12-04 20:08:01,957 INFO     Training average loss at step 66800: 0.175525\n",
      "2023-12-04 20:08:10,135 INFO     Training average positive_sample_loss at step 66900: 0.184687\n",
      "2023-12-04 20:08:10,135 INFO     Training average negative_sample_loss at step 66900: 0.166597\n",
      "2023-12-04 20:08:10,135 INFO     Training average loss at step 66900: 0.175642\n",
      "2023-12-04 20:08:21,696 INFO     Training average positive_sample_loss at step 67000: 0.184357\n",
      "2023-12-04 20:08:21,696 INFO     Training average negative_sample_loss at step 67000: 0.166787\n",
      "2023-12-04 20:08:21,696 INFO     Training average loss at step 67000: 0.175572\n",
      "2023-12-04 20:08:33,773 INFO     Training average positive_sample_loss at step 67100: 0.183683\n",
      "2023-12-04 20:08:33,773 INFO     Training average negative_sample_loss at step 67100: 0.168075\n",
      "2023-12-04 20:08:33,773 INFO     Training average loss at step 67100: 0.175879\n",
      "2023-12-04 20:08:45,677 INFO     Training average positive_sample_loss at step 67200: 0.183273\n",
      "2023-12-04 20:08:45,677 INFO     Training average negative_sample_loss at step 67200: 0.167484\n",
      "2023-12-04 20:08:45,677 INFO     Training average loss at step 67200: 0.175378\n",
      "2023-12-04 20:08:57,494 INFO     Training average positive_sample_loss at step 67300: 0.184185\n",
      "2023-12-04 20:08:57,494 INFO     Training average negative_sample_loss at step 67300: 0.167847\n",
      "2023-12-04 20:08:57,494 INFO     Training average loss at step 67300: 0.176016\n",
      "2023-12-04 20:09:09,258 INFO     Training average positive_sample_loss at step 67400: 0.183785\n",
      "2023-12-04 20:09:09,258 INFO     Training average negative_sample_loss at step 67400: 0.166133\n",
      "2023-12-04 20:09:09,258 INFO     Training average loss at step 67400: 0.174959\n",
      "2023-12-04 20:09:17,443 INFO     Training average positive_sample_loss at step 67500: 0.185656\n",
      "2023-12-04 20:09:17,443 INFO     Training average negative_sample_loss at step 67500: 0.167879\n",
      "2023-12-04 20:09:17,443 INFO     Training average loss at step 67500: 0.176768\n",
      "2023-12-04 20:09:29,427 INFO     Training average positive_sample_loss at step 67600: 0.184353\n",
      "2023-12-04 20:09:29,427 INFO     Training average negative_sample_loss at step 67600: 0.167029\n",
      "2023-12-04 20:09:29,427 INFO     Training average loss at step 67600: 0.175691\n",
      "2023-12-04 20:09:41,177 INFO     Training average positive_sample_loss at step 67700: 0.182548\n",
      "2023-12-04 20:09:41,177 INFO     Training average negative_sample_loss at step 67700: 0.166850\n",
      "2023-12-04 20:09:41,177 INFO     Training average loss at step 67700: 0.174699\n",
      "2023-12-04 20:09:53,080 INFO     Training average positive_sample_loss at step 67800: 0.183092\n",
      "2023-12-04 20:09:53,081 INFO     Training average negative_sample_loss at step 67800: 0.165997\n",
      "2023-12-04 20:09:53,081 INFO     Training average loss at step 67800: 0.174544\n",
      "2023-12-04 20:10:04,937 INFO     Training average positive_sample_loss at step 67900: 0.184363\n",
      "2023-12-04 20:10:04,937 INFO     Training average negative_sample_loss at step 67900: 0.166339\n",
      "2023-12-04 20:10:04,937 INFO     Training average loss at step 67900: 0.175351\n",
      "2023-12-04 20:10:16,806 INFO     Training average positive_sample_loss at step 68000: 0.185471\n",
      "2023-12-04 20:10:16,806 INFO     Training average negative_sample_loss at step 68000: 0.167034\n",
      "2023-12-04 20:10:16,806 INFO     Training average loss at step 68000: 0.176253\n",
      "2023-12-04 20:10:27,175 INFO     Training average positive_sample_loss at step 68100: 0.185439\n",
      "2023-12-04 20:10:27,175 INFO     Training average negative_sample_loss at step 68100: 0.165919\n",
      "2023-12-04 20:10:27,176 INFO     Training average loss at step 68100: 0.175679\n",
      "2023-12-04 20:10:38,236 INFO     Training average positive_sample_loss at step 68200: 0.182865\n",
      "2023-12-04 20:10:38,236 INFO     Training average negative_sample_loss at step 68200: 0.167807\n",
      "2023-12-04 20:10:38,236 INFO     Training average loss at step 68200: 0.175336\n",
      "2023-12-04 20:10:49,985 INFO     Training average positive_sample_loss at step 68300: 0.183373\n",
      "2023-12-04 20:10:49,985 INFO     Training average negative_sample_loss at step 68300: 0.166076\n",
      "2023-12-04 20:10:49,985 INFO     Training average loss at step 68300: 0.174725\n",
      "2023-12-04 20:11:01,912 INFO     Training average positive_sample_loss at step 68400: 0.184268\n",
      "2023-12-04 20:11:01,912 INFO     Training average negative_sample_loss at step 68400: 0.168226\n",
      "2023-12-04 20:11:01,912 INFO     Training average loss at step 68400: 0.176247\n",
      "2023-12-04 20:11:13,865 INFO     Training average positive_sample_loss at step 68500: 0.184144\n",
      "2023-12-04 20:11:13,866 INFO     Training average negative_sample_loss at step 68500: 0.166510\n",
      "2023-12-04 20:11:13,866 INFO     Training average loss at step 68500: 0.175327\n",
      "2023-12-04 20:11:25,702 INFO     Training average positive_sample_loss at step 68600: 0.185651\n",
      "2023-12-04 20:11:25,703 INFO     Training average negative_sample_loss at step 68600: 0.166527\n",
      "2023-12-04 20:11:25,703 INFO     Training average loss at step 68600: 0.176089\n",
      "2023-12-04 20:11:36,495 INFO     Training average positive_sample_loss at step 68700: 0.183212\n",
      "2023-12-04 20:11:36,496 INFO     Training average negative_sample_loss at step 68700: 0.166796\n",
      "2023-12-04 20:11:36,496 INFO     Training average loss at step 68700: 0.175004\n",
      "2023-12-04 20:11:46,122 INFO     Training average positive_sample_loss at step 68800: 0.182788\n",
      "2023-12-04 20:11:46,122 INFO     Training average negative_sample_loss at step 68800: 0.165440\n",
      "2023-12-04 20:11:46,122 INFO     Training average loss at step 68800: 0.174114\n",
      "2023-12-04 20:11:57,776 INFO     Training average positive_sample_loss at step 68900: 0.184166\n",
      "2023-12-04 20:11:57,776 INFO     Training average negative_sample_loss at step 68900: 0.165348\n",
      "2023-12-04 20:11:57,776 INFO     Training average loss at step 68900: 0.174757\n",
      "2023-12-04 20:12:09,577 INFO     Training average positive_sample_loss at step 69000: 0.184767\n",
      "2023-12-04 20:12:09,577 INFO     Training average negative_sample_loss at step 69000: 0.167606\n",
      "2023-12-04 20:12:09,577 INFO     Training average loss at step 69000: 0.176186\n",
      "2023-12-04 20:12:21,346 INFO     Training average positive_sample_loss at step 69100: 0.184758\n",
      "2023-12-04 20:12:21,346 INFO     Training average negative_sample_loss at step 69100: 0.167891\n",
      "2023-12-04 20:12:21,347 INFO     Training average loss at step 69100: 0.176324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:12:33,655 INFO     Training average positive_sample_loss at step 69200: 0.184348\n",
      "2023-12-04 20:12:33,655 INFO     Training average negative_sample_loss at step 69200: 0.166948\n",
      "2023-12-04 20:12:33,655 INFO     Training average loss at step 69200: 0.175648\n",
      "2023-12-04 20:12:45,329 INFO     Training average positive_sample_loss at step 69300: 0.183424\n",
      "2023-12-04 20:12:45,330 INFO     Training average negative_sample_loss at step 69300: 0.167395\n",
      "2023-12-04 20:12:45,330 INFO     Training average loss at step 69300: 0.175410\n",
      "2023-12-04 20:12:53,569 INFO     Training average positive_sample_loss at step 69400: 0.183321\n",
      "2023-12-04 20:12:53,570 INFO     Training average negative_sample_loss at step 69400: 0.165707\n",
      "2023-12-04 20:12:53,570 INFO     Training average loss at step 69400: 0.174514\n",
      "2023-12-04 20:13:05,235 INFO     Training average positive_sample_loss at step 69500: 0.183564\n",
      "2023-12-04 20:13:05,235 INFO     Training average negative_sample_loss at step 69500: 0.165462\n",
      "2023-12-04 20:13:05,235 INFO     Training average loss at step 69500: 0.174513\n",
      "2023-12-04 20:13:13,386 INFO     Training average positive_sample_loss at step 69600: 0.185308\n",
      "2023-12-04 20:13:13,386 INFO     Training average negative_sample_loss at step 69600: 0.167607\n",
      "2023-12-04 20:13:13,386 INFO     Training average loss at step 69600: 0.176457\n",
      "2023-12-04 20:13:23,074 INFO     Training average positive_sample_loss at step 69700: 0.185510\n",
      "2023-12-04 20:13:23,075 INFO     Training average negative_sample_loss at step 69700: 0.168309\n",
      "2023-12-04 20:13:23,075 INFO     Training average loss at step 69700: 0.176909\n",
      "2023-12-04 20:13:31,670 INFO     Training average positive_sample_loss at step 69800: 0.182104\n",
      "2023-12-04 20:13:31,670 INFO     Training average negative_sample_loss at step 69800: 0.166727\n",
      "2023-12-04 20:13:31,670 INFO     Training average loss at step 69800: 0.174416\n",
      "2023-12-04 20:13:40,488 INFO     Training average positive_sample_loss at step 69900: 0.183813\n",
      "2023-12-04 20:13:40,488 INFO     Training average negative_sample_loss at step 69900: 0.167368\n",
      "2023-12-04 20:13:40,488 INFO     Training average loss at step 69900: 0.175590\n",
      "2023-12-04 20:13:58,206 INFO     Training average positive_sample_loss at step 70000: 0.184855\n",
      "2023-12-04 20:13:58,206 INFO     Training average negative_sample_loss at step 70000: 0.167908\n",
      "2023-12-04 20:13:58,206 INFO     Training average loss at step 70000: 0.176382\n",
      "2023-12-04 20:13:58,206 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 20:13:59,046 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 20:14:44,588 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 20:15:30,177 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 20:15:39,619 INFO     Valid MRR at step 70000: 0.342858\n",
      "2023-12-04 20:15:39,619 INFO     Valid MR at step 70000: 164.250071\n",
      "2023-12-04 20:15:39,619 INFO     Valid HITS@1 at step 70000: 0.246279\n",
      "2023-12-04 20:15:39,619 INFO     Valid HITS@3 at step 70000: 0.381494\n",
      "2023-12-04 20:15:39,619 INFO     Valid HITS@10 at step 70000: 0.536384\n",
      "2023-12-04 20:15:50,833 INFO     Training average positive_sample_loss at step 70100: 0.184773\n",
      "2023-12-04 20:15:50,833 INFO     Training average negative_sample_loss at step 70100: 0.165861\n",
      "2023-12-04 20:15:50,833 INFO     Training average loss at step 70100: 0.175317\n",
      "2023-12-04 20:16:02,775 INFO     Training average positive_sample_loss at step 70200: 0.185345\n",
      "2023-12-04 20:16:02,776 INFO     Training average negative_sample_loss at step 70200: 0.167706\n",
      "2023-12-04 20:16:02,776 INFO     Training average loss at step 70200: 0.176526\n",
      "2023-12-04 20:16:15,012 INFO     Training average positive_sample_loss at step 70300: 0.183530\n",
      "2023-12-04 20:16:15,012 INFO     Training average negative_sample_loss at step 70300: 0.168064\n",
      "2023-12-04 20:16:15,012 INFO     Training average loss at step 70300: 0.175797\n",
      "2023-12-04 20:16:23,242 INFO     Training average positive_sample_loss at step 70400: 0.183602\n",
      "2023-12-04 20:16:23,243 INFO     Training average negative_sample_loss at step 70400: 0.166196\n",
      "2023-12-04 20:16:23,243 INFO     Training average loss at step 70400: 0.174899\n",
      "2023-12-04 20:16:34,862 INFO     Training average positive_sample_loss at step 70500: 0.184075\n",
      "2023-12-04 20:16:34,863 INFO     Training average negative_sample_loss at step 70500: 0.165379\n",
      "2023-12-04 20:16:34,863 INFO     Training average loss at step 70500: 0.174727\n",
      "2023-12-04 20:16:46,709 INFO     Training average positive_sample_loss at step 70600: 0.184059\n",
      "2023-12-04 20:16:46,709 INFO     Training average negative_sample_loss at step 70600: 0.166795\n",
      "2023-12-04 20:16:46,710 INFO     Training average loss at step 70600: 0.175427\n",
      "2023-12-04 20:16:58,463 INFO     Training average positive_sample_loss at step 70700: 0.185158\n",
      "2023-12-04 20:16:58,463 INFO     Training average negative_sample_loss at step 70700: 0.166528\n",
      "2023-12-04 20:16:58,463 INFO     Training average loss at step 70700: 0.175843\n",
      "2023-12-04 20:17:10,811 INFO     Training average positive_sample_loss at step 70800: 0.183990\n",
      "2023-12-04 20:17:10,811 INFO     Training average negative_sample_loss at step 70800: 0.166666\n",
      "2023-12-04 20:17:10,811 INFO     Training average loss at step 70800: 0.175328\n",
      "2023-12-04 20:17:22,531 INFO     Training average positive_sample_loss at step 70900: 0.182795\n",
      "2023-12-04 20:17:22,532 INFO     Training average negative_sample_loss at step 70900: 0.166237\n",
      "2023-12-04 20:17:22,532 INFO     Training average loss at step 70900: 0.174516\n",
      "2023-12-04 20:17:31,896 INFO     Training average positive_sample_loss at step 71000: 0.183908\n",
      "2023-12-04 20:17:31,896 INFO     Training average negative_sample_loss at step 71000: 0.167036\n",
      "2023-12-04 20:17:31,896 INFO     Training average loss at step 71000: 0.175472\n",
      "2023-12-04 20:17:42,538 INFO     Training average positive_sample_loss at step 71100: 0.184926\n",
      "2023-12-04 20:17:42,538 INFO     Training average negative_sample_loss at step 71100: 0.167002\n",
      "2023-12-04 20:17:42,538 INFO     Training average loss at step 71100: 0.175964\n",
      "2023-12-04 20:17:54,254 INFO     Training average positive_sample_loss at step 71200: 0.185096\n",
      "2023-12-04 20:17:54,255 INFO     Training average negative_sample_loss at step 71200: 0.167457\n",
      "2023-12-04 20:17:54,255 INFO     Training average loss at step 71200: 0.176277\n",
      "2023-12-04 20:18:06,850 INFO     Training average positive_sample_loss at step 71300: 0.185099\n",
      "2023-12-04 20:18:06,850 INFO     Training average negative_sample_loss at step 71300: 0.168023\n",
      "2023-12-04 20:18:06,850 INFO     Training average loss at step 71300: 0.176561\n",
      "2023-12-04 20:18:18,568 INFO     Training average positive_sample_loss at step 71400: 0.182935\n",
      "2023-12-04 20:18:18,569 INFO     Training average negative_sample_loss at step 71400: 0.165921\n",
      "2023-12-04 20:18:18,569 INFO     Training average loss at step 71400: 0.174428\n",
      "2023-12-04 20:18:30,438 INFO     Training average positive_sample_loss at step 71500: 0.183508\n",
      "2023-12-04 20:18:30,439 INFO     Training average negative_sample_loss at step 71500: 0.167921\n",
      "2023-12-04 20:18:30,439 INFO     Training average loss at step 71500: 0.175714\n",
      "2023-12-04 20:18:41,113 INFO     Training average positive_sample_loss at step 71600: 0.184840\n",
      "2023-12-04 20:18:41,113 INFO     Training average negative_sample_loss at step 71600: 0.166557\n",
      "2023-12-04 20:18:41,113 INFO     Training average loss at step 71600: 0.175699\n",
      "2023-12-04 20:18:50,557 INFO     Training average positive_sample_loss at step 71700: 0.184848\n",
      "2023-12-04 20:18:50,558 INFO     Training average negative_sample_loss at step 71700: 0.166297\n",
      "2023-12-04 20:18:50,558 INFO     Training average loss at step 71700: 0.175572\n",
      "2023-12-04 20:19:02,384 INFO     Training average positive_sample_loss at step 71800: 0.184672\n",
      "2023-12-04 20:19:02,384 INFO     Training average negative_sample_loss at step 71800: 0.166187\n",
      "2023-12-04 20:19:02,385 INFO     Training average loss at step 71800: 0.175430\n",
      "2023-12-04 20:19:14,674 INFO     Training average positive_sample_loss at step 71900: 0.183261\n",
      "2023-12-04 20:19:14,675 INFO     Training average negative_sample_loss at step 71900: 0.167572\n",
      "2023-12-04 20:19:14,675 INFO     Training average loss at step 71900: 0.175417\n",
      "2023-12-04 20:19:26,537 INFO     Training average positive_sample_loss at step 72000: 0.182881\n",
      "2023-12-04 20:19:26,537 INFO     Training average negative_sample_loss at step 72000: 0.167142\n",
      "2023-12-04 20:19:26,537 INFO     Training average loss at step 72000: 0.175011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:19:38,461 INFO     Training average positive_sample_loss at step 72100: 0.184133\n",
      "2023-12-04 20:19:38,462 INFO     Training average negative_sample_loss at step 72100: 0.166084\n",
      "2023-12-04 20:19:38,462 INFO     Training average loss at step 72100: 0.175109\n",
      "2023-12-04 20:19:50,304 INFO     Training average positive_sample_loss at step 72200: 0.184897\n",
      "2023-12-04 20:19:50,304 INFO     Training average negative_sample_loss at step 72200: 0.167677\n",
      "2023-12-04 20:19:50,304 INFO     Training average loss at step 72200: 0.176287\n",
      "2023-12-04 20:19:58,670 INFO     Training average positive_sample_loss at step 72300: 0.185229\n",
      "2023-12-04 20:19:58,670 INFO     Training average negative_sample_loss at step 72300: 0.166081\n",
      "2023-12-04 20:19:58,670 INFO     Training average loss at step 72300: 0.175655\n",
      "2023-12-04 20:20:10,672 INFO     Training average positive_sample_loss at step 72400: 0.183862\n",
      "2023-12-04 20:20:10,672 INFO     Training average negative_sample_loss at step 72400: 0.166032\n",
      "2023-12-04 20:20:10,672 INFO     Training average loss at step 72400: 0.174947\n",
      "2023-12-04 20:20:22,403 INFO     Training average positive_sample_loss at step 72500: 0.182790\n",
      "2023-12-04 20:20:22,404 INFO     Training average negative_sample_loss at step 72500: 0.167358\n",
      "2023-12-04 20:20:22,404 INFO     Training average loss at step 72500: 0.175074\n",
      "2023-12-04 20:20:34,362 INFO     Training average positive_sample_loss at step 72600: 0.183762\n",
      "2023-12-04 20:20:34,363 INFO     Training average negative_sample_loss at step 72600: 0.166910\n",
      "2023-12-04 20:20:34,363 INFO     Training average loss at step 72600: 0.175336\n",
      "2023-12-04 20:20:46,297 INFO     Training average positive_sample_loss at step 72700: 0.185065\n",
      "2023-12-04 20:20:46,298 INFO     Training average negative_sample_loss at step 72700: 0.168123\n",
      "2023-12-04 20:20:46,298 INFO     Training average loss at step 72700: 0.176594\n",
      "2023-12-04 20:20:58,181 INFO     Training average positive_sample_loss at step 72800: 0.184995\n",
      "2023-12-04 20:20:58,182 INFO     Training average negative_sample_loss at step 72800: 0.166920\n",
      "2023-12-04 20:20:58,182 INFO     Training average loss at step 72800: 0.175958\n",
      "2023-12-04 20:21:06,588 INFO     Training average positive_sample_loss at step 72900: 0.185212\n",
      "2023-12-04 20:21:06,589 INFO     Training average negative_sample_loss at step 72900: 0.167181\n",
      "2023-12-04 20:21:06,589 INFO     Training average loss at step 72900: 0.176197\n",
      "2023-12-04 20:21:18,126 INFO     Training average positive_sample_loss at step 73000: 0.183022\n",
      "2023-12-04 20:21:18,126 INFO     Training average negative_sample_loss at step 73000: 0.168075\n",
      "2023-12-04 20:21:18,126 INFO     Training average loss at step 73000: 0.175549\n",
      "2023-12-04 20:21:29,940 INFO     Training average positive_sample_loss at step 73100: 0.183892\n",
      "2023-12-04 20:21:29,941 INFO     Training average negative_sample_loss at step 73100: 0.167701\n",
      "2023-12-04 20:21:29,941 INFO     Training average loss at step 73100: 0.175797\n",
      "2023-12-04 20:21:41,853 INFO     Training average positive_sample_loss at step 73200: 0.184597\n",
      "2023-12-04 20:21:41,854 INFO     Training average negative_sample_loss at step 73200: 0.166832\n",
      "2023-12-04 20:21:41,854 INFO     Training average loss at step 73200: 0.175715\n",
      "2023-12-04 20:21:53,888 INFO     Training average positive_sample_loss at step 73300: 0.184822\n",
      "2023-12-04 20:21:53,889 INFO     Training average negative_sample_loss at step 73300: 0.166065\n",
      "2023-12-04 20:21:53,889 INFO     Training average loss at step 73300: 0.175444\n",
      "2023-12-04 20:22:05,934 INFO     Training average positive_sample_loss at step 73400: 0.185322\n",
      "2023-12-04 20:22:05,935 INFO     Training average negative_sample_loss at step 73400: 0.165944\n",
      "2023-12-04 20:22:05,935 INFO     Training average loss at step 73400: 0.175633\n",
      "2023-12-04 20:22:14,873 INFO     Training average positive_sample_loss at step 73500: 0.182758\n",
      "2023-12-04 20:22:14,874 INFO     Training average negative_sample_loss at step 73500: 0.166262\n",
      "2023-12-04 20:22:14,874 INFO     Training average loss at step 73500: 0.174510\n",
      "2023-12-04 20:22:26,584 INFO     Training average positive_sample_loss at step 73600: 0.183675\n",
      "2023-12-04 20:22:26,584 INFO     Training average negative_sample_loss at step 73600: 0.167065\n",
      "2023-12-04 20:22:26,585 INFO     Training average loss at step 73600: 0.175370\n",
      "2023-12-04 20:22:38,395 INFO     Training average positive_sample_loss at step 73700: 0.184092\n",
      "2023-12-04 20:22:38,395 INFO     Training average negative_sample_loss at step 73700: 0.166696\n",
      "2023-12-04 20:22:38,395 INFO     Training average loss at step 73700: 0.175394\n",
      "2023-12-04 20:22:50,472 INFO     Training average positive_sample_loss at step 73800: 0.185065\n",
      "2023-12-04 20:22:50,472 INFO     Training average negative_sample_loss at step 73800: 0.166490\n",
      "2023-12-04 20:22:50,472 INFO     Training average loss at step 73800: 0.175777\n",
      "2023-12-04 20:23:02,411 INFO     Training average positive_sample_loss at step 73900: 0.184608\n",
      "2023-12-04 20:23:02,411 INFO     Training average negative_sample_loss at step 73900: 0.166799\n",
      "2023-12-04 20:23:02,411 INFO     Training average loss at step 73900: 0.175704\n",
      "2023-12-04 20:23:14,864 INFO     Training average positive_sample_loss at step 74000: 0.184082\n",
      "2023-12-04 20:23:14,865 INFO     Training average negative_sample_loss at step 74000: 0.167466\n",
      "2023-12-04 20:23:14,865 INFO     Training average loss at step 74000: 0.175774\n",
      "2023-12-04 20:23:23,161 INFO     Training average positive_sample_loss at step 74100: 0.183149\n",
      "2023-12-04 20:23:23,162 INFO     Training average negative_sample_loss at step 74100: 0.166807\n",
      "2023-12-04 20:23:23,162 INFO     Training average loss at step 74100: 0.174978\n",
      "2023-12-04 20:23:34,575 INFO     Training average positive_sample_loss at step 74200: 0.183593\n",
      "2023-12-04 20:23:34,575 INFO     Training average negative_sample_loss at step 74200: 0.165188\n",
      "2023-12-04 20:23:34,575 INFO     Training average loss at step 74200: 0.174391\n",
      "2023-12-04 20:23:46,381 INFO     Training average positive_sample_loss at step 74300: 0.183977\n",
      "2023-12-04 20:23:46,382 INFO     Training average negative_sample_loss at step 74300: 0.166927\n",
      "2023-12-04 20:23:46,382 INFO     Training average loss at step 74300: 0.175452\n",
      "2023-12-04 20:23:58,322 INFO     Training average positive_sample_loss at step 74400: 0.185925\n",
      "2023-12-04 20:23:58,322 INFO     Training average negative_sample_loss at step 74400: 0.168283\n",
      "2023-12-04 20:23:58,322 INFO     Training average loss at step 74400: 0.177104\n",
      "2023-12-04 20:24:10,752 INFO     Training average positive_sample_loss at step 74500: 0.184633\n",
      "2023-12-04 20:24:10,753 INFO     Training average negative_sample_loss at step 74500: 0.166598\n",
      "2023-12-04 20:24:10,753 INFO     Training average loss at step 74500: 0.175616\n",
      "2023-12-04 20:24:22,371 INFO     Training average positive_sample_loss at step 74600: 0.182373\n",
      "2023-12-04 20:24:22,372 INFO     Training average negative_sample_loss at step 74600: 0.166339\n",
      "2023-12-04 20:24:22,372 INFO     Training average loss at step 74600: 0.174356\n",
      "2023-12-04 20:24:32,414 INFO     Training average positive_sample_loss at step 74700: 0.183415\n",
      "2023-12-04 20:24:32,415 INFO     Training average negative_sample_loss at step 74700: 0.167347\n",
      "2023-12-04 20:24:32,415 INFO     Training average loss at step 74700: 0.175381\n",
      "2023-12-04 20:24:42,460 INFO     Training average positive_sample_loss at step 74800: 0.184680\n",
      "2023-12-04 20:24:42,461 INFO     Training average negative_sample_loss at step 74800: 0.167062\n",
      "2023-12-04 20:24:42,461 INFO     Training average loss at step 74800: 0.175871\n",
      "2023-12-04 20:24:54,095 INFO     Training average positive_sample_loss at step 74900: 0.185194\n",
      "2023-12-04 20:24:54,095 INFO     Training average negative_sample_loss at step 74900: 0.167431\n",
      "2023-12-04 20:24:54,095 INFO     Training average loss at step 74900: 0.176313\n",
      "2023-12-04 20:25:05,941 INFO     Training average positive_sample_loss at step 75000: 0.185547\n",
      "2023-12-04 20:25:05,942 INFO     Training average negative_sample_loss at step 75000: 0.167093\n",
      "2023-12-04 20:25:05,942 INFO     Training average loss at step 75000: 0.176320\n",
      "2023-12-04 20:25:18,187 INFO     Training average positive_sample_loss at step 75100: 0.183047\n",
      "2023-12-04 20:25:18,188 INFO     Training average negative_sample_loss at step 75100: 0.166624\n",
      "2023-12-04 20:25:18,188 INFO     Training average loss at step 75100: 0.174835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:25:30,233 INFO     Training average positive_sample_loss at step 75200: 0.183357\n",
      "2023-12-04 20:25:30,234 INFO     Training average negative_sample_loss at step 75200: 0.166676\n",
      "2023-12-04 20:25:30,234 INFO     Training average loss at step 75200: 0.175017\n",
      "2023-12-04 20:25:41,535 INFO     Training average positive_sample_loss at step 75300: 0.184521\n",
      "2023-12-04 20:25:41,535 INFO     Training average negative_sample_loss at step 75300: 0.166947\n",
      "2023-12-04 20:25:41,535 INFO     Training average loss at step 75300: 0.175734\n",
      "2023-12-04 20:25:50,231 INFO     Training average positive_sample_loss at step 75400: 0.185220\n",
      "2023-12-04 20:25:50,231 INFO     Training average negative_sample_loss at step 75400: 0.167749\n",
      "2023-12-04 20:25:50,231 INFO     Training average loss at step 75400: 0.176485\n",
      "2023-12-04 20:26:01,727 INFO     Training average positive_sample_loss at step 75500: 0.185116\n",
      "2023-12-04 20:26:01,727 INFO     Training average negative_sample_loss at step 75500: 0.166611\n",
      "2023-12-04 20:26:01,728 INFO     Training average loss at step 75500: 0.175863\n",
      "2023-12-04 20:26:13,968 INFO     Training average positive_sample_loss at step 75600: 0.183344\n",
      "2023-12-04 20:26:13,969 INFO     Training average negative_sample_loss at step 75600: 0.166856\n",
      "2023-12-04 20:26:13,969 INFO     Training average loss at step 75600: 0.175100\n",
      "2023-12-04 20:26:25,907 INFO     Training average positive_sample_loss at step 75700: 0.183669\n",
      "2023-12-04 20:26:25,907 INFO     Training average negative_sample_loss at step 75700: 0.166562\n",
      "2023-12-04 20:26:25,907 INFO     Training average loss at step 75700: 0.175115\n",
      "2023-12-04 20:26:38,023 INFO     Training average positive_sample_loss at step 75800: 0.184411\n",
      "2023-12-04 20:26:38,024 INFO     Training average negative_sample_loss at step 75800: 0.166326\n",
      "2023-12-04 20:26:38,024 INFO     Training average loss at step 75800: 0.175368\n",
      "2023-12-04 20:26:49,820 INFO     Training average positive_sample_loss at step 75900: 0.184438\n",
      "2023-12-04 20:26:49,821 INFO     Training average negative_sample_loss at step 75900: 0.167020\n",
      "2023-12-04 20:26:49,821 INFO     Training average loss at step 75900: 0.175729\n",
      "2023-12-04 20:26:58,276 INFO     Training average positive_sample_loss at step 76000: 0.184978\n",
      "2023-12-04 20:26:58,277 INFO     Training average negative_sample_loss at step 76000: 0.166591\n",
      "2023-12-04 20:26:58,277 INFO     Training average loss at step 76000: 0.175784\n",
      "2023-12-04 20:27:10,167 INFO     Training average positive_sample_loss at step 76100: 0.184646\n",
      "2023-12-04 20:27:10,167 INFO     Training average negative_sample_loss at step 76100: 0.164948\n",
      "2023-12-04 20:27:10,167 INFO     Training average loss at step 76100: 0.174797\n",
      "2023-12-04 20:27:21,779 INFO     Training average positive_sample_loss at step 76200: 0.182920\n",
      "2023-12-04 20:27:21,780 INFO     Training average negative_sample_loss at step 76200: 0.165987\n",
      "2023-12-04 20:27:21,780 INFO     Training average loss at step 76200: 0.174454\n",
      "2023-12-04 20:27:33,472 INFO     Training average positive_sample_loss at step 76300: 0.183756\n",
      "2023-12-04 20:27:33,472 INFO     Training average negative_sample_loss at step 76300: 0.167391\n",
      "2023-12-04 20:27:33,472 INFO     Training average loss at step 76300: 0.175574\n",
      "2023-12-04 20:27:45,327 INFO     Training average positive_sample_loss at step 76400: 0.184595\n",
      "2023-12-04 20:27:45,327 INFO     Training average negative_sample_loss at step 76400: 0.166497\n",
      "2023-12-04 20:27:45,327 INFO     Training average loss at step 76400: 0.175546\n",
      "2023-12-04 20:27:57,274 INFO     Training average positive_sample_loss at step 76500: 0.184221\n",
      "2023-12-04 20:27:57,275 INFO     Training average negative_sample_loss at step 76500: 0.167432\n",
      "2023-12-04 20:27:57,275 INFO     Training average loss at step 76500: 0.175827\n",
      "2023-12-04 20:28:05,664 INFO     Training average positive_sample_loss at step 76600: 0.185444\n",
      "2023-12-04 20:28:05,664 INFO     Training average negative_sample_loss at step 76600: 0.167066\n",
      "2023-12-04 20:28:05,665 INFO     Training average loss at step 76600: 0.176255\n",
      "2023-12-04 20:28:17,481 INFO     Training average positive_sample_loss at step 76700: 0.182176\n",
      "2023-12-04 20:28:17,481 INFO     Training average negative_sample_loss at step 76700: 0.166054\n",
      "2023-12-04 20:28:17,482 INFO     Training average loss at step 76700: 0.174115\n",
      "2023-12-04 20:28:29,298 INFO     Training average positive_sample_loss at step 76800: 0.183979\n",
      "2023-12-04 20:28:29,299 INFO     Training average negative_sample_loss at step 76800: 0.167757\n",
      "2023-12-04 20:28:29,299 INFO     Training average loss at step 76800: 0.175868\n",
      "2023-12-04 20:28:41,283 INFO     Training average positive_sample_loss at step 76900: 0.184434\n",
      "2023-12-04 20:28:41,283 INFO     Training average negative_sample_loss at step 76900: 0.166722\n",
      "2023-12-04 20:28:41,283 INFO     Training average loss at step 76900: 0.175578\n",
      "2023-12-04 20:28:53,170 INFO     Training average positive_sample_loss at step 77000: 0.184726\n",
      "2023-12-04 20:28:53,171 INFO     Training average negative_sample_loss at step 77000: 0.166857\n",
      "2023-12-04 20:28:53,171 INFO     Training average loss at step 77000: 0.175792\n",
      "2023-12-04 20:29:05,141 INFO     Training average positive_sample_loss at step 77100: 0.185001\n",
      "2023-12-04 20:29:05,142 INFO     Training average negative_sample_loss at step 77100: 0.167472\n",
      "2023-12-04 20:29:05,142 INFO     Training average loss at step 77100: 0.176237\n",
      "2023-12-04 20:29:15,120 INFO     Training average positive_sample_loss at step 77200: 0.183795\n",
      "2023-12-04 20:29:15,121 INFO     Training average negative_sample_loss at step 77200: 0.166882\n",
      "2023-12-04 20:29:15,121 INFO     Training average loss at step 77200: 0.175338\n",
      "2023-12-04 20:29:25,753 INFO     Training average positive_sample_loss at step 77300: 0.183158\n",
      "2023-12-04 20:29:25,754 INFO     Training average negative_sample_loss at step 77300: 0.165859\n",
      "2023-12-04 20:29:25,754 INFO     Training average loss at step 77300: 0.174508\n",
      "2023-12-04 20:29:37,597 INFO     Training average positive_sample_loss at step 77400: 0.183251\n",
      "2023-12-04 20:29:37,597 INFO     Training average negative_sample_loss at step 77400: 0.166371\n",
      "2023-12-04 20:29:37,597 INFO     Training average loss at step 77400: 0.174811\n",
      "2023-12-04 20:29:49,598 INFO     Training average positive_sample_loss at step 77500: 0.185375\n",
      "2023-12-04 20:29:49,599 INFO     Training average negative_sample_loss at step 77500: 0.168263\n",
      "2023-12-04 20:29:49,599 INFO     Training average loss at step 77500: 0.176819\n",
      "2023-12-04 20:30:01,422 INFO     Training average positive_sample_loss at step 77600: 0.185063\n",
      "2023-12-04 20:30:01,422 INFO     Training average negative_sample_loss at step 77600: 0.166891\n",
      "2023-12-04 20:30:01,422 INFO     Training average loss at step 77600: 0.175977\n",
      "2023-12-04 20:30:14,061 INFO     Training average positive_sample_loss at step 77700: 0.184888\n",
      "2023-12-04 20:30:14,062 INFO     Training average negative_sample_loss at step 77700: 0.166961\n",
      "2023-12-04 20:30:14,062 INFO     Training average loss at step 77700: 0.175924\n",
      "2023-12-04 20:30:24,287 INFO     Training average positive_sample_loss at step 77800: 0.182958\n",
      "2023-12-04 20:30:24,288 INFO     Training average negative_sample_loss at step 77800: 0.167415\n",
      "2023-12-04 20:30:24,288 INFO     Training average loss at step 77800: 0.175186\n",
      "2023-12-04 20:30:33,703 INFO     Training average positive_sample_loss at step 77900: 0.183415\n",
      "2023-12-04 20:30:33,703 INFO     Training average negative_sample_loss at step 77900: 0.165694\n",
      "2023-12-04 20:30:33,703 INFO     Training average loss at step 77900: 0.174555\n",
      "2023-12-04 20:30:45,248 INFO     Training average positive_sample_loss at step 78000: 0.184827\n",
      "2023-12-04 20:30:45,248 INFO     Training average negative_sample_loss at step 78000: 0.168038\n",
      "2023-12-04 20:30:45,248 INFO     Training average loss at step 78000: 0.176433\n",
      "2023-12-04 20:30:57,271 INFO     Training average positive_sample_loss at step 78100: 0.184799\n",
      "2023-12-04 20:30:57,271 INFO     Training average negative_sample_loss at step 78100: 0.166226\n",
      "2023-12-04 20:30:57,271 INFO     Training average loss at step 78100: 0.175513\n",
      "2023-12-04 20:31:09,263 INFO     Training average positive_sample_loss at step 78200: 0.185616\n",
      "2023-12-04 20:31:09,263 INFO     Training average negative_sample_loss at step 78200: 0.166167\n",
      "2023-12-04 20:31:09,263 INFO     Training average loss at step 78200: 0.175891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:31:21,449 INFO     Training average positive_sample_loss at step 78300: 0.182735\n",
      "2023-12-04 20:31:21,450 INFO     Training average negative_sample_loss at step 78300: 0.167030\n",
      "2023-12-04 20:31:21,450 INFO     Training average loss at step 78300: 0.174882\n",
      "2023-12-04 20:31:33,439 INFO     Training average positive_sample_loss at step 78400: 0.183650\n",
      "2023-12-04 20:31:33,440 INFO     Training average negative_sample_loss at step 78400: 0.166033\n",
      "2023-12-04 20:31:33,440 INFO     Training average loss at step 78400: 0.174842\n",
      "2023-12-04 20:31:41,542 INFO     Training average positive_sample_loss at step 78500: 0.184303\n",
      "2023-12-04 20:31:41,543 INFO     Training average negative_sample_loss at step 78500: 0.165370\n",
      "2023-12-04 20:31:41,543 INFO     Training average loss at step 78500: 0.174836\n",
      "2023-12-04 20:31:53,129 INFO     Training average positive_sample_loss at step 78600: 0.185068\n",
      "2023-12-04 20:31:53,130 INFO     Training average negative_sample_loss at step 78600: 0.166466\n",
      "2023-12-04 20:31:53,130 INFO     Training average loss at step 78600: 0.175767\n",
      "2023-12-04 20:32:05,000 INFO     Training average positive_sample_loss at step 78700: 0.184630\n",
      "2023-12-04 20:32:05,000 INFO     Training average negative_sample_loss at step 78700: 0.167098\n",
      "2023-12-04 20:32:05,000 INFO     Training average loss at step 78700: 0.175864\n",
      "2023-12-04 20:32:17,283 INFO     Training average positive_sample_loss at step 78800: 0.183296\n",
      "2023-12-04 20:32:17,284 INFO     Training average negative_sample_loss at step 78800: 0.167021\n",
      "2023-12-04 20:32:17,284 INFO     Training average loss at step 78800: 0.175158\n",
      "2023-12-04 20:32:28,962 INFO     Training average positive_sample_loss at step 78900: 0.183116\n",
      "2023-12-04 20:32:28,962 INFO     Training average negative_sample_loss at step 78900: 0.167822\n",
      "2023-12-04 20:32:28,962 INFO     Training average loss at step 78900: 0.175469\n",
      "2023-12-04 20:32:40,911 INFO     Training average positive_sample_loss at step 79000: 0.184254\n",
      "2023-12-04 20:32:40,912 INFO     Training average negative_sample_loss at step 79000: 0.166169\n",
      "2023-12-04 20:32:40,912 INFO     Training average loss at step 79000: 0.175212\n",
      "2023-12-04 20:32:49,128 INFO     Training average positive_sample_loss at step 79100: 0.184510\n",
      "2023-12-04 20:32:49,128 INFO     Training average negative_sample_loss at step 79100: 0.166310\n",
      "2023-12-04 20:32:49,128 INFO     Training average loss at step 79100: 0.175410\n",
      "2023-12-04 20:33:00,792 INFO     Training average positive_sample_loss at step 79200: 0.185421\n",
      "2023-12-04 20:33:00,793 INFO     Training average negative_sample_loss at step 79200: 0.165929\n",
      "2023-12-04 20:33:00,793 INFO     Training average loss at step 79200: 0.175675\n",
      "2023-12-04 20:33:13,137 INFO     Training average positive_sample_loss at step 79300: 0.183860\n",
      "2023-12-04 20:33:13,137 INFO     Training average negative_sample_loss at step 79300: 0.166518\n",
      "2023-12-04 20:33:13,137 INFO     Training average loss at step 79300: 0.175189\n",
      "2023-12-04 20:33:24,671 INFO     Training average positive_sample_loss at step 79400: 0.183474\n",
      "2023-12-04 20:33:24,671 INFO     Training average negative_sample_loss at step 79400: 0.167087\n",
      "2023-12-04 20:33:24,671 INFO     Training average loss at step 79400: 0.175280\n",
      "2023-12-04 20:33:36,674 INFO     Training average positive_sample_loss at step 79500: 0.183862\n",
      "2023-12-04 20:33:36,674 INFO     Training average negative_sample_loss at step 79500: 0.167281\n",
      "2023-12-04 20:33:36,674 INFO     Training average loss at step 79500: 0.175572\n",
      "2023-12-04 20:33:48,607 INFO     Training average positive_sample_loss at step 79600: 0.185102\n",
      "2023-12-04 20:33:48,607 INFO     Training average negative_sample_loss at step 79600: 0.167509\n",
      "2023-12-04 20:33:48,607 INFO     Training average loss at step 79600: 0.176305\n",
      "2023-12-04 20:33:57,277 INFO     Training average positive_sample_loss at step 79700: 0.184526\n",
      "2023-12-04 20:33:57,277 INFO     Training average negative_sample_loss at step 79700: 0.165883\n",
      "2023-12-04 20:33:57,277 INFO     Training average loss at step 79700: 0.175204\n",
      "2023-12-04 20:34:08,864 INFO     Training average positive_sample_loss at step 79800: 0.184939\n",
      "2023-12-04 20:34:08,864 INFO     Training average negative_sample_loss at step 79800: 0.167605\n",
      "2023-12-04 20:34:08,864 INFO     Training average loss at step 79800: 0.176272\n",
      "2023-12-04 20:34:20,539 INFO     Training average positive_sample_loss at step 79900: 0.182175\n",
      "2023-12-04 20:34:20,540 INFO     Training average negative_sample_loss at step 79900: 0.165817\n",
      "2023-12-04 20:34:20,540 INFO     Training average loss at step 79900: 0.173996\n",
      "2023-12-04 20:34:42,629 INFO     Training average positive_sample_loss at step 80000: 0.184213\n",
      "2023-12-04 20:34:42,630 INFO     Training average negative_sample_loss at step 80000: 0.166029\n",
      "2023-12-04 20:34:42,630 INFO     Training average loss at step 80000: 0.175121\n",
      "2023-12-04 20:34:42,630 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 20:34:43,845 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 20:35:30,875 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 20:36:11,626 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 20:36:18,459 INFO     Valid MRR at step 80000: 0.343255\n",
      "2023-12-04 20:36:18,459 INFO     Valid MR at step 80000: 164.507927\n",
      "2023-12-04 20:36:18,459 INFO     Valid HITS@1 at step 80000: 0.247305\n",
      "2023-12-04 20:36:18,459 INFO     Valid HITS@3 at step 80000: 0.380325\n",
      "2023-12-04 20:36:18,459 INFO     Valid HITS@10 at step 80000: 0.534902\n",
      "2023-12-04 20:36:27,318 INFO     Training average positive_sample_loss at step 80100: 0.184283\n",
      "2023-12-04 20:36:27,318 INFO     Training average negative_sample_loss at step 80100: 0.166594\n",
      "2023-12-04 20:36:27,318 INFO     Training average loss at step 80100: 0.175439\n",
      "2023-12-04 20:36:35,997 INFO     Training average positive_sample_loss at step 80200: 0.185138\n",
      "2023-12-04 20:36:35,997 INFO     Training average negative_sample_loss at step 80200: 0.167310\n",
      "2023-12-04 20:36:35,997 INFO     Training average loss at step 80200: 0.176224\n",
      "2023-12-04 20:36:45,613 INFO     Training average positive_sample_loss at step 80300: 0.184983\n",
      "2023-12-04 20:36:45,614 INFO     Training average negative_sample_loss at step 80300: 0.165470\n",
      "2023-12-04 20:36:45,614 INFO     Training average loss at step 80300: 0.175226\n",
      "2023-12-04 20:36:57,883 INFO     Training average positive_sample_loss at step 80400: 0.182626\n",
      "2023-12-04 20:36:57,883 INFO     Training average negative_sample_loss at step 80400: 0.165288\n",
      "2023-12-04 20:36:57,884 INFO     Training average loss at step 80400: 0.173957\n",
      "2023-12-04 20:37:09,714 INFO     Training average positive_sample_loss at step 80500: 0.183109\n",
      "2023-12-04 20:37:09,714 INFO     Training average negative_sample_loss at step 80500: 0.166420\n",
      "2023-12-04 20:37:09,714 INFO     Training average loss at step 80500: 0.174764\n",
      "2023-12-04 20:37:21,668 INFO     Training average positive_sample_loss at step 80600: 0.183619\n",
      "2023-12-04 20:37:21,668 INFO     Training average negative_sample_loss at step 80600: 0.167131\n",
      "2023-12-04 20:37:21,668 INFO     Training average loss at step 80600: 0.175375\n",
      "2023-12-04 20:37:29,710 INFO     Training average positive_sample_loss at step 80700: 0.185319\n",
      "2023-12-04 20:37:29,711 INFO     Training average negative_sample_loss at step 80700: 0.167862\n",
      "2023-12-04 20:37:29,711 INFO     Training average loss at step 80700: 0.176590\n",
      "2023-12-04 20:37:41,433 INFO     Training average positive_sample_loss at step 80800: 0.185457\n",
      "2023-12-04 20:37:41,433 INFO     Training average negative_sample_loss at step 80800: 0.166640\n",
      "2023-12-04 20:37:41,433 INFO     Training average loss at step 80800: 0.176048\n",
      "2023-12-04 20:37:53,947 INFO     Training average positive_sample_loss at step 80900: 0.184436\n",
      "2023-12-04 20:37:53,948 INFO     Training average negative_sample_loss at step 80900: 0.165783\n",
      "2023-12-04 20:37:53,948 INFO     Training average loss at step 80900: 0.175110\n",
      "2023-12-04 20:38:05,468 INFO     Training average positive_sample_loss at step 81000: 0.182581\n",
      "2023-12-04 20:38:05,468 INFO     Training average negative_sample_loss at step 81000: 0.166242\n",
      "2023-12-04 20:38:05,468 INFO     Training average loss at step 81000: 0.174411\n",
      "2023-12-04 20:38:17,464 INFO     Training average positive_sample_loss at step 81100: 0.184413\n",
      "2023-12-04 20:38:17,464 INFO     Training average negative_sample_loss at step 81100: 0.167331\n",
      "2023-12-04 20:38:17,464 INFO     Training average loss at step 81100: 0.175872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:38:29,457 INFO     Training average positive_sample_loss at step 81200: 0.184817\n",
      "2023-12-04 20:38:29,458 INFO     Training average negative_sample_loss at step 81200: 0.167751\n",
      "2023-12-04 20:38:29,458 INFO     Training average loss at step 81200: 0.176284\n",
      "2023-12-04 20:38:37,852 INFO     Training average positive_sample_loss at step 81300: 0.184753\n",
      "2023-12-04 20:38:37,852 INFO     Training average negative_sample_loss at step 81300: 0.166887\n",
      "2023-12-04 20:38:37,852 INFO     Training average loss at step 81300: 0.175820\n",
      "2023-12-04 20:38:50,020 INFO     Training average positive_sample_loss at step 81400: 0.185003\n",
      "2023-12-04 20:38:50,020 INFO     Training average negative_sample_loss at step 81400: 0.166370\n",
      "2023-12-04 20:38:50,020 INFO     Training average loss at step 81400: 0.175687\n",
      "2023-12-04 20:39:01,586 INFO     Training average positive_sample_loss at step 81500: 0.182998\n",
      "2023-12-04 20:39:01,586 INFO     Training average negative_sample_loss at step 81500: 0.167505\n",
      "2023-12-04 20:39:01,586 INFO     Training average loss at step 81500: 0.175251\n",
      "2023-12-04 20:39:13,562 INFO     Training average positive_sample_loss at step 81600: 0.183883\n",
      "2023-12-04 20:39:13,563 INFO     Training average negative_sample_loss at step 81600: 0.165953\n",
      "2023-12-04 20:39:13,563 INFO     Training average loss at step 81600: 0.174918\n",
      "2023-12-04 20:39:25,575 INFO     Training average positive_sample_loss at step 81700: 0.184169\n",
      "2023-12-04 20:39:25,575 INFO     Training average negative_sample_loss at step 81700: 0.167685\n",
      "2023-12-04 20:39:25,575 INFO     Training average loss at step 81700: 0.175927\n",
      "2023-12-04 20:39:37,628 INFO     Training average positive_sample_loss at step 81800: 0.184648\n",
      "2023-12-04 20:39:37,628 INFO     Training average negative_sample_loss at step 81800: 0.166667\n",
      "2023-12-04 20:39:37,628 INFO     Training average loss at step 81800: 0.175657\n",
      "2023-12-04 20:39:46,954 INFO     Training average positive_sample_loss at step 81900: 0.185291\n",
      "2023-12-04 20:39:46,954 INFO     Training average negative_sample_loss at step 81900: 0.166797\n",
      "2023-12-04 20:39:46,954 INFO     Training average loss at step 81900: 0.176044\n",
      "2023-12-04 20:39:58,238 INFO     Training average positive_sample_loss at step 82000: 0.183270\n",
      "2023-12-04 20:39:58,239 INFO     Training average negative_sample_loss at step 82000: 0.166805\n",
      "2023-12-04 20:39:58,239 INFO     Training average loss at step 82000: 0.175037\n",
      "2023-12-04 20:40:09,983 INFO     Training average positive_sample_loss at step 82100: 0.183667\n",
      "2023-12-04 20:40:09,984 INFO     Training average negative_sample_loss at step 82100: 0.165806\n",
      "2023-12-04 20:40:09,984 INFO     Training average loss at step 82100: 0.174736\n",
      "2023-12-04 20:40:21,874 INFO     Training average positive_sample_loss at step 82200: 0.184704\n",
      "2023-12-04 20:40:21,874 INFO     Training average negative_sample_loss at step 82200: 0.166898\n",
      "2023-12-04 20:40:21,874 INFO     Training average loss at step 82200: 0.175801\n",
      "2023-12-04 20:40:33,912 INFO     Training average positive_sample_loss at step 82300: 0.184345\n",
      "2023-12-04 20:40:33,913 INFO     Training average negative_sample_loss at step 82300: 0.166285\n",
      "2023-12-04 20:40:33,913 INFO     Training average loss at step 82300: 0.175315\n",
      "2023-12-04 20:40:45,886 INFO     Training average positive_sample_loss at step 82400: 0.185208\n",
      "2023-12-04 20:40:45,887 INFO     Training average negative_sample_loss at step 82400: 0.165715\n",
      "2023-12-04 20:40:45,887 INFO     Training average loss at step 82400: 0.175462\n",
      "2023-12-04 20:40:56,047 INFO     Training average positive_sample_loss at step 82500: 0.183687\n",
      "2023-12-04 20:40:56,048 INFO     Training average negative_sample_loss at step 82500: 0.166187\n",
      "2023-12-04 20:40:56,048 INFO     Training average loss at step 82500: 0.174937\n",
      "2023-12-04 20:41:06,530 INFO     Training average positive_sample_loss at step 82600: 0.183093\n",
      "2023-12-04 20:41:06,531 INFO     Training average negative_sample_loss at step 82600: 0.168041\n",
      "2023-12-04 20:41:06,531 INFO     Training average loss at step 82600: 0.175567\n",
      "2023-12-04 20:41:18,339 INFO     Training average positive_sample_loss at step 82700: 0.183518\n",
      "2023-12-04 20:41:18,339 INFO     Training average negative_sample_loss at step 82700: 0.167286\n",
      "2023-12-04 20:41:18,339 INFO     Training average loss at step 82700: 0.175402\n",
      "2023-12-04 20:41:30,116 INFO     Training average positive_sample_loss at step 82800: 0.184564\n",
      "2023-12-04 20:41:30,116 INFO     Training average negative_sample_loss at step 82800: 0.165584\n",
      "2023-12-04 20:41:30,116 INFO     Training average loss at step 82800: 0.175074\n",
      "2023-12-04 20:41:41,887 INFO     Training average positive_sample_loss at step 82900: 0.185460\n",
      "2023-12-04 20:41:41,887 INFO     Training average negative_sample_loss at step 82900: 0.166754\n",
      "2023-12-04 20:41:41,887 INFO     Training average loss at step 82900: 0.176107\n",
      "2023-12-04 20:41:54,399 INFO     Training average positive_sample_loss at step 83000: 0.185355\n",
      "2023-12-04 20:41:54,400 INFO     Training average negative_sample_loss at step 83000: 0.167264\n",
      "2023-12-04 20:41:54,400 INFO     Training average loss at step 83000: 0.176309\n",
      "2023-12-04 20:42:05,257 INFO     Training average positive_sample_loss at step 83100: 0.182901\n",
      "2023-12-04 20:42:05,257 INFO     Training average negative_sample_loss at step 83100: 0.166123\n",
      "2023-12-04 20:42:05,257 INFO     Training average loss at step 83100: 0.174512\n",
      "2023-12-04 20:42:14,097 INFO     Training average positive_sample_loss at step 83200: 0.183635\n",
      "2023-12-04 20:42:14,098 INFO     Training average negative_sample_loss at step 83200: 0.167224\n",
      "2023-12-04 20:42:14,098 INFO     Training average loss at step 83200: 0.175429\n",
      "2023-12-04 20:42:25,687 INFO     Training average positive_sample_loss at step 83300: 0.184500\n",
      "2023-12-04 20:42:25,687 INFO     Training average negative_sample_loss at step 83300: 0.166560\n",
      "2023-12-04 20:42:25,687 INFO     Training average loss at step 83300: 0.175530\n",
      "2023-12-04 20:42:37,405 INFO     Training average positive_sample_loss at step 83400: 0.184832\n",
      "2023-12-04 20:42:37,405 INFO     Training average negative_sample_loss at step 83400: 0.167122\n",
      "2023-12-04 20:42:37,405 INFO     Training average loss at step 83400: 0.175977\n",
      "2023-12-04 20:42:49,349 INFO     Training average positive_sample_loss at step 83500: 0.185098\n",
      "2023-12-04 20:42:49,349 INFO     Training average negative_sample_loss at step 83500: 0.166054\n",
      "2023-12-04 20:42:49,350 INFO     Training average loss at step 83500: 0.175576\n",
      "2023-12-04 20:43:01,735 INFO     Training average positive_sample_loss at step 83600: 0.183118\n",
      "2023-12-04 20:43:01,736 INFO     Training average negative_sample_loss at step 83600: 0.166379\n",
      "2023-12-04 20:43:01,736 INFO     Training average loss at step 83600: 0.174748\n",
      "2023-12-04 20:43:13,282 INFO     Training average positive_sample_loss at step 83700: 0.183348\n",
      "2023-12-04 20:43:13,283 INFO     Training average negative_sample_loss at step 83700: 0.166551\n",
      "2023-12-04 20:43:13,283 INFO     Training average loss at step 83700: 0.174950\n",
      "2023-12-04 20:43:21,530 INFO     Training average positive_sample_loss at step 83800: 0.184203\n",
      "2023-12-04 20:43:21,531 INFO     Training average negative_sample_loss at step 83800: 0.167390\n",
      "2023-12-04 20:43:21,531 INFO     Training average loss at step 83800: 0.175797\n",
      "2023-12-04 20:43:33,205 INFO     Training average positive_sample_loss at step 83900: 0.184848\n",
      "2023-12-04 20:43:33,205 INFO     Training average negative_sample_loss at step 83900: 0.166698\n",
      "2023-12-04 20:43:33,205 INFO     Training average loss at step 83900: 0.175773\n",
      "2023-12-04 20:43:44,991 INFO     Training average positive_sample_loss at step 84000: 0.184787\n",
      "2023-12-04 20:43:44,991 INFO     Training average negative_sample_loss at step 84000: 0.166499\n",
      "2023-12-04 20:43:44,991 INFO     Training average loss at step 84000: 0.175643\n",
      "2023-12-04 20:43:57,417 INFO     Training average positive_sample_loss at step 84100: 0.184225\n",
      "2023-12-04 20:43:57,417 INFO     Training average negative_sample_loss at step 84100: 0.167708\n",
      "2023-12-04 20:43:57,417 INFO     Training average loss at step 84100: 0.175966\n",
      "2023-12-04 20:44:09,150 INFO     Training average positive_sample_loss at step 84200: 0.183322\n",
      "2023-12-04 20:44:09,150 INFO     Training average negative_sample_loss at step 84200: 0.166702\n",
      "2023-12-04 20:44:09,150 INFO     Training average loss at step 84200: 0.175012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:44:21,052 INFO     Training average positive_sample_loss at step 84300: 0.183567\n",
      "2023-12-04 20:44:21,053 INFO     Training average negative_sample_loss at step 84300: 0.167731\n",
      "2023-12-04 20:44:21,053 INFO     Training average loss at step 84300: 0.175649\n",
      "2023-12-04 20:44:29,350 INFO     Training average positive_sample_loss at step 84400: 0.184494\n",
      "2023-12-04 20:44:29,350 INFO     Training average negative_sample_loss at step 84400: 0.165563\n",
      "2023-12-04 20:44:29,350 INFO     Training average loss at step 84400: 0.175029\n",
      "2023-12-04 20:44:40,909 INFO     Training average positive_sample_loss at step 84500: 0.185323\n",
      "2023-12-04 20:44:40,909 INFO     Training average negative_sample_loss at step 84500: 0.166919\n",
      "2023-12-04 20:44:40,909 INFO     Training average loss at step 84500: 0.176121\n",
      "2023-12-04 20:44:53,348 INFO     Training average positive_sample_loss at step 84600: 0.185100\n",
      "2023-12-04 20:44:53,348 INFO     Training average negative_sample_loss at step 84600: 0.165383\n",
      "2023-12-04 20:44:53,348 INFO     Training average loss at step 84600: 0.175241\n",
      "2023-12-04 20:45:04,938 INFO     Training average positive_sample_loss at step 84700: 0.182845\n",
      "2023-12-04 20:45:04,938 INFO     Training average negative_sample_loss at step 84700: 0.167450\n",
      "2023-12-04 20:45:04,939 INFO     Training average loss at step 84700: 0.175148\n",
      "2023-12-04 20:45:16,787 INFO     Training average positive_sample_loss at step 84800: 0.183566\n",
      "2023-12-04 20:45:16,787 INFO     Training average negative_sample_loss at step 84800: 0.166366\n",
      "2023-12-04 20:45:16,788 INFO     Training average loss at step 84800: 0.174966\n",
      "2023-12-04 20:45:28,848 INFO     Training average positive_sample_loss at step 84900: 0.184766\n",
      "2023-12-04 20:45:28,849 INFO     Training average negative_sample_loss at step 84900: 0.166735\n",
      "2023-12-04 20:45:28,849 INFO     Training average loss at step 84900: 0.175750\n",
      "2023-12-04 20:45:37,911 INFO     Training average positive_sample_loss at step 85000: 0.184019\n",
      "2023-12-04 20:45:37,911 INFO     Training average negative_sample_loss at step 85000: 0.166252\n",
      "2023-12-04 20:45:37,911 INFO     Training average loss at step 85000: 0.175136\n",
      "2023-12-04 20:45:48,697 INFO     Training average positive_sample_loss at step 85100: 0.185854\n",
      "2023-12-04 20:45:48,697 INFO     Training average negative_sample_loss at step 85100: 0.167747\n",
      "2023-12-04 20:45:48,697 INFO     Training average loss at step 85100: 0.176801\n",
      "2023-12-04 20:46:00,718 INFO     Training average positive_sample_loss at step 85200: 0.183370\n",
      "2023-12-04 20:46:00,718 INFO     Training average negative_sample_loss at step 85200: 0.166239\n",
      "2023-12-04 20:46:00,718 INFO     Training average loss at step 85200: 0.174804\n",
      "2023-12-04 20:46:12,362 INFO     Training average positive_sample_loss at step 85300: 0.183657\n",
      "2023-12-04 20:46:12,362 INFO     Training average negative_sample_loss at step 85300: 0.167740\n",
      "2023-12-04 20:46:12,362 INFO     Training average loss at step 85300: 0.175699\n",
      "2023-12-04 20:46:24,148 INFO     Training average positive_sample_loss at step 85400: 0.184171\n",
      "2023-12-04 20:46:24,149 INFO     Training average negative_sample_loss at step 85400: 0.166835\n",
      "2023-12-04 20:46:24,149 INFO     Training average loss at step 85400: 0.175503\n",
      "2023-12-04 20:46:35,926 INFO     Training average positive_sample_loss at step 85500: 0.184657\n",
      "2023-12-04 20:46:35,926 INFO     Training average negative_sample_loss at step 85500: 0.166088\n",
      "2023-12-04 20:46:35,926 INFO     Training average loss at step 85500: 0.175372\n",
      "2023-12-04 20:46:47,063 INFO     Training average positive_sample_loss at step 85600: 0.185471\n",
      "2023-12-04 20:46:47,063 INFO     Training average negative_sample_loss at step 85600: 0.166027\n",
      "2023-12-04 20:46:47,063 INFO     Training average loss at step 85600: 0.175749\n",
      "2023-12-04 20:46:56,230 INFO     Training average positive_sample_loss at step 85700: 0.183707\n",
      "2023-12-04 20:46:56,231 INFO     Training average negative_sample_loss at step 85700: 0.167048\n",
      "2023-12-04 20:46:56,231 INFO     Training average loss at step 85700: 0.175378\n",
      "2023-12-04 20:47:07,925 INFO     Training average positive_sample_loss at step 85800: 0.183470\n",
      "2023-12-04 20:47:07,926 INFO     Training average negative_sample_loss at step 85800: 0.167407\n",
      "2023-12-04 20:47:07,926 INFO     Training average loss at step 85800: 0.175438\n",
      "2023-12-04 20:47:19,935 INFO     Training average positive_sample_loss at step 85900: 0.183991\n",
      "2023-12-04 20:47:19,935 INFO     Training average negative_sample_loss at step 85900: 0.165941\n",
      "2023-12-04 20:47:19,935 INFO     Training average loss at step 85900: 0.174966\n",
      "2023-12-04 20:47:31,850 INFO     Training average positive_sample_loss at step 86000: 0.184480\n",
      "2023-12-04 20:47:31,850 INFO     Training average negative_sample_loss at step 86000: 0.167533\n",
      "2023-12-04 20:47:31,850 INFO     Training average loss at step 86000: 0.176006\n",
      "2023-12-04 20:47:43,714 INFO     Training average positive_sample_loss at step 86100: 0.185475\n",
      "2023-12-04 20:47:43,715 INFO     Training average negative_sample_loss at step 86100: 0.166968\n",
      "2023-12-04 20:47:43,715 INFO     Training average loss at step 86100: 0.176222\n",
      "2023-12-04 20:47:56,129 INFO     Training average positive_sample_loss at step 86200: 0.184339\n",
      "2023-12-04 20:47:56,130 INFO     Training average negative_sample_loss at step 86200: 0.166310\n",
      "2023-12-04 20:47:56,130 INFO     Training average loss at step 86200: 0.175324\n",
      "2023-12-04 20:48:04,189 INFO     Training average positive_sample_loss at step 86300: 0.182945\n",
      "2023-12-04 20:48:04,189 INFO     Training average negative_sample_loss at step 86300: 0.164443\n",
      "2023-12-04 20:48:04,189 INFO     Training average loss at step 86300: 0.173694\n",
      "2023-12-04 20:48:15,800 INFO     Training average positive_sample_loss at step 86400: 0.183513\n",
      "2023-12-04 20:48:15,800 INFO     Training average negative_sample_loss at step 86400: 0.164833\n",
      "2023-12-04 20:48:15,800 INFO     Training average loss at step 86400: 0.174173\n",
      "2023-12-04 20:48:27,607 INFO     Training average positive_sample_loss at step 86500: 0.183556\n",
      "2023-12-04 20:48:27,607 INFO     Training average negative_sample_loss at step 86500: 0.165707\n",
      "2023-12-04 20:48:27,607 INFO     Training average loss at step 86500: 0.174632\n",
      "2023-12-04 20:48:39,458 INFO     Training average positive_sample_loss at step 86600: 0.185148\n",
      "2023-12-04 20:48:39,459 INFO     Training average negative_sample_loss at step 86600: 0.167485\n",
      "2023-12-04 20:48:39,459 INFO     Training average loss at step 86600: 0.176317\n",
      "2023-12-04 20:48:51,435 INFO     Training average positive_sample_loss at step 86700: 0.185564\n",
      "2023-12-04 20:48:51,436 INFO     Training average negative_sample_loss at step 86700: 0.167635\n",
      "2023-12-04 20:48:51,436 INFO     Training average loss at step 86700: 0.176599\n",
      "2023-12-04 20:49:03,560 INFO     Training average positive_sample_loss at step 86800: 0.182919\n",
      "2023-12-04 20:49:03,561 INFO     Training average negative_sample_loss at step 86800: 0.167288\n",
      "2023-12-04 20:49:03,561 INFO     Training average loss at step 86800: 0.175103\n",
      "2023-12-04 20:49:11,807 INFO     Training average positive_sample_loss at step 86900: 0.183514\n",
      "2023-12-04 20:49:11,807 INFO     Training average negative_sample_loss at step 86900: 0.166910\n",
      "2023-12-04 20:49:11,807 INFO     Training average loss at step 86900: 0.175212\n",
      "2023-12-04 20:49:23,174 INFO     Training average positive_sample_loss at step 87000: 0.183821\n",
      "2023-12-04 20:49:23,174 INFO     Training average negative_sample_loss at step 87000: 0.166475\n",
      "2023-12-04 20:49:23,174 INFO     Training average loss at step 87000: 0.175148\n",
      "2023-12-04 20:49:34,818 INFO     Training average positive_sample_loss at step 87100: 0.185544\n",
      "2023-12-04 20:49:34,819 INFO     Training average negative_sample_loss at step 87100: 0.167083\n",
      "2023-12-04 20:49:34,819 INFO     Training average loss at step 87100: 0.176313\n",
      "2023-12-04 20:49:46,587 INFO     Training average positive_sample_loss at step 87200: 0.184784\n",
      "2023-12-04 20:49:46,588 INFO     Training average negative_sample_loss at step 87200: 0.166108\n",
      "2023-12-04 20:49:46,588 INFO     Training average loss at step 87200: 0.175446\n",
      "2023-12-04 20:49:58,976 INFO     Training average positive_sample_loss at step 87300: 0.183974\n",
      "2023-12-04 20:49:58,976 INFO     Training average negative_sample_loss at step 87300: 0.166325\n",
      "2023-12-04 20:49:58,976 INFO     Training average loss at step 87300: 0.175150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:50:10,599 INFO     Training average positive_sample_loss at step 87400: 0.183399\n",
      "2023-12-04 20:50:10,600 INFO     Training average negative_sample_loss at step 87400: 0.166809\n",
      "2023-12-04 20:50:10,600 INFO     Training average loss at step 87400: 0.175104\n",
      "2023-12-04 20:50:20,240 INFO     Training average positive_sample_loss at step 87500: 0.183700\n",
      "2023-12-04 20:50:20,240 INFO     Training average negative_sample_loss at step 87500: 0.166737\n",
      "2023-12-04 20:50:20,240 INFO     Training average loss at step 87500: 0.175218\n",
      "2023-12-04 20:50:30,486 INFO     Training average positive_sample_loss at step 87600: 0.184811\n",
      "2023-12-04 20:50:30,487 INFO     Training average negative_sample_loss at step 87600: 0.166232\n",
      "2023-12-04 20:50:30,487 INFO     Training average loss at step 87600: 0.175522\n",
      "2023-12-04 20:50:42,446 INFO     Training average positive_sample_loss at step 87700: 0.184466\n",
      "2023-12-04 20:50:42,446 INFO     Training average negative_sample_loss at step 87700: 0.166231\n",
      "2023-12-04 20:50:42,446 INFO     Training average loss at step 87700: 0.175348\n",
      "2023-12-04 20:50:54,878 INFO     Training average positive_sample_loss at step 87800: 0.184994\n",
      "2023-12-04 20:50:54,879 INFO     Training average negative_sample_loss at step 87800: 0.165668\n",
      "2023-12-04 20:50:54,879 INFO     Training average loss at step 87800: 0.175331\n",
      "2023-12-04 20:51:06,439 INFO     Training average positive_sample_loss at step 87900: 0.183073\n",
      "2023-12-04 20:51:06,439 INFO     Training average negative_sample_loss at step 87900: 0.165885\n",
      "2023-12-04 20:51:06,439 INFO     Training average loss at step 87900: 0.174479\n",
      "2023-12-04 20:51:18,296 INFO     Training average positive_sample_loss at step 88000: 0.184210\n",
      "2023-12-04 20:51:18,296 INFO     Training average negative_sample_loss at step 88000: 0.165804\n",
      "2023-12-04 20:51:18,296 INFO     Training average loss at step 88000: 0.175007\n",
      "2023-12-04 20:51:29,444 INFO     Training average positive_sample_loss at step 88100: 0.183398\n",
      "2023-12-04 20:51:29,444 INFO     Training average negative_sample_loss at step 88100: 0.166944\n",
      "2023-12-04 20:51:29,445 INFO     Training average loss at step 88100: 0.175171\n",
      "2023-12-04 20:51:38,326 INFO     Training average positive_sample_loss at step 88200: 0.185286\n",
      "2023-12-04 20:51:38,326 INFO     Training average negative_sample_loss at step 88200: 0.166582\n",
      "2023-12-04 20:51:38,326 INFO     Training average loss at step 88200: 0.175934\n",
      "2023-12-04 20:51:50,021 INFO     Training average positive_sample_loss at step 88300: 0.184965\n",
      "2023-12-04 20:51:50,021 INFO     Training average negative_sample_loss at step 88300: 0.166846\n",
      "2023-12-04 20:51:50,021 INFO     Training average loss at step 88300: 0.175906\n",
      "2023-12-04 20:52:02,290 INFO     Training average positive_sample_loss at step 88400: 0.182428\n",
      "2023-12-04 20:52:02,290 INFO     Training average negative_sample_loss at step 88400: 0.166781\n",
      "2023-12-04 20:52:02,290 INFO     Training average loss at step 88400: 0.174605\n",
      "2023-12-04 20:52:14,070 INFO     Training average positive_sample_loss at step 88500: 0.184185\n",
      "2023-12-04 20:52:14,071 INFO     Training average negative_sample_loss at step 88500: 0.166632\n",
      "2023-12-04 20:52:14,071 INFO     Training average loss at step 88500: 0.175409\n",
      "2023-12-04 20:52:26,157 INFO     Training average positive_sample_loss at step 88600: 0.184631\n",
      "2023-12-04 20:52:26,157 INFO     Training average negative_sample_loss at step 88600: 0.166640\n",
      "2023-12-04 20:52:26,157 INFO     Training average loss at step 88600: 0.175636\n",
      "2023-12-04 20:52:38,050 INFO     Training average positive_sample_loss at step 88700: 0.184622\n",
      "2023-12-04 20:52:38,050 INFO     Training average negative_sample_loss at step 88700: 0.167296\n",
      "2023-12-04 20:52:38,050 INFO     Training average loss at step 88700: 0.175959\n",
      "2023-12-04 20:52:46,207 INFO     Training average positive_sample_loss at step 88800: 0.185212\n",
      "2023-12-04 20:52:46,208 INFO     Training average negative_sample_loss at step 88800: 0.165595\n",
      "2023-12-04 20:52:46,208 INFO     Training average loss at step 88800: 0.175404\n",
      "2023-12-04 20:52:58,162 INFO     Training average positive_sample_loss at step 88900: 0.183769\n",
      "2023-12-04 20:52:58,162 INFO     Training average negative_sample_loss at step 88900: 0.167005\n",
      "2023-12-04 20:52:58,162 INFO     Training average loss at step 88900: 0.175387\n",
      "2023-12-04 20:53:09,703 INFO     Training average positive_sample_loss at step 89000: 0.183073\n",
      "2023-12-04 20:53:09,704 INFO     Training average negative_sample_loss at step 89000: 0.166073\n",
      "2023-12-04 20:53:09,704 INFO     Training average loss at step 89000: 0.174573\n",
      "2023-12-04 20:53:21,475 INFO     Training average positive_sample_loss at step 89100: 0.184553\n",
      "2023-12-04 20:53:21,476 INFO     Training average negative_sample_loss at step 89100: 0.167078\n",
      "2023-12-04 20:53:21,476 INFO     Training average loss at step 89100: 0.175815\n",
      "2023-12-04 20:53:33,273 INFO     Training average positive_sample_loss at step 89200: 0.184419\n",
      "2023-12-04 20:53:33,274 INFO     Training average negative_sample_loss at step 89200: 0.167564\n",
      "2023-12-04 20:53:33,274 INFO     Training average loss at step 89200: 0.175992\n",
      "2023-12-04 20:53:45,267 INFO     Training average positive_sample_loss at step 89300: 0.184979\n",
      "2023-12-04 20:53:45,267 INFO     Training average negative_sample_loss at step 89300: 0.166174\n",
      "2023-12-04 20:53:45,267 INFO     Training average loss at step 89300: 0.175577\n",
      "2023-12-04 20:53:55,230 INFO     Training average positive_sample_loss at step 89400: 0.184618\n",
      "2023-12-04 20:53:55,230 INFO     Training average negative_sample_loss at step 89400: 0.167178\n",
      "2023-12-04 20:53:55,230 INFO     Training average loss at step 89400: 0.175898\n",
      "2023-12-04 20:54:06,753 INFO     Training average positive_sample_loss at step 89500: 0.182949\n",
      "2023-12-04 20:54:06,753 INFO     Training average negative_sample_loss at step 89500: 0.166890\n",
      "2023-12-04 20:54:06,753 INFO     Training average loss at step 89500: 0.174920\n",
      "2023-12-04 20:54:18,436 INFO     Training average positive_sample_loss at step 89600: 0.183903\n",
      "2023-12-04 20:54:18,436 INFO     Training average negative_sample_loss at step 89600: 0.164866\n",
      "2023-12-04 20:54:18,436 INFO     Training average loss at step 89600: 0.174385\n",
      "2023-12-04 20:54:30,198 INFO     Training average positive_sample_loss at step 89700: 0.184342\n",
      "2023-12-04 20:54:30,199 INFO     Training average negative_sample_loss at step 89700: 0.166963\n",
      "2023-12-04 20:54:30,199 INFO     Training average loss at step 89700: 0.175653\n",
      "2023-12-04 20:54:42,216 INFO     Training average positive_sample_loss at step 89800: 0.185146\n",
      "2023-12-04 20:54:42,217 INFO     Training average negative_sample_loss at step 89800: 0.165440\n",
      "2023-12-04 20:54:42,217 INFO     Training average loss at step 89800: 0.175293\n",
      "2023-12-04 20:54:54,194 INFO     Training average positive_sample_loss at step 89900: 0.185471\n",
      "2023-12-04 20:54:54,194 INFO     Training average negative_sample_loss at step 89900: 0.166898\n",
      "2023-12-04 20:54:54,195 INFO     Training average loss at step 89900: 0.176185\n",
      "2023-12-04 20:55:16,336 INFO     Training average positive_sample_loss at step 90000: 0.182530\n",
      "2023-12-04 20:55:16,336 INFO     Training average negative_sample_loss at step 90000: 0.166849\n",
      "2023-12-04 20:55:16,336 INFO     Training average loss at step 90000: 0.174690\n",
      "2023-12-04 20:55:16,336 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 20:55:17,044 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 20:56:05,471 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 20:56:50,485 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 20:56:59,645 INFO     Valid MRR at step 90000: 0.343632\n",
      "2023-12-04 20:56:59,645 INFO     Valid MR at step 90000: 164.623781\n",
      "2023-12-04 20:56:59,645 INFO     Valid HITS@1 at step 90000: 0.247676\n",
      "2023-12-04 20:56:59,645 INFO     Valid HITS@3 at step 90000: 0.379612\n",
      "2023-12-04 20:56:59,646 INFO     Valid HITS@10 at step 90000: 0.535329\n",
      "2023-12-04 20:57:10,974 INFO     Training average positive_sample_loss at step 90100: 0.183000\n",
      "2023-12-04 20:57:10,975 INFO     Training average negative_sample_loss at step 90100: 0.166458\n",
      "2023-12-04 20:57:10,975 INFO     Training average loss at step 90100: 0.174729\n",
      "2023-12-04 20:57:21,339 INFO     Training average positive_sample_loss at step 90200: 0.184450\n",
      "2023-12-04 20:57:21,339 INFO     Training average negative_sample_loss at step 90200: 0.166285\n",
      "2023-12-04 20:57:21,340 INFO     Training average loss at step 90200: 0.175367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:57:31,078 INFO     Training average positive_sample_loss at step 90300: 0.184823\n",
      "2023-12-04 20:57:31,079 INFO     Training average negative_sample_loss at step 90300: 0.167734\n",
      "2023-12-04 20:57:31,079 INFO     Training average loss at step 90300: 0.176278\n",
      "2023-12-04 20:57:42,832 INFO     Training average positive_sample_loss at step 90400: 0.185831\n",
      "2023-12-04 20:57:42,832 INFO     Training average negative_sample_loss at step 90400: 0.166907\n",
      "2023-12-04 20:57:42,832 INFO     Training average loss at step 90400: 0.176369\n",
      "2023-12-04 20:57:52,341 INFO     Training average positive_sample_loss at step 90500: 0.183834\n",
      "2023-12-04 20:57:52,341 INFO     Training average negative_sample_loss at step 90500: 0.166896\n",
      "2023-12-04 20:57:52,341 INFO     Training average loss at step 90500: 0.175365\n",
      "2023-12-04 20:57:57,833 INFO     Training average positive_sample_loss at step 90600: 0.183566\n",
      "2023-12-04 20:57:57,833 INFO     Training average negative_sample_loss at step 90600: 0.167368\n",
      "2023-12-04 20:57:57,833 INFO     Training average loss at step 90600: 0.175467\n",
      "2023-12-04 20:58:03,745 INFO     Training average positive_sample_loss at step 90700: 0.183422\n",
      "2023-12-04 20:58:03,745 INFO     Training average negative_sample_loss at step 90700: 0.166405\n",
      "2023-12-04 20:58:03,745 INFO     Training average loss at step 90700: 0.174914\n",
      "2023-12-04 20:58:13,417 INFO     Training average positive_sample_loss at step 90800: 0.185493\n",
      "2023-12-04 20:58:13,418 INFO     Training average negative_sample_loss at step 90800: 0.166390\n",
      "2023-12-04 20:58:13,418 INFO     Training average loss at step 90800: 0.175941\n",
      "2023-12-04 20:58:21,751 INFO     Training average positive_sample_loss at step 90900: 0.184866\n",
      "2023-12-04 20:58:21,752 INFO     Training average negative_sample_loss at step 90900: 0.166096\n",
      "2023-12-04 20:58:21,752 INFO     Training average loss at step 90900: 0.175481\n",
      "2023-12-04 20:58:31,082 INFO     Training average positive_sample_loss at step 91000: 0.184683\n",
      "2023-12-04 20:58:31,082 INFO     Training average negative_sample_loss at step 91000: 0.166860\n",
      "2023-12-04 20:58:31,082 INFO     Training average loss at step 91000: 0.175772\n",
      "2023-12-04 20:58:39,307 INFO     Training average positive_sample_loss at step 91100: 0.182880\n",
      "2023-12-04 20:58:39,307 INFO     Training average negative_sample_loss at step 91100: 0.166630\n",
      "2023-12-04 20:58:39,307 INFO     Training average loss at step 91100: 0.174755\n",
      "2023-12-04 20:58:47,837 INFO     Training average positive_sample_loss at step 91200: 0.184141\n",
      "2023-12-04 20:58:47,837 INFO     Training average negative_sample_loss at step 91200: 0.166094\n",
      "2023-12-04 20:58:47,837 INFO     Training average loss at step 91200: 0.175117\n",
      "2023-12-04 20:58:56,434 INFO     Training average positive_sample_loss at step 91300: 0.184703\n",
      "2023-12-04 20:58:56,435 INFO     Training average negative_sample_loss at step 91300: 0.166696\n",
      "2023-12-04 20:58:56,435 INFO     Training average loss at step 91300: 0.175699\n",
      "2023-12-04 20:59:05,106 INFO     Training average positive_sample_loss at step 91400: 0.184790\n",
      "2023-12-04 20:59:05,106 INFO     Training average negative_sample_loss at step 91400: 0.166038\n",
      "2023-12-04 20:59:05,106 INFO     Training average loss at step 91400: 0.175414\n",
      "2023-12-04 20:59:13,340 INFO     Training average positive_sample_loss at step 91500: 0.185313\n",
      "2023-12-04 20:59:13,341 INFO     Training average negative_sample_loss at step 91500: 0.167036\n",
      "2023-12-04 20:59:13,341 INFO     Training average loss at step 91500: 0.176175\n",
      "2023-12-04 20:59:22,549 INFO     Training average positive_sample_loss at step 91600: 0.181977\n",
      "2023-12-04 20:59:22,549 INFO     Training average negative_sample_loss at step 91600: 0.166920\n",
      "2023-12-04 20:59:22,549 INFO     Training average loss at step 91600: 0.174449\n",
      "2023-12-04 20:59:31,388 INFO     Training average positive_sample_loss at step 91700: 0.184020\n",
      "2023-12-04 20:59:31,388 INFO     Training average negative_sample_loss at step 91700: 0.166426\n",
      "2023-12-04 20:59:31,388 INFO     Training average loss at step 91700: 0.175223\n",
      "2023-12-04 20:59:40,065 INFO     Training average positive_sample_loss at step 91800: 0.184346\n",
      "2023-12-04 20:59:40,065 INFO     Training average negative_sample_loss at step 91800: 0.166069\n",
      "2023-12-04 20:59:40,065 INFO     Training average loss at step 91800: 0.175208\n",
      "2023-12-04 20:59:48,950 INFO     Training average positive_sample_loss at step 91900: 0.184825\n",
      "2023-12-04 20:59:48,950 INFO     Training average negative_sample_loss at step 91900: 0.166988\n",
      "2023-12-04 20:59:48,950 INFO     Training average loss at step 91900: 0.175907\n",
      "2023-12-04 20:59:57,983 INFO     Training average positive_sample_loss at step 92000: 0.185472\n",
      "2023-12-04 20:59:57,983 INFO     Training average negative_sample_loss at step 92000: 0.166633\n",
      "2023-12-04 20:59:57,983 INFO     Training average loss at step 92000: 0.176053\n",
      "2023-12-04 21:00:07,279 INFO     Training average positive_sample_loss at step 92100: 0.184141\n",
      "2023-12-04 21:00:07,279 INFO     Training average negative_sample_loss at step 92100: 0.166838\n",
      "2023-12-04 21:00:07,279 INFO     Training average loss at step 92100: 0.175490\n",
      "2023-12-04 21:00:13,444 INFO     Training average positive_sample_loss at step 92200: 0.182970\n",
      "2023-12-04 21:00:13,444 INFO     Training average negative_sample_loss at step 92200: 0.166522\n",
      "2023-12-04 21:00:13,444 INFO     Training average loss at step 92200: 0.174746\n",
      "2023-12-04 21:00:18,750 INFO     Training average positive_sample_loss at step 92300: 0.184122\n",
      "2023-12-04 21:00:18,751 INFO     Training average negative_sample_loss at step 92300: 0.166520\n",
      "2023-12-04 21:00:18,751 INFO     Training average loss at step 92300: 0.175321\n",
      "2023-12-04 21:00:24,092 INFO     Training average positive_sample_loss at step 92400: 0.184633\n",
      "2023-12-04 21:00:24,093 INFO     Training average negative_sample_loss at step 92400: 0.166998\n",
      "2023-12-04 21:00:24,093 INFO     Training average loss at step 92400: 0.175816\n",
      "2023-12-04 21:00:29,354 INFO     Training average positive_sample_loss at step 92500: 0.185373\n",
      "2023-12-04 21:00:29,355 INFO     Training average negative_sample_loss at step 92500: 0.166205\n",
      "2023-12-04 21:00:29,355 INFO     Training average loss at step 92500: 0.175789\n",
      "2023-12-04 21:00:35,392 INFO     Training average positive_sample_loss at step 92600: 0.184838\n",
      "2023-12-04 21:00:35,392 INFO     Training average negative_sample_loss at step 92600: 0.166870\n",
      "2023-12-04 21:00:35,392 INFO     Training average loss at step 92600: 0.175854\n",
      "2023-12-04 21:00:40,655 INFO     Training average positive_sample_loss at step 92700: 0.182572\n",
      "2023-12-04 21:00:40,655 INFO     Training average negative_sample_loss at step 92700: 0.166352\n",
      "2023-12-04 21:00:40,655 INFO     Training average loss at step 92700: 0.174462\n",
      "2023-12-04 21:00:45,938 INFO     Training average positive_sample_loss at step 92800: 0.183859\n",
      "2023-12-04 21:00:45,938 INFO     Training average negative_sample_loss at step 92800: 0.167632\n",
      "2023-12-04 21:00:45,938 INFO     Training average loss at step 92800: 0.175746\n",
      "2023-12-04 21:00:51,259 INFO     Training average positive_sample_loss at step 92900: 0.185374\n",
      "2023-12-04 21:00:51,259 INFO     Training average negative_sample_loss at step 92900: 0.167934\n",
      "2023-12-04 21:00:51,259 INFO     Training average loss at step 92900: 0.176654\n",
      "2023-12-04 21:00:56,545 INFO     Training average positive_sample_loss at step 93000: 0.185308\n",
      "2023-12-04 21:00:56,545 INFO     Training average negative_sample_loss at step 93000: 0.165623\n",
      "2023-12-04 21:00:56,545 INFO     Training average loss at step 93000: 0.175466\n",
      "2023-12-04 21:01:02,218 INFO     Training average positive_sample_loss at step 93100: 0.184962\n",
      "2023-12-04 21:01:02,219 INFO     Training average negative_sample_loss at step 93100: 0.165988\n",
      "2023-12-04 21:01:02,219 INFO     Training average loss at step 93100: 0.175475\n",
      "2023-12-04 21:01:07,856 INFO     Training average positive_sample_loss at step 93200: 0.182165\n",
      "2023-12-04 21:01:07,856 INFO     Training average negative_sample_loss at step 93200: 0.166469\n",
      "2023-12-04 21:01:07,856 INFO     Training average loss at step 93200: 0.174317\n",
      "2023-12-04 21:01:13,082 INFO     Training average positive_sample_loss at step 93300: 0.183720\n",
      "2023-12-04 21:01:13,082 INFO     Training average negative_sample_loss at step 93300: 0.167674\n",
      "2023-12-04 21:01:13,082 INFO     Training average loss at step 93300: 0.175697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 21:01:18,320 INFO     Training average positive_sample_loss at step 93400: 0.184692\n",
      "2023-12-04 21:01:18,320 INFO     Training average negative_sample_loss at step 93400: 0.165881\n",
      "2023-12-04 21:01:18,321 INFO     Training average loss at step 93400: 0.175286\n",
      "2023-12-04 21:01:23,568 INFO     Training average positive_sample_loss at step 93500: 0.184811\n",
      "2023-12-04 21:01:23,569 INFO     Training average negative_sample_loss at step 93500: 0.166666\n",
      "2023-12-04 21:01:23,569 INFO     Training average loss at step 93500: 0.175739\n",
      "2023-12-04 21:01:28,838 INFO     Training average positive_sample_loss at step 93600: 0.185992\n",
      "2023-12-04 21:01:28,838 INFO     Training average negative_sample_loss at step 93600: 0.166392\n",
      "2023-12-04 21:01:28,838 INFO     Training average loss at step 93600: 0.176192\n",
      "2023-12-04 21:01:34,807 INFO     Training average positive_sample_loss at step 93700: 0.184016\n",
      "2023-12-04 21:01:34,807 INFO     Training average negative_sample_loss at step 93700: 0.166425\n",
      "2023-12-04 21:01:34,807 INFO     Training average loss at step 93700: 0.175220\n",
      "2023-12-04 21:01:40,051 INFO     Training average positive_sample_loss at step 93800: 0.182751\n",
      "2023-12-04 21:01:40,052 INFO     Training average negative_sample_loss at step 93800: 0.167380\n",
      "2023-12-04 21:01:40,052 INFO     Training average loss at step 93800: 0.175066\n",
      "2023-12-04 21:01:45,273 INFO     Training average positive_sample_loss at step 93900: 0.184875\n",
      "2023-12-04 21:01:45,273 INFO     Training average negative_sample_loss at step 93900: 0.167751\n",
      "2023-12-04 21:01:45,273 INFO     Training average loss at step 93900: 0.176313\n",
      "2023-12-04 21:01:50,527 INFO     Training average positive_sample_loss at step 94000: 0.183995\n",
      "2023-12-04 21:01:50,527 INFO     Training average negative_sample_loss at step 94000: 0.166029\n",
      "2023-12-04 21:01:50,527 INFO     Training average loss at step 94000: 0.175012\n",
      "2023-12-04 21:01:55,753 INFO     Training average positive_sample_loss at step 94100: 0.185413\n",
      "2023-12-04 21:01:55,754 INFO     Training average negative_sample_loss at step 94100: 0.166811\n",
      "2023-12-04 21:01:55,754 INFO     Training average loss at step 94100: 0.176112\n",
      "2023-12-04 21:02:01,756 INFO     Training average positive_sample_loss at step 94200: 0.184630\n",
      "2023-12-04 21:02:01,757 INFO     Training average negative_sample_loss at step 94200: 0.167513\n",
      "2023-12-04 21:02:01,757 INFO     Training average loss at step 94200: 0.176071\n",
      "2023-12-04 21:02:07,006 INFO     Training average positive_sample_loss at step 94300: 0.182996\n",
      "2023-12-04 21:02:07,007 INFO     Training average negative_sample_loss at step 94300: 0.165999\n",
      "2023-12-04 21:02:07,007 INFO     Training average loss at step 94300: 0.174498\n",
      "2023-12-04 21:02:12,288 INFO     Training average positive_sample_loss at step 94400: 0.183810\n",
      "2023-12-04 21:02:12,289 INFO     Training average negative_sample_loss at step 94400: 0.165677\n",
      "2023-12-04 21:02:12,289 INFO     Training average loss at step 94400: 0.174744\n",
      "2023-12-04 21:02:17,534 INFO     Training average positive_sample_loss at step 94500: 0.185404\n",
      "2023-12-04 21:02:17,534 INFO     Training average negative_sample_loss at step 94500: 0.167410\n",
      "2023-12-04 21:02:17,534 INFO     Training average loss at step 94500: 0.176407\n",
      "2023-12-04 21:02:22,782 INFO     Training average positive_sample_loss at step 94600: 0.184725\n",
      "2023-12-04 21:02:22,783 INFO     Training average negative_sample_loss at step 94600: 0.166013\n",
      "2023-12-04 21:02:22,783 INFO     Training average loss at step 94600: 0.175369\n",
      "2023-12-04 21:02:28,801 INFO     Training average positive_sample_loss at step 94700: 0.185014\n",
      "2023-12-04 21:02:28,801 INFO     Training average negative_sample_loss at step 94700: 0.166709\n",
      "2023-12-04 21:02:28,801 INFO     Training average loss at step 94700: 0.175861\n",
      "2023-12-04 21:02:34,016 INFO     Training average positive_sample_loss at step 94800: 0.182723\n",
      "2023-12-04 21:02:34,016 INFO     Training average negative_sample_loss at step 94800: 0.167732\n",
      "2023-12-04 21:02:34,016 INFO     Training average loss at step 94800: 0.175228\n",
      "2023-12-04 21:02:39,256 INFO     Training average positive_sample_loss at step 94900: 0.183192\n",
      "2023-12-04 21:02:39,256 INFO     Training average negative_sample_loss at step 94900: 0.166325\n",
      "2023-12-04 21:02:39,256 INFO     Training average loss at step 94900: 0.174758\n",
      "2023-12-04 21:02:44,481 INFO     Training average positive_sample_loss at step 95000: 0.184498\n",
      "2023-12-04 21:02:44,481 INFO     Training average negative_sample_loss at step 95000: 0.165675\n",
      "2023-12-04 21:02:44,481 INFO     Training average loss at step 95000: 0.175086\n",
      "2023-12-04 21:02:49,702 INFO     Training average positive_sample_loss at step 95100: 0.184998\n",
      "2023-12-04 21:02:49,702 INFO     Training average negative_sample_loss at step 95100: 0.167285\n",
      "2023-12-04 21:02:49,702 INFO     Training average loss at step 95100: 0.176142\n",
      "2023-12-04 21:02:54,923 INFO     Training average positive_sample_loss at step 95200: 0.185871\n",
      "2023-12-04 21:02:54,923 INFO     Training average negative_sample_loss at step 95200: 0.165991\n",
      "2023-12-04 21:02:54,923 INFO     Training average loss at step 95200: 0.175931\n",
      "2023-12-04 21:03:00,854 INFO     Training average positive_sample_loss at step 95300: 0.183921\n",
      "2023-12-04 21:03:00,854 INFO     Training average negative_sample_loss at step 95300: 0.167218\n",
      "2023-12-04 21:03:00,854 INFO     Training average loss at step 95300: 0.175569\n",
      "2023-12-04 21:03:06,066 INFO     Training average positive_sample_loss at step 95400: 0.183343\n",
      "2023-12-04 21:03:06,067 INFO     Training average negative_sample_loss at step 95400: 0.166127\n",
      "2023-12-04 21:03:06,067 INFO     Training average loss at step 95400: 0.174735\n",
      "2023-12-04 21:03:11,310 INFO     Training average positive_sample_loss at step 95500: 0.184965\n",
      "2023-12-04 21:03:11,311 INFO     Training average negative_sample_loss at step 95500: 0.166993\n",
      "2023-12-04 21:03:11,311 INFO     Training average loss at step 95500: 0.175979\n",
      "2023-12-04 21:03:16,527 INFO     Training average positive_sample_loss at step 95600: 0.184662\n",
      "2023-12-04 21:03:16,528 INFO     Training average negative_sample_loss at step 95600: 0.167163\n",
      "2023-12-04 21:03:16,528 INFO     Training average loss at step 95600: 0.175913\n",
      "2023-12-04 21:03:21,723 INFO     Training average positive_sample_loss at step 95700: 0.185345\n",
      "2023-12-04 21:03:21,723 INFO     Training average negative_sample_loss at step 95700: 0.167176\n",
      "2023-12-04 21:03:21,723 INFO     Training average loss at step 95700: 0.176260\n",
      "2023-12-04 21:03:27,711 INFO     Training average positive_sample_loss at step 95800: 0.183769\n",
      "2023-12-04 21:03:27,711 INFO     Training average negative_sample_loss at step 95800: 0.165829\n",
      "2023-12-04 21:03:27,711 INFO     Training average loss at step 95800: 0.174799\n",
      "2023-12-04 21:03:32,937 INFO     Training average positive_sample_loss at step 95900: 0.182436\n",
      "2023-12-04 21:03:32,938 INFO     Training average negative_sample_loss at step 95900: 0.166331\n",
      "2023-12-04 21:03:32,938 INFO     Training average loss at step 95900: 0.174383\n",
      "2023-12-04 21:03:38,172 INFO     Training average positive_sample_loss at step 96000: 0.183916\n",
      "2023-12-04 21:03:38,172 INFO     Training average negative_sample_loss at step 96000: 0.165679\n",
      "2023-12-04 21:03:38,172 INFO     Training average loss at step 96000: 0.174798\n",
      "2023-12-04 21:03:43,433 INFO     Training average positive_sample_loss at step 96100: 0.184956\n",
      "2023-12-04 21:03:43,433 INFO     Training average negative_sample_loss at step 96100: 0.166060\n",
      "2023-12-04 21:03:43,433 INFO     Training average loss at step 96100: 0.175508\n",
      "2023-12-04 21:03:48,648 INFO     Training average positive_sample_loss at step 96200: 0.185559\n",
      "2023-12-04 21:03:48,648 INFO     Training average negative_sample_loss at step 96200: 0.166401\n",
      "2023-12-04 21:03:48,648 INFO     Training average loss at step 96200: 0.175980\n",
      "2023-12-04 21:03:54,592 INFO     Training average positive_sample_loss at step 96300: 0.184628\n",
      "2023-12-04 21:03:54,592 INFO     Training average negative_sample_loss at step 96300: 0.167369\n",
      "2023-12-04 21:03:54,592 INFO     Training average loss at step 96300: 0.175999\n",
      "2023-12-04 21:03:59,820 INFO     Training average positive_sample_loss at step 96400: 0.182274\n",
      "2023-12-04 21:03:59,821 INFO     Training average negative_sample_loss at step 96400: 0.166443\n",
      "2023-12-04 21:03:59,821 INFO     Training average loss at step 96400: 0.174359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 21:04:05,073 INFO     Training average positive_sample_loss at step 96500: 0.184082\n",
      "2023-12-04 21:04:05,073 INFO     Training average negative_sample_loss at step 96500: 0.166481\n",
      "2023-12-04 21:04:05,073 INFO     Training average loss at step 96500: 0.175282\n",
      "2023-12-04 21:04:10,316 INFO     Training average positive_sample_loss at step 96600: 0.184613\n",
      "2023-12-04 21:04:10,317 INFO     Training average negative_sample_loss at step 96600: 0.164955\n",
      "2023-12-04 21:04:10,317 INFO     Training average loss at step 96600: 0.174784\n",
      "2023-12-04 21:04:15,577 INFO     Training average positive_sample_loss at step 96700: 0.184884\n",
      "2023-12-04 21:04:15,577 INFO     Training average negative_sample_loss at step 96700: 0.166941\n",
      "2023-12-04 21:04:15,577 INFO     Training average loss at step 96700: 0.175912\n",
      "2023-12-04 21:04:20,844 INFO     Training average positive_sample_loss at step 96800: 0.185149\n",
      "2023-12-04 21:04:20,844 INFO     Training average negative_sample_loss at step 96800: 0.167571\n",
      "2023-12-04 21:04:20,845 INFO     Training average loss at step 96800: 0.176360\n",
      "2023-12-04 21:04:26,887 INFO     Training average positive_sample_loss at step 96900: 0.183089\n",
      "2023-12-04 21:04:26,887 INFO     Training average negative_sample_loss at step 96900: 0.164950\n",
      "2023-12-04 21:04:26,887 INFO     Training average loss at step 96900: 0.174020\n",
      "2023-12-04 21:04:32,157 INFO     Training average positive_sample_loss at step 97000: 0.183647\n",
      "2023-12-04 21:04:32,158 INFO     Training average negative_sample_loss at step 97000: 0.166704\n",
      "2023-12-04 21:04:32,158 INFO     Training average loss at step 97000: 0.175176\n",
      "2023-12-04 21:04:37,439 INFO     Training average positive_sample_loss at step 97100: 0.183662\n",
      "2023-12-04 21:04:37,439 INFO     Training average negative_sample_loss at step 97100: 0.166045\n",
      "2023-12-04 21:04:37,439 INFO     Training average loss at step 97100: 0.174853\n",
      "2023-12-04 21:04:42,708 INFO     Training average positive_sample_loss at step 97200: 0.185426\n",
      "2023-12-04 21:04:42,708 INFO     Training average negative_sample_loss at step 97200: 0.166382\n",
      "2023-12-04 21:04:42,708 INFO     Training average loss at step 97200: 0.175904\n",
      "2023-12-04 21:04:47,911 INFO     Training average positive_sample_loss at step 97300: 0.184956\n",
      "2023-12-04 21:04:47,912 INFO     Training average negative_sample_loss at step 97300: 0.166001\n",
      "2023-12-04 21:04:47,912 INFO     Training average loss at step 97300: 0.175479\n",
      "2023-12-04 21:04:53,860 INFO     Training average positive_sample_loss at step 97400: 0.182940\n",
      "2023-12-04 21:04:53,860 INFO     Training average negative_sample_loss at step 97400: 0.165644\n",
      "2023-12-04 21:04:53,861 INFO     Training average loss at step 97400: 0.174292\n",
      "2023-12-04 21:04:59,077 INFO     Training average positive_sample_loss at step 97500: 0.183282\n",
      "2023-12-04 21:04:59,077 INFO     Training average negative_sample_loss at step 97500: 0.165772\n",
      "2023-12-04 21:04:59,077 INFO     Training average loss at step 97500: 0.174527\n",
      "2023-12-04 21:05:04,321 INFO     Training average positive_sample_loss at step 97600: 0.183703\n",
      "2023-12-04 21:05:04,321 INFO     Training average negative_sample_loss at step 97600: 0.166048\n",
      "2023-12-04 21:05:04,321 INFO     Training average loss at step 97600: 0.174876\n",
      "2023-12-04 21:05:09,521 INFO     Training average positive_sample_loss at step 97700: 0.184813\n",
      "2023-12-04 21:05:09,521 INFO     Training average negative_sample_loss at step 97700: 0.167100\n",
      "2023-12-04 21:05:09,521 INFO     Training average loss at step 97700: 0.175956\n",
      "2023-12-04 21:05:14,742 INFO     Training average positive_sample_loss at step 97800: 0.185353\n",
      "2023-12-04 21:05:14,742 INFO     Training average negative_sample_loss at step 97800: 0.166948\n",
      "2023-12-04 21:05:14,742 INFO     Training average loss at step 97800: 0.176151\n",
      "2023-12-04 21:05:20,690 INFO     Training average positive_sample_loss at step 97900: 0.184858\n",
      "2023-12-04 21:05:20,690 INFO     Training average negative_sample_loss at step 97900: 0.166423\n",
      "2023-12-04 21:05:20,690 INFO     Training average loss at step 97900: 0.175640\n",
      "2023-12-04 21:05:25,932 INFO     Training average positive_sample_loss at step 98000: 0.182413\n",
      "2023-12-04 21:05:25,932 INFO     Training average negative_sample_loss at step 98000: 0.165165\n",
      "2023-12-04 21:05:25,932 INFO     Training average loss at step 98000: 0.173789\n",
      "2023-12-04 21:05:31,175 INFO     Training average positive_sample_loss at step 98100: 0.184129\n",
      "2023-12-04 21:05:31,175 INFO     Training average negative_sample_loss at step 98100: 0.166056\n",
      "2023-12-04 21:05:31,175 INFO     Training average loss at step 98100: 0.175092\n",
      "2023-12-04 21:05:36,409 INFO     Training average positive_sample_loss at step 98200: 0.184031\n",
      "2023-12-04 21:05:36,410 INFO     Training average negative_sample_loss at step 98200: 0.166328\n",
      "2023-12-04 21:05:36,410 INFO     Training average loss at step 98200: 0.175180\n",
      "2023-12-04 21:05:41,626 INFO     Training average positive_sample_loss at step 98300: 0.184852\n",
      "2023-12-04 21:05:41,626 INFO     Training average negative_sample_loss at step 98300: 0.165886\n",
      "2023-12-04 21:05:41,626 INFO     Training average loss at step 98300: 0.175369\n",
      "2023-12-04 21:05:46,859 INFO     Training average positive_sample_loss at step 98400: 0.185315\n",
      "2023-12-04 21:05:46,859 INFO     Training average negative_sample_loss at step 98400: 0.167039\n",
      "2023-12-04 21:05:46,859 INFO     Training average loss at step 98400: 0.176177\n",
      "2023-12-04 21:05:52,792 INFO     Training average positive_sample_loss at step 98500: 0.182245\n",
      "2023-12-04 21:05:52,793 INFO     Training average negative_sample_loss at step 98500: 0.166336\n",
      "2023-12-04 21:05:52,793 INFO     Training average loss at step 98500: 0.174290\n",
      "2023-12-04 21:05:58,029 INFO     Training average positive_sample_loss at step 98600: 0.183373\n",
      "2023-12-04 21:05:58,029 INFO     Training average negative_sample_loss at step 98600: 0.166074\n",
      "2023-12-04 21:05:58,029 INFO     Training average loss at step 98600: 0.174724\n",
      "2023-12-04 21:06:03,269 INFO     Training average positive_sample_loss at step 98700: 0.184719\n",
      "2023-12-04 21:06:03,269 INFO     Training average negative_sample_loss at step 98700: 0.166365\n",
      "2023-12-04 21:06:03,269 INFO     Training average loss at step 98700: 0.175542\n",
      "2023-12-04 21:06:08,591 INFO     Training average positive_sample_loss at step 98800: 0.184719\n",
      "2023-12-04 21:06:08,592 INFO     Training average negative_sample_loss at step 98800: 0.165948\n",
      "2023-12-04 21:06:08,592 INFO     Training average loss at step 98800: 0.175334\n",
      "2023-12-04 21:06:13,827 INFO     Training average positive_sample_loss at step 98900: 0.185534\n",
      "2023-12-04 21:06:13,827 INFO     Training average negative_sample_loss at step 98900: 0.167340\n",
      "2023-12-04 21:06:13,827 INFO     Training average loss at step 98900: 0.176437\n",
      "2023-12-04 21:06:19,811 INFO     Training average positive_sample_loss at step 99000: 0.184026\n",
      "2023-12-04 21:06:19,812 INFO     Training average negative_sample_loss at step 99000: 0.167334\n",
      "2023-12-04 21:06:19,812 INFO     Training average loss at step 99000: 0.175680\n",
      "2023-12-04 21:06:25,037 INFO     Training average positive_sample_loss at step 99100: 0.182484\n",
      "2023-12-04 21:06:25,037 INFO     Training average negative_sample_loss at step 99100: 0.164671\n",
      "2023-12-04 21:06:25,037 INFO     Training average loss at step 99100: 0.173578\n",
      "2023-12-04 21:06:30,282 INFO     Training average positive_sample_loss at step 99200: 0.183773\n",
      "2023-12-04 21:06:30,282 INFO     Training average negative_sample_loss at step 99200: 0.165711\n",
      "2023-12-04 21:06:30,282 INFO     Training average loss at step 99200: 0.174742\n",
      "2023-12-04 21:06:35,513 INFO     Training average positive_sample_loss at step 99300: 0.185499\n",
      "2023-12-04 21:06:35,514 INFO     Training average negative_sample_loss at step 99300: 0.168924\n",
      "2023-12-04 21:06:35,514 INFO     Training average loss at step 99300: 0.177212\n",
      "2023-12-04 21:06:40,781 INFO     Training average positive_sample_loss at step 99400: 0.185247\n",
      "2023-12-04 21:06:40,782 INFO     Training average negative_sample_loss at step 99400: 0.166868\n",
      "2023-12-04 21:06:40,782 INFO     Training average loss at step 99400: 0.176057\n",
      "2023-12-04 21:06:46,899 INFO     Training average positive_sample_loss at step 99500: 0.184349\n",
      "2023-12-04 21:06:46,899 INFO     Training average negative_sample_loss at step 99500: 0.165486\n",
      "2023-12-04 21:06:46,899 INFO     Training average loss at step 99500: 0.174917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 21:06:52,111 INFO     Training average positive_sample_loss at step 99600: 0.182138\n",
      "2023-12-04 21:06:52,111 INFO     Training average negative_sample_loss at step 99600: 0.166452\n",
      "2023-12-04 21:06:52,111 INFO     Training average loss at step 99600: 0.174295\n",
      "2023-12-04 21:06:57,381 INFO     Training average positive_sample_loss at step 99700: 0.183697\n",
      "2023-12-04 21:06:57,381 INFO     Training average negative_sample_loss at step 99700: 0.165887\n",
      "2023-12-04 21:06:57,381 INFO     Training average loss at step 99700: 0.174792\n",
      "2023-12-04 21:07:02,648 INFO     Training average positive_sample_loss at step 99800: 0.184833\n",
      "2023-12-04 21:07:02,649 INFO     Training average negative_sample_loss at step 99800: 0.167017\n",
      "2023-12-04 21:07:02,649 INFO     Training average loss at step 99800: 0.175925\n",
      "2023-12-04 21:07:07,904 INFO     Training average positive_sample_loss at step 99900: 0.185247\n",
      "2023-12-04 21:07:07,904 INFO     Training average negative_sample_loss at step 99900: 0.168207\n",
      "2023-12-04 21:07:07,904 INFO     Training average loss at step 99900: 0.176727\n",
      "2023-12-04 21:07:23,210 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-04 21:07:23,771 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-04 21:07:51,635 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-04 21:08:16,473 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-04 21:08:20,776 INFO     Valid MRR at step 99999: 0.343537\n",
      "2023-12-04 21:08:20,777 INFO     Valid MR at step 99999: 164.081950\n",
      "2023-12-04 21:08:20,777 INFO     Valid HITS@1 at step 99999: 0.247819\n",
      "2023-12-04 21:08:20,777 INFO     Valid HITS@3 at step 99999: 0.379070\n",
      "2023-12-04 21:08:20,777 INFO     Valid HITS@10 at step 99999: 0.535757\n",
      "2023-12-04 21:08:20,777 INFO     Evaluating on Test Dataset...\n",
      "2023-12-04 21:08:21,463 INFO     Evaluating the model... (0/2560)\n",
      "2023-12-04 21:08:49,355 INFO     Evaluating the model... (1000/2560)\n",
      "2023-12-04 21:09:14,563 INFO     Evaluating the model... (2000/2560)\n",
      "2023-12-04 21:09:27,036 INFO     Test MRR at step 99999: 0.336177\n",
      "2023-12-04 21:09:27,037 INFO     Test MR at step 99999: 177.981115\n",
      "2023-12-04 21:09:27,037 INFO     Test HITS@1 at step 99999: 0.239153\n",
      "2023-12-04 21:09:27,037 INFO     Test HITS@3 at step 99999: 0.373473\n",
      "2023-12-04 21:09:27,037 INFO     Test HITS@10 at step 99999: 0.532395\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE FB15k-237 0 0 1024 256 1000 9.0 1.0 0.00005 100000 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione: 194 minuti e 49 secondi\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "minutes, seconds = divmod(execution_time, 60)\n",
    "print(f\"Tempo di esecuzione: {int(minutes)} minuti e {int(seconds)} secondi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con la variante NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-10 08:37:41,472 INFO     Model: RotatE\n",
      "2023-12-10 08:37:41,473 INFO     Data Path: data/FB15k-237\n",
      "2023-12-10 08:37:41,473 INFO     #entity: 14541\n",
      "2023-12-10 08:37:41,473 INFO     #relation: 237\n",
      "2023-12-10 08:37:41,797 INFO     #train: 272115\n",
      "2023-12-10 08:37:41,811 INFO     #valid: 17535\n",
      "2023-12-10 08:37:41,828 INFO     #test: 20466\n",
      "2023-12-10 08:37:41,989 INFO     Model Parameter Configuration:\n",
      "2023-12-10 08:37:41,990 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-10 08:37:41,990 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-10 08:37:41,990 INFO     Parameter entity_embedding: torch.Size([14541, 2000]), require_grad = True\n",
      "2023-12-10 08:37:41,990 INFO     Parameter relation_embedding: torch.Size([237, 1000]), require_grad = True\n",
      "2023-12-10 08:37:44,754 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-10 08:37:44,754 INFO     Start Training...\n",
      "2023-12-10 08:37:44,754 INFO     init_step = 0\n",
      "2023-12-10 08:37:44,754 INFO     batch_size = 1024\n",
      "2023-12-10 08:37:44,754 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-10 08:37:44,754 INFO     hidden_dim = 1000\n",
      "2023-12-10 08:37:44,754 INFO     gamma = 9.000000\n",
      "2023-12-10 08:37:44,754 INFO     negative_adversarial_sampling = True\n",
      "2023-12-10 08:37:44,754 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-10 08:37:44,754 INFO     learning_rate = 0\n",
      "2023-12-10 08:37:57,513 INFO     Training average positive_sample_loss at step 0: 2.556710\n",
      "2023-12-10 08:37:57,514 INFO     Training average negative_sample_loss at step 0: 0.083509\n",
      "2023-12-10 08:37:57,514 INFO     Training average loss at step 0: 1.320109\n",
      "2023-12-10 08:37:57,514 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 08:37:58,373 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 08:38:49,377 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 08:39:41,949 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 08:39:52,221 INFO     Valid MRR at step 0: 0.004929\n",
      "2023-12-10 08:39:52,221 INFO     Valid MR at step 0: 6866.397092\n",
      "2023-12-10 08:39:52,221 INFO     Valid HITS@1 at step 0: 0.004135\n",
      "2023-12-10 08:39:52,221 INFO     Valid HITS@3 at step 0: 0.004391\n",
      "2023-12-10 08:39:52,221 INFO     Valid HITS@10 at step 0: 0.005104\n",
      "2023-12-10 08:40:37,575 INFO     Training average positive_sample_loss at step 100: 2.071806\n",
      "2023-12-10 08:40:37,575 INFO     Training average negative_sample_loss at step 100: 0.202395\n",
      "2023-12-10 08:40:37,575 INFO     Training average loss at step 100: 1.137101\n",
      "2023-12-10 08:41:22,012 INFO     Training average positive_sample_loss at step 200: 1.186177\n",
      "2023-12-10 08:41:22,013 INFO     Training average negative_sample_loss at step 200: 0.450070\n",
      "2023-12-10 08:41:22,013 INFO     Training average loss at step 200: 0.818124\n",
      "2023-12-10 08:42:05,138 INFO     Training average positive_sample_loss at step 300: 0.880933\n",
      "2023-12-10 08:42:05,138 INFO     Training average negative_sample_loss at step 300: 0.563373\n",
      "2023-12-10 08:42:05,138 INFO     Training average loss at step 300: 0.722153\n",
      "2023-12-10 08:42:47,912 INFO     Training average positive_sample_loss at step 400: 0.763662\n",
      "2023-12-10 08:42:47,913 INFO     Training average negative_sample_loss at step 400: 0.603713\n",
      "2023-12-10 08:42:47,913 INFO     Training average loss at step 400: 0.683688\n",
      "2023-12-10 08:43:31,339 INFO     Training average positive_sample_loss at step 500: 0.704086\n",
      "2023-12-10 08:43:31,339 INFO     Training average negative_sample_loss at step 500: 0.612472\n",
      "2023-12-10 08:43:31,339 INFO     Training average loss at step 500: 0.658279\n",
      "2023-12-10 08:44:23,339 INFO     Training average positive_sample_loss at step 600: 0.625962\n",
      "2023-12-10 08:44:23,339 INFO     Training average negative_sample_loss at step 600: 0.596569\n",
      "2023-12-10 08:44:23,340 INFO     Training average loss at step 600: 0.611265\n",
      "2023-12-10 08:45:07,081 INFO     Training average positive_sample_loss at step 700: 0.609822\n",
      "2023-12-10 08:45:07,082 INFO     Training average negative_sample_loss at step 700: 0.562276\n",
      "2023-12-10 08:45:07,082 INFO     Training average loss at step 700: 0.586049\n",
      "2023-12-10 08:45:51,094 INFO     Training average positive_sample_loss at step 800: 0.599045\n",
      "2023-12-10 08:45:51,094 INFO     Training average negative_sample_loss at step 800: 0.545667\n",
      "2023-12-10 08:45:51,095 INFO     Training average loss at step 800: 0.572356\n",
      "2023-12-10 08:46:34,688 INFO     Training average positive_sample_loss at step 900: 0.582961\n",
      "2023-12-10 08:46:34,688 INFO     Training average negative_sample_loss at step 900: 0.529306\n",
      "2023-12-10 08:46:34,688 INFO     Training average loss at step 900: 0.556133\n",
      "2023-12-10 08:47:18,569 INFO     Training average positive_sample_loss at step 1000: 0.565467\n",
      "2023-12-10 08:47:18,569 INFO     Training average negative_sample_loss at step 1000: 0.511456\n",
      "2023-12-10 08:47:18,569 INFO     Training average loss at step 1000: 0.538462\n",
      "2023-12-10 08:48:10,701 INFO     Training average positive_sample_loss at step 1100: 0.527050\n",
      "2023-12-10 08:48:10,702 INFO     Training average negative_sample_loss at step 1100: 0.488328\n",
      "2023-12-10 08:48:10,702 INFO     Training average loss at step 1100: 0.507689\n",
      "2023-12-10 08:48:53,956 INFO     Training average positive_sample_loss at step 1200: 0.498955\n",
      "2023-12-10 08:48:53,956 INFO     Training average negative_sample_loss at step 1200: 0.448613\n",
      "2023-12-10 08:48:53,956 INFO     Training average loss at step 1200: 0.473784\n",
      "2023-12-10 08:49:38,082 INFO     Training average positive_sample_loss at step 1300: 0.492764\n",
      "2023-12-10 08:49:38,083 INFO     Training average negative_sample_loss at step 1300: 0.429085\n",
      "2023-12-10 08:49:38,083 INFO     Training average loss at step 1300: 0.460924\n",
      "2023-12-10 08:50:20,330 INFO     Training average positive_sample_loss at step 1400: 0.480183\n",
      "2023-12-10 08:50:20,331 INFO     Training average negative_sample_loss at step 1400: 0.414814\n",
      "2023-12-10 08:50:20,331 INFO     Training average loss at step 1400: 0.447498\n",
      "2023-12-10 08:51:04,195 INFO     Training average positive_sample_loss at step 1500: 0.465189\n",
      "2023-12-10 08:51:04,195 INFO     Training average negative_sample_loss at step 1500: 0.399782\n",
      "2023-12-10 08:51:04,195 INFO     Training average loss at step 1500: 0.432486\n",
      "2023-12-10 08:51:54,320 INFO     Training average positive_sample_loss at step 1600: 0.447873\n",
      "2023-12-10 08:51:54,320 INFO     Training average negative_sample_loss at step 1600: 0.386333\n",
      "2023-12-10 08:51:54,320 INFO     Training average loss at step 1600: 0.417103\n",
      "2023-12-10 08:52:37,801 INFO     Training average positive_sample_loss at step 1700: 0.401739\n",
      "2023-12-10 08:52:37,801 INFO     Training average negative_sample_loss at step 1700: 0.356888\n",
      "2023-12-10 08:52:37,801 INFO     Training average loss at step 1700: 0.379314\n",
      "2023-12-10 08:53:20,090 INFO     Training average positive_sample_loss at step 1800: 0.403481\n",
      "2023-12-10 08:53:20,091 INFO     Training average negative_sample_loss at step 1800: 0.339008\n",
      "2023-12-10 08:53:20,091 INFO     Training average loss at step 1800: 0.371244\n",
      "2023-12-10 08:54:02,410 INFO     Training average positive_sample_loss at step 1900: 0.392078\n",
      "2023-12-10 08:54:02,410 INFO     Training average negative_sample_loss at step 1900: 0.328983\n",
      "2023-12-10 08:54:02,410 INFO     Training average loss at step 1900: 0.360531\n",
      "2023-12-10 08:54:47,398 INFO     Training average positive_sample_loss at step 2000: 0.383430\n",
      "2023-12-10 08:54:47,398 INFO     Training average negative_sample_loss at step 2000: 0.319774\n",
      "2023-12-10 08:54:47,398 INFO     Training average loss at step 2000: 0.351602\n",
      "2023-12-10 08:55:31,330 INFO     Training average positive_sample_loss at step 2100: 0.370178\n",
      "2023-12-10 08:55:31,330 INFO     Training average negative_sample_loss at step 2100: 0.311466\n",
      "2023-12-10 08:55:31,330 INFO     Training average loss at step 2100: 0.340822\n",
      "2023-12-10 08:56:23,915 INFO     Training average positive_sample_loss at step 2200: 0.334942\n",
      "2023-12-10 08:56:23,916 INFO     Training average negative_sample_loss at step 2200: 0.295619\n",
      "2023-12-10 08:56:23,916 INFO     Training average loss at step 2200: 0.315280\n",
      "2023-12-10 08:57:06,324 INFO     Training average positive_sample_loss at step 2300: 0.330533\n",
      "2023-12-10 08:57:06,325 INFO     Training average negative_sample_loss at step 2300: 0.279065\n",
      "2023-12-10 08:57:06,325 INFO     Training average loss at step 2300: 0.304799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 08:57:49,221 INFO     Training average positive_sample_loss at step 2400: 0.326913\n",
      "2023-12-10 08:57:49,221 INFO     Training average negative_sample_loss at step 2400: 0.274029\n",
      "2023-12-10 08:57:49,221 INFO     Training average loss at step 2400: 0.300471\n",
      "2023-12-10 08:58:31,977 INFO     Training average positive_sample_loss at step 2500: 0.319524\n",
      "2023-12-10 08:58:31,978 INFO     Training average negative_sample_loss at step 2500: 0.269618\n",
      "2023-12-10 08:58:31,978 INFO     Training average loss at step 2500: 0.294571\n",
      "2023-12-10 08:59:15,982 INFO     Training average positive_sample_loss at step 2600: 0.312035\n",
      "2023-12-10 08:59:15,982 INFO     Training average negative_sample_loss at step 2600: 0.265609\n",
      "2023-12-10 08:59:15,982 INFO     Training average loss at step 2600: 0.288822\n",
      "2023-12-10 09:00:02,899 INFO     Training average positive_sample_loss at step 2700: 0.293592\n",
      "2023-12-10 09:00:02,900 INFO     Training average negative_sample_loss at step 2700: 0.260368\n",
      "2023-12-10 09:00:02,900 INFO     Training average loss at step 2700: 0.276980\n",
      "2023-12-10 09:00:45,914 INFO     Training average positive_sample_loss at step 2800: 0.281676\n",
      "2023-12-10 09:00:45,914 INFO     Training average negative_sample_loss at step 2800: 0.246789\n",
      "2023-12-10 09:00:45,915 INFO     Training average loss at step 2800: 0.264232\n",
      "2023-12-10 09:01:30,739 INFO     Training average positive_sample_loss at step 2900: 0.281866\n",
      "2023-12-10 09:01:30,740 INFO     Training average negative_sample_loss at step 2900: 0.242938\n",
      "2023-12-10 09:01:30,740 INFO     Training average loss at step 2900: 0.262402\n",
      "2023-12-10 09:02:14,635 INFO     Training average positive_sample_loss at step 3000: 0.279959\n",
      "2023-12-10 09:02:14,635 INFO     Training average negative_sample_loss at step 3000: 0.242432\n",
      "2023-12-10 09:02:14,635 INFO     Training average loss at step 3000: 0.261195\n",
      "2023-12-10 09:02:59,136 INFO     Training average positive_sample_loss at step 3100: 0.276266\n",
      "2023-12-10 09:02:59,136 INFO     Training average negative_sample_loss at step 3100: 0.241598\n",
      "2023-12-10 09:02:59,136 INFO     Training average loss at step 3100: 0.258932\n",
      "2023-12-10 09:03:50,269 INFO     Training average positive_sample_loss at step 3200: 0.270369\n",
      "2023-12-10 09:03:50,269 INFO     Training average negative_sample_loss at step 3200: 0.240488\n",
      "2023-12-10 09:03:50,269 INFO     Training average loss at step 3200: 0.255429\n",
      "2023-12-10 09:04:33,470 INFO     Training average positive_sample_loss at step 3300: 0.250473\n",
      "2023-12-10 09:04:33,470 INFO     Training average negative_sample_loss at step 3300: 0.230549\n",
      "2023-12-10 09:04:33,470 INFO     Training average loss at step 3300: 0.240511\n",
      "2023-12-10 09:05:18,358 INFO     Training average positive_sample_loss at step 3400: 0.255692\n",
      "2023-12-10 09:05:18,358 INFO     Training average negative_sample_loss at step 3400: 0.226446\n",
      "2023-12-10 09:05:18,358 INFO     Training average loss at step 3400: 0.241069\n",
      "2023-12-10 09:06:02,496 INFO     Training average positive_sample_loss at step 3500: 0.256665\n",
      "2023-12-10 09:06:02,496 INFO     Training average negative_sample_loss at step 3500: 0.226792\n",
      "2023-12-10 09:06:02,496 INFO     Training average loss at step 3500: 0.241728\n",
      "2023-12-10 09:06:45,621 INFO     Training average positive_sample_loss at step 3600: 0.255882\n",
      "2023-12-10 09:06:45,621 INFO     Training average negative_sample_loss at step 3600: 0.226534\n",
      "2023-12-10 09:06:45,621 INFO     Training average loss at step 3600: 0.241208\n",
      "2023-12-10 09:07:29,613 INFO     Training average positive_sample_loss at step 3700: 0.254401\n",
      "2023-12-10 09:07:29,613 INFO     Training average negative_sample_loss at step 3700: 0.227617\n",
      "2023-12-10 09:07:29,613 INFO     Training average loss at step 3700: 0.241009\n",
      "2023-12-10 09:08:21,323 INFO     Training average positive_sample_loss at step 3800: 0.237130\n",
      "2023-12-10 09:08:21,324 INFO     Training average negative_sample_loss at step 3800: 0.223243\n",
      "2023-12-10 09:08:21,324 INFO     Training average loss at step 3800: 0.230186\n",
      "2023-12-10 09:09:06,715 INFO     Training average positive_sample_loss at step 3900: 0.240013\n",
      "2023-12-10 09:09:06,716 INFO     Training average negative_sample_loss at step 3900: 0.216656\n",
      "2023-12-10 09:09:06,716 INFO     Training average loss at step 3900: 0.228335\n",
      "2023-12-10 09:09:50,652 INFO     Training average positive_sample_loss at step 4000: 0.242649\n",
      "2023-12-10 09:09:50,653 INFO     Training average negative_sample_loss at step 4000: 0.217586\n",
      "2023-12-10 09:09:50,653 INFO     Training average loss at step 4000: 0.230117\n",
      "2023-12-10 09:10:36,070 INFO     Training average positive_sample_loss at step 4100: 0.243941\n",
      "2023-12-10 09:10:36,070 INFO     Training average negative_sample_loss at step 4100: 0.219429\n",
      "2023-12-10 09:10:36,070 INFO     Training average loss at step 4100: 0.231685\n",
      "2023-12-10 09:11:21,399 INFO     Training average positive_sample_loss at step 4200: 0.242758\n",
      "2023-12-10 09:11:21,399 INFO     Training average negative_sample_loss at step 4200: 0.218957\n",
      "2023-12-10 09:11:21,399 INFO     Training average loss at step 4200: 0.230858\n",
      "2023-12-10 09:12:10,599 INFO     Training average positive_sample_loss at step 4300: 0.232113\n",
      "2023-12-10 09:12:10,599 INFO     Training average negative_sample_loss at step 4300: 0.217906\n",
      "2023-12-10 09:12:10,599 INFO     Training average loss at step 4300: 0.225009\n",
      "2023-12-10 09:12:53,940 INFO     Training average positive_sample_loss at step 4400: 0.229316\n",
      "2023-12-10 09:12:53,941 INFO     Training average negative_sample_loss at step 4400: 0.210128\n",
      "2023-12-10 09:12:53,941 INFO     Training average loss at step 4400: 0.219722\n",
      "2023-12-10 09:13:36,980 INFO     Training average positive_sample_loss at step 4500: 0.234426\n",
      "2023-12-10 09:13:36,981 INFO     Training average negative_sample_loss at step 4500: 0.211185\n",
      "2023-12-10 09:13:36,981 INFO     Training average loss at step 4500: 0.222805\n",
      "2023-12-10 09:14:21,566 INFO     Training average positive_sample_loss at step 4600: 0.236184\n",
      "2023-12-10 09:14:21,567 INFO     Training average negative_sample_loss at step 4600: 0.212348\n",
      "2023-12-10 09:14:21,567 INFO     Training average loss at step 4600: 0.224266\n",
      "2023-12-10 09:15:05,436 INFO     Training average positive_sample_loss at step 4700: 0.235717\n",
      "2023-12-10 09:15:05,436 INFO     Training average negative_sample_loss at step 4700: 0.213688\n",
      "2023-12-10 09:15:05,436 INFO     Training average loss at step 4700: 0.224703\n",
      "2023-12-10 09:15:55,706 INFO     Training average positive_sample_loss at step 4800: 0.232106\n",
      "2023-12-10 09:15:55,706 INFO     Training average negative_sample_loss at step 4800: 0.213266\n",
      "2023-12-10 09:15:55,706 INFO     Training average loss at step 4800: 0.222686\n",
      "2023-12-10 09:16:38,562 INFO     Training average positive_sample_loss at step 4900: 0.220194\n",
      "2023-12-10 09:16:38,562 INFO     Training average negative_sample_loss at step 4900: 0.207474\n",
      "2023-12-10 09:16:38,562 INFO     Training average loss at step 4900: 0.213834\n",
      "2023-12-10 09:17:22,832 INFO     Training average positive_sample_loss at step 5000: 0.227978\n",
      "2023-12-10 09:17:22,832 INFO     Training average negative_sample_loss at step 5000: 0.205828\n",
      "2023-12-10 09:17:22,832 INFO     Training average loss at step 5000: 0.216903\n",
      "2023-12-10 09:18:07,558 INFO     Training average positive_sample_loss at step 5100: 0.229694\n",
      "2023-12-10 09:18:07,558 INFO     Training average negative_sample_loss at step 5100: 0.207402\n",
      "2023-12-10 09:18:07,558 INFO     Training average loss at step 5100: 0.218548\n",
      "2023-12-10 09:18:51,848 INFO     Training average positive_sample_loss at step 5200: 0.231479\n",
      "2023-12-10 09:18:51,848 INFO     Training average negative_sample_loss at step 5200: 0.208601\n",
      "2023-12-10 09:18:51,848 INFO     Training average loss at step 5200: 0.220040\n",
      "2023-12-10 09:19:35,651 INFO     Training average positive_sample_loss at step 5300: 0.231136\n",
      "2023-12-10 09:19:35,651 INFO     Training average negative_sample_loss at step 5300: 0.210391\n",
      "2023-12-10 09:19:35,651 INFO     Training average loss at step 5300: 0.220763\n",
      "2023-12-10 09:20:23,393 INFO     Training average positive_sample_loss at step 5400: 0.217132\n",
      "2023-12-10 09:20:23,394 INFO     Training average negative_sample_loss at step 5400: 0.205604\n",
      "2023-12-10 09:20:23,394 INFO     Training average loss at step 5400: 0.211368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 09:21:07,469 INFO     Training average positive_sample_loss at step 5500: 0.222369\n",
      "2023-12-10 09:21:07,469 INFO     Training average negative_sample_loss at step 5500: 0.202178\n",
      "2023-12-10 09:21:07,469 INFO     Training average loss at step 5500: 0.212274\n",
      "2023-12-10 09:21:51,579 INFO     Training average positive_sample_loss at step 5600: 0.226079\n",
      "2023-12-10 09:21:51,580 INFO     Training average negative_sample_loss at step 5600: 0.203431\n",
      "2023-12-10 09:21:51,580 INFO     Training average loss at step 5600: 0.214755\n",
      "2023-12-10 09:22:36,547 INFO     Training average positive_sample_loss at step 5700: 0.226758\n",
      "2023-12-10 09:22:36,548 INFO     Training average negative_sample_loss at step 5700: 0.204769\n",
      "2023-12-10 09:22:36,548 INFO     Training average loss at step 5700: 0.215764\n",
      "2023-12-10 09:23:18,681 INFO     Training average positive_sample_loss at step 5800: 0.227613\n",
      "2023-12-10 09:23:18,681 INFO     Training average negative_sample_loss at step 5800: 0.205995\n",
      "2023-12-10 09:23:18,681 INFO     Training average loss at step 5800: 0.216804\n",
      "2023-12-10 09:24:07,550 INFO     Training average positive_sample_loss at step 5900: 0.218053\n",
      "2023-12-10 09:24:07,550 INFO     Training average negative_sample_loss at step 5900: 0.204785\n",
      "2023-12-10 09:24:07,550 INFO     Training average loss at step 5900: 0.211419\n",
      "2023-12-10 09:24:51,454 INFO     Training average positive_sample_loss at step 6000: 0.217542\n",
      "2023-12-10 09:24:51,455 INFO     Training average negative_sample_loss at step 6000: 0.199469\n",
      "2023-12-10 09:24:51,455 INFO     Training average loss at step 6000: 0.208505\n",
      "2023-12-10 09:25:35,704 INFO     Training average positive_sample_loss at step 6100: 0.222535\n",
      "2023-12-10 09:25:35,705 INFO     Training average negative_sample_loss at step 6100: 0.200620\n",
      "2023-12-10 09:25:35,705 INFO     Training average loss at step 6100: 0.211578\n",
      "2023-12-10 09:26:19,133 INFO     Training average positive_sample_loss at step 6200: 0.224335\n",
      "2023-12-10 09:26:19,133 INFO     Training average negative_sample_loss at step 6200: 0.202285\n",
      "2023-12-10 09:26:19,133 INFO     Training average loss at step 6200: 0.213310\n",
      "2023-12-10 09:27:02,375 INFO     Training average positive_sample_loss at step 6300: 0.225535\n",
      "2023-12-10 09:27:02,376 INFO     Training average negative_sample_loss at step 6300: 0.203911\n",
      "2023-12-10 09:27:02,376 INFO     Training average loss at step 6300: 0.214723\n",
      "2023-12-10 09:27:54,944 INFO     Training average positive_sample_loss at step 6400: 0.221221\n",
      "2023-12-10 09:27:54,944 INFO     Training average negative_sample_loss at step 6400: 0.204406\n",
      "2023-12-10 09:27:54,944 INFO     Training average loss at step 6400: 0.212813\n",
      "2023-12-10 09:28:38,665 INFO     Training average positive_sample_loss at step 6500: 0.212437\n",
      "2023-12-10 09:28:38,666 INFO     Training average negative_sample_loss at step 6500: 0.196854\n",
      "2023-12-10 09:28:38,666 INFO     Training average loss at step 6500: 0.204645\n",
      "2023-12-10 09:29:21,417 INFO     Training average positive_sample_loss at step 6600: 0.219429\n",
      "2023-12-10 09:29:21,417 INFO     Training average negative_sample_loss at step 6600: 0.197211\n",
      "2023-12-10 09:29:21,417 INFO     Training average loss at step 6600: 0.208320\n",
      "2023-12-10 09:30:04,965 INFO     Training average positive_sample_loss at step 6700: 0.221525\n",
      "2023-12-10 09:30:04,965 INFO     Training average negative_sample_loss at step 6700: 0.199104\n",
      "2023-12-10 09:30:04,965 INFO     Training average loss at step 6700: 0.210314\n",
      "2023-12-10 09:30:48,634 INFO     Training average positive_sample_loss at step 6800: 0.223522\n",
      "2023-12-10 09:30:48,635 INFO     Training average negative_sample_loss at step 6800: 0.200832\n",
      "2023-12-10 09:30:48,635 INFO     Training average loss at step 6800: 0.212177\n",
      "2023-12-10 09:31:33,658 INFO     Training average positive_sample_loss at step 6900: 0.223196\n",
      "2023-12-10 09:31:33,658 INFO     Training average negative_sample_loss at step 6900: 0.201827\n",
      "2023-12-10 09:31:33,658 INFO     Training average loss at step 6900: 0.212512\n",
      "2023-12-10 09:32:25,411 INFO     Training average positive_sample_loss at step 7000: 0.209511\n",
      "2023-12-10 09:32:25,412 INFO     Training average negative_sample_loss at step 7000: 0.197515\n",
      "2023-12-10 09:32:25,412 INFO     Training average loss at step 7000: 0.203513\n",
      "2023-12-10 09:33:09,375 INFO     Training average positive_sample_loss at step 7100: 0.216030\n",
      "2023-12-10 09:33:09,376 INFO     Training average negative_sample_loss at step 7100: 0.194362\n",
      "2023-12-10 09:33:09,376 INFO     Training average loss at step 7100: 0.205196\n",
      "2023-12-10 09:33:52,143 INFO     Training average positive_sample_loss at step 7200: 0.220191\n",
      "2023-12-10 09:33:52,143 INFO     Training average negative_sample_loss at step 7200: 0.197566\n",
      "2023-12-10 09:33:52,143 INFO     Training average loss at step 7200: 0.208879\n",
      "2023-12-10 09:34:37,010 INFO     Training average positive_sample_loss at step 7300: 0.220471\n",
      "2023-12-10 09:34:37,011 INFO     Training average negative_sample_loss at step 7300: 0.198618\n",
      "2023-12-10 09:34:37,011 INFO     Training average loss at step 7300: 0.209545\n",
      "2023-12-10 09:35:19,205 INFO     Training average positive_sample_loss at step 7400: 0.221963\n",
      "2023-12-10 09:35:19,205 INFO     Training average negative_sample_loss at step 7400: 0.200243\n",
      "2023-12-10 09:35:19,205 INFO     Training average loss at step 7400: 0.211103\n",
      "2023-12-10 09:36:09,878 INFO     Training average positive_sample_loss at step 7500: 0.212329\n",
      "2023-12-10 09:36:09,879 INFO     Training average negative_sample_loss at step 7500: 0.199044\n",
      "2023-12-10 09:36:09,879 INFO     Training average loss at step 7500: 0.205686\n",
      "2023-12-10 09:36:53,561 INFO     Training average positive_sample_loss at step 7600: 0.213288\n",
      "2023-12-10 09:36:53,561 INFO     Training average negative_sample_loss at step 7600: 0.192855\n",
      "2023-12-10 09:36:53,561 INFO     Training average loss at step 7600: 0.203072\n",
      "2023-12-10 09:37:36,395 INFO     Training average positive_sample_loss at step 7700: 0.217772\n",
      "2023-12-10 09:37:36,396 INFO     Training average negative_sample_loss at step 7700: 0.194251\n",
      "2023-12-10 09:37:36,396 INFO     Training average loss at step 7700: 0.206012\n",
      "2023-12-10 09:38:19,770 INFO     Training average positive_sample_loss at step 7800: 0.218869\n",
      "2023-12-10 09:38:19,771 INFO     Training average negative_sample_loss at step 7800: 0.197066\n",
      "2023-12-10 09:38:19,771 INFO     Training average loss at step 7800: 0.207968\n",
      "2023-12-10 09:39:02,647 INFO     Training average positive_sample_loss at step 7900: 0.220676\n",
      "2023-12-10 09:39:02,648 INFO     Training average negative_sample_loss at step 7900: 0.198593\n",
      "2023-12-10 09:39:02,648 INFO     Training average loss at step 7900: 0.209635\n",
      "2023-12-10 09:39:51,351 INFO     Training average positive_sample_loss at step 8000: 0.216133\n",
      "2023-12-10 09:39:51,352 INFO     Training average negative_sample_loss at step 8000: 0.198231\n",
      "2023-12-10 09:39:51,352 INFO     Training average loss at step 8000: 0.207182\n",
      "2023-12-10 09:40:35,056 INFO     Training average positive_sample_loss at step 8100: 0.208698\n",
      "2023-12-10 09:40:35,057 INFO     Training average negative_sample_loss at step 8100: 0.192390\n",
      "2023-12-10 09:40:35,057 INFO     Training average loss at step 8100: 0.200544\n",
      "2023-12-10 09:41:18,706 INFO     Training average positive_sample_loss at step 8200: 0.215817\n",
      "2023-12-10 09:41:18,707 INFO     Training average negative_sample_loss at step 8200: 0.192622\n",
      "2023-12-10 09:41:18,707 INFO     Training average loss at step 8200: 0.204219\n",
      "2023-12-10 09:42:02,128 INFO     Training average positive_sample_loss at step 8300: 0.217669\n",
      "2023-12-10 09:42:02,128 INFO     Training average negative_sample_loss at step 8300: 0.194672\n",
      "2023-12-10 09:42:02,128 INFO     Training average loss at step 8300: 0.206170\n",
      "2023-12-10 09:42:45,366 INFO     Training average positive_sample_loss at step 8400: 0.217992\n",
      "2023-12-10 09:42:45,366 INFO     Training average negative_sample_loss at step 8400: 0.195090\n",
      "2023-12-10 09:42:45,366 INFO     Training average loss at step 8400: 0.206541\n",
      "2023-12-10 09:43:27,858 INFO     Training average positive_sample_loss at step 8500: 0.220187\n",
      "2023-12-10 09:43:27,858 INFO     Training average negative_sample_loss at step 8500: 0.198540\n",
      "2023-12-10 09:43:27,858 INFO     Training average loss at step 8500: 0.209364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 09:44:17,794 INFO     Training average positive_sample_loss at step 8600: 0.205817\n",
      "2023-12-10 09:44:17,794 INFO     Training average negative_sample_loss at step 8600: 0.191368\n",
      "2023-12-10 09:44:17,795 INFO     Training average loss at step 8600: 0.198592\n",
      "2023-12-10 09:45:01,641 INFO     Training average positive_sample_loss at step 8700: 0.212461\n",
      "2023-12-10 09:45:01,642 INFO     Training average negative_sample_loss at step 8700: 0.190131\n",
      "2023-12-10 09:45:01,642 INFO     Training average loss at step 8700: 0.201296\n",
      "2023-12-10 09:45:44,944 INFO     Training average positive_sample_loss at step 8800: 0.216350\n",
      "2023-12-10 09:45:44,945 INFO     Training average negative_sample_loss at step 8800: 0.193431\n",
      "2023-12-10 09:45:44,945 INFO     Training average loss at step 8800: 0.204890\n",
      "2023-12-10 09:46:27,736 INFO     Training average positive_sample_loss at step 8900: 0.218423\n",
      "2023-12-10 09:46:27,736 INFO     Training average negative_sample_loss at step 8900: 0.195911\n",
      "2023-12-10 09:46:27,736 INFO     Training average loss at step 8900: 0.207167\n",
      "2023-12-10 09:47:09,694 INFO     Training average positive_sample_loss at step 9000: 0.218116\n",
      "2023-12-10 09:47:09,695 INFO     Training average negative_sample_loss at step 9000: 0.195824\n",
      "2023-12-10 09:47:09,695 INFO     Training average loss at step 9000: 0.206970\n",
      "2023-12-10 09:48:00,307 INFO     Training average positive_sample_loss at step 9100: 0.208964\n",
      "2023-12-10 09:48:00,308 INFO     Training average negative_sample_loss at step 9100: 0.195102\n",
      "2023-12-10 09:48:00,308 INFO     Training average loss at step 9100: 0.202033\n",
      "2023-12-10 09:48:45,339 INFO     Training average positive_sample_loss at step 9200: 0.212028\n",
      "2023-12-10 09:48:45,339 INFO     Training average negative_sample_loss at step 9200: 0.190466\n",
      "2023-12-10 09:48:45,339 INFO     Training average loss at step 9200: 0.201247\n",
      "2023-12-10 09:49:29,429 INFO     Training average positive_sample_loss at step 9300: 0.214926\n",
      "2023-12-10 09:49:29,429 INFO     Training average negative_sample_loss at step 9300: 0.190957\n",
      "2023-12-10 09:49:29,430 INFO     Training average loss at step 9300: 0.202941\n",
      "2023-12-10 09:50:13,405 INFO     Training average positive_sample_loss at step 9400: 0.216444\n",
      "2023-12-10 09:50:13,405 INFO     Training average negative_sample_loss at step 9400: 0.193112\n",
      "2023-12-10 09:50:13,405 INFO     Training average loss at step 9400: 0.204778\n",
      "2023-12-10 09:50:57,546 INFO     Training average positive_sample_loss at step 9500: 0.217032\n",
      "2023-12-10 09:50:57,546 INFO     Training average negative_sample_loss at step 9500: 0.194888\n",
      "2023-12-10 09:50:57,546 INFO     Training average loss at step 9500: 0.205960\n",
      "2023-12-10 09:51:47,903 INFO     Training average positive_sample_loss at step 9600: 0.211888\n",
      "2023-12-10 09:51:47,904 INFO     Training average negative_sample_loss at step 9600: 0.193714\n",
      "2023-12-10 09:51:47,904 INFO     Training average loss at step 9600: 0.202801\n",
      "2023-12-10 09:52:31,997 INFO     Training average positive_sample_loss at step 9700: 0.207276\n",
      "2023-12-10 09:52:31,998 INFO     Training average negative_sample_loss at step 9700: 0.189177\n",
      "2023-12-10 09:52:31,998 INFO     Training average loss at step 9700: 0.198226\n",
      "2023-12-10 09:53:16,013 INFO     Training average positive_sample_loss at step 9800: 0.213095\n",
      "2023-12-10 09:53:16,014 INFO     Training average negative_sample_loss at step 9800: 0.189898\n",
      "2023-12-10 09:53:16,014 INFO     Training average loss at step 9800: 0.201497\n",
      "2023-12-10 09:53:59,143 INFO     Training average positive_sample_loss at step 9900: 0.215394\n",
      "2023-12-10 09:53:59,143 INFO     Training average negative_sample_loss at step 9900: 0.192517\n",
      "2023-12-10 09:53:59,143 INFO     Training average loss at step 9900: 0.203955\n",
      "2023-12-10 09:54:49,274 INFO     Training average positive_sample_loss at step 10000: 0.216282\n",
      "2023-12-10 09:54:49,275 INFO     Training average negative_sample_loss at step 10000: 0.193456\n",
      "2023-12-10 09:54:49,275 INFO     Training average loss at step 10000: 0.204869\n",
      "2023-12-10 09:54:49,275 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 09:54:50,008 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 09:55:21,285 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 09:55:49,863 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 09:55:55,904 INFO     Valid MRR at step 10000: 0.313629\n",
      "2023-12-10 09:55:55,904 INFO     Valid MR at step 10000: 170.307613\n",
      "2023-12-10 09:55:55,904 INFO     Valid HITS@1 at step 10000: 0.219846\n",
      "2023-12-10 09:55:55,904 INFO     Valid HITS@3 at step 10000: 0.346878\n",
      "2023-12-10 09:55:55,904 INFO     Valid HITS@10 at step 10000: 0.502880\n",
      "2023-12-10 09:56:31,425 INFO     Training average positive_sample_loss at step 10100: 0.217469\n",
      "2023-12-10 09:56:31,425 INFO     Training average negative_sample_loss at step 10100: 0.194604\n",
      "2023-12-10 09:56:31,426 INFO     Training average loss at step 10100: 0.206037\n",
      "2023-12-10 09:57:23,078 INFO     Training average positive_sample_loss at step 10200: 0.203891\n",
      "2023-12-10 09:57:23,079 INFO     Training average negative_sample_loss at step 10200: 0.189885\n",
      "2023-12-10 09:57:23,079 INFO     Training average loss at step 10200: 0.196888\n",
      "2023-12-10 09:58:05,830 INFO     Training average positive_sample_loss at step 10300: 0.211627\n",
      "2023-12-10 09:58:05,830 INFO     Training average negative_sample_loss at step 10300: 0.188313\n",
      "2023-12-10 09:58:05,830 INFO     Training average loss at step 10300: 0.199970\n",
      "2023-12-10 09:58:48,902 INFO     Training average positive_sample_loss at step 10400: 0.213530\n",
      "2023-12-10 09:58:48,902 INFO     Training average negative_sample_loss at step 10400: 0.189554\n",
      "2023-12-10 09:58:48,902 INFO     Training average loss at step 10400: 0.201542\n",
      "2023-12-10 09:59:32,227 INFO     Training average positive_sample_loss at step 10500: 0.216130\n",
      "2023-12-10 09:59:32,228 INFO     Training average negative_sample_loss at step 10500: 0.192730\n",
      "2023-12-10 09:59:32,228 INFO     Training average loss at step 10500: 0.204430\n",
      "2023-12-10 10:00:15,895 INFO     Training average positive_sample_loss at step 10600: 0.216737\n",
      "2023-12-10 10:00:15,896 INFO     Training average negative_sample_loss at step 10600: 0.193333\n",
      "2023-12-10 10:00:15,896 INFO     Training average loss at step 10600: 0.205035\n",
      "2023-12-10 10:01:03,934 INFO     Training average positive_sample_loss at step 10700: 0.207420\n",
      "2023-12-10 10:01:03,934 INFO     Training average negative_sample_loss at step 10700: 0.192060\n",
      "2023-12-10 10:01:03,934 INFO     Training average loss at step 10700: 0.199740\n",
      "2023-12-10 10:01:47,139 INFO     Training average positive_sample_loss at step 10800: 0.209518\n",
      "2023-12-10 10:01:47,139 INFO     Training average negative_sample_loss at step 10800: 0.186924\n",
      "2023-12-10 10:01:47,139 INFO     Training average loss at step 10800: 0.198221\n",
      "2023-12-10 10:02:31,005 INFO     Training average positive_sample_loss at step 10900: 0.213283\n",
      "2023-12-10 10:02:31,005 INFO     Training average negative_sample_loss at step 10900: 0.190128\n",
      "2023-12-10 10:02:31,005 INFO     Training average loss at step 10900: 0.201705\n",
      "2023-12-10 10:03:14,939 INFO     Training average positive_sample_loss at step 11000: 0.213961\n",
      "2023-12-10 10:03:14,939 INFO     Training average negative_sample_loss at step 11000: 0.190567\n",
      "2023-12-10 10:03:14,939 INFO     Training average loss at step 11000: 0.202264\n",
      "2023-12-10 10:03:57,968 INFO     Training average positive_sample_loss at step 11100: 0.215554\n",
      "2023-12-10 10:03:57,968 INFO     Training average negative_sample_loss at step 11100: 0.191872\n",
      "2023-12-10 10:03:57,968 INFO     Training average loss at step 11100: 0.203713\n",
      "2023-12-10 10:04:46,518 INFO     Training average positive_sample_loss at step 11200: 0.210421\n",
      "2023-12-10 10:04:46,519 INFO     Training average negative_sample_loss at step 11200: 0.193763\n",
      "2023-12-10 10:04:46,519 INFO     Training average loss at step 11200: 0.202092\n",
      "2023-12-10 10:05:31,139 INFO     Training average positive_sample_loss at step 11300: 0.206238\n",
      "2023-12-10 10:05:31,139 INFO     Training average negative_sample_loss at step 11300: 0.186622\n",
      "2023-12-10 10:05:31,139 INFO     Training average loss at step 11300: 0.196430\n",
      "2023-12-10 10:06:15,275 INFO     Training average positive_sample_loss at step 11400: 0.211653\n",
      "2023-12-10 10:06:15,275 INFO     Training average negative_sample_loss at step 11400: 0.187892\n",
      "2023-12-10 10:06:15,275 INFO     Training average loss at step 11400: 0.199773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 10:06:58,977 INFO     Training average positive_sample_loss at step 11500: 0.213977\n",
      "2023-12-10 10:06:58,977 INFO     Training average negative_sample_loss at step 11500: 0.189880\n",
      "2023-12-10 10:06:58,977 INFO     Training average loss at step 11500: 0.201929\n",
      "2023-12-10 10:07:41,729 INFO     Training average positive_sample_loss at step 11600: 0.214793\n",
      "2023-12-10 10:07:41,729 INFO     Training average negative_sample_loss at step 11600: 0.191957\n",
      "2023-12-10 10:07:41,729 INFO     Training average loss at step 11600: 0.203375\n",
      "2023-12-10 10:08:26,351 INFO     Training average positive_sample_loss at step 11700: 0.216458\n",
      "2023-12-10 10:08:26,352 INFO     Training average negative_sample_loss at step 11700: 0.192318\n",
      "2023-12-10 10:08:26,352 INFO     Training average loss at step 11700: 0.204388\n",
      "2023-12-10 10:09:17,667 INFO     Training average positive_sample_loss at step 11800: 0.202204\n",
      "2023-12-10 10:09:17,667 INFO     Training average negative_sample_loss at step 11800: 0.188358\n",
      "2023-12-10 10:09:17,667 INFO     Training average loss at step 11800: 0.195281\n",
      "2023-12-10 10:10:01,436 INFO     Training average positive_sample_loss at step 11900: 0.210435\n",
      "2023-12-10 10:10:01,437 INFO     Training average negative_sample_loss at step 11900: 0.185821\n",
      "2023-12-10 10:10:01,437 INFO     Training average loss at step 11900: 0.198128\n",
      "2023-12-10 10:10:44,999 INFO     Training average positive_sample_loss at step 12000: 0.213480\n",
      "2023-12-10 10:10:44,999 INFO     Training average negative_sample_loss at step 12000: 0.188309\n",
      "2023-12-10 10:10:45,000 INFO     Training average loss at step 12000: 0.200895\n",
      "2023-12-10 10:11:28,209 INFO     Training average positive_sample_loss at step 12100: 0.213265\n",
      "2023-12-10 10:11:28,209 INFO     Training average negative_sample_loss at step 12100: 0.190160\n",
      "2023-12-10 10:11:28,209 INFO     Training average loss at step 12100: 0.201712\n",
      "2023-12-10 10:12:12,105 INFO     Training average positive_sample_loss at step 12200: 0.215424\n",
      "2023-12-10 10:12:12,105 INFO     Training average negative_sample_loss at step 12200: 0.191835\n",
      "2023-12-10 10:12:12,105 INFO     Training average loss at step 12200: 0.203630\n",
      "2023-12-10 10:13:01,668 INFO     Training average positive_sample_loss at step 12300: 0.204469\n",
      "2023-12-10 10:13:01,669 INFO     Training average negative_sample_loss at step 12300: 0.189014\n",
      "2023-12-10 10:13:01,669 INFO     Training average loss at step 12300: 0.196742\n",
      "2023-12-10 10:13:45,680 INFO     Training average positive_sample_loss at step 12400: 0.208728\n",
      "2023-12-10 10:13:45,681 INFO     Training average negative_sample_loss at step 12400: 0.185579\n",
      "2023-12-10 10:13:45,681 INFO     Training average loss at step 12400: 0.197154\n",
      "2023-12-10 10:14:29,004 INFO     Training average positive_sample_loss at step 12500: 0.212477\n",
      "2023-12-10 10:14:29,004 INFO     Training average negative_sample_loss at step 12500: 0.188004\n",
      "2023-12-10 10:14:29,004 INFO     Training average loss at step 12500: 0.200241\n",
      "2023-12-10 10:15:12,097 INFO     Training average positive_sample_loss at step 12600: 0.213467\n",
      "2023-12-10 10:15:12,097 INFO     Training average negative_sample_loss at step 12600: 0.189329\n",
      "2023-12-10 10:15:12,097 INFO     Training average loss at step 12600: 0.201398\n",
      "2023-12-10 10:15:55,277 INFO     Training average positive_sample_loss at step 12700: 0.213970\n",
      "2023-12-10 10:15:55,277 INFO     Training average negative_sample_loss at step 12700: 0.190816\n",
      "2023-12-10 10:15:55,277 INFO     Training average loss at step 12700: 0.202393\n",
      "2023-12-10 10:16:49,122 INFO     Training average positive_sample_loss at step 12800: 0.209121\n",
      "2023-12-10 10:16:49,122 INFO     Training average negative_sample_loss at step 12800: 0.191565\n",
      "2023-12-10 10:16:49,122 INFO     Training average loss at step 12800: 0.200343\n",
      "2023-12-10 10:17:33,118 INFO     Training average positive_sample_loss at step 12900: 0.206317\n",
      "2023-12-10 10:17:33,119 INFO     Training average negative_sample_loss at step 12900: 0.184730\n",
      "2023-12-10 10:17:33,119 INFO     Training average loss at step 12900: 0.195524\n",
      "2023-12-10 10:18:16,387 INFO     Training average positive_sample_loss at step 13000: 0.210796\n",
      "2023-12-10 10:18:16,387 INFO     Training average negative_sample_loss at step 13000: 0.186414\n",
      "2023-12-10 10:18:16,387 INFO     Training average loss at step 13000: 0.198605\n",
      "2023-12-10 10:18:59,506 INFO     Training average positive_sample_loss at step 13100: 0.212640\n",
      "2023-12-10 10:18:59,507 INFO     Training average negative_sample_loss at step 13100: 0.188195\n",
      "2023-12-10 10:18:59,507 INFO     Training average loss at step 13100: 0.200418\n",
      "2023-12-10 10:19:42,368 INFO     Training average positive_sample_loss at step 13200: 0.213571\n",
      "2023-12-10 10:19:42,368 INFO     Training average negative_sample_loss at step 13200: 0.190237\n",
      "2023-12-10 10:19:42,368 INFO     Training average loss at step 13200: 0.201904\n",
      "2023-12-10 10:20:29,159 INFO     Training average positive_sample_loss at step 13300: 0.214448\n",
      "2023-12-10 10:20:29,159 INFO     Training average negative_sample_loss at step 13300: 0.190820\n",
      "2023-12-10 10:20:29,159 INFO     Training average loss at step 13300: 0.202634\n",
      "2023-12-10 10:21:14,128 INFO     Training average positive_sample_loss at step 13400: 0.201601\n",
      "2023-12-10 10:21:14,129 INFO     Training average negative_sample_loss at step 13400: 0.186329\n",
      "2023-12-10 10:21:14,129 INFO     Training average loss at step 13400: 0.193965\n",
      "2023-12-10 10:21:58,264 INFO     Training average positive_sample_loss at step 13500: 0.209932\n",
      "2023-12-10 10:21:58,264 INFO     Training average negative_sample_loss at step 13500: 0.184844\n",
      "2023-12-10 10:21:58,264 INFO     Training average loss at step 13500: 0.197388\n",
      "2023-12-10 10:22:41,490 INFO     Training average positive_sample_loss at step 13600: 0.212313\n",
      "2023-12-10 10:22:41,491 INFO     Training average negative_sample_loss at step 13600: 0.187652\n",
      "2023-12-10 10:22:41,491 INFO     Training average loss at step 13600: 0.199982\n",
      "2023-12-10 10:23:23,769 INFO     Training average positive_sample_loss at step 13700: 0.213649\n",
      "2023-12-10 10:23:23,769 INFO     Training average negative_sample_loss at step 13700: 0.189020\n",
      "2023-12-10 10:23:23,770 INFO     Training average loss at step 13700: 0.201335\n",
      "2023-12-10 10:24:06,889 INFO     Training average positive_sample_loss at step 13800: 0.213770\n",
      "2023-12-10 10:24:06,889 INFO     Training average negative_sample_loss at step 13800: 0.190432\n",
      "2023-12-10 10:24:06,889 INFO     Training average loss at step 13800: 0.202101\n",
      "2023-12-10 10:24:57,717 INFO     Training average positive_sample_loss at step 13900: 0.204092\n",
      "2023-12-10 10:24:57,717 INFO     Training average negative_sample_loss at step 13900: 0.187867\n",
      "2023-12-10 10:24:57,717 INFO     Training average loss at step 13900: 0.195980\n",
      "2023-12-10 10:25:41,591 INFO     Training average positive_sample_loss at step 14000: 0.208013\n",
      "2023-12-10 10:25:41,591 INFO     Training average negative_sample_loss at step 14000: 0.184400\n",
      "2023-12-10 10:25:41,591 INFO     Training average loss at step 14000: 0.196206\n",
      "2023-12-10 10:26:25,713 INFO     Training average positive_sample_loss at step 14100: 0.211700\n",
      "2023-12-10 10:26:25,713 INFO     Training average negative_sample_loss at step 14100: 0.187676\n",
      "2023-12-10 10:26:25,713 INFO     Training average loss at step 14100: 0.199688\n",
      "2023-12-10 10:27:09,024 INFO     Training average positive_sample_loss at step 14200: 0.212858\n",
      "2023-12-10 10:27:09,024 INFO     Training average negative_sample_loss at step 14200: 0.188868\n",
      "2023-12-10 10:27:09,025 INFO     Training average loss at step 14200: 0.200863\n",
      "2023-12-10 10:27:52,860 INFO     Training average positive_sample_loss at step 14300: 0.212851\n",
      "2023-12-10 10:27:52,861 INFO     Training average negative_sample_loss at step 14300: 0.188352\n",
      "2023-12-10 10:27:52,861 INFO     Training average loss at step 14300: 0.200602\n",
      "2023-12-10 10:28:42,723 INFO     Training average positive_sample_loss at step 14400: 0.206948\n",
      "2023-12-10 10:28:42,723 INFO     Training average negative_sample_loss at step 14400: 0.188287\n",
      "2023-12-10 10:28:42,723 INFO     Training average loss at step 14400: 0.197618\n",
      "2023-12-10 10:29:27,835 INFO     Training average positive_sample_loss at step 14500: 0.205534\n",
      "2023-12-10 10:29:27,836 INFO     Training average negative_sample_loss at step 14500: 0.184200\n",
      "2023-12-10 10:29:27,836 INFO     Training average loss at step 14500: 0.194867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 10:30:09,676 INFO     Training average positive_sample_loss at step 14600: 0.210064\n",
      "2023-12-10 10:30:09,676 INFO     Training average negative_sample_loss at step 14600: 0.185906\n",
      "2023-12-10 10:30:09,676 INFO     Training average loss at step 14600: 0.197985\n",
      "2023-12-10 10:30:52,469 INFO     Training average positive_sample_loss at step 14700: 0.212031\n",
      "2023-12-10 10:30:52,469 INFO     Training average negative_sample_loss at step 14700: 0.186692\n",
      "2023-12-10 10:30:52,469 INFO     Training average loss at step 14700: 0.199361\n",
      "2023-12-10 10:31:36,494 INFO     Training average positive_sample_loss at step 14800: 0.212552\n",
      "2023-12-10 10:31:36,494 INFO     Training average negative_sample_loss at step 14800: 0.188183\n",
      "2023-12-10 10:31:36,494 INFO     Training average loss at step 14800: 0.200368\n",
      "2023-12-10 10:32:26,329 INFO     Training average positive_sample_loss at step 14900: 0.212542\n",
      "2023-12-10 10:32:26,330 INFO     Training average negative_sample_loss at step 14900: 0.189599\n",
      "2023-12-10 10:32:26,330 INFO     Training average loss at step 14900: 0.201071\n",
      "2023-12-10 10:33:10,388 INFO     Training average positive_sample_loss at step 15000: 0.202252\n",
      "2023-12-10 10:33:10,389 INFO     Training average negative_sample_loss at step 15000: 0.185886\n",
      "2023-12-10 10:33:10,389 INFO     Training average loss at step 15000: 0.194069\n",
      "2023-12-10 10:33:52,908 INFO     Training average positive_sample_loss at step 15100: 0.209491\n",
      "2023-12-10 10:33:52,908 INFO     Training average negative_sample_loss at step 15100: 0.184308\n",
      "2023-12-10 10:33:52,908 INFO     Training average loss at step 15100: 0.196900\n",
      "2023-12-10 10:34:35,452 INFO     Training average positive_sample_loss at step 15200: 0.210441\n",
      "2023-12-10 10:34:35,453 INFO     Training average negative_sample_loss at step 15200: 0.185590\n",
      "2023-12-10 10:34:35,453 INFO     Training average loss at step 15200: 0.198015\n",
      "2023-12-10 10:35:20,779 INFO     Training average positive_sample_loss at step 15300: 0.213235\n",
      "2023-12-10 10:35:20,779 INFO     Training average negative_sample_loss at step 15300: 0.188757\n",
      "2023-12-10 10:35:20,779 INFO     Training average loss at step 15300: 0.200996\n",
      "2023-12-10 10:36:05,850 INFO     Training average positive_sample_loss at step 15400: 0.212442\n",
      "2023-12-10 10:36:05,850 INFO     Training average negative_sample_loss at step 15400: 0.188880\n",
      "2023-12-10 10:36:05,850 INFO     Training average loss at step 15400: 0.200661\n",
      "2023-12-10 10:36:58,088 INFO     Training average positive_sample_loss at step 15500: 0.202456\n",
      "2023-12-10 10:36:58,089 INFO     Training average negative_sample_loss at step 15500: 0.185670\n",
      "2023-12-10 10:36:58,089 INFO     Training average loss at step 15500: 0.194063\n",
      "2023-12-10 10:37:41,742 INFO     Training average positive_sample_loss at step 15600: 0.207028\n",
      "2023-12-10 10:37:41,742 INFO     Training average negative_sample_loss at step 15600: 0.182994\n",
      "2023-12-10 10:37:41,742 INFO     Training average loss at step 15600: 0.195011\n",
      "2023-12-10 10:38:25,191 INFO     Training average positive_sample_loss at step 15700: 0.210536\n",
      "2023-12-10 10:38:25,191 INFO     Training average negative_sample_loss at step 15700: 0.185863\n",
      "2023-12-10 10:38:25,191 INFO     Training average loss at step 15700: 0.198200\n",
      "2023-12-10 10:39:09,566 INFO     Training average positive_sample_loss at step 15800: 0.213088\n",
      "2023-12-10 10:39:09,566 INFO     Training average negative_sample_loss at step 15800: 0.187021\n",
      "2023-12-10 10:39:09,566 INFO     Training average loss at step 15800: 0.200054\n",
      "2023-12-10 10:39:52,612 INFO     Training average positive_sample_loss at step 15900: 0.212667\n",
      "2023-12-10 10:39:52,612 INFO     Training average negative_sample_loss at step 15900: 0.188355\n",
      "2023-12-10 10:39:52,612 INFO     Training average loss at step 15900: 0.200511\n",
      "2023-12-10 10:40:41,158 INFO     Training average positive_sample_loss at step 16000: 0.206300\n",
      "2023-12-10 10:40:41,158 INFO     Training average negative_sample_loss at step 16000: 0.188156\n",
      "2023-12-10 10:40:41,159 INFO     Training average loss at step 16000: 0.197228\n",
      "2023-12-10 10:41:26,156 INFO     Training average positive_sample_loss at step 16100: 0.205661\n",
      "2023-12-10 10:41:26,156 INFO     Training average negative_sample_loss at step 16100: 0.183522\n",
      "2023-12-10 10:41:26,156 INFO     Training average loss at step 16100: 0.194591\n",
      "2023-12-10 10:42:10,007 INFO     Training average positive_sample_loss at step 16200: 0.209635\n",
      "2023-12-10 10:42:10,007 INFO     Training average negative_sample_loss at step 16200: 0.184304\n",
      "2023-12-10 10:42:10,007 INFO     Training average loss at step 16200: 0.196970\n",
      "2023-12-10 10:42:54,641 INFO     Training average positive_sample_loss at step 16300: 0.211453\n",
      "2023-12-10 10:42:54,642 INFO     Training average negative_sample_loss at step 16300: 0.186242\n",
      "2023-12-10 10:42:54,642 INFO     Training average loss at step 16300: 0.198847\n",
      "2023-12-10 10:43:38,539 INFO     Training average positive_sample_loss at step 16400: 0.211733\n",
      "2023-12-10 10:43:38,539 INFO     Training average negative_sample_loss at step 16400: 0.186627\n",
      "2023-12-10 10:43:38,539 INFO     Training average loss at step 16400: 0.199180\n",
      "2023-12-10 10:44:29,017 INFO     Training average positive_sample_loss at step 16500: 0.211064\n",
      "2023-12-10 10:44:29,017 INFO     Training average negative_sample_loss at step 16500: 0.188547\n",
      "2023-12-10 10:44:29,017 INFO     Training average loss at step 16500: 0.199805\n",
      "2023-12-10 10:45:13,791 INFO     Training average positive_sample_loss at step 16600: 0.201710\n",
      "2023-12-10 10:45:13,791 INFO     Training average negative_sample_loss at step 16600: 0.184165\n",
      "2023-12-10 10:45:13,791 INFO     Training average loss at step 16600: 0.192938\n",
      "2023-12-10 10:45:57,365 INFO     Training average positive_sample_loss at step 16700: 0.208726\n",
      "2023-12-10 10:45:57,365 INFO     Training average negative_sample_loss at step 16700: 0.182907\n",
      "2023-12-10 10:45:57,365 INFO     Training average loss at step 16700: 0.195817\n",
      "2023-12-10 10:46:42,309 INFO     Training average positive_sample_loss at step 16800: 0.211170\n",
      "2023-12-10 10:46:42,309 INFO     Training average negative_sample_loss at step 16800: 0.186055\n",
      "2023-12-10 10:46:42,309 INFO     Training average loss at step 16800: 0.198613\n",
      "2023-12-10 10:47:27,328 INFO     Training average positive_sample_loss at step 16900: 0.212039\n",
      "2023-12-10 10:47:27,329 INFO     Training average negative_sample_loss at step 16900: 0.187296\n",
      "2023-12-10 10:47:27,329 INFO     Training average loss at step 16900: 0.199668\n",
      "2023-12-10 10:48:12,382 INFO     Training average positive_sample_loss at step 17000: 0.212838\n",
      "2023-12-10 10:48:12,383 INFO     Training average negative_sample_loss at step 17000: 0.188756\n",
      "2023-12-10 10:48:12,383 INFO     Training average loss at step 17000: 0.200797\n",
      "2023-12-10 10:49:06,258 INFO     Training average positive_sample_loss at step 17100: 0.202066\n",
      "2023-12-10 10:49:06,258 INFO     Training average negative_sample_loss at step 17100: 0.184515\n",
      "2023-12-10 10:49:06,258 INFO     Training average loss at step 17100: 0.193290\n",
      "2023-12-10 10:49:50,557 INFO     Training average positive_sample_loss at step 17200: 0.206938\n",
      "2023-12-10 10:49:50,557 INFO     Training average negative_sample_loss at step 17200: 0.182631\n",
      "2023-12-10 10:49:50,558 INFO     Training average loss at step 17200: 0.194785\n",
      "2023-12-10 10:50:35,311 INFO     Training average positive_sample_loss at step 17300: 0.210416\n",
      "2023-12-10 10:50:35,311 INFO     Training average negative_sample_loss at step 17300: 0.185104\n",
      "2023-12-10 10:50:35,311 INFO     Training average loss at step 17300: 0.197760\n",
      "2023-12-10 10:51:18,900 INFO     Training average positive_sample_loss at step 17400: 0.211867\n",
      "2023-12-10 10:51:18,900 INFO     Training average negative_sample_loss at step 17400: 0.186240\n",
      "2023-12-10 10:51:18,900 INFO     Training average loss at step 17400: 0.199054\n",
      "2023-12-10 10:52:01,323 INFO     Training average positive_sample_loss at step 17500: 0.212797\n",
      "2023-12-10 10:52:01,323 INFO     Training average negative_sample_loss at step 17500: 0.187752\n",
      "2023-12-10 10:52:01,323 INFO     Training average loss at step 17500: 0.200274\n",
      "2023-12-10 10:52:52,348 INFO     Training average positive_sample_loss at step 17600: 0.204858\n",
      "2023-12-10 10:52:52,348 INFO     Training average negative_sample_loss at step 17600: 0.186893\n",
      "2023-12-10 10:52:52,348 INFO     Training average loss at step 17600: 0.195876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 10:53:35,899 INFO     Training average positive_sample_loss at step 17700: 0.204984\n",
      "2023-12-10 10:53:35,899 INFO     Training average negative_sample_loss at step 17700: 0.182785\n",
      "2023-12-10 10:53:35,899 INFO     Training average loss at step 17700: 0.193885\n",
      "2023-12-10 10:54:20,052 INFO     Training average positive_sample_loss at step 17800: 0.210165\n",
      "2023-12-10 10:54:20,053 INFO     Training average negative_sample_loss at step 17800: 0.184331\n",
      "2023-12-10 10:54:20,053 INFO     Training average loss at step 17800: 0.197248\n",
      "2023-12-10 10:55:01,358 INFO     Training average positive_sample_loss at step 17900: 0.211307\n",
      "2023-12-10 10:55:01,358 INFO     Training average negative_sample_loss at step 17900: 0.185928\n",
      "2023-12-10 10:55:01,358 INFO     Training average loss at step 17900: 0.198618\n",
      "2023-12-10 10:55:44,592 INFO     Training average positive_sample_loss at step 18000: 0.212039\n",
      "2023-12-10 10:55:44,592 INFO     Training average negative_sample_loss at step 18000: 0.187608\n",
      "2023-12-10 10:55:44,592 INFO     Training average loss at step 18000: 0.199824\n",
      "2023-12-10 10:56:34,177 INFO     Training average positive_sample_loss at step 18100: 0.210768\n",
      "2023-12-10 10:56:34,177 INFO     Training average negative_sample_loss at step 18100: 0.188343\n",
      "2023-12-10 10:56:34,177 INFO     Training average loss at step 18100: 0.199556\n",
      "2023-12-10 10:57:17,235 INFO     Training average positive_sample_loss at step 18200: 0.202266\n",
      "2023-12-10 10:57:17,235 INFO     Training average negative_sample_loss at step 18200: 0.182808\n",
      "2023-12-10 10:57:17,235 INFO     Training average loss at step 18200: 0.192537\n",
      "2023-12-10 10:58:01,430 INFO     Training average positive_sample_loss at step 18300: 0.208253\n",
      "2023-12-10 10:58:01,431 INFO     Training average negative_sample_loss at step 18300: 0.182149\n",
      "2023-12-10 10:58:01,431 INFO     Training average loss at step 18300: 0.195201\n",
      "2023-12-10 10:58:45,485 INFO     Training average positive_sample_loss at step 18400: 0.209835\n",
      "2023-12-10 10:58:45,485 INFO     Training average negative_sample_loss at step 18400: 0.184883\n",
      "2023-12-10 10:58:45,485 INFO     Training average loss at step 18400: 0.197359\n",
      "2023-12-10 10:59:29,944 INFO     Training average positive_sample_loss at step 18500: 0.211600\n",
      "2023-12-10 10:59:29,944 INFO     Training average negative_sample_loss at step 18500: 0.186696\n",
      "2023-12-10 10:59:29,944 INFO     Training average loss at step 18500: 0.199148\n",
      "2023-12-10 11:00:14,208 INFO     Training average positive_sample_loss at step 18600: 0.212338\n",
      "2023-12-10 11:00:14,209 INFO     Training average negative_sample_loss at step 18600: 0.187927\n",
      "2023-12-10 11:00:14,209 INFO     Training average loss at step 18600: 0.200133\n",
      "2023-12-10 11:01:01,842 INFO     Training average positive_sample_loss at step 18700: 0.201048\n",
      "2023-12-10 11:01:01,843 INFO     Training average negative_sample_loss at step 18700: 0.184122\n",
      "2023-12-10 11:01:01,843 INFO     Training average loss at step 18700: 0.192585\n",
      "2023-12-10 11:01:45,608 INFO     Training average positive_sample_loss at step 18800: 0.207412\n",
      "2023-12-10 11:01:45,608 INFO     Training average negative_sample_loss at step 18800: 0.182471\n",
      "2023-12-10 11:01:45,608 INFO     Training average loss at step 18800: 0.194941\n",
      "2023-12-10 11:02:29,297 INFO     Training average positive_sample_loss at step 18900: 0.210118\n",
      "2023-12-10 11:02:29,298 INFO     Training average negative_sample_loss at step 18900: 0.184614\n",
      "2023-12-10 11:02:29,298 INFO     Training average loss at step 18900: 0.197366\n",
      "2023-12-10 11:03:13,793 INFO     Training average positive_sample_loss at step 19000: 0.211082\n",
      "2023-12-10 11:03:13,793 INFO     Training average negative_sample_loss at step 19000: 0.186408\n",
      "2023-12-10 11:03:13,793 INFO     Training average loss at step 19000: 0.198745\n",
      "2023-12-10 11:03:59,091 INFO     Training average positive_sample_loss at step 19100: 0.213005\n",
      "2023-12-10 11:03:59,091 INFO     Training average negative_sample_loss at step 19100: 0.187302\n",
      "2023-12-10 11:03:59,091 INFO     Training average loss at step 19100: 0.200153\n",
      "2023-12-10 11:04:48,695 INFO     Training average positive_sample_loss at step 19200: 0.204201\n",
      "2023-12-10 11:04:48,695 INFO     Training average negative_sample_loss at step 19200: 0.186615\n",
      "2023-12-10 11:04:48,695 INFO     Training average loss at step 19200: 0.195408\n",
      "2023-12-10 11:05:32,631 INFO     Training average positive_sample_loss at step 19300: 0.205685\n",
      "2023-12-10 11:05:32,631 INFO     Training average negative_sample_loss at step 19300: 0.182338\n",
      "2023-12-10 11:05:32,631 INFO     Training average loss at step 19300: 0.194011\n",
      "2023-12-10 11:06:15,794 INFO     Training average positive_sample_loss at step 19400: 0.208969\n",
      "2023-12-10 11:06:15,795 INFO     Training average negative_sample_loss at step 19400: 0.183059\n",
      "2023-12-10 11:06:15,795 INFO     Training average loss at step 19400: 0.196014\n",
      "2023-12-10 11:06:59,728 INFO     Training average positive_sample_loss at step 19500: 0.211058\n",
      "2023-12-10 11:06:59,728 INFO     Training average negative_sample_loss at step 19500: 0.185499\n",
      "2023-12-10 11:06:59,728 INFO     Training average loss at step 19500: 0.198278\n",
      "2023-12-10 11:07:43,459 INFO     Training average positive_sample_loss at step 19600: 0.211911\n",
      "2023-12-10 11:07:43,459 INFO     Training average negative_sample_loss at step 19600: 0.187286\n",
      "2023-12-10 11:07:43,459 INFO     Training average loss at step 19600: 0.199599\n",
      "2023-12-10 11:08:35,878 INFO     Training average positive_sample_loss at step 19700: 0.209550\n",
      "2023-12-10 11:08:35,879 INFO     Training average negative_sample_loss at step 19700: 0.187808\n",
      "2023-12-10 11:08:35,879 INFO     Training average loss at step 19700: 0.198679\n",
      "2023-12-10 11:09:19,405 INFO     Training average positive_sample_loss at step 19800: 0.202521\n",
      "2023-12-10 11:09:19,406 INFO     Training average negative_sample_loss at step 19800: 0.182526\n",
      "2023-12-10 11:09:19,406 INFO     Training average loss at step 19800: 0.192524\n",
      "2023-12-10 11:10:02,750 INFO     Training average positive_sample_loss at step 19900: 0.208156\n",
      "2023-12-10 11:10:02,751 INFO     Training average negative_sample_loss at step 19900: 0.181642\n",
      "2023-12-10 11:10:02,751 INFO     Training average loss at step 19900: 0.194899\n",
      "2023-12-10 11:10:56,412 INFO     Training average positive_sample_loss at step 20000: 0.210093\n",
      "2023-12-10 11:10:56,412 INFO     Training average negative_sample_loss at step 20000: 0.183962\n",
      "2023-12-10 11:10:56,412 INFO     Training average loss at step 20000: 0.197028\n",
      "2023-12-10 11:10:56,412 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 11:10:57,383 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 11:11:24,718 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 11:11:55,200 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 11:12:01,081 INFO     Valid MRR at step 20000: 0.316878\n",
      "2023-12-10 11:12:01,081 INFO     Valid MR at step 20000: 160.449073\n",
      "2023-12-10 11:12:01,081 INFO     Valid HITS@1 at step 20000: 0.221699\n",
      "2023-12-10 11:12:01,081 INFO     Valid HITS@3 at step 20000: 0.350870\n",
      "2023-12-10 11:12:01,081 INFO     Valid HITS@10 at step 20000: 0.510579\n",
      "2023-12-10 11:12:38,098 INFO     Training average positive_sample_loss at step 20100: 0.211284\n",
      "2023-12-10 11:12:38,099 INFO     Training average negative_sample_loss at step 20100: 0.185263\n",
      "2023-12-10 11:12:38,099 INFO     Training average loss at step 20100: 0.198273\n",
      "2023-12-10 11:13:21,453 INFO     Training average positive_sample_loss at step 20200: 0.211149\n",
      "2023-12-10 11:13:21,454 INFO     Training average negative_sample_loss at step 20200: 0.186957\n",
      "2023-12-10 11:13:21,454 INFO     Training average loss at step 20200: 0.199053\n",
      "2023-12-10 11:14:12,799 INFO     Training average positive_sample_loss at step 20300: 0.201343\n",
      "2023-12-10 11:14:12,799 INFO     Training average negative_sample_loss at step 20300: 0.183662\n",
      "2023-12-10 11:14:12,799 INFO     Training average loss at step 20300: 0.192503\n",
      "2023-12-10 11:14:55,818 INFO     Training average positive_sample_loss at step 20400: 0.207881\n",
      "2023-12-10 11:14:55,819 INFO     Training average negative_sample_loss at step 20400: 0.182430\n",
      "2023-12-10 11:14:55,819 INFO     Training average loss at step 20400: 0.195156\n",
      "2023-12-10 11:15:39,729 INFO     Training average positive_sample_loss at step 20500: 0.208885\n",
      "2023-12-10 11:15:39,730 INFO     Training average negative_sample_loss at step 20500: 0.183459\n",
      "2023-12-10 11:15:39,730 INFO     Training average loss at step 20500: 0.196172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 11:16:23,714 INFO     Training average positive_sample_loss at step 20600: 0.211471\n",
      "2023-12-10 11:16:23,715 INFO     Training average negative_sample_loss at step 20600: 0.184416\n",
      "2023-12-10 11:16:23,715 INFO     Training average loss at step 20600: 0.197944\n",
      "2023-12-10 11:17:06,887 INFO     Training average positive_sample_loss at step 20700: 0.211908\n",
      "2023-12-10 11:17:06,888 INFO     Training average negative_sample_loss at step 20700: 0.186875\n",
      "2023-12-10 11:17:06,888 INFO     Training average loss at step 20700: 0.199391\n",
      "2023-12-10 11:17:57,514 INFO     Training average positive_sample_loss at step 20800: 0.203387\n",
      "2023-12-10 11:17:57,514 INFO     Training average negative_sample_loss at step 20800: 0.185260\n",
      "2023-12-10 11:17:57,514 INFO     Training average loss at step 20800: 0.194324\n",
      "2023-12-10 11:18:41,355 INFO     Training average positive_sample_loss at step 20900: 0.205482\n",
      "2023-12-10 11:18:41,355 INFO     Training average negative_sample_loss at step 20900: 0.181097\n",
      "2023-12-10 11:18:41,356 INFO     Training average loss at step 20900: 0.193290\n",
      "2023-12-10 11:19:25,341 INFO     Training average positive_sample_loss at step 21000: 0.208960\n",
      "2023-12-10 11:19:25,341 INFO     Training average negative_sample_loss at step 21000: 0.183292\n",
      "2023-12-10 11:19:25,341 INFO     Training average loss at step 21000: 0.196126\n",
      "2023-12-10 11:20:08,225 INFO     Training average positive_sample_loss at step 21100: 0.210401\n",
      "2023-12-10 11:20:08,226 INFO     Training average negative_sample_loss at step 21100: 0.184507\n",
      "2023-12-10 11:20:08,226 INFO     Training average loss at step 21100: 0.197454\n",
      "2023-12-10 11:20:52,574 INFO     Training average positive_sample_loss at step 21200: 0.212265\n",
      "2023-12-10 11:20:52,575 INFO     Training average negative_sample_loss at step 21200: 0.186985\n",
      "2023-12-10 11:20:52,575 INFO     Training average loss at step 21200: 0.199625\n",
      "2023-12-10 11:21:40,531 INFO     Training average positive_sample_loss at step 21300: 0.207409\n",
      "2023-12-10 11:21:40,531 INFO     Training average negative_sample_loss at step 21300: 0.186214\n",
      "2023-12-10 11:21:40,531 INFO     Training average loss at step 21300: 0.196811\n",
      "2023-12-10 11:22:28,005 INFO     Training average positive_sample_loss at step 21400: 0.202710\n",
      "2023-12-10 11:22:28,006 INFO     Training average negative_sample_loss at step 21400: 0.181368\n",
      "2023-12-10 11:22:28,006 INFO     Training average loss at step 21400: 0.192039\n",
      "2023-12-10 11:23:11,506 INFO     Training average positive_sample_loss at step 21500: 0.208036\n",
      "2023-12-10 11:23:11,506 INFO     Training average negative_sample_loss at step 21500: 0.182482\n",
      "2023-12-10 11:23:11,506 INFO     Training average loss at step 21500: 0.195259\n",
      "2023-12-10 11:23:55,684 INFO     Training average positive_sample_loss at step 21600: 0.210419\n",
      "2023-12-10 11:23:55,685 INFO     Training average negative_sample_loss at step 21600: 0.183666\n",
      "2023-12-10 11:23:55,685 INFO     Training average loss at step 21600: 0.197042\n",
      "2023-12-10 11:24:38,502 INFO     Training average positive_sample_loss at step 21700: 0.211348\n",
      "2023-12-10 11:24:38,502 INFO     Training average negative_sample_loss at step 21700: 0.186072\n",
      "2023-12-10 11:24:38,502 INFO     Training average loss at step 21700: 0.198710\n",
      "2023-12-10 11:25:22,648 INFO     Training average positive_sample_loss at step 21800: 0.211610\n",
      "2023-12-10 11:25:22,649 INFO     Training average negative_sample_loss at step 21800: 0.186142\n",
      "2023-12-10 11:25:22,649 INFO     Training average loss at step 21800: 0.198876\n",
      "2023-12-10 11:26:15,040 INFO     Training average positive_sample_loss at step 21900: 0.200662\n",
      "2023-12-10 11:26:15,040 INFO     Training average negative_sample_loss at step 21900: 0.183719\n",
      "2023-12-10 11:26:15,040 INFO     Training average loss at step 21900: 0.192190\n",
      "2023-12-10 11:26:58,036 INFO     Training average positive_sample_loss at step 22000: 0.207384\n",
      "2023-12-10 11:26:58,037 INFO     Training average negative_sample_loss at step 22000: 0.180722\n",
      "2023-12-10 11:26:58,037 INFO     Training average loss at step 22000: 0.194053\n",
      "2023-12-10 11:27:40,967 INFO     Training average positive_sample_loss at step 22100: 0.208839\n",
      "2023-12-10 11:27:40,968 INFO     Training average negative_sample_loss at step 22100: 0.182973\n",
      "2023-12-10 11:27:40,968 INFO     Training average loss at step 22100: 0.195906\n",
      "2023-12-10 11:28:26,236 INFO     Training average positive_sample_loss at step 22200: 0.210159\n",
      "2023-12-10 11:28:26,237 INFO     Training average negative_sample_loss at step 22200: 0.183644\n",
      "2023-12-10 11:28:26,237 INFO     Training average loss at step 22200: 0.196901\n",
      "2023-12-10 11:29:09,661 INFO     Training average positive_sample_loss at step 22300: 0.211889\n",
      "2023-12-10 11:29:09,662 INFO     Training average negative_sample_loss at step 22300: 0.187126\n",
      "2023-12-10 11:29:09,662 INFO     Training average loss at step 22300: 0.199508\n",
      "2023-12-10 11:30:00,045 INFO     Training average positive_sample_loss at step 22400: 0.203762\n",
      "2023-12-10 11:30:00,046 INFO     Training average negative_sample_loss at step 22400: 0.185214\n",
      "2023-12-10 11:30:00,046 INFO     Training average loss at step 22400: 0.194488\n",
      "2023-12-10 11:30:43,628 INFO     Training average positive_sample_loss at step 22500: 0.204333\n",
      "2023-12-10 11:30:43,628 INFO     Training average negative_sample_loss at step 22500: 0.179673\n",
      "2023-12-10 11:30:43,628 INFO     Training average loss at step 22500: 0.192003\n",
      "2023-12-10 11:31:27,101 INFO     Training average positive_sample_loss at step 22600: 0.209482\n",
      "2023-12-10 11:31:27,102 INFO     Training average negative_sample_loss at step 22600: 0.183873\n",
      "2023-12-10 11:31:27,102 INFO     Training average loss at step 22600: 0.196677\n",
      "2023-12-10 11:32:10,358 INFO     Training average positive_sample_loss at step 22700: 0.210804\n",
      "2023-12-10 11:32:10,358 INFO     Training average negative_sample_loss at step 22700: 0.183865\n",
      "2023-12-10 11:32:10,358 INFO     Training average loss at step 22700: 0.197335\n",
      "2023-12-10 11:32:54,594 INFO     Training average positive_sample_loss at step 22800: 0.211832\n",
      "2023-12-10 11:32:54,594 INFO     Training average negative_sample_loss at step 22800: 0.186955\n",
      "2023-12-10 11:32:54,594 INFO     Training average loss at step 22800: 0.199394\n",
      "2023-12-10 11:33:44,421 INFO     Training average positive_sample_loss at step 22900: 0.207045\n",
      "2023-12-10 11:33:44,422 INFO     Training average negative_sample_loss at step 22900: 0.186778\n",
      "2023-12-10 11:33:44,422 INFO     Training average loss at step 22900: 0.196911\n",
      "2023-12-10 11:34:28,348 INFO     Training average positive_sample_loss at step 23000: 0.203632\n",
      "2023-12-10 11:34:28,348 INFO     Training average negative_sample_loss at step 23000: 0.181857\n",
      "2023-12-10 11:34:28,348 INFO     Training average loss at step 23000: 0.192744\n",
      "2023-12-10 11:35:11,109 INFO     Training average positive_sample_loss at step 23100: 0.208477\n",
      "2023-12-10 11:35:11,110 INFO     Training average negative_sample_loss at step 23100: 0.181787\n",
      "2023-12-10 11:35:11,110 INFO     Training average loss at step 23100: 0.195132\n",
      "2023-12-10 11:35:54,543 INFO     Training average positive_sample_loss at step 23200: 0.209285\n",
      "2023-12-10 11:35:54,543 INFO     Training average negative_sample_loss at step 23200: 0.182438\n",
      "2023-12-10 11:35:54,543 INFO     Training average loss at step 23200: 0.195861\n",
      "2023-12-10 11:36:38,987 INFO     Training average positive_sample_loss at step 23300: 0.211110\n",
      "2023-12-10 11:36:38,988 INFO     Training average negative_sample_loss at step 23300: 0.185438\n",
      "2023-12-10 11:36:38,988 INFO     Training average loss at step 23300: 0.198274\n",
      "2023-12-10 11:37:22,059 INFO     Training average positive_sample_loss at step 23400: 0.211156\n",
      "2023-12-10 11:37:22,059 INFO     Training average negative_sample_loss at step 23400: 0.186057\n",
      "2023-12-10 11:37:22,059 INFO     Training average loss at step 23400: 0.198606\n",
      "2023-12-10 11:38:14,158 INFO     Training average positive_sample_loss at step 23500: 0.199962\n",
      "2023-12-10 11:38:14,158 INFO     Training average negative_sample_loss at step 23500: 0.181775\n",
      "2023-12-10 11:38:14,158 INFO     Training average loss at step 23500: 0.190869\n",
      "2023-12-10 11:38:57,174 INFO     Training average positive_sample_loss at step 23600: 0.207086\n",
      "2023-12-10 11:38:57,174 INFO     Training average negative_sample_loss at step 23600: 0.182059\n",
      "2023-12-10 11:38:57,174 INFO     Training average loss at step 23600: 0.194573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 11:39:40,172 INFO     Training average positive_sample_loss at step 23700: 0.209825\n",
      "2023-12-10 11:39:40,172 INFO     Training average negative_sample_loss at step 23700: 0.182345\n",
      "2023-12-10 11:39:40,172 INFO     Training average loss at step 23700: 0.196085\n",
      "2023-12-10 11:40:23,131 INFO     Training average positive_sample_loss at step 23800: 0.210155\n",
      "2023-12-10 11:40:23,132 INFO     Training average negative_sample_loss at step 23800: 0.183685\n",
      "2023-12-10 11:40:23,132 INFO     Training average loss at step 23800: 0.196920\n",
      "2023-12-10 11:41:06,724 INFO     Training average positive_sample_loss at step 23900: 0.211049\n",
      "2023-12-10 11:41:06,724 INFO     Training average negative_sample_loss at step 23900: 0.186191\n",
      "2023-12-10 11:41:06,724 INFO     Training average loss at step 23900: 0.198620\n",
      "2023-12-10 11:41:55,416 INFO     Training average positive_sample_loss at step 24000: 0.201985\n",
      "2023-12-10 11:41:55,416 INFO     Training average negative_sample_loss at step 24000: 0.182933\n",
      "2023-12-10 11:41:55,416 INFO     Training average loss at step 24000: 0.192459\n",
      "2023-12-10 11:42:38,517 INFO     Training average positive_sample_loss at step 24100: 0.204979\n",
      "2023-12-10 11:42:38,517 INFO     Training average negative_sample_loss at step 24100: 0.179934\n",
      "2023-12-10 11:42:38,517 INFO     Training average loss at step 24100: 0.192456\n",
      "2023-12-10 11:43:22,632 INFO     Training average positive_sample_loss at step 24200: 0.208775\n",
      "2023-12-10 11:43:22,632 INFO     Training average negative_sample_loss at step 24200: 0.182185\n",
      "2023-12-10 11:43:22,632 INFO     Training average loss at step 24200: 0.195480\n",
      "2023-12-10 11:44:07,531 INFO     Training average positive_sample_loss at step 24300: 0.209936\n",
      "2023-12-10 11:44:07,531 INFO     Training average negative_sample_loss at step 24300: 0.183463\n",
      "2023-12-10 11:44:07,532 INFO     Training average loss at step 24300: 0.196700\n",
      "2023-12-10 11:44:51,274 INFO     Training average positive_sample_loss at step 24400: 0.211847\n",
      "2023-12-10 11:44:51,274 INFO     Training average negative_sample_loss at step 24400: 0.186409\n",
      "2023-12-10 11:44:51,275 INFO     Training average loss at step 24400: 0.199128\n",
      "2023-12-10 11:45:41,511 INFO     Training average positive_sample_loss at step 24500: 0.207141\n",
      "2023-12-10 11:45:41,511 INFO     Training average negative_sample_loss at step 24500: 0.185642\n",
      "2023-12-10 11:45:41,511 INFO     Training average loss at step 24500: 0.196391\n",
      "2023-12-10 11:46:27,148 INFO     Training average positive_sample_loss at step 24600: 0.202986\n",
      "2023-12-10 11:46:27,148 INFO     Training average negative_sample_loss at step 24600: 0.181046\n",
      "2023-12-10 11:46:27,148 INFO     Training average loss at step 24600: 0.192016\n",
      "2023-12-10 11:47:10,186 INFO     Training average positive_sample_loss at step 24700: 0.207805\n",
      "2023-12-10 11:47:10,187 INFO     Training average negative_sample_loss at step 24700: 0.181432\n",
      "2023-12-10 11:47:10,187 INFO     Training average loss at step 24700: 0.194618\n",
      "2023-12-10 11:47:54,076 INFO     Training average positive_sample_loss at step 24800: 0.209826\n",
      "2023-12-10 11:47:54,076 INFO     Training average negative_sample_loss at step 24800: 0.183235\n",
      "2023-12-10 11:47:54,076 INFO     Training average loss at step 24800: 0.196531\n",
      "2023-12-10 11:48:35,955 INFO     Training average positive_sample_loss at step 24900: 0.210592\n",
      "2023-12-10 11:48:35,956 INFO     Training average negative_sample_loss at step 24900: 0.185051\n",
      "2023-12-10 11:48:35,956 INFO     Training average loss at step 24900: 0.197821\n",
      "2023-12-10 11:49:20,297 INFO     Training average positive_sample_loss at step 25000: 0.211699\n",
      "2023-12-10 11:49:20,297 INFO     Training average negative_sample_loss at step 25000: 0.185903\n",
      "2023-12-10 11:49:20,297 INFO     Training average loss at step 25000: 0.198801\n",
      "2023-12-10 11:50:10,719 INFO     Training average positive_sample_loss at step 25100: 0.200050\n",
      "2023-12-10 11:50:10,719 INFO     Training average negative_sample_loss at step 25100: 0.182479\n",
      "2023-12-10 11:50:10,719 INFO     Training average loss at step 25100: 0.191265\n",
      "2023-12-10 11:50:55,068 INFO     Training average positive_sample_loss at step 25200: 0.206856\n",
      "2023-12-10 11:50:55,068 INFO     Training average negative_sample_loss at step 25200: 0.179868\n",
      "2023-12-10 11:50:55,068 INFO     Training average loss at step 25200: 0.193362\n",
      "2023-12-10 11:51:37,994 INFO     Training average positive_sample_loss at step 25300: 0.209174\n",
      "2023-12-10 11:51:37,994 INFO     Training average negative_sample_loss at step 25300: 0.182119\n",
      "2023-12-10 11:51:37,994 INFO     Training average loss at step 25300: 0.195647\n",
      "2023-12-10 11:52:22,287 INFO     Training average positive_sample_loss at step 25400: 0.210252\n",
      "2023-12-10 11:52:22,287 INFO     Training average negative_sample_loss at step 25400: 0.184710\n",
      "2023-12-10 11:52:22,287 INFO     Training average loss at step 25400: 0.197481\n",
      "2023-12-10 11:53:06,700 INFO     Training average positive_sample_loss at step 25500: 0.211222\n",
      "2023-12-10 11:53:06,701 INFO     Training average negative_sample_loss at step 25500: 0.185773\n",
      "2023-12-10 11:53:06,701 INFO     Training average loss at step 25500: 0.198497\n",
      "2023-12-10 11:53:56,175 INFO     Training average positive_sample_loss at step 25600: 0.202603\n",
      "2023-12-10 11:53:56,175 INFO     Training average negative_sample_loss at step 25600: 0.184677\n",
      "2023-12-10 11:53:56,176 INFO     Training average loss at step 25600: 0.193640\n",
      "2023-12-10 11:54:40,101 INFO     Training average positive_sample_loss at step 25700: 0.206044\n",
      "2023-12-10 11:54:40,102 INFO     Training average negative_sample_loss at step 25700: 0.180160\n",
      "2023-12-10 11:54:40,102 INFO     Training average loss at step 25700: 0.193102\n",
      "2023-12-10 11:55:23,085 INFO     Training average positive_sample_loss at step 25800: 0.208684\n",
      "2023-12-10 11:55:23,085 INFO     Training average negative_sample_loss at step 25800: 0.182323\n",
      "2023-12-10 11:55:23,085 INFO     Training average loss at step 25800: 0.195504\n",
      "2023-12-10 11:56:05,636 INFO     Training average positive_sample_loss at step 25900: 0.210318\n",
      "2023-12-10 11:56:05,636 INFO     Training average negative_sample_loss at step 25900: 0.183366\n",
      "2023-12-10 11:56:05,636 INFO     Training average loss at step 25900: 0.196842\n",
      "2023-12-10 11:56:48,366 INFO     Training average positive_sample_loss at step 26000: 0.210462\n",
      "2023-12-10 11:56:48,366 INFO     Training average negative_sample_loss at step 26000: 0.184854\n",
      "2023-12-10 11:56:48,366 INFO     Training average loss at step 26000: 0.197658\n",
      "2023-12-10 11:57:41,035 INFO     Training average positive_sample_loss at step 26100: 0.205193\n",
      "2023-12-10 11:57:41,036 INFO     Training average negative_sample_loss at step 26100: 0.184589\n",
      "2023-12-10 11:57:41,036 INFO     Training average loss at step 26100: 0.194891\n",
      "2023-12-10 11:58:24,754 INFO     Training average positive_sample_loss at step 26200: 0.203682\n",
      "2023-12-10 11:58:24,754 INFO     Training average negative_sample_loss at step 26200: 0.179188\n",
      "2023-12-10 11:58:24,754 INFO     Training average loss at step 26200: 0.191435\n",
      "2023-12-10 11:59:08,432 INFO     Training average positive_sample_loss at step 26300: 0.207544\n",
      "2023-12-10 11:59:08,433 INFO     Training average negative_sample_loss at step 26300: 0.181112\n",
      "2023-12-10 11:59:08,433 INFO     Training average loss at step 26300: 0.194328\n",
      "2023-12-10 11:59:51,798 INFO     Training average positive_sample_loss at step 26400: 0.209542\n",
      "2023-12-10 11:59:51,798 INFO     Training average negative_sample_loss at step 26400: 0.182962\n",
      "2023-12-10 11:59:51,798 INFO     Training average loss at step 26400: 0.196252\n",
      "2023-12-10 12:00:34,990 INFO     Training average positive_sample_loss at step 26500: 0.210706\n",
      "2023-12-10 12:00:34,990 INFO     Training average negative_sample_loss at step 26500: 0.184755\n",
      "2023-12-10 12:00:34,990 INFO     Training average loss at step 26500: 0.197731\n",
      "2023-12-10 12:01:21,827 INFO     Training average positive_sample_loss at step 26600: 0.210804\n",
      "2023-12-10 12:01:21,827 INFO     Training average negative_sample_loss at step 26600: 0.184817\n",
      "2023-12-10 12:01:21,827 INFO     Training average loss at step 26600: 0.197810\n",
      "2023-12-10 12:02:07,000 INFO     Training average positive_sample_loss at step 26700: 0.199850\n",
      "2023-12-10 12:02:07,001 INFO     Training average negative_sample_loss at step 26700: 0.181370\n",
      "2023-12-10 12:02:07,001 INFO     Training average loss at step 26700: 0.190610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 12:02:50,478 INFO     Training average positive_sample_loss at step 26800: 0.206913\n",
      "2023-12-10 12:02:50,478 INFO     Training average negative_sample_loss at step 26800: 0.179817\n",
      "2023-12-10 12:02:50,478 INFO     Training average loss at step 26800: 0.193365\n",
      "2023-12-10 12:03:34,692 INFO     Training average positive_sample_loss at step 26900: 0.208588\n",
      "2023-12-10 12:03:34,693 INFO     Training average negative_sample_loss at step 26900: 0.181656\n",
      "2023-12-10 12:03:34,693 INFO     Training average loss at step 26900: 0.195122\n",
      "2023-12-10 12:04:18,848 INFO     Training average positive_sample_loss at step 27000: 0.210245\n",
      "2023-12-10 12:04:18,848 INFO     Training average negative_sample_loss at step 27000: 0.184395\n",
      "2023-12-10 12:04:18,848 INFO     Training average loss at step 27000: 0.197320\n",
      "2023-12-10 12:05:02,811 INFO     Training average positive_sample_loss at step 27100: 0.211952\n",
      "2023-12-10 12:05:02,811 INFO     Training average negative_sample_loss at step 27100: 0.185388\n",
      "2023-12-10 12:05:02,811 INFO     Training average loss at step 27100: 0.198670\n",
      "2023-12-10 12:05:54,832 INFO     Training average positive_sample_loss at step 27200: 0.200989\n",
      "2023-12-10 12:05:54,832 INFO     Training average negative_sample_loss at step 27200: 0.183353\n",
      "2023-12-10 12:05:54,833 INFO     Training average loss at step 27200: 0.192171\n",
      "2023-12-10 12:06:39,954 INFO     Training average positive_sample_loss at step 27300: 0.205853\n",
      "2023-12-10 12:06:39,955 INFO     Training average negative_sample_loss at step 27300: 0.180238\n",
      "2023-12-10 12:06:39,955 INFO     Training average loss at step 27300: 0.193046\n",
      "2023-12-10 12:07:22,946 INFO     Training average positive_sample_loss at step 27400: 0.209055\n",
      "2023-12-10 12:07:22,947 INFO     Training average negative_sample_loss at step 27400: 0.181305\n",
      "2023-12-10 12:07:22,947 INFO     Training average loss at step 27400: 0.195180\n",
      "2023-12-10 12:08:06,698 INFO     Training average positive_sample_loss at step 27500: 0.209589\n",
      "2023-12-10 12:08:06,698 INFO     Training average negative_sample_loss at step 27500: 0.182685\n",
      "2023-12-10 12:08:06,698 INFO     Training average loss at step 27500: 0.196137\n",
      "2023-12-10 12:08:49,816 INFO     Training average positive_sample_loss at step 27600: 0.210733\n",
      "2023-12-10 12:08:49,816 INFO     Training average negative_sample_loss at step 27600: 0.184648\n",
      "2023-12-10 12:08:49,816 INFO     Training average loss at step 27600: 0.197690\n",
      "2023-12-10 12:09:39,698 INFO     Training average positive_sample_loss at step 27700: 0.205988\n",
      "2023-12-10 12:09:39,698 INFO     Training average negative_sample_loss at step 27700: 0.184971\n",
      "2023-12-10 12:09:39,698 INFO     Training average loss at step 27700: 0.195480\n",
      "2023-12-10 12:10:24,240 INFO     Training average positive_sample_loss at step 27800: 0.203300\n",
      "2023-12-10 12:10:24,241 INFO     Training average negative_sample_loss at step 27800: 0.179795\n",
      "2023-12-10 12:10:24,241 INFO     Training average loss at step 27800: 0.191548\n",
      "2023-12-10 12:11:08,566 INFO     Training average positive_sample_loss at step 27900: 0.207190\n",
      "2023-12-10 12:11:08,566 INFO     Training average negative_sample_loss at step 27900: 0.181117\n",
      "2023-12-10 12:11:08,566 INFO     Training average loss at step 27900: 0.194153\n",
      "2023-12-10 12:11:52,458 INFO     Training average positive_sample_loss at step 28000: 0.210167\n",
      "2023-12-10 12:11:52,459 INFO     Training average negative_sample_loss at step 28000: 0.182714\n",
      "2023-12-10 12:11:52,459 INFO     Training average loss at step 28000: 0.196440\n",
      "2023-12-10 12:12:36,887 INFO     Training average positive_sample_loss at step 28100: 0.210345\n",
      "2023-12-10 12:12:36,887 INFO     Training average negative_sample_loss at step 28100: 0.184047\n",
      "2023-12-10 12:12:36,887 INFO     Training average loss at step 28100: 0.197196\n",
      "2023-12-10 12:13:26,133 INFO     Training average positive_sample_loss at step 28200: 0.210142\n",
      "2023-12-10 12:13:26,133 INFO     Training average negative_sample_loss at step 28200: 0.185638\n",
      "2023-12-10 12:13:26,133 INFO     Training average loss at step 28200: 0.197890\n",
      "2023-12-10 12:14:10,579 INFO     Training average positive_sample_loss at step 28300: 0.200812\n",
      "2023-12-10 12:14:10,580 INFO     Training average negative_sample_loss at step 28300: 0.181900\n",
      "2023-12-10 12:14:10,580 INFO     Training average loss at step 28300: 0.191356\n",
      "2023-12-10 12:14:53,872 INFO     Training average positive_sample_loss at step 28400: 0.207285\n",
      "2023-12-10 12:14:53,873 INFO     Training average negative_sample_loss at step 28400: 0.180669\n",
      "2023-12-10 12:14:53,873 INFO     Training average loss at step 28400: 0.193977\n",
      "2023-12-10 12:15:38,310 INFO     Training average positive_sample_loss at step 28500: 0.209817\n",
      "2023-12-10 12:15:38,310 INFO     Training average negative_sample_loss at step 28500: 0.182593\n",
      "2023-12-10 12:15:38,310 INFO     Training average loss at step 28500: 0.196205\n",
      "2023-12-10 12:16:22,675 INFO     Training average positive_sample_loss at step 28600: 0.210396\n",
      "2023-12-10 12:16:22,675 INFO     Training average negative_sample_loss at step 28600: 0.183686\n",
      "2023-12-10 12:16:22,675 INFO     Training average loss at step 28600: 0.197041\n",
      "2023-12-10 12:17:06,175 INFO     Training average positive_sample_loss at step 28700: 0.210550\n",
      "2023-12-10 12:17:06,175 INFO     Training average negative_sample_loss at step 28700: 0.183770\n",
      "2023-12-10 12:17:06,175 INFO     Training average loss at step 28700: 0.197160\n",
      "2023-12-10 12:17:56,661 INFO     Training average positive_sample_loss at step 28800: 0.200437\n",
      "2023-12-10 12:17:56,661 INFO     Training average negative_sample_loss at step 28800: 0.182295\n",
      "2023-12-10 12:17:56,661 INFO     Training average loss at step 28800: 0.191366\n",
      "2023-12-10 12:18:41,445 INFO     Training average positive_sample_loss at step 28900: 0.206522\n",
      "2023-12-10 12:18:41,445 INFO     Training average negative_sample_loss at step 28900: 0.180330\n",
      "2023-12-10 12:18:41,446 INFO     Training average loss at step 28900: 0.193426\n",
      "2023-12-10 12:19:26,457 INFO     Training average positive_sample_loss at step 29000: 0.208073\n",
      "2023-12-10 12:19:26,458 INFO     Training average negative_sample_loss at step 29000: 0.181995\n",
      "2023-12-10 12:19:26,458 INFO     Training average loss at step 29000: 0.195034\n",
      "2023-12-10 12:20:10,494 INFO     Training average positive_sample_loss at step 29100: 0.210657\n",
      "2023-12-10 12:20:10,494 INFO     Training average negative_sample_loss at step 29100: 0.183723\n",
      "2023-12-10 12:20:10,494 INFO     Training average loss at step 29100: 0.197190\n",
      "2023-12-10 12:20:53,186 INFO     Training average positive_sample_loss at step 29200: 0.210571\n",
      "2023-12-10 12:20:53,186 INFO     Training average negative_sample_loss at step 29200: 0.184719\n",
      "2023-12-10 12:20:53,186 INFO     Training average loss at step 29200: 0.197645\n",
      "2023-12-10 12:21:41,365 INFO     Training average positive_sample_loss at step 29300: 0.204934\n",
      "2023-12-10 12:21:41,366 INFO     Training average negative_sample_loss at step 29300: 0.183947\n",
      "2023-12-10 12:21:41,366 INFO     Training average loss at step 29300: 0.194441\n",
      "2023-12-10 12:22:26,102 INFO     Training average positive_sample_loss at step 29400: 0.203940\n",
      "2023-12-10 12:22:26,102 INFO     Training average negative_sample_loss at step 29400: 0.180244\n",
      "2023-12-10 12:22:26,102 INFO     Training average loss at step 29400: 0.192092\n",
      "2023-12-10 12:23:08,746 INFO     Training average positive_sample_loss at step 29500: 0.208127\n",
      "2023-12-10 12:23:08,746 INFO     Training average negative_sample_loss at step 29500: 0.180972\n",
      "2023-12-10 12:23:08,746 INFO     Training average loss at step 29500: 0.194550\n",
      "2023-12-10 12:23:51,954 INFO     Training average positive_sample_loss at step 29600: 0.210198\n",
      "2023-12-10 12:23:51,954 INFO     Training average negative_sample_loss at step 29600: 0.182809\n",
      "2023-12-10 12:23:51,954 INFO     Training average loss at step 29600: 0.196504\n",
      "2023-12-10 12:24:36,672 INFO     Training average positive_sample_loss at step 29700: 0.210407\n",
      "2023-12-10 12:24:36,672 INFO     Training average negative_sample_loss at step 29700: 0.183897\n",
      "2023-12-10 12:24:36,672 INFO     Training average loss at step 29700: 0.197152\n",
      "2023-12-10 12:25:25,775 INFO     Training average positive_sample_loss at step 29800: 0.209027\n",
      "2023-12-10 12:25:25,776 INFO     Training average negative_sample_loss at step 29800: 0.185424\n",
      "2023-12-10 12:25:25,776 INFO     Training average loss at step 29800: 0.197226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 12:26:09,963 INFO     Training average positive_sample_loss at step 29900: 0.201482\n",
      "2023-12-10 12:26:09,964 INFO     Training average negative_sample_loss at step 29900: 0.179916\n",
      "2023-12-10 12:26:09,964 INFO     Training average loss at step 29900: 0.190699\n",
      "2023-12-10 12:27:05,435 INFO     Training average positive_sample_loss at step 30000: 0.206986\n",
      "2023-12-10 12:27:05,435 INFO     Training average negative_sample_loss at step 30000: 0.180131\n",
      "2023-12-10 12:27:05,435 INFO     Training average loss at step 30000: 0.193558\n",
      "2023-12-10 12:27:05,435 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 12:27:06,169 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 12:27:42,142 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 12:28:19,750 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 12:28:26,802 INFO     Valid MRR at step 30000: 0.318148\n",
      "2023-12-10 12:28:26,803 INFO     Valid MR at step 30000: 158.281523\n",
      "2023-12-10 12:28:26,803 INFO     Valid HITS@1 at step 30000: 0.223268\n",
      "2023-12-10 12:28:26,803 INFO     Valid HITS@3 at step 30000: 0.350014\n",
      "2023-12-10 12:28:26,803 INFO     Valid HITS@10 at step 30000: 0.513003\n",
      "2023-12-10 12:29:03,159 INFO     Training average positive_sample_loss at step 30100: 0.208715\n",
      "2023-12-10 12:29:03,160 INFO     Training average negative_sample_loss at step 30100: 0.182189\n",
      "2023-12-10 12:29:03,160 INFO     Training average loss at step 30100: 0.195452\n",
      "2023-12-10 12:29:47,430 INFO     Training average positive_sample_loss at step 30200: 0.210067\n",
      "2023-12-10 12:29:47,430 INFO     Training average negative_sample_loss at step 30200: 0.183096\n",
      "2023-12-10 12:29:47,430 INFO     Training average loss at step 30200: 0.196581\n",
      "2023-12-10 12:30:31,126 INFO     Training average positive_sample_loss at step 30300: 0.210487\n",
      "2023-12-10 12:30:31,127 INFO     Training average negative_sample_loss at step 30300: 0.184689\n",
      "2023-12-10 12:30:31,127 INFO     Training average loss at step 30300: 0.197588\n",
      "2023-12-10 12:31:23,290 INFO     Training average positive_sample_loss at step 30400: 0.201826\n",
      "2023-12-10 12:31:23,290 INFO     Training average negative_sample_loss at step 30400: 0.182493\n",
      "2023-12-10 12:31:23,290 INFO     Training average loss at step 30400: 0.192159\n",
      "2023-12-10 12:32:06,979 INFO     Training average positive_sample_loss at step 30500: 0.206113\n",
      "2023-12-10 12:32:06,980 INFO     Training average negative_sample_loss at step 30500: 0.180469\n",
      "2023-12-10 12:32:06,980 INFO     Training average loss at step 30500: 0.193291\n",
      "2023-12-10 12:32:50,249 INFO     Training average positive_sample_loss at step 30600: 0.208848\n",
      "2023-12-10 12:32:50,249 INFO     Training average negative_sample_loss at step 30600: 0.180715\n",
      "2023-12-10 12:32:50,249 INFO     Training average loss at step 30600: 0.194781\n",
      "2023-12-10 12:33:33,519 INFO     Training average positive_sample_loss at step 30700: 0.209514\n",
      "2023-12-10 12:33:33,520 INFO     Training average negative_sample_loss at step 30700: 0.183006\n",
      "2023-12-10 12:33:33,520 INFO     Training average loss at step 30700: 0.196260\n",
      "2023-12-10 12:34:16,978 INFO     Training average positive_sample_loss at step 30800: 0.211056\n",
      "2023-12-10 12:34:16,978 INFO     Training average negative_sample_loss at step 30800: 0.184012\n",
      "2023-12-10 12:34:16,978 INFO     Training average loss at step 30800: 0.197534\n",
      "2023-12-10 12:35:08,214 INFO     Training average positive_sample_loss at step 30900: 0.203564\n",
      "2023-12-10 12:35:08,214 INFO     Training average negative_sample_loss at step 30900: 0.183623\n",
      "2023-12-10 12:35:08,214 INFO     Training average loss at step 30900: 0.193593\n",
      "2023-12-10 12:35:50,696 INFO     Training average positive_sample_loss at step 31000: 0.203862\n",
      "2023-12-10 12:35:50,696 INFO     Training average negative_sample_loss at step 31000: 0.178668\n",
      "2023-12-10 12:35:50,696 INFO     Training average loss at step 31000: 0.191265\n",
      "2023-12-10 12:36:33,429 INFO     Training average positive_sample_loss at step 31100: 0.208182\n",
      "2023-12-10 12:36:33,429 INFO     Training average negative_sample_loss at step 31100: 0.180867\n",
      "2023-12-10 12:36:33,429 INFO     Training average loss at step 31100: 0.194525\n",
      "2023-12-10 12:37:15,825 INFO     Training average positive_sample_loss at step 31200: 0.209947\n",
      "2023-12-10 12:37:15,826 INFO     Training average negative_sample_loss at step 31200: 0.182605\n",
      "2023-12-10 12:37:15,826 INFO     Training average loss at step 31200: 0.196276\n",
      "2023-12-10 12:37:59,968 INFO     Training average positive_sample_loss at step 31300: 0.209831\n",
      "2023-12-10 12:37:59,969 INFO     Training average negative_sample_loss at step 31300: 0.183419\n",
      "2023-12-10 12:37:59,969 INFO     Training average loss at step 31300: 0.196625\n",
      "2023-12-10 12:38:51,448 INFO     Training average positive_sample_loss at step 31400: 0.208696\n",
      "2023-12-10 12:38:51,449 INFO     Training average negative_sample_loss at step 31400: 0.183920\n",
      "2023-12-10 12:38:51,449 INFO     Training average loss at step 31400: 0.196308\n",
      "2023-12-10 12:39:35,202 INFO     Training average positive_sample_loss at step 31500: 0.200359\n",
      "2023-12-10 12:39:35,203 INFO     Training average negative_sample_loss at step 31500: 0.179651\n",
      "2023-12-10 12:39:35,203 INFO     Training average loss at step 31500: 0.190005\n",
      "2023-12-10 12:40:19,031 INFO     Training average positive_sample_loss at step 31600: 0.206765\n",
      "2023-12-10 12:40:19,031 INFO     Training average negative_sample_loss at step 31600: 0.178814\n",
      "2023-12-10 12:40:19,031 INFO     Training average loss at step 31600: 0.192789\n",
      "2023-12-10 12:41:02,466 INFO     Training average positive_sample_loss at step 31700: 0.209580\n",
      "2023-12-10 12:41:02,466 INFO     Training average negative_sample_loss at step 31700: 0.182804\n",
      "2023-12-10 12:41:02,467 INFO     Training average loss at step 31700: 0.196192\n",
      "2023-12-10 12:41:46,449 INFO     Training average positive_sample_loss at step 31800: 0.210039\n",
      "2023-12-10 12:41:46,449 INFO     Training average negative_sample_loss at step 31800: 0.184022\n",
      "2023-12-10 12:41:46,449 INFO     Training average loss at step 31800: 0.197030\n",
      "2023-12-10 12:42:31,152 INFO     Training average positive_sample_loss at step 31900: 0.211183\n",
      "2023-12-10 12:42:31,152 INFO     Training average negative_sample_loss at step 31900: 0.184692\n",
      "2023-12-10 12:42:31,152 INFO     Training average loss at step 31900: 0.197938\n",
      "2023-12-10 12:43:18,737 INFO     Training average positive_sample_loss at step 32000: 0.201064\n",
      "2023-12-10 12:43:18,737 INFO     Training average negative_sample_loss at step 32000: 0.182627\n",
      "2023-12-10 12:43:18,737 INFO     Training average loss at step 32000: 0.191846\n",
      "2023-12-10 12:44:02,922 INFO     Training average positive_sample_loss at step 32100: 0.205705\n",
      "2023-12-10 12:44:02,922 INFO     Training average negative_sample_loss at step 32100: 0.178593\n",
      "2023-12-10 12:44:02,922 INFO     Training average loss at step 32100: 0.192149\n",
      "2023-12-10 12:44:45,923 INFO     Training average positive_sample_loss at step 32200: 0.208774\n",
      "2023-12-10 12:44:45,923 INFO     Training average negative_sample_loss at step 32200: 0.181304\n",
      "2023-12-10 12:44:45,923 INFO     Training average loss at step 32200: 0.195039\n",
      "2023-12-10 12:45:29,720 INFO     Training average positive_sample_loss at step 32300: 0.209502\n",
      "2023-12-10 12:45:29,720 INFO     Training average negative_sample_loss at step 32300: 0.182608\n",
      "2023-12-10 12:45:29,720 INFO     Training average loss at step 32300: 0.196055\n",
      "2023-12-10 12:46:13,423 INFO     Training average positive_sample_loss at step 32400: 0.210813\n",
      "2023-12-10 12:46:13,423 INFO     Training average negative_sample_loss at step 32400: 0.184187\n",
      "2023-12-10 12:46:13,423 INFO     Training average loss at step 32400: 0.197500\n",
      "2023-12-10 12:47:05,888 INFO     Training average positive_sample_loss at step 32500: 0.202879\n",
      "2023-12-10 12:47:05,889 INFO     Training average negative_sample_loss at step 32500: 0.183186\n",
      "2023-12-10 12:47:05,889 INFO     Training average loss at step 32500: 0.193032\n",
      "2023-12-10 12:47:49,476 INFO     Training average positive_sample_loss at step 32600: 0.204154\n",
      "2023-12-10 12:47:49,477 INFO     Training average negative_sample_loss at step 32600: 0.179030\n",
      "2023-12-10 12:47:49,477 INFO     Training average loss at step 32600: 0.191592\n",
      "2023-12-10 12:48:33,611 INFO     Training average positive_sample_loss at step 32700: 0.207844\n",
      "2023-12-10 12:48:33,611 INFO     Training average negative_sample_loss at step 32700: 0.179688\n",
      "2023-12-10 12:48:33,611 INFO     Training average loss at step 32700: 0.193766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 12:49:17,691 INFO     Training average positive_sample_loss at step 32800: 0.210377\n",
      "2023-12-10 12:49:17,692 INFO     Training average negative_sample_loss at step 32800: 0.182569\n",
      "2023-12-10 12:49:17,692 INFO     Training average loss at step 32800: 0.196473\n",
      "2023-12-10 12:50:00,111 INFO     Training average positive_sample_loss at step 32900: 0.210284\n",
      "2023-12-10 12:50:00,112 INFO     Training average negative_sample_loss at step 32900: 0.184181\n",
      "2023-12-10 12:50:00,112 INFO     Training average loss at step 32900: 0.197232\n",
      "2023-12-10 12:50:54,392 INFO     Training average positive_sample_loss at step 33000: 0.207456\n",
      "2023-12-10 12:50:54,430 INFO     Training average negative_sample_loss at step 33000: 0.183755\n",
      "2023-12-10 12:50:54,430 INFO     Training average loss at step 33000: 0.195605\n",
      "2023-12-10 12:51:38,054 INFO     Training average positive_sample_loss at step 33100: 0.202111\n",
      "2023-12-10 12:51:38,054 INFO     Training average negative_sample_loss at step 33100: 0.179164\n",
      "2023-12-10 12:51:38,054 INFO     Training average loss at step 33100: 0.190637\n",
      "2023-12-10 12:52:22,207 INFO     Training average positive_sample_loss at step 33200: 0.206703\n",
      "2023-12-10 12:52:22,207 INFO     Training average negative_sample_loss at step 33200: 0.179570\n",
      "2023-12-10 12:52:22,207 INFO     Training average loss at step 33200: 0.193136\n",
      "2023-12-10 12:53:06,115 INFO     Training average positive_sample_loss at step 33300: 0.209701\n",
      "2023-12-10 12:53:06,115 INFO     Training average negative_sample_loss at step 33300: 0.181930\n",
      "2023-12-10 12:53:06,115 INFO     Training average loss at step 33300: 0.195816\n",
      "2023-12-10 12:53:49,767 INFO     Training average positive_sample_loss at step 33400: 0.209662\n",
      "2023-12-10 12:53:49,767 INFO     Training average negative_sample_loss at step 33400: 0.183782\n",
      "2023-12-10 12:53:49,767 INFO     Training average loss at step 33400: 0.196722\n",
      "2023-12-10 12:54:33,684 INFO     Training average positive_sample_loss at step 33500: 0.210512\n",
      "2023-12-10 12:54:33,684 INFO     Training average negative_sample_loss at step 33500: 0.183959\n",
      "2023-12-10 12:54:33,684 INFO     Training average loss at step 33500: 0.197236\n",
      "2023-12-10 12:55:26,077 INFO     Training average positive_sample_loss at step 33600: 0.200596\n",
      "2023-12-10 12:55:26,078 INFO     Training average negative_sample_loss at step 33600: 0.181142\n",
      "2023-12-10 12:55:26,078 INFO     Training average loss at step 33600: 0.190869\n",
      "2023-12-10 12:56:09,875 INFO     Training average positive_sample_loss at step 33700: 0.206234\n",
      "2023-12-10 12:56:09,876 INFO     Training average negative_sample_loss at step 33700: 0.179669\n",
      "2023-12-10 12:56:09,876 INFO     Training average loss at step 33700: 0.192951\n",
      "2023-12-10 12:56:53,060 INFO     Training average positive_sample_loss at step 33800: 0.208582\n",
      "2023-12-10 12:56:53,060 INFO     Training average negative_sample_loss at step 33800: 0.181479\n",
      "2023-12-10 12:56:53,060 INFO     Training average loss at step 33800: 0.195031\n",
      "2023-12-10 12:57:37,377 INFO     Training average positive_sample_loss at step 33900: 0.210223\n",
      "2023-12-10 12:57:37,377 INFO     Training average negative_sample_loss at step 33900: 0.181571\n",
      "2023-12-10 12:57:37,378 INFO     Training average loss at step 33900: 0.195897\n",
      "2023-12-10 12:58:20,688 INFO     Training average positive_sample_loss at step 34000: 0.209922\n",
      "2023-12-10 12:58:20,688 INFO     Training average negative_sample_loss at step 34000: 0.183559\n",
      "2023-12-10 12:58:20,688 INFO     Training average loss at step 34000: 0.196741\n",
      "2023-12-10 12:59:11,960 INFO     Training average positive_sample_loss at step 34100: 0.203047\n",
      "2023-12-10 12:59:11,960 INFO     Training average negative_sample_loss at step 34100: 0.183190\n",
      "2023-12-10 12:59:11,960 INFO     Training average loss at step 34100: 0.193118\n",
      "2023-12-10 12:59:54,567 INFO     Training average positive_sample_loss at step 34200: 0.203527\n",
      "2023-12-10 12:59:54,567 INFO     Training average negative_sample_loss at step 34200: 0.178463\n",
      "2023-12-10 12:59:54,567 INFO     Training average loss at step 34200: 0.190995\n",
      "2023-12-10 13:00:38,243 INFO     Training average positive_sample_loss at step 34300: 0.208067\n",
      "2023-12-10 13:00:38,244 INFO     Training average negative_sample_loss at step 34300: 0.180346\n",
      "2023-12-10 13:00:38,244 INFO     Training average loss at step 34300: 0.194206\n",
      "2023-12-10 13:01:23,259 INFO     Training average positive_sample_loss at step 34400: 0.209895\n",
      "2023-12-10 13:01:23,260 INFO     Training average negative_sample_loss at step 34400: 0.181620\n",
      "2023-12-10 13:01:23,260 INFO     Training average loss at step 34400: 0.195758\n",
      "2023-12-10 13:02:07,912 INFO     Training average positive_sample_loss at step 34500: 0.210562\n",
      "2023-12-10 13:02:07,913 INFO     Training average negative_sample_loss at step 34500: 0.182928\n",
      "2023-12-10 13:02:07,913 INFO     Training average loss at step 34500: 0.196745\n",
      "2023-12-10 13:02:56,505 INFO     Training average positive_sample_loss at step 34600: 0.206076\n",
      "2023-12-10 13:02:56,506 INFO     Training average negative_sample_loss at step 34600: 0.183988\n",
      "2023-12-10 13:02:56,506 INFO     Training average loss at step 34600: 0.195032\n",
      "2023-12-10 13:03:38,986 INFO     Training average positive_sample_loss at step 34700: 0.202031\n",
      "2023-12-10 13:03:38,986 INFO     Training average negative_sample_loss at step 34700: 0.179030\n",
      "2023-12-10 13:03:38,986 INFO     Training average loss at step 34700: 0.190530\n",
      "2023-12-10 13:04:22,480 INFO     Training average positive_sample_loss at step 34800: 0.207464\n",
      "2023-12-10 13:04:22,480 INFO     Training average negative_sample_loss at step 34800: 0.180113\n",
      "2023-12-10 13:04:22,480 INFO     Training average loss at step 34800: 0.193788\n",
      "2023-12-10 13:05:04,817 INFO     Training average positive_sample_loss at step 34900: 0.208901\n",
      "2023-12-10 13:05:04,817 INFO     Training average negative_sample_loss at step 34900: 0.182040\n",
      "2023-12-10 13:05:04,817 INFO     Training average loss at step 34900: 0.195471\n",
      "2023-12-10 13:05:47,648 INFO     Training average positive_sample_loss at step 35000: 0.210995\n",
      "2023-12-10 13:05:47,649 INFO     Training average negative_sample_loss at step 35000: 0.183402\n",
      "2023-12-10 13:05:47,649 INFO     Training average loss at step 35000: 0.197198\n",
      "2023-12-10 13:06:32,882 INFO     Training average positive_sample_loss at step 35100: 0.209669\n",
      "2023-12-10 13:06:32,882 INFO     Training average negative_sample_loss at step 35100: 0.184365\n",
      "2023-12-10 13:06:32,883 INFO     Training average loss at step 35100: 0.197017\n",
      "2023-12-10 13:07:24,439 INFO     Training average positive_sample_loss at step 35200: 0.200548\n",
      "2023-12-10 13:07:24,440 INFO     Training average negative_sample_loss at step 35200: 0.181040\n",
      "2023-12-10 13:07:24,440 INFO     Training average loss at step 35200: 0.190794\n",
      "2023-12-10 13:08:09,889 INFO     Training average positive_sample_loss at step 35300: 0.206059\n",
      "2023-12-10 13:08:09,890 INFO     Training average negative_sample_loss at step 35300: 0.179088\n",
      "2023-12-10 13:08:09,890 INFO     Training average loss at step 35300: 0.192574\n",
      "2023-12-10 13:08:53,036 INFO     Training average positive_sample_loss at step 35400: 0.208424\n",
      "2023-12-10 13:08:53,036 INFO     Training average negative_sample_loss at step 35400: 0.180557\n",
      "2023-12-10 13:08:53,036 INFO     Training average loss at step 35400: 0.194491\n",
      "2023-12-10 13:09:36,568 INFO     Training average positive_sample_loss at step 35500: 0.209820\n",
      "2023-12-10 13:09:36,569 INFO     Training average negative_sample_loss at step 35500: 0.181872\n",
      "2023-12-10 13:09:36,569 INFO     Training average loss at step 35500: 0.195846\n",
      "2023-12-10 13:10:21,074 INFO     Training average positive_sample_loss at step 35600: 0.209979\n",
      "2023-12-10 13:10:21,074 INFO     Training average negative_sample_loss at step 35600: 0.184375\n",
      "2023-12-10 13:10:21,074 INFO     Training average loss at step 35600: 0.197177\n",
      "2023-12-10 13:11:11,191 INFO     Training average positive_sample_loss at step 35700: 0.203215\n",
      "2023-12-10 13:11:11,191 INFO     Training average negative_sample_loss at step 35700: 0.182051\n",
      "2023-12-10 13:11:11,191 INFO     Training average loss at step 35700: 0.192633\n",
      "2023-12-10 13:11:54,700 INFO     Training average positive_sample_loss at step 35800: 0.204624\n",
      "2023-12-10 13:11:54,701 INFO     Training average negative_sample_loss at step 35800: 0.179155\n",
      "2023-12-10 13:11:54,701 INFO     Training average loss at step 35800: 0.191890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 13:12:38,112 INFO     Training average positive_sample_loss at step 35900: 0.207744\n",
      "2023-12-10 13:12:38,112 INFO     Training average negative_sample_loss at step 35900: 0.179819\n",
      "2023-12-10 13:12:38,113 INFO     Training average loss at step 35900: 0.193782\n",
      "2023-12-10 13:13:21,392 INFO     Training average positive_sample_loss at step 36000: 0.209889\n",
      "2023-12-10 13:13:21,392 INFO     Training average negative_sample_loss at step 36000: 0.183123\n",
      "2023-12-10 13:13:21,393 INFO     Training average loss at step 36000: 0.196506\n",
      "2023-12-10 13:14:05,393 INFO     Training average positive_sample_loss at step 36100: 0.209979\n",
      "2023-12-10 13:14:05,393 INFO     Training average negative_sample_loss at step 36100: 0.183911\n",
      "2023-12-10 13:14:05,393 INFO     Training average loss at step 36100: 0.196945\n",
      "2023-12-10 13:14:55,504 INFO     Training average positive_sample_loss at step 36200: 0.207420\n",
      "2023-12-10 13:14:55,504 INFO     Training average negative_sample_loss at step 36200: 0.184545\n",
      "2023-12-10 13:14:55,504 INFO     Training average loss at step 36200: 0.195983\n",
      "2023-12-10 13:15:38,744 INFO     Training average positive_sample_loss at step 36300: 0.202150\n",
      "2023-12-10 13:15:38,745 INFO     Training average negative_sample_loss at step 36300: 0.179495\n",
      "2023-12-10 13:15:38,745 INFO     Training average loss at step 36300: 0.190823\n",
      "2023-12-10 13:16:22,505 INFO     Training average positive_sample_loss at step 36400: 0.207233\n",
      "2023-12-10 13:16:22,505 INFO     Training average negative_sample_loss at step 36400: 0.179347\n",
      "2023-12-10 13:16:22,506 INFO     Training average loss at step 36400: 0.193290\n",
      "2023-12-10 13:17:05,878 INFO     Training average positive_sample_loss at step 36500: 0.209163\n",
      "2023-12-10 13:17:05,879 INFO     Training average negative_sample_loss at step 36500: 0.180868\n",
      "2023-12-10 13:17:05,879 INFO     Training average loss at step 36500: 0.195015\n",
      "2023-12-10 13:17:49,122 INFO     Training average positive_sample_loss at step 36600: 0.209776\n",
      "2023-12-10 13:17:49,122 INFO     Training average negative_sample_loss at step 36600: 0.182549\n",
      "2023-12-10 13:17:49,122 INFO     Training average loss at step 36600: 0.196163\n",
      "2023-12-10 13:18:32,684 INFO     Training average positive_sample_loss at step 36700: 0.210483\n",
      "2023-12-10 13:18:32,684 INFO     Training average negative_sample_loss at step 36700: 0.185150\n",
      "2023-12-10 13:18:32,684 INFO     Training average loss at step 36700: 0.197817\n",
      "2023-12-10 13:19:25,660 INFO     Training average positive_sample_loss at step 36800: 0.200043\n",
      "2023-12-10 13:19:25,661 INFO     Training average negative_sample_loss at step 36800: 0.179998\n",
      "2023-12-10 13:19:25,661 INFO     Training average loss at step 36800: 0.190021\n",
      "2023-12-10 13:20:09,054 INFO     Training average positive_sample_loss at step 36900: 0.206148\n",
      "2023-12-10 13:20:09,055 INFO     Training average negative_sample_loss at step 36900: 0.178480\n",
      "2023-12-10 13:20:09,055 INFO     Training average loss at step 36900: 0.192314\n",
      "2023-12-10 13:20:52,709 INFO     Training average positive_sample_loss at step 37000: 0.207906\n",
      "2023-12-10 13:20:52,710 INFO     Training average negative_sample_loss at step 37000: 0.180286\n",
      "2023-12-10 13:20:52,710 INFO     Training average loss at step 37000: 0.194096\n",
      "2023-12-10 13:21:36,596 INFO     Training average positive_sample_loss at step 37100: 0.210142\n",
      "2023-12-10 13:21:36,597 INFO     Training average negative_sample_loss at step 37100: 0.182923\n",
      "2023-12-10 13:21:36,597 INFO     Training average loss at step 37100: 0.196532\n",
      "2023-12-10 13:22:19,872 INFO     Training average positive_sample_loss at step 37200: 0.211307\n",
      "2023-12-10 13:22:19,872 INFO     Training average negative_sample_loss at step 37200: 0.184597\n",
      "2023-12-10 13:22:19,872 INFO     Training average loss at step 37200: 0.197952\n",
      "2023-12-10 13:23:08,267 INFO     Training average positive_sample_loss at step 37300: 0.201967\n",
      "2023-12-10 13:23:08,267 INFO     Training average negative_sample_loss at step 37300: 0.181742\n",
      "2023-12-10 13:23:08,267 INFO     Training average loss at step 37300: 0.191854\n",
      "2023-12-10 13:23:51,923 INFO     Training average positive_sample_loss at step 37400: 0.203883\n",
      "2023-12-10 13:23:51,924 INFO     Training average negative_sample_loss at step 37400: 0.178456\n",
      "2023-12-10 13:23:51,924 INFO     Training average loss at step 37400: 0.191170\n",
      "2023-12-10 13:24:35,882 INFO     Training average positive_sample_loss at step 37500: 0.208927\n",
      "2023-12-10 13:24:35,882 INFO     Training average negative_sample_loss at step 37500: 0.181526\n",
      "2023-12-10 13:24:35,882 INFO     Training average loss at step 37500: 0.195227\n",
      "2023-12-10 13:25:19,801 INFO     Training average positive_sample_loss at step 37600: 0.209968\n",
      "2023-12-10 13:25:19,802 INFO     Training average negative_sample_loss at step 37600: 0.181827\n",
      "2023-12-10 13:25:19,802 INFO     Training average loss at step 37600: 0.195898\n",
      "2023-12-10 13:26:05,387 INFO     Training average positive_sample_loss at step 37700: 0.211128\n",
      "2023-12-10 13:26:05,387 INFO     Training average negative_sample_loss at step 37700: 0.184428\n",
      "2023-12-10 13:26:05,387 INFO     Training average loss at step 37700: 0.197778\n",
      "2023-12-10 13:26:57,792 INFO     Training average positive_sample_loss at step 37800: 0.205413\n",
      "2023-12-10 13:26:57,792 INFO     Training average negative_sample_loss at step 37800: 0.183083\n",
      "2023-12-10 13:26:57,792 INFO     Training average loss at step 37800: 0.194248\n",
      "2023-12-10 13:27:41,073 INFO     Training average positive_sample_loss at step 37900: 0.202686\n",
      "2023-12-10 13:27:41,074 INFO     Training average negative_sample_loss at step 37900: 0.177688\n",
      "2023-12-10 13:27:41,074 INFO     Training average loss at step 37900: 0.190187\n",
      "2023-12-10 13:28:26,234 INFO     Training average positive_sample_loss at step 38000: 0.207441\n",
      "2023-12-10 13:28:26,234 INFO     Training average negative_sample_loss at step 38000: 0.180153\n",
      "2023-12-10 13:28:26,234 INFO     Training average loss at step 38000: 0.193797\n",
      "2023-12-10 13:29:10,185 INFO     Training average positive_sample_loss at step 38100: 0.208411\n",
      "2023-12-10 13:29:10,185 INFO     Training average negative_sample_loss at step 38100: 0.180984\n",
      "2023-12-10 13:29:10,185 INFO     Training average loss at step 38100: 0.194698\n",
      "2023-12-10 13:29:52,894 INFO     Training average positive_sample_loss at step 38200: 0.209361\n",
      "2023-12-10 13:29:52,894 INFO     Training average negative_sample_loss at step 38200: 0.182777\n",
      "2023-12-10 13:29:52,894 INFO     Training average loss at step 38200: 0.196069\n",
      "2023-12-10 13:30:37,243 INFO     Training average positive_sample_loss at step 38300: 0.210644\n",
      "2023-12-10 13:30:37,244 INFO     Training average negative_sample_loss at step 38300: 0.183364\n",
      "2023-12-10 13:30:37,244 INFO     Training average loss at step 38300: 0.197004\n",
      "2023-12-10 13:31:27,102 INFO     Training average positive_sample_loss at step 38400: 0.199905\n",
      "2023-12-10 13:31:27,102 INFO     Training average negative_sample_loss at step 38400: 0.180411\n",
      "2023-12-10 13:31:27,102 INFO     Training average loss at step 38400: 0.190158\n",
      "2023-12-10 13:32:10,543 INFO     Training average positive_sample_loss at step 38500: 0.206530\n",
      "2023-12-10 13:32:10,543 INFO     Training average negative_sample_loss at step 38500: 0.179412\n",
      "2023-12-10 13:32:10,543 INFO     Training average loss at step 38500: 0.192971\n",
      "2023-12-10 13:32:54,896 INFO     Training average positive_sample_loss at step 38600: 0.208026\n",
      "2023-12-10 13:32:54,896 INFO     Training average negative_sample_loss at step 38600: 0.180779\n",
      "2023-12-10 13:32:54,896 INFO     Training average loss at step 38600: 0.194403\n",
      "2023-12-10 13:33:38,507 INFO     Training average positive_sample_loss at step 38700: 0.209800\n",
      "2023-12-10 13:33:38,507 INFO     Training average negative_sample_loss at step 38700: 0.181865\n",
      "2023-12-10 13:33:38,507 INFO     Training average loss at step 38700: 0.195832\n",
      "2023-12-10 13:34:22,177 INFO     Training average positive_sample_loss at step 38800: 0.210385\n",
      "2023-12-10 13:34:22,178 INFO     Training average negative_sample_loss at step 38800: 0.183822\n",
      "2023-12-10 13:34:22,178 INFO     Training average loss at step 38800: 0.197103\n",
      "2023-12-10 13:35:12,822 INFO     Training average positive_sample_loss at step 38900: 0.201089\n",
      "2023-12-10 13:35:12,822 INFO     Training average negative_sample_loss at step 38900: 0.180318\n",
      "2023-12-10 13:35:12,822 INFO     Training average loss at step 38900: 0.190703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 13:35:56,675 INFO     Training average positive_sample_loss at step 39000: 0.204884\n",
      "2023-12-10 13:35:56,675 INFO     Training average negative_sample_loss at step 39000: 0.178464\n",
      "2023-12-10 13:35:56,675 INFO     Training average loss at step 39000: 0.191674\n",
      "2023-12-10 13:36:39,769 INFO     Training average positive_sample_loss at step 39100: 0.208343\n",
      "2023-12-10 13:36:39,770 INFO     Training average negative_sample_loss at step 39100: 0.180230\n",
      "2023-12-10 13:36:39,770 INFO     Training average loss at step 39100: 0.194286\n",
      "2023-12-10 13:37:23,418 INFO     Training average positive_sample_loss at step 39200: 0.209682\n",
      "2023-12-10 13:37:23,419 INFO     Training average negative_sample_loss at step 39200: 0.181920\n",
      "2023-12-10 13:37:23,419 INFO     Training average loss at step 39200: 0.195801\n",
      "2023-12-10 13:38:07,071 INFO     Training average positive_sample_loss at step 39300: 0.210512\n",
      "2023-12-10 13:38:07,071 INFO     Training average negative_sample_loss at step 39300: 0.183979\n",
      "2023-12-10 13:38:07,071 INFO     Training average loss at step 39300: 0.197245\n",
      "2023-12-10 13:38:58,259 INFO     Training average positive_sample_loss at step 39400: 0.205172\n",
      "2023-12-10 13:38:58,259 INFO     Training average negative_sample_loss at step 39400: 0.183032\n",
      "2023-12-10 13:38:58,259 INFO     Training average loss at step 39400: 0.194102\n",
      "2023-12-10 13:39:41,500 INFO     Training average positive_sample_loss at step 39500: 0.202693\n",
      "2023-12-10 13:39:41,501 INFO     Training average negative_sample_loss at step 39500: 0.178547\n",
      "2023-12-10 13:39:41,501 INFO     Training average loss at step 39500: 0.190620\n",
      "2023-12-10 13:40:24,181 INFO     Training average positive_sample_loss at step 39600: 0.207032\n",
      "2023-12-10 13:40:24,182 INFO     Training average negative_sample_loss at step 39600: 0.178438\n",
      "2023-12-10 13:40:24,182 INFO     Training average loss at step 39600: 0.192735\n",
      "2023-12-10 13:41:06,749 INFO     Training average positive_sample_loss at step 39700: 0.208821\n",
      "2023-12-10 13:41:06,749 INFO     Training average negative_sample_loss at step 39700: 0.180756\n",
      "2023-12-10 13:41:06,750 INFO     Training average loss at step 39700: 0.194789\n",
      "2023-12-10 13:41:51,504 INFO     Training average positive_sample_loss at step 39800: 0.210299\n",
      "2023-12-10 13:41:51,505 INFO     Training average negative_sample_loss at step 39800: 0.182793\n",
      "2023-12-10 13:41:51,505 INFO     Training average loss at step 39800: 0.196546\n",
      "2023-12-10 13:42:39,181 INFO     Training average positive_sample_loss at step 39900: 0.209893\n",
      "2023-12-10 13:42:39,182 INFO     Training average negative_sample_loss at step 39900: 0.183894\n",
      "2023-12-10 13:42:39,182 INFO     Training average loss at step 39900: 0.196894\n",
      "2023-12-10 13:43:35,173 INFO     Training average positive_sample_loss at step 40000: 0.199731\n",
      "2023-12-10 13:43:35,173 INFO     Training average negative_sample_loss at step 40000: 0.179191\n",
      "2023-12-10 13:43:35,174 INFO     Training average loss at step 40000: 0.189461\n",
      "2023-12-10 13:43:35,174 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 13:43:35,725 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 13:44:13,652 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 13:44:49,409 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 13:44:56,099 INFO     Valid MRR at step 40000: 0.317597\n",
      "2023-12-10 13:44:56,099 INFO     Valid MR at step 40000: 158.184973\n",
      "2023-12-10 13:44:56,099 INFO     Valid HITS@1 at step 40000: 0.223353\n",
      "2023-12-10 13:44:56,099 INFO     Valid HITS@3 at step 40000: 0.349244\n",
      "2023-12-10 13:44:56,100 INFO     Valid HITS@10 at step 40000: 0.509666\n",
      "2023-12-10 13:45:32,886 INFO     Training average positive_sample_loss at step 40100: 0.206378\n",
      "2023-12-10 13:45:32,886 INFO     Training average negative_sample_loss at step 40100: 0.179031\n",
      "2023-12-10 13:45:32,886 INFO     Training average loss at step 40100: 0.192704\n",
      "2023-12-10 13:46:16,783 INFO     Training average positive_sample_loss at step 40200: 0.208237\n",
      "2023-12-10 13:46:16,784 INFO     Training average negative_sample_loss at step 40200: 0.179373\n",
      "2023-12-10 13:46:16,784 INFO     Training average loss at step 40200: 0.193805\n",
      "2023-12-10 13:47:01,349 INFO     Training average positive_sample_loss at step 40300: 0.209276\n",
      "2023-12-10 13:47:01,349 INFO     Training average negative_sample_loss at step 40300: 0.181346\n",
      "2023-12-10 13:47:01,349 INFO     Training average loss at step 40300: 0.195311\n",
      "2023-12-10 13:47:45,006 INFO     Training average positive_sample_loss at step 40400: 0.210296\n",
      "2023-12-10 13:47:45,007 INFO     Training average negative_sample_loss at step 40400: 0.183529\n",
      "2023-12-10 13:47:45,007 INFO     Training average loss at step 40400: 0.196913\n",
      "2023-12-10 13:48:34,382 INFO     Training average positive_sample_loss at step 40500: 0.201230\n",
      "2023-12-10 13:48:34,383 INFO     Training average negative_sample_loss at step 40500: 0.181160\n",
      "2023-12-10 13:48:34,383 INFO     Training average loss at step 40500: 0.191195\n",
      "2023-12-10 13:49:18,964 INFO     Training average positive_sample_loss at step 40600: 0.204757\n",
      "2023-12-10 13:49:18,965 INFO     Training average negative_sample_loss at step 40600: 0.177597\n",
      "2023-12-10 13:49:18,965 INFO     Training average loss at step 40600: 0.191177\n",
      "2023-12-10 13:50:03,513 INFO     Training average positive_sample_loss at step 40700: 0.208842\n",
      "2023-12-10 13:50:03,513 INFO     Training average negative_sample_loss at step 40700: 0.180626\n",
      "2023-12-10 13:50:03,513 INFO     Training average loss at step 40700: 0.194734\n",
      "2023-12-10 13:50:47,486 INFO     Training average positive_sample_loss at step 40800: 0.209527\n",
      "2023-12-10 13:50:47,486 INFO     Training average negative_sample_loss at step 40800: 0.182087\n",
      "2023-12-10 13:50:47,486 INFO     Training average loss at step 40800: 0.195807\n",
      "2023-12-10 13:51:29,824 INFO     Training average positive_sample_loss at step 40900: 0.209625\n",
      "2023-12-10 13:51:29,824 INFO     Training average negative_sample_loss at step 40900: 0.182684\n",
      "2023-12-10 13:51:29,825 INFO     Training average loss at step 40900: 0.196154\n",
      "2023-12-10 13:52:21,359 INFO     Training average positive_sample_loss at step 41000: 0.205562\n",
      "2023-12-10 13:52:21,359 INFO     Training average negative_sample_loss at step 41000: 0.183166\n",
      "2023-12-10 13:52:21,359 INFO     Training average loss at step 41000: 0.194364\n",
      "2023-12-10 13:53:05,033 INFO     Training average positive_sample_loss at step 41100: 0.203329\n",
      "2023-12-10 13:53:05,034 INFO     Training average negative_sample_loss at step 41100: 0.179034\n",
      "2023-12-10 13:53:05,034 INFO     Training average loss at step 41100: 0.191181\n",
      "2023-12-10 13:53:48,207 INFO     Training average positive_sample_loss at step 41200: 0.207463\n",
      "2023-12-10 13:53:48,207 INFO     Training average negative_sample_loss at step 41200: 0.178740\n",
      "2023-12-10 13:53:48,207 INFO     Training average loss at step 41200: 0.193102\n",
      "2023-12-10 13:54:31,980 INFO     Training average positive_sample_loss at step 41300: 0.208068\n",
      "2023-12-10 13:54:31,980 INFO     Training average negative_sample_loss at step 41300: 0.180794\n",
      "2023-12-10 13:54:31,981 INFO     Training average loss at step 41300: 0.194431\n",
      "2023-12-10 13:55:15,652 INFO     Training average positive_sample_loss at step 41400: 0.210490\n",
      "2023-12-10 13:55:15,652 INFO     Training average negative_sample_loss at step 41400: 0.183292\n",
      "2023-12-10 13:55:15,653 INFO     Training average loss at step 41400: 0.196891\n",
      "2023-12-10 13:56:04,397 INFO     Training average positive_sample_loss at step 41500: 0.209484\n",
      "2023-12-10 13:56:04,397 INFO     Training average negative_sample_loss at step 41500: 0.183710\n",
      "2023-12-10 13:56:04,398 INFO     Training average loss at step 41500: 0.196597\n",
      "2023-12-10 13:56:49,583 INFO     Training average positive_sample_loss at step 41600: 0.200996\n",
      "2023-12-10 13:56:49,583 INFO     Training average negative_sample_loss at step 41600: 0.179075\n",
      "2023-12-10 13:56:49,583 INFO     Training average loss at step 41600: 0.190036\n",
      "2023-12-10 13:57:33,510 INFO     Training average positive_sample_loss at step 41700: 0.206361\n",
      "2023-12-10 13:57:33,511 INFO     Training average negative_sample_loss at step 41700: 0.179755\n",
      "2023-12-10 13:57:33,511 INFO     Training average loss at step 41700: 0.193058\n",
      "2023-12-10 13:58:17,957 INFO     Training average positive_sample_loss at step 41800: 0.208446\n",
      "2023-12-10 13:58:17,958 INFO     Training average negative_sample_loss at step 41800: 0.180498\n",
      "2023-12-10 13:58:17,958 INFO     Training average loss at step 41800: 0.194472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 13:59:01,632 INFO     Training average positive_sample_loss at step 41900: 0.210052\n",
      "2023-12-10 13:59:01,633 INFO     Training average negative_sample_loss at step 41900: 0.182741\n",
      "2023-12-10 13:59:01,633 INFO     Training average loss at step 41900: 0.196396\n",
      "2023-12-10 13:59:45,927 INFO     Training average positive_sample_loss at step 42000: 0.210230\n",
      "2023-12-10 13:59:45,927 INFO     Training average negative_sample_loss at step 42000: 0.183311\n",
      "2023-12-10 13:59:45,927 INFO     Training average loss at step 42000: 0.196770\n",
      "2023-12-10 14:00:37,708 INFO     Training average positive_sample_loss at step 42100: 0.200913\n",
      "2023-12-10 14:00:37,709 INFO     Training average negative_sample_loss at step 42100: 0.181141\n",
      "2023-12-10 14:00:37,709 INFO     Training average loss at step 42100: 0.191027\n",
      "2023-12-10 14:01:22,299 INFO     Training average positive_sample_loss at step 42200: 0.205906\n",
      "2023-12-10 14:01:22,299 INFO     Training average negative_sample_loss at step 42200: 0.177988\n",
      "2023-12-10 14:01:22,299 INFO     Training average loss at step 42200: 0.191947\n",
      "2023-12-10 14:02:05,974 INFO     Training average positive_sample_loss at step 42300: 0.207732\n",
      "2023-12-10 14:02:05,975 INFO     Training average negative_sample_loss at step 42300: 0.179783\n",
      "2023-12-10 14:02:05,975 INFO     Training average loss at step 42300: 0.193757\n",
      "2023-12-10 14:02:49,675 INFO     Training average positive_sample_loss at step 42400: 0.210041\n",
      "2023-12-10 14:02:49,675 INFO     Training average negative_sample_loss at step 42400: 0.181175\n",
      "2023-12-10 14:02:49,676 INFO     Training average loss at step 42400: 0.195608\n",
      "2023-12-10 14:03:33,398 INFO     Training average positive_sample_loss at step 42500: 0.209031\n",
      "2023-12-10 14:03:33,399 INFO     Training average negative_sample_loss at step 42500: 0.182332\n",
      "2023-12-10 14:03:33,399 INFO     Training average loss at step 42500: 0.195682\n",
      "2023-12-10 14:04:20,904 INFO     Training average positive_sample_loss at step 42600: 0.204597\n",
      "2023-12-10 14:04:20,905 INFO     Training average negative_sample_loss at step 42600: 0.183833\n",
      "2023-12-10 14:04:20,905 INFO     Training average loss at step 42600: 0.194215\n",
      "2023-12-10 14:05:04,062 INFO     Training average positive_sample_loss at step 42700: 0.203522\n",
      "2023-12-10 14:05:04,062 INFO     Training average negative_sample_loss at step 42700: 0.177741\n",
      "2023-12-10 14:05:04,062 INFO     Training average loss at step 42700: 0.190632\n",
      "2023-12-10 14:05:46,692 INFO     Training average positive_sample_loss at step 42800: 0.207380\n",
      "2023-12-10 14:05:46,693 INFO     Training average negative_sample_loss at step 42800: 0.179185\n",
      "2023-12-10 14:05:46,693 INFO     Training average loss at step 42800: 0.193283\n",
      "2023-12-10 14:06:31,488 INFO     Training average positive_sample_loss at step 42900: 0.209853\n",
      "2023-12-10 14:06:31,488 INFO     Training average negative_sample_loss at step 42900: 0.181293\n",
      "2023-12-10 14:06:31,488 INFO     Training average loss at step 42900: 0.195573\n",
      "2023-12-10 14:07:15,673 INFO     Training average positive_sample_loss at step 43000: 0.209709\n",
      "2023-12-10 14:07:15,673 INFO     Training average negative_sample_loss at step 43000: 0.183770\n",
      "2023-12-10 14:07:15,673 INFO     Training average loss at step 43000: 0.196739\n",
      "2023-12-10 14:08:03,583 INFO     Training average positive_sample_loss at step 43100: 0.208799\n",
      "2023-12-10 14:08:03,583 INFO     Training average negative_sample_loss at step 43100: 0.182161\n",
      "2023-12-10 14:08:03,583 INFO     Training average loss at step 43100: 0.195480\n",
      "2023-12-10 14:08:47,330 INFO     Training average positive_sample_loss at step 43200: 0.200105\n",
      "2023-12-10 14:08:47,330 INFO     Training average negative_sample_loss at step 43200: 0.177916\n",
      "2023-12-10 14:08:47,330 INFO     Training average loss at step 43200: 0.189010\n",
      "2023-12-10 14:09:31,061 INFO     Training average positive_sample_loss at step 43300: 0.206613\n",
      "2023-12-10 14:09:31,061 INFO     Training average negative_sample_loss at step 43300: 0.178859\n",
      "2023-12-10 14:09:31,061 INFO     Training average loss at step 43300: 0.192736\n",
      "2023-12-10 14:10:15,234 INFO     Training average positive_sample_loss at step 43400: 0.208495\n",
      "2023-12-10 14:10:15,234 INFO     Training average negative_sample_loss at step 43400: 0.180339\n",
      "2023-12-10 14:10:15,234 INFO     Training average loss at step 43400: 0.194417\n",
      "2023-12-10 14:10:59,681 INFO     Training average positive_sample_loss at step 43500: 0.209825\n",
      "2023-12-10 14:10:59,681 INFO     Training average negative_sample_loss at step 43500: 0.182703\n",
      "2023-12-10 14:10:59,681 INFO     Training average loss at step 43500: 0.196264\n",
      "2023-12-10 14:11:43,209 INFO     Training average positive_sample_loss at step 43600: 0.210346\n",
      "2023-12-10 14:11:43,209 INFO     Training average negative_sample_loss at step 43600: 0.182711\n",
      "2023-12-10 14:11:43,209 INFO     Training average loss at step 43600: 0.196528\n",
      "2023-12-10 14:12:34,824 INFO     Training average positive_sample_loss at step 43700: 0.200570\n",
      "2023-12-10 14:12:34,824 INFO     Training average negative_sample_loss at step 43700: 0.180438\n",
      "2023-12-10 14:12:34,824 INFO     Training average loss at step 43700: 0.190504\n",
      "2023-12-10 14:13:18,559 INFO     Training average positive_sample_loss at step 43800: 0.205770\n",
      "2023-12-10 14:13:18,559 INFO     Training average negative_sample_loss at step 43800: 0.178272\n",
      "2023-12-10 14:13:18,560 INFO     Training average loss at step 43800: 0.192021\n",
      "2023-12-10 14:14:02,371 INFO     Training average positive_sample_loss at step 43900: 0.208156\n",
      "2023-12-10 14:14:02,372 INFO     Training average negative_sample_loss at step 43900: 0.180249\n",
      "2023-12-10 14:14:02,372 INFO     Training average loss at step 43900: 0.194202\n",
      "2023-12-10 14:14:46,645 INFO     Training average positive_sample_loss at step 44000: 0.209779\n",
      "2023-12-10 14:14:46,646 INFO     Training average negative_sample_loss at step 44000: 0.181831\n",
      "2023-12-10 14:14:46,646 INFO     Training average loss at step 44000: 0.195805\n",
      "2023-12-10 14:15:30,002 INFO     Training average positive_sample_loss at step 44100: 0.210151\n",
      "2023-12-10 14:15:30,002 INFO     Training average negative_sample_loss at step 44100: 0.182587\n",
      "2023-12-10 14:15:30,002 INFO     Training average loss at step 44100: 0.196369\n",
      "2023-12-10 14:16:22,554 INFO     Training average positive_sample_loss at step 44200: 0.204197\n",
      "2023-12-10 14:16:22,554 INFO     Training average negative_sample_loss at step 44200: 0.181949\n",
      "2023-12-10 14:16:22,554 INFO     Training average loss at step 44200: 0.193073\n",
      "2023-12-10 14:17:05,440 INFO     Training average positive_sample_loss at step 44300: 0.203971\n",
      "2023-12-10 14:17:05,441 INFO     Training average negative_sample_loss at step 44300: 0.178385\n",
      "2023-12-10 14:17:05,441 INFO     Training average loss at step 44300: 0.191178\n",
      "2023-12-10 14:17:48,639 INFO     Training average positive_sample_loss at step 44400: 0.207399\n",
      "2023-12-10 14:17:48,640 INFO     Training average negative_sample_loss at step 44400: 0.179666\n",
      "2023-12-10 14:17:48,640 INFO     Training average loss at step 44400: 0.193532\n",
      "2023-12-10 14:18:32,379 INFO     Training average positive_sample_loss at step 44500: 0.208849\n",
      "2023-12-10 14:18:32,380 INFO     Training average negative_sample_loss at step 44500: 0.180599\n",
      "2023-12-10 14:18:32,380 INFO     Training average loss at step 44500: 0.194724\n",
      "2023-12-10 14:19:15,306 INFO     Training average positive_sample_loss at step 44600: 0.209583\n",
      "2023-12-10 14:19:15,306 INFO     Training average negative_sample_loss at step 44600: 0.181344\n",
      "2023-12-10 14:19:15,306 INFO     Training average loss at step 44600: 0.195464\n",
      "2023-12-10 14:20:09,244 INFO     Training average positive_sample_loss at step 44700: 0.207351\n",
      "2023-12-10 14:20:09,244 INFO     Training average negative_sample_loss at step 44700: 0.182145\n",
      "2023-12-10 14:20:09,244 INFO     Training average loss at step 44700: 0.194748\n",
      "2023-12-10 14:20:53,965 INFO     Training average positive_sample_loss at step 44800: 0.200522\n",
      "2023-12-10 14:20:53,965 INFO     Training average negative_sample_loss at step 44800: 0.177878\n",
      "2023-12-10 14:20:53,965 INFO     Training average loss at step 44800: 0.189200\n",
      "2023-12-10 14:21:39,373 INFO     Training average positive_sample_loss at step 44900: 0.206660\n",
      "2023-12-10 14:21:39,373 INFO     Training average negative_sample_loss at step 44900: 0.178306\n",
      "2023-12-10 14:21:39,373 INFO     Training average loss at step 44900: 0.192483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 14:22:23,584 INFO     Training average positive_sample_loss at step 45000: 0.208499\n",
      "2023-12-10 14:22:23,585 INFO     Training average negative_sample_loss at step 45000: 0.180488\n",
      "2023-12-10 14:22:23,585 INFO     Training average loss at step 45000: 0.194494\n",
      "2023-12-10 14:23:08,131 INFO     Training average positive_sample_loss at step 45100: 0.209231\n",
      "2023-12-10 14:23:08,131 INFO     Training average negative_sample_loss at step 45100: 0.182453\n",
      "2023-12-10 14:23:08,131 INFO     Training average loss at step 45100: 0.195842\n",
      "2023-12-10 14:23:52,507 INFO     Training average positive_sample_loss at step 45200: 0.211317\n",
      "2023-12-10 14:23:52,508 INFO     Training average negative_sample_loss at step 45200: 0.182917\n",
      "2023-12-10 14:23:52,508 INFO     Training average loss at step 45200: 0.197117\n",
      "2023-12-10 14:24:41,201 INFO     Training average positive_sample_loss at step 45300: 0.200089\n",
      "2023-12-10 14:24:41,202 INFO     Training average negative_sample_loss at step 45300: 0.180128\n",
      "2023-12-10 14:24:41,202 INFO     Training average loss at step 45300: 0.190108\n",
      "2023-12-10 14:25:25,289 INFO     Training average positive_sample_loss at step 45400: 0.205387\n",
      "2023-12-10 14:25:25,289 INFO     Training average negative_sample_loss at step 45400: 0.178183\n",
      "2023-12-10 14:25:25,289 INFO     Training average loss at step 45400: 0.191785\n",
      "2023-12-10 14:26:08,913 INFO     Training average positive_sample_loss at step 45500: 0.208481\n",
      "2023-12-10 14:26:08,913 INFO     Training average negative_sample_loss at step 45500: 0.179513\n",
      "2023-12-10 14:26:08,913 INFO     Training average loss at step 45500: 0.193997\n",
      "2023-12-10 14:26:51,937 INFO     Training average positive_sample_loss at step 45600: 0.209030\n",
      "2023-12-10 14:26:51,937 INFO     Training average negative_sample_loss at step 45600: 0.181545\n",
      "2023-12-10 14:26:51,938 INFO     Training average loss at step 45600: 0.195287\n",
      "2023-12-10 14:27:36,386 INFO     Training average positive_sample_loss at step 45700: 0.209913\n",
      "2023-12-10 14:27:36,386 INFO     Training average negative_sample_loss at step 45700: 0.182289\n",
      "2023-12-10 14:27:36,386 INFO     Training average loss at step 45700: 0.196101\n",
      "2023-12-10 14:28:25,142 INFO     Training average positive_sample_loss at step 45800: 0.202815\n",
      "2023-12-10 14:28:25,142 INFO     Training average negative_sample_loss at step 45800: 0.181494\n",
      "2023-12-10 14:28:25,142 INFO     Training average loss at step 45800: 0.192155\n",
      "2023-12-10 14:29:07,897 INFO     Training average positive_sample_loss at step 45900: 0.203773\n",
      "2023-12-10 14:29:07,897 INFO     Training average negative_sample_loss at step 45900: 0.178322\n",
      "2023-12-10 14:29:07,897 INFO     Training average loss at step 45900: 0.191048\n",
      "2023-12-10 14:29:52,519 INFO     Training average positive_sample_loss at step 46000: 0.208545\n",
      "2023-12-10 14:29:52,520 INFO     Training average negative_sample_loss at step 46000: 0.179717\n",
      "2023-12-10 14:29:52,520 INFO     Training average loss at step 46000: 0.194131\n",
      "2023-12-10 14:30:35,933 INFO     Training average positive_sample_loss at step 46100: 0.208673\n",
      "2023-12-10 14:30:35,934 INFO     Training average negative_sample_loss at step 46100: 0.180313\n",
      "2023-12-10 14:30:35,934 INFO     Training average loss at step 46100: 0.194493\n",
      "2023-12-10 14:31:19,408 INFO     Training average positive_sample_loss at step 46200: 0.209430\n",
      "2023-12-10 14:31:19,409 INFO     Training average negative_sample_loss at step 46200: 0.181782\n",
      "2023-12-10 14:31:19,409 INFO     Training average loss at step 46200: 0.195606\n",
      "2023-12-10 14:32:09,006 INFO     Training average positive_sample_loss at step 46300: 0.206612\n",
      "2023-12-10 14:32:09,007 INFO     Training average negative_sample_loss at step 46300: 0.182145\n",
      "2023-12-10 14:32:09,007 INFO     Training average loss at step 46300: 0.194378\n",
      "2023-12-10 14:32:52,894 INFO     Training average positive_sample_loss at step 46400: 0.200654\n",
      "2023-12-10 14:32:52,894 INFO     Training average negative_sample_loss at step 46400: 0.178082\n",
      "2023-12-10 14:32:52,894 INFO     Training average loss at step 46400: 0.189368\n",
      "2023-12-10 14:33:36,393 INFO     Training average positive_sample_loss at step 46500: 0.206677\n",
      "2023-12-10 14:33:36,393 INFO     Training average negative_sample_loss at step 46500: 0.178339\n",
      "2023-12-10 14:33:36,394 INFO     Training average loss at step 46500: 0.192508\n",
      "2023-12-10 14:34:19,605 INFO     Training average positive_sample_loss at step 46600: 0.209513\n",
      "2023-12-10 14:34:19,606 INFO     Training average negative_sample_loss at step 46600: 0.180753\n",
      "2023-12-10 14:34:19,606 INFO     Training average loss at step 46600: 0.195133\n",
      "2023-12-10 14:35:03,552 INFO     Training average positive_sample_loss at step 46700: 0.209668\n",
      "2023-12-10 14:35:03,552 INFO     Training average negative_sample_loss at step 46700: 0.181646\n",
      "2023-12-10 14:35:03,552 INFO     Training average loss at step 46700: 0.195657\n",
      "2023-12-10 14:35:46,488 INFO     Training average positive_sample_loss at step 46800: 0.210296\n",
      "2023-12-10 14:35:46,489 INFO     Training average negative_sample_loss at step 46800: 0.183337\n",
      "2023-12-10 14:35:46,489 INFO     Training average loss at step 46800: 0.196817\n",
      "2023-12-10 14:36:37,261 INFO     Training average positive_sample_loss at step 46900: 0.200201\n",
      "2023-12-10 14:36:37,261 INFO     Training average negative_sample_loss at step 46900: 0.179999\n",
      "2023-12-10 14:36:37,261 INFO     Training average loss at step 46900: 0.190100\n",
      "2023-12-10 14:37:21,579 INFO     Training average positive_sample_loss at step 47000: 0.205927\n",
      "2023-12-10 14:37:21,579 INFO     Training average negative_sample_loss at step 47000: 0.177567\n",
      "2023-12-10 14:37:21,579 INFO     Training average loss at step 47000: 0.191747\n",
      "2023-12-10 14:38:04,412 INFO     Training average positive_sample_loss at step 47100: 0.207784\n",
      "2023-12-10 14:38:04,412 INFO     Training average negative_sample_loss at step 47100: 0.179025\n",
      "2023-12-10 14:38:04,413 INFO     Training average loss at step 47100: 0.193404\n",
      "2023-12-10 14:38:48,467 INFO     Training average positive_sample_loss at step 47200: 0.209119\n",
      "2023-12-10 14:38:48,467 INFO     Training average negative_sample_loss at step 47200: 0.181673\n",
      "2023-12-10 14:38:48,467 INFO     Training average loss at step 47200: 0.195396\n",
      "2023-12-10 14:39:32,059 INFO     Training average positive_sample_loss at step 47300: 0.210198\n",
      "2023-12-10 14:39:32,060 INFO     Training average negative_sample_loss at step 47300: 0.182611\n",
      "2023-12-10 14:39:32,060 INFO     Training average loss at step 47300: 0.196404\n",
      "2023-12-10 14:40:22,179 INFO     Training average positive_sample_loss at step 47400: 0.202554\n",
      "2023-12-10 14:40:22,179 INFO     Training average negative_sample_loss at step 47400: 0.181533\n",
      "2023-12-10 14:40:22,179 INFO     Training average loss at step 47400: 0.192043\n",
      "2023-12-10 14:41:05,897 INFO     Training average positive_sample_loss at step 47500: 0.204229\n",
      "2023-12-10 14:41:05,898 INFO     Training average negative_sample_loss at step 47500: 0.177638\n",
      "2023-12-10 14:41:05,898 INFO     Training average loss at step 47500: 0.190934\n",
      "2023-12-10 14:41:50,126 INFO     Training average positive_sample_loss at step 47600: 0.207969\n",
      "2023-12-10 14:41:50,127 INFO     Training average negative_sample_loss at step 47600: 0.178957\n",
      "2023-12-10 14:41:50,127 INFO     Training average loss at step 47600: 0.193463\n",
      "2023-12-10 14:42:33,350 INFO     Training average positive_sample_loss at step 47700: 0.209184\n",
      "2023-12-10 14:42:33,350 INFO     Training average negative_sample_loss at step 47700: 0.180944\n",
      "2023-12-10 14:42:33,350 INFO     Training average loss at step 47700: 0.195064\n",
      "2023-12-10 14:43:17,250 INFO     Training average positive_sample_loss at step 47800: 0.209894\n",
      "2023-12-10 14:43:17,251 INFO     Training average negative_sample_loss at step 47800: 0.181746\n",
      "2023-12-10 14:43:17,251 INFO     Training average loss at step 47800: 0.195820\n",
      "2023-12-10 14:44:04,345 INFO     Training average positive_sample_loss at step 47900: 0.206075\n",
      "2023-12-10 14:44:04,345 INFO     Training average negative_sample_loss at step 47900: 0.182036\n",
      "2023-12-10 14:44:04,345 INFO     Training average loss at step 47900: 0.194055\n",
      "2023-12-10 14:44:48,804 INFO     Training average positive_sample_loss at step 48000: 0.202211\n",
      "2023-12-10 14:44:48,805 INFO     Training average negative_sample_loss at step 48000: 0.178421\n",
      "2023-12-10 14:44:48,805 INFO     Training average loss at step 48000: 0.190316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 14:45:32,085 INFO     Training average positive_sample_loss at step 48100: 0.206859\n",
      "2023-12-10 14:45:32,085 INFO     Training average negative_sample_loss at step 48100: 0.178698\n",
      "2023-12-10 14:45:32,085 INFO     Training average loss at step 48100: 0.192779\n",
      "2023-12-10 14:46:15,672 INFO     Training average positive_sample_loss at step 48200: 0.208082\n",
      "2023-12-10 14:46:15,672 INFO     Training average negative_sample_loss at step 48200: 0.178858\n",
      "2023-12-10 14:46:15,672 INFO     Training average loss at step 48200: 0.193470\n",
      "2023-12-10 14:46:59,618 INFO     Training average positive_sample_loss at step 48300: 0.209055\n",
      "2023-12-10 14:46:59,618 INFO     Training average negative_sample_loss at step 48300: 0.181509\n",
      "2023-12-10 14:46:59,618 INFO     Training average loss at step 48300: 0.195282\n",
      "2023-12-10 14:47:43,344 INFO     Training average positive_sample_loss at step 48400: 0.209628\n",
      "2023-12-10 14:47:43,344 INFO     Training average negative_sample_loss at step 48400: 0.182627\n",
      "2023-12-10 14:47:43,344 INFO     Training average loss at step 48400: 0.196128\n",
      "2023-12-10 14:48:32,817 INFO     Training average positive_sample_loss at step 48500: 0.199672\n",
      "2023-12-10 14:48:32,817 INFO     Training average negative_sample_loss at step 48500: 0.179219\n",
      "2023-12-10 14:48:32,817 INFO     Training average loss at step 48500: 0.189445\n",
      "2023-12-10 14:49:15,536 INFO     Training average positive_sample_loss at step 48600: 0.206260\n",
      "2023-12-10 14:49:15,536 INFO     Training average negative_sample_loss at step 48600: 0.177234\n",
      "2023-12-10 14:49:15,536 INFO     Training average loss at step 48600: 0.191747\n",
      "2023-12-10 14:49:59,959 INFO     Training average positive_sample_loss at step 48700: 0.208571\n",
      "2023-12-10 14:49:59,959 INFO     Training average negative_sample_loss at step 48700: 0.179673\n",
      "2023-12-10 14:49:59,959 INFO     Training average loss at step 48700: 0.194122\n",
      "2023-12-10 14:50:42,996 INFO     Training average positive_sample_loss at step 48800: 0.210018\n",
      "2023-12-10 14:50:42,996 INFO     Training average negative_sample_loss at step 48800: 0.183080\n",
      "2023-12-10 14:50:42,996 INFO     Training average loss at step 48800: 0.196549\n",
      "2023-12-10 14:51:25,920 INFO     Training average positive_sample_loss at step 48900: 0.209890\n",
      "2023-12-10 14:51:25,920 INFO     Training average negative_sample_loss at step 48900: 0.182644\n",
      "2023-12-10 14:51:25,920 INFO     Training average loss at step 48900: 0.196267\n",
      "2023-12-10 14:52:14,327 INFO     Training average positive_sample_loss at step 49000: 0.203010\n",
      "2023-12-10 14:52:14,327 INFO     Training average negative_sample_loss at step 49000: 0.182222\n",
      "2023-12-10 14:52:14,327 INFO     Training average loss at step 49000: 0.192616\n",
      "2023-12-10 14:52:57,780 INFO     Training average positive_sample_loss at step 49100: 0.204340\n",
      "2023-12-10 14:52:57,780 INFO     Training average negative_sample_loss at step 49100: 0.177579\n",
      "2023-12-10 14:52:57,780 INFO     Training average loss at step 49100: 0.190959\n",
      "2023-12-10 14:53:41,201 INFO     Training average positive_sample_loss at step 49200: 0.207144\n",
      "2023-12-10 14:53:41,201 INFO     Training average negative_sample_loss at step 49200: 0.178456\n",
      "2023-12-10 14:53:41,201 INFO     Training average loss at step 49200: 0.192800\n",
      "2023-12-10 14:54:25,043 INFO     Training average positive_sample_loss at step 49300: 0.209246\n",
      "2023-12-10 14:54:25,043 INFO     Training average negative_sample_loss at step 49300: 0.180877\n",
      "2023-12-10 14:54:25,043 INFO     Training average loss at step 49300: 0.195061\n",
      "2023-12-10 14:55:09,203 INFO     Training average positive_sample_loss at step 49400: 0.209362\n",
      "2023-12-10 14:55:09,203 INFO     Training average negative_sample_loss at step 49400: 0.181263\n",
      "2023-12-10 14:55:09,203 INFO     Training average loss at step 49400: 0.195312\n",
      "2023-12-10 14:55:59,884 INFO     Training average positive_sample_loss at step 49500: 0.206352\n",
      "2023-12-10 14:55:59,884 INFO     Training average negative_sample_loss at step 49500: 0.182718\n",
      "2023-12-10 14:55:59,884 INFO     Training average loss at step 49500: 0.194535\n",
      "2023-12-10 14:56:43,479 INFO     Training average positive_sample_loss at step 49600: 0.202533\n",
      "2023-12-10 14:56:43,479 INFO     Training average negative_sample_loss at step 49600: 0.177456\n",
      "2023-12-10 14:56:43,479 INFO     Training average loss at step 49600: 0.189995\n",
      "2023-12-10 14:57:27,178 INFO     Training average positive_sample_loss at step 49700: 0.207203\n",
      "2023-12-10 14:57:27,178 INFO     Training average negative_sample_loss at step 49700: 0.179281\n",
      "2023-12-10 14:57:27,178 INFO     Training average loss at step 49700: 0.193242\n",
      "2023-12-10 14:58:12,299 INFO     Training average positive_sample_loss at step 49800: 0.207936\n",
      "2023-12-10 14:58:12,299 INFO     Training average negative_sample_loss at step 49800: 0.179509\n",
      "2023-12-10 14:58:12,299 INFO     Training average loss at step 49800: 0.193722\n",
      "2023-12-10 14:58:56,737 INFO     Training average positive_sample_loss at step 49900: 0.208837\n",
      "2023-12-10 14:58:56,737 INFO     Training average negative_sample_loss at step 49900: 0.181339\n",
      "2023-12-10 14:58:56,737 INFO     Training average loss at step 49900: 0.195088\n",
      "2023-12-10 14:59:41,429 INFO     Change learning_rate to 0.000005 at step 50000\n",
      "2023-12-10 14:59:47,260 INFO     Training average positive_sample_loss at step 50000: 0.210307\n",
      "2023-12-10 14:59:47,261 INFO     Training average negative_sample_loss at step 50000: 0.182177\n",
      "2023-12-10 14:59:47,261 INFO     Training average loss at step 50000: 0.196242\n",
      "2023-12-10 14:59:47,261 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 14:59:47,799 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 15:00:26,959 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 15:01:01,952 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 15:01:09,751 INFO     Valid MRR at step 50000: 0.316845\n",
      "2023-12-10 15:01:09,752 INFO     Valid MR at step 50000: 157.678443\n",
      "2023-12-10 15:01:09,752 INFO     Valid HITS@1 at step 50000: 0.222669\n",
      "2023-12-10 15:01:09,752 INFO     Valid HITS@3 at step 50000: 0.347619\n",
      "2023-12-10 15:01:09,752 INFO     Valid HITS@10 at step 50000: 0.510094\n",
      "2023-12-10 15:01:57,648 INFO     Training average positive_sample_loss at step 50100: 0.195052\n",
      "2023-12-10 15:01:57,649 INFO     Training average negative_sample_loss at step 50100: 0.179730\n",
      "2023-12-10 15:01:57,649 INFO     Training average loss at step 50100: 0.187391\n",
      "2023-12-10 15:02:39,339 INFO     Training average positive_sample_loss at step 50200: 0.194142\n",
      "2023-12-10 15:02:39,339 INFO     Training average negative_sample_loss at step 50200: 0.179973\n",
      "2023-12-10 15:02:39,339 INFO     Training average loss at step 50200: 0.187057\n",
      "2023-12-10 15:03:22,538 INFO     Training average positive_sample_loss at step 50300: 0.194167\n",
      "2023-12-10 15:03:22,539 INFO     Training average negative_sample_loss at step 50300: 0.178436\n",
      "2023-12-10 15:03:22,539 INFO     Training average loss at step 50300: 0.186302\n",
      "2023-12-10 15:04:05,229 INFO     Training average positive_sample_loss at step 50400: 0.193509\n",
      "2023-12-10 15:04:05,229 INFO     Training average negative_sample_loss at step 50400: 0.176322\n",
      "2023-12-10 15:04:05,229 INFO     Training average loss at step 50400: 0.184916\n",
      "2023-12-10 15:04:50,471 INFO     Training average positive_sample_loss at step 50500: 0.195992\n",
      "2023-12-10 15:04:50,471 INFO     Training average negative_sample_loss at step 50500: 0.177334\n",
      "2023-12-10 15:04:50,471 INFO     Training average loss at step 50500: 0.186663\n",
      "2023-12-10 15:05:39,219 INFO     Training average positive_sample_loss at step 50600: 0.192466\n",
      "2023-12-10 15:05:39,219 INFO     Training average negative_sample_loss at step 50600: 0.176374\n",
      "2023-12-10 15:05:39,220 INFO     Training average loss at step 50600: 0.184420\n",
      "2023-12-10 15:06:23,060 INFO     Training average positive_sample_loss at step 50700: 0.192199\n",
      "2023-12-10 15:06:23,060 INFO     Training average negative_sample_loss at step 50700: 0.176363\n",
      "2023-12-10 15:06:23,060 INFO     Training average loss at step 50700: 0.184281\n",
      "2023-12-10 15:07:06,487 INFO     Training average positive_sample_loss at step 50800: 0.192679\n",
      "2023-12-10 15:07:06,487 INFO     Training average negative_sample_loss at step 50800: 0.176266\n",
      "2023-12-10 15:07:06,487 INFO     Training average loss at step 50800: 0.184473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 15:07:50,170 INFO     Training average positive_sample_loss at step 50900: 0.194928\n",
      "2023-12-10 15:07:50,171 INFO     Training average negative_sample_loss at step 50900: 0.176287\n",
      "2023-12-10 15:07:50,171 INFO     Training average loss at step 50900: 0.185607\n",
      "2023-12-10 15:08:32,227 INFO     Training average positive_sample_loss at step 51000: 0.194841\n",
      "2023-12-10 15:08:32,227 INFO     Training average negative_sample_loss at step 51000: 0.175625\n",
      "2023-12-10 15:08:32,227 INFO     Training average loss at step 51000: 0.185233\n",
      "2023-12-10 15:09:22,684 INFO     Training average positive_sample_loss at step 51100: 0.194103\n",
      "2023-12-10 15:09:22,684 INFO     Training average negative_sample_loss at step 51100: 0.174270\n",
      "2023-12-10 15:09:22,684 INFO     Training average loss at step 51100: 0.184186\n",
      "2023-12-10 15:10:06,469 INFO     Training average positive_sample_loss at step 51200: 0.192425\n",
      "2023-12-10 15:10:06,470 INFO     Training average negative_sample_loss at step 51200: 0.174300\n",
      "2023-12-10 15:10:06,470 INFO     Training average loss at step 51200: 0.183363\n",
      "2023-12-10 15:10:49,844 INFO     Training average positive_sample_loss at step 51300: 0.193243\n",
      "2023-12-10 15:10:49,844 INFO     Training average negative_sample_loss at step 51300: 0.173781\n",
      "2023-12-10 15:10:49,844 INFO     Training average loss at step 51300: 0.183512\n",
      "2023-12-10 15:11:33,450 INFO     Training average positive_sample_loss at step 51400: 0.194106\n",
      "2023-12-10 15:11:33,451 INFO     Training average negative_sample_loss at step 51400: 0.174453\n",
      "2023-12-10 15:11:33,451 INFO     Training average loss at step 51400: 0.184279\n",
      "2023-12-10 15:12:16,482 INFO     Training average positive_sample_loss at step 51500: 0.194561\n",
      "2023-12-10 15:12:16,483 INFO     Training average negative_sample_loss at step 51500: 0.173930\n",
      "2023-12-10 15:12:16,483 INFO     Training average loss at step 51500: 0.184246\n",
      "2023-12-10 15:12:59,801 INFO     Training average positive_sample_loss at step 51600: 0.194415\n",
      "2023-12-10 15:12:59,801 INFO     Training average negative_sample_loss at step 51600: 0.173656\n",
      "2023-12-10 15:12:59,801 INFO     Training average loss at step 51600: 0.184035\n",
      "2023-12-10 15:13:52,797 INFO     Training average positive_sample_loss at step 51700: 0.191668\n",
      "2023-12-10 15:13:52,797 INFO     Training average negative_sample_loss at step 51700: 0.173778\n",
      "2023-12-10 15:13:52,797 INFO     Training average loss at step 51700: 0.182723\n",
      "2023-12-10 15:14:37,005 INFO     Training average positive_sample_loss at step 51800: 0.193368\n",
      "2023-12-10 15:14:37,005 INFO     Training average negative_sample_loss at step 51800: 0.173147\n",
      "2023-12-10 15:14:37,005 INFO     Training average loss at step 51800: 0.183257\n",
      "2023-12-10 15:15:19,468 INFO     Training average positive_sample_loss at step 51900: 0.193371\n",
      "2023-12-10 15:15:19,468 INFO     Training average negative_sample_loss at step 51900: 0.173163\n",
      "2023-12-10 15:15:19,468 INFO     Training average loss at step 51900: 0.183267\n",
      "2023-12-10 15:16:03,601 INFO     Training average positive_sample_loss at step 52000: 0.194762\n",
      "2023-12-10 15:16:03,601 INFO     Training average negative_sample_loss at step 52000: 0.172126\n",
      "2023-12-10 15:16:03,601 INFO     Training average loss at step 52000: 0.183444\n",
      "2023-12-10 15:16:47,559 INFO     Training average positive_sample_loss at step 52100: 0.194341\n",
      "2023-12-10 15:16:47,559 INFO     Training average negative_sample_loss at step 52100: 0.172727\n",
      "2023-12-10 15:16:47,559 INFO     Training average loss at step 52100: 0.183534\n",
      "2023-12-10 15:17:36,714 INFO     Training average positive_sample_loss at step 52200: 0.192477\n",
      "2023-12-10 15:17:36,715 INFO     Training average negative_sample_loss at step 52200: 0.173409\n",
      "2023-12-10 15:17:36,715 INFO     Training average loss at step 52200: 0.182943\n",
      "2023-12-10 15:18:20,472 INFO     Training average positive_sample_loss at step 52300: 0.192888\n",
      "2023-12-10 15:18:20,473 INFO     Training average negative_sample_loss at step 52300: 0.173317\n",
      "2023-12-10 15:18:20,473 INFO     Training average loss at step 52300: 0.183102\n",
      "2023-12-10 15:19:04,150 INFO     Training average positive_sample_loss at step 52400: 0.194192\n",
      "2023-12-10 15:19:04,150 INFO     Training average negative_sample_loss at step 52400: 0.173109\n",
      "2023-12-10 15:19:04,150 INFO     Training average loss at step 52400: 0.183650\n",
      "2023-12-10 15:19:49,287 INFO     Training average positive_sample_loss at step 52500: 0.194327\n",
      "2023-12-10 15:19:49,288 INFO     Training average negative_sample_loss at step 52500: 0.171975\n",
      "2023-12-10 15:19:49,288 INFO     Training average loss at step 52500: 0.183151\n",
      "2023-12-10 15:20:33,775 INFO     Training average positive_sample_loss at step 52600: 0.194478\n",
      "2023-12-10 15:20:33,776 INFO     Training average negative_sample_loss at step 52600: 0.173261\n",
      "2023-12-10 15:20:33,776 INFO     Training average loss at step 52600: 0.183870\n",
      "2023-12-10 15:21:25,296 INFO     Training average positive_sample_loss at step 52700: 0.194831\n",
      "2023-12-10 15:21:25,297 INFO     Training average negative_sample_loss at step 52700: 0.172739\n",
      "2023-12-10 15:21:25,297 INFO     Training average loss at step 52700: 0.183785\n",
      "2023-12-10 15:22:08,727 INFO     Training average positive_sample_loss at step 52800: 0.192388\n",
      "2023-12-10 15:22:08,728 INFO     Training average negative_sample_loss at step 52800: 0.172413\n",
      "2023-12-10 15:22:08,728 INFO     Training average loss at step 52800: 0.182401\n",
      "2023-12-10 15:22:51,726 INFO     Training average positive_sample_loss at step 52900: 0.193768\n",
      "2023-12-10 15:22:51,727 INFO     Training average negative_sample_loss at step 52900: 0.171842\n",
      "2023-12-10 15:22:51,727 INFO     Training average loss at step 52900: 0.182805\n",
      "2023-12-10 15:23:35,199 INFO     Training average positive_sample_loss at step 53000: 0.194320\n",
      "2023-12-10 15:23:35,200 INFO     Training average negative_sample_loss at step 53000: 0.172615\n",
      "2023-12-10 15:23:35,200 INFO     Training average loss at step 53000: 0.183467\n",
      "2023-12-10 15:24:18,490 INFO     Training average positive_sample_loss at step 53100: 0.193673\n",
      "2023-12-10 15:24:18,490 INFO     Training average negative_sample_loss at step 53100: 0.172816\n",
      "2023-12-10 15:24:18,490 INFO     Training average loss at step 53100: 0.183244\n",
      "2023-12-10 15:25:05,128 INFO     Training average positive_sample_loss at step 53200: 0.195383\n",
      "2023-12-10 15:25:05,129 INFO     Training average negative_sample_loss at step 53200: 0.171128\n",
      "2023-12-10 15:25:05,129 INFO     Training average loss at step 53200: 0.183255\n",
      "2023-12-10 15:25:50,656 INFO     Training average positive_sample_loss at step 53300: 0.192443\n",
      "2023-12-10 15:25:50,656 INFO     Training average negative_sample_loss at step 53300: 0.171897\n",
      "2023-12-10 15:25:50,657 INFO     Training average loss at step 53300: 0.182170\n",
      "2023-12-10 15:26:34,234 INFO     Training average positive_sample_loss at step 53400: 0.192629\n",
      "2023-12-10 15:26:34,234 INFO     Training average negative_sample_loss at step 53400: 0.171423\n",
      "2023-12-10 15:26:34,235 INFO     Training average loss at step 53400: 0.182026\n",
      "2023-12-10 15:27:16,186 INFO     Training average positive_sample_loss at step 53500: 0.194282\n",
      "2023-12-10 15:27:16,186 INFO     Training average negative_sample_loss at step 53500: 0.171254\n",
      "2023-12-10 15:27:16,186 INFO     Training average loss at step 53500: 0.182768\n",
      "2023-12-10 15:27:59,426 INFO     Training average positive_sample_loss at step 53600: 0.194257\n",
      "2023-12-10 15:27:59,426 INFO     Training average negative_sample_loss at step 53600: 0.172166\n",
      "2023-12-10 15:27:59,426 INFO     Training average loss at step 53600: 0.183212\n",
      "2023-12-10 15:28:42,830 INFO     Training average positive_sample_loss at step 53700: 0.195182\n",
      "2023-12-10 15:28:42,830 INFO     Training average negative_sample_loss at step 53700: 0.173461\n",
      "2023-12-10 15:28:42,830 INFO     Training average loss at step 53700: 0.184322\n",
      "2023-12-10 15:29:34,527 INFO     Training average positive_sample_loss at step 53800: 0.192959\n",
      "2023-12-10 15:29:34,527 INFO     Training average negative_sample_loss at step 53800: 0.172083\n",
      "2023-12-10 15:29:34,528 INFO     Training average loss at step 53800: 0.182521\n",
      "2023-12-10 15:30:18,176 INFO     Training average positive_sample_loss at step 53900: 0.193035\n",
      "2023-12-10 15:30:18,176 INFO     Training average negative_sample_loss at step 53900: 0.171919\n",
      "2023-12-10 15:30:18,176 INFO     Training average loss at step 53900: 0.182477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 15:31:01,992 INFO     Training average positive_sample_loss at step 54000: 0.194266\n",
      "2023-12-10 15:31:01,992 INFO     Training average negative_sample_loss at step 54000: 0.171473\n",
      "2023-12-10 15:31:01,992 INFO     Training average loss at step 54000: 0.182869\n",
      "2023-12-10 15:31:46,362 INFO     Training average positive_sample_loss at step 54100: 0.194093\n",
      "2023-12-10 15:31:46,362 INFO     Training average negative_sample_loss at step 54100: 0.171206\n",
      "2023-12-10 15:31:46,362 INFO     Training average loss at step 54100: 0.182650\n",
      "2023-12-10 15:32:30,774 INFO     Training average positive_sample_loss at step 54200: 0.194588\n",
      "2023-12-10 15:32:30,774 INFO     Training average negative_sample_loss at step 54200: 0.171932\n",
      "2023-12-10 15:32:30,774 INFO     Training average loss at step 54200: 0.183260\n",
      "2023-12-10 15:33:22,244 INFO     Training average positive_sample_loss at step 54300: 0.194757\n",
      "2023-12-10 15:33:22,245 INFO     Training average negative_sample_loss at step 54300: 0.171767\n",
      "2023-12-10 15:33:22,245 INFO     Training average loss at step 54300: 0.183262\n",
      "2023-12-10 15:34:06,256 INFO     Training average positive_sample_loss at step 54400: 0.192724\n",
      "2023-12-10 15:34:06,257 INFO     Training average negative_sample_loss at step 54400: 0.171278\n",
      "2023-12-10 15:34:06,257 INFO     Training average loss at step 54400: 0.182001\n",
      "2023-12-10 15:34:50,514 INFO     Training average positive_sample_loss at step 54500: 0.193649\n",
      "2023-12-10 15:34:50,515 INFO     Training average negative_sample_loss at step 54500: 0.171498\n",
      "2023-12-10 15:34:50,515 INFO     Training average loss at step 54500: 0.182573\n",
      "2023-12-10 15:35:34,219 INFO     Training average positive_sample_loss at step 54600: 0.194113\n",
      "2023-12-10 15:35:34,219 INFO     Training average negative_sample_loss at step 54600: 0.171708\n",
      "2023-12-10 15:35:34,220 INFO     Training average loss at step 54600: 0.182911\n",
      "2023-12-10 15:36:17,585 INFO     Training average positive_sample_loss at step 54700: 0.194972\n",
      "2023-12-10 15:36:17,586 INFO     Training average negative_sample_loss at step 54700: 0.172189\n",
      "2023-12-10 15:36:17,586 INFO     Training average loss at step 54700: 0.183581\n",
      "2023-12-10 15:37:08,386 INFO     Training average positive_sample_loss at step 54800: 0.194624\n",
      "2023-12-10 15:37:08,386 INFO     Training average negative_sample_loss at step 54800: 0.172724\n",
      "2023-12-10 15:37:08,386 INFO     Training average loss at step 54800: 0.183674\n",
      "2023-12-10 15:37:51,639 INFO     Training average positive_sample_loss at step 54900: 0.192263\n",
      "2023-12-10 15:37:51,640 INFO     Training average negative_sample_loss at step 54900: 0.171282\n",
      "2023-12-10 15:37:51,640 INFO     Training average loss at step 54900: 0.181772\n",
      "2023-12-10 15:38:36,105 INFO     Training average positive_sample_loss at step 55000: 0.193787\n",
      "2023-12-10 15:38:36,106 INFO     Training average negative_sample_loss at step 55000: 0.170744\n",
      "2023-12-10 15:38:36,106 INFO     Training average loss at step 55000: 0.182266\n",
      "2023-12-10 15:39:19,807 INFO     Training average positive_sample_loss at step 55100: 0.194117\n",
      "2023-12-10 15:39:19,807 INFO     Training average negative_sample_loss at step 55100: 0.171366\n",
      "2023-12-10 15:39:19,808 INFO     Training average loss at step 55100: 0.182741\n",
      "2023-12-10 15:40:03,732 INFO     Training average positive_sample_loss at step 55200: 0.194710\n",
      "2023-12-10 15:40:03,733 INFO     Training average negative_sample_loss at step 55200: 0.171521\n",
      "2023-12-10 15:40:03,733 INFO     Training average loss at step 55200: 0.183115\n",
      "2023-12-10 15:40:46,294 INFO     Training average positive_sample_loss at step 55300: 0.195188\n",
      "2023-12-10 15:40:46,294 INFO     Training average negative_sample_loss at step 55300: 0.171545\n",
      "2023-12-10 15:40:46,294 INFO     Training average loss at step 55300: 0.183367\n",
      "2023-12-10 15:41:35,603 INFO     Training average positive_sample_loss at step 55400: 0.193616\n",
      "2023-12-10 15:41:35,603 INFO     Training average negative_sample_loss at step 55400: 0.171367\n",
      "2023-12-10 15:41:35,603 INFO     Training average loss at step 55400: 0.182491\n",
      "2023-12-10 15:42:18,387 INFO     Training average positive_sample_loss at step 55500: 0.193041\n",
      "2023-12-10 15:42:18,387 INFO     Training average negative_sample_loss at step 55500: 0.171010\n",
      "2023-12-10 15:42:18,388 INFO     Training average loss at step 55500: 0.182025\n",
      "2023-12-10 15:43:02,585 INFO     Training average positive_sample_loss at step 55600: 0.193508\n",
      "2023-12-10 15:43:02,586 INFO     Training average negative_sample_loss at step 55600: 0.170594\n",
      "2023-12-10 15:43:02,586 INFO     Training average loss at step 55600: 0.182051\n",
      "2023-12-10 15:43:47,143 INFO     Training average positive_sample_loss at step 55700: 0.195014\n",
      "2023-12-10 15:43:47,144 INFO     Training average negative_sample_loss at step 55700: 0.171575\n",
      "2023-12-10 15:43:47,144 INFO     Training average loss at step 55700: 0.183294\n",
      "2023-12-10 15:44:31,083 INFO     Training average positive_sample_loss at step 55800: 0.195210\n",
      "2023-12-10 15:44:31,083 INFO     Training average negative_sample_loss at step 55800: 0.171035\n",
      "2023-12-10 15:44:31,083 INFO     Training average loss at step 55800: 0.183123\n",
      "2023-12-10 15:45:20,186 INFO     Training average positive_sample_loss at step 55900: 0.193293\n",
      "2023-12-10 15:45:20,186 INFO     Training average negative_sample_loss at step 55900: 0.169967\n",
      "2023-12-10 15:45:20,186 INFO     Training average loss at step 55900: 0.181630\n",
      "2023-12-10 15:46:02,690 INFO     Training average positive_sample_loss at step 56000: 0.192969\n",
      "2023-12-10 15:46:02,691 INFO     Training average negative_sample_loss at step 56000: 0.171787\n",
      "2023-12-10 15:46:02,691 INFO     Training average loss at step 56000: 0.182378\n",
      "2023-12-10 15:46:46,908 INFO     Training average positive_sample_loss at step 56100: 0.192854\n",
      "2023-12-10 15:46:46,908 INFO     Training average negative_sample_loss at step 56100: 0.171167\n",
      "2023-12-10 15:46:46,908 INFO     Training average loss at step 56100: 0.182010\n",
      "2023-12-10 15:47:31,490 INFO     Training average positive_sample_loss at step 56200: 0.195024\n",
      "2023-12-10 15:47:31,490 INFO     Training average negative_sample_loss at step 56200: 0.171901\n",
      "2023-12-10 15:47:31,490 INFO     Training average loss at step 56200: 0.183463\n",
      "2023-12-10 15:48:15,190 INFO     Training average positive_sample_loss at step 56300: 0.194876\n",
      "2023-12-10 15:48:15,190 INFO     Training average negative_sample_loss at step 56300: 0.171628\n",
      "2023-12-10 15:48:15,190 INFO     Training average loss at step 56300: 0.183252\n",
      "2023-12-10 15:49:06,277 INFO     Training average positive_sample_loss at step 56400: 0.194842\n",
      "2023-12-10 15:49:06,278 INFO     Training average negative_sample_loss at step 56400: 0.172245\n",
      "2023-12-10 15:49:06,278 INFO     Training average loss at step 56400: 0.183544\n",
      "2023-12-10 15:49:49,723 INFO     Training average positive_sample_loss at step 56500: 0.192522\n",
      "2023-12-10 15:49:49,723 INFO     Training average negative_sample_loss at step 56500: 0.170943\n",
      "2023-12-10 15:49:49,723 INFO     Training average loss at step 56500: 0.181733\n",
      "2023-12-10 15:50:33,783 INFO     Training average positive_sample_loss at step 56600: 0.193369\n",
      "2023-12-10 15:50:33,783 INFO     Training average negative_sample_loss at step 56600: 0.170405\n",
      "2023-12-10 15:50:33,783 INFO     Training average loss at step 56600: 0.181887\n",
      "2023-12-10 15:51:17,013 INFO     Training average positive_sample_loss at step 56700: 0.193718\n",
      "2023-12-10 15:51:17,013 INFO     Training average negative_sample_loss at step 56700: 0.170929\n",
      "2023-12-10 15:51:17,013 INFO     Training average loss at step 56700: 0.182323\n",
      "2023-12-10 15:52:00,804 INFO     Training average positive_sample_loss at step 56800: 0.195793\n",
      "2023-12-10 15:52:00,804 INFO     Training average negative_sample_loss at step 56800: 0.172260\n",
      "2023-12-10 15:52:00,804 INFO     Training average loss at step 56800: 0.184027\n",
      "2023-12-10 15:52:43,708 INFO     Training average positive_sample_loss at step 56900: 0.195261\n",
      "2023-12-10 15:52:43,709 INFO     Training average negative_sample_loss at step 56900: 0.170620\n",
      "2023-12-10 15:52:43,709 INFO     Training average loss at step 56900: 0.182941\n",
      "2023-12-10 15:53:34,135 INFO     Training average positive_sample_loss at step 57000: 0.193097\n",
      "2023-12-10 15:53:34,136 INFO     Training average negative_sample_loss at step 57000: 0.170862\n",
      "2023-12-10 15:53:34,136 INFO     Training average loss at step 57000: 0.181979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 15:54:19,250 INFO     Training average positive_sample_loss at step 57100: 0.192643\n",
      "2023-12-10 15:54:19,251 INFO     Training average negative_sample_loss at step 57100: 0.170756\n",
      "2023-12-10 15:54:19,251 INFO     Training average loss at step 57100: 0.181700\n",
      "2023-12-10 15:55:02,200 INFO     Training average positive_sample_loss at step 57200: 0.193339\n",
      "2023-12-10 15:55:02,200 INFO     Training average negative_sample_loss at step 57200: 0.170935\n",
      "2023-12-10 15:55:02,200 INFO     Training average loss at step 57200: 0.182137\n",
      "2023-12-10 15:55:46,934 INFO     Training average positive_sample_loss at step 57300: 0.194837\n",
      "2023-12-10 15:55:46,934 INFO     Training average negative_sample_loss at step 57300: 0.171458\n",
      "2023-12-10 15:55:46,934 INFO     Training average loss at step 57300: 0.183148\n",
      "2023-12-10 15:56:30,277 INFO     Training average positive_sample_loss at step 57400: 0.195601\n",
      "2023-12-10 15:56:30,277 INFO     Training average negative_sample_loss at step 57400: 0.170568\n",
      "2023-12-10 15:56:30,277 INFO     Training average loss at step 57400: 0.183085\n",
      "2023-12-10 15:57:21,910 INFO     Training average positive_sample_loss at step 57500: 0.193982\n",
      "2023-12-10 15:57:21,911 INFO     Training average negative_sample_loss at step 57500: 0.171463\n",
      "2023-12-10 15:57:21,911 INFO     Training average loss at step 57500: 0.182723\n",
      "2023-12-10 15:58:06,219 INFO     Training average positive_sample_loss at step 57600: 0.192480\n",
      "2023-12-10 15:58:06,219 INFO     Training average negative_sample_loss at step 57600: 0.171357\n",
      "2023-12-10 15:58:06,219 INFO     Training average loss at step 57600: 0.181919\n",
      "2023-12-10 15:58:49,318 INFO     Training average positive_sample_loss at step 57700: 0.194416\n",
      "2023-12-10 15:58:49,318 INFO     Training average negative_sample_loss at step 57700: 0.171258\n",
      "2023-12-10 15:58:49,318 INFO     Training average loss at step 57700: 0.182837\n",
      "2023-12-10 15:59:33,567 INFO     Training average positive_sample_loss at step 57800: 0.194423\n",
      "2023-12-10 15:59:33,567 INFO     Training average negative_sample_loss at step 57800: 0.170338\n",
      "2023-12-10 15:59:33,567 INFO     Training average loss at step 57800: 0.182381\n",
      "2023-12-10 16:00:16,240 INFO     Training average positive_sample_loss at step 57900: 0.194346\n",
      "2023-12-10 16:00:16,240 INFO     Training average negative_sample_loss at step 57900: 0.171778\n",
      "2023-12-10 16:00:16,240 INFO     Training average loss at step 57900: 0.183062\n",
      "2023-12-10 16:01:08,413 INFO     Training average positive_sample_loss at step 58000: 0.195334\n",
      "2023-12-10 16:01:08,414 INFO     Training average negative_sample_loss at step 58000: 0.171584\n",
      "2023-12-10 16:01:08,414 INFO     Training average loss at step 58000: 0.183459\n",
      "2023-12-10 16:01:52,057 INFO     Training average positive_sample_loss at step 58100: 0.192788\n",
      "2023-12-10 16:01:52,057 INFO     Training average negative_sample_loss at step 58100: 0.171326\n",
      "2023-12-10 16:01:52,058 INFO     Training average loss at step 58100: 0.182057\n",
      "2023-12-10 16:02:36,280 INFO     Training average positive_sample_loss at step 58200: 0.193445\n",
      "2023-12-10 16:02:36,280 INFO     Training average negative_sample_loss at step 58200: 0.170680\n",
      "2023-12-10 16:02:36,280 INFO     Training average loss at step 58200: 0.182062\n",
      "2023-12-10 16:03:20,299 INFO     Training average positive_sample_loss at step 58300: 0.194309\n",
      "2023-12-10 16:03:20,299 INFO     Training average negative_sample_loss at step 58300: 0.171859\n",
      "2023-12-10 16:03:20,299 INFO     Training average loss at step 58300: 0.183084\n",
      "2023-12-10 16:04:05,505 INFO     Training average positive_sample_loss at step 58400: 0.194968\n",
      "2023-12-10 16:04:05,505 INFO     Training average negative_sample_loss at step 58400: 0.171204\n",
      "2023-12-10 16:04:05,505 INFO     Training average loss at step 58400: 0.183086\n",
      "2023-12-10 16:04:50,641 INFO     Training average positive_sample_loss at step 58500: 0.195149\n",
      "2023-12-10 16:04:50,642 INFO     Training average negative_sample_loss at step 58500: 0.170626\n",
      "2023-12-10 16:04:50,642 INFO     Training average loss at step 58500: 0.182887\n",
      "2023-12-10 16:05:39,510 INFO     Training average positive_sample_loss at step 58600: 0.193165\n",
      "2023-12-10 16:05:39,510 INFO     Training average negative_sample_loss at step 58600: 0.171185\n",
      "2023-12-10 16:05:39,510 INFO     Training average loss at step 58600: 0.182175\n",
      "2023-12-10 16:06:23,962 INFO     Training average positive_sample_loss at step 58700: 0.192787\n",
      "2023-12-10 16:06:23,963 INFO     Training average negative_sample_loss at step 58700: 0.171216\n",
      "2023-12-10 16:06:23,963 INFO     Training average loss at step 58700: 0.182001\n",
      "2023-12-10 16:07:07,994 INFO     Training average positive_sample_loss at step 58800: 0.193711\n",
      "2023-12-10 16:07:07,994 INFO     Training average negative_sample_loss at step 58800: 0.171663\n",
      "2023-12-10 16:07:07,994 INFO     Training average loss at step 58800: 0.182687\n",
      "2023-12-10 16:07:51,062 INFO     Training average positive_sample_loss at step 58900: 0.195068\n",
      "2023-12-10 16:07:51,062 INFO     Training average negative_sample_loss at step 58900: 0.170771\n",
      "2023-12-10 16:07:51,062 INFO     Training average loss at step 58900: 0.182920\n",
      "2023-12-10 16:08:35,859 INFO     Training average positive_sample_loss at step 59000: 0.195362\n",
      "2023-12-10 16:08:35,859 INFO     Training average negative_sample_loss at step 59000: 0.171355\n",
      "2023-12-10 16:08:35,859 INFO     Training average loss at step 59000: 0.183359\n",
      "2023-12-10 16:09:28,093 INFO     Training average positive_sample_loss at step 59100: 0.194059\n",
      "2023-12-10 16:09:28,094 INFO     Training average negative_sample_loss at step 59100: 0.171074\n",
      "2023-12-10 16:09:28,094 INFO     Training average loss at step 59100: 0.182566\n",
      "2023-12-10 16:10:10,971 INFO     Training average positive_sample_loss at step 59200: 0.192744\n",
      "2023-12-10 16:10:10,972 INFO     Training average negative_sample_loss at step 59200: 0.170832\n",
      "2023-12-10 16:10:10,972 INFO     Training average loss at step 59200: 0.181788\n",
      "2023-12-10 16:10:54,809 INFO     Training average positive_sample_loss at step 59300: 0.193952\n",
      "2023-12-10 16:10:54,809 INFO     Training average negative_sample_loss at step 59300: 0.171584\n",
      "2023-12-10 16:10:54,809 INFO     Training average loss at step 59300: 0.182768\n",
      "2023-12-10 16:11:37,846 INFO     Training average positive_sample_loss at step 59400: 0.194452\n",
      "2023-12-10 16:11:37,847 INFO     Training average negative_sample_loss at step 59400: 0.170851\n",
      "2023-12-10 16:11:37,847 INFO     Training average loss at step 59400: 0.182651\n",
      "2023-12-10 16:12:22,285 INFO     Training average positive_sample_loss at step 59500: 0.195247\n",
      "2023-12-10 16:12:22,286 INFO     Training average negative_sample_loss at step 59500: 0.170619\n",
      "2023-12-10 16:12:22,286 INFO     Training average loss at step 59500: 0.182933\n",
      "2023-12-10 16:13:10,273 INFO     Training average positive_sample_loss at step 59600: 0.195169\n",
      "2023-12-10 16:13:10,274 INFO     Training average negative_sample_loss at step 59600: 0.171070\n",
      "2023-12-10 16:13:10,274 INFO     Training average loss at step 59600: 0.183120\n",
      "2023-12-10 16:13:54,075 INFO     Training average positive_sample_loss at step 59700: 0.192809\n",
      "2023-12-10 16:13:54,075 INFO     Training average negative_sample_loss at step 59700: 0.170586\n",
      "2023-12-10 16:13:54,075 INFO     Training average loss at step 59700: 0.181698\n",
      "2023-12-10 16:14:38,837 INFO     Training average positive_sample_loss at step 59800: 0.193075\n",
      "2023-12-10 16:14:38,838 INFO     Training average negative_sample_loss at step 59800: 0.169885\n",
      "2023-12-10 16:14:38,838 INFO     Training average loss at step 59800: 0.181480\n",
      "2023-12-10 16:15:23,127 INFO     Training average positive_sample_loss at step 59900: 0.194278\n",
      "2023-12-10 16:15:23,127 INFO     Training average negative_sample_loss at step 59900: 0.170849\n",
      "2023-12-10 16:15:23,127 INFO     Training average loss at step 59900: 0.182564\n",
      "2023-12-10 16:16:18,139 INFO     Training average positive_sample_loss at step 60000: 0.194536\n",
      "2023-12-10 16:16:18,140 INFO     Training average negative_sample_loss at step 60000: 0.171680\n",
      "2023-12-10 16:16:18,140 INFO     Training average loss at step 60000: 0.183108\n",
      "2023-12-10 16:16:18,140 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 16:16:18,792 INFO     Evaluating the model... (0/2192)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 16:16:58,850 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 16:17:35,675 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 16:17:43,236 INFO     Valid MRR at step 60000: 0.324922\n",
      "2023-12-10 16:17:43,237 INFO     Valid MR at step 60000: 153.413829\n",
      "2023-12-10 16:17:43,237 INFO     Valid HITS@1 at step 60000: 0.230510\n",
      "2023-12-10 16:17:43,237 INFO     Valid HITS@3 at step 60000: 0.357029\n",
      "2023-12-10 16:17:43,237 INFO     Valid HITS@10 at step 60000: 0.519989\n",
      "2023-12-10 16:18:20,971 INFO     Training average positive_sample_loss at step 60100: 0.195323\n",
      "2023-12-10 16:18:20,971 INFO     Training average negative_sample_loss at step 60100: 0.170547\n",
      "2023-12-10 16:18:20,972 INFO     Training average loss at step 60100: 0.182935\n",
      "2023-12-10 16:19:14,632 INFO     Training average positive_sample_loss at step 60200: 0.192899\n",
      "2023-12-10 16:19:14,633 INFO     Training average negative_sample_loss at step 60200: 0.171018\n",
      "2023-12-10 16:19:14,633 INFO     Training average loss at step 60200: 0.181958\n",
      "2023-12-10 16:19:57,683 INFO     Training average positive_sample_loss at step 60300: 0.193663\n",
      "2023-12-10 16:19:57,683 INFO     Training average negative_sample_loss at step 60300: 0.170771\n",
      "2023-12-10 16:19:57,684 INFO     Training average loss at step 60300: 0.182217\n",
      "2023-12-10 16:20:40,533 INFO     Training average positive_sample_loss at step 60400: 0.193764\n",
      "2023-12-10 16:20:40,533 INFO     Training average negative_sample_loss at step 60400: 0.171043\n",
      "2023-12-10 16:20:40,533 INFO     Training average loss at step 60400: 0.182404\n",
      "2023-12-10 16:21:23,621 INFO     Training average positive_sample_loss at step 60500: 0.194458\n",
      "2023-12-10 16:21:23,621 INFO     Training average negative_sample_loss at step 60500: 0.170164\n",
      "2023-12-10 16:21:23,621 INFO     Training average loss at step 60500: 0.182311\n",
      "2023-12-10 16:22:07,082 INFO     Training average positive_sample_loss at step 60600: 0.195437\n",
      "2023-12-10 16:22:07,082 INFO     Training average negative_sample_loss at step 60600: 0.170931\n",
      "2023-12-10 16:22:07,082 INFO     Training average loss at step 60600: 0.183184\n",
      "2023-12-10 16:22:59,034 INFO     Training average positive_sample_loss at step 60700: 0.193214\n",
      "2023-12-10 16:22:59,034 INFO     Training average negative_sample_loss at step 60700: 0.171034\n",
      "2023-12-10 16:22:59,034 INFO     Training average loss at step 60700: 0.182124\n",
      "2023-12-10 16:23:42,165 INFO     Training average positive_sample_loss at step 60800: 0.192623\n",
      "2023-12-10 16:23:42,166 INFO     Training average negative_sample_loss at step 60800: 0.170458\n",
      "2023-12-10 16:23:42,166 INFO     Training average loss at step 60800: 0.181541\n",
      "2023-12-10 16:24:24,897 INFO     Training average positive_sample_loss at step 60900: 0.193283\n",
      "2023-12-10 16:24:24,897 INFO     Training average negative_sample_loss at step 60900: 0.170160\n",
      "2023-12-10 16:24:24,897 INFO     Training average loss at step 60900: 0.181721\n",
      "2023-12-10 16:25:07,227 INFO     Training average positive_sample_loss at step 61000: 0.195074\n",
      "2023-12-10 16:25:07,227 INFO     Training average negative_sample_loss at step 61000: 0.170986\n",
      "2023-12-10 16:25:07,227 INFO     Training average loss at step 61000: 0.183030\n",
      "2023-12-10 16:25:50,452 INFO     Training average positive_sample_loss at step 61100: 0.196363\n",
      "2023-12-10 16:25:50,452 INFO     Training average negative_sample_loss at step 61100: 0.171639\n",
      "2023-12-10 16:25:50,452 INFO     Training average loss at step 61100: 0.184001\n",
      "2023-12-10 16:26:39,854 INFO     Training average positive_sample_loss at step 61200: 0.194702\n",
      "2023-12-10 16:26:39,854 INFO     Training average negative_sample_loss at step 61200: 0.170067\n",
      "2023-12-10 16:26:39,854 INFO     Training average loss at step 61200: 0.182384\n",
      "2023-12-10 16:27:23,073 INFO     Training average positive_sample_loss at step 61300: 0.192851\n",
      "2023-12-10 16:27:23,073 INFO     Training average negative_sample_loss at step 61300: 0.170890\n",
      "2023-12-10 16:27:23,073 INFO     Training average loss at step 61300: 0.181871\n",
      "2023-12-10 16:28:05,875 INFO     Training average positive_sample_loss at step 61400: 0.194044\n",
      "2023-12-10 16:28:05,876 INFO     Training average negative_sample_loss at step 61400: 0.170751\n",
      "2023-12-10 16:28:05,876 INFO     Training average loss at step 61400: 0.182398\n",
      "2023-12-10 16:28:48,928 INFO     Training average positive_sample_loss at step 61500: 0.194450\n",
      "2023-12-10 16:28:48,928 INFO     Training average negative_sample_loss at step 61500: 0.169725\n",
      "2023-12-10 16:28:48,928 INFO     Training average loss at step 61500: 0.182087\n",
      "2023-12-10 16:29:32,443 INFO     Training average positive_sample_loss at step 61600: 0.194037\n",
      "2023-12-10 16:29:32,443 INFO     Training average negative_sample_loss at step 61600: 0.170424\n",
      "2023-12-10 16:29:32,443 INFO     Training average loss at step 61600: 0.182231\n",
      "2023-12-10 16:30:15,899 INFO     Training average positive_sample_loss at step 61700: 0.195234\n",
      "2023-12-10 16:30:15,900 INFO     Training average negative_sample_loss at step 61700: 0.170572\n",
      "2023-12-10 16:30:15,900 INFO     Training average loss at step 61700: 0.182903\n",
      "2023-12-10 16:31:07,983 INFO     Training average positive_sample_loss at step 61800: 0.193514\n",
      "2023-12-10 16:31:07,983 INFO     Training average negative_sample_loss at step 61800: 0.171658\n",
      "2023-12-10 16:31:07,983 INFO     Training average loss at step 61800: 0.182586\n",
      "2023-12-10 16:31:51,192 INFO     Training average positive_sample_loss at step 61900: 0.193089\n",
      "2023-12-10 16:31:51,192 INFO     Training average negative_sample_loss at step 61900: 0.168711\n",
      "2023-12-10 16:31:51,192 INFO     Training average loss at step 61900: 0.180900\n",
      "2023-12-10 16:32:34,024 INFO     Training average positive_sample_loss at step 62000: 0.193801\n",
      "2023-12-10 16:32:34,025 INFO     Training average negative_sample_loss at step 62000: 0.170991\n",
      "2023-12-10 16:32:34,025 INFO     Training average loss at step 62000: 0.182396\n",
      "2023-12-10 16:33:19,410 INFO     Training average positive_sample_loss at step 62100: 0.194009\n",
      "2023-12-10 16:33:19,410 INFO     Training average negative_sample_loss at step 62100: 0.170645\n",
      "2023-12-10 16:33:19,410 INFO     Training average loss at step 62100: 0.182327\n",
      "2023-12-10 16:34:04,578 INFO     Training average positive_sample_loss at step 62200: 0.195327\n",
      "2023-12-10 16:34:04,578 INFO     Training average negative_sample_loss at step 62200: 0.169989\n",
      "2023-12-10 16:34:04,578 INFO     Training average loss at step 62200: 0.182658\n",
      "2023-12-10 16:34:55,113 INFO     Training average positive_sample_loss at step 62300: 0.193471\n",
      "2023-12-10 16:34:55,114 INFO     Training average negative_sample_loss at step 62300: 0.170849\n",
      "2023-12-10 16:34:55,114 INFO     Training average loss at step 62300: 0.182160\n",
      "2023-12-10 16:35:38,875 INFO     Training average positive_sample_loss at step 62400: 0.192934\n",
      "2023-12-10 16:35:38,875 INFO     Training average negative_sample_loss at step 62400: 0.171421\n",
      "2023-12-10 16:35:38,875 INFO     Training average loss at step 62400: 0.182177\n",
      "2023-12-10 16:36:22,107 INFO     Training average positive_sample_loss at step 62500: 0.193342\n",
      "2023-12-10 16:36:22,107 INFO     Training average negative_sample_loss at step 62500: 0.169807\n",
      "2023-12-10 16:36:22,107 INFO     Training average loss at step 62500: 0.181574\n",
      "2023-12-10 16:37:05,015 INFO     Training average positive_sample_loss at step 62600: 0.194425\n",
      "2023-12-10 16:37:05,016 INFO     Training average negative_sample_loss at step 62600: 0.169608\n",
      "2023-12-10 16:37:05,016 INFO     Training average loss at step 62600: 0.182017\n",
      "2023-12-10 16:37:47,851 INFO     Training average positive_sample_loss at step 62700: 0.195273\n",
      "2023-12-10 16:37:47,851 INFO     Training average negative_sample_loss at step 62700: 0.170964\n",
      "2023-12-10 16:37:47,851 INFO     Training average loss at step 62700: 0.183119\n",
      "2023-12-10 16:38:39,848 INFO     Training average positive_sample_loss at step 62800: 0.194998\n",
      "2023-12-10 16:38:39,848 INFO     Training average negative_sample_loss at step 62800: 0.170591\n",
      "2023-12-10 16:38:39,848 INFO     Training average loss at step 62800: 0.182794\n",
      "2023-12-10 16:39:21,815 INFO     Training average positive_sample_loss at step 62900: 0.192268\n",
      "2023-12-10 16:39:21,815 INFO     Training average negative_sample_loss at step 62900: 0.170979\n",
      "2023-12-10 16:39:21,815 INFO     Training average loss at step 62900: 0.181623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 16:40:04,024 INFO     Training average positive_sample_loss at step 63000: 0.193745\n",
      "2023-12-10 16:40:04,024 INFO     Training average negative_sample_loss at step 63000: 0.170488\n",
      "2023-12-10 16:40:04,024 INFO     Training average loss at step 63000: 0.182116\n",
      "2023-12-10 16:40:47,247 INFO     Training average positive_sample_loss at step 63100: 0.194452\n",
      "2023-12-10 16:40:47,247 INFO     Training average negative_sample_loss at step 63100: 0.169683\n",
      "2023-12-10 16:40:47,247 INFO     Training average loss at step 63100: 0.182067\n",
      "2023-12-10 16:41:31,188 INFO     Training average positive_sample_loss at step 63200: 0.194629\n",
      "2023-12-10 16:41:31,189 INFO     Training average negative_sample_loss at step 63200: 0.171112\n",
      "2023-12-10 16:41:31,189 INFO     Training average loss at step 63200: 0.182870\n",
      "2023-12-10 16:42:15,331 INFO     Training average positive_sample_loss at step 63300: 0.195061\n",
      "2023-12-10 16:42:15,331 INFO     Training average negative_sample_loss at step 63300: 0.171125\n",
      "2023-12-10 16:42:15,331 INFO     Training average loss at step 63300: 0.183093\n",
      "2023-12-10 16:43:08,218 INFO     Training average positive_sample_loss at step 63400: 0.192913\n",
      "2023-12-10 16:43:08,218 INFO     Training average negative_sample_loss at step 63400: 0.170316\n",
      "2023-12-10 16:43:08,219 INFO     Training average loss at step 63400: 0.181614\n",
      "2023-12-10 16:43:51,694 INFO     Training average positive_sample_loss at step 63500: 0.193347\n",
      "2023-12-10 16:43:51,695 INFO     Training average negative_sample_loss at step 63500: 0.170654\n",
      "2023-12-10 16:43:51,695 INFO     Training average loss at step 63500: 0.182001\n",
      "2023-12-10 16:44:35,064 INFO     Training average positive_sample_loss at step 63600: 0.192783\n",
      "2023-12-10 16:44:35,064 INFO     Training average negative_sample_loss at step 63600: 0.170449\n",
      "2023-12-10 16:44:35,064 INFO     Training average loss at step 63600: 0.181616\n",
      "2023-12-10 16:45:18,305 INFO     Training average positive_sample_loss at step 63700: 0.195303\n",
      "2023-12-10 16:45:18,305 INFO     Training average negative_sample_loss at step 63700: 0.172140\n",
      "2023-12-10 16:45:18,305 INFO     Training average loss at step 63700: 0.183722\n",
      "2023-12-10 16:46:01,901 INFO     Training average positive_sample_loss at step 63800: 0.196270\n",
      "2023-12-10 16:46:01,902 INFO     Training average negative_sample_loss at step 63800: 0.170717\n",
      "2023-12-10 16:46:01,902 INFO     Training average loss at step 63800: 0.183494\n",
      "2023-12-10 16:46:49,600 INFO     Training average positive_sample_loss at step 63900: 0.192479\n",
      "2023-12-10 16:46:49,600 INFO     Training average negative_sample_loss at step 63900: 0.171127\n",
      "2023-12-10 16:46:49,600 INFO     Training average loss at step 63900: 0.181803\n",
      "2023-12-10 16:47:33,605 INFO     Training average positive_sample_loss at step 64000: 0.193770\n",
      "2023-12-10 16:47:33,606 INFO     Training average negative_sample_loss at step 64000: 0.170720\n",
      "2023-12-10 16:47:33,606 INFO     Training average loss at step 64000: 0.182245\n",
      "2023-12-10 16:48:16,950 INFO     Training average positive_sample_loss at step 64100: 0.193657\n",
      "2023-12-10 16:48:16,951 INFO     Training average negative_sample_loss at step 64100: 0.170471\n",
      "2023-12-10 16:48:16,951 INFO     Training average loss at step 64100: 0.182064\n",
      "2023-12-10 16:49:00,774 INFO     Training average positive_sample_loss at step 64200: 0.194845\n",
      "2023-12-10 16:49:00,775 INFO     Training average negative_sample_loss at step 64200: 0.171683\n",
      "2023-12-10 16:49:00,775 INFO     Training average loss at step 64200: 0.183264\n",
      "2023-12-10 16:49:44,645 INFO     Training average positive_sample_loss at step 64300: 0.195870\n",
      "2023-12-10 16:49:44,645 INFO     Training average negative_sample_loss at step 64300: 0.169670\n",
      "2023-12-10 16:49:44,646 INFO     Training average loss at step 64300: 0.182770\n",
      "2023-12-10 16:50:34,164 INFO     Training average positive_sample_loss at step 64400: 0.193948\n",
      "2023-12-10 16:50:34,164 INFO     Training average negative_sample_loss at step 64400: 0.171457\n",
      "2023-12-10 16:50:34,164 INFO     Training average loss at step 64400: 0.182702\n",
      "2023-12-10 16:51:17,256 INFO     Training average positive_sample_loss at step 64500: 0.192823\n",
      "2023-12-10 16:51:17,256 INFO     Training average negative_sample_loss at step 64500: 0.170573\n",
      "2023-12-10 16:51:17,256 INFO     Training average loss at step 64500: 0.181698\n",
      "2023-12-10 16:51:59,997 INFO     Training average positive_sample_loss at step 64600: 0.193975\n",
      "2023-12-10 16:51:59,997 INFO     Training average negative_sample_loss at step 64600: 0.171233\n",
      "2023-12-10 16:51:59,997 INFO     Training average loss at step 64600: 0.182604\n",
      "2023-12-10 16:52:45,368 INFO     Training average positive_sample_loss at step 64700: 0.194529\n",
      "2023-12-10 16:52:45,369 INFO     Training average negative_sample_loss at step 64700: 0.171932\n",
      "2023-12-10 16:52:45,369 INFO     Training average loss at step 64700: 0.183231\n",
      "2023-12-10 16:53:29,278 INFO     Training average positive_sample_loss at step 64800: 0.194459\n",
      "2023-12-10 16:53:29,278 INFO     Training average negative_sample_loss at step 64800: 0.169833\n",
      "2023-12-10 16:53:29,278 INFO     Training average loss at step 64800: 0.182146\n",
      "2023-12-10 16:54:12,722 INFO     Training average positive_sample_loss at step 64900: 0.195804\n",
      "2023-12-10 16:54:12,723 INFO     Training average negative_sample_loss at step 64900: 0.171466\n",
      "2023-12-10 16:54:12,723 INFO     Training average loss at step 64900: 0.183635\n",
      "2023-12-10 16:55:01,696 INFO     Training average positive_sample_loss at step 65000: 0.193457\n",
      "2023-12-10 16:55:01,697 INFO     Training average negative_sample_loss at step 65000: 0.171077\n",
      "2023-12-10 16:55:01,697 INFO     Training average loss at step 65000: 0.182267\n",
      "2023-12-10 16:55:45,433 INFO     Training average positive_sample_loss at step 65100: 0.193186\n",
      "2023-12-10 16:55:45,433 INFO     Training average negative_sample_loss at step 65100: 0.170784\n",
      "2023-12-10 16:55:45,433 INFO     Training average loss at step 65100: 0.181985\n",
      "2023-12-10 16:56:29,704 INFO     Training average positive_sample_loss at step 65200: 0.193687\n",
      "2023-12-10 16:56:29,705 INFO     Training average negative_sample_loss at step 65200: 0.170713\n",
      "2023-12-10 16:56:29,705 INFO     Training average loss at step 65200: 0.182200\n",
      "2023-12-10 16:57:14,934 INFO     Training average positive_sample_loss at step 65300: 0.194752\n",
      "2023-12-10 16:57:14,934 INFO     Training average negative_sample_loss at step 65300: 0.171098\n",
      "2023-12-10 16:57:14,934 INFO     Training average loss at step 65300: 0.182925\n",
      "2023-12-10 16:57:58,829 INFO     Training average positive_sample_loss at step 65400: 0.195364\n",
      "2023-12-10 16:57:58,830 INFO     Training average negative_sample_loss at step 65400: 0.170523\n",
      "2023-12-10 16:57:58,830 INFO     Training average loss at step 65400: 0.182944\n",
      "2023-12-10 16:58:51,609 INFO     Training average positive_sample_loss at step 65500: 0.194040\n",
      "2023-12-10 16:58:51,610 INFO     Training average negative_sample_loss at step 65500: 0.170273\n",
      "2023-12-10 16:58:51,610 INFO     Training average loss at step 65500: 0.182157\n",
      "2023-12-10 16:59:34,249 INFO     Training average positive_sample_loss at step 65600: 0.193404\n",
      "2023-12-10 16:59:34,249 INFO     Training average negative_sample_loss at step 65600: 0.170576\n",
      "2023-12-10 16:59:34,249 INFO     Training average loss at step 65600: 0.181990\n",
      "2023-12-10 17:00:17,558 INFO     Training average positive_sample_loss at step 65700: 0.194240\n",
      "2023-12-10 17:00:17,559 INFO     Training average negative_sample_loss at step 65700: 0.169819\n",
      "2023-12-10 17:00:17,559 INFO     Training average loss at step 65700: 0.182030\n",
      "2023-12-10 17:01:02,168 INFO     Training average positive_sample_loss at step 65800: 0.194864\n",
      "2023-12-10 17:01:02,168 INFO     Training average negative_sample_loss at step 65800: 0.170541\n",
      "2023-12-10 17:01:02,168 INFO     Training average loss at step 65800: 0.182702\n",
      "2023-12-10 17:01:45,693 INFO     Training average positive_sample_loss at step 65900: 0.194378\n",
      "2023-12-10 17:01:45,694 INFO     Training average negative_sample_loss at step 65900: 0.169865\n",
      "2023-12-10 17:01:45,694 INFO     Training average loss at step 65900: 0.182121\n",
      "2023-12-10 17:02:35,713 INFO     Training average positive_sample_loss at step 66000: 0.194031\n",
      "2023-12-10 17:02:35,713 INFO     Training average negative_sample_loss at step 66000: 0.171376\n",
      "2023-12-10 17:02:35,713 INFO     Training average loss at step 66000: 0.182703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 17:03:18,781 INFO     Training average positive_sample_loss at step 66100: 0.193825\n",
      "2023-12-10 17:03:18,782 INFO     Training average negative_sample_loss at step 66100: 0.169718\n",
      "2023-12-10 17:03:18,782 INFO     Training average loss at step 66100: 0.181771\n",
      "2023-12-10 17:04:02,919 INFO     Training average positive_sample_loss at step 66200: 0.193321\n",
      "2023-12-10 17:04:02,920 INFO     Training average negative_sample_loss at step 66200: 0.170334\n",
      "2023-12-10 17:04:02,920 INFO     Training average loss at step 66200: 0.181828\n",
      "2023-12-10 17:04:44,609 INFO     Training average positive_sample_loss at step 66300: 0.194160\n",
      "2023-12-10 17:04:44,610 INFO     Training average negative_sample_loss at step 66300: 0.170300\n",
      "2023-12-10 17:04:44,610 INFO     Training average loss at step 66300: 0.182230\n",
      "2023-12-10 17:05:27,838 INFO     Training average positive_sample_loss at step 66400: 0.194428\n",
      "2023-12-10 17:05:27,838 INFO     Training average negative_sample_loss at step 66400: 0.170434\n",
      "2023-12-10 17:05:27,838 INFO     Training average loss at step 66400: 0.182431\n",
      "2023-12-10 17:06:16,187 INFO     Training average positive_sample_loss at step 66500: 0.195713\n",
      "2023-12-10 17:06:16,188 INFO     Training average negative_sample_loss at step 66500: 0.172017\n",
      "2023-12-10 17:06:16,188 INFO     Training average loss at step 66500: 0.183865\n",
      "2023-12-10 17:07:01,750 INFO     Training average positive_sample_loss at step 66600: 0.192915\n",
      "2023-12-10 17:07:01,751 INFO     Training average negative_sample_loss at step 66600: 0.170588\n",
      "2023-12-10 17:07:01,751 INFO     Training average loss at step 66600: 0.181752\n",
      "2023-12-10 17:07:47,744 INFO     Training average positive_sample_loss at step 66700: 0.192904\n",
      "2023-12-10 17:07:47,744 INFO     Training average negative_sample_loss at step 66700: 0.169630\n",
      "2023-12-10 17:07:47,744 INFO     Training average loss at step 66700: 0.181267\n",
      "2023-12-10 17:08:33,733 INFO     Training average positive_sample_loss at step 66800: 0.194720\n",
      "2023-12-10 17:08:33,734 INFO     Training average negative_sample_loss at step 66800: 0.171289\n",
      "2023-12-10 17:08:33,734 INFO     Training average loss at step 66800: 0.183004\n",
      "2023-12-10 17:09:18,099 INFO     Training average positive_sample_loss at step 66900: 0.195455\n",
      "2023-12-10 17:09:18,099 INFO     Training average negative_sample_loss at step 66900: 0.170912\n",
      "2023-12-10 17:09:18,099 INFO     Training average loss at step 66900: 0.183184\n",
      "2023-12-10 17:10:02,506 INFO     Training average positive_sample_loss at step 67000: 0.194696\n",
      "2023-12-10 17:10:02,507 INFO     Training average negative_sample_loss at step 67000: 0.170652\n",
      "2023-12-10 17:10:02,507 INFO     Training average loss at step 67000: 0.182674\n",
      "2023-12-10 17:10:55,720 INFO     Training average positive_sample_loss at step 67100: 0.193460\n",
      "2023-12-10 17:10:55,721 INFO     Training average negative_sample_loss at step 67100: 0.170835\n",
      "2023-12-10 17:10:55,721 INFO     Training average loss at step 67100: 0.182148\n",
      "2023-12-10 17:11:39,549 INFO     Training average positive_sample_loss at step 67200: 0.192868\n",
      "2023-12-10 17:11:39,550 INFO     Training average negative_sample_loss at step 67200: 0.170798\n",
      "2023-12-10 17:11:39,550 INFO     Training average loss at step 67200: 0.181833\n",
      "2023-12-10 17:12:22,959 INFO     Training average positive_sample_loss at step 67300: 0.194364\n",
      "2023-12-10 17:12:22,960 INFO     Training average negative_sample_loss at step 67300: 0.170792\n",
      "2023-12-10 17:12:22,960 INFO     Training average loss at step 67300: 0.182578\n",
      "2023-12-10 17:13:07,625 INFO     Training average positive_sample_loss at step 67400: 0.194868\n",
      "2023-12-10 17:13:07,625 INFO     Training average negative_sample_loss at step 67400: 0.170577\n",
      "2023-12-10 17:13:07,625 INFO     Training average loss at step 67400: 0.182723\n",
      "2023-12-10 17:13:51,999 INFO     Training average positive_sample_loss at step 67500: 0.195339\n",
      "2023-12-10 17:13:51,999 INFO     Training average negative_sample_loss at step 67500: 0.169958\n",
      "2023-12-10 17:13:51,999 INFO     Training average loss at step 67500: 0.182649\n",
      "2023-12-10 17:14:40,788 INFO     Training average positive_sample_loss at step 67600: 0.193978\n",
      "2023-12-10 17:14:40,788 INFO     Training average negative_sample_loss at step 67600: 0.171143\n",
      "2023-12-10 17:14:40,788 INFO     Training average loss at step 67600: 0.182561\n",
      "2023-12-10 17:15:24,493 INFO     Training average positive_sample_loss at step 67700: 0.192564\n",
      "2023-12-10 17:15:24,494 INFO     Training average negative_sample_loss at step 67700: 0.170955\n",
      "2023-12-10 17:15:24,494 INFO     Training average loss at step 67700: 0.181759\n",
      "2023-12-10 17:16:08,415 INFO     Training average positive_sample_loss at step 67800: 0.193711\n",
      "2023-12-10 17:16:08,416 INFO     Training average negative_sample_loss at step 67800: 0.170127\n",
      "2023-12-10 17:16:08,416 INFO     Training average loss at step 67800: 0.181919\n",
      "2023-12-10 17:16:52,206 INFO     Training average positive_sample_loss at step 67900: 0.194788\n",
      "2023-12-10 17:16:52,206 INFO     Training average negative_sample_loss at step 67900: 0.170772\n",
      "2023-12-10 17:16:52,206 INFO     Training average loss at step 67900: 0.182780\n",
      "2023-12-10 17:17:36,212 INFO     Training average positive_sample_loss at step 68000: 0.195275\n",
      "2023-12-10 17:17:36,212 INFO     Training average negative_sample_loss at step 68000: 0.169610\n",
      "2023-12-10 17:17:36,212 INFO     Training average loss at step 68000: 0.182443\n",
      "2023-12-10 17:18:28,867 INFO     Training average positive_sample_loss at step 68100: 0.195726\n",
      "2023-12-10 17:18:28,867 INFO     Training average negative_sample_loss at step 68100: 0.171708\n",
      "2023-12-10 17:18:28,867 INFO     Training average loss at step 68100: 0.183717\n",
      "2023-12-10 17:19:11,320 INFO     Training average positive_sample_loss at step 68200: 0.193101\n",
      "2023-12-10 17:19:11,320 INFO     Training average negative_sample_loss at step 68200: 0.171619\n",
      "2023-12-10 17:19:11,320 INFO     Training average loss at step 68200: 0.182360\n",
      "2023-12-10 17:19:53,098 INFO     Training average positive_sample_loss at step 68300: 0.193395\n",
      "2023-12-10 17:19:53,098 INFO     Training average negative_sample_loss at step 68300: 0.170516\n",
      "2023-12-10 17:19:53,098 INFO     Training average loss at step 68300: 0.181956\n",
      "2023-12-10 17:20:37,098 INFO     Training average positive_sample_loss at step 68400: 0.194879\n",
      "2023-12-10 17:20:37,098 INFO     Training average negative_sample_loss at step 68400: 0.170862\n",
      "2023-12-10 17:20:37,098 INFO     Training average loss at step 68400: 0.182871\n",
      "2023-12-10 17:21:20,024 INFO     Training average positive_sample_loss at step 68500: 0.194474\n",
      "2023-12-10 17:21:20,024 INFO     Training average negative_sample_loss at step 68500: 0.170108\n",
      "2023-12-10 17:21:20,024 INFO     Training average loss at step 68500: 0.182291\n",
      "2023-12-10 17:22:02,821 INFO     Training average positive_sample_loss at step 68600: 0.194761\n",
      "2023-12-10 17:22:02,821 INFO     Training average negative_sample_loss at step 68600: 0.169508\n",
      "2023-12-10 17:22:02,821 INFO     Training average loss at step 68600: 0.182135\n",
      "2023-12-10 17:22:54,485 INFO     Training average positive_sample_loss at step 68700: 0.194052\n",
      "2023-12-10 17:22:54,485 INFO     Training average negative_sample_loss at step 68700: 0.170509\n",
      "2023-12-10 17:22:54,485 INFO     Training average loss at step 68700: 0.182281\n",
      "2023-12-10 17:23:37,321 INFO     Training average positive_sample_loss at step 68800: 0.193568\n",
      "2023-12-10 17:23:37,321 INFO     Training average negative_sample_loss at step 68800: 0.170299\n",
      "2023-12-10 17:23:37,321 INFO     Training average loss at step 68800: 0.181933\n",
      "2023-12-10 17:24:19,752 INFO     Training average positive_sample_loss at step 68900: 0.193984\n",
      "2023-12-10 17:24:19,753 INFO     Training average negative_sample_loss at step 68900: 0.170074\n",
      "2023-12-10 17:24:19,753 INFO     Training average loss at step 68900: 0.182029\n",
      "2023-12-10 17:25:02,411 INFO     Training average positive_sample_loss at step 69000: 0.194692\n",
      "2023-12-10 17:25:02,411 INFO     Training average negative_sample_loss at step 69000: 0.170425\n",
      "2023-12-10 17:25:02,411 INFO     Training average loss at step 69000: 0.182559\n",
      "2023-12-10 17:25:46,157 INFO     Training average positive_sample_loss at step 69100: 0.194544\n",
      "2023-12-10 17:25:46,157 INFO     Training average negative_sample_loss at step 69100: 0.169583\n",
      "2023-12-10 17:25:46,157 INFO     Training average loss at step 69100: 0.182063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 17:26:35,724 INFO     Training average positive_sample_loss at step 69200: 0.194085\n",
      "2023-12-10 17:26:35,724 INFO     Training average negative_sample_loss at step 69200: 0.171525\n",
      "2023-12-10 17:26:35,724 INFO     Training average loss at step 69200: 0.182805\n",
      "2023-12-10 17:27:19,282 INFO     Training average positive_sample_loss at step 69300: 0.193100\n",
      "2023-12-10 17:27:19,282 INFO     Training average negative_sample_loss at step 69300: 0.171107\n",
      "2023-12-10 17:27:19,282 INFO     Training average loss at step 69300: 0.182103\n",
      "2023-12-10 17:28:06,186 INFO     Training average positive_sample_loss at step 69400: 0.193321\n",
      "2023-12-10 17:28:06,187 INFO     Training average negative_sample_loss at step 69400: 0.170900\n",
      "2023-12-10 17:28:06,187 INFO     Training average loss at step 69400: 0.182111\n",
      "2023-12-10 17:28:49,568 INFO     Training average positive_sample_loss at step 69500: 0.194797\n",
      "2023-12-10 17:28:49,569 INFO     Training average negative_sample_loss at step 69500: 0.170663\n",
      "2023-12-10 17:28:49,569 INFO     Training average loss at step 69500: 0.182730\n",
      "2023-12-10 17:29:32,327 INFO     Training average positive_sample_loss at step 69600: 0.195263\n",
      "2023-12-10 17:29:32,327 INFO     Training average negative_sample_loss at step 69600: 0.170957\n",
      "2023-12-10 17:29:32,328 INFO     Training average loss at step 69600: 0.183110\n",
      "2023-12-10 17:30:20,920 INFO     Training average positive_sample_loss at step 69700: 0.194614\n",
      "2023-12-10 17:30:20,920 INFO     Training average negative_sample_loss at step 69700: 0.169710\n",
      "2023-12-10 17:30:20,920 INFO     Training average loss at step 69700: 0.182162\n",
      "2023-12-10 17:31:04,655 INFO     Training average positive_sample_loss at step 69800: 0.193463\n",
      "2023-12-10 17:31:04,656 INFO     Training average negative_sample_loss at step 69800: 0.170925\n",
      "2023-12-10 17:31:04,656 INFO     Training average loss at step 69800: 0.182194\n",
      "2023-12-10 17:31:48,713 INFO     Training average positive_sample_loss at step 69900: 0.193844\n",
      "2023-12-10 17:31:48,713 INFO     Training average negative_sample_loss at step 69900: 0.169692\n",
      "2023-12-10 17:31:48,713 INFO     Training average loss at step 69900: 0.181768\n",
      "2023-12-10 17:32:40,296 INFO     Training average positive_sample_loss at step 70000: 0.194177\n",
      "2023-12-10 17:32:40,296 INFO     Training average negative_sample_loss at step 70000: 0.169888\n",
      "2023-12-10 17:32:40,296 INFO     Training average loss at step 70000: 0.182032\n",
      "2023-12-10 17:32:40,296 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 17:32:40,961 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 17:33:18,657 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 17:33:55,952 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 17:34:01,257 INFO     Valid MRR at step 70000: 0.324742\n",
      "2023-12-10 17:34:01,257 INFO     Valid MR at step 70000: 153.859053\n",
      "2023-12-10 17:34:01,257 INFO     Valid HITS@1 at step 70000: 0.230140\n",
      "2023-12-10 17:34:01,257 INFO     Valid HITS@3 at step 70000: 0.357770\n",
      "2023-12-10 17:34:01,257 INFO     Valid HITS@10 at step 70000: 0.520416\n",
      "2023-12-10 17:34:37,815 INFO     Training average positive_sample_loss at step 70100: 0.194525\n",
      "2023-12-10 17:34:37,816 INFO     Training average negative_sample_loss at step 70100: 0.170282\n",
      "2023-12-10 17:34:37,816 INFO     Training average loss at step 70100: 0.182404\n",
      "2023-12-10 17:35:22,041 INFO     Training average positive_sample_loss at step 70200: 0.195052\n",
      "2023-12-10 17:35:22,042 INFO     Training average negative_sample_loss at step 70200: 0.171134\n",
      "2023-12-10 17:35:22,042 INFO     Training average loss at step 70200: 0.183093\n",
      "2023-12-10 17:36:12,895 INFO     Training average positive_sample_loss at step 70300: 0.193257\n",
      "2023-12-10 17:36:12,896 INFO     Training average negative_sample_loss at step 70300: 0.170483\n",
      "2023-12-10 17:36:12,896 INFO     Training average loss at step 70300: 0.181870\n",
      "2023-12-10 17:36:56,708 INFO     Training average positive_sample_loss at step 70400: 0.193127\n",
      "2023-12-10 17:36:56,709 INFO     Training average negative_sample_loss at step 70400: 0.170323\n",
      "2023-12-10 17:36:56,709 INFO     Training average loss at step 70400: 0.181725\n",
      "2023-12-10 17:37:40,318 INFO     Training average positive_sample_loss at step 70500: 0.194172\n",
      "2023-12-10 17:37:40,318 INFO     Training average negative_sample_loss at step 70500: 0.169911\n",
      "2023-12-10 17:37:40,318 INFO     Training average loss at step 70500: 0.182041\n",
      "2023-12-10 17:38:24,013 INFO     Training average positive_sample_loss at step 70600: 0.193989\n",
      "2023-12-10 17:38:24,014 INFO     Training average negative_sample_loss at step 70600: 0.169984\n",
      "2023-12-10 17:38:24,014 INFO     Training average loss at step 70600: 0.181986\n",
      "2023-12-10 17:39:07,435 INFO     Training average positive_sample_loss at step 70700: 0.195277\n",
      "2023-12-10 17:39:07,435 INFO     Training average negative_sample_loss at step 70700: 0.169722\n",
      "2023-12-10 17:39:07,435 INFO     Training average loss at step 70700: 0.182500\n",
      "2023-12-10 17:39:59,817 INFO     Training average positive_sample_loss at step 70800: 0.195059\n",
      "2023-12-10 17:39:59,817 INFO     Training average negative_sample_loss at step 70800: 0.171158\n",
      "2023-12-10 17:39:59,818 INFO     Training average loss at step 70800: 0.183109\n",
      "2023-12-10 17:40:44,301 INFO     Training average positive_sample_loss at step 70900: 0.192521\n",
      "2023-12-10 17:40:44,301 INFO     Training average negative_sample_loss at step 70900: 0.170053\n",
      "2023-12-10 17:40:44,301 INFO     Training average loss at step 70900: 0.181287\n",
      "2023-12-10 17:41:28,752 INFO     Training average positive_sample_loss at step 71000: 0.194103\n",
      "2023-12-10 17:41:28,753 INFO     Training average negative_sample_loss at step 71000: 0.170559\n",
      "2023-12-10 17:41:28,753 INFO     Training average loss at step 71000: 0.182331\n",
      "2023-12-10 17:42:12,173 INFO     Training average positive_sample_loss at step 71100: 0.194420\n",
      "2023-12-10 17:42:12,173 INFO     Training average negative_sample_loss at step 71100: 0.169721\n",
      "2023-12-10 17:42:12,173 INFO     Training average loss at step 71100: 0.182070\n",
      "2023-12-10 17:42:57,642 INFO     Training average positive_sample_loss at step 71200: 0.194867\n",
      "2023-12-10 17:42:57,643 INFO     Training average negative_sample_loss at step 71200: 0.170455\n",
      "2023-12-10 17:42:57,643 INFO     Training average loss at step 71200: 0.182661\n",
      "2023-12-10 17:43:50,217 INFO     Training average positive_sample_loss at step 71300: 0.194625\n",
      "2023-12-10 17:43:50,218 INFO     Training average negative_sample_loss at step 71300: 0.170120\n",
      "2023-12-10 17:43:50,218 INFO     Training average loss at step 71300: 0.182372\n",
      "2023-12-10 17:44:34,688 INFO     Training average positive_sample_loss at step 71400: 0.192910\n",
      "2023-12-10 17:44:34,689 INFO     Training average negative_sample_loss at step 71400: 0.170183\n",
      "2023-12-10 17:44:34,689 INFO     Training average loss at step 71400: 0.181546\n",
      "2023-12-10 17:45:19,061 INFO     Training average positive_sample_loss at step 71500: 0.193133\n",
      "2023-12-10 17:45:19,062 INFO     Training average negative_sample_loss at step 71500: 0.170015\n",
      "2023-12-10 17:45:19,062 INFO     Training average loss at step 71500: 0.181574\n",
      "2023-12-10 17:46:03,558 INFO     Training average positive_sample_loss at step 71600: 0.194853\n",
      "2023-12-10 17:46:03,558 INFO     Training average negative_sample_loss at step 71600: 0.171194\n",
      "2023-12-10 17:46:03,558 INFO     Training average loss at step 71600: 0.183024\n",
      "2023-12-10 17:46:48,015 INFO     Training average positive_sample_loss at step 71700: 0.195019\n",
      "2023-12-10 17:46:48,015 INFO     Training average negative_sample_loss at step 71700: 0.170912\n",
      "2023-12-10 17:46:48,015 INFO     Training average loss at step 71700: 0.182966\n",
      "2023-12-10 17:47:31,941 INFO     Training average positive_sample_loss at step 71800: 0.194763\n",
      "2023-12-10 17:47:31,942 INFO     Training average negative_sample_loss at step 71800: 0.170621\n",
      "2023-12-10 17:47:31,942 INFO     Training average loss at step 71800: 0.182692\n",
      "2023-12-10 17:48:20,210 INFO     Training average positive_sample_loss at step 71900: 0.193202\n",
      "2023-12-10 17:48:20,211 INFO     Training average negative_sample_loss at step 71900: 0.170623\n",
      "2023-12-10 17:48:20,211 INFO     Training average loss at step 71900: 0.181912\n",
      "2023-12-10 17:49:03,433 INFO     Training average positive_sample_loss at step 72000: 0.193025\n",
      "2023-12-10 17:49:03,433 INFO     Training average negative_sample_loss at step 72000: 0.170041\n",
      "2023-12-10 17:49:03,433 INFO     Training average loss at step 72000: 0.181533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 17:49:47,467 INFO     Training average positive_sample_loss at step 72100: 0.193530\n",
      "2023-12-10 17:49:47,468 INFO     Training average negative_sample_loss at step 72100: 0.170039\n",
      "2023-12-10 17:49:47,468 INFO     Training average loss at step 72100: 0.181785\n",
      "2023-12-10 17:50:31,408 INFO     Training average positive_sample_loss at step 72200: 0.195460\n",
      "2023-12-10 17:50:31,409 INFO     Training average negative_sample_loss at step 72200: 0.170763\n",
      "2023-12-10 17:50:31,409 INFO     Training average loss at step 72200: 0.183111\n",
      "2023-12-10 17:51:15,313 INFO     Training average positive_sample_loss at step 72300: 0.196063\n",
      "2023-12-10 17:51:15,313 INFO     Training average negative_sample_loss at step 72300: 0.169570\n",
      "2023-12-10 17:51:15,313 INFO     Training average loss at step 72300: 0.182816\n",
      "2023-12-10 17:52:04,875 INFO     Training average positive_sample_loss at step 72400: 0.193017\n",
      "2023-12-10 17:52:04,876 INFO     Training average negative_sample_loss at step 72400: 0.170039\n",
      "2023-12-10 17:52:04,876 INFO     Training average loss at step 72400: 0.181528\n",
      "2023-12-10 17:52:48,777 INFO     Training average positive_sample_loss at step 72500: 0.193247\n",
      "2023-12-10 17:52:48,777 INFO     Training average negative_sample_loss at step 72500: 0.171052\n",
      "2023-12-10 17:52:48,777 INFO     Training average loss at step 72500: 0.182150\n",
      "2023-12-10 17:53:33,011 INFO     Training average positive_sample_loss at step 72600: 0.193872\n",
      "2023-12-10 17:53:33,011 INFO     Training average negative_sample_loss at step 72600: 0.170287\n",
      "2023-12-10 17:53:33,011 INFO     Training average loss at step 72600: 0.182079\n",
      "2023-12-10 17:54:16,586 INFO     Training average positive_sample_loss at step 72700: 0.194904\n",
      "2023-12-10 17:54:16,587 INFO     Training average negative_sample_loss at step 72700: 0.171170\n",
      "2023-12-10 17:54:16,587 INFO     Training average loss at step 72700: 0.183037\n",
      "2023-12-10 17:54:59,767 INFO     Training average positive_sample_loss at step 72800: 0.195176\n",
      "2023-12-10 17:54:59,767 INFO     Training average negative_sample_loss at step 72800: 0.169702\n",
      "2023-12-10 17:54:59,767 INFO     Training average loss at step 72800: 0.182439\n",
      "2023-12-10 17:55:49,014 INFO     Training average positive_sample_loss at step 72900: 0.194698\n",
      "2023-12-10 17:55:49,014 INFO     Training average negative_sample_loss at step 72900: 0.171062\n",
      "2023-12-10 17:55:49,014 INFO     Training average loss at step 72900: 0.182880\n",
      "2023-12-10 17:56:32,768 INFO     Training average positive_sample_loss at step 73000: 0.193327\n",
      "2023-12-10 17:56:32,768 INFO     Training average negative_sample_loss at step 73000: 0.170515\n",
      "2023-12-10 17:56:32,768 INFO     Training average loss at step 73000: 0.181921\n",
      "2023-12-10 17:57:16,279 INFO     Training average positive_sample_loss at step 73100: 0.192872\n",
      "2023-12-10 17:57:16,279 INFO     Training average negative_sample_loss at step 73100: 0.169657\n",
      "2023-12-10 17:57:16,280 INFO     Training average loss at step 73100: 0.181264\n",
      "2023-12-10 17:58:00,160 INFO     Training average positive_sample_loss at step 73200: 0.193850\n",
      "2023-12-10 17:58:00,161 INFO     Training average negative_sample_loss at step 73200: 0.168822\n",
      "2023-12-10 17:58:00,161 INFO     Training average loss at step 73200: 0.181336\n",
      "2023-12-10 17:58:44,017 INFO     Training average positive_sample_loss at step 73300: 0.194939\n",
      "2023-12-10 17:58:44,018 INFO     Training average negative_sample_loss at step 73300: 0.170933\n",
      "2023-12-10 17:58:44,018 INFO     Training average loss at step 73300: 0.182936\n",
      "2023-12-10 17:59:27,910 INFO     Training average positive_sample_loss at step 73400: 0.196244\n",
      "2023-12-10 17:59:27,910 INFO     Training average negative_sample_loss at step 73400: 0.171801\n",
      "2023-12-10 17:59:27,910 INFO     Training average loss at step 73400: 0.184022\n",
      "2023-12-10 18:00:18,828 INFO     Training average positive_sample_loss at step 73500: 0.192918\n",
      "2023-12-10 18:00:18,829 INFO     Training average negative_sample_loss at step 73500: 0.169500\n",
      "2023-12-10 18:00:18,829 INFO     Training average loss at step 73500: 0.181209\n",
      "2023-12-10 18:01:03,270 INFO     Training average positive_sample_loss at step 73600: 0.193160\n",
      "2023-12-10 18:01:03,271 INFO     Training average negative_sample_loss at step 73600: 0.169695\n",
      "2023-12-10 18:01:03,271 INFO     Training average loss at step 73600: 0.181428\n",
      "2023-12-10 18:01:47,038 INFO     Training average positive_sample_loss at step 73700: 0.194002\n",
      "2023-12-10 18:01:47,039 INFO     Training average negative_sample_loss at step 73700: 0.170542\n",
      "2023-12-10 18:01:47,039 INFO     Training average loss at step 73700: 0.182272\n",
      "2023-12-10 18:02:33,015 INFO     Training average positive_sample_loss at step 73800: 0.194933\n",
      "2023-12-10 18:02:33,016 INFO     Training average negative_sample_loss at step 73800: 0.171133\n",
      "2023-12-10 18:02:33,016 INFO     Training average loss at step 73800: 0.183033\n",
      "2023-12-10 18:03:17,129 INFO     Training average positive_sample_loss at step 73900: 0.195372\n",
      "2023-12-10 18:03:17,130 INFO     Training average negative_sample_loss at step 73900: 0.170627\n",
      "2023-12-10 18:03:17,130 INFO     Training average loss at step 73900: 0.182999\n",
      "2023-12-10 18:04:08,605 INFO     Training average positive_sample_loss at step 74000: 0.194394\n",
      "2023-12-10 18:04:08,606 INFO     Training average negative_sample_loss at step 74000: 0.169613\n",
      "2023-12-10 18:04:08,606 INFO     Training average loss at step 74000: 0.182004\n",
      "2023-12-10 18:04:50,457 INFO     Training average positive_sample_loss at step 74100: 0.193203\n",
      "2023-12-10 18:04:50,457 INFO     Training average negative_sample_loss at step 74100: 0.169714\n",
      "2023-12-10 18:04:50,458 INFO     Training average loss at step 74100: 0.181458\n",
      "2023-12-10 18:05:34,104 INFO     Training average positive_sample_loss at step 74200: 0.193650\n",
      "2023-12-10 18:05:34,105 INFO     Training average negative_sample_loss at step 74200: 0.170678\n",
      "2023-12-10 18:05:34,105 INFO     Training average loss at step 74200: 0.182164\n",
      "2023-12-10 18:06:17,250 INFO     Training average positive_sample_loss at step 74300: 0.194781\n",
      "2023-12-10 18:06:17,251 INFO     Training average negative_sample_loss at step 74300: 0.170961\n",
      "2023-12-10 18:06:17,251 INFO     Training average loss at step 74300: 0.182871\n",
      "2023-12-10 18:07:00,062 INFO     Training average positive_sample_loss at step 74400: 0.194723\n",
      "2023-12-10 18:07:00,063 INFO     Training average negative_sample_loss at step 74400: 0.170153\n",
      "2023-12-10 18:07:00,063 INFO     Training average loss at step 74400: 0.182438\n",
      "2023-12-10 18:07:48,274 INFO     Training average positive_sample_loss at step 74500: 0.194467\n",
      "2023-12-10 18:07:48,275 INFO     Training average negative_sample_loss at step 74500: 0.169836\n",
      "2023-12-10 18:07:48,275 INFO     Training average loss at step 74500: 0.182151\n",
      "2023-12-10 18:08:32,143 INFO     Training average positive_sample_loss at step 74600: 0.192167\n",
      "2023-12-10 18:08:32,144 INFO     Training average negative_sample_loss at step 74600: 0.170470\n",
      "2023-12-10 18:08:32,144 INFO     Training average loss at step 74600: 0.181319\n",
      "2023-12-10 18:09:16,358 INFO     Training average positive_sample_loss at step 74700: 0.194134\n",
      "2023-12-10 18:09:16,359 INFO     Training average negative_sample_loss at step 74700: 0.169371\n",
      "2023-12-10 18:09:16,359 INFO     Training average loss at step 74700: 0.181752\n",
      "2023-12-10 18:10:00,023 INFO     Training average positive_sample_loss at step 74800: 0.194734\n",
      "2023-12-10 18:10:00,024 INFO     Training average negative_sample_loss at step 74800: 0.170264\n",
      "2023-12-10 18:10:00,024 INFO     Training average loss at step 74800: 0.182499\n",
      "2023-12-10 18:10:44,462 INFO     Training average positive_sample_loss at step 74900: 0.195745\n",
      "2023-12-10 18:10:44,463 INFO     Training average negative_sample_loss at step 74900: 0.171157\n",
      "2023-12-10 18:10:44,463 INFO     Training average loss at step 74900: 0.183451\n",
      "2023-12-10 18:11:27,811 INFO     Training average positive_sample_loss at step 75000: 0.195001\n",
      "2023-12-10 18:11:27,811 INFO     Training average negative_sample_loss at step 75000: 0.171130\n",
      "2023-12-10 18:11:27,812 INFO     Training average loss at step 75000: 0.183065\n",
      "2023-12-10 18:12:17,972 INFO     Training average positive_sample_loss at step 75100: 0.193298\n",
      "2023-12-10 18:12:17,973 INFO     Training average negative_sample_loss at step 75100: 0.170501\n",
      "2023-12-10 18:12:17,973 INFO     Training average loss at step 75100: 0.181900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 18:13:01,396 INFO     Training average positive_sample_loss at step 75200: 0.193710\n",
      "2023-12-10 18:13:01,397 INFO     Training average negative_sample_loss at step 75200: 0.169841\n",
      "2023-12-10 18:13:01,397 INFO     Training average loss at step 75200: 0.181776\n",
      "2023-12-10 18:13:45,972 INFO     Training average positive_sample_loss at step 75300: 0.193379\n",
      "2023-12-10 18:13:45,973 INFO     Training average negative_sample_loss at step 75300: 0.169500\n",
      "2023-12-10 18:13:45,973 INFO     Training average loss at step 75300: 0.181439\n",
      "2023-12-10 18:14:30,040 INFO     Training average positive_sample_loss at step 75400: 0.194700\n",
      "2023-12-10 18:14:30,040 INFO     Training average negative_sample_loss at step 75400: 0.169756\n",
      "2023-12-10 18:14:30,040 INFO     Training average loss at step 75400: 0.182228\n",
      "2023-12-10 18:15:14,174 INFO     Training average positive_sample_loss at step 75500: 0.194998\n",
      "2023-12-10 18:15:14,175 INFO     Training average negative_sample_loss at step 75500: 0.169829\n",
      "2023-12-10 18:15:14,175 INFO     Training average loss at step 75500: 0.182414\n",
      "2023-12-10 18:16:06,206 INFO     Training average positive_sample_loss at step 75600: 0.193795\n",
      "2023-12-10 18:16:06,207 INFO     Training average negative_sample_loss at step 75600: 0.168943\n",
      "2023-12-10 18:16:06,207 INFO     Training average loss at step 75600: 0.181369\n",
      "2023-12-10 18:16:50,647 INFO     Training average positive_sample_loss at step 75700: 0.193345\n",
      "2023-12-10 18:16:50,648 INFO     Training average negative_sample_loss at step 75700: 0.170717\n",
      "2023-12-10 18:16:50,648 INFO     Training average loss at step 75700: 0.182031\n",
      "2023-12-10 18:17:34,596 INFO     Training average positive_sample_loss at step 75800: 0.194248\n",
      "2023-12-10 18:17:34,596 INFO     Training average negative_sample_loss at step 75800: 0.172118\n",
      "2023-12-10 18:17:34,596 INFO     Training average loss at step 75800: 0.183183\n",
      "2023-12-10 18:18:18,279 INFO     Training average positive_sample_loss at step 75900: 0.194397\n",
      "2023-12-10 18:18:18,279 INFO     Training average negative_sample_loss at step 75900: 0.169331\n",
      "2023-12-10 18:18:18,279 INFO     Training average loss at step 75900: 0.181864\n",
      "2023-12-10 18:19:04,397 INFO     Training average positive_sample_loss at step 76000: 0.195072\n",
      "2023-12-10 18:19:04,397 INFO     Training average negative_sample_loss at step 76000: 0.169461\n",
      "2023-12-10 18:19:04,397 INFO     Training average loss at step 76000: 0.182266\n",
      "2023-12-10 18:19:55,579 INFO     Training average positive_sample_loss at step 76100: 0.194456\n",
      "2023-12-10 18:19:55,579 INFO     Training average negative_sample_loss at step 76100: 0.170854\n",
      "2023-12-10 18:19:55,579 INFO     Training average loss at step 76100: 0.182655\n",
      "2023-12-10 18:20:39,211 INFO     Training average positive_sample_loss at step 76200: 0.192418\n",
      "2023-12-10 18:20:39,211 INFO     Training average negative_sample_loss at step 76200: 0.170068\n",
      "2023-12-10 18:20:39,211 INFO     Training average loss at step 76200: 0.181243\n",
      "2023-12-10 18:21:21,739 INFO     Training average positive_sample_loss at step 76300: 0.193434\n",
      "2023-12-10 18:21:21,739 INFO     Training average negative_sample_loss at step 76300: 0.170329\n",
      "2023-12-10 18:21:21,739 INFO     Training average loss at step 76300: 0.181882\n",
      "2023-12-10 18:22:04,667 INFO     Training average positive_sample_loss at step 76400: 0.195469\n",
      "2023-12-10 18:22:04,667 INFO     Training average negative_sample_loss at step 76400: 0.171237\n",
      "2023-12-10 18:22:04,667 INFO     Training average loss at step 76400: 0.183353\n",
      "2023-12-10 18:22:47,367 INFO     Training average positive_sample_loss at step 76500: 0.194805\n",
      "2023-12-10 18:22:47,368 INFO     Training average negative_sample_loss at step 76500: 0.170382\n",
      "2023-12-10 18:22:47,368 INFO     Training average loss at step 76500: 0.182594\n",
      "2023-12-10 18:23:31,412 INFO     Training average positive_sample_loss at step 76600: 0.195187\n",
      "2023-12-10 18:23:31,412 INFO     Training average negative_sample_loss at step 76600: 0.170162\n",
      "2023-12-10 18:23:31,412 INFO     Training average loss at step 76600: 0.182675\n",
      "2023-12-10 18:24:24,404 INFO     Training average positive_sample_loss at step 76700: 0.192550\n",
      "2023-12-10 18:24:24,405 INFO     Training average negative_sample_loss at step 76700: 0.170325\n",
      "2023-12-10 18:24:24,405 INFO     Training average loss at step 76700: 0.181437\n",
      "2023-12-10 18:25:06,788 INFO     Training average positive_sample_loss at step 76800: 0.193508\n",
      "2023-12-10 18:25:06,789 INFO     Training average negative_sample_loss at step 76800: 0.169591\n",
      "2023-12-10 18:25:06,789 INFO     Training average loss at step 76800: 0.181549\n",
      "2023-12-10 18:25:49,959 INFO     Training average positive_sample_loss at step 76900: 0.193532\n",
      "2023-12-10 18:25:49,959 INFO     Training average negative_sample_loss at step 76900: 0.168892\n",
      "2023-12-10 18:25:49,960 INFO     Training average loss at step 76900: 0.181212\n",
      "2023-12-10 18:26:32,762 INFO     Training average positive_sample_loss at step 77000: 0.195332\n",
      "2023-12-10 18:26:32,762 INFO     Training average negative_sample_loss at step 77000: 0.170213\n",
      "2023-12-10 18:26:32,762 INFO     Training average loss at step 77000: 0.182772\n",
      "2023-12-10 18:27:15,752 INFO     Training average positive_sample_loss at step 77100: 0.195551\n",
      "2023-12-10 18:27:15,753 INFO     Training average negative_sample_loss at step 77100: 0.171032\n",
      "2023-12-10 18:27:15,753 INFO     Training average loss at step 77100: 0.183292\n",
      "2023-12-10 18:28:04,289 INFO     Training average positive_sample_loss at step 77200: 0.193453\n",
      "2023-12-10 18:28:04,289 INFO     Training average negative_sample_loss at step 77200: 0.171026\n",
      "2023-12-10 18:28:04,289 INFO     Training average loss at step 77200: 0.182240\n",
      "2023-12-10 18:28:46,793 INFO     Training average positive_sample_loss at step 77300: 0.193603\n",
      "2023-12-10 18:28:46,794 INFO     Training average negative_sample_loss at step 77300: 0.170508\n",
      "2023-12-10 18:28:46,794 INFO     Training average loss at step 77300: 0.182055\n",
      "2023-12-10 18:29:29,882 INFO     Training average positive_sample_loss at step 77400: 0.194339\n",
      "2023-12-10 18:29:29,882 INFO     Training average negative_sample_loss at step 77400: 0.171427\n",
      "2023-12-10 18:29:29,882 INFO     Training average loss at step 77400: 0.182883\n",
      "2023-12-10 18:30:14,698 INFO     Training average positive_sample_loss at step 77500: 0.194971\n",
      "2023-12-10 18:30:14,698 INFO     Training average negative_sample_loss at step 77500: 0.170128\n",
      "2023-12-10 18:30:14,698 INFO     Training average loss at step 77500: 0.182550\n",
      "2023-12-10 18:30:58,968 INFO     Training average positive_sample_loss at step 77600: 0.194718\n",
      "2023-12-10 18:30:58,968 INFO     Training average negative_sample_loss at step 77600: 0.170147\n",
      "2023-12-10 18:30:58,968 INFO     Training average loss at step 77600: 0.182433\n",
      "2023-12-10 18:31:48,587 INFO     Training average positive_sample_loss at step 77700: 0.194577\n",
      "2023-12-10 18:31:48,587 INFO     Training average negative_sample_loss at step 77700: 0.169828\n",
      "2023-12-10 18:31:48,587 INFO     Training average loss at step 77700: 0.182202\n",
      "2023-12-10 18:32:31,878 INFO     Training average positive_sample_loss at step 77800: 0.192613\n",
      "2023-12-10 18:32:31,878 INFO     Training average negative_sample_loss at step 77800: 0.169936\n",
      "2023-12-10 18:32:31,878 INFO     Training average loss at step 77800: 0.181274\n",
      "2023-12-10 18:33:16,214 INFO     Training average positive_sample_loss at step 77900: 0.194255\n",
      "2023-12-10 18:33:16,214 INFO     Training average negative_sample_loss at step 77900: 0.170070\n",
      "2023-12-10 18:33:16,214 INFO     Training average loss at step 77900: 0.182162\n",
      "2023-12-10 18:33:59,578 INFO     Training average positive_sample_loss at step 78000: 0.194756\n",
      "2023-12-10 18:33:59,578 INFO     Training average negative_sample_loss at step 78000: 0.169707\n",
      "2023-12-10 18:33:59,578 INFO     Training average loss at step 78000: 0.182231\n",
      "2023-12-10 18:34:42,492 INFO     Training average positive_sample_loss at step 78100: 0.194543\n",
      "2023-12-10 18:34:42,492 INFO     Training average negative_sample_loss at step 78100: 0.170774\n",
      "2023-12-10 18:34:42,492 INFO     Training average loss at step 78100: 0.182658\n",
      "2023-12-10 18:35:27,230 INFO     Training average positive_sample_loss at step 78200: 0.195383\n",
      "2023-12-10 18:35:27,230 INFO     Training average negative_sample_loss at step 78200: 0.169209\n",
      "2023-12-10 18:35:27,230 INFO     Training average loss at step 78200: 0.182296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 18:36:18,534 INFO     Training average positive_sample_loss at step 78300: 0.192560\n",
      "2023-12-10 18:36:18,535 INFO     Training average negative_sample_loss at step 78300: 0.170198\n",
      "2023-12-10 18:36:18,535 INFO     Training average loss at step 78300: 0.181379\n",
      "2023-12-10 18:37:01,999 INFO     Training average positive_sample_loss at step 78400: 0.194123\n",
      "2023-12-10 18:37:02,000 INFO     Training average negative_sample_loss at step 78400: 0.170549\n",
      "2023-12-10 18:37:02,000 INFO     Training average loss at step 78400: 0.182336\n",
      "2023-12-10 18:37:45,525 INFO     Training average positive_sample_loss at step 78500: 0.194200\n",
      "2023-12-10 18:37:45,526 INFO     Training average negative_sample_loss at step 78500: 0.169951\n",
      "2023-12-10 18:37:45,526 INFO     Training average loss at step 78500: 0.182075\n",
      "2023-12-10 18:38:29,646 INFO     Training average positive_sample_loss at step 78600: 0.194432\n",
      "2023-12-10 18:38:29,646 INFO     Training average negative_sample_loss at step 78600: 0.170057\n",
      "2023-12-10 18:38:29,647 INFO     Training average loss at step 78600: 0.182245\n",
      "2023-12-10 18:39:14,149 INFO     Training average positive_sample_loss at step 78700: 0.194848\n",
      "2023-12-10 18:39:14,150 INFO     Training average negative_sample_loss at step 78700: 0.171119\n",
      "2023-12-10 18:39:14,150 INFO     Training average loss at step 78700: 0.182984\n",
      "2023-12-10 18:40:04,164 INFO     Training average positive_sample_loss at step 78800: 0.193434\n",
      "2023-12-10 18:40:04,164 INFO     Training average negative_sample_loss at step 78800: 0.171557\n",
      "2023-12-10 18:40:04,164 INFO     Training average loss at step 78800: 0.182495\n",
      "2023-12-10 18:40:47,692 INFO     Training average positive_sample_loss at step 78900: 0.193427\n",
      "2023-12-10 18:40:47,693 INFO     Training average negative_sample_loss at step 78900: 0.171007\n",
      "2023-12-10 18:40:47,693 INFO     Training average loss at step 78900: 0.182217\n",
      "2023-12-10 18:41:31,387 INFO     Training average positive_sample_loss at step 79000: 0.194758\n",
      "2023-12-10 18:41:31,387 INFO     Training average negative_sample_loss at step 79000: 0.170527\n",
      "2023-12-10 18:41:31,387 INFO     Training average loss at step 79000: 0.182642\n",
      "2023-12-10 18:42:15,447 INFO     Training average positive_sample_loss at step 79100: 0.194658\n",
      "2023-12-10 18:42:15,447 INFO     Training average negative_sample_loss at step 79100: 0.169656\n",
      "2023-12-10 18:42:15,447 INFO     Training average loss at step 79100: 0.182157\n",
      "2023-12-10 18:42:59,395 INFO     Training average positive_sample_loss at step 79200: 0.195344\n",
      "2023-12-10 18:42:59,396 INFO     Training average negative_sample_loss at step 79200: 0.169927\n",
      "2023-12-10 18:42:59,396 INFO     Training average loss at step 79200: 0.182636\n",
      "2023-12-10 18:43:52,264 INFO     Training average positive_sample_loss at step 79300: 0.194220\n",
      "2023-12-10 18:43:52,265 INFO     Training average negative_sample_loss at step 79300: 0.168982\n",
      "2023-12-10 18:43:52,265 INFO     Training average loss at step 79300: 0.181601\n",
      "2023-12-10 18:44:36,294 INFO     Training average positive_sample_loss at step 79400: 0.193227\n",
      "2023-12-10 18:44:36,295 INFO     Training average negative_sample_loss at step 79400: 0.169827\n",
      "2023-12-10 18:44:36,295 INFO     Training average loss at step 79400: 0.181527\n",
      "2023-12-10 18:45:19,892 INFO     Training average positive_sample_loss at step 79500: 0.193922\n",
      "2023-12-10 18:45:19,893 INFO     Training average negative_sample_loss at step 79500: 0.170064\n",
      "2023-12-10 18:45:19,893 INFO     Training average loss at step 79500: 0.181993\n",
      "2023-12-10 18:46:04,001 INFO     Training average positive_sample_loss at step 79600: 0.193992\n",
      "2023-12-10 18:46:04,002 INFO     Training average negative_sample_loss at step 79600: 0.170236\n",
      "2023-12-10 18:46:04,002 INFO     Training average loss at step 79600: 0.182114\n",
      "2023-12-10 18:46:47,717 INFO     Training average positive_sample_loss at step 79700: 0.194931\n",
      "2023-12-10 18:46:47,717 INFO     Training average negative_sample_loss at step 79700: 0.170944\n",
      "2023-12-10 18:46:47,718 INFO     Training average loss at step 79700: 0.182938\n",
      "2023-12-10 18:47:33,930 INFO     Training average positive_sample_loss at step 79800: 0.195522\n",
      "2023-12-10 18:47:33,930 INFO     Training average negative_sample_loss at step 79800: 0.169885\n",
      "2023-12-10 18:47:33,930 INFO     Training average loss at step 79800: 0.182704\n",
      "2023-12-10 18:48:18,532 INFO     Training average positive_sample_loss at step 79900: 0.192885\n",
      "2023-12-10 18:48:18,532 INFO     Training average negative_sample_loss at step 79900: 0.170023\n",
      "2023-12-10 18:48:18,532 INFO     Training average loss at step 79900: 0.181454\n",
      "2023-12-10 18:49:18,908 INFO     Training average positive_sample_loss at step 80000: 0.193127\n",
      "2023-12-10 18:49:18,908 INFO     Training average negative_sample_loss at step 80000: 0.169161\n",
      "2023-12-10 18:49:18,908 INFO     Training average loss at step 80000: 0.181144\n",
      "2023-12-10 18:49:18,908 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 18:49:19,569 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 18:50:11,737 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 18:50:57,887 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 18:51:03,415 INFO     Valid MRR at step 80000: 0.325011\n",
      "2023-12-10 18:51:03,415 INFO     Valid MR at step 80000: 153.824750\n",
      "2023-12-10 18:51:03,416 INFO     Valid HITS@1 at step 80000: 0.230197\n",
      "2023-12-10 18:51:03,416 INFO     Valid HITS@3 at step 80000: 0.357770\n",
      "2023-12-10 18:51:03,416 INFO     Valid HITS@10 at step 80000: 0.519618\n",
      "2023-12-10 18:51:39,457 INFO     Training average positive_sample_loss at step 80100: 0.194093\n",
      "2023-12-10 18:51:39,457 INFO     Training average negative_sample_loss at step 80100: 0.170495\n",
      "2023-12-10 18:51:39,457 INFO     Training average loss at step 80100: 0.182294\n",
      "2023-12-10 18:52:22,406 INFO     Training average positive_sample_loss at step 80200: 0.194769\n",
      "2023-12-10 18:52:22,406 INFO     Training average negative_sample_loss at step 80200: 0.170703\n",
      "2023-12-10 18:52:22,406 INFO     Training average loss at step 80200: 0.182736\n",
      "2023-12-10 18:53:07,397 INFO     Training average positive_sample_loss at step 80300: 0.194878\n",
      "2023-12-10 18:53:07,397 INFO     Training average negative_sample_loss at step 80300: 0.170274\n",
      "2023-12-10 18:53:07,397 INFO     Training average loss at step 80300: 0.182576\n",
      "2023-12-10 18:53:57,299 INFO     Training average positive_sample_loss at step 80400: 0.194666\n",
      "2023-12-10 18:53:57,299 INFO     Training average negative_sample_loss at step 80400: 0.170320\n",
      "2023-12-10 18:53:57,299 INFO     Training average loss at step 80400: 0.182493\n",
      "2023-12-10 18:54:41,321 INFO     Training average positive_sample_loss at step 80500: 0.192840\n",
      "2023-12-10 18:54:41,322 INFO     Training average negative_sample_loss at step 80500: 0.170601\n",
      "2023-12-10 18:54:41,322 INFO     Training average loss at step 80500: 0.181721\n",
      "2023-12-10 18:55:24,166 INFO     Training average positive_sample_loss at step 80600: 0.194583\n",
      "2023-12-10 18:55:24,166 INFO     Training average negative_sample_loss at step 80600: 0.171535\n",
      "2023-12-10 18:55:24,166 INFO     Training average loss at step 80600: 0.183059\n",
      "2023-12-10 18:56:07,840 INFO     Training average positive_sample_loss at step 80700: 0.194458\n",
      "2023-12-10 18:56:07,841 INFO     Training average negative_sample_loss at step 80700: 0.168854\n",
      "2023-12-10 18:56:07,841 INFO     Training average loss at step 80700: 0.181656\n",
      "2023-12-10 18:56:50,170 INFO     Training average positive_sample_loss at step 80800: 0.195001\n",
      "2023-12-10 18:56:50,171 INFO     Training average negative_sample_loss at step 80800: 0.169688\n",
      "2023-12-10 18:56:50,171 INFO     Training average loss at step 80800: 0.182344\n",
      "2023-12-10 18:57:43,051 INFO     Training average positive_sample_loss at step 80900: 0.193938\n",
      "2023-12-10 18:57:43,052 INFO     Training average negative_sample_loss at step 80900: 0.170581\n",
      "2023-12-10 18:57:43,052 INFO     Training average loss at step 80900: 0.182260\n",
      "2023-12-10 18:58:26,719 INFO     Training average positive_sample_loss at step 81000: 0.192467\n",
      "2023-12-10 18:58:26,720 INFO     Training average negative_sample_loss at step 81000: 0.168996\n",
      "2023-12-10 18:58:26,720 INFO     Training average loss at step 81000: 0.180731\n",
      "2023-12-10 18:59:10,706 INFO     Training average positive_sample_loss at step 81100: 0.194104\n",
      "2023-12-10 18:59:10,707 INFO     Training average negative_sample_loss at step 81100: 0.170790\n",
      "2023-12-10 18:59:10,707 INFO     Training average loss at step 81100: 0.182447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 18:59:54,943 INFO     Training average positive_sample_loss at step 81200: 0.194709\n",
      "2023-12-10 18:59:54,943 INFO     Training average negative_sample_loss at step 81200: 0.170450\n",
      "2023-12-10 18:59:54,943 INFO     Training average loss at step 81200: 0.182580\n",
      "2023-12-10 19:00:39,000 INFO     Training average positive_sample_loss at step 81300: 0.194600\n",
      "2023-12-10 19:00:39,000 INFO     Training average negative_sample_loss at step 81300: 0.169875\n",
      "2023-12-10 19:00:39,000 INFO     Training average loss at step 81300: 0.182237\n",
      "2023-12-10 19:01:28,978 INFO     Training average positive_sample_loss at step 81400: 0.195668\n",
      "2023-12-10 19:01:28,978 INFO     Training average negative_sample_loss at step 81400: 0.170998\n",
      "2023-12-10 19:01:28,978 INFO     Training average loss at step 81400: 0.183333\n",
      "2023-12-10 19:02:12,910 INFO     Training average positive_sample_loss at step 81500: 0.192120\n",
      "2023-12-10 19:02:12,910 INFO     Training average negative_sample_loss at step 81500: 0.169323\n",
      "2023-12-10 19:02:12,910 INFO     Training average loss at step 81500: 0.180722\n",
      "2023-12-10 19:02:57,241 INFO     Training average positive_sample_loss at step 81600: 0.193688\n",
      "2023-12-10 19:02:57,242 INFO     Training average negative_sample_loss at step 81600: 0.169959\n",
      "2023-12-10 19:02:57,242 INFO     Training average loss at step 81600: 0.181824\n",
      "2023-12-10 19:03:40,514 INFO     Training average positive_sample_loss at step 81700: 0.193987\n",
      "2023-12-10 19:03:40,514 INFO     Training average negative_sample_loss at step 81700: 0.169639\n",
      "2023-12-10 19:03:40,514 INFO     Training average loss at step 81700: 0.181813\n",
      "2023-12-10 19:04:22,352 INFO     Training average positive_sample_loss at step 81800: 0.195486\n",
      "2023-12-10 19:04:22,353 INFO     Training average negative_sample_loss at step 81800: 0.170570\n",
      "2023-12-10 19:04:22,353 INFO     Training average loss at step 81800: 0.183028\n",
      "2023-12-10 19:05:05,648 INFO     Training average positive_sample_loss at step 81900: 0.195117\n",
      "2023-12-10 19:05:05,649 INFO     Training average negative_sample_loss at step 81900: 0.170265\n",
      "2023-12-10 19:05:05,649 INFO     Training average loss at step 81900: 0.182691\n",
      "2023-12-10 19:05:56,208 INFO     Training average positive_sample_loss at step 82000: 0.193914\n",
      "2023-12-10 19:05:56,209 INFO     Training average negative_sample_loss at step 82000: 0.171075\n",
      "2023-12-10 19:05:56,209 INFO     Training average loss at step 82000: 0.182495\n",
      "2023-12-10 19:06:38,772 INFO     Training average positive_sample_loss at step 82100: 0.192824\n",
      "2023-12-10 19:06:38,773 INFO     Training average negative_sample_loss at step 82100: 0.170583\n",
      "2023-12-10 19:06:38,773 INFO     Training average loss at step 82100: 0.181703\n",
      "2023-12-10 19:07:20,963 INFO     Training average positive_sample_loss at step 82200: 0.194016\n",
      "2023-12-10 19:07:20,964 INFO     Training average negative_sample_loss at step 82200: 0.169420\n",
      "2023-12-10 19:07:20,964 INFO     Training average loss at step 82200: 0.181718\n",
      "2023-12-10 19:08:04,863 INFO     Training average positive_sample_loss at step 82300: 0.195852\n",
      "2023-12-10 19:08:04,863 INFO     Training average negative_sample_loss at step 82300: 0.171289\n",
      "2023-12-10 19:08:04,863 INFO     Training average loss at step 82300: 0.183571\n",
      "2023-12-10 19:08:49,069 INFO     Training average positive_sample_loss at step 82400: 0.194918\n",
      "2023-12-10 19:08:49,070 INFO     Training average negative_sample_loss at step 82400: 0.169756\n",
      "2023-12-10 19:08:49,070 INFO     Training average loss at step 82400: 0.182337\n",
      "2023-12-10 19:09:37,262 INFO     Training average positive_sample_loss at step 82500: 0.194025\n",
      "2023-12-10 19:09:37,263 INFO     Training average negative_sample_loss at step 82500: 0.170667\n",
      "2023-12-10 19:09:37,263 INFO     Training average loss at step 82500: 0.182346\n",
      "2023-12-10 19:10:21,713 INFO     Training average positive_sample_loss at step 82600: 0.192441\n",
      "2023-12-10 19:10:21,713 INFO     Training average negative_sample_loss at step 82600: 0.168147\n",
      "2023-12-10 19:10:21,714 INFO     Training average loss at step 82600: 0.180294\n",
      "2023-12-10 19:11:05,644 INFO     Training average positive_sample_loss at step 82700: 0.194353\n",
      "2023-12-10 19:11:05,644 INFO     Training average negative_sample_loss at step 82700: 0.169942\n",
      "2023-12-10 19:11:05,644 INFO     Training average loss at step 82700: 0.182148\n",
      "2023-12-10 19:11:49,121 INFO     Training average positive_sample_loss at step 82800: 0.194248\n",
      "2023-12-10 19:11:49,122 INFO     Training average negative_sample_loss at step 82800: 0.170408\n",
      "2023-12-10 19:11:49,122 INFO     Training average loss at step 82800: 0.182328\n",
      "2023-12-10 19:12:32,006 INFO     Training average positive_sample_loss at step 82900: 0.195108\n",
      "2023-12-10 19:12:32,007 INFO     Training average negative_sample_loss at step 82900: 0.168581\n",
      "2023-12-10 19:12:32,007 INFO     Training average loss at step 82900: 0.181844\n",
      "2023-12-10 19:13:24,563 INFO     Training average positive_sample_loss at step 83000: 0.195238\n",
      "2023-12-10 19:13:24,564 INFO     Training average negative_sample_loss at step 83000: 0.171250\n",
      "2023-12-10 19:13:24,564 INFO     Training average loss at step 83000: 0.183244\n",
      "2023-12-10 19:14:07,656 INFO     Training average positive_sample_loss at step 83100: 0.192990\n",
      "2023-12-10 19:14:07,657 INFO     Training average negative_sample_loss at step 83100: 0.170244\n",
      "2023-12-10 19:14:07,657 INFO     Training average loss at step 83100: 0.181617\n",
      "2023-12-10 19:14:50,872 INFO     Training average positive_sample_loss at step 83200: 0.194031\n",
      "2023-12-10 19:14:50,872 INFO     Training average negative_sample_loss at step 83200: 0.171313\n",
      "2023-12-10 19:14:50,872 INFO     Training average loss at step 83200: 0.182672\n",
      "2023-12-10 19:15:35,051 INFO     Training average positive_sample_loss at step 83300: 0.193502\n",
      "2023-12-10 19:15:35,051 INFO     Training average negative_sample_loss at step 83300: 0.169337\n",
      "2023-12-10 19:15:35,051 INFO     Training average loss at step 83300: 0.181420\n",
      "2023-12-10 19:16:19,735 INFO     Training average positive_sample_loss at step 83400: 0.195676\n",
      "2023-12-10 19:16:19,735 INFO     Training average negative_sample_loss at step 83400: 0.170720\n",
      "2023-12-10 19:16:19,735 INFO     Training average loss at step 83400: 0.183198\n",
      "2023-12-10 19:17:04,348 INFO     Training average positive_sample_loss at step 83500: 0.194684\n",
      "2023-12-10 19:17:04,348 INFO     Training average negative_sample_loss at step 83500: 0.170767\n",
      "2023-12-10 19:17:04,348 INFO     Training average loss at step 83500: 0.182725\n",
      "2023-12-10 19:17:54,175 INFO     Training average positive_sample_loss at step 83600: 0.193700\n",
      "2023-12-10 19:17:54,175 INFO     Training average negative_sample_loss at step 83600: 0.169634\n",
      "2023-12-10 19:17:54,175 INFO     Training average loss at step 83600: 0.181667\n",
      "2023-12-10 19:18:37,795 INFO     Training average positive_sample_loss at step 83700: 0.194348\n",
      "2023-12-10 19:18:37,795 INFO     Training average negative_sample_loss at step 83700: 0.171162\n",
      "2023-12-10 19:18:37,795 INFO     Training average loss at step 83700: 0.182755\n",
      "2023-12-10 19:19:21,298 INFO     Training average positive_sample_loss at step 83800: 0.194234\n",
      "2023-12-10 19:19:21,299 INFO     Training average negative_sample_loss at step 83800: 0.169328\n",
      "2023-12-10 19:19:21,299 INFO     Training average loss at step 83800: 0.181781\n",
      "2023-12-10 19:20:05,067 INFO     Training average positive_sample_loss at step 83900: 0.194682\n",
      "2023-12-10 19:20:05,067 INFO     Training average negative_sample_loss at step 83900: 0.170261\n",
      "2023-12-10 19:20:05,067 INFO     Training average loss at step 83900: 0.182471\n",
      "2023-12-10 19:20:47,320 INFO     Training average positive_sample_loss at step 84000: 0.194140\n",
      "2023-12-10 19:20:47,320 INFO     Training average negative_sample_loss at step 84000: 0.171263\n",
      "2023-12-10 19:20:47,320 INFO     Training average loss at step 84000: 0.182702\n",
      "2023-12-10 19:21:37,476 INFO     Training average positive_sample_loss at step 84100: 0.193989\n",
      "2023-12-10 19:21:37,477 INFO     Training average negative_sample_loss at step 84100: 0.170475\n",
      "2023-12-10 19:21:37,477 INFO     Training average loss at step 84100: 0.182232\n",
      "2023-12-10 19:22:20,821 INFO     Training average positive_sample_loss at step 84200: 0.192712\n",
      "2023-12-10 19:22:20,821 INFO     Training average negative_sample_loss at step 84200: 0.169819\n",
      "2023-12-10 19:22:20,821 INFO     Training average loss at step 84200: 0.181266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 19:23:02,968 INFO     Training average positive_sample_loss at step 84300: 0.193962\n",
      "2023-12-10 19:23:02,969 INFO     Training average negative_sample_loss at step 84300: 0.170191\n",
      "2023-12-10 19:23:02,969 INFO     Training average loss at step 84300: 0.182077\n",
      "2023-12-10 19:23:45,176 INFO     Training average positive_sample_loss at step 84400: 0.195658\n",
      "2023-12-10 19:23:45,177 INFO     Training average negative_sample_loss at step 84400: 0.170861\n",
      "2023-12-10 19:23:45,177 INFO     Training average loss at step 84400: 0.183260\n",
      "2023-12-10 19:24:28,668 INFO     Training average positive_sample_loss at step 84500: 0.195184\n",
      "2023-12-10 19:24:28,668 INFO     Training average negative_sample_loss at step 84500: 0.170378\n",
      "2023-12-10 19:24:28,668 INFO     Training average loss at step 84500: 0.182781\n",
      "2023-12-10 19:25:21,220 INFO     Training average positive_sample_loss at step 84600: 0.194647\n",
      "2023-12-10 19:25:21,221 INFO     Training average negative_sample_loss at step 84600: 0.169895\n",
      "2023-12-10 19:25:21,221 INFO     Training average loss at step 84600: 0.182271\n",
      "2023-12-10 19:26:04,882 INFO     Training average positive_sample_loss at step 84700: 0.192303\n",
      "2023-12-10 19:26:04,883 INFO     Training average negative_sample_loss at step 84700: 0.169591\n",
      "2023-12-10 19:26:04,883 INFO     Training average loss at step 84700: 0.180947\n",
      "2023-12-10 19:26:48,988 INFO     Training average positive_sample_loss at step 84800: 0.194013\n",
      "2023-12-10 19:26:48,988 INFO     Training average negative_sample_loss at step 84800: 0.169802\n",
      "2023-12-10 19:26:48,988 INFO     Training average loss at step 84800: 0.181907\n",
      "2023-12-10 19:27:31,756 INFO     Training average positive_sample_loss at step 84900: 0.194401\n",
      "2023-12-10 19:27:31,757 INFO     Training average negative_sample_loss at step 84900: 0.170458\n",
      "2023-12-10 19:27:31,757 INFO     Training average loss at step 84900: 0.182430\n",
      "2023-12-10 19:28:13,445 INFO     Training average positive_sample_loss at step 85000: 0.195494\n",
      "2023-12-10 19:28:13,445 INFO     Training average negative_sample_loss at step 85000: 0.171374\n",
      "2023-12-10 19:28:13,445 INFO     Training average loss at step 85000: 0.183434\n",
      "2023-12-10 19:28:56,992 INFO     Training average positive_sample_loss at step 85100: 0.195359\n",
      "2023-12-10 19:28:56,992 INFO     Training average negative_sample_loss at step 85100: 0.170828\n",
      "2023-12-10 19:28:56,992 INFO     Training average loss at step 85100: 0.183094\n",
      "2023-12-10 19:29:44,957 INFO     Training average positive_sample_loss at step 85200: 0.192641\n",
      "2023-12-10 19:29:44,958 INFO     Training average negative_sample_loss at step 85200: 0.169912\n",
      "2023-12-10 19:29:44,958 INFO     Training average loss at step 85200: 0.181277\n",
      "2023-12-10 19:30:28,574 INFO     Training average positive_sample_loss at step 85300: 0.193874\n",
      "2023-12-10 19:30:28,574 INFO     Training average negative_sample_loss at step 85300: 0.170493\n",
      "2023-12-10 19:30:28,574 INFO     Training average loss at step 85300: 0.182183\n",
      "2023-12-10 19:31:12,118 INFO     Training average positive_sample_loss at step 85400: 0.194156\n",
      "2023-12-10 19:31:12,118 INFO     Training average negative_sample_loss at step 85400: 0.170709\n",
      "2023-12-10 19:31:12,119 INFO     Training average loss at step 85400: 0.182433\n",
      "2023-12-10 19:31:56,445 INFO     Training average positive_sample_loss at step 85500: 0.194870\n",
      "2023-12-10 19:31:56,445 INFO     Training average negative_sample_loss at step 85500: 0.168875\n",
      "2023-12-10 19:31:56,445 INFO     Training average loss at step 85500: 0.181873\n",
      "2023-12-10 19:32:38,692 INFO     Training average positive_sample_loss at step 85600: 0.195513\n",
      "2023-12-10 19:32:38,693 INFO     Training average negative_sample_loss at step 85600: 0.169830\n",
      "2023-12-10 19:32:38,693 INFO     Training average loss at step 85600: 0.182672\n",
      "2023-12-10 19:33:27,272 INFO     Training average positive_sample_loss at step 85700: 0.194475\n",
      "2023-12-10 19:33:27,272 INFO     Training average negative_sample_loss at step 85700: 0.170926\n",
      "2023-12-10 19:33:27,272 INFO     Training average loss at step 85700: 0.182700\n",
      "2023-12-10 19:34:11,731 INFO     Training average positive_sample_loss at step 85800: 0.192655\n",
      "2023-12-10 19:34:11,732 INFO     Training average negative_sample_loss at step 85800: 0.170019\n",
      "2023-12-10 19:34:11,732 INFO     Training average loss at step 85800: 0.181337\n",
      "2023-12-10 19:34:56,238 INFO     Training average positive_sample_loss at step 85900: 0.193558\n",
      "2023-12-10 19:34:56,239 INFO     Training average negative_sample_loss at step 85900: 0.169524\n",
      "2023-12-10 19:34:56,239 INFO     Training average loss at step 85900: 0.181541\n",
      "2023-12-10 19:35:40,736 INFO     Training average positive_sample_loss at step 86000: 0.194561\n",
      "2023-12-10 19:35:40,736 INFO     Training average negative_sample_loss at step 86000: 0.170752\n",
      "2023-12-10 19:35:40,736 INFO     Training average loss at step 86000: 0.182657\n",
      "2023-12-10 19:36:24,864 INFO     Training average positive_sample_loss at step 86100: 0.195403\n",
      "2023-12-10 19:36:24,864 INFO     Training average negative_sample_loss at step 86100: 0.170285\n",
      "2023-12-10 19:36:24,864 INFO     Training average loss at step 86100: 0.182844\n",
      "2023-12-10 19:37:16,696 INFO     Training average positive_sample_loss at step 86200: 0.195567\n",
      "2023-12-10 19:37:16,696 INFO     Training average negative_sample_loss at step 86200: 0.170937\n",
      "2023-12-10 19:37:16,696 INFO     Training average loss at step 86200: 0.183252\n",
      "2023-12-10 19:37:59,630 INFO     Training average positive_sample_loss at step 86300: 0.191955\n",
      "2023-12-10 19:37:59,631 INFO     Training average negative_sample_loss at step 86300: 0.169309\n",
      "2023-12-10 19:37:59,631 INFO     Training average loss at step 86300: 0.180632\n",
      "2023-12-10 19:38:43,290 INFO     Training average positive_sample_loss at step 86400: 0.194061\n",
      "2023-12-10 19:38:43,290 INFO     Training average negative_sample_loss at step 86400: 0.170449\n",
      "2023-12-10 19:38:43,290 INFO     Training average loss at step 86400: 0.182255\n",
      "2023-12-10 19:39:26,769 INFO     Training average positive_sample_loss at step 86500: 0.194612\n",
      "2023-12-10 19:39:26,770 INFO     Training average negative_sample_loss at step 86500: 0.169423\n",
      "2023-12-10 19:39:26,770 INFO     Training average loss at step 86500: 0.182018\n",
      "2023-12-10 19:40:11,369 INFO     Training average positive_sample_loss at step 86600: 0.195114\n",
      "2023-12-10 19:40:11,369 INFO     Training average negative_sample_loss at step 86600: 0.170031\n",
      "2023-12-10 19:40:11,369 INFO     Training average loss at step 86600: 0.182572\n",
      "2023-12-10 19:40:54,598 INFO     Training average positive_sample_loss at step 86700: 0.195631\n",
      "2023-12-10 19:40:54,598 INFO     Training average negative_sample_loss at step 86700: 0.170709\n",
      "2023-12-10 19:40:54,598 INFO     Training average loss at step 86700: 0.183170\n",
      "2023-12-10 19:41:48,527 INFO     Training average positive_sample_loss at step 86800: 0.192133\n",
      "2023-12-10 19:41:48,527 INFO     Training average negative_sample_loss at step 86800: 0.169731\n",
      "2023-12-10 19:41:48,527 INFO     Training average loss at step 86800: 0.180932\n",
      "2023-12-10 19:42:34,610 INFO     Training average positive_sample_loss at step 86900: 0.192990\n",
      "2023-12-10 19:42:34,610 INFO     Training average negative_sample_loss at step 86900: 0.171012\n",
      "2023-12-10 19:42:34,610 INFO     Training average loss at step 86900: 0.182001\n",
      "2023-12-10 19:43:19,802 INFO     Training average positive_sample_loss at step 87000: 0.194485\n",
      "2023-12-10 19:43:19,803 INFO     Training average negative_sample_loss at step 87000: 0.169919\n",
      "2023-12-10 19:43:19,803 INFO     Training average loss at step 87000: 0.182202\n",
      "2023-12-10 19:44:03,715 INFO     Training average positive_sample_loss at step 87100: 0.194813\n",
      "2023-12-10 19:44:03,715 INFO     Training average negative_sample_loss at step 87100: 0.170292\n",
      "2023-12-10 19:44:03,715 INFO     Training average loss at step 87100: 0.182553\n",
      "2023-12-10 19:44:48,784 INFO     Training average positive_sample_loss at step 87200: 0.195975\n",
      "2023-12-10 19:44:48,785 INFO     Training average negative_sample_loss at step 87200: 0.169891\n",
      "2023-12-10 19:44:48,785 INFO     Training average loss at step 87200: 0.182933\n",
      "2023-12-10 19:45:39,560 INFO     Training average positive_sample_loss at step 87300: 0.194846\n",
      "2023-12-10 19:45:39,561 INFO     Training average negative_sample_loss at step 87300: 0.171375\n",
      "2023-12-10 19:45:39,561 INFO     Training average loss at step 87300: 0.183111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 19:46:23,440 INFO     Training average positive_sample_loss at step 87400: 0.193122\n",
      "2023-12-10 19:46:23,440 INFO     Training average negative_sample_loss at step 87400: 0.170888\n",
      "2023-12-10 19:46:23,441 INFO     Training average loss at step 87400: 0.182005\n",
      "2023-12-10 19:47:06,789 INFO     Training average positive_sample_loss at step 87500: 0.193923\n",
      "2023-12-10 19:47:06,790 INFO     Training average negative_sample_loss at step 87500: 0.170404\n",
      "2023-12-10 19:47:06,790 INFO     Training average loss at step 87500: 0.182163\n",
      "2023-12-10 19:47:49,460 INFO     Training average positive_sample_loss at step 87600: 0.194094\n",
      "2023-12-10 19:47:49,461 INFO     Training average negative_sample_loss at step 87600: 0.169026\n",
      "2023-12-10 19:47:49,461 INFO     Training average loss at step 87600: 0.181560\n",
      "2023-12-10 19:48:31,985 INFO     Training average positive_sample_loss at step 87700: 0.195114\n",
      "2023-12-10 19:48:31,986 INFO     Training average negative_sample_loss at step 87700: 0.169117\n",
      "2023-12-10 19:48:31,986 INFO     Training average loss at step 87700: 0.182115\n",
      "2023-12-10 19:49:18,612 INFO     Training average positive_sample_loss at step 87800: 0.195347\n",
      "2023-12-10 19:49:18,612 INFO     Training average negative_sample_loss at step 87800: 0.169989\n",
      "2023-12-10 19:49:18,612 INFO     Training average loss at step 87800: 0.182668\n",
      "2023-12-10 19:50:02,487 INFO     Training average positive_sample_loss at step 87900: 0.192877\n",
      "2023-12-10 19:50:02,487 INFO     Training average negative_sample_loss at step 87900: 0.169953\n",
      "2023-12-10 19:50:02,487 INFO     Training average loss at step 87900: 0.181415\n",
      "2023-12-10 19:50:46,096 INFO     Training average positive_sample_loss at step 88000: 0.193699\n",
      "2023-12-10 19:50:46,096 INFO     Training average negative_sample_loss at step 88000: 0.170478\n",
      "2023-12-10 19:50:46,096 INFO     Training average loss at step 88000: 0.182088\n",
      "2023-12-10 19:51:29,909 INFO     Training average positive_sample_loss at step 88100: 0.194823\n",
      "2023-12-10 19:51:29,909 INFO     Training average negative_sample_loss at step 88100: 0.170809\n",
      "2023-12-10 19:51:29,909 INFO     Training average loss at step 88100: 0.182816\n",
      "2023-12-10 19:52:12,915 INFO     Training average positive_sample_loss at step 88200: 0.195248\n",
      "2023-12-10 19:52:12,915 INFO     Training average negative_sample_loss at step 88200: 0.169836\n",
      "2023-12-10 19:52:12,915 INFO     Training average loss at step 88200: 0.182542\n",
      "2023-12-10 19:52:57,303 INFO     Training average positive_sample_loss at step 88300: 0.194872\n",
      "2023-12-10 19:52:57,304 INFO     Training average negative_sample_loss at step 88300: 0.170141\n",
      "2023-12-10 19:52:57,304 INFO     Training average loss at step 88300: 0.182507\n",
      "2023-12-10 19:53:46,274 INFO     Training average positive_sample_loss at step 88400: 0.193238\n",
      "2023-12-10 19:53:46,275 INFO     Training average negative_sample_loss at step 88400: 0.170285\n",
      "2023-12-10 19:53:46,275 INFO     Training average loss at step 88400: 0.181762\n",
      "2023-12-10 19:54:30,068 INFO     Training average positive_sample_loss at step 88500: 0.193546\n",
      "2023-12-10 19:54:30,068 INFO     Training average negative_sample_loss at step 88500: 0.170842\n",
      "2023-12-10 19:54:30,068 INFO     Training average loss at step 88500: 0.182194\n",
      "2023-12-10 19:55:14,324 INFO     Training average positive_sample_loss at step 88600: 0.194344\n",
      "2023-12-10 19:55:14,324 INFO     Training average negative_sample_loss at step 88600: 0.169851\n",
      "2023-12-10 19:55:14,324 INFO     Training average loss at step 88600: 0.182098\n",
      "2023-12-10 19:55:58,658 INFO     Training average positive_sample_loss at step 88700: 0.194974\n",
      "2023-12-10 19:55:58,659 INFO     Training average negative_sample_loss at step 88700: 0.169986\n",
      "2023-12-10 19:55:58,659 INFO     Training average loss at step 88700: 0.182480\n",
      "2023-12-10 19:56:41,376 INFO     Training average positive_sample_loss at step 88800: 0.195444\n",
      "2023-12-10 19:56:41,376 INFO     Training average negative_sample_loss at step 88800: 0.169371\n",
      "2023-12-10 19:56:41,376 INFO     Training average loss at step 88800: 0.182407\n",
      "2023-12-10 19:57:30,636 INFO     Training average positive_sample_loss at step 88900: 0.194055\n",
      "2023-12-10 19:57:30,637 INFO     Training average negative_sample_loss at step 88900: 0.170958\n",
      "2023-12-10 19:57:30,637 INFO     Training average loss at step 88900: 0.182507\n",
      "2023-12-10 19:58:14,863 INFO     Training average positive_sample_loss at step 89000: 0.193622\n",
      "2023-12-10 19:58:14,863 INFO     Training average negative_sample_loss at step 89000: 0.170693\n",
      "2023-12-10 19:58:14,863 INFO     Training average loss at step 89000: 0.182158\n",
      "2023-12-10 19:58:58,957 INFO     Training average positive_sample_loss at step 89100: 0.194075\n",
      "2023-12-10 19:58:58,957 INFO     Training average negative_sample_loss at step 89100: 0.169254\n",
      "2023-12-10 19:58:58,957 INFO     Training average loss at step 89100: 0.181664\n",
      "2023-12-10 19:59:42,190 INFO     Training average positive_sample_loss at step 89200: 0.194076\n",
      "2023-12-10 19:59:42,190 INFO     Training average negative_sample_loss at step 89200: 0.169615\n",
      "2023-12-10 19:59:42,190 INFO     Training average loss at step 89200: 0.181846\n",
      "2023-12-10 20:00:27,081 INFO     Training average positive_sample_loss at step 89300: 0.195319\n",
      "2023-12-10 20:00:27,081 INFO     Training average negative_sample_loss at step 89300: 0.170728\n",
      "2023-12-10 20:00:27,081 INFO     Training average loss at step 89300: 0.183024\n",
      "2023-12-10 20:01:15,374 INFO     Training average positive_sample_loss at step 89400: 0.194372\n",
      "2023-12-10 20:01:15,374 INFO     Training average negative_sample_loss at step 89400: 0.171198\n",
      "2023-12-10 20:01:15,374 INFO     Training average loss at step 89400: 0.182785\n",
      "2023-12-10 20:01:57,531 INFO     Training average positive_sample_loss at step 89500: 0.192541\n",
      "2023-12-10 20:01:57,531 INFO     Training average negative_sample_loss at step 89500: 0.170505\n",
      "2023-12-10 20:01:57,531 INFO     Training average loss at step 89500: 0.181523\n",
      "2023-12-10 20:02:41,346 INFO     Training average positive_sample_loss at step 89600: 0.194702\n",
      "2023-12-10 20:02:41,347 INFO     Training average negative_sample_loss at step 89600: 0.169809\n",
      "2023-12-10 20:02:41,347 INFO     Training average loss at step 89600: 0.182256\n",
      "2023-12-10 20:03:25,737 INFO     Training average positive_sample_loss at step 89700: 0.194982\n",
      "2023-12-10 20:03:25,737 INFO     Training average negative_sample_loss at step 89700: 0.170969\n",
      "2023-12-10 20:03:25,737 INFO     Training average loss at step 89700: 0.182976\n",
      "2023-12-10 20:04:10,505 INFO     Training average positive_sample_loss at step 89800: 0.195517\n",
      "2023-12-10 20:04:10,506 INFO     Training average negative_sample_loss at step 89800: 0.168986\n",
      "2023-12-10 20:04:10,506 INFO     Training average loss at step 89800: 0.182252\n",
      "2023-12-10 20:04:53,841 INFO     Training average positive_sample_loss at step 89900: 0.194710\n",
      "2023-12-10 20:04:53,842 INFO     Training average negative_sample_loss at step 89900: 0.169806\n",
      "2023-12-10 20:04:53,842 INFO     Training average loss at step 89900: 0.182258\n",
      "2023-12-10 20:05:54,755 INFO     Training average positive_sample_loss at step 90000: 0.192954\n",
      "2023-12-10 20:05:54,756 INFO     Training average negative_sample_loss at step 90000: 0.170132\n",
      "2023-12-10 20:05:54,756 INFO     Training average loss at step 90000: 0.181543\n",
      "2023-12-10 20:05:54,756 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 20:05:55,445 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 20:06:26,517 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 20:06:56,509 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 20:07:02,370 INFO     Valid MRR at step 90000: 0.325163\n",
      "2023-12-10 20:07:02,370 INFO     Valid MR at step 90000: 153.824551\n",
      "2023-12-10 20:07:02,370 INFO     Valid HITS@1 at step 90000: 0.230681\n",
      "2023-12-10 20:07:02,370 INFO     Valid HITS@3 at step 90000: 0.357941\n",
      "2023-12-10 20:07:02,370 INFO     Valid HITS@10 at step 90000: 0.520046\n",
      "2023-12-10 20:07:38,206 INFO     Training average positive_sample_loss at step 90100: 0.194347\n",
      "2023-12-10 20:07:38,207 INFO     Training average negative_sample_loss at step 90100: 0.169705\n",
      "2023-12-10 20:07:38,207 INFO     Training average loss at step 90100: 0.182026\n",
      "2023-12-10 20:08:23,072 INFO     Training average positive_sample_loss at step 90200: 0.194409\n",
      "2023-12-10 20:08:23,072 INFO     Training average negative_sample_loss at step 90200: 0.170443\n",
      "2023-12-10 20:08:23,072 INFO     Training average loss at step 90200: 0.182426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 20:09:07,715 INFO     Training average positive_sample_loss at step 90300: 0.194459\n",
      "2023-12-10 20:09:07,715 INFO     Training average negative_sample_loss at step 90300: 0.169908\n",
      "2023-12-10 20:09:07,715 INFO     Training average loss at step 90300: 0.182183\n",
      "2023-12-10 20:09:52,246 INFO     Training average positive_sample_loss at step 90400: 0.194981\n",
      "2023-12-10 20:09:52,246 INFO     Training average negative_sample_loss at step 90400: 0.169468\n",
      "2023-12-10 20:09:52,246 INFO     Training average loss at step 90400: 0.182225\n",
      "2023-12-10 20:10:40,857 INFO     Training average positive_sample_loss at step 90500: 0.193543\n",
      "2023-12-10 20:10:40,858 INFO     Training average negative_sample_loss at step 90500: 0.169535\n",
      "2023-12-10 20:10:40,858 INFO     Training average loss at step 90500: 0.181539\n",
      "2023-12-10 20:11:24,957 INFO     Training average positive_sample_loss at step 90600: 0.193150\n",
      "2023-12-10 20:11:24,957 INFO     Training average negative_sample_loss at step 90600: 0.171024\n",
      "2023-12-10 20:11:24,957 INFO     Training average loss at step 90600: 0.182087\n",
      "2023-12-10 20:12:08,268 INFO     Training average positive_sample_loss at step 90700: 0.193667\n",
      "2023-12-10 20:12:08,268 INFO     Training average negative_sample_loss at step 90700: 0.169763\n",
      "2023-12-10 20:12:08,269 INFO     Training average loss at step 90700: 0.181715\n",
      "2023-12-10 20:12:52,596 INFO     Training average positive_sample_loss at step 90800: 0.194774\n",
      "2023-12-10 20:12:52,596 INFO     Training average negative_sample_loss at step 90800: 0.171014\n",
      "2023-12-10 20:12:52,596 INFO     Training average loss at step 90800: 0.182894\n",
      "2023-12-10 20:13:36,886 INFO     Training average positive_sample_loss at step 90900: 0.195693\n",
      "2023-12-10 20:13:36,886 INFO     Training average negative_sample_loss at step 90900: 0.169990\n",
      "2023-12-10 20:13:36,886 INFO     Training average loss at step 90900: 0.182841\n",
      "2023-12-10 20:14:24,697 INFO     Training average positive_sample_loss at step 91000: 0.194440\n",
      "2023-12-10 20:14:24,697 INFO     Training average negative_sample_loss at step 91000: 0.169365\n",
      "2023-12-10 20:14:24,697 INFO     Training average loss at step 91000: 0.181902\n",
      "2023-12-10 20:15:06,969 INFO     Training average positive_sample_loss at step 91100: 0.192673\n",
      "2023-12-10 20:15:06,969 INFO     Training average negative_sample_loss at step 91100: 0.169798\n",
      "2023-12-10 20:15:06,969 INFO     Training average loss at step 91100: 0.181236\n",
      "2023-12-10 20:15:50,120 INFO     Training average positive_sample_loss at step 91200: 0.193781\n",
      "2023-12-10 20:15:50,120 INFO     Training average negative_sample_loss at step 91200: 0.170480\n",
      "2023-12-10 20:15:50,120 INFO     Training average loss at step 91200: 0.182131\n",
      "2023-12-10 20:16:35,032 INFO     Training average positive_sample_loss at step 91300: 0.194562\n",
      "2023-12-10 20:16:35,032 INFO     Training average negative_sample_loss at step 91300: 0.169394\n",
      "2023-12-10 20:16:35,032 INFO     Training average loss at step 91300: 0.181978\n",
      "2023-12-10 20:17:17,808 INFO     Training average positive_sample_loss at step 91400: 0.195144\n",
      "2023-12-10 20:17:17,808 INFO     Training average negative_sample_loss at step 91400: 0.170858\n",
      "2023-12-10 20:17:17,808 INFO     Training average loss at step 91400: 0.183001\n",
      "2023-12-10 20:18:01,031 INFO     Training average positive_sample_loss at step 91500: 0.196094\n",
      "2023-12-10 20:18:01,031 INFO     Training average negative_sample_loss at step 91500: 0.171588\n",
      "2023-12-10 20:18:01,031 INFO     Training average loss at step 91500: 0.183841\n",
      "2023-12-10 20:18:52,093 INFO     Training average positive_sample_loss at step 91600: 0.192524\n",
      "2023-12-10 20:18:52,093 INFO     Training average negative_sample_loss at step 91600: 0.169004\n",
      "2023-12-10 20:18:52,093 INFO     Training average loss at step 91600: 0.180764\n",
      "2023-12-10 20:19:35,552 INFO     Training average positive_sample_loss at step 91700: 0.194046\n",
      "2023-12-10 20:19:35,553 INFO     Training average negative_sample_loss at step 91700: 0.169860\n",
      "2023-12-10 20:19:35,553 INFO     Training average loss at step 91700: 0.181953\n",
      "2023-12-10 20:20:19,687 INFO     Training average positive_sample_loss at step 91800: 0.193389\n",
      "2023-12-10 20:20:19,687 INFO     Training average negative_sample_loss at step 91800: 0.170804\n",
      "2023-12-10 20:20:19,687 INFO     Training average loss at step 91800: 0.182097\n",
      "2023-12-10 20:21:04,840 INFO     Training average positive_sample_loss at step 91900: 0.195258\n",
      "2023-12-10 20:21:04,840 INFO     Training average negative_sample_loss at step 91900: 0.170987\n",
      "2023-12-10 20:21:04,841 INFO     Training average loss at step 91900: 0.183122\n",
      "2023-12-10 20:21:47,574 INFO     Training average positive_sample_loss at step 92000: 0.195551\n",
      "2023-12-10 20:21:47,574 INFO     Training average negative_sample_loss at step 92000: 0.169473\n",
      "2023-12-10 20:21:47,574 INFO     Training average loss at step 92000: 0.182512\n",
      "2023-12-10 20:22:38,916 INFO     Training average positive_sample_loss at step 92100: 0.194456\n",
      "2023-12-10 20:22:38,917 INFO     Training average negative_sample_loss at step 92100: 0.170568\n",
      "2023-12-10 20:22:38,917 INFO     Training average loss at step 92100: 0.182512\n",
      "2023-12-10 20:23:21,913 INFO     Training average positive_sample_loss at step 92200: 0.193850\n",
      "2023-12-10 20:23:21,913 INFO     Training average negative_sample_loss at step 92200: 0.169919\n",
      "2023-12-10 20:23:21,913 INFO     Training average loss at step 92200: 0.181884\n",
      "2023-12-10 20:24:04,874 INFO     Training average positive_sample_loss at step 92300: 0.193717\n",
      "2023-12-10 20:24:04,874 INFO     Training average negative_sample_loss at step 92300: 0.170095\n",
      "2023-12-10 20:24:04,874 INFO     Training average loss at step 92300: 0.181906\n",
      "2023-12-10 20:24:46,973 INFO     Training average positive_sample_loss at step 92400: 0.195173\n",
      "2023-12-10 20:24:46,973 INFO     Training average negative_sample_loss at step 92400: 0.170016\n",
      "2023-12-10 20:24:46,973 INFO     Training average loss at step 92400: 0.182595\n",
      "2023-12-10 20:25:29,487 INFO     Training average positive_sample_loss at step 92500: 0.194721\n",
      "2023-12-10 20:25:29,487 INFO     Training average negative_sample_loss at step 92500: 0.169487\n",
      "2023-12-10 20:25:29,487 INFO     Training average loss at step 92500: 0.182104\n",
      "2023-12-10 20:26:23,811 INFO     Training average positive_sample_loss at step 92600: 0.193898\n",
      "2023-12-10 20:26:23,812 INFO     Training average negative_sample_loss at step 92600: 0.169516\n",
      "2023-12-10 20:26:23,812 INFO     Training average loss at step 92600: 0.181707\n",
      "2023-12-10 20:27:07,218 INFO     Training average positive_sample_loss at step 92700: 0.193162\n",
      "2023-12-10 20:27:07,218 INFO     Training average negative_sample_loss at step 92700: 0.170544\n",
      "2023-12-10 20:27:07,218 INFO     Training average loss at step 92700: 0.181853\n",
      "2023-12-10 20:27:50,419 INFO     Training average positive_sample_loss at step 92800: 0.193583\n",
      "2023-12-10 20:27:50,420 INFO     Training average negative_sample_loss at step 92800: 0.171106\n",
      "2023-12-10 20:27:50,420 INFO     Training average loss at step 92800: 0.182345\n",
      "2023-12-10 20:28:35,597 INFO     Training average positive_sample_loss at step 92900: 0.194947\n",
      "2023-12-10 20:28:35,597 INFO     Training average negative_sample_loss at step 92900: 0.168825\n",
      "2023-12-10 20:28:35,597 INFO     Training average loss at step 92900: 0.181886\n",
      "2023-12-10 20:29:19,066 INFO     Training average positive_sample_loss at step 93000: 0.195102\n",
      "2023-12-10 20:29:19,066 INFO     Training average negative_sample_loss at step 93000: 0.170356\n",
      "2023-12-10 20:29:19,066 INFO     Training average loss at step 93000: 0.182729\n",
      "2023-12-10 20:30:06,459 INFO     Training average positive_sample_loss at step 93100: 0.195293\n",
      "2023-12-10 20:30:06,459 INFO     Training average negative_sample_loss at step 93100: 0.171453\n",
      "2023-12-10 20:30:06,459 INFO     Training average loss at step 93100: 0.183373\n",
      "2023-12-10 20:30:51,167 INFO     Training average positive_sample_loss at step 93200: 0.191893\n",
      "2023-12-10 20:30:51,167 INFO     Training average negative_sample_loss at step 93200: 0.169770\n",
      "2023-12-10 20:30:51,167 INFO     Training average loss at step 93200: 0.180832\n",
      "2023-12-10 20:31:35,032 INFO     Training average positive_sample_loss at step 93300: 0.193754\n",
      "2023-12-10 20:31:35,033 INFO     Training average negative_sample_loss at step 93300: 0.169375\n",
      "2023-12-10 20:31:35,033 INFO     Training average loss at step 93300: 0.181564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 20:32:19,653 INFO     Training average positive_sample_loss at step 93400: 0.194652\n",
      "2023-12-10 20:32:19,653 INFO     Training average negative_sample_loss at step 93400: 0.168980\n",
      "2023-12-10 20:32:19,654 INFO     Training average loss at step 93400: 0.181816\n",
      "2023-12-10 20:33:04,056 INFO     Training average positive_sample_loss at step 93500: 0.195517\n",
      "2023-12-10 20:33:04,056 INFO     Training average negative_sample_loss at step 93500: 0.171276\n",
      "2023-12-10 20:33:04,057 INFO     Training average loss at step 93500: 0.183396\n",
      "2023-12-10 20:33:48,056 INFO     Training average positive_sample_loss at step 93600: 0.195699\n",
      "2023-12-10 20:33:48,056 INFO     Training average negative_sample_loss at step 93600: 0.171167\n",
      "2023-12-10 20:33:48,056 INFO     Training average loss at step 93600: 0.183433\n",
      "2023-12-10 20:34:37,281 INFO     Training average positive_sample_loss at step 93700: 0.193422\n",
      "2023-12-10 20:34:37,281 INFO     Training average negative_sample_loss at step 93700: 0.170727\n",
      "2023-12-10 20:34:37,281 INFO     Training average loss at step 93700: 0.182074\n",
      "2023-12-10 20:35:20,968 INFO     Training average positive_sample_loss at step 93800: 0.193237\n",
      "2023-12-10 20:35:20,969 INFO     Training average negative_sample_loss at step 93800: 0.170460\n",
      "2023-12-10 20:35:20,969 INFO     Training average loss at step 93800: 0.181849\n",
      "2023-12-10 20:36:03,987 INFO     Training average positive_sample_loss at step 93900: 0.194368\n",
      "2023-12-10 20:36:03,988 INFO     Training average negative_sample_loss at step 93900: 0.169552\n",
      "2023-12-10 20:36:03,988 INFO     Training average loss at step 93900: 0.181960\n",
      "2023-12-10 20:36:46,351 INFO     Training average positive_sample_loss at step 94000: 0.194091\n",
      "2023-12-10 20:36:46,351 INFO     Training average negative_sample_loss at step 94000: 0.170230\n",
      "2023-12-10 20:36:46,351 INFO     Training average loss at step 94000: 0.182160\n",
      "2023-12-10 20:37:28,861 INFO     Training average positive_sample_loss at step 94100: 0.195791\n",
      "2023-12-10 20:37:28,862 INFO     Training average negative_sample_loss at step 94100: 0.170545\n",
      "2023-12-10 20:37:28,862 INFO     Training average loss at step 94100: 0.183168\n",
      "2023-12-10 20:38:18,896 INFO     Training average positive_sample_loss at step 94200: 0.195127\n",
      "2023-12-10 20:38:18,896 INFO     Training average negative_sample_loss at step 94200: 0.171253\n",
      "2023-12-10 20:38:18,896 INFO     Training average loss at step 94200: 0.183190\n",
      "2023-12-10 20:39:01,695 INFO     Training average positive_sample_loss at step 94300: 0.193631\n",
      "2023-12-10 20:39:01,696 INFO     Training average negative_sample_loss at step 94300: 0.169373\n",
      "2023-12-10 20:39:01,696 INFO     Training average loss at step 94300: 0.181502\n",
      "2023-12-10 20:39:44,643 INFO     Training average positive_sample_loss at step 94400: 0.194184\n",
      "2023-12-10 20:39:44,644 INFO     Training average negative_sample_loss at step 94400: 0.170728\n",
      "2023-12-10 20:39:44,644 INFO     Training average loss at step 94400: 0.182456\n",
      "2023-12-10 20:40:28,267 INFO     Training average positive_sample_loss at step 94500: 0.194342\n",
      "2023-12-10 20:40:28,267 INFO     Training average negative_sample_loss at step 94500: 0.170127\n",
      "2023-12-10 20:40:28,268 INFO     Training average loss at step 94500: 0.182235\n",
      "2023-12-10 20:41:12,043 INFO     Training average positive_sample_loss at step 94600: 0.195290\n",
      "2023-12-10 20:41:12,044 INFO     Training average negative_sample_loss at step 94600: 0.170281\n",
      "2023-12-10 20:41:12,044 INFO     Training average loss at step 94600: 0.182786\n",
      "2023-12-10 20:42:03,186 INFO     Training average positive_sample_loss at step 94700: 0.195136\n",
      "2023-12-10 20:42:03,186 INFO     Training average negative_sample_loss at step 94700: 0.169300\n",
      "2023-12-10 20:42:03,186 INFO     Training average loss at step 94700: 0.182218\n",
      "2023-12-10 20:42:48,582 INFO     Training average positive_sample_loss at step 94800: 0.192556\n",
      "2023-12-10 20:42:48,583 INFO     Training average negative_sample_loss at step 94800: 0.170483\n",
      "2023-12-10 20:42:48,583 INFO     Training average loss at step 94800: 0.181519\n",
      "2023-12-10 20:43:31,479 INFO     Training average positive_sample_loss at step 94900: 0.193739\n",
      "2023-12-10 20:43:31,480 INFO     Training average negative_sample_loss at step 94900: 0.169906\n",
      "2023-12-10 20:43:31,480 INFO     Training average loss at step 94900: 0.181823\n",
      "2023-12-10 20:44:13,590 INFO     Training average positive_sample_loss at step 95000: 0.194288\n",
      "2023-12-10 20:44:13,591 INFO     Training average negative_sample_loss at step 95000: 0.168999\n",
      "2023-12-10 20:44:13,591 INFO     Training average loss at step 95000: 0.181644\n",
      "2023-12-10 20:44:55,720 INFO     Training average positive_sample_loss at step 95100: 0.194841\n",
      "2023-12-10 20:44:55,720 INFO     Training average negative_sample_loss at step 95100: 0.170287\n",
      "2023-12-10 20:44:55,720 INFO     Training average loss at step 95100: 0.182564\n",
      "2023-12-10 20:45:39,338 INFO     Training average positive_sample_loss at step 95200: 0.196009\n",
      "2023-12-10 20:45:39,338 INFO     Training average negative_sample_loss at step 95200: 0.170166\n",
      "2023-12-10 20:45:39,338 INFO     Training average loss at step 95200: 0.183088\n",
      "2023-12-10 20:46:31,730 INFO     Training average positive_sample_loss at step 95300: 0.193127\n",
      "2023-12-10 20:46:31,730 INFO     Training average negative_sample_loss at step 95300: 0.169711\n",
      "2023-12-10 20:46:31,730 INFO     Training average loss at step 95300: 0.181419\n",
      "2023-12-10 20:47:14,174 INFO     Training average positive_sample_loss at step 95400: 0.193428\n",
      "2023-12-10 20:47:14,175 INFO     Training average negative_sample_loss at step 95400: 0.170180\n",
      "2023-12-10 20:47:14,175 INFO     Training average loss at step 95400: 0.181804\n",
      "2023-12-10 20:47:57,685 INFO     Training average positive_sample_loss at step 95500: 0.194586\n",
      "2023-12-10 20:47:57,686 INFO     Training average negative_sample_loss at step 95500: 0.169554\n",
      "2023-12-10 20:47:57,686 INFO     Training average loss at step 95500: 0.182070\n",
      "2023-12-10 20:48:41,980 INFO     Training average positive_sample_loss at step 95600: 0.195088\n",
      "2023-12-10 20:48:41,981 INFO     Training average negative_sample_loss at step 95600: 0.169567\n",
      "2023-12-10 20:48:41,981 INFO     Training average loss at step 95600: 0.182327\n",
      "2023-12-10 20:49:26,102 INFO     Training average positive_sample_loss at step 95700: 0.195729\n",
      "2023-12-10 20:49:26,103 INFO     Training average negative_sample_loss at step 95700: 0.169683\n",
      "2023-12-10 20:49:26,103 INFO     Training average loss at step 95700: 0.182706\n",
      "2023-12-10 20:50:14,652 INFO     Training average positive_sample_loss at step 95800: 0.193291\n",
      "2023-12-10 20:50:14,652 INFO     Training average negative_sample_loss at step 95800: 0.170996\n",
      "2023-12-10 20:50:14,652 INFO     Training average loss at step 95800: 0.182144\n",
      "2023-12-10 20:50:57,944 INFO     Training average positive_sample_loss at step 95900: 0.193278\n",
      "2023-12-10 20:50:57,945 INFO     Training average negative_sample_loss at step 95900: 0.169922\n",
      "2023-12-10 20:50:57,945 INFO     Training average loss at step 95900: 0.181600\n",
      "2023-12-10 20:51:41,913 INFO     Training average positive_sample_loss at step 96000: 0.194293\n",
      "2023-12-10 20:51:41,913 INFO     Training average negative_sample_loss at step 96000: 0.169482\n",
      "2023-12-10 20:51:41,913 INFO     Training average loss at step 96000: 0.181888\n",
      "2023-12-10 20:52:24,044 INFO     Training average positive_sample_loss at step 96100: 0.195084\n",
      "2023-12-10 20:52:24,045 INFO     Training average negative_sample_loss at step 96100: 0.170339\n",
      "2023-12-10 20:52:24,045 INFO     Training average loss at step 96100: 0.182712\n",
      "2023-12-10 20:53:08,733 INFO     Training average positive_sample_loss at step 96200: 0.194359\n",
      "2023-12-10 20:53:08,733 INFO     Training average negative_sample_loss at step 96200: 0.170839\n",
      "2023-12-10 20:53:08,733 INFO     Training average loss at step 96200: 0.182599\n",
      "2023-12-10 20:53:58,665 INFO     Training average positive_sample_loss at step 96300: 0.195329\n",
      "2023-12-10 20:53:58,666 INFO     Training average negative_sample_loss at step 96300: 0.171436\n",
      "2023-12-10 20:53:58,666 INFO     Training average loss at step 96300: 0.183382\n",
      "2023-12-10 20:54:42,693 INFO     Training average positive_sample_loss at step 96400: 0.192580\n",
      "2023-12-10 20:54:42,694 INFO     Training average negative_sample_loss at step 96400: 0.169214\n",
      "2023-12-10 20:54:42,694 INFO     Training average loss at step 96400: 0.180897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 20:55:28,269 INFO     Training average positive_sample_loss at step 96500: 0.193686\n",
      "2023-12-10 20:55:28,270 INFO     Training average negative_sample_loss at step 96500: 0.170651\n",
      "2023-12-10 20:55:28,270 INFO     Training average loss at step 96500: 0.182169\n",
      "2023-12-10 20:56:13,911 INFO     Training average positive_sample_loss at step 96600: 0.194770\n",
      "2023-12-10 20:56:13,911 INFO     Training average negative_sample_loss at step 96600: 0.170243\n",
      "2023-12-10 20:56:13,911 INFO     Training average loss at step 96600: 0.182507\n",
      "2023-12-10 20:56:59,511 INFO     Training average positive_sample_loss at step 96700: 0.195504\n",
      "2023-12-10 20:56:59,512 INFO     Training average negative_sample_loss at step 96700: 0.169784\n",
      "2023-12-10 20:56:59,512 INFO     Training average loss at step 96700: 0.182644\n",
      "2023-12-10 20:57:41,685 INFO     Training average positive_sample_loss at step 96800: 0.195189\n",
      "2023-12-10 20:57:41,685 INFO     Training average negative_sample_loss at step 96800: 0.169879\n",
      "2023-12-10 20:57:41,685 INFO     Training average loss at step 96800: 0.182534\n",
      "2023-12-10 20:58:30,667 INFO     Training average positive_sample_loss at step 96900: 0.193660\n",
      "2023-12-10 20:58:30,667 INFO     Training average negative_sample_loss at step 96900: 0.170282\n",
      "2023-12-10 20:58:30,667 INFO     Training average loss at step 96900: 0.181971\n",
      "2023-12-10 20:59:15,050 INFO     Training average positive_sample_loss at step 97000: 0.193545\n",
      "2023-12-10 20:59:15,050 INFO     Training average negative_sample_loss at step 97000: 0.170356\n",
      "2023-12-10 20:59:15,050 INFO     Training average loss at step 97000: 0.181951\n",
      "2023-12-10 20:59:57,772 INFO     Training average positive_sample_loss at step 97100: 0.194045\n",
      "2023-12-10 20:59:57,772 INFO     Training average negative_sample_loss at step 97100: 0.170371\n",
      "2023-12-10 20:59:57,772 INFO     Training average loss at step 97100: 0.182208\n",
      "2023-12-10 21:00:41,291 INFO     Training average positive_sample_loss at step 97200: 0.194544\n",
      "2023-12-10 21:00:41,291 INFO     Training average negative_sample_loss at step 97200: 0.170280\n",
      "2023-12-10 21:00:41,291 INFO     Training average loss at step 97200: 0.182412\n",
      "2023-12-10 21:01:24,519 INFO     Training average positive_sample_loss at step 97300: 0.195560\n",
      "2023-12-10 21:01:24,520 INFO     Training average negative_sample_loss at step 97300: 0.169214\n",
      "2023-12-10 21:01:24,520 INFO     Training average loss at step 97300: 0.182387\n",
      "2023-12-10 21:02:15,928 INFO     Training average positive_sample_loss at step 97400: 0.194434\n",
      "2023-12-10 21:02:15,928 INFO     Training average negative_sample_loss at step 97400: 0.169620\n",
      "2023-12-10 21:02:15,928 INFO     Training average loss at step 97400: 0.182027\n",
      "2023-12-10 21:02:58,909 INFO     Training average positive_sample_loss at step 97500: 0.193362\n",
      "2023-12-10 21:02:58,910 INFO     Training average negative_sample_loss at step 97500: 0.170015\n",
      "2023-12-10 21:02:58,910 INFO     Training average loss at step 97500: 0.181688\n",
      "2023-12-10 21:03:42,123 INFO     Training average positive_sample_loss at step 97600: 0.193883\n",
      "2023-12-10 21:03:42,124 INFO     Training average negative_sample_loss at step 97600: 0.170140\n",
      "2023-12-10 21:03:42,124 INFO     Training average loss at step 97600: 0.182011\n",
      "2023-12-10 21:04:26,223 INFO     Training average positive_sample_loss at step 97700: 0.194928\n",
      "2023-12-10 21:04:26,223 INFO     Training average negative_sample_loss at step 97700: 0.169414\n",
      "2023-12-10 21:04:26,223 INFO     Training average loss at step 97700: 0.182171\n",
      "2023-12-10 21:05:09,416 INFO     Training average positive_sample_loss at step 97800: 0.195400\n",
      "2023-12-10 21:05:09,416 INFO     Training average negative_sample_loss at step 97800: 0.171011\n",
      "2023-12-10 21:05:09,416 INFO     Training average loss at step 97800: 0.183205\n",
      "2023-12-10 21:05:58,903 INFO     Training average positive_sample_loss at step 97900: 0.194138\n",
      "2023-12-10 21:05:58,903 INFO     Training average negative_sample_loss at step 97900: 0.170051\n",
      "2023-12-10 21:05:58,903 INFO     Training average loss at step 97900: 0.182095\n",
      "2023-12-10 21:06:41,713 INFO     Training average positive_sample_loss at step 98000: 0.192846\n",
      "2023-12-10 21:06:41,713 INFO     Training average negative_sample_loss at step 98000: 0.170509\n",
      "2023-12-10 21:06:41,713 INFO     Training average loss at step 98000: 0.181677\n",
      "2023-12-10 21:07:25,734 INFO     Training average positive_sample_loss at step 98100: 0.194249\n",
      "2023-12-10 21:07:25,734 INFO     Training average negative_sample_loss at step 98100: 0.169895\n",
      "2023-12-10 21:07:25,734 INFO     Training average loss at step 98100: 0.182072\n",
      "2023-12-10 21:08:08,834 INFO     Training average positive_sample_loss at step 98200: 0.194801\n",
      "2023-12-10 21:08:08,834 INFO     Training average negative_sample_loss at step 98200: 0.169048\n",
      "2023-12-10 21:08:08,834 INFO     Training average loss at step 98200: 0.181925\n",
      "2023-12-10 21:08:51,520 INFO     Training average positive_sample_loss at step 98300: 0.194841\n",
      "2023-12-10 21:08:51,520 INFO     Training average negative_sample_loss at step 98300: 0.170704\n",
      "2023-12-10 21:08:51,520 INFO     Training average loss at step 98300: 0.182773\n",
      "2023-12-10 21:09:35,552 INFO     Training average positive_sample_loss at step 98400: 0.195228\n",
      "2023-12-10 21:09:35,552 INFO     Training average negative_sample_loss at step 98400: 0.169671\n",
      "2023-12-10 21:09:35,552 INFO     Training average loss at step 98400: 0.182449\n",
      "2023-12-10 21:10:23,716 INFO     Training average positive_sample_loss at step 98500: 0.193072\n",
      "2023-12-10 21:10:23,716 INFO     Training average negative_sample_loss at step 98500: 0.169070\n",
      "2023-12-10 21:10:23,716 INFO     Training average loss at step 98500: 0.181071\n",
      "2023-12-10 21:11:07,849 INFO     Training average positive_sample_loss at step 98600: 0.193808\n",
      "2023-12-10 21:11:07,850 INFO     Training average negative_sample_loss at step 98600: 0.171138\n",
      "2023-12-10 21:11:07,850 INFO     Training average loss at step 98600: 0.182473\n",
      "2023-12-10 21:11:52,101 INFO     Training average positive_sample_loss at step 98700: 0.194201\n",
      "2023-12-10 21:11:52,101 INFO     Training average negative_sample_loss at step 98700: 0.169271\n",
      "2023-12-10 21:11:52,101 INFO     Training average loss at step 98700: 0.181736\n",
      "2023-12-10 21:12:36,506 INFO     Training average positive_sample_loss at step 98800: 0.194312\n",
      "2023-12-10 21:12:36,506 INFO     Training average negative_sample_loss at step 98800: 0.169704\n",
      "2023-12-10 21:12:36,507 INFO     Training average loss at step 98800: 0.182008\n",
      "2023-12-10 21:13:20,591 INFO     Training average positive_sample_loss at step 98900: 0.195608\n",
      "2023-12-10 21:13:20,591 INFO     Training average negative_sample_loss at step 98900: 0.170308\n",
      "2023-12-10 21:13:20,591 INFO     Training average loss at step 98900: 0.182958\n",
      "2023-12-10 21:14:10,994 INFO     Training average positive_sample_loss at step 99000: 0.194002\n",
      "2023-12-10 21:14:10,995 INFO     Training average negative_sample_loss at step 99000: 0.169710\n",
      "2023-12-10 21:14:10,995 INFO     Training average loss at step 99000: 0.181856\n",
      "2023-12-10 21:14:54,801 INFO     Training average positive_sample_loss at step 99100: 0.192035\n",
      "2023-12-10 21:14:54,801 INFO     Training average negative_sample_loss at step 99100: 0.168510\n",
      "2023-12-10 21:14:54,801 INFO     Training average loss at step 99100: 0.180273\n",
      "2023-12-10 21:15:37,290 INFO     Training average positive_sample_loss at step 99200: 0.194479\n",
      "2023-12-10 21:15:37,290 INFO     Training average negative_sample_loss at step 99200: 0.170635\n",
      "2023-12-10 21:15:37,290 INFO     Training average loss at step 99200: 0.182557\n",
      "2023-12-10 21:16:22,151 INFO     Training average positive_sample_loss at step 99300: 0.195233\n",
      "2023-12-10 21:16:22,152 INFO     Training average negative_sample_loss at step 99300: 0.170459\n",
      "2023-12-10 21:16:22,152 INFO     Training average loss at step 99300: 0.182846\n",
      "2023-12-10 21:17:06,076 INFO     Training average positive_sample_loss at step 99400: 0.194842\n",
      "2023-12-10 21:17:06,077 INFO     Training average negative_sample_loss at step 99400: 0.169076\n",
      "2023-12-10 21:17:06,077 INFO     Training average loss at step 99400: 0.181959\n",
      "2023-12-10 21:17:54,937 INFO     Training average positive_sample_loss at step 99500: 0.195788\n",
      "2023-12-10 21:17:54,937 INFO     Training average negative_sample_loss at step 99500: 0.171237\n",
      "2023-12-10 21:17:54,937 INFO     Training average loss at step 99500: 0.183513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 21:18:38,006 INFO     Training average positive_sample_loss at step 99600: 0.193155\n",
      "2023-12-10 21:18:38,006 INFO     Training average negative_sample_loss at step 99600: 0.169953\n",
      "2023-12-10 21:18:38,006 INFO     Training average loss at step 99600: 0.181554\n",
      "2023-12-10 21:19:21,380 INFO     Training average positive_sample_loss at step 99700: 0.193974\n",
      "2023-12-10 21:19:21,380 INFO     Training average negative_sample_loss at step 99700: 0.170335\n",
      "2023-12-10 21:19:21,381 INFO     Training average loss at step 99700: 0.182154\n",
      "2023-12-10 21:20:04,741 INFO     Training average positive_sample_loss at step 99800: 0.194342\n",
      "2023-12-10 21:20:04,742 INFO     Training average negative_sample_loss at step 99800: 0.168935\n",
      "2023-12-10 21:20:04,742 INFO     Training average loss at step 99800: 0.181638\n",
      "2023-12-10 21:20:48,788 INFO     Training average positive_sample_loss at step 99900: 0.195111\n",
      "2023-12-10 21:20:48,789 INFO     Training average negative_sample_loss at step 99900: 0.169709\n",
      "2023-12-10 21:20:48,789 INFO     Training average loss at step 99900: 0.182410\n",
      "2023-12-10 21:21:42,033 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 21:21:42,679 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-10 21:22:13,755 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-10 21:22:45,129 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-10 21:22:51,250 INFO     Valid MRR at step 99999: 0.324651\n",
      "2023-12-10 21:22:51,250 INFO     Valid MR at step 99999: 153.724636\n",
      "2023-12-10 21:22:51,251 INFO     Valid HITS@1 at step 99999: 0.230026\n",
      "2023-12-10 21:22:51,251 INFO     Valid HITS@3 at step 99999: 0.357114\n",
      "2023-12-10 21:22:51,251 INFO     Valid HITS@10 at step 99999: 0.519618\n",
      "2023-12-10 21:22:51,251 INFO     Evaluating on Test Dataset...\n",
      "2023-12-10 21:22:51,824 INFO     Evaluating the model... (0/2560)\n",
      "2023-12-10 21:23:23,475 INFO     Evaluating the model... (1000/2560)\n",
      "2023-12-10 21:23:56,988 INFO     Evaluating the model... (2000/2560)\n",
      "2023-12-10 21:24:13,122 INFO     Test MRR at step 99999: 0.318819\n",
      "2023-12-10 21:24:13,123 INFO     Test MR at step 99999: 158.377431\n",
      "2023-12-10 21:24:13,123 INFO     Test HITS@1 at step 99999: 0.223151\n",
      "2023-12-10 21:24:13,123 INFO     Test HITS@3 at step 99999: 0.350606\n",
      "2023-12-10 21:24:13,123 INFO     Test HITS@10 at step 99999: 0.514536\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE FB15k-237 0 0 1024 256 1000 9.0 1.0 0.00005 100000 16 -de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding_patt\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding_NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-12 11:58:49,526 INFO     Model: RotatE\n",
      "2023-12-12 11:58:49,526 INFO     Data Path: data/FB15k-237\n",
      "2023-12-12 11:58:49,526 INFO     #entity: 14541\n",
      "2023-12-12 11:58:49,526 INFO     #relation: 237\n",
      "2023-12-12 11:58:51,626 INFO     #train: 272115\n",
      "2023-12-12 11:58:51,775 INFO     #valid: 17535\n",
      "2023-12-12 11:58:51,838 INFO     #test: 20466\n",
      "2023-12-12 11:58:52,087 INFO     Model Parameter Configuration:\n",
      "2023-12-12 11:58:52,089 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-12 11:58:52,089 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-12 11:58:52,089 INFO     Parameter entity_embedding: torch.Size([14541, 2000]), require_grad = True\n",
      "2023-12-12 11:58:52,089 INFO     Parameter relation_embedding: torch.Size([237, 1000]), require_grad = True\n",
      "2023-12-12 11:58:58,841 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-12 11:58:58,841 INFO     Start Training...\n",
      "2023-12-12 11:58:58,841 INFO     init_step = 0\n",
      "2023-12-12 11:58:58,841 INFO     batch_size = 1024\n",
      "2023-12-12 11:58:58,841 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-12 11:58:58,841 INFO     hidden_dim = 1000\n",
      "2023-12-12 11:58:58,841 INFO     gamma = 9.000000\n",
      "2023-12-12 11:58:58,841 INFO     negative_adversarial_sampling = True\n",
      "2023-12-12 11:58:58,841 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-12 11:58:58,841 INFO     learning_rate = 0\n",
      "2023-12-12 11:59:13,938 INFO     Training average positive_sample_loss at step 0: 2.547372\n",
      "2023-12-12 11:59:13,939 INFO     Training average negative_sample_loss at step 0: 0.084808\n",
      "2023-12-12 11:59:13,939 INFO     Training average loss at step 0: 1.316090\n",
      "2023-12-12 11:59:13,939 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-12 11:59:14,571 INFO     Evaluating the model... (0/2192)\n",
      "2023-12-12 11:59:39,898 INFO     Evaluating the model... (1000/2192)\n",
      "2023-12-12 12:00:03,536 INFO     Evaluating the model... (2000/2192)\n",
      "2023-12-12 12:00:07,929 INFO     Valid MRR at step 0: 0.005726\n",
      "2023-12-12 12:00:07,929 INFO     Valid MR at step 0: 6827.551126\n",
      "2023-12-12 12:00:07,929 INFO     Valid HITS@1 at step 0: 0.004876\n",
      "2023-12-12 12:00:07,929 INFO     Valid HITS@3 at step 0: 0.005218\n",
      "2023-12-12 12:00:07,929 INFO     Valid HITS@10 at step 0: 0.005902\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE FB15k-237 0 0 1024 256 1000 9.0 1.0 0.00005 100000 16 -de"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
