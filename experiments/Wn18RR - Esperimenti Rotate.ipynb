{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con self.adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-03 00:14:07,857 INFO     Model: RotatE\n",
      "2023-12-03 00:14:07,859 INFO     Data Path: data/wn18rr\n",
      "2023-12-03 00:14:07,859 INFO     #entity: 40943\n",
      "2023-12-03 00:14:07,859 INFO     #relation: 11\n",
      "2023-12-03 00:14:08,004 INFO     #train: 86835\n",
      "2023-12-03 00:14:08,009 INFO     #valid: 3034\n",
      "2023-12-03 00:14:08,013 INFO     #test: 3134\n",
      "2023-12-03 00:14:08,304 INFO     Model Parameter Configuration:\n",
      "2023-12-03 00:14:08,305 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-03 00:14:08,305 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-03 00:14:08,305 INFO     Parameter entity_embedding: torch.Size([40943, 1000]), require_grad = True\n",
      "2023-12-03 00:14:08,305 INFO     Parameter relation_embedding: torch.Size([11, 500]), require_grad = True\n",
      "2023-12-03 00:14:09,969 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-03 00:14:09,970 INFO     Start Training...\n",
      "2023-12-03 00:14:09,970 INFO     init_step = 0\n",
      "2023-12-03 00:14:09,970 INFO     batch_size = 512\n",
      "2023-12-03 00:14:09,970 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-03 00:14:09,970 INFO     hidden_dim = 500\n",
      "2023-12-03 00:14:09,970 INFO     gamma = 6.000000\n",
      "2023-12-03 00:14:09,970 INFO     negative_adversarial_sampling = True\n",
      "2023-12-03 00:14:09,970 INFO     adversarial_temperature = 0.500000\n",
      "2023-12-03 00:14:09,970 INFO     learning_rate = 0\n",
      "2023-12-03 00:14:20,074 INFO     Training average positive_sample_loss at step 0: 2.446145\n",
      "2023-12-03 00:14:20,074 INFO     Training average negative_sample_loss at step 0: 0.093440\n",
      "2023-12-03 00:14:20,074 INFO     Training average loss at step 0: 1.269792\n",
      "2023-12-03 00:14:20,074 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:14:20,976 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:14:52,577 INFO     Valid MRR at step 0: 0.000201\n",
      "2023-12-03 00:14:52,577 INFO     Valid MR at step 0: 20342.272742\n",
      "2023-12-03 00:14:52,577 INFO     Valid HITS@1 at step 0: 0.000000\n",
      "2023-12-03 00:14:52,577 INFO     Valid HITS@3 at step 0: 0.000000\n",
      "2023-12-03 00:14:52,577 INFO     Valid HITS@10 at step 0: 0.000000\n",
      "2023-12-03 00:14:58,317 INFO     Training average positive_sample_loss at step 100: 2.919692\n",
      "2023-12-03 00:14:58,318 INFO     Training average negative_sample_loss at step 100: 0.059145\n",
      "2023-12-03 00:14:58,318 INFO     Training average loss at step 100: 1.489418\n",
      "2023-12-03 00:15:04,391 INFO     Training average positive_sample_loss at step 200: 2.777005\n",
      "2023-12-03 00:15:04,391 INFO     Training average negative_sample_loss at step 200: 0.073714\n",
      "2023-12-03 00:15:04,391 INFO     Training average loss at step 200: 1.425359\n",
      "2023-12-03 00:15:10,447 INFO     Training average positive_sample_loss at step 300: 2.384369\n",
      "2023-12-03 00:15:10,447 INFO     Training average negative_sample_loss at step 300: 0.107056\n",
      "2023-12-03 00:15:10,447 INFO     Training average loss at step 300: 1.245713\n",
      "2023-12-03 00:15:17,122 INFO     Training average positive_sample_loss at step 400: 1.833029\n",
      "2023-12-03 00:15:17,122 INFO     Training average negative_sample_loss at step 400: 0.152266\n",
      "2023-12-03 00:15:17,122 INFO     Training average loss at step 400: 0.992648\n",
      "2023-12-03 00:15:23,221 INFO     Training average positive_sample_loss at step 500: 1.479332\n",
      "2023-12-03 00:15:23,221 INFO     Training average negative_sample_loss at step 500: 0.197456\n",
      "2023-12-03 00:15:23,221 INFO     Training average loss at step 500: 0.838394\n",
      "2023-12-03 00:15:28,644 INFO     Training average positive_sample_loss at step 600: 1.276890\n",
      "2023-12-03 00:15:28,645 INFO     Training average negative_sample_loss at step 600: 0.239895\n",
      "2023-12-03 00:15:28,645 INFO     Training average loss at step 600: 0.758393\n",
      "2023-12-03 00:15:35,277 INFO     Training average positive_sample_loss at step 700: 1.083148\n",
      "2023-12-03 00:15:35,277 INFO     Training average negative_sample_loss at step 700: 0.278458\n",
      "2023-12-03 00:15:35,277 INFO     Training average loss at step 700: 0.680803\n",
      "2023-12-03 00:15:41,392 INFO     Training average positive_sample_loss at step 800: 0.848548\n",
      "2023-12-03 00:15:41,393 INFO     Training average negative_sample_loss at step 800: 0.309856\n",
      "2023-12-03 00:15:41,393 INFO     Training average loss at step 800: 0.579202\n",
      "2023-12-03 00:15:47,521 INFO     Training average positive_sample_loss at step 900: 0.777844\n",
      "2023-12-03 00:15:47,522 INFO     Training average negative_sample_loss at step 900: 0.327174\n",
      "2023-12-03 00:15:47,522 INFO     Training average loss at step 900: 0.552509\n",
      "2023-12-03 00:15:53,639 INFO     Training average positive_sample_loss at step 1000: 0.715253\n",
      "2023-12-03 00:15:53,639 INFO     Training average negative_sample_loss at step 1000: 0.340711\n",
      "2023-12-03 00:15:53,639 INFO     Training average loss at step 1000: 0.527982\n",
      "2023-12-03 00:15:59,753 INFO     Training average positive_sample_loss at step 1100: 0.585534\n",
      "2023-12-03 00:15:59,754 INFO     Training average negative_sample_loss at step 1100: 0.349727\n",
      "2023-12-03 00:15:59,754 INFO     Training average loss at step 1100: 0.467631\n",
      "2023-12-03 00:16:05,662 INFO     Training average positive_sample_loss at step 1200: 0.545800\n",
      "2023-12-03 00:16:05,663 INFO     Training average negative_sample_loss at step 1200: 0.347904\n",
      "2023-12-03 00:16:05,663 INFO     Training average loss at step 1200: 0.446852\n",
      "2023-12-03 00:16:11,832 INFO     Training average positive_sample_loss at step 1300: 0.526767\n",
      "2023-12-03 00:16:11,832 INFO     Training average negative_sample_loss at step 1300: 0.344458\n",
      "2023-12-03 00:16:11,832 INFO     Training average loss at step 1300: 0.435612\n",
      "2023-12-03 00:16:18,318 INFO     Training average positive_sample_loss at step 1400: 0.476315\n",
      "2023-12-03 00:16:18,318 INFO     Training average negative_sample_loss at step 1400: 0.339449\n",
      "2023-12-03 00:16:18,318 INFO     Training average loss at step 1400: 0.407882\n",
      "2023-12-03 00:16:24,451 INFO     Training average positive_sample_loss at step 1500: 0.429733\n",
      "2023-12-03 00:16:24,451 INFO     Training average negative_sample_loss at step 1500: 0.330395\n",
      "2023-12-03 00:16:24,451 INFO     Training average loss at step 1500: 0.380064\n",
      "2023-12-03 00:16:29,874 INFO     Training average positive_sample_loss at step 1600: 0.426160\n",
      "2023-12-03 00:16:29,874 INFO     Training average negative_sample_loss at step 1600: 0.321017\n",
      "2023-12-03 00:16:29,874 INFO     Training average loss at step 1600: 0.373589\n",
      "2023-12-03 00:16:36,200 INFO     Training average positive_sample_loss at step 1700: 0.419130\n",
      "2023-12-03 00:16:36,201 INFO     Training average negative_sample_loss at step 1700: 0.310154\n",
      "2023-12-03 00:16:36,201 INFO     Training average loss at step 1700: 0.364642\n",
      "2023-12-03 00:16:42,607 INFO     Training average positive_sample_loss at step 1800: 0.361405\n",
      "2023-12-03 00:16:42,607 INFO     Training average negative_sample_loss at step 1800: 0.299916\n",
      "2023-12-03 00:16:42,607 INFO     Training average loss at step 1800: 0.330661\n",
      "2023-12-03 00:16:48,746 INFO     Training average positive_sample_loss at step 1900: 0.365561\n",
      "2023-12-03 00:16:48,747 INFO     Training average negative_sample_loss at step 1900: 0.286042\n",
      "2023-12-03 00:16:48,747 INFO     Training average loss at step 1900: 0.325802\n",
      "2023-12-03 00:16:54,823 INFO     Training average positive_sample_loss at step 2000: 0.364363\n",
      "2023-12-03 00:16:54,824 INFO     Training average negative_sample_loss at step 2000: 0.277291\n",
      "2023-12-03 00:16:54,824 INFO     Training average loss at step 2000: 0.320827\n",
      "2023-12-03 00:17:01,178 INFO     Training average positive_sample_loss at step 2100: 0.333703\n",
      "2023-12-03 00:17:01,178 INFO     Training average negative_sample_loss at step 2100: 0.266729\n",
      "2023-12-03 00:17:01,178 INFO     Training average loss at step 2100: 0.300216\n",
      "2023-12-03 00:17:06,768 INFO     Training average positive_sample_loss at step 2200: 0.322165\n",
      "2023-12-03 00:17:06,768 INFO     Training average negative_sample_loss at step 2200: 0.254831\n",
      "2023-12-03 00:17:06,769 INFO     Training average loss at step 2200: 0.288498\n",
      "2023-12-03 00:17:12,858 INFO     Training average positive_sample_loss at step 2300: 0.323616\n",
      "2023-12-03 00:17:12,858 INFO     Training average negative_sample_loss at step 2300: 0.245562\n",
      "2023-12-03 00:17:12,858 INFO     Training average loss at step 2300: 0.284589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:17:19,409 INFO     Training average positive_sample_loss at step 2400: 0.314742\n",
      "2023-12-03 00:17:19,409 INFO     Training average negative_sample_loss at step 2400: 0.236566\n",
      "2023-12-03 00:17:19,409 INFO     Training average loss at step 2400: 0.275654\n",
      "2023-12-03 00:17:25,480 INFO     Training average positive_sample_loss at step 2500: 0.287011\n",
      "2023-12-03 00:17:25,480 INFO     Training average negative_sample_loss at step 2500: 0.226820\n",
      "2023-12-03 00:17:25,480 INFO     Training average loss at step 2500: 0.256915\n",
      "2023-12-03 00:17:31,537 INFO     Training average positive_sample_loss at step 2600: 0.291595\n",
      "2023-12-03 00:17:31,538 INFO     Training average negative_sample_loss at step 2600: 0.216844\n",
      "2023-12-03 00:17:31,538 INFO     Training average loss at step 2600: 0.254220\n",
      "2023-12-03 00:17:36,981 INFO     Training average positive_sample_loss at step 2700: 0.292821\n",
      "2023-12-03 00:17:36,981 INFO     Training average negative_sample_loss at step 2700: 0.209586\n",
      "2023-12-03 00:17:36,981 INFO     Training average loss at step 2700: 0.251204\n",
      "2023-12-03 00:17:43,376 INFO     Training average positive_sample_loss at step 2800: 0.262950\n",
      "2023-12-03 00:17:43,376 INFO     Training average negative_sample_loss at step 2800: 0.201372\n",
      "2023-12-03 00:17:43,376 INFO     Training average loss at step 2800: 0.232161\n",
      "2023-12-03 00:17:49,459 INFO     Training average positive_sample_loss at step 2900: 0.265003\n",
      "2023-12-03 00:17:49,459 INFO     Training average negative_sample_loss at step 2900: 0.193468\n",
      "2023-12-03 00:17:49,459 INFO     Training average loss at step 2900: 0.229235\n",
      "2023-12-03 00:17:55,539 INFO     Training average positive_sample_loss at step 3000: 0.267213\n",
      "2023-12-03 00:17:55,539 INFO     Training average negative_sample_loss at step 3000: 0.186629\n",
      "2023-12-03 00:17:55,539 INFO     Training average loss at step 3000: 0.226921\n",
      "2023-12-03 00:18:02,148 INFO     Training average positive_sample_loss at step 3100: 0.253685\n",
      "2023-12-03 00:18:02,148 INFO     Training average negative_sample_loss at step 3100: 0.180611\n",
      "2023-12-03 00:18:02,148 INFO     Training average loss at step 3100: 0.217148\n",
      "2023-12-03 00:18:07,615 INFO     Training average positive_sample_loss at step 3200: 0.239737\n",
      "2023-12-03 00:18:07,615 INFO     Training average negative_sample_loss at step 3200: 0.173058\n",
      "2023-12-03 00:18:07,615 INFO     Training average loss at step 3200: 0.206398\n",
      "2023-12-03 00:18:13,633 INFO     Training average positive_sample_loss at step 3300: 0.243801\n",
      "2023-12-03 00:18:13,633 INFO     Training average negative_sample_loss at step 3300: 0.166890\n",
      "2023-12-03 00:18:13,633 INFO     Training average loss at step 3300: 0.205345\n",
      "2023-12-03 00:18:19,943 INFO     Training average positive_sample_loss at step 3400: 0.245315\n",
      "2023-12-03 00:18:19,943 INFO     Training average negative_sample_loss at step 3400: 0.162338\n",
      "2023-12-03 00:18:19,943 INFO     Training average loss at step 3400: 0.203827\n",
      "2023-12-03 00:18:26,274 INFO     Training average positive_sample_loss at step 3500: 0.218051\n",
      "2023-12-03 00:18:26,274 INFO     Training average negative_sample_loss at step 3500: 0.156037\n",
      "2023-12-03 00:18:26,275 INFO     Training average loss at step 3500: 0.187044\n",
      "2023-12-03 00:18:32,335 INFO     Training average positive_sample_loss at step 3600: 0.224211\n",
      "2023-12-03 00:18:32,336 INFO     Training average negative_sample_loss at step 3600: 0.150449\n",
      "2023-12-03 00:18:32,336 INFO     Training average loss at step 3600: 0.187330\n",
      "2023-12-03 00:18:38,054 INFO     Training average positive_sample_loss at step 3700: 0.227313\n",
      "2023-12-03 00:18:38,054 INFO     Training average negative_sample_loss at step 3700: 0.145869\n",
      "2023-12-03 00:18:38,054 INFO     Training average loss at step 3700: 0.186591\n",
      "2023-12-03 00:18:44,330 INFO     Training average positive_sample_loss at step 3800: 0.210079\n",
      "2023-12-03 00:18:44,330 INFO     Training average negative_sample_loss at step 3800: 0.141506\n",
      "2023-12-03 00:18:44,330 INFO     Training average loss at step 3800: 0.175792\n",
      "2023-12-03 00:18:50,503 INFO     Training average positive_sample_loss at step 3900: 0.205558\n",
      "2023-12-03 00:18:50,503 INFO     Training average negative_sample_loss at step 3900: 0.136017\n",
      "2023-12-03 00:18:50,503 INFO     Training average loss at step 3900: 0.170788\n",
      "2023-12-03 00:18:56,592 INFO     Training average positive_sample_loss at step 4000: 0.209913\n",
      "2023-12-03 00:18:56,593 INFO     Training average negative_sample_loss at step 4000: 0.132249\n",
      "2023-12-03 00:18:56,593 INFO     Training average loss at step 4000: 0.171081\n",
      "2023-12-03 00:19:03,145 INFO     Training average positive_sample_loss at step 4100: 0.205979\n",
      "2023-12-03 00:19:03,145 INFO     Training average negative_sample_loss at step 4100: 0.128429\n",
      "2023-12-03 00:19:03,145 INFO     Training average loss at step 4100: 0.167204\n",
      "2023-12-03 00:19:09,236 INFO     Training average positive_sample_loss at step 4200: 0.188688\n",
      "2023-12-03 00:19:09,237 INFO     Training average negative_sample_loss at step 4200: 0.124046\n",
      "2023-12-03 00:19:09,237 INFO     Training average loss at step 4200: 0.156367\n",
      "2023-12-03 00:19:15,336 INFO     Training average positive_sample_loss at step 4300: 0.194720\n",
      "2023-12-03 00:19:15,336 INFO     Training average negative_sample_loss at step 4300: 0.120184\n",
      "2023-12-03 00:19:15,336 INFO     Training average loss at step 4300: 0.157452\n",
      "2023-12-03 00:19:20,865 INFO     Training average positive_sample_loss at step 4400: 0.196972\n",
      "2023-12-03 00:19:20,866 INFO     Training average negative_sample_loss at step 4400: 0.117469\n",
      "2023-12-03 00:19:20,866 INFO     Training average loss at step 4400: 0.157221\n",
      "2023-12-03 00:19:27,578 INFO     Training average positive_sample_loss at step 4500: 0.178504\n",
      "2023-12-03 00:19:27,578 INFO     Training average negative_sample_loss at step 4500: 0.113873\n",
      "2023-12-03 00:19:27,578 INFO     Training average loss at step 4500: 0.146188\n",
      "2023-12-03 00:19:33,815 INFO     Training average positive_sample_loss at step 4600: 0.180825\n",
      "2023-12-03 00:19:33,815 INFO     Training average negative_sample_loss at step 4600: 0.110263\n",
      "2023-12-03 00:19:33,815 INFO     Training average loss at step 4600: 0.145544\n",
      "2023-12-03 00:19:40,138 INFO     Training average positive_sample_loss at step 4700: 0.183027\n",
      "2023-12-03 00:19:40,139 INFO     Training average negative_sample_loss at step 4700: 0.107063\n",
      "2023-12-03 00:19:40,139 INFO     Training average loss at step 4700: 0.145045\n",
      "2023-12-03 00:19:46,674 INFO     Training average positive_sample_loss at step 4800: 0.175783\n",
      "2023-12-03 00:19:46,675 INFO     Training average negative_sample_loss at step 4800: 0.105018\n",
      "2023-12-03 00:19:46,675 INFO     Training average loss at step 4800: 0.140401\n",
      "2023-12-03 00:19:52,796 INFO     Training average positive_sample_loss at step 4900: 0.167057\n",
      "2023-12-03 00:19:52,796 INFO     Training average negative_sample_loss at step 4900: 0.101387\n",
      "2023-12-03 00:19:52,796 INFO     Training average loss at step 4900: 0.134222\n",
      "2023-12-03 00:19:58,283 INFO     Training average positive_sample_loss at step 5000: 0.171969\n",
      "2023-12-03 00:19:58,283 INFO     Training average negative_sample_loss at step 5000: 0.098565\n",
      "2023-12-03 00:19:58,283 INFO     Training average loss at step 5000: 0.135267\n",
      "2023-12-03 00:20:04,680 INFO     Training average positive_sample_loss at step 5100: 0.172465\n",
      "2023-12-03 00:20:04,681 INFO     Training average negative_sample_loss at step 5100: 0.096374\n",
      "2023-12-03 00:20:04,681 INFO     Training average loss at step 5100: 0.134419\n",
      "2023-12-03 00:20:11,084 INFO     Training average positive_sample_loss at step 5200: 0.154740\n",
      "2023-12-03 00:20:11,084 INFO     Training average negative_sample_loss at step 5200: 0.093839\n",
      "2023-12-03 00:20:11,084 INFO     Training average loss at step 5200: 0.124289\n",
      "2023-12-03 00:20:17,204 INFO     Training average positive_sample_loss at step 5300: 0.159472\n",
      "2023-12-03 00:20:17,204 INFO     Training average negative_sample_loss at step 5300: 0.090834\n",
      "2023-12-03 00:20:17,204 INFO     Training average loss at step 5300: 0.125153\n",
      "2023-12-03 00:20:23,337 INFO     Training average positive_sample_loss at step 5400: 0.164038\n",
      "2023-12-03 00:20:23,337 INFO     Training average negative_sample_loss at step 5400: 0.088972\n",
      "2023-12-03 00:20:23,337 INFO     Training average loss at step 5400: 0.126505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:20:30,108 INFO     Training average positive_sample_loss at step 5500: 0.151648\n",
      "2023-12-03 00:20:30,109 INFO     Training average negative_sample_loss at step 5500: 0.087138\n",
      "2023-12-03 00:20:30,109 INFO     Training average loss at step 5500: 0.119393\n",
      "2023-12-03 00:20:35,549 INFO     Training average positive_sample_loss at step 5600: 0.149445\n",
      "2023-12-03 00:20:35,549 INFO     Training average negative_sample_loss at step 5600: 0.084329\n",
      "2023-12-03 00:20:35,549 INFO     Training average loss at step 5600: 0.116887\n",
      "2023-12-03 00:20:41,695 INFO     Training average positive_sample_loss at step 5700: 0.154139\n",
      "2023-12-03 00:20:41,695 INFO     Training average negative_sample_loss at step 5700: 0.082738\n",
      "2023-12-03 00:20:41,695 INFO     Training average loss at step 5700: 0.118439\n",
      "2023-12-03 00:20:48,340 INFO     Training average positive_sample_loss at step 5800: 0.150019\n",
      "2023-12-03 00:20:48,341 INFO     Training average negative_sample_loss at step 5800: 0.080803\n",
      "2023-12-03 00:20:48,341 INFO     Training average loss at step 5800: 0.115411\n",
      "2023-12-03 00:20:54,475 INFO     Training average positive_sample_loss at step 5900: 0.139692\n",
      "2023-12-03 00:20:54,476 INFO     Training average negative_sample_loss at step 5900: 0.078705\n",
      "2023-12-03 00:20:54,476 INFO     Training average loss at step 5900: 0.109198\n",
      "2023-12-03 00:21:00,662 INFO     Training average positive_sample_loss at step 6000: 0.144858\n",
      "2023-12-03 00:21:00,662 INFO     Training average negative_sample_loss at step 6000: 0.076874\n",
      "2023-12-03 00:21:00,662 INFO     Training average loss at step 6000: 0.110866\n",
      "2023-12-03 00:21:06,900 INFO     Training average positive_sample_loss at step 6100: 0.146420\n",
      "2023-12-03 00:21:06,901 INFO     Training average negative_sample_loss at step 6100: 0.075386\n",
      "2023-12-03 00:21:06,901 INFO     Training average loss at step 6100: 0.110903\n",
      "2023-12-03 00:21:12,889 INFO     Training average positive_sample_loss at step 6200: 0.133436\n",
      "2023-12-03 00:21:12,890 INFO     Training average negative_sample_loss at step 6200: 0.073623\n",
      "2023-12-03 00:21:12,890 INFO     Training average loss at step 6200: 0.103529\n",
      "2023-12-03 00:21:19,005 INFO     Training average positive_sample_loss at step 6300: 0.135527\n",
      "2023-12-03 00:21:19,005 INFO     Training average negative_sample_loss at step 6300: 0.071635\n",
      "2023-12-03 00:21:19,005 INFO     Training average loss at step 6300: 0.103581\n",
      "2023-12-03 00:21:25,121 INFO     Training average positive_sample_loss at step 6400: 0.139277\n",
      "2023-12-03 00:21:25,121 INFO     Training average negative_sample_loss at step 6400: 0.070377\n",
      "2023-12-03 00:21:25,121 INFO     Training average loss at step 6400: 0.104827\n",
      "2023-12-03 00:21:31,464 INFO     Training average positive_sample_loss at step 6500: 0.133186\n",
      "2023-12-03 00:21:31,464 INFO     Training average negative_sample_loss at step 6500: 0.069334\n",
      "2023-12-03 00:21:31,464 INFO     Training average loss at step 6500: 0.101260\n",
      "2023-12-03 00:21:37,565 INFO     Training average positive_sample_loss at step 6600: 0.128052\n",
      "2023-12-03 00:21:37,566 INFO     Training average negative_sample_loss at step 6600: 0.067317\n",
      "2023-12-03 00:21:37,566 INFO     Training average loss at step 6600: 0.097684\n",
      "2023-12-03 00:21:43,216 INFO     Training average positive_sample_loss at step 6700: 0.131180\n",
      "2023-12-03 00:21:43,216 INFO     Training average negative_sample_loss at step 6700: 0.065849\n",
      "2023-12-03 00:21:43,217 INFO     Training average loss at step 6700: 0.098514\n",
      "2023-12-03 00:21:49,454 INFO     Training average positive_sample_loss at step 6800: 0.132581\n",
      "2023-12-03 00:21:49,455 INFO     Training average negative_sample_loss at step 6800: 0.064914\n",
      "2023-12-03 00:21:49,455 INFO     Training average loss at step 6800: 0.098747\n",
      "2023-12-03 00:21:55,831 INFO     Training average positive_sample_loss at step 6900: 0.119651\n",
      "2023-12-03 00:21:55,831 INFO     Training average negative_sample_loss at step 6900: 0.063462\n",
      "2023-12-03 00:21:55,831 INFO     Training average loss at step 6900: 0.091556\n",
      "2023-12-03 00:22:01,941 INFO     Training average positive_sample_loss at step 7000: 0.124055\n",
      "2023-12-03 00:22:01,941 INFO     Training average negative_sample_loss at step 7000: 0.061887\n",
      "2023-12-03 00:22:01,942 INFO     Training average loss at step 7000: 0.092971\n",
      "2023-12-03 00:22:07,568 INFO     Training average positive_sample_loss at step 7100: 0.126639\n",
      "2023-12-03 00:22:07,568 INFO     Training average negative_sample_loss at step 7100: 0.060949\n",
      "2023-12-03 00:22:07,568 INFO     Training average loss at step 7100: 0.093794\n",
      "2023-12-03 00:22:14,249 INFO     Training average positive_sample_loss at step 7200: 0.118849\n",
      "2023-12-03 00:22:14,250 INFO     Training average negative_sample_loss at step 7200: 0.059944\n",
      "2023-12-03 00:22:14,250 INFO     Training average loss at step 7200: 0.089396\n",
      "2023-12-03 00:22:20,376 INFO     Training average positive_sample_loss at step 7300: 0.117624\n",
      "2023-12-03 00:22:20,376 INFO     Training average negative_sample_loss at step 7300: 0.058632\n",
      "2023-12-03 00:22:20,376 INFO     Training average loss at step 7300: 0.088128\n",
      "2023-12-03 00:22:26,364 INFO     Training average positive_sample_loss at step 7400: 0.120695\n",
      "2023-12-03 00:22:26,364 INFO     Training average negative_sample_loss at step 7400: 0.057506\n",
      "2023-12-03 00:22:26,364 INFO     Training average loss at step 7400: 0.089101\n",
      "2023-12-03 00:22:32,494 INFO     Training average positive_sample_loss at step 7500: 0.119052\n",
      "2023-12-03 00:22:32,494 INFO     Training average negative_sample_loss at step 7500: 0.056777\n",
      "2023-12-03 00:22:32,494 INFO     Training average loss at step 7500: 0.087914\n",
      "2023-12-03 00:22:38,580 INFO     Training average positive_sample_loss at step 7600: 0.110792\n",
      "2023-12-03 00:22:38,580 INFO     Training average negative_sample_loss at step 7600: 0.055529\n",
      "2023-12-03 00:22:38,580 INFO     Training average loss at step 7600: 0.083161\n",
      "2023-12-03 00:22:44,678 INFO     Training average positive_sample_loss at step 7700: 0.114889\n",
      "2023-12-03 00:22:44,678 INFO     Training average negative_sample_loss at step 7700: 0.054209\n",
      "2023-12-03 00:22:44,678 INFO     Training average loss at step 7700: 0.084549\n",
      "2023-12-03 00:22:50,775 INFO     Training average positive_sample_loss at step 7800: 0.117350\n",
      "2023-12-03 00:22:50,775 INFO     Training average negative_sample_loss at step 7800: 0.053732\n",
      "2023-12-03 00:22:50,775 INFO     Training average loss at step 7800: 0.085541\n",
      "2023-12-03 00:22:56,642 INFO     Training average positive_sample_loss at step 7900: 0.107638\n",
      "2023-12-03 00:22:56,642 INFO     Training average negative_sample_loss at step 7900: 0.053064\n",
      "2023-12-03 00:22:56,642 INFO     Training average loss at step 7900: 0.080351\n",
      "2023-12-03 00:23:02,757 INFO     Training average positive_sample_loss at step 8000: 0.109119\n",
      "2023-12-03 00:23:02,757 INFO     Training average negative_sample_loss at step 8000: 0.051594\n",
      "2023-12-03 00:23:02,757 INFO     Training average loss at step 8000: 0.080356\n",
      "2023-12-03 00:23:08,941 INFO     Training average positive_sample_loss at step 8100: 0.112596\n",
      "2023-12-03 00:23:08,941 INFO     Training average negative_sample_loss at step 8100: 0.051039\n",
      "2023-12-03 00:23:08,941 INFO     Training average loss at step 8100: 0.081817\n",
      "2023-12-03 00:23:15,303 INFO     Training average positive_sample_loss at step 8200: 0.107072\n",
      "2023-12-03 00:23:15,303 INFO     Training average negative_sample_loss at step 8200: 0.050201\n",
      "2023-12-03 00:23:15,304 INFO     Training average loss at step 8200: 0.078637\n",
      "2023-12-03 00:23:21,446 INFO     Training average positive_sample_loss at step 8300: 0.103951\n",
      "2023-12-03 00:23:21,446 INFO     Training average negative_sample_loss at step 8300: 0.049385\n",
      "2023-12-03 00:23:21,446 INFO     Training average loss at step 8300: 0.076668\n",
      "2023-12-03 00:23:27,269 INFO     Training average positive_sample_loss at step 8400: 0.106919\n",
      "2023-12-03 00:23:27,269 INFO     Training average negative_sample_loss at step 8400: 0.048514\n",
      "2023-12-03 00:23:27,269 INFO     Training average loss at step 8400: 0.077717\n",
      "2023-12-03 00:23:33,442 INFO     Training average positive_sample_loss at step 8500: 0.108838\n",
      "2023-12-03 00:23:33,443 INFO     Training average negative_sample_loss at step 8500: 0.047932\n",
      "2023-12-03 00:23:33,443 INFO     Training average loss at step 8500: 0.078385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:23:39,593 INFO     Training average positive_sample_loss at step 8600: 0.098401\n",
      "2023-12-03 00:23:39,594 INFO     Training average negative_sample_loss at step 8600: 0.047207\n",
      "2023-12-03 00:23:39,594 INFO     Training average loss at step 8600: 0.072804\n",
      "2023-12-03 00:23:45,725 INFO     Training average positive_sample_loss at step 8700: 0.102843\n",
      "2023-12-03 00:23:45,725 INFO     Training average negative_sample_loss at step 8700: 0.046409\n",
      "2023-12-03 00:23:45,725 INFO     Training average loss at step 8700: 0.074626\n",
      "2023-12-03 00:23:51,521 INFO     Training average positive_sample_loss at step 8800: 0.104158\n",
      "2023-12-03 00:23:51,522 INFO     Training average negative_sample_loss at step 8800: 0.045726\n",
      "2023-12-03 00:23:51,522 INFO     Training average loss at step 8800: 0.074942\n",
      "2023-12-03 00:23:58,088 INFO     Training average positive_sample_loss at step 8900: 0.098154\n",
      "2023-12-03 00:23:58,088 INFO     Training average negative_sample_loss at step 8900: 0.045137\n",
      "2023-12-03 00:23:58,088 INFO     Training average loss at step 8900: 0.071646\n",
      "2023-12-03 00:24:04,156 INFO     Training average positive_sample_loss at step 9000: 0.097651\n",
      "2023-12-03 00:24:04,156 INFO     Training average negative_sample_loss at step 9000: 0.044392\n",
      "2023-12-03 00:24:04,156 INFO     Training average loss at step 9000: 0.071022\n",
      "2023-12-03 00:24:10,049 INFO     Training average positive_sample_loss at step 9100: 0.101031\n",
      "2023-12-03 00:24:10,050 INFO     Training average negative_sample_loss at step 9100: 0.043895\n",
      "2023-12-03 00:24:10,050 INFO     Training average loss at step 9100: 0.072463\n",
      "2023-12-03 00:24:16,461 INFO     Training average positive_sample_loss at step 9200: 0.099511\n",
      "2023-12-03 00:24:16,462 INFO     Training average negative_sample_loss at step 9200: 0.043317\n",
      "2023-12-03 00:24:16,462 INFO     Training average loss at step 9200: 0.071414\n",
      "2023-12-03 00:24:22,211 INFO     Training average positive_sample_loss at step 9300: 0.093093\n",
      "2023-12-03 00:24:22,211 INFO     Training average negative_sample_loss at step 9300: 0.042715\n",
      "2023-12-03 00:24:22,211 INFO     Training average loss at step 9300: 0.067904\n",
      "2023-12-03 00:24:28,275 INFO     Training average positive_sample_loss at step 9400: 0.096536\n",
      "2023-12-03 00:24:28,275 INFO     Training average negative_sample_loss at step 9400: 0.041946\n",
      "2023-12-03 00:24:28,275 INFO     Training average loss at step 9400: 0.069241\n",
      "2023-12-03 00:24:34,351 INFO     Training average positive_sample_loss at step 9500: 0.098673\n",
      "2023-12-03 00:24:34,351 INFO     Training average negative_sample_loss at step 9500: 0.041736\n",
      "2023-12-03 00:24:34,351 INFO     Training average loss at step 9500: 0.070204\n",
      "2023-12-03 00:24:40,888 INFO     Training average positive_sample_loss at step 9600: 0.090404\n",
      "2023-12-03 00:24:40,889 INFO     Training average negative_sample_loss at step 9600: 0.041151\n",
      "2023-12-03 00:24:40,889 INFO     Training average loss at step 9600: 0.065777\n",
      "2023-12-03 00:24:46,621 INFO     Training average positive_sample_loss at step 9700: 0.092709\n",
      "2023-12-03 00:24:46,621 INFO     Training average negative_sample_loss at step 9700: 0.040521\n",
      "2023-12-03 00:24:46,621 INFO     Training average loss at step 9700: 0.066615\n",
      "2023-12-03 00:24:52,352 INFO     Training average positive_sample_loss at step 9800: 0.095428\n",
      "2023-12-03 00:24:52,352 INFO     Training average negative_sample_loss at step 9800: 0.040040\n",
      "2023-12-03 00:24:52,352 INFO     Training average loss at step 9800: 0.067734\n",
      "2023-12-03 00:24:58,909 INFO     Training average positive_sample_loss at step 9900: 0.091871\n",
      "2023-12-03 00:24:58,909 INFO     Training average negative_sample_loss at step 9900: 0.039829\n",
      "2023-12-03 00:24:58,909 INFO     Training average loss at step 9900: 0.065850\n",
      "2023-12-03 00:25:13,145 INFO     Training average positive_sample_loss at step 10000: 0.089036\n",
      "2023-12-03 00:25:13,145 INFO     Training average negative_sample_loss at step 10000: 0.039181\n",
      "2023-12-03 00:25:13,145 INFO     Training average loss at step 10000: 0.064109\n",
      "2023-12-03 00:25:13,145 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:25:13,691 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:25:43,345 INFO     Valid MRR at step 10000: 0.455253\n",
      "2023-12-03 00:25:43,345 INFO     Valid MR at step 10000: 6230.521918\n",
      "2023-12-03 00:25:43,345 INFO     Valid HITS@1 at step 10000: 0.429960\n",
      "2023-12-03 00:25:43,345 INFO     Valid HITS@3 at step 10000: 0.465887\n",
      "2023-12-03 00:25:43,345 INFO     Valid HITS@10 at step 10000: 0.499670\n",
      "2023-12-03 00:25:49,166 INFO     Training average positive_sample_loss at step 10100: 0.091720\n",
      "2023-12-03 00:25:49,166 INFO     Training average negative_sample_loss at step 10100: 0.038643\n",
      "2023-12-03 00:25:49,166 INFO     Training average loss at step 10100: 0.065182\n",
      "2023-12-03 00:25:55,467 INFO     Training average positive_sample_loss at step 10200: 0.092766\n",
      "2023-12-03 00:25:55,468 INFO     Training average negative_sample_loss at step 10200: 0.038282\n",
      "2023-12-03 00:25:55,468 INFO     Training average loss at step 10200: 0.065524\n",
      "2023-12-03 00:26:01,789 INFO     Training average positive_sample_loss at step 10300: 0.084489\n",
      "2023-12-03 00:26:01,789 INFO     Training average negative_sample_loss at step 10300: 0.037902\n",
      "2023-12-03 00:26:01,789 INFO     Training average loss at step 10300: 0.061195\n",
      "2023-12-03 00:26:07,586 INFO     Training average positive_sample_loss at step 10400: 0.088113\n",
      "2023-12-03 00:26:07,587 INFO     Training average negative_sample_loss at step 10400: 0.037147\n",
      "2023-12-03 00:26:07,587 INFO     Training average loss at step 10400: 0.062630\n",
      "2023-12-03 00:26:13,563 INFO     Training average positive_sample_loss at step 10500: 0.090345\n",
      "2023-12-03 00:26:13,563 INFO     Training average negative_sample_loss at step 10500: 0.037014\n",
      "2023-12-03 00:26:13,563 INFO     Training average loss at step 10500: 0.063679\n",
      "2023-12-03 00:26:20,147 INFO     Training average positive_sample_loss at step 10600: 0.085602\n",
      "2023-12-03 00:26:20,147 INFO     Training average negative_sample_loss at step 10600: 0.036869\n",
      "2023-12-03 00:26:20,147 INFO     Training average loss at step 10600: 0.061235\n",
      "2023-12-03 00:26:25,949 INFO     Training average positive_sample_loss at step 10700: 0.084886\n",
      "2023-12-03 00:26:25,949 INFO     Training average negative_sample_loss at step 10700: 0.036084\n",
      "2023-12-03 00:26:25,949 INFO     Training average loss at step 10700: 0.060485\n",
      "2023-12-03 00:26:32,020 INFO     Training average positive_sample_loss at step 10800: 0.087518\n",
      "2023-12-03 00:26:32,020 INFO     Training average negative_sample_loss at step 10800: 0.035863\n",
      "2023-12-03 00:26:32,020 INFO     Training average loss at step 10800: 0.061690\n",
      "2023-12-03 00:26:38,601 INFO     Training average positive_sample_loss at step 10900: 0.086832\n",
      "2023-12-03 00:26:38,602 INFO     Training average negative_sample_loss at step 10900: 0.035705\n",
      "2023-12-03 00:26:38,602 INFO     Training average loss at step 10900: 0.061269\n",
      "2023-12-03 00:26:44,064 INFO     Training average positive_sample_loss at step 11000: 0.081320\n",
      "2023-12-03 00:26:44,064 INFO     Training average negative_sample_loss at step 11000: 0.035207\n",
      "2023-12-03 00:26:44,064 INFO     Training average loss at step 11000: 0.058264\n",
      "2023-12-03 00:26:49,546 INFO     Training average positive_sample_loss at step 11100: 0.084631\n",
      "2023-12-03 00:26:49,546 INFO     Training average negative_sample_loss at step 11100: 0.034791\n",
      "2023-12-03 00:26:49,546 INFO     Training average loss at step 11100: 0.059711\n",
      "2023-12-03 00:26:55,660 INFO     Training average positive_sample_loss at step 11200: 0.086178\n",
      "2023-12-03 00:26:55,660 INFO     Training average negative_sample_loss at step 11200: 0.034544\n",
      "2023-12-03 00:26:55,660 INFO     Training average loss at step 11200: 0.060361\n",
      "2023-12-03 00:27:01,621 INFO     Training average positive_sample_loss at step 11300: 0.080150\n",
      "2023-12-03 00:27:01,621 INFO     Training average negative_sample_loss at step 11300: 0.034342\n",
      "2023-12-03 00:27:01,621 INFO     Training average loss at step 11300: 0.057246\n",
      "2023-12-03 00:27:07,682 INFO     Training average positive_sample_loss at step 11400: 0.081549\n",
      "2023-12-03 00:27:07,682 INFO     Training average negative_sample_loss at step 11400: 0.033789\n",
      "2023-12-03 00:27:07,682 INFO     Training average loss at step 11400: 0.057669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:27:13,744 INFO     Training average positive_sample_loss at step 11500: 0.083771\n",
      "2023-12-03 00:27:13,745 INFO     Training average negative_sample_loss at step 11500: 0.033485\n",
      "2023-12-03 00:27:13,745 INFO     Training average loss at step 11500: 0.058628\n",
      "2023-12-03 00:27:19,907 INFO     Training average positive_sample_loss at step 11600: 0.080743\n",
      "2023-12-03 00:27:19,907 INFO     Training average negative_sample_loss at step 11600: 0.033406\n",
      "2023-12-03 00:27:19,907 INFO     Training average loss at step 11600: 0.057074\n",
      "2023-12-03 00:27:25,956 INFO     Training average positive_sample_loss at step 11700: 0.078370\n",
      "2023-12-03 00:27:25,956 INFO     Training average negative_sample_loss at step 11700: 0.032898\n",
      "2023-12-03 00:27:25,956 INFO     Training average loss at step 11700: 0.055634\n",
      "2023-12-03 00:27:31,471 INFO     Training average positive_sample_loss at step 11800: 0.081586\n",
      "2023-12-03 00:27:31,471 INFO     Training average negative_sample_loss at step 11800: 0.032720\n",
      "2023-12-03 00:27:31,471 INFO     Training average loss at step 11800: 0.057153\n",
      "2023-12-03 00:27:37,618 INFO     Training average positive_sample_loss at step 11900: 0.082669\n",
      "2023-12-03 00:27:37,619 INFO     Training average negative_sample_loss at step 11900: 0.032654\n",
      "2023-12-03 00:27:37,619 INFO     Training average loss at step 11900: 0.057661\n",
      "2023-12-03 00:27:43,961 INFO     Training average positive_sample_loss at step 12000: 0.075565\n",
      "2023-12-03 00:27:43,961 INFO     Training average negative_sample_loss at step 12000: 0.032228\n",
      "2023-12-03 00:27:43,961 INFO     Training average loss at step 12000: 0.053897\n",
      "2023-12-03 00:27:50,051 INFO     Training average positive_sample_loss at step 12100: 0.079069\n",
      "2023-12-03 00:27:50,052 INFO     Training average negative_sample_loss at step 12100: 0.031901\n",
      "2023-12-03 00:27:50,052 INFO     Training average loss at step 12100: 0.055485\n",
      "2023-12-03 00:27:56,125 INFO     Training average positive_sample_loss at step 12200: 0.080181\n",
      "2023-12-03 00:27:56,126 INFO     Training average negative_sample_loss at step 12200: 0.031609\n",
      "2023-12-03 00:27:56,126 INFO     Training average loss at step 12200: 0.055895\n",
      "2023-12-03 00:28:02,251 INFO     Training average positive_sample_loss at step 12300: 0.076111\n",
      "2023-12-03 00:28:02,251 INFO     Training average negative_sample_loss at step 12300: 0.031517\n",
      "2023-12-03 00:28:02,251 INFO     Training average loss at step 12300: 0.053814\n",
      "2023-12-03 00:28:08,298 INFO     Training average positive_sample_loss at step 12400: 0.076165\n",
      "2023-12-03 00:28:08,298 INFO     Training average negative_sample_loss at step 12400: 0.031113\n",
      "2023-12-03 00:28:08,298 INFO     Training average loss at step 12400: 0.053639\n",
      "2023-12-03 00:28:14,213 INFO     Training average positive_sample_loss at step 12500: 0.078490\n",
      "2023-12-03 00:28:14,213 INFO     Training average negative_sample_loss at step 12500: 0.030832\n",
      "2023-12-03 00:28:14,214 INFO     Training average loss at step 12500: 0.054661\n",
      "2023-12-03 00:28:20,752 INFO     Training average positive_sample_loss at step 12600: 0.077836\n",
      "2023-12-03 00:28:20,753 INFO     Training average negative_sample_loss at step 12600: 0.030821\n",
      "2023-12-03 00:28:20,753 INFO     Training average loss at step 12600: 0.054328\n",
      "2023-12-03 00:28:26,839 INFO     Training average positive_sample_loss at step 12700: 0.073022\n",
      "2023-12-03 00:28:26,840 INFO     Training average negative_sample_loss at step 12700: 0.030453\n",
      "2023-12-03 00:28:26,840 INFO     Training average loss at step 12700: 0.051737\n",
      "2023-12-03 00:28:32,389 INFO     Training average positive_sample_loss at step 12800: 0.076184\n",
      "2023-12-03 00:28:32,390 INFO     Training average negative_sample_loss at step 12800: 0.030107\n",
      "2023-12-03 00:28:32,390 INFO     Training average loss at step 12800: 0.053146\n",
      "2023-12-03 00:28:38,476 INFO     Training average positive_sample_loss at step 12900: 0.077837\n",
      "2023-12-03 00:28:38,477 INFO     Training average negative_sample_loss at step 12900: 0.030124\n",
      "2023-12-03 00:28:38,477 INFO     Training average loss at step 12900: 0.053981\n",
      "2023-12-03 00:28:45,126 INFO     Training average positive_sample_loss at step 13000: 0.072232\n",
      "2023-12-03 00:28:45,126 INFO     Training average negative_sample_loss at step 13000: 0.029869\n",
      "2023-12-03 00:28:45,126 INFO     Training average loss at step 13000: 0.051050\n",
      "2023-12-03 00:28:51,087 INFO     Training average positive_sample_loss at step 13100: 0.074094\n",
      "2023-12-03 00:28:51,087 INFO     Training average negative_sample_loss at step 13100: 0.029638\n",
      "2023-12-03 00:28:51,087 INFO     Training average loss at step 13100: 0.051866\n",
      "2023-12-03 00:28:57,252 INFO     Training average positive_sample_loss at step 13200: 0.075886\n",
      "2023-12-03 00:28:57,252 INFO     Training average negative_sample_loss at step 13200: 0.029422\n",
      "2023-12-03 00:28:57,252 INFO     Training average loss at step 13200: 0.052654\n",
      "2023-12-03 00:29:03,895 INFO     Training average positive_sample_loss at step 13300: 0.073277\n",
      "2023-12-03 00:29:03,895 INFO     Training average negative_sample_loss at step 13300: 0.029260\n",
      "2023-12-03 00:29:03,895 INFO     Training average loss at step 13300: 0.051269\n",
      "2023-12-03 00:29:09,422 INFO     Training average positive_sample_loss at step 13400: 0.070862\n",
      "2023-12-03 00:29:09,423 INFO     Training average negative_sample_loss at step 13400: 0.028819\n",
      "2023-12-03 00:29:09,423 INFO     Training average loss at step 13400: 0.049840\n",
      "2023-12-03 00:29:15,484 INFO     Training average positive_sample_loss at step 13500: 0.074324\n",
      "2023-12-03 00:29:15,484 INFO     Training average negative_sample_loss at step 13500: 0.028831\n",
      "2023-12-03 00:29:15,484 INFO     Training average loss at step 13500: 0.051577\n",
      "2023-12-03 00:29:21,802 INFO     Training average positive_sample_loss at step 13600: 0.075535\n",
      "2023-12-03 00:29:21,802 INFO     Training average negative_sample_loss at step 13600: 0.028816\n",
      "2023-12-03 00:29:21,802 INFO     Training average loss at step 13600: 0.052176\n",
      "2023-12-03 00:29:28,076 INFO     Training average positive_sample_loss at step 13700: 0.068796\n",
      "2023-12-03 00:29:28,077 INFO     Training average negative_sample_loss at step 13700: 0.028494\n",
      "2023-12-03 00:29:28,077 INFO     Training average loss at step 13700: 0.048645\n",
      "2023-12-03 00:29:33,893 INFO     Training average positive_sample_loss at step 13800: 0.072213\n",
      "2023-12-03 00:29:33,893 INFO     Training average negative_sample_loss at step 13800: 0.028220\n",
      "2023-12-03 00:29:33,893 INFO     Training average loss at step 13800: 0.050217\n",
      "2023-12-03 00:29:39,714 INFO     Training average positive_sample_loss at step 13900: 0.073172\n",
      "2023-12-03 00:29:39,715 INFO     Training average negative_sample_loss at step 13900: 0.028110\n",
      "2023-12-03 00:29:39,715 INFO     Training average loss at step 13900: 0.050641\n",
      "2023-12-03 00:29:46,159 INFO     Training average positive_sample_loss at step 14000: 0.070036\n",
      "2023-12-03 00:29:46,159 INFO     Training average negative_sample_loss at step 14000: 0.028088\n",
      "2023-12-03 00:29:46,159 INFO     Training average loss at step 14000: 0.049062\n",
      "2023-12-03 00:29:52,284 INFO     Training average positive_sample_loss at step 14100: 0.069898\n",
      "2023-12-03 00:29:52,284 INFO     Training average negative_sample_loss at step 14100: 0.027754\n",
      "2023-12-03 00:29:52,284 INFO     Training average loss at step 14100: 0.048826\n",
      "2023-12-03 00:29:58,457 INFO     Training average positive_sample_loss at step 14200: 0.071987\n",
      "2023-12-03 00:29:58,457 INFO     Training average negative_sample_loss at step 14200: 0.027561\n",
      "2023-12-03 00:29:58,457 INFO     Training average loss at step 14200: 0.049774\n",
      "2023-12-03 00:30:04,729 INFO     Training average positive_sample_loss at step 14300: 0.071127\n",
      "2023-12-03 00:30:04,729 INFO     Training average negative_sample_loss at step 14300: 0.027583\n",
      "2023-12-03 00:30:04,729 INFO     Training average loss at step 14300: 0.049355\n",
      "2023-12-03 00:30:10,579 INFO     Training average positive_sample_loss at step 14400: 0.067438\n",
      "2023-12-03 00:30:10,579 INFO     Training average negative_sample_loss at step 14400: 0.027315\n",
      "2023-12-03 00:30:10,579 INFO     Training average loss at step 14400: 0.047377\n",
      "2023-12-03 00:30:16,645 INFO     Training average positive_sample_loss at step 14500: 0.069982\n",
      "2023-12-03 00:30:16,645 INFO     Training average negative_sample_loss at step 14500: 0.027067\n",
      "2023-12-03 00:30:16,645 INFO     Training average loss at step 14500: 0.048525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:30:22,696 INFO     Training average positive_sample_loss at step 14600: 0.072010\n",
      "2023-12-03 00:30:22,696 INFO     Training average negative_sample_loss at step 14600: 0.027004\n",
      "2023-12-03 00:30:22,696 INFO     Training average loss at step 14600: 0.049507\n",
      "2023-12-03 00:30:29,257 INFO     Training average positive_sample_loss at step 14700: 0.066392\n",
      "2023-12-03 00:30:29,258 INFO     Training average negative_sample_loss at step 14700: 0.026894\n",
      "2023-12-03 00:30:29,258 INFO     Training average loss at step 14700: 0.046643\n",
      "2023-12-03 00:30:35,424 INFO     Training average positive_sample_loss at step 14800: 0.068480\n",
      "2023-12-03 00:30:35,424 INFO     Training average negative_sample_loss at step 14800: 0.026684\n",
      "2023-12-03 00:30:35,424 INFO     Training average loss at step 14800: 0.047582\n",
      "2023-12-03 00:30:41,149 INFO     Training average positive_sample_loss at step 14900: 0.070070\n",
      "2023-12-03 00:30:41,149 INFO     Training average negative_sample_loss at step 14900: 0.026608\n",
      "2023-12-03 00:30:41,149 INFO     Training average loss at step 14900: 0.048339\n",
      "2023-12-03 00:30:47,638 INFO     Training average positive_sample_loss at step 15000: 0.067887\n",
      "2023-12-03 00:30:47,638 INFO     Training average negative_sample_loss at step 15000: 0.026515\n",
      "2023-12-03 00:30:47,638 INFO     Training average loss at step 15000: 0.047201\n",
      "2023-12-03 00:30:53,694 INFO     Training average positive_sample_loss at step 15100: 0.066457\n",
      "2023-12-03 00:30:53,695 INFO     Training average negative_sample_loss at step 15100: 0.026338\n",
      "2023-12-03 00:30:53,695 INFO     Training average loss at step 15100: 0.046397\n",
      "2023-12-03 00:30:59,860 INFO     Training average positive_sample_loss at step 15200: 0.068413\n",
      "2023-12-03 00:30:59,861 INFO     Training average negative_sample_loss at step 15200: 0.026105\n",
      "2023-12-03 00:30:59,861 INFO     Training average loss at step 15200: 0.047259\n",
      "2023-12-03 00:31:06,242 INFO     Training average positive_sample_loss at step 15300: 0.069647\n",
      "2023-12-03 00:31:06,242 INFO     Training average negative_sample_loss at step 15300: 0.026226\n",
      "2023-12-03 00:31:06,242 INFO     Training average loss at step 15300: 0.047936\n",
      "2023-12-03 00:31:12,701 INFO     Training average positive_sample_loss at step 15400: 0.064113\n",
      "2023-12-03 00:31:12,701 INFO     Training average negative_sample_loss at step 15400: 0.025986\n",
      "2023-12-03 00:31:12,702 INFO     Training average loss at step 15400: 0.045050\n",
      "2023-12-03 00:31:18,576 INFO     Training average positive_sample_loss at step 15500: 0.066926\n",
      "2023-12-03 00:31:18,576 INFO     Training average negative_sample_loss at step 15500: 0.025647\n",
      "2023-12-03 00:31:18,577 INFO     Training average loss at step 15500: 0.046286\n",
      "2023-12-03 00:31:24,678 INFO     Training average positive_sample_loss at step 15600: 0.068412\n",
      "2023-12-03 00:31:24,678 INFO     Training average negative_sample_loss at step 15600: 0.025651\n",
      "2023-12-03 00:31:24,678 INFO     Training average loss at step 15600: 0.047031\n",
      "2023-12-03 00:31:31,198 INFO     Training average positive_sample_loss at step 15700: 0.064661\n",
      "2023-12-03 00:31:31,198 INFO     Training average negative_sample_loss at step 15700: 0.025659\n",
      "2023-12-03 00:31:31,198 INFO     Training average loss at step 15700: 0.045160\n",
      "2023-12-03 00:31:37,241 INFO     Training average positive_sample_loss at step 15800: 0.065011\n",
      "2023-12-03 00:31:37,242 INFO     Training average negative_sample_loss at step 15800: 0.025359\n",
      "2023-12-03 00:31:37,242 INFO     Training average loss at step 15800: 0.045185\n",
      "2023-12-03 00:31:43,350 INFO     Training average positive_sample_loss at step 15900: 0.067144\n",
      "2023-12-03 00:31:43,350 INFO     Training average negative_sample_loss at step 15900: 0.025361\n",
      "2023-12-03 00:31:43,350 INFO     Training average loss at step 15900: 0.046253\n",
      "2023-12-03 00:31:49,775 INFO     Training average positive_sample_loss at step 16000: 0.066674\n",
      "2023-12-03 00:31:49,775 INFO     Training average negative_sample_loss at step 16000: 0.025278\n",
      "2023-12-03 00:31:49,775 INFO     Training average loss at step 16000: 0.045976\n",
      "2023-12-03 00:31:55,503 INFO     Training average positive_sample_loss at step 16100: 0.062833\n",
      "2023-12-03 00:31:55,504 INFO     Training average negative_sample_loss at step 16100: 0.025066\n",
      "2023-12-03 00:31:55,504 INFO     Training average loss at step 16100: 0.043949\n",
      "2023-12-03 00:32:01,608 INFO     Training average positive_sample_loss at step 16200: 0.065907\n",
      "2023-12-03 00:32:01,608 INFO     Training average negative_sample_loss at step 16200: 0.024964\n",
      "2023-12-03 00:32:01,608 INFO     Training average loss at step 16200: 0.045435\n",
      "2023-12-03 00:32:07,708 INFO     Training average positive_sample_loss at step 16300: 0.066818\n",
      "2023-12-03 00:32:07,708 INFO     Training average negative_sample_loss at step 16300: 0.024894\n",
      "2023-12-03 00:32:07,708 INFO     Training average loss at step 16300: 0.045856\n",
      "2023-12-03 00:32:14,019 INFO     Training average positive_sample_loss at step 16400: 0.062546\n",
      "2023-12-03 00:32:14,020 INFO     Training average negative_sample_loss at step 16400: 0.024857\n",
      "2023-12-03 00:32:14,020 INFO     Training average loss at step 16400: 0.043701\n",
      "2023-12-03 00:32:20,128 INFO     Training average positive_sample_loss at step 16500: 0.063896\n",
      "2023-12-03 00:32:20,128 INFO     Training average negative_sample_loss at step 16500: 0.024597\n",
      "2023-12-03 00:32:20,128 INFO     Training average loss at step 16500: 0.044247\n",
      "2023-12-03 00:32:25,788 INFO     Training average positive_sample_loss at step 16600: 0.065736\n",
      "2023-12-03 00:32:25,788 INFO     Training average negative_sample_loss at step 16600: 0.024505\n",
      "2023-12-03 00:32:25,788 INFO     Training average loss at step 16600: 0.045121\n",
      "2023-12-03 00:32:32,149 INFO     Training average positive_sample_loss at step 16700: 0.063953\n",
      "2023-12-03 00:32:32,149 INFO     Training average negative_sample_loss at step 16700: 0.024596\n",
      "2023-12-03 00:32:32,149 INFO     Training average loss at step 16700: 0.044274\n",
      "2023-12-03 00:32:38,246 INFO     Training average positive_sample_loss at step 16800: 0.062197\n",
      "2023-12-03 00:32:38,247 INFO     Training average negative_sample_loss at step 16800: 0.024284\n",
      "2023-12-03 00:32:38,247 INFO     Training average loss at step 16800: 0.043241\n",
      "2023-12-03 00:32:44,340 INFO     Training average positive_sample_loss at step 16900: 0.064447\n",
      "2023-12-03 00:32:44,341 INFO     Training average negative_sample_loss at step 16900: 0.024267\n",
      "2023-12-03 00:32:44,341 INFO     Training average loss at step 16900: 0.044357\n",
      "2023-12-03 00:32:50,365 INFO     Training average positive_sample_loss at step 17000: 0.065429\n",
      "2023-12-03 00:32:50,365 INFO     Training average negative_sample_loss at step 17000: 0.024192\n",
      "2023-12-03 00:32:50,366 INFO     Training average loss at step 17000: 0.044811\n",
      "2023-12-03 00:32:56,738 INFO     Training average positive_sample_loss at step 17100: 0.060106\n",
      "2023-12-03 00:32:56,739 INFO     Training average negative_sample_loss at step 17100: 0.024094\n",
      "2023-12-03 00:32:56,739 INFO     Training average loss at step 17100: 0.042100\n",
      "2023-12-03 00:33:02,407 INFO     Training average positive_sample_loss at step 17200: 0.063321\n",
      "2023-12-03 00:33:02,407 INFO     Training average negative_sample_loss at step 17200: 0.023934\n",
      "2023-12-03 00:33:02,407 INFO     Training average loss at step 17200: 0.043628\n",
      "2023-12-03 00:33:08,485 INFO     Training average positive_sample_loss at step 17300: 0.064337\n",
      "2023-12-03 00:33:08,485 INFO     Training average negative_sample_loss at step 17300: 0.023925\n",
      "2023-12-03 00:33:08,486 INFO     Training average loss at step 17300: 0.044131\n",
      "2023-12-03 00:33:15,002 INFO     Training average positive_sample_loss at step 17400: 0.061403\n",
      "2023-12-03 00:33:15,003 INFO     Training average negative_sample_loss at step 17400: 0.023917\n",
      "2023-12-03 00:33:15,003 INFO     Training average loss at step 17400: 0.042660\n",
      "2023-12-03 00:33:20,954 INFO     Training average positive_sample_loss at step 17500: 0.061176\n",
      "2023-12-03 00:33:20,955 INFO     Training average negative_sample_loss at step 17500: 0.023529\n",
      "2023-12-03 00:33:20,955 INFO     Training average loss at step 17500: 0.042353\n",
      "2023-12-03 00:33:26,926 INFO     Training average positive_sample_loss at step 17600: 0.063203\n",
      "2023-12-03 00:33:26,926 INFO     Training average negative_sample_loss at step 17600: 0.023593\n",
      "2023-12-03 00:33:26,926 INFO     Training average loss at step 17600: 0.043398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:33:33,513 INFO     Training average positive_sample_loss at step 17700: 0.063157\n",
      "2023-12-03 00:33:33,514 INFO     Training average negative_sample_loss at step 17700: 0.023712\n",
      "2023-12-03 00:33:33,514 INFO     Training average loss at step 17700: 0.043434\n",
      "2023-12-03 00:33:39,196 INFO     Training average positive_sample_loss at step 17800: 0.059665\n",
      "2023-12-03 00:33:39,196 INFO     Training average negative_sample_loss at step 17800: 0.023408\n",
      "2023-12-03 00:33:39,196 INFO     Training average loss at step 17800: 0.041536\n",
      "2023-12-03 00:33:45,260 INFO     Training average positive_sample_loss at step 17900: 0.061966\n",
      "2023-12-03 00:33:45,260 INFO     Training average negative_sample_loss at step 17900: 0.023363\n",
      "2023-12-03 00:33:45,260 INFO     Training average loss at step 17900: 0.042665\n",
      "2023-12-03 00:33:51,341 INFO     Training average positive_sample_loss at step 18000: 0.063332\n",
      "2023-12-03 00:33:51,341 INFO     Training average negative_sample_loss at step 18000: 0.023392\n",
      "2023-12-03 00:33:51,341 INFO     Training average loss at step 18000: 0.043362\n",
      "2023-12-03 00:33:57,692 INFO     Training average positive_sample_loss at step 18100: 0.059031\n",
      "2023-12-03 00:33:57,693 INFO     Training average negative_sample_loss at step 18100: 0.023219\n",
      "2023-12-03 00:33:57,693 INFO     Training average loss at step 18100: 0.041125\n",
      "2023-12-03 00:34:03,616 INFO     Training average positive_sample_loss at step 18200: 0.060435\n",
      "2023-12-03 00:34:03,616 INFO     Training average negative_sample_loss at step 18200: 0.023048\n",
      "2023-12-03 00:34:03,616 INFO     Training average loss at step 18200: 0.041741\n",
      "2023-12-03 00:34:09,671 INFO     Training average positive_sample_loss at step 18300: 0.062578\n",
      "2023-12-03 00:34:09,672 INFO     Training average negative_sample_loss at step 18300: 0.022948\n",
      "2023-12-03 00:34:09,672 INFO     Training average loss at step 18300: 0.042763\n",
      "2023-12-03 00:34:15,934 INFO     Training average positive_sample_loss at step 18400: 0.060577\n",
      "2023-12-03 00:34:15,934 INFO     Training average negative_sample_loss at step 18400: 0.023029\n",
      "2023-12-03 00:34:15,934 INFO     Training average loss at step 18400: 0.041803\n",
      "2023-12-03 00:34:22,113 INFO     Training average positive_sample_loss at step 18500: 0.059040\n",
      "2023-12-03 00:34:22,113 INFO     Training average negative_sample_loss at step 18500: 0.022859\n",
      "2023-12-03 00:34:22,113 INFO     Training average loss at step 18500: 0.040949\n",
      "2023-12-03 00:34:28,224 INFO     Training average positive_sample_loss at step 18600: 0.061326\n",
      "2023-12-03 00:34:28,224 INFO     Training average negative_sample_loss at step 18600: 0.022810\n",
      "2023-12-03 00:34:28,224 INFO     Training average loss at step 18600: 0.042068\n",
      "2023-12-03 00:34:34,358 INFO     Training average positive_sample_loss at step 18700: 0.062080\n",
      "2023-12-03 00:34:34,359 INFO     Training average negative_sample_loss at step 18700: 0.022818\n",
      "2023-12-03 00:34:34,359 INFO     Training average loss at step 18700: 0.042449\n",
      "2023-12-03 00:34:40,676 INFO     Training average positive_sample_loss at step 18800: 0.057197\n",
      "2023-12-03 00:34:40,676 INFO     Training average negative_sample_loss at step 18800: 0.022722\n",
      "2023-12-03 00:34:40,676 INFO     Training average loss at step 18800: 0.039960\n",
      "2023-12-03 00:34:46,678 INFO     Training average positive_sample_loss at step 18900: 0.059913\n",
      "2023-12-03 00:34:46,678 INFO     Training average negative_sample_loss at step 18900: 0.022662\n",
      "2023-12-03 00:34:46,678 INFO     Training average loss at step 18900: 0.041287\n",
      "2023-12-03 00:34:52,361 INFO     Training average positive_sample_loss at step 19000: 0.061476\n",
      "2023-12-03 00:34:52,361 INFO     Training average negative_sample_loss at step 19000: 0.022559\n",
      "2023-12-03 00:34:52,361 INFO     Training average loss at step 19000: 0.042018\n",
      "2023-12-03 00:34:58,946 INFO     Training average positive_sample_loss at step 19100: 0.058436\n",
      "2023-12-03 00:34:58,946 INFO     Training average negative_sample_loss at step 19100: 0.022409\n",
      "2023-12-03 00:34:58,946 INFO     Training average loss at step 19100: 0.040422\n",
      "2023-12-03 00:35:04,823 INFO     Training average positive_sample_loss at step 19200: 0.058353\n",
      "2023-12-03 00:35:04,824 INFO     Training average negative_sample_loss at step 19200: 0.022357\n",
      "2023-12-03 00:35:04,824 INFO     Training average loss at step 19200: 0.040355\n",
      "2023-12-03 00:35:10,900 INFO     Training average positive_sample_loss at step 19300: 0.060286\n",
      "2023-12-03 00:35:10,900 INFO     Training average negative_sample_loss at step 19300: 0.022426\n",
      "2023-12-03 00:35:10,900 INFO     Training average loss at step 19300: 0.041356\n",
      "2023-12-03 00:35:17,436 INFO     Training average positive_sample_loss at step 19400: 0.059944\n",
      "2023-12-03 00:35:17,436 INFO     Training average negative_sample_loss at step 19400: 0.022312\n",
      "2023-12-03 00:35:17,436 INFO     Training average loss at step 19400: 0.041128\n",
      "2023-12-03 00:35:23,471 INFO     Training average positive_sample_loss at step 19500: 0.056906\n",
      "2023-12-03 00:35:23,471 INFO     Training average negative_sample_loss at step 19500: 0.022271\n",
      "2023-12-03 00:35:23,471 INFO     Training average loss at step 19500: 0.039589\n",
      "2023-12-03 00:35:29,143 INFO     Training average positive_sample_loss at step 19600: 0.059389\n",
      "2023-12-03 00:35:29,143 INFO     Training average negative_sample_loss at step 19600: 0.022107\n",
      "2023-12-03 00:35:29,144 INFO     Training average loss at step 19600: 0.040748\n",
      "2023-12-03 00:35:35,071 INFO     Training average positive_sample_loss at step 19700: 0.060649\n",
      "2023-12-03 00:35:35,071 INFO     Training average negative_sample_loss at step 19700: 0.022149\n",
      "2023-12-03 00:35:35,071 INFO     Training average loss at step 19700: 0.041399\n",
      "2023-12-03 00:35:41,674 INFO     Training average positive_sample_loss at step 19800: 0.056688\n",
      "2023-12-03 00:35:41,674 INFO     Training average negative_sample_loss at step 19800: 0.022137\n",
      "2023-12-03 00:35:41,674 INFO     Training average loss at step 19800: 0.039412\n",
      "2023-12-03 00:35:47,776 INFO     Training average positive_sample_loss at step 19900: 0.057843\n",
      "2023-12-03 00:35:47,776 INFO     Training average negative_sample_loss at step 19900: 0.021947\n",
      "2023-12-03 00:35:47,776 INFO     Training average loss at step 19900: 0.039895\n",
      "2023-12-03 00:36:03,893 INFO     Training average positive_sample_loss at step 20000: 0.059519\n",
      "2023-12-03 00:36:03,893 INFO     Training average negative_sample_loss at step 20000: 0.021863\n",
      "2023-12-03 00:36:03,894 INFO     Training average loss at step 20000: 0.040691\n",
      "2023-12-03 00:36:03,894 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:36:04,446 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:36:33,734 INFO     Valid MRR at step 20000: 0.481485\n",
      "2023-12-03 00:36:33,735 INFO     Valid MR at step 20000: 4405.410349\n",
      "2023-12-03 00:36:33,735 INFO     Valid HITS@1 at step 20000: 0.444133\n",
      "2023-12-03 00:36:33,735 INFO     Valid HITS@3 at step 20000: 0.493408\n",
      "2023-12-03 00:36:33,735 INFO     Valid HITS@10 at step 20000: 0.554219\n",
      "2023-12-03 00:36:40,495 INFO     Training average positive_sample_loss at step 20100: 0.057468\n",
      "2023-12-03 00:36:40,496 INFO     Training average negative_sample_loss at step 20100: 0.021979\n",
      "2023-12-03 00:36:40,496 INFO     Training average loss at step 20100: 0.039723\n",
      "2023-12-03 00:36:46,278 INFO     Training average positive_sample_loss at step 20200: 0.056508\n",
      "2023-12-03 00:36:46,278 INFO     Training average negative_sample_loss at step 20200: 0.021834\n",
      "2023-12-03 00:36:46,278 INFO     Training average loss at step 20200: 0.039171\n",
      "2023-12-03 00:36:52,442 INFO     Training average positive_sample_loss at step 20300: 0.058844\n",
      "2023-12-03 00:36:52,442 INFO     Training average negative_sample_loss at step 20300: 0.021704\n",
      "2023-12-03 00:36:52,443 INFO     Training average loss at step 20300: 0.040274\n",
      "2023-12-03 00:36:58,918 INFO     Training average positive_sample_loss at step 20400: 0.059547\n",
      "2023-12-03 00:36:58,919 INFO     Training average negative_sample_loss at step 20400: 0.021750\n",
      "2023-12-03 00:36:58,919 INFO     Training average loss at step 20400: 0.040649\n",
      "2023-12-03 00:37:05,211 INFO     Training average positive_sample_loss at step 20500: 0.054614\n",
      "2023-12-03 00:37:05,212 INFO     Training average negative_sample_loss at step 20500: 0.021513\n",
      "2023-12-03 00:37:05,212 INFO     Training average loss at step 20500: 0.038064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:37:11,480 INFO     Training average positive_sample_loss at step 20600: 0.057718\n",
      "2023-12-03 00:37:11,480 INFO     Training average negative_sample_loss at step 20600: 0.021545\n",
      "2023-12-03 00:37:11,480 INFO     Training average loss at step 20600: 0.039631\n",
      "2023-12-03 00:37:17,404 INFO     Training average positive_sample_loss at step 20700: 0.059053\n",
      "2023-12-03 00:37:17,404 INFO     Training average negative_sample_loss at step 20700: 0.021558\n",
      "2023-12-03 00:37:17,404 INFO     Training average loss at step 20700: 0.040306\n",
      "2023-12-03 00:37:23,974 INFO     Training average positive_sample_loss at step 20800: 0.055871\n",
      "2023-12-03 00:37:23,975 INFO     Training average negative_sample_loss at step 20800: 0.021547\n",
      "2023-12-03 00:37:23,975 INFO     Training average loss at step 20800: 0.038709\n",
      "2023-12-03 00:37:29,994 INFO     Training average positive_sample_loss at step 20900: 0.056221\n",
      "2023-12-03 00:37:29,994 INFO     Training average negative_sample_loss at step 20900: 0.021430\n",
      "2023-12-03 00:37:29,994 INFO     Training average loss at step 20900: 0.038826\n",
      "2023-12-03 00:37:36,038 INFO     Training average positive_sample_loss at step 21000: 0.057610\n",
      "2023-12-03 00:37:36,038 INFO     Training average negative_sample_loss at step 21000: 0.021294\n",
      "2023-12-03 00:37:36,039 INFO     Training average loss at step 21000: 0.039452\n",
      "2023-12-03 00:37:42,294 INFO     Training average positive_sample_loss at step 21100: 0.057879\n",
      "2023-12-03 00:37:42,295 INFO     Training average negative_sample_loss at step 21100: 0.021333\n",
      "2023-12-03 00:37:42,295 INFO     Training average loss at step 21100: 0.039606\n",
      "2023-12-03 00:37:48,411 INFO     Training average positive_sample_loss at step 21200: 0.054780\n",
      "2023-12-03 00:37:48,412 INFO     Training average negative_sample_loss at step 21200: 0.021283\n",
      "2023-12-03 00:37:48,412 INFO     Training average loss at step 21200: 0.038031\n",
      "2023-12-03 00:37:54,504 INFO     Training average positive_sample_loss at step 21300: 0.056988\n",
      "2023-12-03 00:37:54,505 INFO     Training average negative_sample_loss at step 21300: 0.021230\n",
      "2023-12-03 00:37:54,505 INFO     Training average loss at step 21300: 0.039109\n",
      "2023-12-03 00:38:00,157 INFO     Training average positive_sample_loss at step 21400: 0.057973\n",
      "2023-12-03 00:38:00,157 INFO     Training average negative_sample_loss at step 21400: 0.021169\n",
      "2023-12-03 00:38:00,157 INFO     Training average loss at step 21400: 0.039571\n",
      "2023-12-03 00:38:06,539 INFO     Training average positive_sample_loss at step 21500: 0.054073\n",
      "2023-12-03 00:38:06,539 INFO     Training average negative_sample_loss at step 21500: 0.021139\n",
      "2023-12-03 00:38:06,539 INFO     Training average loss at step 21500: 0.037606\n",
      "2023-12-03 00:38:12,659 INFO     Training average positive_sample_loss at step 21600: 0.055953\n",
      "2023-12-03 00:38:12,659 INFO     Training average negative_sample_loss at step 21600: 0.021029\n",
      "2023-12-03 00:38:12,659 INFO     Training average loss at step 21600: 0.038491\n",
      "2023-12-03 00:38:18,783 INFO     Training average positive_sample_loss at step 21700: 0.057403\n",
      "2023-12-03 00:38:18,783 INFO     Training average negative_sample_loss at step 21700: 0.021003\n",
      "2023-12-03 00:38:18,784 INFO     Training average loss at step 21700: 0.039203\n",
      "2023-12-03 00:38:24,942 INFO     Training average positive_sample_loss at step 21800: 0.055843\n",
      "2023-12-03 00:38:24,942 INFO     Training average negative_sample_loss at step 21800: 0.020916\n",
      "2023-12-03 00:38:24,942 INFO     Training average loss at step 21800: 0.038380\n",
      "2023-12-03 00:38:31,012 INFO     Training average positive_sample_loss at step 21900: 0.054583\n",
      "2023-12-03 00:38:31,012 INFO     Training average negative_sample_loss at step 21900: 0.020889\n",
      "2023-12-03 00:38:31,012 INFO     Training average loss at step 21900: 0.037736\n",
      "2023-12-03 00:38:36,530 INFO     Training average positive_sample_loss at step 22000: 0.056604\n",
      "2023-12-03 00:38:36,531 INFO     Training average negative_sample_loss at step 22000: 0.020924\n",
      "2023-12-03 00:38:36,531 INFO     Training average loss at step 22000: 0.038764\n",
      "2023-12-03 00:38:42,519 INFO     Training average positive_sample_loss at step 22100: 0.057016\n",
      "2023-12-03 00:38:42,519 INFO     Training average negative_sample_loss at step 22100: 0.020911\n",
      "2023-12-03 00:38:42,519 INFO     Training average loss at step 22100: 0.038963\n",
      "2023-12-03 00:38:48,330 INFO     Training average positive_sample_loss at step 22200: 0.052632\n",
      "2023-12-03 00:38:48,331 INFO     Training average negative_sample_loss at step 22200: 0.020775\n",
      "2023-12-03 00:38:48,331 INFO     Training average loss at step 22200: 0.036704\n",
      "2023-12-03 00:38:54,496 INFO     Training average positive_sample_loss at step 22300: 0.055364\n",
      "2023-12-03 00:38:54,496 INFO     Training average negative_sample_loss at step 22300: 0.020732\n",
      "2023-12-03 00:38:54,496 INFO     Training average loss at step 22300: 0.038048\n",
      "2023-12-03 00:38:59,990 INFO     Training average positive_sample_loss at step 22400: 0.057057\n",
      "2023-12-03 00:38:59,991 INFO     Training average negative_sample_loss at step 22400: 0.020685\n",
      "2023-12-03 00:38:59,991 INFO     Training average loss at step 22400: 0.038871\n",
      "2023-12-03 00:39:06,642 INFO     Training average positive_sample_loss at step 22500: 0.054332\n",
      "2023-12-03 00:39:06,643 INFO     Training average negative_sample_loss at step 22500: 0.020765\n",
      "2023-12-03 00:39:06,643 INFO     Training average loss at step 22500: 0.037549\n",
      "2023-12-03 00:39:12,744 INFO     Training average positive_sample_loss at step 22600: 0.054399\n",
      "2023-12-03 00:39:12,744 INFO     Training average negative_sample_loss at step 22600: 0.020627\n",
      "2023-12-03 00:39:12,745 INFO     Training average loss at step 22600: 0.037513\n",
      "2023-12-03 00:39:18,854 INFO     Training average positive_sample_loss at step 22700: 0.055724\n",
      "2023-12-03 00:39:18,855 INFO     Training average negative_sample_loss at step 22700: 0.020546\n",
      "2023-12-03 00:39:18,855 INFO     Training average loss at step 22700: 0.038135\n",
      "2023-12-03 00:39:25,048 INFO     Training average positive_sample_loss at step 22800: 0.055447\n",
      "2023-12-03 00:39:25,048 INFO     Training average negative_sample_loss at step 22800: 0.020586\n",
      "2023-12-03 00:39:25,048 INFO     Training average loss at step 22800: 0.038016\n",
      "2023-12-03 00:39:30,449 INFO     Training average positive_sample_loss at step 22900: 0.052873\n",
      "2023-12-03 00:39:30,450 INFO     Training average negative_sample_loss at step 22900: 0.020422\n",
      "2023-12-03 00:39:30,450 INFO     Training average loss at step 22900: 0.036647\n",
      "2023-12-03 00:39:36,574 INFO     Training average positive_sample_loss at step 23000: 0.055239\n",
      "2023-12-03 00:39:36,574 INFO     Training average negative_sample_loss at step 23000: 0.020501\n",
      "2023-12-03 00:39:36,574 INFO     Training average loss at step 23000: 0.037870\n",
      "2023-12-03 00:39:42,679 INFO     Training average positive_sample_loss at step 23100: 0.056259\n",
      "2023-12-03 00:39:42,679 INFO     Training average negative_sample_loss at step 23100: 0.020539\n",
      "2023-12-03 00:39:42,679 INFO     Training average loss at step 23100: 0.038399\n",
      "2023-12-03 00:39:49,191 INFO     Training average positive_sample_loss at step 23200: 0.052459\n",
      "2023-12-03 00:39:49,191 INFO     Training average negative_sample_loss at step 23200: 0.020411\n",
      "2023-12-03 00:39:49,191 INFO     Training average loss at step 23200: 0.036435\n",
      "2023-12-03 00:39:55,191 INFO     Training average positive_sample_loss at step 23300: 0.054144\n",
      "2023-12-03 00:39:55,191 INFO     Training average negative_sample_loss at step 23300: 0.020304\n",
      "2023-12-03 00:39:55,191 INFO     Training average loss at step 23300: 0.037224\n",
      "2023-12-03 00:40:00,748 INFO     Training average positive_sample_loss at step 23400: 0.055479\n",
      "2023-12-03 00:40:00,748 INFO     Training average negative_sample_loss at step 23400: 0.020244\n",
      "2023-12-03 00:40:00,748 INFO     Training average loss at step 23400: 0.037861\n",
      "2023-12-03 00:40:07,282 INFO     Training average positive_sample_loss at step 23500: 0.053830\n",
      "2023-12-03 00:40:07,282 INFO     Training average negative_sample_loss at step 23500: 0.020411\n",
      "2023-12-03 00:40:07,282 INFO     Training average loss at step 23500: 0.037120\n",
      "2023-12-03 00:40:13,239 INFO     Training average positive_sample_loss at step 23600: 0.052868\n",
      "2023-12-03 00:40:13,239 INFO     Training average negative_sample_loss at step 23600: 0.020164\n",
      "2023-12-03 00:40:13,239 INFO     Training average loss at step 23600: 0.036516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:40:19,289 INFO     Training average positive_sample_loss at step 23700: 0.054642\n",
      "2023-12-03 00:40:19,289 INFO     Training average negative_sample_loss at step 23700: 0.020175\n",
      "2023-12-03 00:40:19,289 INFO     Training average loss at step 23700: 0.037409\n",
      "2023-12-03 00:40:25,656 INFO     Training average positive_sample_loss at step 23800: 0.055629\n",
      "2023-12-03 00:40:25,657 INFO     Training average negative_sample_loss at step 23800: 0.020260\n",
      "2023-12-03 00:40:25,657 INFO     Training average loss at step 23800: 0.037944\n",
      "2023-12-03 00:40:31,553 INFO     Training average positive_sample_loss at step 23900: 0.051337\n",
      "2023-12-03 00:40:31,553 INFO     Training average negative_sample_loss at step 23900: 0.020112\n",
      "2023-12-03 00:40:31,553 INFO     Training average loss at step 23900: 0.035725\n",
      "2023-12-03 00:40:37,668 INFO     Training average positive_sample_loss at step 24000: 0.053992\n",
      "2023-12-03 00:40:37,668 INFO     Training average negative_sample_loss at step 24000: 0.020081\n",
      "2023-12-03 00:40:37,668 INFO     Training average loss at step 24000: 0.037037\n",
      "2023-12-03 00:40:43,617 INFO     Training average positive_sample_loss at step 24100: 0.054855\n",
      "2023-12-03 00:40:43,617 INFO     Training average negative_sample_loss at step 24100: 0.019989\n",
      "2023-12-03 00:40:43,617 INFO     Training average loss at step 24100: 0.037422\n",
      "2023-12-03 00:40:49,857 INFO     Training average positive_sample_loss at step 24200: 0.052258\n",
      "2023-12-03 00:40:49,857 INFO     Training average negative_sample_loss at step 24200: 0.020168\n",
      "2023-12-03 00:40:49,857 INFO     Training average loss at step 24200: 0.036213\n",
      "2023-12-03 00:40:55,907 INFO     Training average positive_sample_loss at step 24300: 0.052576\n",
      "2023-12-03 00:40:55,907 INFO     Training average negative_sample_loss at step 24300: 0.019971\n",
      "2023-12-03 00:40:55,907 INFO     Training average loss at step 24300: 0.036273\n",
      "2023-12-03 00:41:01,969 INFO     Training average positive_sample_loss at step 24400: 0.054189\n",
      "2023-12-03 00:41:01,969 INFO     Training average negative_sample_loss at step 24400: 0.019969\n",
      "2023-12-03 00:41:01,969 INFO     Training average loss at step 24400: 0.037079\n",
      "2023-12-03 00:41:08,025 INFO     Training average positive_sample_loss at step 24500: 0.054180\n",
      "2023-12-03 00:41:08,025 INFO     Training average negative_sample_loss at step 24500: 0.020061\n",
      "2023-12-03 00:41:08,025 INFO     Training average loss at step 24500: 0.037120\n",
      "2023-12-03 00:41:14,147 INFO     Training average positive_sample_loss at step 24600: 0.051554\n",
      "2023-12-03 00:41:14,147 INFO     Training average negative_sample_loss at step 24600: 0.019882\n",
      "2023-12-03 00:41:14,147 INFO     Training average loss at step 24600: 0.035718\n",
      "2023-12-03 00:41:20,135 INFO     Training average positive_sample_loss at step 24700: 0.053555\n",
      "2023-12-03 00:41:20,135 INFO     Training average negative_sample_loss at step 24700: 0.019787\n",
      "2023-12-03 00:41:20,135 INFO     Training average loss at step 24700: 0.036671\n",
      "2023-12-03 00:41:26,250 INFO     Training average positive_sample_loss at step 24800: 0.054346\n",
      "2023-12-03 00:41:26,250 INFO     Training average negative_sample_loss at step 24800: 0.019971\n",
      "2023-12-03 00:41:26,250 INFO     Training average loss at step 24800: 0.037158\n",
      "2023-12-03 00:41:32,900 INFO     Training average positive_sample_loss at step 24900: 0.051098\n",
      "2023-12-03 00:41:32,900 INFO     Training average negative_sample_loss at step 24900: 0.019969\n",
      "2023-12-03 00:41:32,901 INFO     Training average loss at step 24900: 0.035534\n",
      "2023-12-03 00:41:38,663 INFO     Training average positive_sample_loss at step 25000: 0.052248\n",
      "2023-12-03 00:41:38,663 INFO     Training average negative_sample_loss at step 25000: 0.019490\n",
      "2023-12-03 00:41:38,663 INFO     Training average loss at step 25000: 0.035869\n",
      "2023-12-03 00:41:44,816 INFO     Training average positive_sample_loss at step 25100: 0.054214\n",
      "2023-12-03 00:41:44,816 INFO     Training average negative_sample_loss at step 25100: 0.019738\n",
      "2023-12-03 00:41:44,816 INFO     Training average loss at step 25100: 0.036976\n",
      "2023-12-03 00:41:51,436 INFO     Training average positive_sample_loss at step 25200: 0.052371\n",
      "2023-12-03 00:41:51,436 INFO     Training average negative_sample_loss at step 25200: 0.019814\n",
      "2023-12-03 00:41:51,436 INFO     Training average loss at step 25200: 0.036093\n",
      "2023-12-03 00:41:57,486 INFO     Training average positive_sample_loss at step 25300: 0.051331\n",
      "2023-12-03 00:41:57,487 INFO     Training average negative_sample_loss at step 25300: 0.019715\n",
      "2023-12-03 00:41:57,487 INFO     Training average loss at step 25300: 0.035523\n",
      "2023-12-03 00:42:03,607 INFO     Training average positive_sample_loss at step 25400: 0.053319\n",
      "2023-12-03 00:42:03,607 INFO     Training average negative_sample_loss at step 25400: 0.019656\n",
      "2023-12-03 00:42:03,607 INFO     Training average loss at step 25400: 0.036488\n",
      "2023-12-03 00:42:09,868 INFO     Training average positive_sample_loss at step 25500: 0.054104\n",
      "2023-12-03 00:42:09,868 INFO     Training average negative_sample_loss at step 25500: 0.019721\n",
      "2023-12-03 00:42:09,868 INFO     Training average loss at step 25500: 0.036912\n",
      "2023-12-03 00:42:15,908 INFO     Training average positive_sample_loss at step 25600: 0.050024\n",
      "2023-12-03 00:42:15,908 INFO     Training average negative_sample_loss at step 25600: 0.019675\n",
      "2023-12-03 00:42:15,908 INFO     Training average loss at step 25600: 0.034850\n",
      "2023-12-03 00:42:22,033 INFO     Training average positive_sample_loss at step 25700: 0.052205\n",
      "2023-12-03 00:42:22,033 INFO     Training average negative_sample_loss at step 25700: 0.019524\n",
      "2023-12-03 00:42:22,033 INFO     Training average loss at step 25700: 0.035865\n",
      "2023-12-03 00:42:27,997 INFO     Training average positive_sample_loss at step 25800: 0.053702\n",
      "2023-12-03 00:42:27,998 INFO     Training average negative_sample_loss at step 25800: 0.019587\n",
      "2023-12-03 00:42:27,998 INFO     Training average loss at step 25800: 0.036644\n",
      "2023-12-03 00:42:34,422 INFO     Training average positive_sample_loss at step 25900: 0.050991\n",
      "2023-12-03 00:42:34,422 INFO     Training average negative_sample_loss at step 25900: 0.019650\n",
      "2023-12-03 00:42:34,422 INFO     Training average loss at step 25900: 0.035321\n",
      "2023-12-03 00:42:40,495 INFO     Training average positive_sample_loss at step 26000: 0.051375\n",
      "2023-12-03 00:42:40,495 INFO     Training average negative_sample_loss at step 26000: 0.019444\n",
      "2023-12-03 00:42:40,495 INFO     Training average loss at step 26000: 0.035410\n",
      "2023-12-03 00:42:46,221 INFO     Training average positive_sample_loss at step 26100: 0.052771\n",
      "2023-12-03 00:42:46,221 INFO     Training average negative_sample_loss at step 26100: 0.019428\n",
      "2023-12-03 00:42:46,221 INFO     Training average loss at step 26100: 0.036099\n",
      "2023-12-03 00:42:52,857 INFO     Training average positive_sample_loss at step 26200: 0.052844\n",
      "2023-12-03 00:42:52,857 INFO     Training average negative_sample_loss at step 26200: 0.019538\n",
      "2023-12-03 00:42:52,857 INFO     Training average loss at step 26200: 0.036191\n",
      "2023-12-03 00:42:58,952 INFO     Training average positive_sample_loss at step 26300: 0.050446\n",
      "2023-12-03 00:42:58,953 INFO     Training average negative_sample_loss at step 26300: 0.019354\n",
      "2023-12-03 00:42:58,953 INFO     Training average loss at step 26300: 0.034900\n",
      "2023-12-03 00:43:04,878 INFO     Training average positive_sample_loss at step 26400: 0.051914\n",
      "2023-12-03 00:43:04,878 INFO     Training average negative_sample_loss at step 26400: 0.019346\n",
      "2023-12-03 00:43:04,878 INFO     Training average loss at step 26400: 0.035630\n",
      "2023-12-03 00:43:10,976 INFO     Training average positive_sample_loss at step 26500: 0.053030\n",
      "2023-12-03 00:43:10,977 INFO     Training average negative_sample_loss at step 26500: 0.019659\n",
      "2023-12-03 00:43:10,977 INFO     Training average loss at step 26500: 0.036344\n",
      "2023-12-03 00:43:17,060 INFO     Training average positive_sample_loss at step 26600: 0.049836\n",
      "2023-12-03 00:43:17,060 INFO     Training average negative_sample_loss at step 26600: 0.019307\n",
      "2023-12-03 00:43:17,060 INFO     Training average loss at step 26600: 0.034572\n",
      "2023-12-03 00:43:23,144 INFO     Training average positive_sample_loss at step 26700: 0.051379\n",
      "2023-12-03 00:43:23,144 INFO     Training average negative_sample_loss at step 26700: 0.019306\n",
      "2023-12-03 00:43:23,144 INFO     Training average loss at step 26700: 0.035342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:43:29,239 INFO     Training average positive_sample_loss at step 26800: 0.052748\n",
      "2023-12-03 00:43:29,239 INFO     Training average negative_sample_loss at step 26800: 0.019337\n",
      "2023-12-03 00:43:29,239 INFO     Training average loss at step 26800: 0.036042\n",
      "2023-12-03 00:43:35,756 INFO     Training average positive_sample_loss at step 26900: 0.050894\n",
      "2023-12-03 00:43:35,756 INFO     Training average negative_sample_loss at step 26900: 0.019360\n",
      "2023-12-03 00:43:35,756 INFO     Training average loss at step 26900: 0.035127\n",
      "2023-12-03 00:43:41,791 INFO     Training average positive_sample_loss at step 27000: 0.050568\n",
      "2023-12-03 00:43:41,791 INFO     Training average negative_sample_loss at step 27000: 0.019360\n",
      "2023-12-03 00:43:41,791 INFO     Training average loss at step 27000: 0.034964\n",
      "2023-12-03 00:43:47,246 INFO     Training average positive_sample_loss at step 27100: 0.051785\n",
      "2023-12-03 00:43:47,246 INFO     Training average negative_sample_loss at step 27100: 0.019205\n",
      "2023-12-03 00:43:47,246 INFO     Training average loss at step 27100: 0.035495\n",
      "2023-12-03 00:43:53,570 INFO     Training average positive_sample_loss at step 27200: 0.052677\n",
      "2023-12-03 00:43:53,570 INFO     Training average negative_sample_loss at step 27200: 0.019192\n",
      "2023-12-03 00:43:53,570 INFO     Training average loss at step 27200: 0.035934\n",
      "2023-12-03 00:43:59,912 INFO     Training average positive_sample_loss at step 27300: 0.048792\n",
      "2023-12-03 00:43:59,912 INFO     Training average negative_sample_loss at step 27300: 0.019159\n",
      "2023-12-03 00:43:59,912 INFO     Training average loss at step 27300: 0.033975\n",
      "2023-12-03 00:44:05,970 INFO     Training average positive_sample_loss at step 27400: 0.051289\n",
      "2023-12-03 00:44:05,970 INFO     Training average negative_sample_loss at step 27400: 0.019158\n",
      "2023-12-03 00:44:05,970 INFO     Training average loss at step 27400: 0.035223\n",
      "2023-12-03 00:44:12,023 INFO     Training average positive_sample_loss at step 27500: 0.052147\n",
      "2023-12-03 00:44:12,024 INFO     Training average negative_sample_loss at step 27500: 0.019174\n",
      "2023-12-03 00:44:12,024 INFO     Training average loss at step 27500: 0.035660\n",
      "2023-12-03 00:44:18,377 INFO     Training average positive_sample_loss at step 27600: 0.050010\n",
      "2023-12-03 00:44:18,378 INFO     Training average negative_sample_loss at step 27600: 0.019201\n",
      "2023-12-03 00:44:18,378 INFO     Training average loss at step 27600: 0.034606\n",
      "2023-12-03 00:44:24,017 INFO     Training average positive_sample_loss at step 27700: 0.050217\n",
      "2023-12-03 00:44:24,017 INFO     Training average negative_sample_loss at step 27700: 0.019126\n",
      "2023-12-03 00:44:24,017 INFO     Training average loss at step 27700: 0.034672\n",
      "2023-12-03 00:44:30,145 INFO     Training average positive_sample_loss at step 27800: 0.051830\n",
      "2023-12-03 00:44:30,145 INFO     Training average negative_sample_loss at step 27800: 0.019130\n",
      "2023-12-03 00:44:30,145 INFO     Training average loss at step 27800: 0.035480\n",
      "2023-12-03 00:44:36,792 INFO     Training average positive_sample_loss at step 27900: 0.051378\n",
      "2023-12-03 00:44:36,792 INFO     Training average negative_sample_loss at step 27900: 0.019016\n",
      "2023-12-03 00:44:36,792 INFO     Training average loss at step 27900: 0.035197\n",
      "2023-12-03 00:44:42,912 INFO     Training average positive_sample_loss at step 28000: 0.048904\n",
      "2023-12-03 00:44:42,912 INFO     Training average negative_sample_loss at step 28000: 0.018883\n",
      "2023-12-03 00:44:42,912 INFO     Training average loss at step 28000: 0.033893\n",
      "2023-12-03 00:44:48,795 INFO     Training average positive_sample_loss at step 28100: 0.050934\n",
      "2023-12-03 00:44:48,795 INFO     Training average negative_sample_loss at step 28100: 0.018934\n",
      "2023-12-03 00:44:48,795 INFO     Training average loss at step 28100: 0.034934\n",
      "2023-12-03 00:44:54,584 INFO     Training average positive_sample_loss at step 28200: 0.052340\n",
      "2023-12-03 00:44:54,584 INFO     Training average negative_sample_loss at step 28200: 0.019054\n",
      "2023-12-03 00:44:54,584 INFO     Training average loss at step 28200: 0.035697\n",
      "2023-12-03 00:45:00,890 INFO     Training average positive_sample_loss at step 28300: 0.048895\n",
      "2023-12-03 00:45:00,891 INFO     Training average negative_sample_loss at step 28300: 0.019043\n",
      "2023-12-03 00:45:00,891 INFO     Training average loss at step 28300: 0.033969\n",
      "2023-12-03 00:45:07,006 INFO     Training average positive_sample_loss at step 28400: 0.050045\n",
      "2023-12-03 00:45:07,006 INFO     Training average negative_sample_loss at step 28400: 0.018943\n",
      "2023-12-03 00:45:07,006 INFO     Training average loss at step 28400: 0.034494\n",
      "2023-12-03 00:45:13,086 INFO     Training average positive_sample_loss at step 28500: 0.051268\n",
      "2023-12-03 00:45:13,086 INFO     Training average negative_sample_loss at step 28500: 0.018880\n",
      "2023-12-03 00:45:13,086 INFO     Training average loss at step 28500: 0.035074\n",
      "2023-12-03 00:45:19,363 INFO     Training average positive_sample_loss at step 28600: 0.050378\n",
      "2023-12-03 00:45:19,364 INFO     Training average negative_sample_loss at step 28600: 0.019007\n",
      "2023-12-03 00:45:19,364 INFO     Training average loss at step 28600: 0.034693\n",
      "2023-12-03 00:45:25,292 INFO     Training average positive_sample_loss at step 28700: 0.048931\n",
      "2023-12-03 00:45:25,293 INFO     Training average negative_sample_loss at step 28700: 0.018747\n",
      "2023-12-03 00:45:25,293 INFO     Training average loss at step 28700: 0.033839\n",
      "2023-12-03 00:45:31,076 INFO     Training average positive_sample_loss at step 28800: 0.050879\n",
      "2023-12-03 00:45:31,076 INFO     Training average negative_sample_loss at step 28800: 0.018887\n",
      "2023-12-03 00:45:31,076 INFO     Training average loss at step 28800: 0.034883\n",
      "2023-12-03 00:45:37,482 INFO     Training average positive_sample_loss at step 28900: 0.051956\n",
      "2023-12-03 00:45:37,482 INFO     Training average negative_sample_loss at step 28900: 0.018974\n",
      "2023-12-03 00:45:37,482 INFO     Training average loss at step 28900: 0.035465\n",
      "2023-12-03 00:45:43,943 INFO     Training average positive_sample_loss at step 29000: 0.047846\n",
      "2023-12-03 00:45:43,943 INFO     Training average negative_sample_loss at step 29000: 0.018899\n",
      "2023-12-03 00:45:43,944 INFO     Training average loss at step 29000: 0.033372\n",
      "2023-12-03 00:45:50,028 INFO     Training average positive_sample_loss at step 29100: 0.050158\n",
      "2023-12-03 00:45:50,028 INFO     Training average negative_sample_loss at step 29100: 0.018762\n",
      "2023-12-03 00:45:50,028 INFO     Training average loss at step 29100: 0.034460\n",
      "2023-12-03 00:45:56,053 INFO     Training average positive_sample_loss at step 29200: 0.051244\n",
      "2023-12-03 00:45:56,053 INFO     Training average negative_sample_loss at step 29200: 0.018754\n",
      "2023-12-03 00:45:56,053 INFO     Training average loss at step 29200: 0.034999\n",
      "2023-12-03 00:46:02,523 INFO     Training average positive_sample_loss at step 29300: 0.049147\n",
      "2023-12-03 00:46:02,523 INFO     Training average negative_sample_loss at step 29300: 0.018881\n",
      "2023-12-03 00:46:02,523 INFO     Training average loss at step 29300: 0.034014\n",
      "2023-12-03 00:46:08,249 INFO     Training average positive_sample_loss at step 29400: 0.049028\n",
      "2023-12-03 00:46:08,249 INFO     Training average negative_sample_loss at step 29400: 0.018604\n",
      "2023-12-03 00:46:08,249 INFO     Training average loss at step 29400: 0.033816\n",
      "2023-12-03 00:46:14,358 INFO     Training average positive_sample_loss at step 29500: 0.050621\n",
      "2023-12-03 00:46:14,358 INFO     Training average negative_sample_loss at step 29500: 0.018695\n",
      "2023-12-03 00:46:14,358 INFO     Training average loss at step 29500: 0.034658\n",
      "2023-12-03 00:46:20,959 INFO     Training average positive_sample_loss at step 29600: 0.050495\n",
      "2023-12-03 00:46:20,960 INFO     Training average negative_sample_loss at step 29600: 0.018777\n",
      "2023-12-03 00:46:20,960 INFO     Training average loss at step 29600: 0.034636\n",
      "2023-12-03 00:46:27,044 INFO     Training average positive_sample_loss at step 29700: 0.048240\n",
      "2023-12-03 00:46:27,044 INFO     Training average negative_sample_loss at step 29700: 0.018800\n",
      "2023-12-03 00:46:27,044 INFO     Training average loss at step 29700: 0.033520\n",
      "2023-12-03 00:46:32,981 INFO     Training average positive_sample_loss at step 29800: 0.049935\n",
      "2023-12-03 00:46:32,981 INFO     Training average negative_sample_loss at step 29800: 0.018602\n",
      "2023-12-03 00:46:32,981 INFO     Training average loss at step 29800: 0.034269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:46:38,954 INFO     Training average positive_sample_loss at step 29900: 0.051085\n",
      "2023-12-03 00:46:38,954 INFO     Training average negative_sample_loss at step 29900: 0.018647\n",
      "2023-12-03 00:46:38,954 INFO     Training average loss at step 29900: 0.034866\n",
      "2023-12-03 00:46:56,810 INFO     Training average positive_sample_loss at step 30000: 0.048033\n",
      "2023-12-03 00:46:56,810 INFO     Training average negative_sample_loss at step 30000: 0.018746\n",
      "2023-12-03 00:46:56,810 INFO     Training average loss at step 30000: 0.033390\n",
      "2023-12-03 00:46:56,810 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:46:57,847 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:47:30,607 INFO     Valid MRR at step 30000: 0.480568\n",
      "2023-12-03 00:47:30,607 INFO     Valid MR at step 30000: 3693.904252\n",
      "2023-12-03 00:47:30,607 INFO     Valid HITS@1 at step 30000: 0.437376\n",
      "2023-12-03 00:47:30,607 INFO     Valid HITS@3 at step 30000: 0.495056\n",
      "2023-12-03 00:47:30,607 INFO     Valid HITS@10 at step 30000: 0.565755\n",
      "2023-12-03 00:47:36,696 INFO     Training average positive_sample_loss at step 30100: 0.049248\n",
      "2023-12-03 00:47:36,696 INFO     Training average negative_sample_loss at step 30100: 0.018591\n",
      "2023-12-03 00:47:36,696 INFO     Training average loss at step 30100: 0.033919\n",
      "2023-12-03 00:47:42,672 INFO     Training average positive_sample_loss at step 30200: 0.050491\n",
      "2023-12-03 00:47:42,673 INFO     Training average negative_sample_loss at step 30200: 0.018540\n",
      "2023-12-03 00:47:42,673 INFO     Training average loss at step 30200: 0.034515\n",
      "2023-12-03 00:47:49,430 INFO     Training average positive_sample_loss at step 30300: 0.049122\n",
      "2023-12-03 00:47:49,430 INFO     Training average negative_sample_loss at step 30300: 0.018731\n",
      "2023-12-03 00:47:49,430 INFO     Training average loss at step 30300: 0.033927\n",
      "2023-12-03 00:47:55,542 INFO     Training average positive_sample_loss at step 30400: 0.048112\n",
      "2023-12-03 00:47:55,543 INFO     Training average negative_sample_loss at step 30400: 0.018633\n",
      "2023-12-03 00:47:55,543 INFO     Training average loss at step 30400: 0.033372\n",
      "2023-12-03 00:48:01,213 INFO     Training average positive_sample_loss at step 30500: 0.050081\n",
      "2023-12-03 00:48:01,214 INFO     Training average negative_sample_loss at step 30500: 0.018594\n",
      "2023-12-03 00:48:01,214 INFO     Training average loss at step 30500: 0.034338\n",
      "2023-12-03 00:48:07,527 INFO     Training average positive_sample_loss at step 30600: 0.050843\n",
      "2023-12-03 00:48:07,527 INFO     Training average negative_sample_loss at step 30600: 0.018663\n",
      "2023-12-03 00:48:07,527 INFO     Training average loss at step 30600: 0.034753\n",
      "2023-12-03 00:48:13,871 INFO     Training average positive_sample_loss at step 30700: 0.047119\n",
      "2023-12-03 00:48:13,871 INFO     Training average negative_sample_loss at step 30700: 0.018615\n",
      "2023-12-03 00:48:13,871 INFO     Training average loss at step 30700: 0.032867\n",
      "2023-12-03 00:48:19,765 INFO     Training average positive_sample_loss at step 30800: 0.049169\n",
      "2023-12-03 00:48:19,766 INFO     Training average negative_sample_loss at step 30800: 0.018429\n",
      "2023-12-03 00:48:19,766 INFO     Training average loss at step 30800: 0.033799\n",
      "2023-12-03 00:48:25,908 INFO     Training average positive_sample_loss at step 30900: 0.050379\n",
      "2023-12-03 00:48:25,909 INFO     Training average negative_sample_loss at step 30900: 0.018437\n",
      "2023-12-03 00:48:25,909 INFO     Training average loss at step 30900: 0.034408\n",
      "2023-12-03 00:48:32,501 INFO     Training average positive_sample_loss at step 31000: 0.048253\n",
      "2023-12-03 00:48:32,501 INFO     Training average negative_sample_loss at step 31000: 0.018605\n",
      "2023-12-03 00:48:32,501 INFO     Training average loss at step 31000: 0.033429\n",
      "2023-12-03 00:48:38,191 INFO     Training average positive_sample_loss at step 31100: 0.048425\n",
      "2023-12-03 00:48:38,192 INFO     Training average negative_sample_loss at step 31100: 0.018439\n",
      "2023-12-03 00:48:38,192 INFO     Training average loss at step 31100: 0.033432\n",
      "2023-12-03 00:48:44,356 INFO     Training average positive_sample_loss at step 31200: 0.049774\n",
      "2023-12-03 00:48:44,357 INFO     Training average negative_sample_loss at step 31200: 0.018532\n",
      "2023-12-03 00:48:44,357 INFO     Training average loss at step 31200: 0.034153\n",
      "2023-12-03 00:48:51,123 INFO     Training average positive_sample_loss at step 31300: 0.049288\n",
      "2023-12-03 00:48:51,124 INFO     Training average negative_sample_loss at step 31300: 0.018440\n",
      "2023-12-03 00:48:51,124 INFO     Training average loss at step 31300: 0.033864\n",
      "2023-12-03 00:48:57,018 INFO     Training average positive_sample_loss at step 31400: 0.047324\n",
      "2023-12-03 00:48:57,019 INFO     Training average negative_sample_loss at step 31400: 0.018414\n",
      "2023-12-03 00:48:57,019 INFO     Training average loss at step 31400: 0.032869\n",
      "2023-12-03 00:49:03,169 INFO     Training average positive_sample_loss at step 31500: 0.049157\n",
      "2023-12-03 00:49:03,169 INFO     Training average negative_sample_loss at step 31500: 0.018324\n",
      "2023-12-03 00:49:03,170 INFO     Training average loss at step 31500: 0.033741\n",
      "2023-12-03 00:49:09,107 INFO     Training average positive_sample_loss at step 31600: 0.050457\n",
      "2023-12-03 00:49:09,107 INFO     Training average negative_sample_loss at step 31600: 0.018436\n",
      "2023-12-03 00:49:09,107 INFO     Training average loss at step 31600: 0.034447\n",
      "2023-12-03 00:49:15,593 INFO     Training average positive_sample_loss at step 31700: 0.046976\n",
      "2023-12-03 00:49:15,593 INFO     Training average negative_sample_loss at step 31700: 0.018330\n",
      "2023-12-03 00:49:15,593 INFO     Training average loss at step 31700: 0.032653\n",
      "2023-12-03 00:49:21,660 INFO     Training average positive_sample_loss at step 31800: 0.048456\n",
      "2023-12-03 00:49:21,660 INFO     Training average negative_sample_loss at step 31800: 0.018408\n",
      "2023-12-03 00:49:21,660 INFO     Training average loss at step 31800: 0.033432\n",
      "2023-12-03 00:49:27,603 INFO     Training average positive_sample_loss at step 31900: 0.049664\n",
      "2023-12-03 00:49:27,604 INFO     Training average negative_sample_loss at step 31900: 0.018335\n",
      "2023-12-03 00:49:27,604 INFO     Training average loss at step 31900: 0.034000\n",
      "2023-12-03 00:49:34,311 INFO     Training average positive_sample_loss at step 32000: 0.048735\n",
      "2023-12-03 00:49:34,311 INFO     Training average negative_sample_loss at step 32000: 0.018356\n",
      "2023-12-03 00:49:34,311 INFO     Training average loss at step 32000: 0.033546\n",
      "2023-12-03 00:49:40,209 INFO     Training average positive_sample_loss at step 32100: 0.047591\n",
      "2023-12-03 00:49:40,210 INFO     Training average negative_sample_loss at step 32100: 0.018412\n",
      "2023-12-03 00:49:40,210 INFO     Training average loss at step 32100: 0.033002\n",
      "2023-12-03 00:49:46,339 INFO     Training average positive_sample_loss at step 32200: 0.049122\n",
      "2023-12-03 00:49:46,339 INFO     Training average negative_sample_loss at step 32200: 0.018330\n",
      "2023-12-03 00:49:46,339 INFO     Training average loss at step 32200: 0.033726\n",
      "2023-12-03 00:49:52,586 INFO     Training average positive_sample_loss at step 32300: 0.049801\n",
      "2023-12-03 00:49:52,587 INFO     Training average negative_sample_loss at step 32300: 0.018420\n",
      "2023-12-03 00:49:52,587 INFO     Training average loss at step 32300: 0.034111\n",
      "2023-12-03 00:49:58,805 INFO     Training average positive_sample_loss at step 32400: 0.046229\n",
      "2023-12-03 00:49:58,806 INFO     Training average negative_sample_loss at step 32400: 0.018249\n",
      "2023-12-03 00:49:58,806 INFO     Training average loss at step 32400: 0.032239\n",
      "2023-12-03 00:50:04,888 INFO     Training average positive_sample_loss at step 32500: 0.048613\n",
      "2023-12-03 00:50:04,889 INFO     Training average negative_sample_loss at step 32500: 0.018286\n",
      "2023-12-03 00:50:04,889 INFO     Training average loss at step 32500: 0.033450\n",
      "2023-12-03 00:50:10,892 INFO     Training average positive_sample_loss at step 32600: 0.049710\n",
      "2023-12-03 00:50:10,893 INFO     Training average negative_sample_loss at step 32600: 0.018404\n",
      "2023-12-03 00:50:10,893 INFO     Training average loss at step 32600: 0.034057\n",
      "2023-12-03 00:50:17,464 INFO     Training average positive_sample_loss at step 32700: 0.047376\n",
      "2023-12-03 00:50:17,465 INFO     Training average negative_sample_loss at step 32700: 0.018325\n",
      "2023-12-03 00:50:17,465 INFO     Training average loss at step 32700: 0.032850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:50:23,599 INFO     Training average positive_sample_loss at step 32800: 0.047578\n",
      "2023-12-03 00:50:23,599 INFO     Training average negative_sample_loss at step 32800: 0.018207\n",
      "2023-12-03 00:50:23,599 INFO     Training average loss at step 32800: 0.032892\n",
      "2023-12-03 00:50:29,724 INFO     Training average positive_sample_loss at step 32900: 0.049148\n",
      "2023-12-03 00:50:29,724 INFO     Training average negative_sample_loss at step 32900: 0.018246\n",
      "2023-12-03 00:50:29,724 INFO     Training average loss at step 32900: 0.033697\n",
      "2023-12-03 00:50:35,872 INFO     Training average positive_sample_loss at step 33000: 0.048614\n",
      "2023-12-03 00:50:35,873 INFO     Training average negative_sample_loss at step 33000: 0.018143\n",
      "2023-12-03 00:50:35,873 INFO     Training average loss at step 33000: 0.033378\n",
      "2023-12-03 00:50:41,588 INFO     Training average positive_sample_loss at step 33100: 0.046695\n",
      "2023-12-03 00:50:41,588 INFO     Training average negative_sample_loss at step 33100: 0.018154\n",
      "2023-12-03 00:50:41,588 INFO     Training average loss at step 33100: 0.032424\n",
      "2023-12-03 00:50:47,148 INFO     Training average positive_sample_loss at step 33200: 0.048445\n",
      "2023-12-03 00:50:47,149 INFO     Training average negative_sample_loss at step 33200: 0.018262\n",
      "2023-12-03 00:50:47,149 INFO     Training average loss at step 33200: 0.033353\n",
      "2023-12-03 00:50:53,365 INFO     Training average positive_sample_loss at step 33300: 0.049651\n",
      "2023-12-03 00:50:53,366 INFO     Training average negative_sample_loss at step 33300: 0.018302\n",
      "2023-12-03 00:50:53,366 INFO     Training average loss at step 33300: 0.033977\n",
      "2023-12-03 00:50:59,498 INFO     Training average positive_sample_loss at step 33400: 0.046456\n",
      "2023-12-03 00:50:59,498 INFO     Training average negative_sample_loss at step 33400: 0.018167\n",
      "2023-12-03 00:50:59,498 INFO     Training average loss at step 33400: 0.032312\n",
      "2023-12-03 00:51:05,596 INFO     Training average positive_sample_loss at step 33500: 0.047695\n",
      "2023-12-03 00:51:05,597 INFO     Training average negative_sample_loss at step 33500: 0.017995\n",
      "2023-12-03 00:51:05,597 INFO     Training average loss at step 33500: 0.032845\n",
      "2023-12-03 00:51:11,760 INFO     Training average positive_sample_loss at step 33600: 0.049067\n",
      "2023-12-03 00:51:11,761 INFO     Training average negative_sample_loss at step 33600: 0.018223\n",
      "2023-12-03 00:51:11,761 INFO     Training average loss at step 33600: 0.033645\n",
      "2023-12-03 00:51:18,096 INFO     Training average positive_sample_loss at step 33700: 0.047640\n",
      "2023-12-03 00:51:18,096 INFO     Training average negative_sample_loss at step 33700: 0.018308\n",
      "2023-12-03 00:51:18,096 INFO     Training average loss at step 33700: 0.032974\n",
      "2023-12-03 00:51:24,283 INFO     Training average positive_sample_loss at step 33800: 0.046908\n",
      "2023-12-03 00:51:24,283 INFO     Training average negative_sample_loss at step 33800: 0.018125\n",
      "2023-12-03 00:51:24,284 INFO     Training average loss at step 33800: 0.032517\n",
      "2023-12-03 00:51:29,848 INFO     Training average positive_sample_loss at step 33900: 0.048543\n",
      "2023-12-03 00:51:29,849 INFO     Training average negative_sample_loss at step 33900: 0.018050\n",
      "2023-12-03 00:51:29,849 INFO     Training average loss at step 33900: 0.033297\n",
      "2023-12-03 00:51:36,033 INFO     Training average positive_sample_loss at step 34000: 0.049242\n",
      "2023-12-03 00:51:36,033 INFO     Training average negative_sample_loss at step 34000: 0.018176\n",
      "2023-12-03 00:51:36,034 INFO     Training average loss at step 34000: 0.033709\n",
      "2023-12-03 00:51:42,331 INFO     Training average positive_sample_loss at step 34100: 0.045685\n",
      "2023-12-03 00:51:42,331 INFO     Training average negative_sample_loss at step 34100: 0.018203\n",
      "2023-12-03 00:51:42,331 INFO     Training average loss at step 34100: 0.031944\n",
      "2023-12-03 00:51:48,476 INFO     Training average positive_sample_loss at step 34200: 0.047766\n",
      "2023-12-03 00:51:48,476 INFO     Training average negative_sample_loss at step 34200: 0.018117\n",
      "2023-12-03 00:51:48,476 INFO     Training average loss at step 34200: 0.032942\n",
      "2023-12-03 00:51:54,650 INFO     Training average positive_sample_loss at step 34300: 0.049100\n",
      "2023-12-03 00:51:54,650 INFO     Training average negative_sample_loss at step 34300: 0.018082\n",
      "2023-12-03 00:51:54,650 INFO     Training average loss at step 34300: 0.033591\n",
      "2023-12-03 00:52:00,745 INFO     Training average positive_sample_loss at step 34400: 0.046564\n",
      "2023-12-03 00:52:00,746 INFO     Training average negative_sample_loss at step 34400: 0.018088\n",
      "2023-12-03 00:52:00,746 INFO     Training average loss at step 34400: 0.032326\n",
      "2023-12-03 00:52:06,898 INFO     Training average positive_sample_loss at step 34500: 0.047035\n",
      "2023-12-03 00:52:06,898 INFO     Training average negative_sample_loss at step 34500: 0.017974\n",
      "2023-12-03 00:52:06,898 INFO     Training average loss at step 34500: 0.032505\n",
      "2023-12-03 00:52:13,060 INFO     Training average positive_sample_loss at step 34600: 0.048494\n",
      "2023-12-03 00:52:13,060 INFO     Training average negative_sample_loss at step 34600: 0.018038\n",
      "2023-12-03 00:52:13,060 INFO     Training average loss at step 34600: 0.033266\n",
      "2023-12-03 00:52:19,742 INFO     Training average positive_sample_loss at step 34700: 0.048265\n",
      "2023-12-03 00:52:19,743 INFO     Training average negative_sample_loss at step 34700: 0.018206\n",
      "2023-12-03 00:52:19,743 INFO     Training average loss at step 34700: 0.033236\n",
      "2023-12-03 00:52:25,733 INFO     Training average positive_sample_loss at step 34800: 0.046229\n",
      "2023-12-03 00:52:25,734 INFO     Training average negative_sample_loss at step 34800: 0.018081\n",
      "2023-12-03 00:52:25,734 INFO     Training average loss at step 34800: 0.032155\n",
      "2023-12-03 00:52:31,405 INFO     Training average positive_sample_loss at step 34900: 0.047460\n",
      "2023-12-03 00:52:31,405 INFO     Training average negative_sample_loss at step 34900: 0.017866\n",
      "2023-12-03 00:52:31,405 INFO     Training average loss at step 34900: 0.032663\n",
      "2023-12-03 00:52:37,495 INFO     Training average positive_sample_loss at step 35000: 0.049139\n",
      "2023-12-03 00:52:37,495 INFO     Training average negative_sample_loss at step 35000: 0.018078\n",
      "2023-12-03 00:52:37,495 INFO     Training average loss at step 35000: 0.033608\n",
      "2023-12-03 00:52:43,658 INFO     Training average positive_sample_loss at step 35100: 0.045904\n",
      "2023-12-03 00:52:43,658 INFO     Training average negative_sample_loss at step 35100: 0.018035\n",
      "2023-12-03 00:52:43,658 INFO     Training average loss at step 35100: 0.031970\n",
      "2023-12-03 00:52:49,657 INFO     Training average positive_sample_loss at step 35200: 0.047006\n",
      "2023-12-03 00:52:49,657 INFO     Training average negative_sample_loss at step 35200: 0.017838\n",
      "2023-12-03 00:52:49,657 INFO     Training average loss at step 35200: 0.032422\n",
      "2023-12-03 00:52:55,755 INFO     Training average positive_sample_loss at step 35300: 0.048470\n",
      "2023-12-03 00:52:55,756 INFO     Training average negative_sample_loss at step 35300: 0.018208\n",
      "2023-12-03 00:52:55,756 INFO     Training average loss at step 35300: 0.033339\n",
      "2023-12-03 00:53:02,411 INFO     Training average positive_sample_loss at step 35400: 0.047396\n",
      "2023-12-03 00:53:02,411 INFO     Training average negative_sample_loss at step 35400: 0.018069\n",
      "2023-12-03 00:53:02,411 INFO     Training average loss at step 35400: 0.032732\n",
      "2023-12-03 00:53:08,103 INFO     Training average positive_sample_loss at step 35500: 0.046466\n",
      "2023-12-03 00:53:08,104 INFO     Training average negative_sample_loss at step 35500: 0.018080\n",
      "2023-12-03 00:53:08,104 INFO     Training average loss at step 35500: 0.032273\n",
      "2023-12-03 00:53:14,229 INFO     Training average positive_sample_loss at step 35600: 0.047487\n",
      "2023-12-03 00:53:14,229 INFO     Training average negative_sample_loss at step 35600: 0.017970\n",
      "2023-12-03 00:53:14,229 INFO     Training average loss at step 35600: 0.032728\n",
      "2023-12-03 00:53:20,648 INFO     Training average positive_sample_loss at step 35700: 0.048810\n",
      "2023-12-03 00:53:20,648 INFO     Training average negative_sample_loss at step 35700: 0.017993\n",
      "2023-12-03 00:53:20,648 INFO     Training average loss at step 35700: 0.033402\n",
      "2023-12-03 00:53:27,033 INFO     Training average positive_sample_loss at step 35800: 0.045364\n",
      "2023-12-03 00:53:27,034 INFO     Training average negative_sample_loss at step 35800: 0.017922\n",
      "2023-12-03 00:53:27,034 INFO     Training average loss at step 35800: 0.031643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:53:33,015 INFO     Training average positive_sample_loss at step 35900: 0.047223\n",
      "2023-12-03 00:53:33,016 INFO     Training average negative_sample_loss at step 35900: 0.018021\n",
      "2023-12-03 00:53:33,016 INFO     Training average loss at step 35900: 0.032622\n",
      "2023-12-03 00:53:39,170 INFO     Training average positive_sample_loss at step 36000: 0.048310\n",
      "2023-12-03 00:53:39,171 INFO     Training average negative_sample_loss at step 36000: 0.017969\n",
      "2023-12-03 00:53:39,171 INFO     Training average loss at step 36000: 0.033140\n",
      "2023-12-03 00:53:45,851 INFO     Training average positive_sample_loss at step 36100: 0.046373\n",
      "2023-12-03 00:53:45,852 INFO     Training average negative_sample_loss at step 36100: 0.017818\n",
      "2023-12-03 00:53:45,852 INFO     Training average loss at step 36100: 0.032096\n",
      "2023-12-03 00:53:51,450 INFO     Training average positive_sample_loss at step 36200: 0.046421\n",
      "2023-12-03 00:53:51,451 INFO     Training average negative_sample_loss at step 36200: 0.017961\n",
      "2023-12-03 00:53:51,451 INFO     Training average loss at step 36200: 0.032191\n",
      "2023-12-03 00:53:57,637 INFO     Training average positive_sample_loss at step 36300: 0.047885\n",
      "2023-12-03 00:53:57,637 INFO     Training average negative_sample_loss at step 36300: 0.017848\n",
      "2023-12-03 00:53:57,637 INFO     Training average loss at step 36300: 0.032867\n",
      "2023-12-03 00:54:04,316 INFO     Training average positive_sample_loss at step 36400: 0.047358\n",
      "2023-12-03 00:54:04,316 INFO     Training average negative_sample_loss at step 36400: 0.017883\n",
      "2023-12-03 00:54:04,316 INFO     Training average loss at step 36400: 0.032620\n",
      "2023-12-03 00:54:10,456 INFO     Training average positive_sample_loss at step 36500: 0.045489\n",
      "2023-12-03 00:54:10,457 INFO     Training average negative_sample_loss at step 36500: 0.017863\n",
      "2023-12-03 00:54:10,457 INFO     Training average loss at step 36500: 0.031676\n",
      "2023-12-03 00:54:16,458 INFO     Training average positive_sample_loss at step 36600: 0.047163\n",
      "2023-12-03 00:54:16,458 INFO     Training average negative_sample_loss at step 36600: 0.017815\n",
      "2023-12-03 00:54:16,458 INFO     Training average loss at step 36600: 0.032489\n",
      "2023-12-03 00:54:22,083 INFO     Training average positive_sample_loss at step 36700: 0.048570\n",
      "2023-12-03 00:54:22,083 INFO     Training average negative_sample_loss at step 36700: 0.017916\n",
      "2023-12-03 00:54:22,083 INFO     Training average loss at step 36700: 0.033243\n",
      "2023-12-03 00:54:28,674 INFO     Training average positive_sample_loss at step 36800: 0.045343\n",
      "2023-12-03 00:54:28,674 INFO     Training average negative_sample_loss at step 36800: 0.017871\n",
      "2023-12-03 00:54:28,674 INFO     Training average loss at step 36800: 0.031607\n",
      "2023-12-03 00:54:34,801 INFO     Training average positive_sample_loss at step 36900: 0.046746\n",
      "2023-12-03 00:54:34,801 INFO     Training average negative_sample_loss at step 36900: 0.017813\n",
      "2023-12-03 00:54:34,801 INFO     Training average loss at step 36900: 0.032280\n",
      "2023-12-03 00:54:40,924 INFO     Training average positive_sample_loss at step 37000: 0.048013\n",
      "2023-12-03 00:54:40,924 INFO     Training average negative_sample_loss at step 37000: 0.017926\n",
      "2023-12-03 00:54:40,924 INFO     Training average loss at step 37000: 0.032969\n",
      "2023-12-03 00:54:47,443 INFO     Training average positive_sample_loss at step 37100: 0.046387\n",
      "2023-12-03 00:54:47,444 INFO     Training average negative_sample_loss at step 37100: 0.017782\n",
      "2023-12-03 00:54:47,444 INFO     Training average loss at step 37100: 0.032085\n",
      "2023-12-03 00:54:53,215 INFO     Training average positive_sample_loss at step 37200: 0.045626\n",
      "2023-12-03 00:54:53,216 INFO     Training average negative_sample_loss at step 37200: 0.017691\n",
      "2023-12-03 00:54:53,216 INFO     Training average loss at step 37200: 0.031659\n",
      "2023-12-03 00:54:59,359 INFO     Training average positive_sample_loss at step 37300: 0.047643\n",
      "2023-12-03 00:54:59,359 INFO     Training average negative_sample_loss at step 37300: 0.017947\n",
      "2023-12-03 00:54:59,359 INFO     Training average loss at step 37300: 0.032795\n",
      "2023-12-03 00:55:05,523 INFO     Training average positive_sample_loss at step 37400: 0.048160\n",
      "2023-12-03 00:55:05,524 INFO     Training average negative_sample_loss at step 37400: 0.017849\n",
      "2023-12-03 00:55:05,524 INFO     Training average loss at step 37400: 0.033005\n",
      "2023-12-03 00:55:11,910 INFO     Training average positive_sample_loss at step 37500: 0.044627\n",
      "2023-12-03 00:55:11,910 INFO     Training average negative_sample_loss at step 37500: 0.017818\n",
      "2023-12-03 00:55:11,911 INFO     Training average loss at step 37500: 0.031222\n",
      "2023-12-03 00:55:18,019 INFO     Training average positive_sample_loss at step 37600: 0.046817\n",
      "2023-12-03 00:55:18,020 INFO     Training average negative_sample_loss at step 37600: 0.017725\n",
      "2023-12-03 00:55:18,020 INFO     Training average loss at step 37600: 0.032271\n",
      "2023-12-03 00:55:23,762 INFO     Training average positive_sample_loss at step 37700: 0.047912\n",
      "2023-12-03 00:55:23,762 INFO     Training average negative_sample_loss at step 37700: 0.017745\n",
      "2023-12-03 00:55:23,762 INFO     Training average loss at step 37700: 0.032829\n",
      "2023-12-03 00:55:30,405 INFO     Training average positive_sample_loss at step 37800: 0.045613\n",
      "2023-12-03 00:55:30,405 INFO     Training average negative_sample_loss at step 37800: 0.017563\n",
      "2023-12-03 00:55:30,405 INFO     Training average loss at step 37800: 0.031588\n",
      "2023-12-03 00:55:36,498 INFO     Training average positive_sample_loss at step 37900: 0.046199\n",
      "2023-12-03 00:55:36,498 INFO     Training average negative_sample_loss at step 37900: 0.017737\n",
      "2023-12-03 00:55:36,498 INFO     Training average loss at step 37900: 0.031968\n",
      "2023-12-03 00:55:42,356 INFO     Training average positive_sample_loss at step 38000: 0.047531\n",
      "2023-12-03 00:55:42,356 INFO     Training average negative_sample_loss at step 38000: 0.017682\n",
      "2023-12-03 00:55:42,356 INFO     Training average loss at step 38000: 0.032607\n",
      "2023-12-03 00:55:48,730 INFO     Training average positive_sample_loss at step 38100: 0.046855\n",
      "2023-12-03 00:55:48,731 INFO     Training average negative_sample_loss at step 38100: 0.017810\n",
      "2023-12-03 00:55:48,731 INFO     Training average loss at step 38100: 0.032333\n",
      "2023-12-03 00:55:54,453 INFO     Training average positive_sample_loss at step 38200: 0.045076\n",
      "2023-12-03 00:55:54,453 INFO     Training average negative_sample_loss at step 38200: 0.017718\n",
      "2023-12-03 00:55:54,453 INFO     Training average loss at step 38200: 0.031397\n",
      "2023-12-03 00:56:00,561 INFO     Training average positive_sample_loss at step 38300: 0.046941\n",
      "2023-12-03 00:56:00,561 INFO     Training average negative_sample_loss at step 38300: 0.017752\n",
      "2023-12-03 00:56:00,561 INFO     Training average loss at step 38300: 0.032347\n",
      "2023-12-03 00:56:06,451 INFO     Training average positive_sample_loss at step 38400: 0.047663\n",
      "2023-12-03 00:56:06,451 INFO     Training average negative_sample_loss at step 38400: 0.017730\n",
      "2023-12-03 00:56:06,451 INFO     Training average loss at step 38400: 0.032697\n",
      "2023-12-03 00:56:12,909 INFO     Training average positive_sample_loss at step 38500: 0.044970\n",
      "2023-12-03 00:56:12,910 INFO     Training average negative_sample_loss at step 38500: 0.017784\n",
      "2023-12-03 00:56:12,910 INFO     Training average loss at step 38500: 0.031377\n",
      "2023-12-03 00:56:19,071 INFO     Training average positive_sample_loss at step 38600: 0.046414\n",
      "2023-12-03 00:56:19,072 INFO     Training average negative_sample_loss at step 38600: 0.017668\n",
      "2023-12-03 00:56:19,072 INFO     Training average loss at step 38600: 0.032041\n",
      "2023-12-03 00:56:25,023 INFO     Training average positive_sample_loss at step 38700: 0.047254\n",
      "2023-12-03 00:56:25,023 INFO     Training average negative_sample_loss at step 38700: 0.017665\n",
      "2023-12-03 00:56:25,023 INFO     Training average loss at step 38700: 0.032460\n",
      "2023-12-03 00:56:31,429 INFO     Training average positive_sample_loss at step 38800: 0.046114\n",
      "2023-12-03 00:56:31,429 INFO     Training average negative_sample_loss at step 38800: 0.017799\n",
      "2023-12-03 00:56:31,430 INFO     Training average loss at step 38800: 0.031956\n",
      "2023-12-03 00:56:37,306 INFO     Training average positive_sample_loss at step 38900: 0.045382\n",
      "2023-12-03 00:56:37,306 INFO     Training average negative_sample_loss at step 38900: 0.017603\n",
      "2023-12-03 00:56:37,306 INFO     Training average loss at step 38900: 0.031493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 00:56:43,426 INFO     Training average positive_sample_loss at step 39000: 0.046814\n",
      "2023-12-03 00:56:43,426 INFO     Training average negative_sample_loss at step 39000: 0.017670\n",
      "2023-12-03 00:56:43,426 INFO     Training average loss at step 39000: 0.032242\n",
      "2023-12-03 00:56:49,862 INFO     Training average positive_sample_loss at step 39100: 0.047826\n",
      "2023-12-03 00:56:49,862 INFO     Training average negative_sample_loss at step 39100: 0.017725\n",
      "2023-12-03 00:56:49,862 INFO     Training average loss at step 39100: 0.032775\n",
      "2023-12-03 00:56:56,273 INFO     Training average positive_sample_loss at step 39200: 0.044339\n",
      "2023-12-03 00:56:56,273 INFO     Training average negative_sample_loss at step 39200: 0.017558\n",
      "2023-12-03 00:56:56,273 INFO     Training average loss at step 39200: 0.030948\n",
      "2023-12-03 00:57:01,818 INFO     Training average positive_sample_loss at step 39300: 0.046419\n",
      "2023-12-03 00:57:01,819 INFO     Training average negative_sample_loss at step 39300: 0.017579\n",
      "2023-12-03 00:57:01,819 INFO     Training average loss at step 39300: 0.031999\n",
      "2023-12-03 00:57:07,942 INFO     Training average positive_sample_loss at step 39400: 0.047101\n",
      "2023-12-03 00:57:07,943 INFO     Training average negative_sample_loss at step 39400: 0.017722\n",
      "2023-12-03 00:57:07,943 INFO     Training average loss at step 39400: 0.032411\n",
      "2023-12-03 00:57:14,603 INFO     Training average positive_sample_loss at step 39500: 0.045350\n",
      "2023-12-03 00:57:14,603 INFO     Training average negative_sample_loss at step 39500: 0.017662\n",
      "2023-12-03 00:57:14,604 INFO     Training average loss at step 39500: 0.031506\n",
      "2023-12-03 00:57:20,893 INFO     Training average positive_sample_loss at step 39600: 0.045708\n",
      "2023-12-03 00:57:20,893 INFO     Training average negative_sample_loss at step 39600: 0.017754\n",
      "2023-12-03 00:57:20,893 INFO     Training average loss at step 39600: 0.031731\n",
      "2023-12-03 00:57:27,109 INFO     Training average positive_sample_loss at step 39700: 0.047039\n",
      "2023-12-03 00:57:27,109 INFO     Training average negative_sample_loss at step 39700: 0.017673\n",
      "2023-12-03 00:57:27,109 INFO     Training average loss at step 39700: 0.032356\n",
      "2023-12-03 00:57:33,476 INFO     Training average positive_sample_loss at step 39800: 0.046840\n",
      "2023-12-03 00:57:33,476 INFO     Training average negative_sample_loss at step 39800: 0.017665\n",
      "2023-12-03 00:57:33,476 INFO     Training average loss at step 39800: 0.032253\n",
      "2023-12-03 00:57:38,939 INFO     Training average positive_sample_loss at step 39900: 0.044638\n",
      "2023-12-03 00:57:38,939 INFO     Training average negative_sample_loss at step 39900: 0.017845\n",
      "2023-12-03 00:57:38,939 INFO     Training average loss at step 39900: 0.031242\n",
      "2023-12-03 00:57:45,042 INFO     Change learning_rate to 0.000005 at step 40000\n",
      "2023-12-03 00:57:51,386 INFO     Training average positive_sample_loss at step 40000: 0.046326\n",
      "2023-12-03 00:57:51,386 INFO     Training average negative_sample_loss at step 40000: 0.017591\n",
      "2023-12-03 00:57:51,386 INFO     Training average loss at step 40000: 0.031959\n",
      "2023-12-03 00:57:51,386 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 00:57:51,951 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 00:58:23,067 INFO     Valid MRR at step 40000: 0.479155\n",
      "2023-12-03 00:58:23,067 INFO     Valid MR at step 40000: 3378.622610\n",
      "2023-12-03 00:58:23,068 INFO     Valid HITS@1 at step 40000: 0.435399\n",
      "2023-12-03 00:58:23,068 INFO     Valid HITS@3 at step 40000: 0.490606\n",
      "2023-12-03 00:58:23,068 INFO     Valid HITS@10 at step 40000: 0.569380\n",
      "2023-12-03 00:58:29,207 INFO     Training average positive_sample_loss at step 40100: 0.047603\n",
      "2023-12-03 00:58:29,208 INFO     Training average negative_sample_loss at step 40100: 0.016979\n",
      "2023-12-03 00:58:29,208 INFO     Training average loss at step 40100: 0.032291\n",
      "2023-12-03 00:58:35,845 INFO     Training average positive_sample_loss at step 40200: 0.044077\n",
      "2023-12-03 00:58:35,845 INFO     Training average negative_sample_loss at step 40200: 0.016820\n",
      "2023-12-03 00:58:35,845 INFO     Training average loss at step 40200: 0.030449\n",
      "2023-12-03 00:58:41,946 INFO     Training average positive_sample_loss at step 40300: 0.043578\n",
      "2023-12-03 00:58:41,946 INFO     Training average negative_sample_loss at step 40300: 0.016843\n",
      "2023-12-03 00:58:41,946 INFO     Training average loss at step 40300: 0.030211\n",
      "2023-12-03 00:58:48,061 INFO     Training average positive_sample_loss at step 40400: 0.043509\n",
      "2023-12-03 00:58:48,062 INFO     Training average negative_sample_loss at step 40400: 0.016663\n",
      "2023-12-03 00:58:48,062 INFO     Training average loss at step 40400: 0.030086\n",
      "2023-12-03 00:58:54,265 INFO     Training average positive_sample_loss at step 40500: 0.043309\n",
      "2023-12-03 00:58:54,266 INFO     Training average negative_sample_loss at step 40500: 0.016788\n",
      "2023-12-03 00:58:54,266 INFO     Training average loss at step 40500: 0.030048\n",
      "2023-12-03 00:59:00,262 INFO     Training average positive_sample_loss at step 40600: 0.042409\n",
      "2023-12-03 00:59:00,262 INFO     Training average negative_sample_loss at step 40600: 0.016847\n",
      "2023-12-03 00:59:00,262 INFO     Training average loss at step 40600: 0.029628\n",
      "2023-12-03 00:59:06,454 INFO     Training average positive_sample_loss at step 40700: 0.042267\n",
      "2023-12-03 00:59:06,454 INFO     Training average negative_sample_loss at step 40700: 0.016797\n",
      "2023-12-03 00:59:06,454 INFO     Training average loss at step 40700: 0.029532\n",
      "2023-12-03 00:59:12,911 INFO     Training average positive_sample_loss at step 40800: 0.042840\n",
      "2023-12-03 00:59:12,911 INFO     Training average negative_sample_loss at step 40800: 0.016790\n",
      "2023-12-03 00:59:12,911 INFO     Training average loss at step 40800: 0.029815\n",
      "2023-12-03 00:59:19,117 INFO     Training average positive_sample_loss at step 40900: 0.041897\n",
      "2023-12-03 00:59:19,118 INFO     Training average negative_sample_loss at step 40900: 0.016908\n",
      "2023-12-03 00:59:19,119 INFO     Training average loss at step 40900: 0.029402\n",
      "2023-12-03 00:59:25,237 INFO     Training average positive_sample_loss at step 41000: 0.041851\n",
      "2023-12-03 00:59:25,237 INFO     Training average negative_sample_loss at step 41000: 0.016694\n",
      "2023-12-03 00:59:25,237 INFO     Training average loss at step 41000: 0.029272\n",
      "2023-12-03 00:59:30,964 INFO     Training average positive_sample_loss at step 41100: 0.042214\n",
      "2023-12-03 00:59:30,965 INFO     Training average negative_sample_loss at step 41100: 0.016771\n",
      "2023-12-03 00:59:30,965 INFO     Training average loss at step 41100: 0.029493\n",
      "2023-12-03 00:59:37,589 INFO     Training average positive_sample_loss at step 41200: 0.041865\n",
      "2023-12-03 00:59:37,589 INFO     Training average negative_sample_loss at step 41200: 0.016765\n",
      "2023-12-03 00:59:37,589 INFO     Training average loss at step 41200: 0.029315\n",
      "2023-12-03 00:59:43,723 INFO     Training average positive_sample_loss at step 41300: 0.041509\n",
      "2023-12-03 00:59:43,724 INFO     Training average negative_sample_loss at step 41300: 0.016843\n",
      "2023-12-03 00:59:43,724 INFO     Training average loss at step 41300: 0.029176\n",
      "2023-12-03 00:59:49,786 INFO     Training average positive_sample_loss at step 41400: 0.041836\n",
      "2023-12-03 00:59:49,786 INFO     Training average negative_sample_loss at step 41400: 0.016828\n",
      "2023-12-03 00:59:49,786 INFO     Training average loss at step 41400: 0.029332\n",
      "2023-12-03 00:59:56,170 INFO     Training average positive_sample_loss at step 41500: 0.041829\n",
      "2023-12-03 00:59:56,170 INFO     Training average negative_sample_loss at step 41500: 0.016826\n",
      "2023-12-03 00:59:56,170 INFO     Training average loss at step 41500: 0.029328\n",
      "2023-12-03 01:00:01,876 INFO     Training average positive_sample_loss at step 41600: 0.041083\n",
      "2023-12-03 01:00:01,876 INFO     Training average negative_sample_loss at step 41600: 0.016863\n",
      "2023-12-03 01:00:01,876 INFO     Training average loss at step 41600: 0.028973\n",
      "2023-12-03 01:00:07,996 INFO     Training average positive_sample_loss at step 41700: 0.041671\n",
      "2023-12-03 01:00:07,996 INFO     Training average negative_sample_loss at step 41700: 0.016819\n",
      "2023-12-03 01:00:07,996 INFO     Training average loss at step 41700: 0.029245\n",
      "2023-12-03 01:00:14,076 INFO     Training average positive_sample_loss at step 41800: 0.041834\n",
      "2023-12-03 01:00:14,076 INFO     Training average negative_sample_loss at step 41800: 0.016690\n",
      "2023-12-03 01:00:14,076 INFO     Training average loss at step 41800: 0.029262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:00:20,727 INFO     Training average positive_sample_loss at step 41900: 0.041306\n",
      "2023-12-03 01:00:20,728 INFO     Training average negative_sample_loss at step 41900: 0.016850\n",
      "2023-12-03 01:00:20,728 INFO     Training average loss at step 41900: 0.029078\n",
      "2023-12-03 01:00:26,614 INFO     Training average positive_sample_loss at step 42000: 0.041491\n",
      "2023-12-03 01:00:26,614 INFO     Training average negative_sample_loss at step 42000: 0.017023\n",
      "2023-12-03 01:00:26,614 INFO     Training average loss at step 42000: 0.029257\n",
      "2023-12-03 01:00:32,560 INFO     Training average positive_sample_loss at step 42100: 0.041302\n",
      "2023-12-03 01:00:32,561 INFO     Training average negative_sample_loss at step 42100: 0.016841\n",
      "2023-12-03 01:00:32,561 INFO     Training average loss at step 42100: 0.029072\n",
      "2023-12-03 01:00:38,972 INFO     Training average positive_sample_loss at step 42200: 0.041283\n",
      "2023-12-03 01:00:38,973 INFO     Training average negative_sample_loss at step 42200: 0.016880\n",
      "2023-12-03 01:00:38,973 INFO     Training average loss at step 42200: 0.029082\n",
      "2023-12-03 01:00:45,135 INFO     Training average positive_sample_loss at step 42300: 0.040942\n",
      "2023-12-03 01:00:45,135 INFO     Training average negative_sample_loss at step 42300: 0.016930\n",
      "2023-12-03 01:00:45,135 INFO     Training average loss at step 42300: 0.028936\n",
      "2023-12-03 01:00:51,183 INFO     Training average positive_sample_loss at step 42400: 0.041254\n",
      "2023-12-03 01:00:51,183 INFO     Training average negative_sample_loss at step 42400: 0.016918\n",
      "2023-12-03 01:00:51,183 INFO     Training average loss at step 42400: 0.029086\n",
      "2023-12-03 01:00:57,442 INFO     Training average positive_sample_loss at step 42500: 0.041758\n",
      "2023-12-03 01:00:57,443 INFO     Training average negative_sample_loss at step 42500: 0.016662\n",
      "2023-12-03 01:00:57,443 INFO     Training average loss at step 42500: 0.029210\n",
      "2023-12-03 01:01:03,731 INFO     Training average positive_sample_loss at step 42600: 0.040813\n",
      "2023-12-03 01:01:03,731 INFO     Training average negative_sample_loss at step 42600: 0.016839\n",
      "2023-12-03 01:01:03,731 INFO     Training average loss at step 42600: 0.028826\n",
      "2023-12-03 01:01:09,454 INFO     Training average positive_sample_loss at step 42700: 0.041229\n",
      "2023-12-03 01:01:09,454 INFO     Training average negative_sample_loss at step 42700: 0.016815\n",
      "2023-12-03 01:01:09,454 INFO     Training average loss at step 42700: 0.029022\n",
      "2023-12-03 01:01:15,573 INFO     Training average positive_sample_loss at step 42800: 0.041384\n",
      "2023-12-03 01:01:15,574 INFO     Training average negative_sample_loss at step 42800: 0.016645\n",
      "2023-12-03 01:01:15,574 INFO     Training average loss at step 42800: 0.029014\n",
      "2023-12-03 01:01:21,864 INFO     Training average positive_sample_loss at step 42900: 0.040973\n",
      "2023-12-03 01:01:21,865 INFO     Training average negative_sample_loss at step 42900: 0.016887\n",
      "2023-12-03 01:01:21,865 INFO     Training average loss at step 42900: 0.028930\n",
      "2023-12-03 01:01:28,017 INFO     Training average positive_sample_loss at step 43000: 0.040846\n",
      "2023-12-03 01:01:28,018 INFO     Training average negative_sample_loss at step 43000: 0.016902\n",
      "2023-12-03 01:01:28,018 INFO     Training average loss at step 43000: 0.028874\n",
      "2023-12-03 01:01:33,910 INFO     Training average positive_sample_loss at step 43100: 0.041280\n",
      "2023-12-03 01:01:33,910 INFO     Training average negative_sample_loss at step 43100: 0.016819\n",
      "2023-12-03 01:01:33,910 INFO     Training average loss at step 43100: 0.029049\n",
      "2023-12-03 01:01:40,162 INFO     Training average positive_sample_loss at step 43200: 0.041390\n",
      "2023-12-03 01:01:40,162 INFO     Training average negative_sample_loss at step 43200: 0.016863\n",
      "2023-12-03 01:01:40,162 INFO     Training average loss at step 43200: 0.029126\n",
      "2023-12-03 01:01:46,271 INFO     Training average positive_sample_loss at step 43300: 0.040869\n",
      "2023-12-03 01:01:46,271 INFO     Training average negative_sample_loss at step 43300: 0.016853\n",
      "2023-12-03 01:01:46,271 INFO     Training average loss at step 43300: 0.028861\n",
      "2023-12-03 01:01:52,352 INFO     Training average positive_sample_loss at step 43400: 0.041018\n",
      "2023-12-03 01:01:52,353 INFO     Training average negative_sample_loss at step 43400: 0.016899\n",
      "2023-12-03 01:01:52,353 INFO     Training average loss at step 43400: 0.028959\n",
      "2023-12-03 01:01:58,455 INFO     Training average positive_sample_loss at step 43500: 0.041368\n",
      "2023-12-03 01:01:58,455 INFO     Training average negative_sample_loss at step 43500: 0.016731\n",
      "2023-12-03 01:01:58,455 INFO     Training average loss at step 43500: 0.029049\n",
      "2023-12-03 01:02:05,104 INFO     Training average positive_sample_loss at step 43600: 0.040725\n",
      "2023-12-03 01:02:05,105 INFO     Training average negative_sample_loss at step 43600: 0.016975\n",
      "2023-12-03 01:02:05,105 INFO     Training average loss at step 43600: 0.028850\n",
      "2023-12-03 01:02:10,988 INFO     Training average positive_sample_loss at step 43700: 0.041061\n",
      "2023-12-03 01:02:10,989 INFO     Training average negative_sample_loss at step 43700: 0.016782\n",
      "2023-12-03 01:02:10,989 INFO     Training average loss at step 43700: 0.028922\n",
      "2023-12-03 01:02:16,745 INFO     Training average positive_sample_loss at step 43800: 0.041305\n",
      "2023-12-03 01:02:16,746 INFO     Training average negative_sample_loss at step 43800: 0.016734\n",
      "2023-12-03 01:02:16,746 INFO     Training average loss at step 43800: 0.029020\n",
      "2023-12-03 01:02:23,392 INFO     Training average positive_sample_loss at step 43900: 0.040695\n",
      "2023-12-03 01:02:23,392 INFO     Training average negative_sample_loss at step 43900: 0.016741\n",
      "2023-12-03 01:02:23,392 INFO     Training average loss at step 43900: 0.028718\n",
      "2023-12-03 01:02:29,520 INFO     Training average positive_sample_loss at step 44000: 0.040910\n",
      "2023-12-03 01:02:29,521 INFO     Training average negative_sample_loss at step 44000: 0.016845\n",
      "2023-12-03 01:02:29,521 INFO     Training average loss at step 44000: 0.028878\n",
      "2023-12-03 01:02:35,626 INFO     Training average positive_sample_loss at step 44100: 0.040939\n",
      "2023-12-03 01:02:35,626 INFO     Training average negative_sample_loss at step 44100: 0.016793\n",
      "2023-12-03 01:02:35,626 INFO     Training average loss at step 44100: 0.028866\n",
      "2023-12-03 01:02:41,431 INFO     Training average positive_sample_loss at step 44200: 0.041283\n",
      "2023-12-03 01:02:41,431 INFO     Training average negative_sample_loss at step 44200: 0.016642\n",
      "2023-12-03 01:02:41,431 INFO     Training average loss at step 44200: 0.028962\n",
      "2023-12-03 01:02:47,317 INFO     Training average positive_sample_loss at step 44300: 0.040629\n",
      "2023-12-03 01:02:47,318 INFO     Training average negative_sample_loss at step 44300: 0.016723\n",
      "2023-12-03 01:02:47,318 INFO     Training average loss at step 44300: 0.028676\n",
      "2023-12-03 01:02:53,418 INFO     Training average positive_sample_loss at step 44400: 0.040737\n",
      "2023-12-03 01:02:53,418 INFO     Training average negative_sample_loss at step 44400: 0.016639\n",
      "2023-12-03 01:02:53,418 INFO     Training average loss at step 44400: 0.028688\n",
      "2023-12-03 01:02:59,546 INFO     Training average positive_sample_loss at step 44500: 0.041333\n",
      "2023-12-03 01:02:59,546 INFO     Training average negative_sample_loss at step 44500: 0.016796\n",
      "2023-12-03 01:02:59,547 INFO     Training average loss at step 44500: 0.029065\n",
      "2023-12-03 01:03:06,180 INFO     Training average positive_sample_loss at step 44600: 0.040879\n",
      "2023-12-03 01:03:06,180 INFO     Training average negative_sample_loss at step 44600: 0.016609\n",
      "2023-12-03 01:03:06,180 INFO     Training average loss at step 44600: 0.028744\n",
      "2023-12-03 01:03:11,767 INFO     Training average positive_sample_loss at step 44700: 0.040761\n",
      "2023-12-03 01:03:11,768 INFO     Training average negative_sample_loss at step 44700: 0.016825\n",
      "2023-12-03 01:03:11,768 INFO     Training average loss at step 44700: 0.028793\n",
      "2023-12-03 01:03:17,917 INFO     Training average positive_sample_loss at step 44800: 0.041043\n",
      "2023-12-03 01:03:17,918 INFO     Training average negative_sample_loss at step 44800: 0.016697\n",
      "2023-12-03 01:03:17,918 INFO     Training average loss at step 44800: 0.028870\n",
      "2023-12-03 01:03:24,656 INFO     Training average positive_sample_loss at step 44900: 0.041087\n",
      "2023-12-03 01:03:24,656 INFO     Training average negative_sample_loss at step 44900: 0.016661\n",
      "2023-12-03 01:03:24,656 INFO     Training average loss at step 44900: 0.028874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:03:30,773 INFO     Training average positive_sample_loss at step 45000: 0.040686\n",
      "2023-12-03 01:03:30,773 INFO     Training average negative_sample_loss at step 45000: 0.016814\n",
      "2023-12-03 01:03:30,773 INFO     Training average loss at step 45000: 0.028750\n",
      "2023-12-03 01:03:36,901 INFO     Training average positive_sample_loss at step 45100: 0.040974\n",
      "2023-12-03 01:03:36,901 INFO     Training average negative_sample_loss at step 45100: 0.016567\n",
      "2023-12-03 01:03:36,901 INFO     Training average loss at step 45100: 0.028771\n",
      "2023-12-03 01:03:42,598 INFO     Training average positive_sample_loss at step 45200: 0.040969\n",
      "2023-12-03 01:03:42,599 INFO     Training average negative_sample_loss at step 45200: 0.016695\n",
      "2023-12-03 01:03:42,599 INFO     Training average loss at step 45200: 0.028832\n",
      "2023-12-03 01:03:49,288 INFO     Training average positive_sample_loss at step 45300: 0.040896\n",
      "2023-12-03 01:03:49,288 INFO     Training average negative_sample_loss at step 45300: 0.016689\n",
      "2023-12-03 01:03:49,288 INFO     Training average loss at step 45300: 0.028792\n",
      "2023-12-03 01:03:55,265 INFO     Training average positive_sample_loss at step 45400: 0.040697\n",
      "2023-12-03 01:03:55,265 INFO     Training average negative_sample_loss at step 45400: 0.016659\n",
      "2023-12-03 01:03:55,265 INFO     Training average loss at step 45400: 0.028678\n",
      "2023-12-03 01:04:01,584 INFO     Training average positive_sample_loss at step 45500: 0.040980\n",
      "2023-12-03 01:04:01,584 INFO     Training average negative_sample_loss at step 45500: 0.016770\n",
      "2023-12-03 01:04:01,584 INFO     Training average loss at step 45500: 0.028875\n",
      "2023-12-03 01:04:08,201 INFO     Training average positive_sample_loss at step 45600: 0.041003\n",
      "2023-12-03 01:04:08,202 INFO     Training average negative_sample_loss at step 45600: 0.016637\n",
      "2023-12-03 01:04:08,202 INFO     Training average loss at step 45600: 0.028820\n",
      "2023-12-03 01:04:14,377 INFO     Training average positive_sample_loss at step 45700: 0.040680\n",
      "2023-12-03 01:04:14,377 INFO     Training average negative_sample_loss at step 45700: 0.016718\n",
      "2023-12-03 01:04:14,377 INFO     Training average loss at step 45700: 0.028699\n",
      "2023-12-03 01:04:19,951 INFO     Training average positive_sample_loss at step 45800: 0.040933\n",
      "2023-12-03 01:04:19,951 INFO     Training average negative_sample_loss at step 45800: 0.016769\n",
      "2023-12-03 01:04:19,951 INFO     Training average loss at step 45800: 0.028851\n",
      "2023-12-03 01:04:26,368 INFO     Training average positive_sample_loss at step 45900: 0.041046\n",
      "2023-12-03 01:04:26,369 INFO     Training average negative_sample_loss at step 45900: 0.016523\n",
      "2023-12-03 01:04:26,369 INFO     Training average loss at step 45900: 0.028784\n",
      "2023-12-03 01:04:32,749 INFO     Training average positive_sample_loss at step 46000: 0.040486\n",
      "2023-12-03 01:04:32,750 INFO     Training average negative_sample_loss at step 46000: 0.016726\n",
      "2023-12-03 01:04:32,750 INFO     Training average loss at step 46000: 0.028606\n",
      "2023-12-03 01:04:39,071 INFO     Training average positive_sample_loss at step 46100: 0.040757\n",
      "2023-12-03 01:04:39,072 INFO     Training average negative_sample_loss at step 46100: 0.016699\n",
      "2023-12-03 01:04:39,072 INFO     Training average loss at step 46100: 0.028728\n",
      "2023-12-03 01:04:45,253 INFO     Training average positive_sample_loss at step 46200: 0.041034\n",
      "2023-12-03 01:04:45,254 INFO     Training average negative_sample_loss at step 46200: 0.016632\n",
      "2023-12-03 01:04:45,254 INFO     Training average loss at step 46200: 0.028833\n",
      "2023-12-03 01:04:51,932 INFO     Training average positive_sample_loss at step 46300: 0.040798\n",
      "2023-12-03 01:04:51,932 INFO     Training average negative_sample_loss at step 46300: 0.016765\n",
      "2023-12-03 01:04:51,932 INFO     Training average loss at step 46300: 0.028781\n",
      "2023-12-03 01:04:57,682 INFO     Training average positive_sample_loss at step 46400: 0.040852\n",
      "2023-12-03 01:04:57,683 INFO     Training average negative_sample_loss at step 46400: 0.016509\n",
      "2023-12-03 01:04:57,683 INFO     Training average loss at step 46400: 0.028680\n",
      "2023-12-03 01:05:03,881 INFO     Training average positive_sample_loss at step 46500: 0.040957\n",
      "2023-12-03 01:05:03,881 INFO     Training average negative_sample_loss at step 46500: 0.016697\n",
      "2023-12-03 01:05:03,881 INFO     Training average loss at step 46500: 0.028827\n",
      "2023-12-03 01:05:10,483 INFO     Training average positive_sample_loss at step 46600: 0.041006\n",
      "2023-12-03 01:05:10,484 INFO     Training average negative_sample_loss at step 46600: 0.016563\n",
      "2023-12-03 01:05:10,484 INFO     Training average loss at step 46600: 0.028785\n",
      "2023-12-03 01:05:16,582 INFO     Training average positive_sample_loss at step 46700: 0.040634\n",
      "2023-12-03 01:05:16,582 INFO     Training average negative_sample_loss at step 46700: 0.016714\n",
      "2023-12-03 01:05:16,582 INFO     Training average loss at step 46700: 0.028674\n",
      "2023-12-03 01:05:22,694 INFO     Training average positive_sample_loss at step 46800: 0.040889\n",
      "2023-12-03 01:05:22,694 INFO     Training average negative_sample_loss at step 46800: 0.016578\n",
      "2023-12-03 01:05:22,694 INFO     Training average loss at step 46800: 0.028734\n",
      "2023-12-03 01:05:28,314 INFO     Training average positive_sample_loss at step 46900: 0.040888\n",
      "2023-12-03 01:05:28,314 INFO     Training average negative_sample_loss at step 46900: 0.016603\n",
      "2023-12-03 01:05:28,314 INFO     Training average loss at step 46900: 0.028746\n",
      "2023-12-03 01:05:34,488 INFO     Training average positive_sample_loss at step 47000: 0.040661\n",
      "2023-12-03 01:05:34,489 INFO     Training average negative_sample_loss at step 47000: 0.016527\n",
      "2023-12-03 01:05:34,489 INFO     Training average loss at step 47000: 0.028594\n",
      "2023-12-03 01:05:40,607 INFO     Training average positive_sample_loss at step 47100: 0.040821\n",
      "2023-12-03 01:05:40,607 INFO     Training average negative_sample_loss at step 47100: 0.016732\n",
      "2023-12-03 01:05:40,607 INFO     Training average loss at step 47100: 0.028776\n",
      "2023-12-03 01:05:46,288 INFO     Training average positive_sample_loss at step 47200: 0.040812\n",
      "2023-12-03 01:05:46,289 INFO     Training average negative_sample_loss at step 47200: 0.016557\n",
      "2023-12-03 01:05:46,289 INFO     Training average loss at step 47200: 0.028684\n",
      "2023-12-03 01:05:52,789 INFO     Training average positive_sample_loss at step 47300: 0.041020\n",
      "2023-12-03 01:05:52,789 INFO     Training average negative_sample_loss at step 47300: 0.016711\n",
      "2023-12-03 01:05:52,789 INFO     Training average loss at step 47300: 0.028866\n",
      "2023-12-03 01:05:58,979 INFO     Training average positive_sample_loss at step 47400: 0.040599\n",
      "2023-12-03 01:05:58,980 INFO     Training average negative_sample_loss at step 47400: 0.016617\n",
      "2023-12-03 01:05:58,980 INFO     Training average loss at step 47400: 0.028608\n",
      "2023-12-03 01:06:05,127 INFO     Training average positive_sample_loss at step 47500: 0.040911\n",
      "2023-12-03 01:06:05,130 INFO     Training average negative_sample_loss at step 47500: 0.016559\n",
      "2023-12-03 01:06:05,130 INFO     Training average loss at step 47500: 0.028735\n",
      "2023-12-03 01:06:11,548 INFO     Training average positive_sample_loss at step 47600: 0.041011\n",
      "2023-12-03 01:06:11,549 INFO     Training average negative_sample_loss at step 47600: 0.016642\n",
      "2023-12-03 01:06:11,549 INFO     Training average loss at step 47600: 0.028826\n",
      "2023-12-03 01:06:17,939 INFO     Training average positive_sample_loss at step 47700: 0.040546\n",
      "2023-12-03 01:06:17,940 INFO     Training average negative_sample_loss at step 47700: 0.016581\n",
      "2023-12-03 01:06:17,940 INFO     Training average loss at step 47700: 0.028564\n",
      "2023-12-03 01:06:23,452 INFO     Training average positive_sample_loss at step 47800: 0.040924\n",
      "2023-12-03 01:06:23,453 INFO     Training average negative_sample_loss at step 47800: 0.016510\n",
      "2023-12-03 01:06:23,453 INFO     Training average loss at step 47800: 0.028717\n",
      "2023-12-03 01:06:29,607 INFO     Training average positive_sample_loss at step 47900: 0.040975\n",
      "2023-12-03 01:06:29,608 INFO     Training average negative_sample_loss at step 47900: 0.016665\n",
      "2023-12-03 01:06:29,608 INFO     Training average loss at step 47900: 0.028820\n",
      "2023-12-03 01:06:36,349 INFO     Training average positive_sample_loss at step 48000: 0.040702\n",
      "2023-12-03 01:06:36,349 INFO     Training average negative_sample_loss at step 48000: 0.016501\n",
      "2023-12-03 01:06:36,349 INFO     Training average loss at step 48000: 0.028602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:06:42,504 INFO     Training average positive_sample_loss at step 48100: 0.040797\n",
      "2023-12-03 01:06:42,504 INFO     Training average negative_sample_loss at step 48100: 0.016576\n",
      "2023-12-03 01:06:42,504 INFO     Training average loss at step 48100: 0.028686\n",
      "2023-12-03 01:06:47,930 INFO     Training average positive_sample_loss at step 48200: 0.040797\n",
      "2023-12-03 01:06:47,930 INFO     Training average negative_sample_loss at step 48200: 0.016659\n",
      "2023-12-03 01:06:47,930 INFO     Training average loss at step 48200: 0.028728\n",
      "2023-12-03 01:06:54,514 INFO     Training average positive_sample_loss at step 48300: 0.040827\n",
      "2023-12-03 01:06:54,515 INFO     Training average negative_sample_loss at step 48300: 0.016533\n",
      "2023-12-03 01:06:54,515 INFO     Training average loss at step 48300: 0.028680\n",
      "2023-12-03 01:07:00,597 INFO     Training average positive_sample_loss at step 48400: 0.040402\n",
      "2023-12-03 01:07:00,597 INFO     Training average negative_sample_loss at step 48400: 0.016518\n",
      "2023-12-03 01:07:00,597 INFO     Training average loss at step 48400: 0.028460\n",
      "2023-12-03 01:07:06,677 INFO     Training average positive_sample_loss at step 48500: 0.040917\n",
      "2023-12-03 01:07:06,678 INFO     Training average negative_sample_loss at step 48500: 0.016545\n",
      "2023-12-03 01:07:06,678 INFO     Training average loss at step 48500: 0.028731\n",
      "2023-12-03 01:07:12,839 INFO     Training average positive_sample_loss at step 48600: 0.041216\n",
      "2023-12-03 01:07:12,840 INFO     Training average negative_sample_loss at step 48600: 0.016567\n",
      "2023-12-03 01:07:12,840 INFO     Training average loss at step 48600: 0.028891\n",
      "2023-12-03 01:07:19,412 INFO     Training average positive_sample_loss at step 48700: 0.040431\n",
      "2023-12-03 01:07:19,412 INFO     Training average negative_sample_loss at step 48700: 0.016608\n",
      "2023-12-03 01:07:19,412 INFO     Training average loss at step 48700: 0.028519\n",
      "2023-12-03 01:07:24,942 INFO     Training average positive_sample_loss at step 48800: 0.040733\n",
      "2023-12-03 01:07:24,943 INFO     Training average negative_sample_loss at step 48800: 0.016506\n",
      "2023-12-03 01:07:24,943 INFO     Training average loss at step 48800: 0.028619\n",
      "2023-12-03 01:07:31,075 INFO     Training average positive_sample_loss at step 48900: 0.040931\n",
      "2023-12-03 01:07:31,075 INFO     Training average negative_sample_loss at step 48900: 0.016427\n",
      "2023-12-03 01:07:31,076 INFO     Training average loss at step 48900: 0.028679\n",
      "2023-12-03 01:07:37,687 INFO     Training average positive_sample_loss at step 49000: 0.040914\n",
      "2023-12-03 01:07:37,687 INFO     Training average negative_sample_loss at step 49000: 0.016575\n",
      "2023-12-03 01:07:37,687 INFO     Training average loss at step 49000: 0.028744\n",
      "2023-12-03 01:07:43,746 INFO     Training average positive_sample_loss at step 49100: 0.040706\n",
      "2023-12-03 01:07:43,746 INFO     Training average negative_sample_loss at step 49100: 0.016492\n",
      "2023-12-03 01:07:43,746 INFO     Training average loss at step 49100: 0.028599\n",
      "2023-12-03 01:07:49,826 INFO     Training average positive_sample_loss at step 49200: 0.040693\n",
      "2023-12-03 01:07:49,827 INFO     Training average negative_sample_loss at step 49200: 0.016385\n",
      "2023-12-03 01:07:49,827 INFO     Training average loss at step 49200: 0.028539\n",
      "2023-12-03 01:07:56,087 INFO     Training average positive_sample_loss at step 49300: 0.041081\n",
      "2023-12-03 01:07:56,088 INFO     Training average negative_sample_loss at step 49300: 0.016657\n",
      "2023-12-03 01:07:56,088 INFO     Training average loss at step 49300: 0.028869\n",
      "2023-12-03 01:08:01,837 INFO     Training average positive_sample_loss at step 49400: 0.040561\n",
      "2023-12-03 01:08:01,837 INFO     Training average negative_sample_loss at step 49400: 0.016475\n",
      "2023-12-03 01:08:01,837 INFO     Training average loss at step 49400: 0.028518\n",
      "2023-12-03 01:08:08,003 INFO     Training average positive_sample_loss at step 49500: 0.040560\n",
      "2023-12-03 01:08:08,003 INFO     Training average negative_sample_loss at step 49500: 0.016486\n",
      "2023-12-03 01:08:08,003 INFO     Training average loss at step 49500: 0.028523\n",
      "2023-12-03 01:08:14,095 INFO     Training average positive_sample_loss at step 49600: 0.041028\n",
      "2023-12-03 01:08:14,095 INFO     Training average negative_sample_loss at step 49600: 0.016421\n",
      "2023-12-03 01:08:14,095 INFO     Training average loss at step 49600: 0.028724\n",
      "2023-12-03 01:08:20,561 INFO     Training average positive_sample_loss at step 49700: 0.040877\n",
      "2023-12-03 01:08:20,562 INFO     Training average negative_sample_loss at step 49700: 0.016548\n",
      "2023-12-03 01:08:20,562 INFO     Training average loss at step 49700: 0.028712\n",
      "2023-12-03 01:08:26,707 INFO     Training average positive_sample_loss at step 49800: 0.040657\n",
      "2023-12-03 01:08:26,707 INFO     Training average negative_sample_loss at step 49800: 0.016466\n",
      "2023-12-03 01:08:26,707 INFO     Training average loss at step 49800: 0.028562\n",
      "2023-12-03 01:08:32,823 INFO     Training average positive_sample_loss at step 49900: 0.040846\n",
      "2023-12-03 01:08:32,824 INFO     Training average negative_sample_loss at step 49900: 0.016546\n",
      "2023-12-03 01:08:32,824 INFO     Training average loss at step 49900: 0.028696\n",
      "2023-12-03 01:08:51,002 INFO     Training average positive_sample_loss at step 50000: 0.040880\n",
      "2023-12-03 01:08:51,002 INFO     Training average negative_sample_loss at step 50000: 0.016493\n",
      "2023-12-03 01:08:51,002 INFO     Training average loss at step 50000: 0.028687\n",
      "2023-12-03 01:08:51,002 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 01:08:51,516 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 01:09:25,040 INFO     Valid MRR at step 50000: 0.479413\n",
      "2023-12-03 01:09:25,040 INFO     Valid MR at step 50000: 3338.464403\n",
      "2023-12-03 01:09:25,040 INFO     Valid HITS@1 at step 50000: 0.434740\n",
      "2023-12-03 01:09:25,040 INFO     Valid HITS@3 at step 50000: 0.492914\n",
      "2023-12-03 01:09:25,041 INFO     Valid HITS@10 at step 50000: 0.570699\n",
      "2023-12-03 01:09:31,209 INFO     Training average positive_sample_loss at step 50100: 0.040736\n",
      "2023-12-03 01:09:31,209 INFO     Training average negative_sample_loss at step 50100: 0.016478\n",
      "2023-12-03 01:09:31,209 INFO     Training average loss at step 50100: 0.028607\n",
      "2023-12-03 01:09:37,067 INFO     Training average positive_sample_loss at step 50200: 0.040817\n",
      "2023-12-03 01:09:37,068 INFO     Training average negative_sample_loss at step 50200: 0.016545\n",
      "2023-12-03 01:09:37,068 INFO     Training average loss at step 50200: 0.028681\n",
      "2023-12-03 01:09:43,156 INFO     Training average positive_sample_loss at step 50300: 0.040889\n",
      "2023-12-03 01:09:43,157 INFO     Training average negative_sample_loss at step 50300: 0.016416\n",
      "2023-12-03 01:09:43,157 INFO     Training average loss at step 50300: 0.028652\n",
      "2023-12-03 01:09:49,856 INFO     Training average positive_sample_loss at step 50400: 0.040673\n",
      "2023-12-03 01:09:49,856 INFO     Training average negative_sample_loss at step 50400: 0.016444\n",
      "2023-12-03 01:09:49,856 INFO     Training average loss at step 50400: 0.028558\n",
      "2023-12-03 01:09:55,899 INFO     Training average positive_sample_loss at step 50500: 0.040781\n",
      "2023-12-03 01:09:55,900 INFO     Training average negative_sample_loss at step 50500: 0.016459\n",
      "2023-12-03 01:09:55,900 INFO     Training average loss at step 50500: 0.028620\n",
      "2023-12-03 01:10:01,605 INFO     Training average positive_sample_loss at step 50600: 0.040824\n",
      "2023-12-03 01:10:01,605 INFO     Training average negative_sample_loss at step 50600: 0.016571\n",
      "2023-12-03 01:10:01,605 INFO     Training average loss at step 50600: 0.028698\n",
      "2023-12-03 01:10:08,145 INFO     Training average positive_sample_loss at step 50700: 0.040819\n",
      "2023-12-03 01:10:08,145 INFO     Training average negative_sample_loss at step 50700: 0.016572\n",
      "2023-12-03 01:10:08,145 INFO     Training average loss at step 50700: 0.028696\n",
      "2023-12-03 01:10:14,012 INFO     Training average positive_sample_loss at step 50800: 0.040460\n",
      "2023-12-03 01:10:14,012 INFO     Training average negative_sample_loss at step 50800: 0.016561\n",
      "2023-12-03 01:10:14,012 INFO     Training average loss at step 50800: 0.028510\n",
      "2023-12-03 01:10:20,104 INFO     Training average positive_sample_loss at step 50900: 0.040790\n",
      "2023-12-03 01:10:20,104 INFO     Training average negative_sample_loss at step 50900: 0.016410\n",
      "2023-12-03 01:10:20,104 INFO     Training average loss at step 50900: 0.028600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:10:26,329 INFO     Training average positive_sample_loss at step 51000: 0.041093\n",
      "2023-12-03 01:10:26,329 INFO     Training average negative_sample_loss at step 51000: 0.016317\n",
      "2023-12-03 01:10:26,330 INFO     Training average loss at step 51000: 0.028705\n",
      "2023-12-03 01:10:32,708 INFO     Training average positive_sample_loss at step 51100: 0.040706\n",
      "2023-12-03 01:10:32,708 INFO     Training average negative_sample_loss at step 51100: 0.016517\n",
      "2023-12-03 01:10:32,708 INFO     Training average loss at step 51100: 0.028612\n",
      "2023-12-03 01:10:38,449 INFO     Training average positive_sample_loss at step 51200: 0.040445\n",
      "2023-12-03 01:10:38,450 INFO     Training average negative_sample_loss at step 51200: 0.016451\n",
      "2023-12-03 01:10:38,450 INFO     Training average loss at step 51200: 0.028448\n",
      "2023-12-03 01:10:44,345 INFO     Training average positive_sample_loss at step 51300: 0.041094\n",
      "2023-12-03 01:10:44,345 INFO     Training average negative_sample_loss at step 51300: 0.016411\n",
      "2023-12-03 01:10:44,345 INFO     Training average loss at step 51300: 0.028753\n",
      "2023-12-03 01:10:51,023 INFO     Training average positive_sample_loss at step 51400: 0.040593\n",
      "2023-12-03 01:10:51,023 INFO     Training average negative_sample_loss at step 51400: 0.016423\n",
      "2023-12-03 01:10:51,023 INFO     Training average loss at step 51400: 0.028508\n",
      "2023-12-03 01:10:57,127 INFO     Training average positive_sample_loss at step 51500: 0.040630\n",
      "2023-12-03 01:10:57,128 INFO     Training average negative_sample_loss at step 51500: 0.016327\n",
      "2023-12-03 01:10:57,128 INFO     Training average loss at step 51500: 0.028478\n",
      "2023-12-03 01:11:03,159 INFO     Training average positive_sample_loss at step 51600: 0.040967\n",
      "2023-12-03 01:11:03,159 INFO     Training average negative_sample_loss at step 51600: 0.016471\n",
      "2023-12-03 01:11:03,159 INFO     Training average loss at step 51600: 0.028719\n",
      "2023-12-03 01:11:09,270 INFO     Training average positive_sample_loss at step 51700: 0.040836\n",
      "2023-12-03 01:11:09,271 INFO     Training average negative_sample_loss at step 51700: 0.016454\n",
      "2023-12-03 01:11:09,271 INFO     Training average loss at step 51700: 0.028645\n",
      "2023-12-03 01:11:15,244 INFO     Training average positive_sample_loss at step 51800: 0.040524\n",
      "2023-12-03 01:11:15,244 INFO     Training average negative_sample_loss at step 51800: 0.016410\n",
      "2023-12-03 01:11:15,244 INFO     Training average loss at step 51800: 0.028467\n",
      "2023-12-03 01:11:21,338 INFO     Training average positive_sample_loss at step 51900: 0.040845\n",
      "2023-12-03 01:11:21,339 INFO     Training average negative_sample_loss at step 51900: 0.016329\n",
      "2023-12-03 01:11:21,339 INFO     Training average loss at step 51900: 0.028587\n",
      "2023-12-03 01:11:27,372 INFO     Training average positive_sample_loss at step 52000: 0.040992\n",
      "2023-12-03 01:11:27,372 INFO     Training average negative_sample_loss at step 52000: 0.016372\n",
      "2023-12-03 01:11:27,372 INFO     Training average loss at step 52000: 0.028682\n",
      "2023-12-03 01:11:34,071 INFO     Training average positive_sample_loss at step 52100: 0.040701\n",
      "2023-12-03 01:11:34,072 INFO     Training average negative_sample_loss at step 52100: 0.016482\n",
      "2023-12-03 01:11:34,072 INFO     Training average loss at step 52100: 0.028592\n",
      "2023-12-03 01:11:40,232 INFO     Training average positive_sample_loss at step 52200: 0.040817\n",
      "2023-12-03 01:11:40,232 INFO     Training average negative_sample_loss at step 52200: 0.016504\n",
      "2023-12-03 01:11:40,232 INFO     Training average loss at step 52200: 0.028661\n",
      "2023-12-03 01:11:46,391 INFO     Training average positive_sample_loss at step 52300: 0.040784\n",
      "2023-12-03 01:11:46,391 INFO     Training average negative_sample_loss at step 52300: 0.016425\n",
      "2023-12-03 01:11:46,391 INFO     Training average loss at step 52300: 0.028604\n",
      "2023-12-03 01:11:52,442 INFO     Training average positive_sample_loss at step 52400: 0.040827\n",
      "2023-12-03 01:11:52,443 INFO     Training average negative_sample_loss at step 52400: 0.016413\n",
      "2023-12-03 01:11:52,443 INFO     Training average loss at step 52400: 0.028620\n",
      "2023-12-03 01:11:58,672 INFO     Training average positive_sample_loss at step 52500: 0.040262\n",
      "2023-12-03 01:11:58,674 INFO     Training average negative_sample_loss at step 52500: 0.016463\n",
      "2023-12-03 01:11:58,674 INFO     Training average loss at step 52500: 0.028363\n",
      "2023-12-03 01:12:04,725 INFO     Training average positive_sample_loss at step 52600: 0.040806\n",
      "2023-12-03 01:12:04,725 INFO     Training average negative_sample_loss at step 52600: 0.016429\n",
      "2023-12-03 01:12:04,726 INFO     Training average loss at step 52600: 0.028617\n",
      "2023-12-03 01:12:11,113 INFO     Training average positive_sample_loss at step 52700: 0.041141\n",
      "2023-12-03 01:12:11,113 INFO     Training average negative_sample_loss at step 52700: 0.016341\n",
      "2023-12-03 01:12:11,113 INFO     Training average loss at step 52700: 0.028741\n",
      "2023-12-03 01:12:17,156 INFO     Training average positive_sample_loss at step 52800: 0.040370\n",
      "2023-12-03 01:12:17,156 INFO     Training average negative_sample_loss at step 52800: 0.016479\n",
      "2023-12-03 01:12:17,156 INFO     Training average loss at step 52800: 0.028424\n",
      "2023-12-03 01:12:23,024 INFO     Training average positive_sample_loss at step 52900: 0.040772\n",
      "2023-12-03 01:12:23,025 INFO     Training average negative_sample_loss at step 52900: 0.016505\n",
      "2023-12-03 01:12:23,025 INFO     Training average loss at step 52900: 0.028638\n",
      "2023-12-03 01:12:29,134 INFO     Training average positive_sample_loss at step 53000: 0.040966\n",
      "2023-12-03 01:12:29,135 INFO     Training average negative_sample_loss at step 53000: 0.016425\n",
      "2023-12-03 01:12:29,135 INFO     Training average loss at step 53000: 0.028695\n",
      "2023-12-03 01:12:35,756 INFO     Training average positive_sample_loss at step 53100: 0.040638\n",
      "2023-12-03 01:12:35,756 INFO     Training average negative_sample_loss at step 53100: 0.016297\n",
      "2023-12-03 01:12:35,756 INFO     Training average loss at step 53100: 0.028468\n",
      "2023-12-03 01:12:41,870 INFO     Training average positive_sample_loss at step 53200: 0.040701\n",
      "2023-12-03 01:12:41,871 INFO     Training average negative_sample_loss at step 53200: 0.016332\n",
      "2023-12-03 01:12:41,871 INFO     Training average loss at step 53200: 0.028517\n",
      "2023-12-03 01:12:48,006 INFO     Training average positive_sample_loss at step 53300: 0.041166\n",
      "2023-12-03 01:12:48,007 INFO     Training average negative_sample_loss at step 53300: 0.016489\n",
      "2023-12-03 01:12:48,007 INFO     Training average loss at step 53300: 0.028827\n",
      "2023-12-03 01:12:54,666 INFO     Training average positive_sample_loss at step 53400: 0.040528\n",
      "2023-12-03 01:12:54,666 INFO     Training average negative_sample_loss at step 53400: 0.016336\n",
      "2023-12-03 01:12:54,666 INFO     Training average loss at step 53400: 0.028432\n",
      "2023-12-03 01:13:00,174 INFO     Training average positive_sample_loss at step 53500: 0.040718\n",
      "2023-12-03 01:13:00,174 INFO     Training average negative_sample_loss at step 53500: 0.016435\n",
      "2023-12-03 01:13:00,174 INFO     Training average loss at step 53500: 0.028576\n",
      "2023-12-03 01:13:06,254 INFO     Training average positive_sample_loss at step 53600: 0.040887\n",
      "2023-12-03 01:13:06,254 INFO     Training average negative_sample_loss at step 53600: 0.016388\n",
      "2023-12-03 01:13:06,254 INFO     Training average loss at step 53600: 0.028637\n",
      "2023-12-03 01:13:12,404 INFO     Training average positive_sample_loss at step 53700: 0.040778\n",
      "2023-12-03 01:13:12,405 INFO     Training average negative_sample_loss at step 53700: 0.016416\n",
      "2023-12-03 01:13:12,405 INFO     Training average loss at step 53700: 0.028597\n",
      "2023-12-03 01:13:18,976 INFO     Training average positive_sample_loss at step 53800: 0.040512\n",
      "2023-12-03 01:13:18,977 INFO     Training average negative_sample_loss at step 53800: 0.016415\n",
      "2023-12-03 01:13:18,977 INFO     Training average loss at step 53800: 0.028464\n",
      "2023-12-03 01:13:25,041 INFO     Training average positive_sample_loss at step 53900: 0.040607\n",
      "2023-12-03 01:13:25,041 INFO     Training average negative_sample_loss at step 53900: 0.016340\n",
      "2023-12-03 01:13:25,041 INFO     Training average loss at step 53900: 0.028473\n",
      "2023-12-03 01:13:31,004 INFO     Training average positive_sample_loss at step 54000: 0.040836\n",
      "2023-12-03 01:13:31,004 INFO     Training average negative_sample_loss at step 54000: 0.016400\n",
      "2023-12-03 01:13:31,005 INFO     Training average loss at step 54000: 0.028618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:13:37,450 INFO     Training average positive_sample_loss at step 54100: 0.040850\n",
      "2023-12-03 01:13:37,450 INFO     Training average negative_sample_loss at step 54100: 0.016413\n",
      "2023-12-03 01:13:37,450 INFO     Training average loss at step 54100: 0.028632\n",
      "2023-12-03 01:13:43,323 INFO     Training average positive_sample_loss at step 54200: 0.040857\n",
      "2023-12-03 01:13:43,323 INFO     Training average negative_sample_loss at step 54200: 0.016510\n",
      "2023-12-03 01:13:43,323 INFO     Training average loss at step 54200: 0.028684\n",
      "2023-12-03 01:13:49,468 INFO     Training average positive_sample_loss at step 54300: 0.040751\n",
      "2023-12-03 01:13:49,468 INFO     Training average negative_sample_loss at step 54300: 0.016331\n",
      "2023-12-03 01:13:49,468 INFO     Training average loss at step 54300: 0.028541\n",
      "2023-12-03 01:13:55,889 INFO     Training average positive_sample_loss at step 54400: 0.040778\n",
      "2023-12-03 01:13:55,889 INFO     Training average negative_sample_loss at step 54400: 0.016251\n",
      "2023-12-03 01:13:55,889 INFO     Training average loss at step 54400: 0.028515\n",
      "2023-12-03 01:14:02,253 INFO     Training average positive_sample_loss at step 54500: 0.040559\n",
      "2023-12-03 01:14:02,253 INFO     Training average negative_sample_loss at step 54500: 0.016353\n",
      "2023-12-03 01:14:02,253 INFO     Training average loss at step 54500: 0.028456\n",
      "2023-12-03 01:14:08,372 INFO     Training average positive_sample_loss at step 54600: 0.040527\n",
      "2023-12-03 01:14:08,372 INFO     Training average negative_sample_loss at step 54600: 0.016503\n",
      "2023-12-03 01:14:08,372 INFO     Training average loss at step 54600: 0.028515\n",
      "2023-12-03 01:14:14,126 INFO     Training average positive_sample_loss at step 54700: 0.041016\n",
      "2023-12-03 01:14:14,127 INFO     Training average negative_sample_loss at step 54700: 0.016351\n",
      "2023-12-03 01:14:14,127 INFO     Training average loss at step 54700: 0.028684\n",
      "2023-12-03 01:14:20,670 INFO     Training average positive_sample_loss at step 54800: 0.040399\n",
      "2023-12-03 01:14:20,670 INFO     Training average negative_sample_loss at step 54800: 0.016273\n",
      "2023-12-03 01:14:20,670 INFO     Training average loss at step 54800: 0.028336\n",
      "2023-12-03 01:14:26,691 INFO     Training average positive_sample_loss at step 54900: 0.040771\n",
      "2023-12-03 01:14:26,692 INFO     Training average negative_sample_loss at step 54900: 0.016494\n",
      "2023-12-03 01:14:26,692 INFO     Training average loss at step 54900: 0.028632\n",
      "2023-12-03 01:14:32,830 INFO     Training average positive_sample_loss at step 55000: 0.040865\n",
      "2023-12-03 01:14:32,830 INFO     Training average negative_sample_loss at step 55000: 0.016402\n",
      "2023-12-03 01:14:32,830 INFO     Training average loss at step 55000: 0.028634\n",
      "2023-12-03 01:14:38,856 INFO     Training average positive_sample_loss at step 55100: 0.040994\n",
      "2023-12-03 01:14:38,857 INFO     Training average negative_sample_loss at step 55100: 0.016335\n",
      "2023-12-03 01:14:38,857 INFO     Training average loss at step 55100: 0.028665\n",
      "2023-12-03 01:14:44,379 INFO     Training average positive_sample_loss at step 55200: 0.040619\n",
      "2023-12-03 01:14:44,380 INFO     Training average negative_sample_loss at step 55200: 0.016267\n",
      "2023-12-03 01:14:44,380 INFO     Training average loss at step 55200: 0.028443\n",
      "2023-12-03 01:14:50,591 INFO     Training average positive_sample_loss at step 55300: 0.040659\n",
      "2023-12-03 01:14:50,591 INFO     Training average negative_sample_loss at step 55300: 0.016334\n",
      "2023-12-03 01:14:50,591 INFO     Training average loss at step 55300: 0.028497\n",
      "2023-12-03 01:14:56,258 INFO     Training average positive_sample_loss at step 55400: 0.041019\n",
      "2023-12-03 01:14:56,258 INFO     Training average negative_sample_loss at step 55400: 0.016196\n",
      "2023-12-03 01:14:56,258 INFO     Training average loss at step 55400: 0.028607\n",
      "2023-12-03 01:15:02,513 INFO     Training average positive_sample_loss at step 55500: 0.040280\n",
      "2023-12-03 01:15:02,513 INFO     Training average negative_sample_loss at step 55500: 0.016453\n",
      "2023-12-03 01:15:02,513 INFO     Training average loss at step 55500: 0.028366\n",
      "2023-12-03 01:15:08,624 INFO     Training average positive_sample_loss at step 55600: 0.040596\n",
      "2023-12-03 01:15:08,625 INFO     Training average negative_sample_loss at step 55600: 0.016263\n",
      "2023-12-03 01:15:08,625 INFO     Training average loss at step 55600: 0.028430\n",
      "2023-12-03 01:15:14,788 INFO     Training average positive_sample_loss at step 55700: 0.041188\n",
      "2023-12-03 01:15:14,788 INFO     Training average negative_sample_loss at step 55700: 0.016383\n",
      "2023-12-03 01:15:14,788 INFO     Training average loss at step 55700: 0.028786\n",
      "2023-12-03 01:15:21,442 INFO     Training average positive_sample_loss at step 55800: 0.040343\n",
      "2023-12-03 01:15:21,442 INFO     Training average negative_sample_loss at step 55800: 0.016193\n",
      "2023-12-03 01:15:21,443 INFO     Training average loss at step 55800: 0.028268\n",
      "2023-12-03 01:15:27,036 INFO     Training average positive_sample_loss at step 55900: 0.040376\n",
      "2023-12-03 01:15:27,037 INFO     Training average negative_sample_loss at step 55900: 0.016318\n",
      "2023-12-03 01:15:27,037 INFO     Training average loss at step 55900: 0.028347\n",
      "2023-12-03 01:15:33,074 INFO     Training average positive_sample_loss at step 56000: 0.041164\n",
      "2023-12-03 01:15:33,074 INFO     Training average negative_sample_loss at step 56000: 0.016223\n",
      "2023-12-03 01:15:33,074 INFO     Training average loss at step 56000: 0.028693\n",
      "2023-12-03 01:15:39,447 INFO     Training average positive_sample_loss at step 56100: 0.040999\n",
      "2023-12-03 01:15:39,447 INFO     Training average negative_sample_loss at step 56100: 0.016348\n",
      "2023-12-03 01:15:39,447 INFO     Training average loss at step 56100: 0.028673\n",
      "2023-12-03 01:15:45,877 INFO     Training average positive_sample_loss at step 56200: 0.040395\n",
      "2023-12-03 01:15:45,877 INFO     Training average negative_sample_loss at step 56200: 0.016374\n",
      "2023-12-03 01:15:45,877 INFO     Training average loss at step 56200: 0.028385\n",
      "2023-12-03 01:15:51,704 INFO     Training average positive_sample_loss at step 56300: 0.040651\n",
      "2023-12-03 01:15:51,705 INFO     Training average negative_sample_loss at step 56300: 0.016313\n",
      "2023-12-03 01:15:51,705 INFO     Training average loss at step 56300: 0.028482\n",
      "2023-12-03 01:15:57,671 INFO     Training average positive_sample_loss at step 56400: 0.041036\n",
      "2023-12-03 01:15:57,672 INFO     Training average negative_sample_loss at step 56400: 0.016310\n",
      "2023-12-03 01:15:57,672 INFO     Training average loss at step 56400: 0.028673\n",
      "2023-12-03 01:16:04,353 INFO     Training average positive_sample_loss at step 56500: 0.040561\n",
      "2023-12-03 01:16:04,354 INFO     Training average negative_sample_loss at step 56500: 0.016258\n",
      "2023-12-03 01:16:04,354 INFO     Training average loss at step 56500: 0.028409\n",
      "2023-12-03 01:16:10,383 INFO     Training average positive_sample_loss at step 56600: 0.040413\n",
      "2023-12-03 01:16:10,383 INFO     Training average negative_sample_loss at step 56600: 0.016342\n",
      "2023-12-03 01:16:10,383 INFO     Training average loss at step 56600: 0.028377\n",
      "2023-12-03 01:16:16,542 INFO     Training average positive_sample_loss at step 56700: 0.041019\n",
      "2023-12-03 01:16:16,542 INFO     Training average negative_sample_loss at step 56700: 0.016329\n",
      "2023-12-03 01:16:16,542 INFO     Training average loss at step 56700: 0.028674\n",
      "2023-12-03 01:16:22,936 INFO     Training average positive_sample_loss at step 56800: 0.040984\n",
      "2023-12-03 01:16:22,937 INFO     Training average negative_sample_loss at step 56800: 0.016370\n",
      "2023-12-03 01:16:22,937 INFO     Training average loss at step 56800: 0.028677\n",
      "2023-12-03 01:16:28,535 INFO     Training average positive_sample_loss at step 56900: 0.040552\n",
      "2023-12-03 01:16:28,535 INFO     Training average negative_sample_loss at step 56900: 0.016291\n",
      "2023-12-03 01:16:28,535 INFO     Training average loss at step 56900: 0.028421\n",
      "2023-12-03 01:16:34,680 INFO     Training average positive_sample_loss at step 57000: 0.040620\n",
      "2023-12-03 01:16:34,680 INFO     Training average negative_sample_loss at step 57000: 0.016315\n",
      "2023-12-03 01:16:34,680 INFO     Training average loss at step 57000: 0.028468\n",
      "2023-12-03 01:16:40,694 INFO     Training average positive_sample_loss at step 57100: 0.040925\n",
      "2023-12-03 01:16:40,695 INFO     Training average negative_sample_loss at step 57100: 0.016460\n",
      "2023-12-03 01:16:40,695 INFO     Training average loss at step 57100: 0.028692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:16:47,445 INFO     Training average positive_sample_loss at step 57200: 0.040339\n",
      "2023-12-03 01:16:47,445 INFO     Training average negative_sample_loss at step 57200: 0.016327\n",
      "2023-12-03 01:16:47,445 INFO     Training average loss at step 57200: 0.028333\n",
      "2023-12-03 01:16:53,555 INFO     Training average positive_sample_loss at step 57300: 0.040693\n",
      "2023-12-03 01:16:53,555 INFO     Training average negative_sample_loss at step 57300: 0.016421\n",
      "2023-12-03 01:16:53,555 INFO     Training average loss at step 57300: 0.028557\n",
      "2023-12-03 01:16:59,632 INFO     Training average positive_sample_loss at step 57400: 0.040899\n",
      "2023-12-03 01:16:59,632 INFO     Training average negative_sample_loss at step 57400: 0.016288\n",
      "2023-12-03 01:16:59,632 INFO     Training average loss at step 57400: 0.028593\n",
      "2023-12-03 01:17:05,654 INFO     Training average positive_sample_loss at step 57500: 0.040610\n",
      "2023-12-03 01:17:05,654 INFO     Training average negative_sample_loss at step 57500: 0.016382\n",
      "2023-12-03 01:17:05,654 INFO     Training average loss at step 57500: 0.028496\n",
      "2023-12-03 01:17:11,822 INFO     Training average positive_sample_loss at step 57600: 0.040642\n",
      "2023-12-03 01:17:11,823 INFO     Training average negative_sample_loss at step 57600: 0.016362\n",
      "2023-12-03 01:17:11,823 INFO     Training average loss at step 57600: 0.028502\n",
      "2023-12-03 01:17:17,814 INFO     Training average positive_sample_loss at step 57700: 0.040676\n",
      "2023-12-03 01:17:17,814 INFO     Training average negative_sample_loss at step 57700: 0.016243\n",
      "2023-12-03 01:17:17,814 INFO     Training average loss at step 57700: 0.028459\n",
      "2023-12-03 01:17:24,169 INFO     Training average positive_sample_loss at step 57800: 0.041001\n",
      "2023-12-03 01:17:24,169 INFO     Training average negative_sample_loss at step 57800: 0.016147\n",
      "2023-12-03 01:17:24,169 INFO     Training average loss at step 57800: 0.028574\n",
      "2023-12-03 01:17:30,550 INFO     Training average positive_sample_loss at step 57900: 0.040440\n",
      "2023-12-03 01:17:30,550 INFO     Training average negative_sample_loss at step 57900: 0.016532\n",
      "2023-12-03 01:17:30,550 INFO     Training average loss at step 57900: 0.028486\n",
      "2023-12-03 01:17:36,238 INFO     Training average positive_sample_loss at step 58000: 0.040728\n",
      "2023-12-03 01:17:36,238 INFO     Training average negative_sample_loss at step 58000: 0.016263\n",
      "2023-12-03 01:17:36,238 INFO     Training average loss at step 58000: 0.028495\n",
      "2023-12-03 01:17:42,342 INFO     Training average positive_sample_loss at step 58100: 0.040765\n",
      "2023-12-03 01:17:42,343 INFO     Training average negative_sample_loss at step 58100: 0.016191\n",
      "2023-12-03 01:17:42,343 INFO     Training average loss at step 58100: 0.028478\n",
      "2023-12-03 01:17:49,071 INFO     Training average positive_sample_loss at step 58200: 0.040581\n",
      "2023-12-03 01:17:49,071 INFO     Training average negative_sample_loss at step 58200: 0.016296\n",
      "2023-12-03 01:17:49,072 INFO     Training average loss at step 58200: 0.028438\n",
      "2023-12-03 01:17:55,106 INFO     Training average positive_sample_loss at step 58300: 0.040635\n",
      "2023-12-03 01:17:55,107 INFO     Training average negative_sample_loss at step 58300: 0.016422\n",
      "2023-12-03 01:17:55,107 INFO     Training average loss at step 58300: 0.028528\n",
      "2023-12-03 01:18:01,225 INFO     Training average positive_sample_loss at step 58400: 0.040688\n",
      "2023-12-03 01:18:01,226 INFO     Training average negative_sample_loss at step 58400: 0.016315\n",
      "2023-12-03 01:18:01,226 INFO     Training average loss at step 58400: 0.028502\n",
      "2023-12-03 01:18:08,033 INFO     Training average positive_sample_loss at step 58500: 0.040817\n",
      "2023-12-03 01:18:08,034 INFO     Training average negative_sample_loss at step 58500: 0.016364\n",
      "2023-12-03 01:18:08,034 INFO     Training average loss at step 58500: 0.028590\n",
      "2023-12-03 01:18:14,213 INFO     Training average positive_sample_loss at step 58600: 0.040597\n",
      "2023-12-03 01:18:14,213 INFO     Training average negative_sample_loss at step 58600: 0.016303\n",
      "2023-12-03 01:18:14,213 INFO     Training average loss at step 58600: 0.028450\n",
      "2023-12-03 01:18:19,784 INFO     Training average positive_sample_loss at step 58700: 0.040732\n",
      "2023-12-03 01:18:19,784 INFO     Training average negative_sample_loss at step 58700: 0.016339\n",
      "2023-12-03 01:18:19,784 INFO     Training average loss at step 58700: 0.028535\n",
      "2023-12-03 01:18:25,891 INFO     Training average positive_sample_loss at step 58800: 0.040802\n",
      "2023-12-03 01:18:25,891 INFO     Training average negative_sample_loss at step 58800: 0.016227\n",
      "2023-12-03 01:18:25,891 INFO     Training average loss at step 58800: 0.028514\n",
      "2023-12-03 01:18:32,244 INFO     Training average positive_sample_loss at step 58900: 0.040622\n",
      "2023-12-03 01:18:32,245 INFO     Training average negative_sample_loss at step 58900: 0.016175\n",
      "2023-12-03 01:18:32,245 INFO     Training average loss at step 58900: 0.028399\n",
      "2023-12-03 01:18:38,327 INFO     Training average positive_sample_loss at step 59000: 0.040646\n",
      "2023-12-03 01:18:38,328 INFO     Training average negative_sample_loss at step 59000: 0.016257\n",
      "2023-12-03 01:18:38,328 INFO     Training average loss at step 59000: 0.028452\n",
      "2023-12-03 01:18:44,488 INFO     Training average positive_sample_loss at step 59100: 0.040700\n",
      "2023-12-03 01:18:44,488 INFO     Training average negative_sample_loss at step 59100: 0.016275\n",
      "2023-12-03 01:18:44,488 INFO     Training average loss at step 59100: 0.028487\n",
      "2023-12-03 01:18:51,124 INFO     Training average positive_sample_loss at step 59200: 0.040690\n",
      "2023-12-03 01:18:51,125 INFO     Training average negative_sample_loss at step 59200: 0.016149\n",
      "2023-12-03 01:18:51,125 INFO     Training average loss at step 59200: 0.028420\n",
      "2023-12-03 01:18:56,779 INFO     Training average positive_sample_loss at step 59300: 0.040521\n",
      "2023-12-03 01:18:56,779 INFO     Training average negative_sample_loss at step 59300: 0.016246\n",
      "2023-12-03 01:18:56,779 INFO     Training average loss at step 59300: 0.028383\n",
      "2023-12-03 01:19:02,814 INFO     Training average positive_sample_loss at step 59400: 0.040751\n",
      "2023-12-03 01:19:02,814 INFO     Training average negative_sample_loss at step 59400: 0.016222\n",
      "2023-12-03 01:19:02,814 INFO     Training average loss at step 59400: 0.028486\n",
      "2023-12-03 01:19:09,077 INFO     Training average positive_sample_loss at step 59500: 0.041048\n",
      "2023-12-03 01:19:09,077 INFO     Training average negative_sample_loss at step 59500: 0.016245\n",
      "2023-12-03 01:19:09,077 INFO     Training average loss at step 59500: 0.028646\n",
      "2023-12-03 01:19:15,382 INFO     Training average positive_sample_loss at step 59600: 0.040395\n",
      "2023-12-03 01:19:15,382 INFO     Training average negative_sample_loss at step 59600: 0.016255\n",
      "2023-12-03 01:19:15,382 INFO     Training average loss at step 59600: 0.028325\n",
      "2023-12-03 01:19:21,564 INFO     Training average positive_sample_loss at step 59700: 0.040799\n",
      "2023-12-03 01:19:21,564 INFO     Training average negative_sample_loss at step 59700: 0.016208\n",
      "2023-12-03 01:19:21,564 INFO     Training average loss at step 59700: 0.028504\n",
      "2023-12-03 01:19:27,752 INFO     Training average positive_sample_loss at step 59800: 0.040900\n",
      "2023-12-03 01:19:27,753 INFO     Training average negative_sample_loss at step 59800: 0.016281\n",
      "2023-12-03 01:19:27,753 INFO     Training average loss at step 59800: 0.028590\n",
      "2023-12-03 01:19:34,457 INFO     Training average positive_sample_loss at step 59900: 0.040438\n",
      "2023-12-03 01:19:34,458 INFO     Training average negative_sample_loss at step 59900: 0.016306\n",
      "2023-12-03 01:19:34,458 INFO     Training average loss at step 59900: 0.028372\n",
      "2023-12-03 01:19:50,017 INFO     Training average positive_sample_loss at step 60000: 0.040621\n",
      "2023-12-03 01:19:50,017 INFO     Training average negative_sample_loss at step 60000: 0.016302\n",
      "2023-12-03 01:19:50,017 INFO     Training average loss at step 60000: 0.028461\n",
      "2023-12-03 01:19:50,017 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 01:19:50,655 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 01:20:23,326 INFO     Valid MRR at step 60000: 0.479386\n",
      "2023-12-03 01:20:23,327 INFO     Valid MR at step 60000: 3325.590310\n",
      "2023-12-03 01:20:23,327 INFO     Valid HITS@1 at step 60000: 0.434575\n",
      "2023-12-03 01:20:23,327 INFO     Valid HITS@3 at step 60000: 0.492254\n",
      "2023-12-03 01:20:23,327 INFO     Valid HITS@10 at step 60000: 0.571523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:20:29,478 INFO     Training average positive_sample_loss at step 60100: 0.040650\n",
      "2023-12-03 01:20:29,479 INFO     Training average negative_sample_loss at step 60100: 0.016287\n",
      "2023-12-03 01:20:29,479 INFO     Training average loss at step 60100: 0.028469\n",
      "2023-12-03 01:20:36,140 INFO     Training average positive_sample_loss at step 60200: 0.040896\n",
      "2023-12-03 01:20:36,140 INFO     Training average negative_sample_loss at step 60200: 0.016144\n",
      "2023-12-03 01:20:36,140 INFO     Training average loss at step 60200: 0.028520\n",
      "2023-12-03 01:20:41,818 INFO     Training average positive_sample_loss at step 60300: 0.040567\n",
      "2023-12-03 01:20:41,819 INFO     Training average negative_sample_loss at step 60300: 0.016348\n",
      "2023-12-03 01:20:41,819 INFO     Training average loss at step 60300: 0.028458\n",
      "2023-12-03 01:20:48,042 INFO     Training average positive_sample_loss at step 60400: 0.040579\n",
      "2023-12-03 01:20:48,043 INFO     Training average negative_sample_loss at step 60400: 0.016088\n",
      "2023-12-03 01:20:48,043 INFO     Training average loss at step 60400: 0.028334\n",
      "2023-12-03 01:20:54,159 INFO     Training average positive_sample_loss at step 60500: 0.040834\n",
      "2023-12-03 01:20:54,159 INFO     Training average negative_sample_loss at step 60500: 0.016272\n",
      "2023-12-03 01:20:54,159 INFO     Training average loss at step 60500: 0.028553\n",
      "2023-12-03 01:21:00,681 INFO     Training average positive_sample_loss at step 60600: 0.040406\n",
      "2023-12-03 01:21:00,682 INFO     Training average negative_sample_loss at step 60600: 0.016173\n",
      "2023-12-03 01:21:00,682 INFO     Training average loss at step 60600: 0.028290\n",
      "2023-12-03 01:21:06,785 INFO     Training average positive_sample_loss at step 60700: 0.040769\n",
      "2023-12-03 01:21:06,785 INFO     Training average negative_sample_loss at step 60700: 0.016299\n",
      "2023-12-03 01:21:06,785 INFO     Training average loss at step 60700: 0.028534\n",
      "2023-12-03 01:21:12,862 INFO     Training average positive_sample_loss at step 60800: 0.040882\n",
      "2023-12-03 01:21:12,862 INFO     Training average negative_sample_loss at step 60800: 0.016233\n",
      "2023-12-03 01:21:12,862 INFO     Training average loss at step 60800: 0.028557\n",
      "2023-12-03 01:21:18,982 INFO     Training average positive_sample_loss at step 60900: 0.040551\n",
      "2023-12-03 01:21:18,982 INFO     Training average negative_sample_loss at step 60900: 0.016258\n",
      "2023-12-03 01:21:18,982 INFO     Training average loss at step 60900: 0.028405\n",
      "2023-12-03 01:21:24,892 INFO     Training average positive_sample_loss at step 61000: 0.040656\n",
      "2023-12-03 01:21:24,893 INFO     Training average negative_sample_loss at step 61000: 0.016234\n",
      "2023-12-03 01:21:24,893 INFO     Training average loss at step 61000: 0.028445\n",
      "2023-12-03 01:21:30,979 INFO     Training average positive_sample_loss at step 61100: 0.040658\n",
      "2023-12-03 01:21:30,980 INFO     Training average negative_sample_loss at step 61100: 0.016299\n",
      "2023-12-03 01:21:30,980 INFO     Training average loss at step 61100: 0.028479\n",
      "2023-12-03 01:21:37,337 INFO     Training average positive_sample_loss at step 61200: 0.040753\n",
      "2023-12-03 01:21:37,337 INFO     Training average negative_sample_loss at step 61200: 0.016248\n",
      "2023-12-03 01:21:37,337 INFO     Training average loss at step 61200: 0.028501\n",
      "2023-12-03 01:21:43,400 INFO     Training average positive_sample_loss at step 61300: 0.040504\n",
      "2023-12-03 01:21:43,400 INFO     Training average negative_sample_loss at step 61300: 0.016180\n",
      "2023-12-03 01:21:43,400 INFO     Training average loss at step 61300: 0.028342\n",
      "2023-12-03 01:21:49,264 INFO     Training average positive_sample_loss at step 61400: 0.040607\n",
      "2023-12-03 01:21:49,264 INFO     Training average negative_sample_loss at step 61400: 0.016114\n",
      "2023-12-03 01:21:49,264 INFO     Training average loss at step 61400: 0.028361\n",
      "2023-12-03 01:21:55,333 INFO     Training average positive_sample_loss at step 61500: 0.040635\n",
      "2023-12-03 01:21:55,333 INFO     Training average negative_sample_loss at step 61500: 0.016116\n",
      "2023-12-03 01:21:55,333 INFO     Training average loss at step 61500: 0.028375\n",
      "2023-12-03 01:22:01,967 INFO     Training average positive_sample_loss at step 61600: 0.040787\n",
      "2023-12-03 01:22:01,968 INFO     Training average negative_sample_loss at step 61600: 0.016203\n",
      "2023-12-03 01:22:01,968 INFO     Training average loss at step 61600: 0.028495\n",
      "2023-12-03 01:22:08,051 INFO     Training average positive_sample_loss at step 61700: 0.040553\n",
      "2023-12-03 01:22:08,051 INFO     Training average negative_sample_loss at step 61700: 0.016264\n",
      "2023-12-03 01:22:08,051 INFO     Training average loss at step 61700: 0.028408\n",
      "2023-12-03 01:22:13,557 INFO     Training average positive_sample_loss at step 61800: 0.040728\n",
      "2023-12-03 01:22:13,558 INFO     Training average negative_sample_loss at step 61800: 0.016343\n",
      "2023-12-03 01:22:13,558 INFO     Training average loss at step 61800: 0.028535\n",
      "2023-12-03 01:22:20,189 INFO     Training average positive_sample_loss at step 61900: 0.040896\n",
      "2023-12-03 01:22:20,189 INFO     Training average negative_sample_loss at step 61900: 0.016415\n",
      "2023-12-03 01:22:20,189 INFO     Training average loss at step 61900: 0.028656\n",
      "2023-12-03 01:22:26,322 INFO     Training average positive_sample_loss at step 62000: 0.040365\n",
      "2023-12-03 01:22:26,323 INFO     Training average negative_sample_loss at step 62000: 0.016321\n",
      "2023-12-03 01:22:26,323 INFO     Training average loss at step 62000: 0.028343\n",
      "2023-12-03 01:22:32,470 INFO     Training average positive_sample_loss at step 62100: 0.040710\n",
      "2023-12-03 01:22:32,471 INFO     Training average negative_sample_loss at step 62100: 0.016398\n",
      "2023-12-03 01:22:32,471 INFO     Training average loss at step 62100: 0.028554\n",
      "2023-12-03 01:22:38,594 INFO     Training average positive_sample_loss at step 62200: 0.040821\n",
      "2023-12-03 01:22:38,595 INFO     Training average negative_sample_loss at step 62200: 0.016259\n",
      "2023-12-03 01:22:38,595 INFO     Training average loss at step 62200: 0.028540\n",
      "2023-12-03 01:22:45,255 INFO     Training average positive_sample_loss at step 62300: 0.040533\n",
      "2023-12-03 01:22:45,255 INFO     Training average negative_sample_loss at step 62300: 0.016223\n",
      "2023-12-03 01:22:45,256 INFO     Training average loss at step 62300: 0.028378\n",
      "2023-12-03 01:22:50,716 INFO     Training average positive_sample_loss at step 62400: 0.040442\n",
      "2023-12-03 01:22:50,717 INFO     Training average negative_sample_loss at step 62400: 0.016193\n",
      "2023-12-03 01:22:50,717 INFO     Training average loss at step 62400: 0.028317\n",
      "2023-12-03 01:22:56,893 INFO     Training average positive_sample_loss at step 62500: 0.040786\n",
      "2023-12-03 01:22:56,893 INFO     Training average negative_sample_loss at step 62500: 0.016068\n",
      "2023-12-03 01:22:56,893 INFO     Training average loss at step 62500: 0.028427\n",
      "2023-12-03 01:23:03,674 INFO     Training average positive_sample_loss at step 62600: 0.040751\n",
      "2023-12-03 01:23:03,674 INFO     Training average negative_sample_loss at step 62600: 0.016359\n",
      "2023-12-03 01:23:03,674 INFO     Training average loss at step 62600: 0.028555\n",
      "2023-12-03 01:23:09,796 INFO     Training average positive_sample_loss at step 62700: 0.040387\n",
      "2023-12-03 01:23:09,796 INFO     Training average negative_sample_loss at step 62700: 0.016239\n",
      "2023-12-03 01:23:09,797 INFO     Training average loss at step 62700: 0.028313\n",
      "2023-12-03 01:23:15,940 INFO     Training average positive_sample_loss at step 62800: 0.040924\n",
      "2023-12-03 01:23:15,940 INFO     Training average negative_sample_loss at step 62800: 0.016241\n",
      "2023-12-03 01:23:15,940 INFO     Training average loss at step 62800: 0.028582\n",
      "2023-12-03 01:23:22,173 INFO     Training average positive_sample_loss at step 62900: 0.040661\n",
      "2023-12-03 01:23:22,174 INFO     Training average negative_sample_loss at step 62900: 0.016123\n",
      "2023-12-03 01:23:22,174 INFO     Training average loss at step 62900: 0.028392\n",
      "2023-12-03 01:23:27,915 INFO     Training average positive_sample_loss at step 63000: 0.040454\n",
      "2023-12-03 01:23:27,916 INFO     Training average negative_sample_loss at step 63000: 0.016171\n",
      "2023-12-03 01:23:27,916 INFO     Training average loss at step 63000: 0.028313\n",
      "2023-12-03 01:23:34,039 INFO     Training average positive_sample_loss at step 63100: 0.040639\n",
      "2023-12-03 01:23:34,040 INFO     Training average negative_sample_loss at step 63100: 0.016208\n",
      "2023-12-03 01:23:34,040 INFO     Training average loss at step 63100: 0.028424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:23:40,319 INFO     Training average positive_sample_loss at step 63200: 0.040820\n",
      "2023-12-03 01:23:40,319 INFO     Training average negative_sample_loss at step 63200: 0.016306\n",
      "2023-12-03 01:23:40,319 INFO     Training average loss at step 63200: 0.028563\n",
      "2023-12-03 01:23:47,071 INFO     Training average positive_sample_loss at step 63300: 0.040396\n",
      "2023-12-03 01:23:47,071 INFO     Training average negative_sample_loss at step 63300: 0.016237\n",
      "2023-12-03 01:23:47,071 INFO     Training average loss at step 63300: 0.028316\n",
      "2023-12-03 01:23:53,194 INFO     Training average positive_sample_loss at step 63400: 0.040559\n",
      "2023-12-03 01:23:53,194 INFO     Training average negative_sample_loss at step 63400: 0.016351\n",
      "2023-12-03 01:23:53,194 INFO     Training average loss at step 63400: 0.028455\n",
      "2023-12-03 01:23:58,623 INFO     Training average positive_sample_loss at step 63500: 0.040777\n",
      "2023-12-03 01:23:58,623 INFO     Training average negative_sample_loss at step 63500: 0.016334\n",
      "2023-12-03 01:23:58,624 INFO     Training average loss at step 63500: 0.028556\n",
      "2023-12-03 01:24:05,304 INFO     Training average positive_sample_loss at step 63600: 0.040686\n",
      "2023-12-03 01:24:05,304 INFO     Training average negative_sample_loss at step 63600: 0.016168\n",
      "2023-12-03 01:24:05,304 INFO     Training average loss at step 63600: 0.028427\n",
      "2023-12-03 01:24:11,434 INFO     Training average positive_sample_loss at step 63700: 0.040537\n",
      "2023-12-03 01:24:11,435 INFO     Training average negative_sample_loss at step 63700: 0.016117\n",
      "2023-12-03 01:24:11,435 INFO     Training average loss at step 63700: 0.028327\n",
      "2023-12-03 01:24:17,639 INFO     Training average positive_sample_loss at step 63800: 0.040456\n",
      "2023-12-03 01:24:17,639 INFO     Training average negative_sample_loss at step 63800: 0.016215\n",
      "2023-12-03 01:24:17,639 INFO     Training average loss at step 63800: 0.028335\n",
      "2023-12-03 01:24:23,854 INFO     Training average positive_sample_loss at step 63900: 0.040934\n",
      "2023-12-03 01:24:23,855 INFO     Training average negative_sample_loss at step 63900: 0.016110\n",
      "2023-12-03 01:24:23,855 INFO     Training average loss at step 63900: 0.028522\n",
      "2023-12-03 01:24:30,455 INFO     Training average positive_sample_loss at step 64000: 0.040527\n",
      "2023-12-03 01:24:30,455 INFO     Training average negative_sample_loss at step 64000: 0.016055\n",
      "2023-12-03 01:24:30,455 INFO     Training average loss at step 64000: 0.028291\n",
      "2023-12-03 01:24:36,108 INFO     Training average positive_sample_loss at step 64100: 0.040504\n",
      "2023-12-03 01:24:36,108 INFO     Training average negative_sample_loss at step 64100: 0.016139\n",
      "2023-12-03 01:24:36,108 INFO     Training average loss at step 64100: 0.028321\n",
      "2023-12-03 01:24:41,996 INFO     Training average positive_sample_loss at step 64200: 0.040642\n",
      "2023-12-03 01:24:41,997 INFO     Training average negative_sample_loss at step 64200: 0.016176\n",
      "2023-12-03 01:24:41,997 INFO     Training average loss at step 64200: 0.028409\n",
      "2023-12-03 01:24:48,589 INFO     Training average positive_sample_loss at step 64300: 0.040737\n",
      "2023-12-03 01:24:48,589 INFO     Training average negative_sample_loss at step 64300: 0.016360\n",
      "2023-12-03 01:24:48,590 INFO     Training average loss at step 64300: 0.028548\n",
      "2023-12-03 01:24:54,714 INFO     Training average positive_sample_loss at step 64400: 0.040622\n",
      "2023-12-03 01:24:54,715 INFO     Training average negative_sample_loss at step 64400: 0.016255\n",
      "2023-12-03 01:24:54,715 INFO     Training average loss at step 64400: 0.028439\n",
      "2023-12-03 01:25:00,820 INFO     Training average positive_sample_loss at step 64500: 0.040604\n",
      "2023-12-03 01:25:00,821 INFO     Training average negative_sample_loss at step 64500: 0.016202\n",
      "2023-12-03 01:25:00,821 INFO     Training average loss at step 64500: 0.028403\n",
      "2023-12-03 01:25:07,221 INFO     Training average positive_sample_loss at step 64600: 0.040764\n",
      "2023-12-03 01:25:07,221 INFO     Training average negative_sample_loss at step 64600: 0.016208\n",
      "2023-12-03 01:25:07,221 INFO     Training average loss at step 64600: 0.028486\n",
      "2023-12-03 01:25:13,379 INFO     Training average positive_sample_loss at step 64700: 0.040128\n",
      "2023-12-03 01:25:13,379 INFO     Training average negative_sample_loss at step 64700: 0.016204\n",
      "2023-12-03 01:25:13,379 INFO     Training average loss at step 64700: 0.028166\n",
      "2023-12-03 01:25:19,166 INFO     Training average positive_sample_loss at step 64800: 0.040677\n",
      "2023-12-03 01:25:19,166 INFO     Training average negative_sample_loss at step 64800: 0.016193\n",
      "2023-12-03 01:25:19,166 INFO     Training average loss at step 64800: 0.028435\n",
      "2023-12-03 01:25:25,314 INFO     Training average positive_sample_loss at step 64900: 0.040793\n",
      "2023-12-03 01:25:25,314 INFO     Training average negative_sample_loss at step 64900: 0.016133\n",
      "2023-12-03 01:25:25,314 INFO     Training average loss at step 64900: 0.028463\n",
      "2023-12-03 01:25:31,558 INFO     Training average positive_sample_loss at step 65000: 0.040621\n",
      "2023-12-03 01:25:31,559 INFO     Training average negative_sample_loss at step 65000: 0.016110\n",
      "2023-12-03 01:25:31,559 INFO     Training average loss at step 65000: 0.028365\n",
      "2023-12-03 01:25:37,680 INFO     Training average positive_sample_loss at step 65100: 0.040717\n",
      "2023-12-03 01:25:37,681 INFO     Training average negative_sample_loss at step 65100: 0.016107\n",
      "2023-12-03 01:25:37,681 INFO     Training average loss at step 65100: 0.028412\n",
      "2023-12-03 01:25:43,800 INFO     Training average positive_sample_loss at step 65200: 0.040462\n",
      "2023-12-03 01:25:43,801 INFO     Training average negative_sample_loss at step 65200: 0.016049\n",
      "2023-12-03 01:25:43,801 INFO     Training average loss at step 65200: 0.028256\n",
      "2023-12-03 01:25:49,948 INFO     Training average positive_sample_loss at step 65300: 0.040918\n",
      "2023-12-03 01:25:49,948 INFO     Training average negative_sample_loss at step 65300: 0.016481\n",
      "2023-12-03 01:25:49,948 INFO     Training average loss at step 65300: 0.028699\n",
      "2023-12-03 01:25:55,875 INFO     Training average positive_sample_loss at step 65400: 0.040276\n",
      "2023-12-03 01:25:55,875 INFO     Training average negative_sample_loss at step 65400: 0.016322\n",
      "2023-12-03 01:25:55,875 INFO     Training average loss at step 65400: 0.028299\n",
      "2023-12-03 01:26:01,967 INFO     Training average positive_sample_loss at step 65500: 0.040733\n",
      "2023-12-03 01:26:01,968 INFO     Training average negative_sample_loss at step 65500: 0.016103\n",
      "2023-12-03 01:26:01,968 INFO     Training average loss at step 65500: 0.028418\n",
      "2023-12-03 01:26:08,082 INFO     Training average positive_sample_loss at step 65600: 0.040826\n",
      "2023-12-03 01:26:08,082 INFO     Training average negative_sample_loss at step 65600: 0.016151\n",
      "2023-12-03 01:26:08,082 INFO     Training average loss at step 65600: 0.028489\n",
      "2023-12-03 01:26:14,669 INFO     Training average positive_sample_loss at step 65700: 0.040464\n",
      "2023-12-03 01:26:14,670 INFO     Training average negative_sample_loss at step 65700: 0.016128\n",
      "2023-12-03 01:26:14,670 INFO     Training average loss at step 65700: 0.028296\n",
      "2023-12-03 01:26:20,336 INFO     Training average positive_sample_loss at step 65800: 0.040378\n",
      "2023-12-03 01:26:20,336 INFO     Training average negative_sample_loss at step 65800: 0.016194\n",
      "2023-12-03 01:26:20,336 INFO     Training average loss at step 65800: 0.028286\n",
      "2023-12-03 01:26:26,329 INFO     Training average positive_sample_loss at step 65900: 0.040707\n",
      "2023-12-03 01:26:26,329 INFO     Training average negative_sample_loss at step 65900: 0.016346\n",
      "2023-12-03 01:26:26,329 INFO     Training average loss at step 65900: 0.028527\n",
      "2023-12-03 01:26:33,012 INFO     Training average positive_sample_loss at step 66000: 0.040731\n",
      "2023-12-03 01:26:33,012 INFO     Training average negative_sample_loss at step 66000: 0.016286\n",
      "2023-12-03 01:26:33,012 INFO     Training average loss at step 66000: 0.028509\n",
      "2023-12-03 01:26:38,688 INFO     Training average positive_sample_loss at step 66100: 0.040469\n",
      "2023-12-03 01:26:38,688 INFO     Training average negative_sample_loss at step 66100: 0.016204\n",
      "2023-12-03 01:26:38,688 INFO     Training average loss at step 66100: 0.028336\n",
      "2023-12-03 01:26:44,331 INFO     Training average positive_sample_loss at step 66200: 0.040788\n",
      "2023-12-03 01:26:44,332 INFO     Training average negative_sample_loss at step 66200: 0.016107\n",
      "2023-12-03 01:26:44,332 INFO     Training average loss at step 66200: 0.028447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:26:50,198 INFO     Training average positive_sample_loss at step 66300: 0.040627\n",
      "2023-12-03 01:26:50,199 INFO     Training average negative_sample_loss at step 66300: 0.016252\n",
      "2023-12-03 01:26:50,199 INFO     Training average loss at step 66300: 0.028440\n",
      "2023-12-03 01:26:56,640 INFO     Training average positive_sample_loss at step 66400: 0.040093\n",
      "2023-12-03 01:26:56,641 INFO     Training average negative_sample_loss at step 66400: 0.016044\n",
      "2023-12-03 01:26:56,641 INFO     Training average loss at step 66400: 0.028068\n",
      "2023-12-03 01:27:02,735 INFO     Training average positive_sample_loss at step 66500: 0.040742\n",
      "2023-12-03 01:27:02,736 INFO     Training average negative_sample_loss at step 66500: 0.016250\n",
      "2023-12-03 01:27:02,736 INFO     Training average loss at step 66500: 0.028496\n",
      "2023-12-03 01:27:08,834 INFO     Training average positive_sample_loss at step 66600: 0.040906\n",
      "2023-12-03 01:27:08,834 INFO     Training average negative_sample_loss at step 66600: 0.016230\n",
      "2023-12-03 01:27:08,834 INFO     Training average loss at step 66600: 0.028568\n",
      "2023-12-03 01:27:15,176 INFO     Training average positive_sample_loss at step 66700: 0.040356\n",
      "2023-12-03 01:27:15,176 INFO     Training average negative_sample_loss at step 66700: 0.016307\n",
      "2023-12-03 01:27:15,176 INFO     Training average loss at step 66700: 0.028331\n",
      "2023-12-03 01:27:20,869 INFO     Training average positive_sample_loss at step 66800: 0.040429\n",
      "2023-12-03 01:27:20,869 INFO     Training average negative_sample_loss at step 66800: 0.016182\n",
      "2023-12-03 01:27:20,869 INFO     Training average loss at step 66800: 0.028305\n",
      "2023-12-03 01:27:26,966 INFO     Training average positive_sample_loss at step 66900: 0.040805\n",
      "2023-12-03 01:27:26,966 INFO     Training average negative_sample_loss at step 66900: 0.016149\n",
      "2023-12-03 01:27:26,966 INFO     Training average loss at step 66900: 0.028477\n",
      "2023-12-03 01:27:33,540 INFO     Training average positive_sample_loss at step 67000: 0.040641\n",
      "2023-12-03 01:27:33,540 INFO     Training average negative_sample_loss at step 67000: 0.016213\n",
      "2023-12-03 01:27:33,540 INFO     Training average loss at step 67000: 0.028427\n",
      "2023-12-03 01:27:39,650 INFO     Training average positive_sample_loss at step 67100: 0.040395\n",
      "2023-12-03 01:27:39,650 INFO     Training average negative_sample_loss at step 67100: 0.016105\n",
      "2023-12-03 01:27:39,650 INFO     Training average loss at step 67100: 0.028250\n",
      "2023-12-03 01:27:45,750 INFO     Training average positive_sample_loss at step 67200: 0.040596\n",
      "2023-12-03 01:27:45,750 INFO     Training average negative_sample_loss at step 67200: 0.016321\n",
      "2023-12-03 01:27:45,750 INFO     Training average loss at step 67200: 0.028458\n",
      "2023-12-03 01:27:51,198 INFO     Training average positive_sample_loss at step 67300: 0.040844\n",
      "2023-12-03 01:27:51,199 INFO     Training average negative_sample_loss at step 67300: 0.016265\n",
      "2023-12-03 01:27:51,199 INFO     Training average loss at step 67300: 0.028555\n",
      "2023-12-03 01:27:57,904 INFO     Training average positive_sample_loss at step 67400: 0.040238\n",
      "2023-12-03 01:27:57,904 INFO     Training average negative_sample_loss at step 67400: 0.016200\n",
      "2023-12-03 01:27:57,904 INFO     Training average loss at step 67400: 0.028219\n",
      "2023-12-03 01:28:04,086 INFO     Training average positive_sample_loss at step 67500: 0.040570\n",
      "2023-12-03 01:28:04,087 INFO     Training average negative_sample_loss at step 67500: 0.016133\n",
      "2023-12-03 01:28:04,087 INFO     Training average loss at step 67500: 0.028351\n",
      "2023-12-03 01:28:10,235 INFO     Training average positive_sample_loss at step 67600: 0.040847\n",
      "2023-12-03 01:28:10,235 INFO     Training average negative_sample_loss at step 67600: 0.016230\n",
      "2023-12-03 01:28:10,235 INFO     Training average loss at step 67600: 0.028539\n",
      "2023-12-03 01:28:16,858 INFO     Training average positive_sample_loss at step 67700: 0.040463\n",
      "2023-12-03 01:28:16,858 INFO     Training average negative_sample_loss at step 67700: 0.016068\n",
      "2023-12-03 01:28:16,858 INFO     Training average loss at step 67700: 0.028266\n",
      "2023-12-03 01:28:22,874 INFO     Training average positive_sample_loss at step 67800: 0.040487\n",
      "2023-12-03 01:28:22,875 INFO     Training average negative_sample_loss at step 67800: 0.016191\n",
      "2023-12-03 01:28:22,875 INFO     Training average loss at step 67800: 0.028339\n",
      "2023-12-03 01:28:28,776 INFO     Training average positive_sample_loss at step 67900: 0.040454\n",
      "2023-12-03 01:28:28,776 INFO     Training average negative_sample_loss at step 67900: 0.016163\n",
      "2023-12-03 01:28:28,776 INFO     Training average loss at step 67900: 0.028309\n",
      "2023-12-03 01:28:34,885 INFO     Training average positive_sample_loss at step 68000: 0.041038\n",
      "2023-12-03 01:28:34,885 INFO     Training average negative_sample_loss at step 68000: 0.016155\n",
      "2023-12-03 01:28:34,885 INFO     Training average loss at step 68000: 0.028597\n",
      "2023-12-03 01:28:41,266 INFO     Training average positive_sample_loss at step 68100: 0.040489\n",
      "2023-12-03 01:28:41,266 INFO     Training average negative_sample_loss at step 68100: 0.016256\n",
      "2023-12-03 01:28:41,266 INFO     Training average loss at step 68100: 0.028373\n",
      "2023-12-03 01:28:47,409 INFO     Training average positive_sample_loss at step 68200: 0.040377\n",
      "2023-12-03 01:28:47,410 INFO     Training average negative_sample_loss at step 68200: 0.016115\n",
      "2023-12-03 01:28:47,410 INFO     Training average loss at step 68200: 0.028246\n",
      "2023-12-03 01:28:53,515 INFO     Training average positive_sample_loss at step 68300: 0.040769\n",
      "2023-12-03 01:28:53,515 INFO     Training average negative_sample_loss at step 68300: 0.016136\n",
      "2023-12-03 01:28:53,515 INFO     Training average loss at step 68300: 0.028452\n",
      "2023-12-03 01:28:59,731 INFO     Training average positive_sample_loss at step 68400: 0.040446\n",
      "2023-12-03 01:28:59,731 INFO     Training average negative_sample_loss at step 68400: 0.016246\n",
      "2023-12-03 01:28:59,731 INFO     Training average loss at step 68400: 0.028346\n",
      "2023-12-03 01:29:05,819 INFO     Training average positive_sample_loss at step 68500: 0.040605\n",
      "2023-12-03 01:29:05,819 INFO     Training average negative_sample_loss at step 68500: 0.016181\n",
      "2023-12-03 01:29:05,819 INFO     Training average loss at step 68500: 0.028393\n",
      "2023-12-03 01:29:11,648 INFO     Training average positive_sample_loss at step 68600: 0.040718\n",
      "2023-12-03 01:29:11,648 INFO     Training average negative_sample_loss at step 68600: 0.016105\n",
      "2023-12-03 01:29:11,648 INFO     Training average loss at step 68600: 0.028411\n",
      "2023-12-03 01:29:18,244 INFO     Training average positive_sample_loss at step 68700: 0.040492\n",
      "2023-12-03 01:29:18,244 INFO     Training average negative_sample_loss at step 68700: 0.016090\n",
      "2023-12-03 01:29:18,244 INFO     Training average loss at step 68700: 0.028291\n",
      "2023-12-03 01:29:24,367 INFO     Training average positive_sample_loss at step 68800: 0.040208\n",
      "2023-12-03 01:29:24,368 INFO     Training average negative_sample_loss at step 68800: 0.016290\n",
      "2023-12-03 01:29:24,368 INFO     Training average loss at step 68800: 0.028249\n",
      "2023-12-03 01:29:30,489 INFO     Training average positive_sample_loss at step 68900: 0.040737\n",
      "2023-12-03 01:29:30,489 INFO     Training average negative_sample_loss at step 68900: 0.016436\n",
      "2023-12-03 01:29:30,489 INFO     Training average loss at step 68900: 0.028587\n",
      "2023-12-03 01:29:36,191 INFO     Training average positive_sample_loss at step 69000: 0.040646\n",
      "2023-12-03 01:29:36,192 INFO     Training average negative_sample_loss at step 69000: 0.016219\n",
      "2023-12-03 01:29:36,192 INFO     Training average loss at step 69000: 0.028432\n",
      "2023-12-03 01:29:42,736 INFO     Training average positive_sample_loss at step 69100: 0.040484\n",
      "2023-12-03 01:29:42,737 INFO     Training average negative_sample_loss at step 69100: 0.016188\n",
      "2023-12-03 01:29:42,737 INFO     Training average loss at step 69100: 0.028336\n",
      "2023-12-03 01:29:48,542 INFO     Training average positive_sample_loss at step 69200: 0.040343\n",
      "2023-12-03 01:29:48,543 INFO     Training average negative_sample_loss at step 69200: 0.016233\n",
      "2023-12-03 01:29:48,543 INFO     Training average loss at step 69200: 0.028288\n",
      "2023-12-03 01:29:54,602 INFO     Training average positive_sample_loss at step 69300: 0.040721\n",
      "2023-12-03 01:29:54,602 INFO     Training average negative_sample_loss at step 69300: 0.016249\n",
      "2023-12-03 01:29:54,602 INFO     Training average loss at step 69300: 0.028485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:30:00,875 INFO     Training average positive_sample_loss at step 69400: 0.040758\n",
      "2023-12-03 01:30:00,875 INFO     Training average negative_sample_loss at step 69400: 0.016233\n",
      "2023-12-03 01:30:00,875 INFO     Training average loss at step 69400: 0.028496\n",
      "2023-12-03 01:30:06,926 INFO     Training average positive_sample_loss at step 69500: 0.040325\n",
      "2023-12-03 01:30:06,926 INFO     Training average negative_sample_loss at step 69500: 0.016169\n",
      "2023-12-03 01:30:06,926 INFO     Training average loss at step 69500: 0.028247\n",
      "2023-12-03 01:30:12,831 INFO     Training average positive_sample_loss at step 69600: 0.040572\n",
      "2023-12-03 01:30:12,831 INFO     Training average negative_sample_loss at step 69600: 0.016161\n",
      "2023-12-03 01:30:12,831 INFO     Training average loss at step 69600: 0.028366\n",
      "2023-12-03 01:30:18,731 INFO     Training average positive_sample_loss at step 69700: 0.040866\n",
      "2023-12-03 01:30:18,731 INFO     Training average negative_sample_loss at step 69700: 0.016164\n",
      "2023-12-03 01:30:18,732 INFO     Training average loss at step 69700: 0.028515\n",
      "2023-12-03 01:30:25,154 INFO     Training average positive_sample_loss at step 69800: 0.040318\n",
      "2023-12-03 01:30:25,154 INFO     Training average negative_sample_loss at step 69800: 0.016291\n",
      "2023-12-03 01:30:25,154 INFO     Training average loss at step 69800: 0.028304\n",
      "2023-12-03 01:30:31,271 INFO     Training average positive_sample_loss at step 69900: 0.040593\n",
      "2023-12-03 01:30:31,271 INFO     Training average negative_sample_loss at step 69900: 0.016021\n",
      "2023-12-03 01:30:31,271 INFO     Training average loss at step 69900: 0.028307\n",
      "2023-12-03 01:30:48,968 INFO     Training average positive_sample_loss at step 70000: 0.040833\n",
      "2023-12-03 01:30:48,968 INFO     Training average negative_sample_loss at step 70000: 0.016105\n",
      "2023-12-03 01:30:48,968 INFO     Training average loss at step 70000: 0.028469\n",
      "2023-12-03 01:30:48,968 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 01:30:49,648 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 01:31:20,301 INFO     Valid MRR at step 70000: 0.478922\n",
      "2023-12-03 01:31:20,301 INFO     Valid MR at step 70000: 3314.547627\n",
      "2023-12-03 01:31:20,301 INFO     Valid HITS@1 at step 70000: 0.433916\n",
      "2023-12-03 01:31:20,301 INFO     Valid HITS@3 at step 70000: 0.492419\n",
      "2023-12-03 01:31:20,302 INFO     Valid HITS@10 at step 70000: 0.572017\n",
      "2023-12-03 01:31:26,971 INFO     Training average positive_sample_loss at step 70100: 0.040223\n",
      "2023-12-03 01:31:26,971 INFO     Training average negative_sample_loss at step 70100: 0.016232\n",
      "2023-12-03 01:31:26,971 INFO     Training average loss at step 70100: 0.028227\n",
      "2023-12-03 01:31:33,113 INFO     Training average positive_sample_loss at step 70200: 0.040358\n",
      "2023-12-03 01:31:33,113 INFO     Training average negative_sample_loss at step 70200: 0.016197\n",
      "2023-12-03 01:31:33,113 INFO     Training average loss at step 70200: 0.028278\n",
      "2023-12-03 01:31:39,249 INFO     Training average positive_sample_loss at step 70300: 0.040566\n",
      "2023-12-03 01:31:39,250 INFO     Training average negative_sample_loss at step 70300: 0.016145\n",
      "2023-12-03 01:31:39,250 INFO     Training average loss at step 70300: 0.028355\n",
      "2023-12-03 01:31:45,954 INFO     Training average positive_sample_loss at step 70400: 0.040901\n",
      "2023-12-03 01:31:45,955 INFO     Training average negative_sample_loss at step 70400: 0.016181\n",
      "2023-12-03 01:31:45,955 INFO     Training average loss at step 70400: 0.028541\n",
      "2023-12-03 01:31:52,013 INFO     Training average positive_sample_loss at step 70500: 0.040179\n",
      "2023-12-03 01:31:52,013 INFO     Training average negative_sample_loss at step 70500: 0.016127\n",
      "2023-12-03 01:31:52,013 INFO     Training average loss at step 70500: 0.028153\n",
      "2023-12-03 01:31:57,789 INFO     Training average positive_sample_loss at step 70600: 0.040564\n",
      "2023-12-03 01:31:57,789 INFO     Training average negative_sample_loss at step 70600: 0.016286\n",
      "2023-12-03 01:31:57,789 INFO     Training average loss at step 70600: 0.028425\n",
      "2023-12-03 01:32:03,681 INFO     Training average positive_sample_loss at step 70700: 0.040886\n",
      "2023-12-03 01:32:03,681 INFO     Training average negative_sample_loss at step 70700: 0.016223\n",
      "2023-12-03 01:32:03,681 INFO     Training average loss at step 70700: 0.028555\n",
      "2023-12-03 01:32:10,021 INFO     Training average positive_sample_loss at step 70800: 0.040314\n",
      "2023-12-03 01:32:10,022 INFO     Training average negative_sample_loss at step 70800: 0.016146\n",
      "2023-12-03 01:32:10,022 INFO     Training average loss at step 70800: 0.028230\n",
      "2023-12-03 01:32:16,017 INFO     Training average positive_sample_loss at step 70900: 0.040296\n",
      "2023-12-03 01:32:16,017 INFO     Training average negative_sample_loss at step 70900: 0.016073\n",
      "2023-12-03 01:32:16,017 INFO     Training average loss at step 70900: 0.028185\n",
      "2023-12-03 01:32:22,115 INFO     Training average positive_sample_loss at step 71000: 0.040825\n",
      "2023-12-03 01:32:22,115 INFO     Training average negative_sample_loss at step 71000: 0.016158\n",
      "2023-12-03 01:32:22,115 INFO     Training average loss at step 71000: 0.028491\n",
      "2023-12-03 01:32:28,635 INFO     Training average positive_sample_loss at step 71100: 0.040531\n",
      "2023-12-03 01:32:28,636 INFO     Training average negative_sample_loss at step 71100: 0.016130\n",
      "2023-12-03 01:32:28,636 INFO     Training average loss at step 71100: 0.028331\n",
      "2023-12-03 01:32:34,733 INFO     Training average positive_sample_loss at step 71200: 0.040462\n",
      "2023-12-03 01:32:34,734 INFO     Training average negative_sample_loss at step 71200: 0.016067\n",
      "2023-12-03 01:32:34,734 INFO     Training average loss at step 71200: 0.028264\n",
      "2023-12-03 01:32:40,323 INFO     Training average positive_sample_loss at step 71300: 0.040511\n",
      "2023-12-03 01:32:40,324 INFO     Training average negative_sample_loss at step 71300: 0.016087\n",
      "2023-12-03 01:32:40,324 INFO     Training average loss at step 71300: 0.028299\n",
      "2023-12-03 01:32:46,810 INFO     Training average positive_sample_loss at step 71400: 0.040729\n",
      "2023-12-03 01:32:46,810 INFO     Training average negative_sample_loss at step 71400: 0.016073\n",
      "2023-12-03 01:32:46,810 INFO     Training average loss at step 71400: 0.028401\n",
      "2023-12-03 01:32:53,202 INFO     Training average positive_sample_loss at step 71500: 0.040171\n",
      "2023-12-03 01:32:53,203 INFO     Training average negative_sample_loss at step 71500: 0.016123\n",
      "2023-12-03 01:32:53,203 INFO     Training average loss at step 71500: 0.028147\n",
      "2023-12-03 01:32:59,310 INFO     Training average positive_sample_loss at step 71600: 0.040408\n",
      "2023-12-03 01:32:59,310 INFO     Training average negative_sample_loss at step 71600: 0.016162\n",
      "2023-12-03 01:32:59,310 INFO     Training average loss at step 71600: 0.028285\n",
      "2023-12-03 01:33:05,482 INFO     Training average positive_sample_loss at step 71700: 0.040860\n",
      "2023-12-03 01:33:05,483 INFO     Training average negative_sample_loss at step 71700: 0.016430\n",
      "2023-12-03 01:33:05,483 INFO     Training average loss at step 71700: 0.028645\n",
      "2023-12-03 01:33:11,905 INFO     Training average positive_sample_loss at step 71800: 0.040403\n",
      "2023-12-03 01:33:11,905 INFO     Training average negative_sample_loss at step 71800: 0.016183\n",
      "2023-12-03 01:33:11,905 INFO     Training average loss at step 71800: 0.028293\n",
      "2023-12-03 01:33:17,919 INFO     Training average positive_sample_loss at step 71900: 0.040508\n",
      "2023-12-03 01:33:17,919 INFO     Training average negative_sample_loss at step 71900: 0.016100\n",
      "2023-12-03 01:33:17,920 INFO     Training average loss at step 71900: 0.028304\n",
      "2023-12-03 01:33:23,628 INFO     Training average positive_sample_loss at step 72000: 0.040815\n",
      "2023-12-03 01:33:23,628 INFO     Training average negative_sample_loss at step 72000: 0.016168\n",
      "2023-12-03 01:33:23,628 INFO     Training average loss at step 72000: 0.028491\n",
      "2023-12-03 01:33:30,096 INFO     Training average positive_sample_loss at step 72100: 0.040430\n",
      "2023-12-03 01:33:30,096 INFO     Training average negative_sample_loss at step 72100: 0.016100\n",
      "2023-12-03 01:33:30,096 INFO     Training average loss at step 72100: 0.028265\n",
      "2023-12-03 01:33:36,134 INFO     Training average positive_sample_loss at step 72200: 0.040390\n",
      "2023-12-03 01:33:36,134 INFO     Training average negative_sample_loss at step 72200: 0.016128\n",
      "2023-12-03 01:33:36,134 INFO     Training average loss at step 72200: 0.028259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:33:42,252 INFO     Training average positive_sample_loss at step 72300: 0.040455\n",
      "2023-12-03 01:33:42,252 INFO     Training average negative_sample_loss at step 72300: 0.016329\n",
      "2023-12-03 01:33:42,252 INFO     Training average loss at step 72300: 0.028392\n",
      "2023-12-03 01:33:48,359 INFO     Training average positive_sample_loss at step 72400: 0.040785\n",
      "2023-12-03 01:33:48,359 INFO     Training average negative_sample_loss at step 72400: 0.016108\n",
      "2023-12-03 01:33:48,359 INFO     Training average loss at step 72400: 0.028447\n",
      "2023-12-03 01:33:54,457 INFO     Training average positive_sample_loss at step 72500: 0.040164\n",
      "2023-12-03 01:33:54,457 INFO     Training average negative_sample_loss at step 72500: 0.016080\n",
      "2023-12-03 01:33:54,457 INFO     Training average loss at step 72500: 0.028122\n",
      "2023-12-03 01:34:00,541 INFO     Training average positive_sample_loss at step 72600: 0.040545\n",
      "2023-12-03 01:34:00,541 INFO     Training average negative_sample_loss at step 72600: 0.016278\n",
      "2023-12-03 01:34:00,541 INFO     Training average loss at step 72600: 0.028412\n",
      "2023-12-03 01:34:06,411 INFO     Training average positive_sample_loss at step 72700: 0.040748\n",
      "2023-12-03 01:34:06,411 INFO     Training average negative_sample_loss at step 72700: 0.016258\n",
      "2023-12-03 01:34:06,412 INFO     Training average loss at step 72700: 0.028503\n",
      "2023-12-03 01:34:12,756 INFO     Training average positive_sample_loss at step 72800: 0.040338\n",
      "2023-12-03 01:34:12,756 INFO     Training average negative_sample_loss at step 72800: 0.016084\n",
      "2023-12-03 01:34:12,756 INFO     Training average loss at step 72800: 0.028211\n",
      "2023-12-03 01:34:18,892 INFO     Training average positive_sample_loss at step 72900: 0.040372\n",
      "2023-12-03 01:34:18,892 INFO     Training average negative_sample_loss at step 72900: 0.016201\n",
      "2023-12-03 01:34:18,892 INFO     Training average loss at step 72900: 0.028287\n",
      "2023-12-03 01:34:24,641 INFO     Training average positive_sample_loss at step 73000: 0.040598\n",
      "2023-12-03 01:34:24,641 INFO     Training average negative_sample_loss at step 73000: 0.016264\n",
      "2023-12-03 01:34:24,641 INFO     Training average loss at step 73000: 0.028431\n",
      "2023-12-03 01:34:30,710 INFO     Training average positive_sample_loss at step 73100: 0.040833\n",
      "2023-12-03 01:34:30,711 INFO     Training average negative_sample_loss at step 73100: 0.015953\n",
      "2023-12-03 01:34:30,711 INFO     Training average loss at step 73100: 0.028393\n",
      "2023-12-03 01:34:36,934 INFO     Training average positive_sample_loss at step 73200: 0.040278\n",
      "2023-12-03 01:34:36,935 INFO     Training average negative_sample_loss at step 73200: 0.016049\n",
      "2023-12-03 01:34:36,935 INFO     Training average loss at step 73200: 0.028163\n",
      "2023-12-03 01:34:43,155 INFO     Training average positive_sample_loss at step 73300: 0.040638\n",
      "2023-12-03 01:34:43,156 INFO     Training average negative_sample_loss at step 73300: 0.016082\n",
      "2023-12-03 01:34:43,156 INFO     Training average loss at step 73300: 0.028360\n",
      "2023-12-03 01:34:49,277 INFO     Training average positive_sample_loss at step 73400: 0.040778\n",
      "2023-12-03 01:34:49,278 INFO     Training average negative_sample_loss at step 73400: 0.016219\n",
      "2023-12-03 01:34:49,278 INFO     Training average loss at step 73400: 0.028499\n",
      "2023-12-03 01:34:55,779 INFO     Training average positive_sample_loss at step 73500: 0.040149\n",
      "2023-12-03 01:34:55,780 INFO     Training average negative_sample_loss at step 73500: 0.016132\n",
      "2023-12-03 01:34:55,780 INFO     Training average loss at step 73500: 0.028141\n",
      "2023-12-03 01:35:01,322 INFO     Training average positive_sample_loss at step 73600: 0.040234\n",
      "2023-12-03 01:35:01,323 INFO     Training average negative_sample_loss at step 73600: 0.016124\n",
      "2023-12-03 01:35:01,323 INFO     Training average loss at step 73600: 0.028179\n",
      "2023-12-03 01:35:07,447 INFO     Training average positive_sample_loss at step 73700: 0.040653\n",
      "2023-12-03 01:35:07,447 INFO     Training average negative_sample_loss at step 73700: 0.016077\n",
      "2023-12-03 01:35:07,447 INFO     Training average loss at step 73700: 0.028365\n",
      "2023-12-03 01:35:14,064 INFO     Training average positive_sample_loss at step 73800: 0.040565\n",
      "2023-12-03 01:35:14,065 INFO     Training average negative_sample_loss at step 73800: 0.016004\n",
      "2023-12-03 01:35:14,065 INFO     Training average loss at step 73800: 0.028285\n",
      "2023-12-03 01:35:20,218 INFO     Training average positive_sample_loss at step 73900: 0.040384\n",
      "2023-12-03 01:35:20,219 INFO     Training average negative_sample_loss at step 73900: 0.016117\n",
      "2023-12-03 01:35:20,219 INFO     Training average loss at step 73900: 0.028250\n",
      "2023-12-03 01:35:26,362 INFO     Training average positive_sample_loss at step 74000: 0.040546\n",
      "2023-12-03 01:35:26,362 INFO     Training average negative_sample_loss at step 74000: 0.016144\n",
      "2023-12-03 01:35:26,362 INFO     Training average loss at step 74000: 0.028345\n",
      "2023-12-03 01:35:32,453 INFO     Training average positive_sample_loss at step 74100: 0.040643\n",
      "2023-12-03 01:35:32,454 INFO     Training average negative_sample_loss at step 74100: 0.016112\n",
      "2023-12-03 01:35:32,454 INFO     Training average loss at step 74100: 0.028377\n",
      "2023-12-03 01:35:38,660 INFO     Training average positive_sample_loss at step 74200: 0.040306\n",
      "2023-12-03 01:35:38,661 INFO     Training average negative_sample_loss at step 74200: 0.016170\n",
      "2023-12-03 01:35:38,661 INFO     Training average loss at step 74200: 0.028238\n",
      "2023-12-03 01:35:44,541 INFO     Training average positive_sample_loss at step 74300: 0.040499\n",
      "2023-12-03 01:35:44,541 INFO     Training average negative_sample_loss at step 74300: 0.016194\n",
      "2023-12-03 01:35:44,541 INFO     Training average loss at step 74300: 0.028347\n",
      "2023-12-03 01:35:50,608 INFO     Training average positive_sample_loss at step 74400: 0.040604\n",
      "2023-12-03 01:35:50,608 INFO     Training average negative_sample_loss at step 74400: 0.016064\n",
      "2023-12-03 01:35:50,609 INFO     Training average loss at step 74400: 0.028334\n",
      "2023-12-03 01:35:56,809 INFO     Training average positive_sample_loss at step 74500: 0.040509\n",
      "2023-12-03 01:35:56,810 INFO     Training average negative_sample_loss at step 74500: 0.016192\n",
      "2023-12-03 01:35:56,810 INFO     Training average loss at step 74500: 0.028350\n",
      "2023-12-03 01:36:02,954 INFO     Training average positive_sample_loss at step 74600: 0.040382\n",
      "2023-12-03 01:36:02,954 INFO     Training average negative_sample_loss at step 74600: 0.016226\n",
      "2023-12-03 01:36:02,954 INFO     Training average loss at step 74600: 0.028304\n",
      "2023-12-03 01:36:08,539 INFO     Training average positive_sample_loss at step 74700: 0.040512\n",
      "2023-12-03 01:36:08,539 INFO     Training average negative_sample_loss at step 74700: 0.016001\n",
      "2023-12-03 01:36:08,539 INFO     Training average loss at step 74700: 0.028257\n",
      "2023-12-03 01:36:14,975 INFO     Training average positive_sample_loss at step 74800: 0.040590\n",
      "2023-12-03 01:36:14,975 INFO     Training average negative_sample_loss at step 74800: 0.015984\n",
      "2023-12-03 01:36:14,975 INFO     Training average loss at step 74800: 0.028287\n",
      "2023-12-03 01:36:21,409 INFO     Training average positive_sample_loss at step 74900: 0.040311\n",
      "2023-12-03 01:36:21,409 INFO     Training average negative_sample_loss at step 74900: 0.016088\n",
      "2023-12-03 01:36:21,409 INFO     Training average loss at step 74900: 0.028200\n",
      "2023-12-03 01:36:27,585 INFO     Training average positive_sample_loss at step 75000: 0.040425\n",
      "2023-12-03 01:36:27,585 INFO     Training average negative_sample_loss at step 75000: 0.016110\n",
      "2023-12-03 01:36:27,585 INFO     Training average loss at step 75000: 0.028268\n",
      "2023-12-03 01:36:33,775 INFO     Training average positive_sample_loss at step 75100: 0.040563\n",
      "2023-12-03 01:36:33,776 INFO     Training average negative_sample_loss at step 75100: 0.016084\n",
      "2023-12-03 01:36:33,776 INFO     Training average loss at step 75100: 0.028324\n",
      "2023-12-03 01:36:40,469 INFO     Training average positive_sample_loss at step 75200: 0.040594\n",
      "2023-12-03 01:36:40,469 INFO     Training average negative_sample_loss at step 75200: 0.016062\n",
      "2023-12-03 01:36:40,469 INFO     Training average loss at step 75200: 0.028328\n",
      "2023-12-03 01:36:45,979 INFO     Training average positive_sample_loss at step 75300: 0.040405\n",
      "2023-12-03 01:36:45,979 INFO     Training average negative_sample_loss at step 75300: 0.016090\n",
      "2023-12-03 01:36:45,979 INFO     Training average loss at step 75300: 0.028248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:36:52,045 INFO     Training average positive_sample_loss at step 75400: 0.040622\n",
      "2023-12-03 01:36:52,047 INFO     Training average negative_sample_loss at step 75400: 0.016001\n",
      "2023-12-03 01:36:52,047 INFO     Training average loss at step 75400: 0.028312\n",
      "2023-12-03 01:36:58,584 INFO     Training average positive_sample_loss at step 75500: 0.040352\n",
      "2023-12-03 01:36:58,584 INFO     Training average negative_sample_loss at step 75500: 0.016103\n",
      "2023-12-03 01:36:58,584 INFO     Training average loss at step 75500: 0.028227\n",
      "2023-12-03 01:37:04,658 INFO     Training average positive_sample_loss at step 75600: 0.040352\n",
      "2023-12-03 01:37:04,658 INFO     Training average negative_sample_loss at step 75600: 0.016199\n",
      "2023-12-03 01:37:04,658 INFO     Training average loss at step 75600: 0.028275\n",
      "2023-12-03 01:37:10,072 INFO     Training average positive_sample_loss at step 75700: 0.040431\n",
      "2023-12-03 01:37:10,073 INFO     Training average negative_sample_loss at step 75700: 0.016128\n",
      "2023-12-03 01:37:10,073 INFO     Training average loss at step 75700: 0.028279\n",
      "2023-12-03 01:37:16,160 INFO     Training average positive_sample_loss at step 75800: 0.040511\n",
      "2023-12-03 01:37:16,160 INFO     Training average negative_sample_loss at step 75800: 0.016158\n",
      "2023-12-03 01:37:16,160 INFO     Training average loss at step 75800: 0.028334\n",
      "2023-12-03 01:37:22,811 INFO     Training average positive_sample_loss at step 75900: 0.040274\n",
      "2023-12-03 01:37:22,811 INFO     Training average negative_sample_loss at step 75900: 0.016022\n",
      "2023-12-03 01:37:22,811 INFO     Training average loss at step 75900: 0.028148\n",
      "2023-12-03 01:37:28,938 INFO     Training average positive_sample_loss at step 76000: 0.040394\n",
      "2023-12-03 01:37:28,938 INFO     Training average negative_sample_loss at step 76000: 0.016195\n",
      "2023-12-03 01:37:28,938 INFO     Training average loss at step 76000: 0.028294\n",
      "2023-12-03 01:37:35,094 INFO     Training average positive_sample_loss at step 76100: 0.040663\n",
      "2023-12-03 01:37:35,095 INFO     Training average negative_sample_loss at step 76100: 0.016100\n",
      "2023-12-03 01:37:35,095 INFO     Training average loss at step 76100: 0.028382\n",
      "2023-12-03 01:37:41,746 INFO     Training average positive_sample_loss at step 76200: 0.040553\n",
      "2023-12-03 01:37:41,746 INFO     Training average negative_sample_loss at step 76200: 0.016029\n",
      "2023-12-03 01:37:41,746 INFO     Training average loss at step 76200: 0.028291\n",
      "2023-12-03 01:37:47,155 INFO     Training average positive_sample_loss at step 76300: 0.040463\n",
      "2023-12-03 01:37:47,156 INFO     Training average negative_sample_loss at step 76300: 0.016055\n",
      "2023-12-03 01:37:47,156 INFO     Training average loss at step 76300: 0.028259\n",
      "2023-12-03 01:37:53,304 INFO     Training average positive_sample_loss at step 76400: 0.040314\n",
      "2023-12-03 01:37:53,305 INFO     Training average negative_sample_loss at step 76400: 0.015976\n",
      "2023-12-03 01:37:53,305 INFO     Training average loss at step 76400: 0.028145\n",
      "2023-12-03 01:37:59,724 INFO     Training average positive_sample_loss at step 76500: 0.040709\n",
      "2023-12-03 01:37:59,725 INFO     Training average negative_sample_loss at step 76500: 0.016140\n",
      "2023-12-03 01:37:59,725 INFO     Training average loss at step 76500: 0.028424\n",
      "2023-12-03 01:38:06,192 INFO     Training average positive_sample_loss at step 76600: 0.040351\n",
      "2023-12-03 01:38:06,193 INFO     Training average negative_sample_loss at step 76600: 0.016170\n",
      "2023-12-03 01:38:06,193 INFO     Training average loss at step 76600: 0.028260\n",
      "2023-12-03 01:38:12,319 INFO     Training average positive_sample_loss at step 76700: 0.040327\n",
      "2023-12-03 01:38:12,320 INFO     Training average negative_sample_loss at step 76700: 0.016146\n",
      "2023-12-03 01:38:12,320 INFO     Training average loss at step 76700: 0.028237\n",
      "2023-12-03 01:38:17,786 INFO     Training average positive_sample_loss at step 76800: 0.040522\n",
      "2023-12-03 01:38:17,786 INFO     Training average negative_sample_loss at step 76800: 0.016043\n",
      "2023-12-03 01:38:17,786 INFO     Training average loss at step 76800: 0.028282\n",
      "2023-12-03 01:38:24,484 INFO     Training average positive_sample_loss at step 76900: 0.040412\n",
      "2023-12-03 01:38:24,484 INFO     Training average negative_sample_loss at step 76900: 0.016020\n",
      "2023-12-03 01:38:24,485 INFO     Training average loss at step 76900: 0.028216\n",
      "2023-12-03 01:38:30,653 INFO     Training average positive_sample_loss at step 77000: 0.040244\n",
      "2023-12-03 01:38:30,654 INFO     Training average negative_sample_loss at step 77000: 0.016163\n",
      "2023-12-03 01:38:30,654 INFO     Training average loss at step 77000: 0.028203\n",
      "2023-12-03 01:38:36,634 INFO     Training average positive_sample_loss at step 77100: 0.040556\n",
      "2023-12-03 01:38:36,635 INFO     Training average negative_sample_loss at step 77100: 0.016057\n",
      "2023-12-03 01:38:36,635 INFO     Training average loss at step 77100: 0.028307\n",
      "2023-12-03 01:38:42,815 INFO     Training average positive_sample_loss at step 77200: 0.040668\n",
      "2023-12-03 01:38:42,815 INFO     Training average negative_sample_loss at step 77200: 0.016226\n",
      "2023-12-03 01:38:42,815 INFO     Training average loss at step 77200: 0.028447\n",
      "2023-12-03 01:38:48,306 INFO     Training average positive_sample_loss at step 77300: 0.040294\n",
      "2023-12-03 01:38:48,306 INFO     Training average negative_sample_loss at step 77300: 0.016120\n",
      "2023-12-03 01:38:48,306 INFO     Training average loss at step 77300: 0.028207\n",
      "2023-12-03 01:38:54,397 INFO     Training average positive_sample_loss at step 77400: 0.040351\n",
      "2023-12-03 01:38:54,397 INFO     Training average negative_sample_loss at step 77400: 0.016325\n",
      "2023-12-03 01:38:54,397 INFO     Training average loss at step 77400: 0.028338\n",
      "2023-12-03 01:39:00,490 INFO     Training average positive_sample_loss at step 77500: 0.040637\n",
      "2023-12-03 01:39:00,490 INFO     Training average negative_sample_loss at step 77500: 0.016003\n",
      "2023-12-03 01:39:00,490 INFO     Training average loss at step 77500: 0.028320\n",
      "2023-12-03 01:39:07,124 INFO     Training average positive_sample_loss at step 77600: 0.040388\n",
      "2023-12-03 01:39:07,124 INFO     Training average negative_sample_loss at step 77600: 0.016245\n",
      "2023-12-03 01:39:07,124 INFO     Training average loss at step 77600: 0.028316\n",
      "2023-12-03 01:39:12,571 INFO     Training average positive_sample_loss at step 77700: 0.040272\n",
      "2023-12-03 01:39:12,572 INFO     Training average negative_sample_loss at step 77700: 0.016125\n",
      "2023-12-03 01:39:12,572 INFO     Training average loss at step 77700: 0.028198\n",
      "2023-12-03 01:39:18,685 INFO     Training average positive_sample_loss at step 77800: 0.040599\n",
      "2023-12-03 01:39:18,686 INFO     Training average negative_sample_loss at step 77800: 0.016067\n",
      "2023-12-03 01:39:18,686 INFO     Training average loss at step 77800: 0.028333\n",
      "2023-12-03 01:39:25,183 INFO     Training average positive_sample_loss at step 77900: 0.040315\n",
      "2023-12-03 01:39:25,183 INFO     Training average negative_sample_loss at step 77900: 0.016141\n",
      "2023-12-03 01:39:25,183 INFO     Training average loss at step 77900: 0.028228\n",
      "2023-12-03 01:39:31,352 INFO     Training average positive_sample_loss at step 78000: 0.040393\n",
      "2023-12-03 01:39:31,353 INFO     Training average negative_sample_loss at step 78000: 0.016324\n",
      "2023-12-03 01:39:31,353 INFO     Training average loss at step 78000: 0.028359\n",
      "2023-12-03 01:39:36,888 INFO     Training average positive_sample_loss at step 78100: 0.040571\n",
      "2023-12-03 01:39:36,888 INFO     Training average negative_sample_loss at step 78100: 0.015853\n",
      "2023-12-03 01:39:36,888 INFO     Training average loss at step 78100: 0.028212\n",
      "2023-12-03 01:39:43,098 INFO     Training average positive_sample_loss at step 78200: 0.040524\n",
      "2023-12-03 01:39:43,098 INFO     Training average negative_sample_loss at step 78200: 0.016104\n",
      "2023-12-03 01:39:43,098 INFO     Training average loss at step 78200: 0.028314\n",
      "2023-12-03 01:39:49,416 INFO     Training average positive_sample_loss at step 78300: 0.040368\n",
      "2023-12-03 01:39:49,416 INFO     Training average negative_sample_loss at step 78300: 0.016069\n",
      "2023-12-03 01:39:49,416 INFO     Training average loss at step 78300: 0.028218\n",
      "2023-12-03 01:39:55,543 INFO     Training average positive_sample_loss at step 78400: 0.040400\n",
      "2023-12-03 01:39:55,543 INFO     Training average negative_sample_loss at step 78400: 0.016120\n",
      "2023-12-03 01:39:55,543 INFO     Training average loss at step 78400: 0.028260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 01:40:01,654 INFO     Training average positive_sample_loss at step 78500: 0.040467\n",
      "2023-12-03 01:40:01,654 INFO     Training average negative_sample_loss at step 78500: 0.016074\n",
      "2023-12-03 01:40:01,654 INFO     Training average loss at step 78500: 0.028271\n",
      "2023-12-03 01:40:08,295 INFO     Training average positive_sample_loss at step 78600: 0.040191\n",
      "2023-12-03 01:40:08,295 INFO     Training average negative_sample_loss at step 78600: 0.016028\n",
      "2023-12-03 01:40:08,295 INFO     Training average loss at step 78600: 0.028109\n",
      "2023-12-03 01:40:13,861 INFO     Training average positive_sample_loss at step 78700: 0.040460\n",
      "2023-12-03 01:40:13,862 INFO     Training average negative_sample_loss at step 78700: 0.016155\n",
      "2023-12-03 01:40:13,862 INFO     Training average loss at step 78700: 0.028307\n",
      "2023-12-03 01:40:19,959 INFO     Training average positive_sample_loss at step 78800: 0.040455\n",
      "2023-12-03 01:40:19,960 INFO     Training average negative_sample_loss at step 78800: 0.015970\n",
      "2023-12-03 01:40:19,960 INFO     Training average loss at step 78800: 0.028212\n",
      "2023-12-03 01:40:26,578 INFO     Training average positive_sample_loss at step 78900: 0.040610\n",
      "2023-12-03 01:40:26,578 INFO     Training average negative_sample_loss at step 78900: 0.016116\n",
      "2023-12-03 01:40:26,578 INFO     Training average loss at step 78900: 0.028363\n",
      "2023-12-03 01:40:32,734 INFO     Training average positive_sample_loss at step 79000: 0.040328\n",
      "2023-12-03 01:40:32,735 INFO     Training average negative_sample_loss at step 79000: 0.016034\n",
      "2023-12-03 01:40:32,735 INFO     Training average loss at step 79000: 0.028181\n",
      "2023-12-03 01:40:38,885 INFO     Training average positive_sample_loss at step 79100: 0.040244\n",
      "2023-12-03 01:40:38,885 INFO     Training average negative_sample_loss at step 79100: 0.015944\n",
      "2023-12-03 01:40:38,885 INFO     Training average loss at step 79100: 0.028094\n",
      "2023-12-03 01:40:44,352 INFO     Training average positive_sample_loss at step 79200: 0.040666\n",
      "2023-12-03 01:40:44,353 INFO     Training average negative_sample_loss at step 79200: 0.016109\n",
      "2023-12-03 01:40:44,353 INFO     Training average loss at step 79200: 0.028388\n",
      "2023-12-03 01:40:50,872 INFO     Training average positive_sample_loss at step 79300: 0.040111\n",
      "2023-12-03 01:40:50,872 INFO     Training average negative_sample_loss at step 79300: 0.015940\n",
      "2023-12-03 01:40:50,872 INFO     Training average loss at step 79300: 0.028025\n",
      "2023-12-03 01:40:56,976 INFO     Training average positive_sample_loss at step 79400: 0.040415\n",
      "2023-12-03 01:40:56,976 INFO     Training average negative_sample_loss at step 79400: 0.016199\n",
      "2023-12-03 01:40:56,976 INFO     Training average loss at step 79400: 0.028307\n",
      "2023-12-03 01:41:03,100 INFO     Training average positive_sample_loss at step 79500: 0.040567\n",
      "2023-12-03 01:41:03,100 INFO     Training average negative_sample_loss at step 79500: 0.016283\n",
      "2023-12-03 01:41:03,100 INFO     Training average loss at step 79500: 0.028425\n",
      "2023-12-03 01:41:09,609 INFO     Training average positive_sample_loss at step 79600: 0.040485\n",
      "2023-12-03 01:41:09,610 INFO     Training average negative_sample_loss at step 79600: 0.016062\n",
      "2023-12-03 01:41:09,610 INFO     Training average loss at step 79600: 0.028274\n",
      "2023-12-03 01:41:15,182 INFO     Training average positive_sample_loss at step 79700: 0.040381\n",
      "2023-12-03 01:41:15,182 INFO     Training average negative_sample_loss at step 79700: 0.016079\n",
      "2023-12-03 01:41:15,182 INFO     Training average loss at step 79700: 0.028230\n",
      "2023-12-03 01:41:21,332 INFO     Training average positive_sample_loss at step 79800: 0.040464\n",
      "2023-12-03 01:41:21,332 INFO     Training average negative_sample_loss at step 79800: 0.016067\n",
      "2023-12-03 01:41:21,332 INFO     Training average loss at step 79800: 0.028265\n",
      "2023-12-03 01:41:27,736 INFO     Training average positive_sample_loss at step 79900: 0.040458\n",
      "2023-12-03 01:41:27,736 INFO     Training average negative_sample_loss at step 79900: 0.016083\n",
      "2023-12-03 01:41:27,736 INFO     Training average loss at step 79900: 0.028271\n",
      "2023-12-03 01:41:47,544 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 01:41:48,537 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 01:42:22,237 INFO     Valid MRR at step 79999: 0.478979\n",
      "2023-12-03 01:42:22,238 INFO     Valid MR at step 79999: 3301.097231\n",
      "2023-12-03 01:42:22,238 INFO     Valid HITS@1 at step 79999: 0.433916\n",
      "2023-12-03 01:42:22,238 INFO     Valid HITS@3 at step 79999: 0.492419\n",
      "2023-12-03 01:42:22,238 INFO     Valid HITS@10 at step 79999: 0.573006\n",
      "2023-12-03 01:42:22,238 INFO     Evaluating on Test Dataset...\n",
      "2023-12-03 01:42:22,693 INFO     Evaluating the model... (0/784)\n",
      "2023-12-03 01:42:52,728 INFO     Test MRR at step 79999: 0.475920\n",
      "2023-12-03 01:42:52,728 INFO     Test MR at step 79999: 3383.699745\n",
      "2023-12-03 01:42:52,729 INFO     Test HITS@1 at step 79999: 0.428047\n",
      "2023-12-03 01:42:52,729 INFO     Test HITS@3 at step 79999: 0.495214\n",
      "2023-12-03 01:42:52,729 INFO     Test HITS@10 at step 79999: 0.573070\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE wn18rr 0 0 512 1024 500 6.0 0.5 0.00005 80000 8 -de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di Rotate con la variante NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-03 12:09:57,991 INFO     Model: RotatE\n",
      "2023-12-03 12:09:57,991 INFO     Data Path: data/wn18rr\n",
      "2023-12-03 12:09:57,991 INFO     #entity: 40943\n",
      "2023-12-03 12:09:57,991 INFO     #relation: 11\n",
      "2023-12-03 12:09:58,256 INFO     #train: 86835\n",
      "2023-12-03 12:09:58,260 INFO     #valid: 3034\n",
      "2023-12-03 12:09:58,264 INFO     #test: 3134\n",
      "2023-12-03 12:09:58,495 INFO     Model Parameter Configuration:\n",
      "2023-12-03 12:09:58,496 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-03 12:09:58,496 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-03 12:09:58,496 INFO     Parameter entity_embedding: torch.Size([40943, 1000]), require_grad = True\n",
      "2023-12-03 12:09:58,496 INFO     Parameter relation_embedding: torch.Size([11, 500]), require_grad = True\n",
      "2023-12-03 12:10:00,278 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-03 12:10:00,278 INFO     Start Training...\n",
      "2023-12-03 12:10:00,278 INFO     init_step = 0\n",
      "2023-12-03 12:10:00,278 INFO     batch_size = 512\n",
      "2023-12-03 12:10:00,278 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-03 12:10:00,278 INFO     hidden_dim = 500\n",
      "2023-12-03 12:10:00,278 INFO     gamma = 6.000000\n",
      "2023-12-03 12:10:00,278 INFO     negative_adversarial_sampling = True\n",
      "2023-12-03 12:10:00,278 INFO     adversarial_temperature = 0.500000\n",
      "2023-12-03 12:10:00,278 INFO     learning_rate = 0\n",
      "2023-12-03 12:10:14,747 INFO     Training average positive_sample_loss at step 0: 2.435075\n",
      "2023-12-03 12:10:14,747 INFO     Training average negative_sample_loss at step 0: 0.093349\n",
      "2023-12-03 12:10:14,747 INFO     Training average loss at step 0: 1.264212\n",
      "2023-12-03 12:10:14,747 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 12:10:15,223 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 12:10:47,208 INFO     Valid MRR at step 0: 0.000183\n",
      "2023-12-03 12:10:47,209 INFO     Valid MR at step 0: 20420.361239\n",
      "2023-12-03 12:10:47,209 INFO     Valid HITS@1 at step 0: 0.000000\n",
      "2023-12-03 12:10:47,209 INFO     Valid HITS@3 at step 0: 0.000000\n",
      "2023-12-03 12:10:47,209 INFO     Valid HITS@10 at step 0: 0.000000\n",
      "2023-12-03 12:10:55,933 INFO     Training average positive_sample_loss at step 100: 2.869715\n",
      "2023-12-03 12:10:55,934 INFO     Training average negative_sample_loss at step 100: 0.071669\n",
      "2023-12-03 12:10:55,934 INFO     Training average loss at step 100: 1.470692\n",
      "2023-12-03 12:11:03,785 INFO     Training average positive_sample_loss at step 200: 2.712463\n",
      "2023-12-03 12:11:03,786 INFO     Training average negative_sample_loss at step 200: 0.100477\n",
      "2023-12-03 12:11:03,786 INFO     Training average loss at step 200: 1.406470\n",
      "2023-12-03 12:11:11,327 INFO     Training average positive_sample_loss at step 300: 2.330553\n",
      "2023-12-03 12:11:11,327 INFO     Training average negative_sample_loss at step 300: 0.145392\n",
      "2023-12-03 12:11:11,328 INFO     Training average loss at step 300: 1.237973\n",
      "2023-12-03 12:11:20,668 INFO     Training average positive_sample_loss at step 400: 1.799877\n",
      "2023-12-03 12:11:20,668 INFO     Training average negative_sample_loss at step 400: 0.200217\n",
      "2023-12-03 12:11:20,668 INFO     Training average loss at step 400: 1.000047\n",
      "2023-12-03 12:11:28,453 INFO     Training average positive_sample_loss at step 500: 1.458721\n",
      "2023-12-03 12:11:28,453 INFO     Training average negative_sample_loss at step 500: 0.246522\n",
      "2023-12-03 12:11:28,453 INFO     Training average loss at step 500: 0.852622\n",
      "2023-12-03 12:11:36,235 INFO     Training average positive_sample_loss at step 600: 1.271590\n",
      "2023-12-03 12:11:36,236 INFO     Training average negative_sample_loss at step 600: 0.285807\n",
      "2023-12-03 12:11:36,236 INFO     Training average loss at step 600: 0.778698\n",
      "2023-12-03 12:11:46,181 INFO     Training average positive_sample_loss at step 700: 1.082323\n",
      "2023-12-03 12:11:46,181 INFO     Training average negative_sample_loss at step 700: 0.319933\n",
      "2023-12-03 12:11:46,181 INFO     Training average loss at step 700: 0.701128\n",
      "2023-12-03 12:11:54,157 INFO     Training average positive_sample_loss at step 800: 0.852921\n",
      "2023-12-03 12:11:54,157 INFO     Training average negative_sample_loss at step 800: 0.344822\n",
      "2023-12-03 12:11:54,157 INFO     Training average loss at step 800: 0.598871\n",
      "2023-12-03 12:12:02,092 INFO     Training average positive_sample_loss at step 900: 0.790568\n",
      "2023-12-03 12:12:02,092 INFO     Training average negative_sample_loss at step 900: 0.355851\n",
      "2023-12-03 12:12:02,092 INFO     Training average loss at step 900: 0.573210\n",
      "2023-12-03 12:12:09,766 INFO     Training average positive_sample_loss at step 1000: 0.731685\n",
      "2023-12-03 12:12:09,766 INFO     Training average negative_sample_loss at step 1000: 0.364533\n",
      "2023-12-03 12:12:09,766 INFO     Training average loss at step 1000: 0.548109\n",
      "2023-12-03 12:12:18,797 INFO     Training average positive_sample_loss at step 1100: 0.604860\n",
      "2023-12-03 12:12:18,798 INFO     Training average negative_sample_loss at step 1100: 0.368738\n",
      "2023-12-03 12:12:18,798 INFO     Training average loss at step 1100: 0.486799\n",
      "2023-12-03 12:12:26,433 INFO     Training average positive_sample_loss at step 1200: 0.567101\n",
      "2023-12-03 12:12:26,434 INFO     Training average negative_sample_loss at step 1200: 0.362572\n",
      "2023-12-03 12:12:26,434 INFO     Training average loss at step 1200: 0.464836\n",
      "2023-12-03 12:12:34,244 INFO     Training average positive_sample_loss at step 1300: 0.549583\n",
      "2023-12-03 12:12:34,245 INFO     Training average negative_sample_loss at step 1300: 0.356773\n",
      "2023-12-03 12:12:34,245 INFO     Training average loss at step 1300: 0.453178\n",
      "2023-12-03 12:12:43,362 INFO     Training average positive_sample_loss at step 1400: 0.498746\n",
      "2023-12-03 12:12:43,363 INFO     Training average negative_sample_loss at step 1400: 0.351475\n",
      "2023-12-03 12:12:43,363 INFO     Training average loss at step 1400: 0.425110\n",
      "2023-12-03 12:12:51,152 INFO     Training average positive_sample_loss at step 1500: 0.454517\n",
      "2023-12-03 12:12:51,152 INFO     Training average negative_sample_loss at step 1500: 0.338807\n",
      "2023-12-03 12:12:51,153 INFO     Training average loss at step 1500: 0.396662\n",
      "2023-12-03 12:12:58,765 INFO     Training average positive_sample_loss at step 1600: 0.450116\n",
      "2023-12-03 12:12:58,766 INFO     Training average negative_sample_loss at step 1600: 0.327262\n",
      "2023-12-03 12:12:58,766 INFO     Training average loss at step 1600: 0.388689\n",
      "2023-12-03 12:13:07,365 INFO     Training average positive_sample_loss at step 1700: 0.439879\n",
      "2023-12-03 12:13:07,366 INFO     Training average negative_sample_loss at step 1700: 0.318308\n",
      "2023-12-03 12:13:07,366 INFO     Training average loss at step 1700: 0.379094\n",
      "2023-12-03 12:13:16,461 INFO     Training average positive_sample_loss at step 1800: 0.382678\n",
      "2023-12-03 12:13:16,461 INFO     Training average negative_sample_loss at step 1800: 0.305047\n",
      "2023-12-03 12:13:16,461 INFO     Training average loss at step 1800: 0.343863\n",
      "2023-12-03 12:13:24,076 INFO     Training average positive_sample_loss at step 1900: 0.386834\n",
      "2023-12-03 12:13:24,077 INFO     Training average negative_sample_loss at step 1900: 0.292325\n",
      "2023-12-03 12:13:24,077 INFO     Training average loss at step 1900: 0.339579\n",
      "2023-12-03 12:13:31,641 INFO     Training average positive_sample_loss at step 2000: 0.385195\n",
      "2023-12-03 12:13:31,641 INFO     Training average negative_sample_loss at step 2000: 0.282155\n",
      "2023-12-03 12:13:31,641 INFO     Training average loss at step 2000: 0.333675\n",
      "2023-12-03 12:13:40,989 INFO     Training average positive_sample_loss at step 2100: 0.351383\n",
      "2023-12-03 12:13:40,990 INFO     Training average negative_sample_loss at step 2100: 0.271894\n",
      "2023-12-03 12:13:40,990 INFO     Training average loss at step 2100: 0.311639\n",
      "2023-12-03 12:13:48,617 INFO     Training average positive_sample_loss at step 2200: 0.338056\n",
      "2023-12-03 12:13:48,618 INFO     Training average negative_sample_loss at step 2200: 0.258574\n",
      "2023-12-03 12:13:48,618 INFO     Training average loss at step 2200: 0.298315\n",
      "2023-12-03 12:13:56,274 INFO     Training average positive_sample_loss at step 2300: 0.340843\n",
      "2023-12-03 12:13:56,274 INFO     Training average negative_sample_loss at step 2300: 0.249003\n",
      "2023-12-03 12:13:56,274 INFO     Training average loss at step 2300: 0.294923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:14:06,075 INFO     Training average positive_sample_loss at step 2400: 0.329608\n",
      "2023-12-03 12:14:06,076 INFO     Training average negative_sample_loss at step 2400: 0.240684\n",
      "2023-12-03 12:14:06,076 INFO     Training average loss at step 2400: 0.285146\n",
      "2023-12-03 12:14:14,064 INFO     Training average positive_sample_loss at step 2500: 0.300977\n",
      "2023-12-03 12:14:14,064 INFO     Training average negative_sample_loss at step 2500: 0.228988\n",
      "2023-12-03 12:14:14,065 INFO     Training average loss at step 2500: 0.264982\n",
      "2023-12-03 12:14:21,594 INFO     Training average positive_sample_loss at step 2600: 0.304672\n",
      "2023-12-03 12:14:21,594 INFO     Training average negative_sample_loss at step 2600: 0.219882\n",
      "2023-12-03 12:14:21,594 INFO     Training average loss at step 2600: 0.262277\n",
      "2023-12-03 12:14:29,376 INFO     Training average positive_sample_loss at step 2700: 0.304908\n",
      "2023-12-03 12:14:29,376 INFO     Training average negative_sample_loss at step 2700: 0.212729\n",
      "2023-12-03 12:14:29,376 INFO     Training average loss at step 2700: 0.258818\n",
      "2023-12-03 12:14:38,974 INFO     Training average positive_sample_loss at step 2800: 0.276140\n",
      "2023-12-03 12:14:38,975 INFO     Training average negative_sample_loss at step 2800: 0.204229\n",
      "2023-12-03 12:14:38,975 INFO     Training average loss at step 2800: 0.240184\n",
      "2023-12-03 12:14:46,683 INFO     Training average positive_sample_loss at step 2900: 0.274175\n",
      "2023-12-03 12:14:46,683 INFO     Training average negative_sample_loss at step 2900: 0.195091\n",
      "2023-12-03 12:14:46,683 INFO     Training average loss at step 2900: 0.234633\n",
      "2023-12-03 12:14:54,235 INFO     Training average positive_sample_loss at step 3000: 0.277004\n",
      "2023-12-03 12:14:54,235 INFO     Training average negative_sample_loss at step 3000: 0.188601\n",
      "2023-12-03 12:14:54,235 INFO     Training average loss at step 3000: 0.232802\n",
      "2023-12-03 12:15:03,771 INFO     Training average positive_sample_loss at step 3100: 0.261341\n",
      "2023-12-03 12:15:03,771 INFO     Training average negative_sample_loss at step 3100: 0.182511\n",
      "2023-12-03 12:15:03,771 INFO     Training average loss at step 3100: 0.221926\n",
      "2023-12-03 12:15:11,470 INFO     Training average positive_sample_loss at step 3200: 0.247801\n",
      "2023-12-03 12:15:11,470 INFO     Training average negative_sample_loss at step 3200: 0.173912\n",
      "2023-12-03 12:15:11,470 INFO     Training average loss at step 3200: 0.210857\n",
      "2023-12-03 12:15:19,239 INFO     Training average positive_sample_loss at step 3300: 0.251580\n",
      "2023-12-03 12:15:19,240 INFO     Training average negative_sample_loss at step 3300: 0.167808\n",
      "2023-12-03 12:15:19,240 INFO     Training average loss at step 3300: 0.209694\n",
      "2023-12-03 12:15:27,982 INFO     Training average positive_sample_loss at step 3400: 0.252450\n",
      "2023-12-03 12:15:27,982 INFO     Training average negative_sample_loss at step 3400: 0.163646\n",
      "2023-12-03 12:15:27,982 INFO     Training average loss at step 3400: 0.208048\n",
      "2023-12-03 12:15:36,805 INFO     Training average positive_sample_loss at step 3500: 0.223401\n",
      "2023-12-03 12:15:36,806 INFO     Training average negative_sample_loss at step 3500: 0.156436\n",
      "2023-12-03 12:15:36,806 INFO     Training average loss at step 3500: 0.189919\n",
      "2023-12-03 12:15:44,870 INFO     Training average positive_sample_loss at step 3600: 0.230424\n",
      "2023-12-03 12:15:44,870 INFO     Training average negative_sample_loss at step 3600: 0.150573\n",
      "2023-12-03 12:15:44,870 INFO     Training average loss at step 3600: 0.190499\n",
      "2023-12-03 12:15:52,833 INFO     Training average positive_sample_loss at step 3700: 0.232335\n",
      "2023-12-03 12:15:52,833 INFO     Training average negative_sample_loss at step 3700: 0.146500\n",
      "2023-12-03 12:15:52,833 INFO     Training average loss at step 3700: 0.189417\n",
      "2023-12-03 12:16:02,560 INFO     Training average positive_sample_loss at step 3800: 0.214751\n",
      "2023-12-03 12:16:02,560 INFO     Training average negative_sample_loss at step 3800: 0.141791\n",
      "2023-12-03 12:16:02,560 INFO     Training average loss at step 3800: 0.178271\n",
      "2023-12-03 12:16:11,320 INFO     Training average positive_sample_loss at step 3900: 0.210855\n",
      "2023-12-03 12:16:11,320 INFO     Training average negative_sample_loss at step 3900: 0.136069\n",
      "2023-12-03 12:16:11,320 INFO     Training average loss at step 3900: 0.173462\n",
      "2023-12-03 12:16:19,322 INFO     Training average positive_sample_loss at step 4000: 0.213363\n",
      "2023-12-03 12:16:19,322 INFO     Training average negative_sample_loss at step 4000: 0.131893\n",
      "2023-12-03 12:16:19,322 INFO     Training average loss at step 4000: 0.172628\n",
      "2023-12-03 12:16:29,657 INFO     Training average positive_sample_loss at step 4100: 0.208649\n",
      "2023-12-03 12:16:29,658 INFO     Training average negative_sample_loss at step 4100: 0.128577\n",
      "2023-12-03 12:16:29,658 INFO     Training average loss at step 4100: 0.168613\n",
      "2023-12-03 12:16:37,540 INFO     Training average positive_sample_loss at step 4200: 0.192432\n",
      "2023-12-03 12:16:37,541 INFO     Training average negative_sample_loss at step 4200: 0.123329\n",
      "2023-12-03 12:16:37,541 INFO     Training average loss at step 4200: 0.157881\n",
      "2023-12-03 12:16:45,364 INFO     Training average positive_sample_loss at step 4300: 0.196827\n",
      "2023-12-03 12:16:45,365 INFO     Training average negative_sample_loss at step 4300: 0.119599\n",
      "2023-12-03 12:16:45,365 INFO     Training average loss at step 4300: 0.158213\n",
      "2023-12-03 12:16:53,131 INFO     Training average positive_sample_loss at step 4400: 0.199103\n",
      "2023-12-03 12:16:53,132 INFO     Training average negative_sample_loss at step 4400: 0.117007\n",
      "2023-12-03 12:16:53,132 INFO     Training average loss at step 4400: 0.158055\n",
      "2023-12-03 12:17:02,987 INFO     Training average positive_sample_loss at step 4500: 0.180569\n",
      "2023-12-03 12:17:02,987 INFO     Training average negative_sample_loss at step 4500: 0.112994\n",
      "2023-12-03 12:17:02,987 INFO     Training average loss at step 4500: 0.146781\n",
      "2023-12-03 12:17:10,526 INFO     Training average positive_sample_loss at step 4600: 0.181490\n",
      "2023-12-03 12:17:10,527 INFO     Training average negative_sample_loss at step 4600: 0.108746\n",
      "2023-12-03 12:17:10,527 INFO     Training average loss at step 4600: 0.145118\n",
      "2023-12-03 12:17:18,284 INFO     Training average positive_sample_loss at step 4700: 0.185884\n",
      "2023-12-03 12:17:18,284 INFO     Training average negative_sample_loss at step 4700: 0.106484\n",
      "2023-12-03 12:17:18,284 INFO     Training average loss at step 4700: 0.146184\n",
      "2023-12-03 12:17:27,938 INFO     Training average positive_sample_loss at step 4800: 0.176761\n",
      "2023-12-03 12:17:27,939 INFO     Training average negative_sample_loss at step 4800: 0.103774\n",
      "2023-12-03 12:17:27,939 INFO     Training average loss at step 4800: 0.140268\n",
      "2023-12-03 12:17:35,453 INFO     Training average positive_sample_loss at step 4900: 0.167517\n",
      "2023-12-03 12:17:35,453 INFO     Training average negative_sample_loss at step 4900: 0.099784\n",
      "2023-12-03 12:17:35,453 INFO     Training average loss at step 4900: 0.133651\n",
      "2023-12-03 12:17:43,352 INFO     Training average positive_sample_loss at step 5000: 0.173323\n",
      "2023-12-03 12:17:43,352 INFO     Training average negative_sample_loss at step 5000: 0.097381\n",
      "2023-12-03 12:17:43,352 INFO     Training average loss at step 5000: 0.135352\n",
      "2023-12-03 12:17:52,023 INFO     Training average positive_sample_loss at step 5100: 0.173271\n",
      "2023-12-03 12:17:52,023 INFO     Training average negative_sample_loss at step 5100: 0.095679\n",
      "2023-12-03 12:17:52,023 INFO     Training average loss at step 5100: 0.134475\n",
      "2023-12-03 12:18:00,647 INFO     Training average positive_sample_loss at step 5200: 0.154691\n",
      "2023-12-03 12:18:00,647 INFO     Training average negative_sample_loss at step 5200: 0.092044\n",
      "2023-12-03 12:18:00,647 INFO     Training average loss at step 5200: 0.123367\n",
      "2023-12-03 12:18:08,510 INFO     Training average positive_sample_loss at step 5300: 0.160464\n",
      "2023-12-03 12:18:08,511 INFO     Training average negative_sample_loss at step 5300: 0.089655\n",
      "2023-12-03 12:18:08,511 INFO     Training average loss at step 5300: 0.125060\n",
      "2023-12-03 12:18:16,071 INFO     Training average positive_sample_loss at step 5400: 0.163888\n",
      "2023-12-03 12:18:16,072 INFO     Training average negative_sample_loss at step 5400: 0.087781\n",
      "2023-12-03 12:18:16,072 INFO     Training average loss at step 5400: 0.125835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:18:25,523 INFO     Training average positive_sample_loss at step 5500: 0.151617\n",
      "2023-12-03 12:18:25,523 INFO     Training average negative_sample_loss at step 5500: 0.085578\n",
      "2023-12-03 12:18:25,523 INFO     Training average loss at step 5500: 0.118597\n",
      "2023-12-03 12:18:33,481 INFO     Training average positive_sample_loss at step 5600: 0.149441\n",
      "2023-12-03 12:18:33,481 INFO     Training average negative_sample_loss at step 5600: 0.082663\n",
      "2023-12-03 12:18:33,481 INFO     Training average loss at step 5600: 0.116052\n",
      "2023-12-03 12:18:41,240 INFO     Training average positive_sample_loss at step 5700: 0.153656\n",
      "2023-12-03 12:18:41,241 INFO     Training average negative_sample_loss at step 5700: 0.081156\n",
      "2023-12-03 12:18:41,241 INFO     Training average loss at step 5700: 0.117406\n",
      "2023-12-03 12:18:51,362 INFO     Training average positive_sample_loss at step 5800: 0.149973\n",
      "2023-12-03 12:18:51,362 INFO     Training average negative_sample_loss at step 5800: 0.079676\n",
      "2023-12-03 12:18:51,362 INFO     Training average loss at step 5800: 0.114825\n",
      "2023-12-03 12:18:58,911 INFO     Training average positive_sample_loss at step 5900: 0.139313\n",
      "2023-12-03 12:18:58,912 INFO     Training average negative_sample_loss at step 5900: 0.076902\n",
      "2023-12-03 12:18:58,912 INFO     Training average loss at step 5900: 0.108107\n",
      "2023-12-03 12:19:06,580 INFO     Training average positive_sample_loss at step 6000: 0.143771\n",
      "2023-12-03 12:19:06,580 INFO     Training average negative_sample_loss at step 6000: 0.075267\n",
      "2023-12-03 12:19:06,580 INFO     Training average loss at step 6000: 0.109519\n",
      "2023-12-03 12:19:14,172 INFO     Training average positive_sample_loss at step 6100: 0.146047\n",
      "2023-12-03 12:19:14,172 INFO     Training average negative_sample_loss at step 6100: 0.074130\n",
      "2023-12-03 12:19:14,172 INFO     Training average loss at step 6100: 0.110088\n",
      "2023-12-03 12:19:23,625 INFO     Training average positive_sample_loss at step 6200: 0.133481\n",
      "2023-12-03 12:19:23,625 INFO     Training average negative_sample_loss at step 6200: 0.072085\n",
      "2023-12-03 12:19:23,625 INFO     Training average loss at step 6200: 0.102783\n",
      "2023-12-03 12:19:31,239 INFO     Training average positive_sample_loss at step 6300: 0.135204\n",
      "2023-12-03 12:19:31,240 INFO     Training average negative_sample_loss at step 6300: 0.070073\n",
      "2023-12-03 12:19:31,240 INFO     Training average loss at step 6300: 0.102639\n",
      "2023-12-03 12:19:39,109 INFO     Training average positive_sample_loss at step 6400: 0.137821\n",
      "2023-12-03 12:19:39,109 INFO     Training average negative_sample_loss at step 6400: 0.068942\n",
      "2023-12-03 12:19:39,109 INFO     Training average loss at step 6400: 0.103382\n",
      "2023-12-03 12:19:48,478 INFO     Training average positive_sample_loss at step 6500: 0.131833\n",
      "2023-12-03 12:19:48,478 INFO     Training average negative_sample_loss at step 6500: 0.067770\n",
      "2023-12-03 12:19:48,478 INFO     Training average loss at step 6500: 0.099802\n",
      "2023-12-03 12:19:56,443 INFO     Training average positive_sample_loss at step 6600: 0.127427\n",
      "2023-12-03 12:19:56,443 INFO     Training average negative_sample_loss at step 6600: 0.065687\n",
      "2023-12-03 12:19:56,443 INFO     Training average loss at step 6600: 0.096557\n",
      "2023-12-03 12:20:04,165 INFO     Training average positive_sample_loss at step 6700: 0.130803\n",
      "2023-12-03 12:20:04,165 INFO     Training average negative_sample_loss at step 6700: 0.064524\n",
      "2023-12-03 12:20:04,165 INFO     Training average loss at step 6700: 0.097664\n",
      "2023-12-03 12:20:12,745 INFO     Training average positive_sample_loss at step 6800: 0.131538\n",
      "2023-12-03 12:20:12,745 INFO     Training average negative_sample_loss at step 6800: 0.063606\n",
      "2023-12-03 12:20:12,745 INFO     Training average loss at step 6800: 0.097572\n",
      "2023-12-03 12:20:21,633 INFO     Training average positive_sample_loss at step 6900: 0.118892\n",
      "2023-12-03 12:20:21,633 INFO     Training average negative_sample_loss at step 6900: 0.061845\n",
      "2023-12-03 12:20:21,633 INFO     Training average loss at step 6900: 0.090369\n",
      "2023-12-03 12:20:29,122 INFO     Training average positive_sample_loss at step 7000: 0.124048\n",
      "2023-12-03 12:20:29,122 INFO     Training average negative_sample_loss at step 7000: 0.060621\n",
      "2023-12-03 12:20:29,122 INFO     Training average loss at step 7000: 0.092334\n",
      "2023-12-03 12:20:36,944 INFO     Training average positive_sample_loss at step 7100: 0.125689\n",
      "2023-12-03 12:20:36,944 INFO     Training average negative_sample_loss at step 7100: 0.059708\n",
      "2023-12-03 12:20:36,944 INFO     Training average loss at step 7100: 0.092698\n",
      "2023-12-03 12:20:46,551 INFO     Training average positive_sample_loss at step 7200: 0.117939\n",
      "2023-12-03 12:20:46,552 INFO     Training average negative_sample_loss at step 7200: 0.058772\n",
      "2023-12-03 12:20:46,552 INFO     Training average loss at step 7200: 0.088356\n",
      "2023-12-03 12:20:54,195 INFO     Training average positive_sample_loss at step 7300: 0.116812\n",
      "2023-12-03 12:20:54,195 INFO     Training average negative_sample_loss at step 7300: 0.057123\n",
      "2023-12-03 12:20:54,195 INFO     Training average loss at step 7300: 0.086968\n",
      "2023-12-03 12:21:02,140 INFO     Training average positive_sample_loss at step 7400: 0.119502\n",
      "2023-12-03 12:21:02,140 INFO     Training average negative_sample_loss at step 7400: 0.056121\n",
      "2023-12-03 12:21:02,140 INFO     Training average loss at step 7400: 0.087811\n",
      "2023-12-03 12:21:11,379 INFO     Training average positive_sample_loss at step 7500: 0.118408\n",
      "2023-12-03 12:21:11,379 INFO     Training average negative_sample_loss at step 7500: 0.055524\n",
      "2023-12-03 12:21:11,379 INFO     Training average loss at step 7500: 0.086966\n",
      "2023-12-03 12:21:18,939 INFO     Training average positive_sample_loss at step 7600: 0.109540\n",
      "2023-12-03 12:21:18,940 INFO     Training average negative_sample_loss at step 7600: 0.054083\n",
      "2023-12-03 12:21:18,940 INFO     Training average loss at step 7600: 0.081812\n",
      "2023-12-03 12:21:27,047 INFO     Training average positive_sample_loss at step 7700: 0.114492\n",
      "2023-12-03 12:21:27,047 INFO     Training average negative_sample_loss at step 7700: 0.053218\n",
      "2023-12-03 12:21:27,047 INFO     Training average loss at step 7700: 0.083855\n",
      "2023-12-03 12:21:34,826 INFO     Training average positive_sample_loss at step 7800: 0.116312\n",
      "2023-12-03 12:21:34,826 INFO     Training average negative_sample_loss at step 7800: 0.052729\n",
      "2023-12-03 12:21:34,826 INFO     Training average loss at step 7800: 0.084521\n",
      "2023-12-03 12:21:44,340 INFO     Training average positive_sample_loss at step 7900: 0.106341\n",
      "2023-12-03 12:21:44,341 INFO     Training average negative_sample_loss at step 7900: 0.051618\n",
      "2023-12-03 12:21:44,341 INFO     Training average loss at step 7900: 0.078980\n",
      "2023-12-03 12:21:52,414 INFO     Training average positive_sample_loss at step 8000: 0.108691\n",
      "2023-12-03 12:21:52,415 INFO     Training average negative_sample_loss at step 8000: 0.050405\n",
      "2023-12-03 12:21:52,415 INFO     Training average loss at step 8000: 0.079548\n",
      "2023-12-03 12:22:00,129 INFO     Training average positive_sample_loss at step 8100: 0.111356\n",
      "2023-12-03 12:22:00,129 INFO     Training average negative_sample_loss at step 8100: 0.050009\n",
      "2023-12-03 12:22:00,129 INFO     Training average loss at step 8100: 0.080683\n",
      "2023-12-03 12:22:09,917 INFO     Training average positive_sample_loss at step 8200: 0.107866\n",
      "2023-12-03 12:22:09,917 INFO     Training average negative_sample_loss at step 8200: 0.049537\n",
      "2023-12-03 12:22:09,917 INFO     Training average loss at step 8200: 0.078702\n",
      "2023-12-03 12:22:17,775 INFO     Training average positive_sample_loss at step 8300: 0.102838\n",
      "2023-12-03 12:22:17,775 INFO     Training average negative_sample_loss at step 8300: 0.048169\n",
      "2023-12-03 12:22:17,775 INFO     Training average loss at step 8300: 0.075503\n",
      "2023-12-03 12:22:25,864 INFO     Training average positive_sample_loss at step 8400: 0.106684\n",
      "2023-12-03 12:22:25,864 INFO     Training average negative_sample_loss at step 8400: 0.047567\n",
      "2023-12-03 12:22:25,864 INFO     Training average loss at step 8400: 0.077126\n",
      "2023-12-03 12:22:34,857 INFO     Training average positive_sample_loss at step 8500: 0.107860\n",
      "2023-12-03 12:22:34,857 INFO     Training average negative_sample_loss at step 8500: 0.047136\n",
      "2023-12-03 12:22:34,857 INFO     Training average loss at step 8500: 0.077498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:22:43,328 INFO     Training average positive_sample_loss at step 8600: 0.097375\n",
      "2023-12-03 12:22:43,328 INFO     Training average negative_sample_loss at step 8600: 0.046024\n",
      "2023-12-03 12:22:43,328 INFO     Training average loss at step 8600: 0.071699\n",
      "2023-12-03 12:22:51,112 INFO     Training average positive_sample_loss at step 8700: 0.102365\n",
      "2023-12-03 12:22:51,112 INFO     Training average negative_sample_loss at step 8700: 0.045439\n",
      "2023-12-03 12:22:51,112 INFO     Training average loss at step 8700: 0.073902\n",
      "2023-12-03 12:22:59,304 INFO     Training average positive_sample_loss at step 8800: 0.104477\n",
      "2023-12-03 12:22:59,305 INFO     Training average negative_sample_loss at step 8800: 0.045020\n",
      "2023-12-03 12:22:59,305 INFO     Training average loss at step 8800: 0.074748\n",
      "2023-12-03 12:23:08,884 INFO     Training average positive_sample_loss at step 8900: 0.097612\n",
      "2023-12-03 12:23:08,884 INFO     Training average negative_sample_loss at step 8900: 0.044509\n",
      "2023-12-03 12:23:08,884 INFO     Training average loss at step 8900: 0.071061\n",
      "2023-12-03 12:23:16,563 INFO     Training average positive_sample_loss at step 9000: 0.097643\n",
      "2023-12-03 12:23:16,564 INFO     Training average negative_sample_loss at step 9000: 0.043514\n",
      "2023-12-03 12:23:16,564 INFO     Training average loss at step 9000: 0.070578\n",
      "2023-12-03 12:23:24,089 INFO     Training average positive_sample_loss at step 9100: 0.099688\n",
      "2023-12-03 12:23:24,090 INFO     Training average negative_sample_loss at step 9100: 0.043086\n",
      "2023-12-03 12:23:24,090 INFO     Training average loss at step 9100: 0.071387\n",
      "2023-12-03 12:23:33,168 INFO     Training average positive_sample_loss at step 9200: 0.099154\n",
      "2023-12-03 12:23:33,169 INFO     Training average negative_sample_loss at step 9200: 0.042668\n",
      "2023-12-03 12:23:33,169 INFO     Training average loss at step 9200: 0.070911\n",
      "2023-12-03 12:23:41,035 INFO     Training average positive_sample_loss at step 9300: 0.092582\n",
      "2023-12-03 12:23:41,036 INFO     Training average negative_sample_loss at step 9300: 0.041793\n",
      "2023-12-03 12:23:41,036 INFO     Training average loss at step 9300: 0.067188\n",
      "2023-12-03 12:23:49,070 INFO     Training average positive_sample_loss at step 9400: 0.096458\n",
      "2023-12-03 12:23:49,070 INFO     Training average negative_sample_loss at step 9400: 0.041344\n",
      "2023-12-03 12:23:49,070 INFO     Training average loss at step 9400: 0.068901\n",
      "2023-12-03 12:23:56,954 INFO     Training average positive_sample_loss at step 9500: 0.097685\n",
      "2023-12-03 12:23:56,954 INFO     Training average negative_sample_loss at step 9500: 0.041067\n",
      "2023-12-03 12:23:56,954 INFO     Training average loss at step 9500: 0.069376\n",
      "2023-12-03 12:24:06,035 INFO     Training average positive_sample_loss at step 9600: 0.090350\n",
      "2023-12-03 12:24:06,036 INFO     Training average negative_sample_loss at step 9600: 0.040514\n",
      "2023-12-03 12:24:06,036 INFO     Training average loss at step 9600: 0.065432\n",
      "2023-12-03 12:24:13,637 INFO     Training average positive_sample_loss at step 9700: 0.092573\n",
      "2023-12-03 12:24:13,637 INFO     Training average negative_sample_loss at step 9700: 0.039694\n",
      "2023-12-03 12:24:13,637 INFO     Training average loss at step 9700: 0.066134\n",
      "2023-12-03 12:24:21,304 INFO     Training average positive_sample_loss at step 9800: 0.094935\n",
      "2023-12-03 12:24:21,305 INFO     Training average negative_sample_loss at step 9800: 0.039429\n",
      "2023-12-03 12:24:21,305 INFO     Training average loss at step 9800: 0.067182\n",
      "2023-12-03 12:24:30,951 INFO     Training average positive_sample_loss at step 9900: 0.090939\n",
      "2023-12-03 12:24:30,952 INFO     Training average negative_sample_loss at step 9900: 0.039140\n",
      "2023-12-03 12:24:30,952 INFO     Training average loss at step 9900: 0.065040\n",
      "2023-12-03 12:24:51,396 INFO     Training average positive_sample_loss at step 10000: 0.088683\n",
      "2023-12-03 12:24:51,396 INFO     Training average negative_sample_loss at step 10000: 0.038393\n",
      "2023-12-03 12:24:51,396 INFO     Training average loss at step 10000: 0.063538\n",
      "2023-12-03 12:24:51,396 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 12:24:51,942 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 12:25:23,353 INFO     Valid MRR at step 10000: 0.465963\n",
      "2023-12-03 12:25:23,354 INFO     Valid MR at step 10000: 4466.044825\n",
      "2023-12-03 12:25:23,354 INFO     Valid HITS@1 at step 10000: 0.434080\n",
      "2023-12-03 12:25:23,354 INFO     Valid HITS@3 at step 10000: 0.478906\n",
      "2023-12-03 12:25:23,354 INFO     Valid HITS@10 at step 10000: 0.526862\n",
      "2023-12-03 12:25:30,668 INFO     Training average positive_sample_loss at step 10100: 0.091877\n",
      "2023-12-03 12:25:30,669 INFO     Training average negative_sample_loss at step 10100: 0.038096\n",
      "2023-12-03 12:25:30,669 INFO     Training average loss at step 10100: 0.064986\n",
      "2023-12-03 12:25:39,193 INFO     Training average positive_sample_loss at step 10200: 0.092539\n",
      "2023-12-03 12:25:39,194 INFO     Training average negative_sample_loss at step 10200: 0.037809\n",
      "2023-12-03 12:25:39,194 INFO     Training average loss at step 10200: 0.065174\n",
      "2023-12-03 12:25:47,696 INFO     Training average positive_sample_loss at step 10300: 0.084511\n",
      "2023-12-03 12:25:47,696 INFO     Training average negative_sample_loss at step 10300: 0.037243\n",
      "2023-12-03 12:25:47,696 INFO     Training average loss at step 10300: 0.060877\n",
      "2023-12-03 12:25:55,412 INFO     Training average positive_sample_loss at step 10400: 0.088280\n",
      "2023-12-03 12:25:55,413 INFO     Training average negative_sample_loss at step 10400: 0.036737\n",
      "2023-12-03 12:25:55,413 INFO     Training average loss at step 10400: 0.062509\n",
      "2023-12-03 12:26:03,677 INFO     Training average positive_sample_loss at step 10500: 0.089671\n",
      "2023-12-03 12:26:03,677 INFO     Training average negative_sample_loss at step 10500: 0.036582\n",
      "2023-12-03 12:26:03,677 INFO     Training average loss at step 10500: 0.063127\n",
      "2023-12-03 12:26:13,256 INFO     Training average positive_sample_loss at step 10600: 0.085373\n",
      "2023-12-03 12:26:13,257 INFO     Training average negative_sample_loss at step 10600: 0.036259\n",
      "2023-12-03 12:26:13,257 INFO     Training average loss at step 10600: 0.060816\n",
      "2023-12-03 12:26:21,005 INFO     Training average positive_sample_loss at step 10700: 0.084603\n",
      "2023-12-03 12:26:21,006 INFO     Training average negative_sample_loss at step 10700: 0.035519\n",
      "2023-12-03 12:26:21,006 INFO     Training average loss at step 10700: 0.060061\n",
      "2023-12-03 12:26:28,827 INFO     Training average positive_sample_loss at step 10800: 0.087201\n",
      "2023-12-03 12:26:28,827 INFO     Training average negative_sample_loss at step 10800: 0.035286\n",
      "2023-12-03 12:26:28,827 INFO     Training average loss at step 10800: 0.061243\n",
      "2023-12-03 12:26:38,674 INFO     Training average positive_sample_loss at step 10900: 0.086296\n",
      "2023-12-03 12:26:38,675 INFO     Training average negative_sample_loss at step 10900: 0.035221\n",
      "2023-12-03 12:26:38,675 INFO     Training average loss at step 10900: 0.060758\n",
      "2023-12-03 12:26:46,594 INFO     Training average positive_sample_loss at step 11000: 0.081122\n",
      "2023-12-03 12:26:46,595 INFO     Training average negative_sample_loss at step 11000: 0.034574\n",
      "2023-12-03 12:26:46,595 INFO     Training average loss at step 11000: 0.057848\n",
      "2023-12-03 12:26:54,187 INFO     Training average positive_sample_loss at step 11100: 0.084622\n",
      "2023-12-03 12:26:54,187 INFO     Training average negative_sample_loss at step 11100: 0.034270\n",
      "2023-12-03 12:26:54,187 INFO     Training average loss at step 11100: 0.059446\n",
      "2023-12-03 12:27:01,723 INFO     Training average positive_sample_loss at step 11200: 0.086445\n",
      "2023-12-03 12:27:01,724 INFO     Training average negative_sample_loss at step 11200: 0.034244\n",
      "2023-12-03 12:27:01,724 INFO     Training average loss at step 11200: 0.060345\n",
      "2023-12-03 12:27:10,717 INFO     Training average positive_sample_loss at step 11300: 0.079390\n",
      "2023-12-03 12:27:10,718 INFO     Training average negative_sample_loss at step 11300: 0.033760\n",
      "2023-12-03 12:27:10,718 INFO     Training average loss at step 11300: 0.056575\n",
      "2023-12-03 12:27:18,520 INFO     Training average positive_sample_loss at step 11400: 0.081590\n",
      "2023-12-03 12:27:18,520 INFO     Training average negative_sample_loss at step 11400: 0.033249\n",
      "2023-12-03 12:27:18,520 INFO     Training average loss at step 11400: 0.057419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:27:26,339 INFO     Training average positive_sample_loss at step 11500: 0.083943\n",
      "2023-12-03 12:27:26,340 INFO     Training average negative_sample_loss at step 11500: 0.033189\n",
      "2023-12-03 12:27:26,340 INFO     Training average loss at step 11500: 0.058566\n",
      "2023-12-03 12:27:35,720 INFO     Training average positive_sample_loss at step 11600: 0.080365\n",
      "2023-12-03 12:27:35,721 INFO     Training average negative_sample_loss at step 11600: 0.032950\n",
      "2023-12-03 12:27:35,721 INFO     Training average loss at step 11600: 0.056658\n",
      "2023-12-03 12:27:43,433 INFO     Training average positive_sample_loss at step 11700: 0.078443\n",
      "2023-12-03 12:27:43,434 INFO     Training average negative_sample_loss at step 11700: 0.032349\n",
      "2023-12-03 12:27:43,434 INFO     Training average loss at step 11700: 0.055396\n",
      "2023-12-03 12:27:51,332 INFO     Training average positive_sample_loss at step 11800: 0.081632\n",
      "2023-12-03 12:27:51,333 INFO     Training average negative_sample_loss at step 11800: 0.032263\n",
      "2023-12-03 12:27:51,333 INFO     Training average loss at step 11800: 0.056948\n",
      "2023-12-03 12:28:00,104 INFO     Training average positive_sample_loss at step 11900: 0.082482\n",
      "2023-12-03 12:28:00,104 INFO     Training average negative_sample_loss at step 11900: 0.032208\n",
      "2023-12-03 12:28:00,104 INFO     Training average loss at step 11900: 0.057345\n",
      "2023-12-03 12:28:08,457 INFO     Training average positive_sample_loss at step 12000: 0.074979\n",
      "2023-12-03 12:28:08,457 INFO     Training average negative_sample_loss at step 12000: 0.031716\n",
      "2023-12-03 12:28:08,457 INFO     Training average loss at step 12000: 0.053348\n",
      "2023-12-03 12:28:16,115 INFO     Training average positive_sample_loss at step 12100: 0.078869\n",
      "2023-12-03 12:28:16,116 INFO     Training average negative_sample_loss at step 12100: 0.031369\n",
      "2023-12-03 12:28:16,116 INFO     Training average loss at step 12100: 0.055119\n",
      "2023-12-03 12:28:23,883 INFO     Training average positive_sample_loss at step 12200: 0.080681\n",
      "2023-12-03 12:28:23,884 INFO     Training average negative_sample_loss at step 12200: 0.031230\n",
      "2023-12-03 12:28:23,884 INFO     Training average loss at step 12200: 0.055955\n",
      "2023-12-03 12:28:33,351 INFO     Training average positive_sample_loss at step 12300: 0.076352\n",
      "2023-12-03 12:28:33,351 INFO     Training average negative_sample_loss at step 12300: 0.031160\n",
      "2023-12-03 12:28:33,351 INFO     Training average loss at step 12300: 0.053756\n",
      "2023-12-03 12:28:41,123 INFO     Training average positive_sample_loss at step 12400: 0.076024\n",
      "2023-12-03 12:28:41,124 INFO     Training average negative_sample_loss at step 12400: 0.030683\n",
      "2023-12-03 12:28:41,124 INFO     Training average loss at step 12400: 0.053354\n",
      "2023-12-03 12:28:48,844 INFO     Training average positive_sample_loss at step 12500: 0.078533\n",
      "2023-12-03 12:28:48,844 INFO     Training average negative_sample_loss at step 12500: 0.030506\n",
      "2023-12-03 12:28:48,844 INFO     Training average loss at step 12500: 0.054520\n",
      "2023-12-03 12:28:58,113 INFO     Training average positive_sample_loss at step 12600: 0.077030\n",
      "2023-12-03 12:28:58,113 INFO     Training average negative_sample_loss at step 12600: 0.030401\n",
      "2023-12-03 12:28:58,113 INFO     Training average loss at step 12600: 0.053716\n",
      "2023-12-03 12:29:06,693 INFO     Training average positive_sample_loss at step 12700: 0.072809\n",
      "2023-12-03 12:29:06,693 INFO     Training average negative_sample_loss at step 12700: 0.029906\n",
      "2023-12-03 12:29:06,693 INFO     Training average loss at step 12700: 0.051357\n",
      "2023-12-03 12:29:15,515 INFO     Training average positive_sample_loss at step 12800: 0.076226\n",
      "2023-12-03 12:29:15,516 INFO     Training average negative_sample_loss at step 12800: 0.029665\n",
      "2023-12-03 12:29:15,516 INFO     Training average loss at step 12800: 0.052946\n",
      "2023-12-03 12:29:23,837 INFO     Training average positive_sample_loss at step 12900: 0.078108\n",
      "2023-12-03 12:29:23,837 INFO     Training average negative_sample_loss at step 12900: 0.029757\n",
      "2023-12-03 12:29:23,837 INFO     Training average loss at step 12900: 0.053933\n",
      "2023-12-03 12:29:33,690 INFO     Training average positive_sample_loss at step 13000: 0.071880\n",
      "2023-12-03 12:29:33,690 INFO     Training average negative_sample_loss at step 13000: 0.029476\n",
      "2023-12-03 12:29:33,690 INFO     Training average loss at step 13000: 0.050678\n",
      "2023-12-03 12:29:41,377 INFO     Training average positive_sample_loss at step 13100: 0.073677\n",
      "2023-12-03 12:29:41,377 INFO     Training average negative_sample_loss at step 13100: 0.029084\n",
      "2023-12-03 12:29:41,377 INFO     Training average loss at step 13100: 0.051380\n",
      "2023-12-03 12:29:48,823 INFO     Training average positive_sample_loss at step 13200: 0.075646\n",
      "2023-12-03 12:29:48,823 INFO     Training average negative_sample_loss at step 13200: 0.029040\n",
      "2023-12-03 12:29:48,823 INFO     Training average loss at step 13200: 0.052343\n",
      "2023-12-03 12:29:57,968 INFO     Training average positive_sample_loss at step 13300: 0.074116\n",
      "2023-12-03 12:29:57,969 INFO     Training average negative_sample_loss at step 13300: 0.029051\n",
      "2023-12-03 12:29:57,969 INFO     Training average loss at step 13300: 0.051583\n",
      "2023-12-03 12:30:05,915 INFO     Training average positive_sample_loss at step 13400: 0.071449\n",
      "2023-12-03 12:30:05,915 INFO     Training average negative_sample_loss at step 13400: 0.028589\n",
      "2023-12-03 12:30:05,915 INFO     Training average loss at step 13400: 0.050019\n",
      "2023-12-03 12:30:13,659 INFO     Training average positive_sample_loss at step 13500: 0.073953\n",
      "2023-12-03 12:30:13,660 INFO     Training average negative_sample_loss at step 13500: 0.028359\n",
      "2023-12-03 12:30:13,660 INFO     Training average loss at step 13500: 0.051156\n",
      "2023-12-03 12:30:22,522 INFO     Training average positive_sample_loss at step 13600: 0.074899\n",
      "2023-12-03 12:30:22,522 INFO     Training average negative_sample_loss at step 13600: 0.028460\n",
      "2023-12-03 12:30:22,522 INFO     Training average loss at step 13600: 0.051679\n",
      "2023-12-03 12:30:31,062 INFO     Training average positive_sample_loss at step 13700: 0.068346\n",
      "2023-12-03 12:30:31,063 INFO     Training average negative_sample_loss at step 13700: 0.027965\n",
      "2023-12-03 12:30:31,063 INFO     Training average loss at step 13700: 0.048155\n",
      "2023-12-03 12:30:39,328 INFO     Training average positive_sample_loss at step 13800: 0.072399\n",
      "2023-12-03 12:30:39,329 INFO     Training average negative_sample_loss at step 13800: 0.027924\n",
      "2023-12-03 12:30:39,329 INFO     Training average loss at step 13800: 0.050161\n",
      "2023-12-03 12:30:46,902 INFO     Training average positive_sample_loss at step 13900: 0.073440\n",
      "2023-12-03 12:30:46,902 INFO     Training average negative_sample_loss at step 13900: 0.027818\n",
      "2023-12-03 12:30:46,902 INFO     Training average loss at step 13900: 0.050629\n",
      "2023-12-03 12:30:55,917 INFO     Training average positive_sample_loss at step 14000: 0.069552\n",
      "2023-12-03 12:30:55,917 INFO     Training average negative_sample_loss at step 14000: 0.027650\n",
      "2023-12-03 12:30:55,917 INFO     Training average loss at step 14000: 0.048601\n",
      "2023-12-03 12:31:03,690 INFO     Training average positive_sample_loss at step 14100: 0.069658\n",
      "2023-12-03 12:31:03,690 INFO     Training average negative_sample_loss at step 14100: 0.027357\n",
      "2023-12-03 12:31:03,690 INFO     Training average loss at step 14100: 0.048507\n",
      "2023-12-03 12:31:11,298 INFO     Training average positive_sample_loss at step 14200: 0.071821\n",
      "2023-12-03 12:31:11,298 INFO     Training average negative_sample_loss at step 14200: 0.027203\n",
      "2023-12-03 12:31:11,299 INFO     Training average loss at step 14200: 0.049512\n",
      "2023-12-03 12:31:20,782 INFO     Training average positive_sample_loss at step 14300: 0.071219\n",
      "2023-12-03 12:31:20,783 INFO     Training average negative_sample_loss at step 14300: 0.027262\n",
      "2023-12-03 12:31:20,783 INFO     Training average loss at step 14300: 0.049240\n",
      "2023-12-03 12:31:28,819 INFO     Training average positive_sample_loss at step 14400: 0.067538\n",
      "2023-12-03 12:31:28,820 INFO     Training average negative_sample_loss at step 14400: 0.026849\n",
      "2023-12-03 12:31:28,820 INFO     Training average loss at step 14400: 0.047194\n",
      "2023-12-03 12:31:36,495 INFO     Training average positive_sample_loss at step 14500: 0.070355\n",
      "2023-12-03 12:31:36,496 INFO     Training average negative_sample_loss at step 14500: 0.026800\n",
      "2023-12-03 12:31:36,496 INFO     Training average loss at step 14500: 0.048577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:31:44,503 INFO     Training average positive_sample_loss at step 14600: 0.071394\n",
      "2023-12-03 12:31:44,503 INFO     Training average negative_sample_loss at step 14600: 0.026714\n",
      "2023-12-03 12:31:44,503 INFO     Training average loss at step 14600: 0.049054\n",
      "2023-12-03 12:31:54,039 INFO     Training average positive_sample_loss at step 14700: 0.066752\n",
      "2023-12-03 12:31:54,039 INFO     Training average negative_sample_loss at step 14700: 0.026573\n",
      "2023-12-03 12:31:54,039 INFO     Training average loss at step 14700: 0.046662\n",
      "2023-12-03 12:32:01,780 INFO     Training average positive_sample_loss at step 14800: 0.067944\n",
      "2023-12-03 12:32:01,781 INFO     Training average negative_sample_loss at step 14800: 0.026302\n",
      "2023-12-03 12:32:01,781 INFO     Training average loss at step 14800: 0.047123\n",
      "2023-12-03 12:32:09,529 INFO     Training average positive_sample_loss at step 14900: 0.069833\n",
      "2023-12-03 12:32:09,529 INFO     Training average negative_sample_loss at step 14900: 0.026130\n",
      "2023-12-03 12:32:09,529 INFO     Training average loss at step 14900: 0.047981\n",
      "2023-12-03 12:32:19,140 INFO     Training average positive_sample_loss at step 15000: 0.068103\n",
      "2023-12-03 12:32:19,141 INFO     Training average negative_sample_loss at step 15000: 0.026322\n",
      "2023-12-03 12:32:19,141 INFO     Training average loss at step 15000: 0.047213\n",
      "2023-12-03 12:32:27,029 INFO     Training average positive_sample_loss at step 15100: 0.066235\n",
      "2023-12-03 12:32:27,030 INFO     Training average negative_sample_loss at step 15100: 0.025873\n",
      "2023-12-03 12:32:27,030 INFO     Training average loss at step 15100: 0.046054\n",
      "2023-12-03 12:32:34,673 INFO     Training average positive_sample_loss at step 15200: 0.068536\n",
      "2023-12-03 12:32:34,674 INFO     Training average negative_sample_loss at step 15200: 0.025763\n",
      "2023-12-03 12:32:34,674 INFO     Training average loss at step 15200: 0.047150\n",
      "2023-12-03 12:32:43,729 INFO     Training average positive_sample_loss at step 15300: 0.069603\n",
      "2023-12-03 12:32:43,730 INFO     Training average negative_sample_loss at step 15300: 0.025845\n",
      "2023-12-03 12:32:43,730 INFO     Training average loss at step 15300: 0.047724\n",
      "2023-12-03 12:32:52,814 INFO     Training average positive_sample_loss at step 15400: 0.063510\n",
      "2023-12-03 12:32:52,814 INFO     Training average negative_sample_loss at step 15400: 0.025585\n",
      "2023-12-03 12:32:52,814 INFO     Training average loss at step 15400: 0.044548\n",
      "2023-12-03 12:33:00,540 INFO     Training average positive_sample_loss at step 15500: 0.066924\n",
      "2023-12-03 12:33:00,540 INFO     Training average negative_sample_loss at step 15500: 0.025365\n",
      "2023-12-03 12:33:00,540 INFO     Training average loss at step 15500: 0.046145\n",
      "2023-12-03 12:33:08,382 INFO     Training average positive_sample_loss at step 15600: 0.068644\n",
      "2023-12-03 12:33:08,382 INFO     Training average negative_sample_loss at step 15600: 0.025394\n",
      "2023-12-03 12:33:08,382 INFO     Training average loss at step 15600: 0.047019\n",
      "2023-12-03 12:33:17,625 INFO     Training average positive_sample_loss at step 15700: 0.064934\n",
      "2023-12-03 12:33:17,626 INFO     Training average negative_sample_loss at step 15700: 0.025355\n",
      "2023-12-03 12:33:17,626 INFO     Training average loss at step 15700: 0.045145\n",
      "2023-12-03 12:33:25,424 INFO     Training average positive_sample_loss at step 15800: 0.064687\n",
      "2023-12-03 12:33:25,425 INFO     Training average negative_sample_loss at step 15800: 0.025037\n",
      "2023-12-03 12:33:25,425 INFO     Training average loss at step 15800: 0.044862\n",
      "2023-12-03 12:33:33,310 INFO     Training average positive_sample_loss at step 15900: 0.067266\n",
      "2023-12-03 12:33:33,310 INFO     Training average negative_sample_loss at step 15900: 0.024971\n",
      "2023-12-03 12:33:33,310 INFO     Training average loss at step 15900: 0.046119\n",
      "2023-12-03 12:33:43,020 INFO     Training average positive_sample_loss at step 16000: 0.066566\n",
      "2023-12-03 12:33:43,021 INFO     Training average negative_sample_loss at step 16000: 0.025058\n",
      "2023-12-03 12:33:43,021 INFO     Training average loss at step 16000: 0.045812\n",
      "2023-12-03 12:33:51,010 INFO     Training average positive_sample_loss at step 16100: 0.062479\n",
      "2023-12-03 12:33:51,010 INFO     Training average negative_sample_loss at step 16100: 0.024705\n",
      "2023-12-03 12:33:51,010 INFO     Training average loss at step 16100: 0.043592\n",
      "2023-12-03 12:33:58,731 INFO     Training average positive_sample_loss at step 16200: 0.065783\n",
      "2023-12-03 12:33:58,731 INFO     Training average negative_sample_loss at step 16200: 0.024632\n",
      "2023-12-03 12:33:58,731 INFO     Training average loss at step 16200: 0.045207\n",
      "2023-12-03 12:34:06,875 INFO     Training average positive_sample_loss at step 16300: 0.067047\n",
      "2023-12-03 12:34:06,875 INFO     Training average negative_sample_loss at step 16300: 0.024611\n",
      "2023-12-03 12:34:06,875 INFO     Training average loss at step 16300: 0.045829\n",
      "2023-12-03 12:34:15,942 INFO     Training average positive_sample_loss at step 16400: 0.062343\n",
      "2023-12-03 12:34:15,943 INFO     Training average negative_sample_loss at step 16400: 0.024491\n",
      "2023-12-03 12:34:15,943 INFO     Training average loss at step 16400: 0.043417\n",
      "2023-12-03 12:34:23,715 INFO     Training average positive_sample_loss at step 16500: 0.064115\n",
      "2023-12-03 12:34:23,715 INFO     Training average negative_sample_loss at step 16500: 0.024293\n",
      "2023-12-03 12:34:23,715 INFO     Training average loss at step 16500: 0.044204\n",
      "2023-12-03 12:34:31,418 INFO     Training average positive_sample_loss at step 16600: 0.066052\n",
      "2023-12-03 12:34:31,418 INFO     Training average negative_sample_loss at step 16600: 0.024327\n",
      "2023-12-03 12:34:31,418 INFO     Training average loss at step 16600: 0.045189\n",
      "2023-12-03 12:34:40,915 INFO     Training average positive_sample_loss at step 16700: 0.063173\n",
      "2023-12-03 12:34:40,916 INFO     Training average negative_sample_loss at step 16700: 0.024201\n",
      "2023-12-03 12:34:40,916 INFO     Training average loss at step 16700: 0.043687\n",
      "2023-12-03 12:34:48,740 INFO     Training average positive_sample_loss at step 16800: 0.061981\n",
      "2023-12-03 12:34:48,740 INFO     Training average negative_sample_loss at step 16800: 0.023993\n",
      "2023-12-03 12:34:48,740 INFO     Training average loss at step 16800: 0.042987\n",
      "2023-12-03 12:34:56,406 INFO     Training average positive_sample_loss at step 16900: 0.064086\n",
      "2023-12-03 12:34:56,407 INFO     Training average negative_sample_loss at step 16900: 0.023845\n",
      "2023-12-03 12:34:56,407 INFO     Training average loss at step 16900: 0.043966\n",
      "2023-12-03 12:35:05,036 INFO     Training average positive_sample_loss at step 17000: 0.065728\n",
      "2023-12-03 12:35:05,037 INFO     Training average negative_sample_loss at step 17000: 0.024006\n",
      "2023-12-03 12:35:05,037 INFO     Training average loss at step 17000: 0.044867\n",
      "2023-12-03 12:35:14,205 INFO     Training average positive_sample_loss at step 17100: 0.059944\n",
      "2023-12-03 12:35:14,205 INFO     Training average negative_sample_loss at step 17100: 0.023795\n",
      "2023-12-03 12:35:14,206 INFO     Training average loss at step 17100: 0.041870\n",
      "2023-12-03 12:35:21,874 INFO     Training average positive_sample_loss at step 17200: 0.063153\n",
      "2023-12-03 12:35:21,874 INFO     Training average negative_sample_loss at step 17200: 0.023632\n",
      "2023-12-03 12:35:21,874 INFO     Training average loss at step 17200: 0.043392\n",
      "2023-12-03 12:35:29,386 INFO     Training average positive_sample_loss at step 17300: 0.064273\n",
      "2023-12-03 12:35:29,387 INFO     Training average negative_sample_loss at step 17300: 0.023526\n",
      "2023-12-03 12:35:29,387 INFO     Training average loss at step 17300: 0.043900\n",
      "2023-12-03 12:35:38,872 INFO     Training average positive_sample_loss at step 17400: 0.061453\n",
      "2023-12-03 12:35:38,873 INFO     Training average negative_sample_loss at step 17400: 0.023676\n",
      "2023-12-03 12:35:38,873 INFO     Training average loss at step 17400: 0.042565\n",
      "2023-12-03 12:35:46,919 INFO     Training average positive_sample_loss at step 17500: 0.061415\n",
      "2023-12-03 12:35:46,920 INFO     Training average negative_sample_loss at step 17500: 0.023373\n",
      "2023-12-03 12:35:46,920 INFO     Training average loss at step 17500: 0.042394\n",
      "2023-12-03 12:35:54,828 INFO     Training average positive_sample_loss at step 17600: 0.063190\n",
      "2023-12-03 12:35:54,828 INFO     Training average negative_sample_loss at step 17600: 0.023272\n",
      "2023-12-03 12:35:54,828 INFO     Training average loss at step 17600: 0.043231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:36:04,615 INFO     Training average positive_sample_loss at step 17700: 0.062641\n",
      "2023-12-03 12:36:04,615 INFO     Training average negative_sample_loss at step 17700: 0.023308\n",
      "2023-12-03 12:36:04,615 INFO     Training average loss at step 17700: 0.042975\n",
      "2023-12-03 12:36:12,516 INFO     Training average positive_sample_loss at step 17800: 0.059585\n",
      "2023-12-03 12:36:12,516 INFO     Training average negative_sample_loss at step 17800: 0.023087\n",
      "2023-12-03 12:36:12,516 INFO     Training average loss at step 17800: 0.041336\n",
      "2023-12-03 12:36:20,704 INFO     Training average positive_sample_loss at step 17900: 0.062064\n",
      "2023-12-03 12:36:20,704 INFO     Training average negative_sample_loss at step 17900: 0.023069\n",
      "2023-12-03 12:36:20,704 INFO     Training average loss at step 17900: 0.042567\n",
      "2023-12-03 12:36:28,198 INFO     Training average positive_sample_loss at step 18000: 0.063032\n",
      "2023-12-03 12:36:28,199 INFO     Training average negative_sample_loss at step 18000: 0.023067\n",
      "2023-12-03 12:36:28,199 INFO     Training average loss at step 18000: 0.043050\n",
      "2023-12-03 12:36:37,621 INFO     Training average positive_sample_loss at step 18100: 0.059053\n",
      "2023-12-03 12:36:37,622 INFO     Training average negative_sample_loss at step 18100: 0.022962\n",
      "2023-12-03 12:36:37,622 INFO     Training average loss at step 18100: 0.041007\n",
      "2023-12-03 12:36:45,272 INFO     Training average positive_sample_loss at step 18200: 0.060606\n",
      "2023-12-03 12:36:45,273 INFO     Training average negative_sample_loss at step 18200: 0.022765\n",
      "2023-12-03 12:36:45,273 INFO     Training average loss at step 18200: 0.041685\n",
      "2023-12-03 12:36:52,921 INFO     Training average positive_sample_loss at step 18300: 0.062107\n",
      "2023-12-03 12:36:52,921 INFO     Training average negative_sample_loss at step 18300: 0.022744\n",
      "2023-12-03 12:36:52,921 INFO     Training average loss at step 18300: 0.042425\n",
      "2023-12-03 12:37:02,749 INFO     Training average positive_sample_loss at step 18400: 0.060133\n",
      "2023-12-03 12:37:02,749 INFO     Training average negative_sample_loss at step 18400: 0.022808\n",
      "2023-12-03 12:37:02,749 INFO     Training average loss at step 18400: 0.041471\n",
      "2023-12-03 12:37:10,479 INFO     Training average positive_sample_loss at step 18500: 0.059343\n",
      "2023-12-03 12:37:10,480 INFO     Training average negative_sample_loss at step 18500: 0.022627\n",
      "2023-12-03 12:37:10,480 INFO     Training average loss at step 18500: 0.040985\n",
      "2023-12-03 12:37:18,236 INFO     Training average positive_sample_loss at step 18600: 0.061265\n",
      "2023-12-03 12:37:18,236 INFO     Training average negative_sample_loss at step 18600: 0.022561\n",
      "2023-12-03 12:37:18,236 INFO     Training average loss at step 18600: 0.041913\n",
      "2023-12-03 12:37:26,390 INFO     Training average positive_sample_loss at step 18700: 0.061628\n",
      "2023-12-03 12:37:26,390 INFO     Training average negative_sample_loss at step 18700: 0.022552\n",
      "2023-12-03 12:37:26,390 INFO     Training average loss at step 18700: 0.042090\n",
      "2023-12-03 12:37:34,878 INFO     Training average positive_sample_loss at step 18800: 0.057172\n",
      "2023-12-03 12:37:34,878 INFO     Training average negative_sample_loss at step 18800: 0.022415\n",
      "2023-12-03 12:37:34,878 INFO     Training average loss at step 18800: 0.039794\n",
      "2023-12-03 12:37:42,544 INFO     Training average positive_sample_loss at step 18900: 0.059843\n",
      "2023-12-03 12:37:42,545 INFO     Training average negative_sample_loss at step 18900: 0.022223\n",
      "2023-12-03 12:37:42,545 INFO     Training average loss at step 18900: 0.041033\n",
      "2023-12-03 12:37:50,026 INFO     Training average positive_sample_loss at step 19000: 0.061246\n",
      "2023-12-03 12:37:50,027 INFO     Training average negative_sample_loss at step 19000: 0.022380\n",
      "2023-12-03 12:37:50,027 INFO     Training average loss at step 19000: 0.041813\n",
      "2023-12-03 12:37:59,288 INFO     Training average positive_sample_loss at step 19100: 0.057948\n",
      "2023-12-03 12:37:59,288 INFO     Training average negative_sample_loss at step 19100: 0.022237\n",
      "2023-12-03 12:37:59,288 INFO     Training average loss at step 19100: 0.040093\n",
      "2023-12-03 12:38:07,065 INFO     Training average positive_sample_loss at step 19200: 0.058411\n",
      "2023-12-03 12:38:07,066 INFO     Training average negative_sample_loss at step 19200: 0.022008\n",
      "2023-12-03 12:38:07,066 INFO     Training average loss at step 19200: 0.040209\n",
      "2023-12-03 12:38:14,639 INFO     Training average positive_sample_loss at step 19300: 0.060468\n",
      "2023-12-03 12:38:14,640 INFO     Training average negative_sample_loss at step 19300: 0.022131\n",
      "2023-12-03 12:38:14,640 INFO     Training average loss at step 19300: 0.041299\n",
      "2023-12-03 12:38:24,044 INFO     Training average positive_sample_loss at step 19400: 0.059822\n",
      "2023-12-03 12:38:24,045 INFO     Training average negative_sample_loss at step 19400: 0.022102\n",
      "2023-12-03 12:38:24,045 INFO     Training average loss at step 19400: 0.040962\n",
      "2023-12-03 12:38:31,967 INFO     Training average positive_sample_loss at step 19500: 0.057079\n",
      "2023-12-03 12:38:31,967 INFO     Training average negative_sample_loss at step 19500: 0.022000\n",
      "2023-12-03 12:38:31,967 INFO     Training average loss at step 19500: 0.039539\n",
      "2023-12-03 12:38:39,973 INFO     Training average positive_sample_loss at step 19600: 0.059051\n",
      "2023-12-03 12:38:39,974 INFO     Training average negative_sample_loss at step 19600: 0.021861\n",
      "2023-12-03 12:38:39,974 INFO     Training average loss at step 19600: 0.040456\n",
      "2023-12-03 12:38:47,625 INFO     Training average positive_sample_loss at step 19700: 0.060439\n",
      "2023-12-03 12:38:47,625 INFO     Training average negative_sample_loss at step 19700: 0.021992\n",
      "2023-12-03 12:38:47,626 INFO     Training average loss at step 19700: 0.041215\n",
      "2023-12-03 12:38:57,022 INFO     Training average positive_sample_loss at step 19800: 0.056081\n",
      "2023-12-03 12:38:57,023 INFO     Training average negative_sample_loss at step 19800: 0.021829\n",
      "2023-12-03 12:38:57,023 INFO     Training average loss at step 19800: 0.038955\n",
      "2023-12-03 12:39:04,965 INFO     Training average positive_sample_loss at step 19900: 0.057582\n",
      "2023-12-03 12:39:04,965 INFO     Training average negative_sample_loss at step 19900: 0.021668\n",
      "2023-12-03 12:39:04,965 INFO     Training average loss at step 19900: 0.039625\n",
      "2023-12-03 12:39:25,259 INFO     Training average positive_sample_loss at step 20000: 0.059605\n",
      "2023-12-03 12:39:25,259 INFO     Training average negative_sample_loss at step 20000: 0.021640\n",
      "2023-12-03 12:39:25,259 INFO     Training average loss at step 20000: 0.040622\n",
      "2023-12-03 12:39:25,259 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 12:39:25,889 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 12:39:59,621 INFO     Valid MRR at step 20000: 0.481500\n",
      "2023-12-03 12:39:59,622 INFO     Valid MR at step 20000: 2739.901780\n",
      "2023-12-03 12:39:59,622 INFO     Valid HITS@1 at step 20000: 0.442485\n",
      "2023-12-03 12:39:59,622 INFO     Valid HITS@3 at step 20000: 0.493243\n",
      "2023-12-03 12:39:59,622 INFO     Valid HITS@10 at step 20000: 0.558174\n",
      "2023-12-03 12:40:08,680 INFO     Training average positive_sample_loss at step 20100: 0.058005\n",
      "2023-12-03 12:40:08,680 INFO     Training average negative_sample_loss at step 20100: 0.021738\n",
      "2023-12-03 12:40:08,681 INFO     Training average loss at step 20100: 0.039871\n",
      "2023-12-03 12:40:16,688 INFO     Training average positive_sample_loss at step 20200: 0.056402\n",
      "2023-12-03 12:40:16,688 INFO     Training average negative_sample_loss at step 20200: 0.021572\n",
      "2023-12-03 12:40:16,688 INFO     Training average loss at step 20200: 0.038987\n",
      "2023-12-03 12:40:24,608 INFO     Training average positive_sample_loss at step 20300: 0.058442\n",
      "2023-12-03 12:40:24,609 INFO     Training average negative_sample_loss at step 20300: 0.021373\n",
      "2023-12-03 12:40:24,609 INFO     Training average loss at step 20300: 0.039908\n",
      "2023-12-03 12:40:33,607 INFO     Training average positive_sample_loss at step 20400: 0.059496\n",
      "2023-12-03 12:40:33,607 INFO     Training average negative_sample_loss at step 20400: 0.021567\n",
      "2023-12-03 12:40:33,607 INFO     Training average loss at step 20400: 0.040531\n",
      "2023-12-03 12:40:42,389 INFO     Training average positive_sample_loss at step 20500: 0.054641\n",
      "2023-12-03 12:40:42,389 INFO     Training average negative_sample_loss at step 20500: 0.021361\n",
      "2023-12-03 12:40:42,389 INFO     Training average loss at step 20500: 0.038001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:40:50,579 INFO     Training average positive_sample_loss at step 20600: 0.057238\n",
      "2023-12-03 12:40:50,579 INFO     Training average negative_sample_loss at step 20600: 0.021226\n",
      "2023-12-03 12:40:50,579 INFO     Training average loss at step 20600: 0.039232\n",
      "2023-12-03 12:40:58,628 INFO     Training average positive_sample_loss at step 20700: 0.058794\n",
      "2023-12-03 12:40:58,628 INFO     Training average negative_sample_loss at step 20700: 0.021415\n",
      "2023-12-03 12:40:58,628 INFO     Training average loss at step 20700: 0.040105\n",
      "2023-12-03 12:41:08,289 INFO     Training average positive_sample_loss at step 20800: 0.055800\n",
      "2023-12-03 12:41:08,289 INFO     Training average negative_sample_loss at step 20800: 0.021252\n",
      "2023-12-03 12:41:08,289 INFO     Training average loss at step 20800: 0.038526\n",
      "2023-12-03 12:41:16,019 INFO     Training average positive_sample_loss at step 20900: 0.056069\n",
      "2023-12-03 12:41:16,020 INFO     Training average negative_sample_loss at step 20900: 0.021140\n",
      "2023-12-03 12:41:16,020 INFO     Training average loss at step 20900: 0.038604\n",
      "2023-12-03 12:41:23,846 INFO     Training average positive_sample_loss at step 21000: 0.058253\n",
      "2023-12-03 12:41:23,847 INFO     Training average negative_sample_loss at step 21000: 0.021158\n",
      "2023-12-03 12:41:23,847 INFO     Training average loss at step 21000: 0.039705\n",
      "2023-12-03 12:41:33,265 INFO     Training average positive_sample_loss at step 21100: 0.057138\n",
      "2023-12-03 12:41:33,265 INFO     Training average negative_sample_loss at step 21100: 0.021273\n",
      "2023-12-03 12:41:33,265 INFO     Training average loss at step 21100: 0.039205\n",
      "2023-12-03 12:41:41,645 INFO     Training average positive_sample_loss at step 21200: 0.054532\n",
      "2023-12-03 12:41:41,645 INFO     Training average negative_sample_loss at step 21200: 0.020916\n",
      "2023-12-03 12:41:41,645 INFO     Training average loss at step 21200: 0.037724\n",
      "2023-12-03 12:41:49,719 INFO     Training average positive_sample_loss at step 21300: 0.056771\n",
      "2023-12-03 12:41:49,719 INFO     Training average negative_sample_loss at step 21300: 0.020888\n",
      "2023-12-03 12:41:49,720 INFO     Training average loss at step 21300: 0.038830\n",
      "2023-12-03 12:41:57,307 INFO     Training average positive_sample_loss at step 21400: 0.058014\n",
      "2023-12-03 12:41:57,308 INFO     Training average negative_sample_loss at step 21400: 0.021121\n",
      "2023-12-03 12:41:57,308 INFO     Training average loss at step 21400: 0.039568\n",
      "2023-12-03 12:42:06,755 INFO     Training average positive_sample_loss at step 21500: 0.054400\n",
      "2023-12-03 12:42:06,755 INFO     Training average negative_sample_loss at step 21500: 0.020899\n",
      "2023-12-03 12:42:06,755 INFO     Training average loss at step 21500: 0.037649\n",
      "2023-12-03 12:42:14,685 INFO     Training average positive_sample_loss at step 21600: 0.055772\n",
      "2023-12-03 12:42:14,685 INFO     Training average negative_sample_loss at step 21600: 0.020859\n",
      "2023-12-03 12:42:14,685 INFO     Training average loss at step 21600: 0.038316\n",
      "2023-12-03 12:42:22,925 INFO     Training average positive_sample_loss at step 21700: 0.057270\n",
      "2023-12-03 12:42:22,925 INFO     Training average negative_sample_loss at step 21700: 0.020891\n",
      "2023-12-03 12:42:22,925 INFO     Training average loss at step 21700: 0.039081\n",
      "2023-12-03 12:42:32,579 INFO     Training average positive_sample_loss at step 21800: 0.055476\n",
      "2023-12-03 12:42:32,580 INFO     Training average negative_sample_loss at step 21800: 0.020847\n",
      "2023-12-03 12:42:32,580 INFO     Training average loss at step 21800: 0.038161\n",
      "2023-12-03 12:42:40,334 INFO     Training average positive_sample_loss at step 21900: 0.054441\n",
      "2023-12-03 12:42:40,334 INFO     Training average negative_sample_loss at step 21900: 0.020727\n",
      "2023-12-03 12:42:40,334 INFO     Training average loss at step 21900: 0.037584\n",
      "2023-12-03 12:42:48,088 INFO     Training average positive_sample_loss at step 22000: 0.056438\n",
      "2023-12-03 12:42:48,088 INFO     Training average negative_sample_loss at step 22000: 0.020679\n",
      "2023-12-03 12:42:48,088 INFO     Training average loss at step 22000: 0.038558\n",
      "2023-12-03 12:42:56,747 INFO     Training average positive_sample_loss at step 22100: 0.057136\n",
      "2023-12-03 12:42:56,747 INFO     Training average negative_sample_loss at step 22100: 0.020687\n",
      "2023-12-03 12:42:56,747 INFO     Training average loss at step 22100: 0.038911\n",
      "2023-12-03 12:43:05,411 INFO     Training average positive_sample_loss at step 22200: 0.052429\n",
      "2023-12-03 12:43:05,412 INFO     Training average negative_sample_loss at step 22200: 0.020475\n",
      "2023-12-03 12:43:05,412 INFO     Training average loss at step 22200: 0.036452\n",
      "2023-12-03 12:43:13,195 INFO     Training average positive_sample_loss at step 22300: 0.055171\n",
      "2023-12-03 12:43:13,196 INFO     Training average negative_sample_loss at step 22300: 0.020412\n",
      "2023-12-03 12:43:13,196 INFO     Training average loss at step 22300: 0.037791\n",
      "2023-12-03 12:43:20,815 INFO     Training average positive_sample_loss at step 22400: 0.057384\n",
      "2023-12-03 12:43:20,815 INFO     Training average negative_sample_loss at step 22400: 0.020560\n",
      "2023-12-03 12:43:20,815 INFO     Training average loss at step 22400: 0.038972\n",
      "2023-12-03 12:43:30,840 INFO     Training average positive_sample_loss at step 22500: 0.053687\n",
      "2023-12-03 12:43:30,840 INFO     Training average negative_sample_loss at step 22500: 0.020562\n",
      "2023-12-03 12:43:30,840 INFO     Training average loss at step 22500: 0.037124\n",
      "2023-12-03 12:43:38,303 INFO     Training average positive_sample_loss at step 22600: 0.053961\n",
      "2023-12-03 12:43:38,303 INFO     Training average negative_sample_loss at step 22600: 0.020313\n",
      "2023-12-03 12:43:38,303 INFO     Training average loss at step 22600: 0.037137\n",
      "2023-12-03 12:43:45,884 INFO     Training average positive_sample_loss at step 22700: 0.056055\n",
      "2023-12-03 12:43:45,884 INFO     Training average negative_sample_loss at step 22700: 0.020366\n",
      "2023-12-03 12:43:45,884 INFO     Training average loss at step 22700: 0.038211\n",
      "2023-12-03 12:43:54,779 INFO     Training average positive_sample_loss at step 22800: 0.055499\n",
      "2023-12-03 12:43:54,780 INFO     Training average negative_sample_loss at step 22800: 0.020556\n",
      "2023-12-03 12:43:54,780 INFO     Training average loss at step 22800: 0.038028\n",
      "2023-12-03 12:44:02,406 INFO     Training average positive_sample_loss at step 22900: 0.052865\n",
      "2023-12-03 12:44:02,406 INFO     Training average negative_sample_loss at step 22900: 0.020261\n",
      "2023-12-03 12:44:02,406 INFO     Training average loss at step 22900: 0.036563\n",
      "2023-12-03 12:44:10,062 INFO     Training average positive_sample_loss at step 23000: 0.054980\n",
      "2023-12-03 12:44:10,062 INFO     Training average negative_sample_loss at step 23000: 0.020151\n",
      "2023-12-03 12:44:10,062 INFO     Training average loss at step 23000: 0.037565\n",
      "2023-12-03 12:44:17,906 INFO     Training average positive_sample_loss at step 23100: 0.055721\n",
      "2023-12-03 12:44:17,906 INFO     Training average negative_sample_loss at step 23100: 0.020330\n",
      "2023-12-03 12:44:17,906 INFO     Training average loss at step 23100: 0.038025\n",
      "2023-12-03 12:44:27,160 INFO     Training average positive_sample_loss at step 23200: 0.052440\n",
      "2023-12-03 12:44:27,160 INFO     Training average negative_sample_loss at step 23200: 0.020194\n",
      "2023-12-03 12:44:27,160 INFO     Training average loss at step 23200: 0.036317\n",
      "2023-12-03 12:44:35,034 INFO     Training average positive_sample_loss at step 23300: 0.053877\n",
      "2023-12-03 12:44:35,034 INFO     Training average negative_sample_loss at step 23300: 0.020190\n",
      "2023-12-03 12:44:35,034 INFO     Training average loss at step 23300: 0.037033\n",
      "2023-12-03 12:44:42,841 INFO     Training average positive_sample_loss at step 23400: 0.055389\n",
      "2023-12-03 12:44:42,842 INFO     Training average negative_sample_loss at step 23400: 0.020145\n",
      "2023-12-03 12:44:42,842 INFO     Training average loss at step 23400: 0.037767\n",
      "2023-12-03 12:44:52,625 INFO     Training average positive_sample_loss at step 23500: 0.053703\n",
      "2023-12-03 12:44:52,625 INFO     Training average negative_sample_loss at step 23500: 0.020094\n",
      "2023-12-03 12:44:52,625 INFO     Training average loss at step 23500: 0.036898\n",
      "2023-12-03 12:45:00,176 INFO     Training average positive_sample_loss at step 23600: 0.052272\n",
      "2023-12-03 12:45:00,177 INFO     Training average negative_sample_loss at step 23600: 0.019946\n",
      "2023-12-03 12:45:00,177 INFO     Training average loss at step 23600: 0.036109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:45:07,661 INFO     Training average positive_sample_loss at step 23700: 0.054775\n",
      "2023-12-03 12:45:07,661 INFO     Training average negative_sample_loss at step 23700: 0.020000\n",
      "2023-12-03 12:45:07,661 INFO     Training average loss at step 23700: 0.037388\n",
      "2023-12-03 12:45:16,197 INFO     Training average positive_sample_loss at step 23800: 0.055986\n",
      "2023-12-03 12:45:16,197 INFO     Training average negative_sample_loss at step 23800: 0.020039\n",
      "2023-12-03 12:45:16,197 INFO     Training average loss at step 23800: 0.038012\n",
      "2023-12-03 12:45:24,837 INFO     Training average positive_sample_loss at step 23900: 0.050993\n",
      "2023-12-03 12:45:24,838 INFO     Training average negative_sample_loss at step 23900: 0.020024\n",
      "2023-12-03 12:45:24,838 INFO     Training average loss at step 23900: 0.035509\n",
      "2023-12-03 12:45:32,560 INFO     Training average positive_sample_loss at step 24000: 0.053734\n",
      "2023-12-03 12:45:32,561 INFO     Training average negative_sample_loss at step 24000: 0.019853\n",
      "2023-12-03 12:45:32,561 INFO     Training average loss at step 24000: 0.036794\n",
      "2023-12-03 12:45:40,229 INFO     Training average positive_sample_loss at step 24100: 0.054855\n",
      "2023-12-03 12:45:40,229 INFO     Training average negative_sample_loss at step 24100: 0.019916\n",
      "2023-12-03 12:45:40,229 INFO     Training average loss at step 24100: 0.037386\n",
      "2023-12-03 12:45:50,171 INFO     Training average positive_sample_loss at step 24200: 0.052314\n",
      "2023-12-03 12:45:50,171 INFO     Training average negative_sample_loss at step 24200: 0.019936\n",
      "2023-12-03 12:45:50,171 INFO     Training average loss at step 24200: 0.036125\n",
      "2023-12-03 12:45:58,231 INFO     Training average positive_sample_loss at step 24300: 0.052538\n",
      "2023-12-03 12:45:58,231 INFO     Training average negative_sample_loss at step 24300: 0.019708\n",
      "2023-12-03 12:45:58,231 INFO     Training average loss at step 24300: 0.036123\n",
      "2023-12-03 12:46:06,038 INFO     Training average positive_sample_loss at step 24400: 0.054231\n",
      "2023-12-03 12:46:06,039 INFO     Training average negative_sample_loss at step 24400: 0.019861\n",
      "2023-12-03 12:46:06,039 INFO     Training average loss at step 24400: 0.037046\n",
      "2023-12-03 12:46:15,665 INFO     Training average positive_sample_loss at step 24500: 0.053911\n",
      "2023-12-03 12:46:15,666 INFO     Training average negative_sample_loss at step 24500: 0.019855\n",
      "2023-12-03 12:46:15,666 INFO     Training average loss at step 24500: 0.036883\n",
      "2023-12-03 12:46:23,485 INFO     Training average positive_sample_loss at step 24600: 0.051075\n",
      "2023-12-03 12:46:23,486 INFO     Training average negative_sample_loss at step 24600: 0.019735\n",
      "2023-12-03 12:46:23,486 INFO     Training average loss at step 24600: 0.035405\n",
      "2023-12-03 12:46:31,773 INFO     Training average positive_sample_loss at step 24700: 0.053544\n",
      "2023-12-03 12:46:31,774 INFO     Training average negative_sample_loss at step 24700: 0.019623\n",
      "2023-12-03 12:46:31,774 INFO     Training average loss at step 24700: 0.036584\n",
      "2023-12-03 12:46:39,369 INFO     Training average positive_sample_loss at step 24800: 0.054510\n",
      "2023-12-03 12:46:39,369 INFO     Training average negative_sample_loss at step 24800: 0.019619\n",
      "2023-12-03 12:46:39,369 INFO     Training average loss at step 24800: 0.037065\n",
      "2023-12-03 12:46:48,599 INFO     Training average positive_sample_loss at step 24900: 0.051025\n",
      "2023-12-03 12:46:48,600 INFO     Training average negative_sample_loss at step 24900: 0.019703\n",
      "2023-12-03 12:46:48,600 INFO     Training average loss at step 24900: 0.035364\n",
      "2023-12-03 12:46:56,288 INFO     Training average positive_sample_loss at step 25000: 0.052599\n",
      "2023-12-03 12:46:56,288 INFO     Training average negative_sample_loss at step 25000: 0.019574\n",
      "2023-12-03 12:46:56,288 INFO     Training average loss at step 25000: 0.036086\n",
      "2023-12-03 12:47:04,168 INFO     Training average positive_sample_loss at step 25100: 0.053749\n",
      "2023-12-03 12:47:04,168 INFO     Training average negative_sample_loss at step 25100: 0.019601\n",
      "2023-12-03 12:47:04,168 INFO     Training average loss at step 25100: 0.036675\n",
      "2023-12-03 12:47:13,805 INFO     Training average positive_sample_loss at step 25200: 0.052149\n",
      "2023-12-03 12:47:13,805 INFO     Training average negative_sample_loss at step 25200: 0.019626\n",
      "2023-12-03 12:47:13,805 INFO     Training average loss at step 25200: 0.035887\n",
      "2023-12-03 12:47:21,605 INFO     Training average positive_sample_loss at step 25300: 0.051043\n",
      "2023-12-03 12:47:21,605 INFO     Training average negative_sample_loss at step 25300: 0.019483\n",
      "2023-12-03 12:47:21,605 INFO     Training average loss at step 25300: 0.035263\n",
      "2023-12-03 12:47:29,338 INFO     Training average positive_sample_loss at step 25400: 0.053640\n",
      "2023-12-03 12:47:29,338 INFO     Training average negative_sample_loss at step 25400: 0.019511\n",
      "2023-12-03 12:47:29,338 INFO     Training average loss at step 25400: 0.036576\n",
      "2023-12-03 12:47:38,148 INFO     Training average positive_sample_loss at step 25500: 0.053590\n",
      "2023-12-03 12:47:38,148 INFO     Training average negative_sample_loss at step 25500: 0.019391\n",
      "2023-12-03 12:47:38,148 INFO     Training average loss at step 25500: 0.036490\n",
      "2023-12-03 12:47:46,575 INFO     Training average positive_sample_loss at step 25600: 0.049875\n",
      "2023-12-03 12:47:46,575 INFO     Training average negative_sample_loss at step 25600: 0.019314\n",
      "2023-12-03 12:47:46,575 INFO     Training average loss at step 25600: 0.034595\n",
      "2023-12-03 12:47:54,257 INFO     Training average positive_sample_loss at step 25700: 0.052220\n",
      "2023-12-03 12:47:54,258 INFO     Training average negative_sample_loss at step 25700: 0.019326\n",
      "2023-12-03 12:47:54,258 INFO     Training average loss at step 25700: 0.035773\n",
      "2023-12-03 12:48:01,890 INFO     Training average positive_sample_loss at step 25800: 0.053345\n",
      "2023-12-03 12:48:01,891 INFO     Training average negative_sample_loss at step 25800: 0.019458\n",
      "2023-12-03 12:48:01,891 INFO     Training average loss at step 25800: 0.036402\n",
      "2023-12-03 12:48:11,250 INFO     Training average positive_sample_loss at step 25900: 0.051008\n",
      "2023-12-03 12:48:11,250 INFO     Training average negative_sample_loss at step 25900: 0.019526\n",
      "2023-12-03 12:48:11,250 INFO     Training average loss at step 25900: 0.035267\n",
      "2023-12-03 12:48:18,948 INFO     Training average positive_sample_loss at step 26000: 0.051104\n",
      "2023-12-03 12:48:18,949 INFO     Training average negative_sample_loss at step 26000: 0.019211\n",
      "2023-12-03 12:48:18,949 INFO     Training average loss at step 26000: 0.035157\n",
      "2023-12-03 12:48:27,455 INFO     Training average positive_sample_loss at step 26100: 0.053264\n",
      "2023-12-03 12:48:27,455 INFO     Training average negative_sample_loss at step 26100: 0.019393\n",
      "2023-12-03 12:48:27,455 INFO     Training average loss at step 26100: 0.036329\n",
      "2023-12-03 12:48:36,560 INFO     Training average positive_sample_loss at step 26200: 0.052131\n",
      "2023-12-03 12:48:36,560 INFO     Training average negative_sample_loss at step 26200: 0.019324\n",
      "2023-12-03 12:48:36,560 INFO     Training average loss at step 26200: 0.035728\n",
      "2023-12-03 12:48:44,174 INFO     Training average positive_sample_loss at step 26300: 0.050128\n",
      "2023-12-03 12:48:44,175 INFO     Training average negative_sample_loss at step 26300: 0.019248\n",
      "2023-12-03 12:48:44,175 INFO     Training average loss at step 26300: 0.034688\n",
      "2023-12-03 12:48:52,331 INFO     Training average positive_sample_loss at step 26400: 0.052204\n",
      "2023-12-03 12:48:52,332 INFO     Training average negative_sample_loss at step 26400: 0.019200\n",
      "2023-12-03 12:48:52,332 INFO     Training average loss at step 26400: 0.035702\n",
      "2023-12-03 12:49:00,280 INFO     Training average positive_sample_loss at step 26500: 0.053023\n",
      "2023-12-03 12:49:00,281 INFO     Training average negative_sample_loss at step 26500: 0.019366\n",
      "2023-12-03 12:49:00,281 INFO     Training average loss at step 26500: 0.036194\n",
      "2023-12-03 12:49:09,882 INFO     Training average positive_sample_loss at step 26600: 0.049608\n",
      "2023-12-03 12:49:09,883 INFO     Training average negative_sample_loss at step 26600: 0.019125\n",
      "2023-12-03 12:49:09,883 INFO     Training average loss at step 26600: 0.034366\n",
      "2023-12-03 12:49:17,596 INFO     Training average positive_sample_loss at step 26700: 0.051333\n",
      "2023-12-03 12:49:17,596 INFO     Training average negative_sample_loss at step 26700: 0.019175\n",
      "2023-12-03 12:49:17,596 INFO     Training average loss at step 26700: 0.035254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:49:25,323 INFO     Training average positive_sample_loss at step 26800: 0.052802\n",
      "2023-12-03 12:49:25,323 INFO     Training average negative_sample_loss at step 26800: 0.019151\n",
      "2023-12-03 12:49:25,323 INFO     Training average loss at step 26800: 0.035977\n",
      "2023-12-03 12:49:34,603 INFO     Training average positive_sample_loss at step 26900: 0.050679\n",
      "2023-12-03 12:49:34,603 INFO     Training average negative_sample_loss at step 26900: 0.019254\n",
      "2023-12-03 12:49:34,603 INFO     Training average loss at step 26900: 0.034966\n",
      "2023-12-03 12:49:42,291 INFO     Training average positive_sample_loss at step 27000: 0.049981\n",
      "2023-12-03 12:49:42,291 INFO     Training average negative_sample_loss at step 27000: 0.019090\n",
      "2023-12-03 12:49:42,291 INFO     Training average loss at step 27000: 0.034535\n",
      "2023-12-03 12:49:50,000 INFO     Training average positive_sample_loss at step 27100: 0.051814\n",
      "2023-12-03 12:49:50,001 INFO     Training average negative_sample_loss at step 27100: 0.018968\n",
      "2023-12-03 12:49:50,001 INFO     Training average loss at step 27100: 0.035391\n",
      "2023-12-03 12:49:58,344 INFO     Training average positive_sample_loss at step 27200: 0.053037\n",
      "2023-12-03 12:49:58,344 INFO     Training average negative_sample_loss at step 27200: 0.019251\n",
      "2023-12-03 12:49:58,344 INFO     Training average loss at step 27200: 0.036144\n",
      "2023-12-03 12:50:07,129 INFO     Training average positive_sample_loss at step 27300: 0.048595\n",
      "2023-12-03 12:50:07,129 INFO     Training average negative_sample_loss at step 27300: 0.018975\n",
      "2023-12-03 12:50:07,129 INFO     Training average loss at step 27300: 0.033785\n",
      "2023-12-03 12:50:14,731 INFO     Training average positive_sample_loss at step 27400: 0.051301\n",
      "2023-12-03 12:50:14,732 INFO     Training average negative_sample_loss at step 27400: 0.018927\n",
      "2023-12-03 12:50:14,732 INFO     Training average loss at step 27400: 0.035114\n",
      "2023-12-03 12:50:22,255 INFO     Training average positive_sample_loss at step 27500: 0.052304\n",
      "2023-12-03 12:50:22,256 INFO     Training average negative_sample_loss at step 27500: 0.019046\n",
      "2023-12-03 12:50:22,256 INFO     Training average loss at step 27500: 0.035675\n",
      "2023-12-03 12:50:32,014 INFO     Training average positive_sample_loss at step 27600: 0.049593\n",
      "2023-12-03 12:50:32,015 INFO     Training average negative_sample_loss at step 27600: 0.019007\n",
      "2023-12-03 12:50:32,015 INFO     Training average loss at step 27600: 0.034300\n",
      "2023-12-03 12:50:39,924 INFO     Training average positive_sample_loss at step 27700: 0.050323\n",
      "2023-12-03 12:50:39,925 INFO     Training average negative_sample_loss at step 27700: 0.018909\n",
      "2023-12-03 12:50:39,925 INFO     Training average loss at step 27700: 0.034616\n",
      "2023-12-03 12:50:47,798 INFO     Training average positive_sample_loss at step 27800: 0.051637\n",
      "2023-12-03 12:50:47,798 INFO     Training average negative_sample_loss at step 27800: 0.018992\n",
      "2023-12-03 12:50:47,799 INFO     Training average loss at step 27800: 0.035314\n",
      "2023-12-03 12:50:56,691 INFO     Training average positive_sample_loss at step 27900: 0.051256\n",
      "2023-12-03 12:50:56,692 INFO     Training average negative_sample_loss at step 27900: 0.018959\n",
      "2023-12-03 12:50:56,692 INFO     Training average loss at step 27900: 0.035108\n",
      "2023-12-03 12:51:04,381 INFO     Training average positive_sample_loss at step 28000: 0.049246\n",
      "2023-12-03 12:51:04,382 INFO     Training average negative_sample_loss at step 28000: 0.018872\n",
      "2023-12-03 12:51:04,382 INFO     Training average loss at step 28000: 0.034059\n",
      "2023-12-03 12:51:12,024 INFO     Training average positive_sample_loss at step 28100: 0.050975\n",
      "2023-12-03 12:51:12,025 INFO     Training average negative_sample_loss at step 28100: 0.018900\n",
      "2023-12-03 12:51:12,025 INFO     Training average loss at step 28100: 0.034937\n",
      "2023-12-03 12:51:20,120 INFO     Training average positive_sample_loss at step 28200: 0.051770\n",
      "2023-12-03 12:51:20,121 INFO     Training average negative_sample_loss at step 28200: 0.018917\n",
      "2023-12-03 12:51:20,121 INFO     Training average loss at step 28200: 0.035343\n",
      "2023-12-03 12:51:29,541 INFO     Training average positive_sample_loss at step 28300: 0.049068\n",
      "2023-12-03 12:51:29,541 INFO     Training average negative_sample_loss at step 28300: 0.018850\n",
      "2023-12-03 12:51:29,541 INFO     Training average loss at step 28300: 0.033959\n",
      "2023-12-03 12:51:37,638 INFO     Training average positive_sample_loss at step 28400: 0.049991\n",
      "2023-12-03 12:51:37,638 INFO     Training average negative_sample_loss at step 28400: 0.018728\n",
      "2023-12-03 12:51:37,638 INFO     Training average loss at step 28400: 0.034360\n",
      "2023-12-03 12:51:45,419 INFO     Training average positive_sample_loss at step 28500: 0.051196\n",
      "2023-12-03 12:51:45,419 INFO     Training average negative_sample_loss at step 28500: 0.018723\n",
      "2023-12-03 12:51:45,419 INFO     Training average loss at step 28500: 0.034960\n",
      "2023-12-03 12:51:54,758 INFO     Training average positive_sample_loss at step 28600: 0.049886\n",
      "2023-12-03 12:51:54,759 INFO     Training average negative_sample_loss at step 28600: 0.018935\n",
      "2023-12-03 12:51:54,759 INFO     Training average loss at step 28600: 0.034411\n",
      "2023-12-03 12:52:03,040 INFO     Training average positive_sample_loss at step 28700: 0.048827\n",
      "2023-12-03 12:52:03,041 INFO     Training average negative_sample_loss at step 28700: 0.018588\n",
      "2023-12-03 12:52:03,041 INFO     Training average loss at step 28700: 0.033708\n",
      "2023-12-03 12:52:10,932 INFO     Training average positive_sample_loss at step 28800: 0.051006\n",
      "2023-12-03 12:52:10,932 INFO     Training average negative_sample_loss at step 28800: 0.018724\n",
      "2023-12-03 12:52:10,933 INFO     Training average loss at step 28800: 0.034865\n",
      "2023-12-03 12:52:19,468 INFO     Training average positive_sample_loss at step 28900: 0.051812\n",
      "2023-12-03 12:52:19,468 INFO     Training average negative_sample_loss at step 28900: 0.018852\n",
      "2023-12-03 12:52:19,469 INFO     Training average loss at step 28900: 0.035332\n",
      "2023-12-03 12:52:28,180 INFO     Training average positive_sample_loss at step 29000: 0.047790\n",
      "2023-12-03 12:52:28,180 INFO     Training average negative_sample_loss at step 29000: 0.018531\n",
      "2023-12-03 12:52:28,180 INFO     Training average loss at step 29000: 0.033160\n",
      "2023-12-03 12:52:36,033 INFO     Training average positive_sample_loss at step 29100: 0.049907\n",
      "2023-12-03 12:52:36,034 INFO     Training average negative_sample_loss at step 29100: 0.018543\n",
      "2023-12-03 12:52:36,034 INFO     Training average loss at step 29100: 0.034225\n",
      "2023-12-03 12:52:43,620 INFO     Training average positive_sample_loss at step 29200: 0.051277\n",
      "2023-12-03 12:52:43,620 INFO     Training average negative_sample_loss at step 29200: 0.018662\n",
      "2023-12-03 12:52:43,620 INFO     Training average loss at step 29200: 0.034969\n",
      "2023-12-03 12:52:52,873 INFO     Training average positive_sample_loss at step 29300: 0.049076\n",
      "2023-12-03 12:52:52,874 INFO     Training average negative_sample_loss at step 29300: 0.018682\n",
      "2023-12-03 12:52:52,874 INFO     Training average loss at step 29300: 0.033879\n",
      "2023-12-03 12:53:00,715 INFO     Training average positive_sample_loss at step 29400: 0.048805\n",
      "2023-12-03 12:53:00,715 INFO     Training average negative_sample_loss at step 29400: 0.018484\n",
      "2023-12-03 12:53:00,715 INFO     Training average loss at step 29400: 0.033644\n",
      "2023-12-03 12:53:08,493 INFO     Training average positive_sample_loss at step 29500: 0.050795\n",
      "2023-12-03 12:53:08,494 INFO     Training average negative_sample_loss at step 29500: 0.018618\n",
      "2023-12-03 12:53:08,494 INFO     Training average loss at step 29500: 0.034706\n",
      "2023-12-03 12:53:17,860 INFO     Training average positive_sample_loss at step 29600: 0.050464\n",
      "2023-12-03 12:53:17,860 INFO     Training average negative_sample_loss at step 29600: 0.018643\n",
      "2023-12-03 12:53:17,861 INFO     Training average loss at step 29600: 0.034553\n",
      "2023-12-03 12:53:25,563 INFO     Training average positive_sample_loss at step 29700: 0.047931\n",
      "2023-12-03 12:53:25,563 INFO     Training average negative_sample_loss at step 29700: 0.018482\n",
      "2023-12-03 12:53:25,563 INFO     Training average loss at step 29700: 0.033206\n",
      "2023-12-03 12:53:33,492 INFO     Training average positive_sample_loss at step 29800: 0.049963\n",
      "2023-12-03 12:53:33,492 INFO     Training average negative_sample_loss at step 29800: 0.018627\n",
      "2023-12-03 12:53:33,492 INFO     Training average loss at step 29800: 0.034295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:53:41,164 INFO     Training average positive_sample_loss at step 29900: 0.051175\n",
      "2023-12-03 12:53:41,164 INFO     Training average negative_sample_loss at step 29900: 0.018705\n",
      "2023-12-03 12:53:41,164 INFO     Training average loss at step 29900: 0.034940\n",
      "2023-12-03 12:54:07,249 INFO     Training average positive_sample_loss at step 30000: 0.048173\n",
      "2023-12-03 12:54:07,249 INFO     Training average negative_sample_loss at step 30000: 0.018530\n",
      "2023-12-03 12:54:07,249 INFO     Training average loss at step 30000: 0.033352\n",
      "2023-12-03 12:54:07,249 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 12:54:07,849 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 12:54:38,584 INFO     Valid MRR at step 30000: 0.481685\n",
      "2023-12-03 12:54:38,585 INFO     Valid MR at step 30000: 2108.563942\n",
      "2023-12-03 12:54:38,585 INFO     Valid HITS@1 at step 30000: 0.439189\n",
      "2023-12-03 12:54:38,585 INFO     Valid HITS@3 at step 30000: 0.495386\n",
      "2023-12-03 12:54:38,585 INFO     Valid HITS@10 at step 30000: 0.565260\n",
      "2023-12-03 12:54:45,879 INFO     Training average positive_sample_loss at step 30100: 0.049347\n",
      "2023-12-03 12:54:45,879 INFO     Training average negative_sample_loss at step 30100: 0.018473\n",
      "2023-12-03 12:54:45,879 INFO     Training average loss at step 30100: 0.033910\n",
      "2023-12-03 12:54:53,750 INFO     Training average positive_sample_loss at step 30200: 0.050635\n",
      "2023-12-03 12:54:53,751 INFO     Training average negative_sample_loss at step 30200: 0.018516\n",
      "2023-12-03 12:54:53,751 INFO     Training average loss at step 30200: 0.034575\n",
      "2023-12-03 12:55:03,238 INFO     Training average positive_sample_loss at step 30300: 0.048808\n",
      "2023-12-03 12:55:03,239 INFO     Training average negative_sample_loss at step 30300: 0.018398\n",
      "2023-12-03 12:55:03,239 INFO     Training average loss at step 30300: 0.033603\n",
      "2023-12-03 12:55:11,092 INFO     Training average positive_sample_loss at step 30400: 0.048204\n",
      "2023-12-03 12:55:11,092 INFO     Training average negative_sample_loss at step 30400: 0.018380\n",
      "2023-12-03 12:55:11,092 INFO     Training average loss at step 30400: 0.033292\n",
      "2023-12-03 12:55:18,616 INFO     Training average positive_sample_loss at step 30500: 0.049734\n",
      "2023-12-03 12:55:18,616 INFO     Training average negative_sample_loss at step 30500: 0.018337\n",
      "2023-12-03 12:55:18,616 INFO     Training average loss at step 30500: 0.034036\n",
      "2023-12-03 12:55:27,387 INFO     Training average positive_sample_loss at step 30600: 0.050823\n",
      "2023-12-03 12:55:27,387 INFO     Training average negative_sample_loss at step 30600: 0.018678\n",
      "2023-12-03 12:55:27,387 INFO     Training average loss at step 30600: 0.034750\n",
      "2023-12-03 12:55:36,342 INFO     Training average positive_sample_loss at step 30700: 0.046890\n",
      "2023-12-03 12:55:36,343 INFO     Training average negative_sample_loss at step 30700: 0.018397\n",
      "2023-12-03 12:55:36,343 INFO     Training average loss at step 30700: 0.032644\n",
      "2023-12-03 12:55:43,879 INFO     Training average positive_sample_loss at step 30800: 0.048934\n",
      "2023-12-03 12:55:43,879 INFO     Training average negative_sample_loss at step 30800: 0.018248\n",
      "2023-12-03 12:55:43,879 INFO     Training average loss at step 30800: 0.033591\n",
      "2023-12-03 12:55:51,788 INFO     Training average positive_sample_loss at step 30900: 0.050567\n",
      "2023-12-03 12:55:51,789 INFO     Training average negative_sample_loss at step 30900: 0.018440\n",
      "2023-12-03 12:55:51,789 INFO     Training average loss at step 30900: 0.034504\n",
      "2023-12-03 12:56:01,572 INFO     Training average positive_sample_loss at step 31000: 0.048271\n",
      "2023-12-03 12:56:01,573 INFO     Training average negative_sample_loss at step 31000: 0.018451\n",
      "2023-12-03 12:56:01,573 INFO     Training average loss at step 31000: 0.033361\n",
      "2023-12-03 12:56:09,368 INFO     Training average positive_sample_loss at step 31100: 0.048256\n",
      "2023-12-03 12:56:09,368 INFO     Training average negative_sample_loss at step 31100: 0.018315\n",
      "2023-12-03 12:56:09,368 INFO     Training average loss at step 31100: 0.033286\n",
      "2023-12-03 12:56:17,085 INFO     Training average positive_sample_loss at step 31200: 0.049961\n",
      "2023-12-03 12:56:17,085 INFO     Training average negative_sample_loss at step 31200: 0.018317\n",
      "2023-12-03 12:56:17,086 INFO     Training average loss at step 31200: 0.034139\n",
      "2023-12-03 12:56:27,332 INFO     Training average positive_sample_loss at step 31300: 0.049469\n",
      "2023-12-03 12:56:27,332 INFO     Training average negative_sample_loss at step 31300: 0.018493\n",
      "2023-12-03 12:56:27,332 INFO     Training average loss at step 31300: 0.033981\n",
      "2023-12-03 12:56:35,307 INFO     Training average positive_sample_loss at step 31400: 0.047098\n",
      "2023-12-03 12:56:35,308 INFO     Training average negative_sample_loss at step 31400: 0.018253\n",
      "2023-12-03 12:56:35,308 INFO     Training average loss at step 31400: 0.032675\n",
      "2023-12-03 12:56:43,140 INFO     Training average positive_sample_loss at step 31500: 0.049032\n",
      "2023-12-03 12:56:43,140 INFO     Training average negative_sample_loss at step 31500: 0.018246\n",
      "2023-12-03 12:56:43,140 INFO     Training average loss at step 31500: 0.033639\n",
      "2023-12-03 12:56:50,832 INFO     Training average positive_sample_loss at step 31600: 0.050492\n",
      "2023-12-03 12:56:50,833 INFO     Training average negative_sample_loss at step 31600: 0.018314\n",
      "2023-12-03 12:56:50,833 INFO     Training average loss at step 31600: 0.034403\n",
      "2023-12-03 12:57:01,036 INFO     Training average positive_sample_loss at step 31700: 0.047337\n",
      "2023-12-03 12:57:01,036 INFO     Training average negative_sample_loss at step 31700: 0.018289\n",
      "2023-12-03 12:57:01,036 INFO     Training average loss at step 31700: 0.032813\n",
      "2023-12-03 12:57:08,681 INFO     Training average positive_sample_loss at step 31800: 0.048482\n",
      "2023-12-03 12:57:08,682 INFO     Training average negative_sample_loss at step 31800: 0.018228\n",
      "2023-12-03 12:57:08,682 INFO     Training average loss at step 31800: 0.033355\n",
      "2023-12-03 12:57:16,321 INFO     Training average positive_sample_loss at step 31900: 0.049614\n",
      "2023-12-03 12:57:16,322 INFO     Training average negative_sample_loss at step 31900: 0.018327\n",
      "2023-12-03 12:57:16,322 INFO     Training average loss at step 31900: 0.033971\n",
      "2023-12-03 12:57:26,166 INFO     Training average positive_sample_loss at step 32000: 0.048390\n",
      "2023-12-03 12:57:26,167 INFO     Training average negative_sample_loss at step 32000: 0.018363\n",
      "2023-12-03 12:57:26,167 INFO     Training average loss at step 32000: 0.033377\n",
      "2023-12-03 12:57:33,676 INFO     Training average positive_sample_loss at step 32100: 0.047193\n",
      "2023-12-03 12:57:33,676 INFO     Training average negative_sample_loss at step 32100: 0.018096\n",
      "2023-12-03 12:57:33,676 INFO     Training average loss at step 32100: 0.032644\n",
      "2023-12-03 12:57:41,649 INFO     Training average positive_sample_loss at step 32200: 0.049263\n",
      "2023-12-03 12:57:41,650 INFO     Training average negative_sample_loss at step 32200: 0.018211\n",
      "2023-12-03 12:57:41,650 INFO     Training average loss at step 32200: 0.033737\n",
      "2023-12-03 12:57:50,373 INFO     Training average positive_sample_loss at step 32300: 0.050005\n",
      "2023-12-03 12:57:50,373 INFO     Training average negative_sample_loss at step 32300: 0.018376\n",
      "2023-12-03 12:57:50,373 INFO     Training average loss at step 32300: 0.034191\n",
      "2023-12-03 12:57:58,869 INFO     Training average positive_sample_loss at step 32400: 0.046236\n",
      "2023-12-03 12:57:58,870 INFO     Training average negative_sample_loss at step 32400: 0.018098\n",
      "2023-12-03 12:57:58,870 INFO     Training average loss at step 32400: 0.032167\n",
      "2023-12-03 12:58:06,728 INFO     Training average positive_sample_loss at step 32500: 0.048500\n",
      "2023-12-03 12:58:06,729 INFO     Training average negative_sample_loss at step 32500: 0.018199\n",
      "2023-12-03 12:58:06,729 INFO     Training average loss at step 32500: 0.033350\n",
      "2023-12-03 12:58:14,478 INFO     Training average positive_sample_loss at step 32600: 0.049720\n",
      "2023-12-03 12:58:14,479 INFO     Training average negative_sample_loss at step 32600: 0.018246\n",
      "2023-12-03 12:58:14,479 INFO     Training average loss at step 32600: 0.033983\n",
      "2023-12-03 12:58:23,843 INFO     Training average positive_sample_loss at step 32700: 0.047117\n",
      "2023-12-03 12:58:23,843 INFO     Training average negative_sample_loss at step 32700: 0.018160\n",
      "2023-12-03 12:58:23,843 INFO     Training average loss at step 32700: 0.032639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:58:31,428 INFO     Training average positive_sample_loss at step 32800: 0.047545\n",
      "2023-12-03 12:58:31,429 INFO     Training average negative_sample_loss at step 32800: 0.018050\n",
      "2023-12-03 12:58:31,429 INFO     Training average loss at step 32800: 0.032797\n",
      "2023-12-03 12:58:39,172 INFO     Training average positive_sample_loss at step 32900: 0.049314\n",
      "2023-12-03 12:58:39,173 INFO     Training average negative_sample_loss at step 32900: 0.018115\n",
      "2023-12-03 12:58:39,173 INFO     Training average loss at step 32900: 0.033714\n",
      "2023-12-03 12:58:48,991 INFO     Training average positive_sample_loss at step 33000: 0.048955\n",
      "2023-12-03 12:58:48,991 INFO     Training average negative_sample_loss at step 33000: 0.018226\n",
      "2023-12-03 12:58:48,991 INFO     Training average loss at step 33000: 0.033590\n",
      "2023-12-03 12:58:56,524 INFO     Training average positive_sample_loss at step 33100: 0.046653\n",
      "2023-12-03 12:58:56,525 INFO     Training average negative_sample_loss at step 33100: 0.018058\n",
      "2023-12-03 12:58:56,525 INFO     Training average loss at step 33100: 0.032355\n",
      "2023-12-03 12:59:04,008 INFO     Training average positive_sample_loss at step 33200: 0.048637\n",
      "2023-12-03 12:59:04,008 INFO     Training average negative_sample_loss at step 33200: 0.017935\n",
      "2023-12-03 12:59:04,008 INFO     Training average loss at step 33200: 0.033286\n",
      "2023-12-03 12:59:11,906 INFO     Training average positive_sample_loss at step 33300: 0.049396\n",
      "2023-12-03 12:59:11,907 INFO     Training average negative_sample_loss at step 33300: 0.018166\n",
      "2023-12-03 12:59:11,907 INFO     Training average loss at step 33300: 0.033781\n",
      "2023-12-03 12:59:21,416 INFO     Training average positive_sample_loss at step 33400: 0.046129\n",
      "2023-12-03 12:59:21,416 INFO     Training average negative_sample_loss at step 33400: 0.017963\n",
      "2023-12-03 12:59:21,416 INFO     Training average loss at step 33400: 0.032046\n",
      "2023-12-03 12:59:29,389 INFO     Training average positive_sample_loss at step 33500: 0.048105\n",
      "2023-12-03 12:59:29,390 INFO     Training average negative_sample_loss at step 33500: 0.018071\n",
      "2023-12-03 12:59:29,390 INFO     Training average loss at step 33500: 0.033088\n",
      "2023-12-03 12:59:37,043 INFO     Training average positive_sample_loss at step 33600: 0.049165\n",
      "2023-12-03 12:59:37,043 INFO     Training average negative_sample_loss at step 33600: 0.018181\n",
      "2023-12-03 12:59:37,043 INFO     Training average loss at step 33600: 0.033673\n",
      "2023-12-03 12:59:46,762 INFO     Training average positive_sample_loss at step 33700: 0.047576\n",
      "2023-12-03 12:59:46,762 INFO     Training average negative_sample_loss at step 33700: 0.018106\n",
      "2023-12-03 12:59:46,762 INFO     Training average loss at step 33700: 0.032841\n",
      "2023-12-03 12:59:54,274 INFO     Training average positive_sample_loss at step 33800: 0.046915\n",
      "2023-12-03 12:59:54,275 INFO     Training average negative_sample_loss at step 33800: 0.018103\n",
      "2023-12-03 12:59:54,275 INFO     Training average loss at step 33800: 0.032509\n",
      "2023-12-03 13:00:01,831 INFO     Training average positive_sample_loss at step 33900: 0.048595\n",
      "2023-12-03 13:00:01,831 INFO     Training average negative_sample_loss at step 33900: 0.018012\n",
      "2023-12-03 13:00:01,831 INFO     Training average loss at step 33900: 0.033303\n",
      "2023-12-03 13:00:10,875 INFO     Training average positive_sample_loss at step 34000: 0.049163\n",
      "2023-12-03 13:00:10,875 INFO     Training average negative_sample_loss at step 34000: 0.018059\n",
      "2023-12-03 13:00:10,875 INFO     Training average loss at step 34000: 0.033611\n",
      "2023-12-03 13:00:19,305 INFO     Training average positive_sample_loss at step 34100: 0.045730\n",
      "2023-12-03 13:00:19,306 INFO     Training average negative_sample_loss at step 34100: 0.018012\n",
      "2023-12-03 13:00:19,306 INFO     Training average loss at step 34100: 0.031871\n",
      "2023-12-03 13:00:26,997 INFO     Training average positive_sample_loss at step 34200: 0.047935\n",
      "2023-12-03 13:00:26,997 INFO     Training average negative_sample_loss at step 34200: 0.017887\n",
      "2023-12-03 13:00:26,997 INFO     Training average loss at step 34200: 0.032911\n",
      "2023-12-03 13:00:34,765 INFO     Training average positive_sample_loss at step 34300: 0.048663\n",
      "2023-12-03 13:00:34,765 INFO     Training average negative_sample_loss at step 34300: 0.018018\n",
      "2023-12-03 13:00:34,765 INFO     Training average loss at step 34300: 0.033341\n",
      "2023-12-03 13:00:44,348 INFO     Training average positive_sample_loss at step 34400: 0.046748\n",
      "2023-12-03 13:00:44,348 INFO     Training average negative_sample_loss at step 34400: 0.017808\n",
      "2023-12-03 13:00:44,348 INFO     Training average loss at step 34400: 0.032278\n",
      "2023-12-03 13:00:51,969 INFO     Training average positive_sample_loss at step 34500: 0.047190\n",
      "2023-12-03 13:00:51,969 INFO     Training average negative_sample_loss at step 34500: 0.017804\n",
      "2023-12-03 13:00:51,969 INFO     Training average loss at step 34500: 0.032497\n",
      "2023-12-03 13:00:59,903 INFO     Training average positive_sample_loss at step 34600: 0.048565\n",
      "2023-12-03 13:00:59,903 INFO     Training average negative_sample_loss at step 34600: 0.018061\n",
      "2023-12-03 13:00:59,903 INFO     Training average loss at step 34600: 0.033313\n",
      "2023-12-03 13:01:09,059 INFO     Training average positive_sample_loss at step 34700: 0.048163\n",
      "2023-12-03 13:01:09,060 INFO     Training average negative_sample_loss at step 34700: 0.018077\n",
      "2023-12-03 13:01:09,060 INFO     Training average loss at step 34700: 0.033120\n",
      "2023-12-03 13:01:17,011 INFO     Training average positive_sample_loss at step 34800: 0.045686\n",
      "2023-12-03 13:01:17,011 INFO     Training average negative_sample_loss at step 34800: 0.017915\n",
      "2023-12-03 13:01:17,011 INFO     Training average loss at step 34800: 0.031801\n",
      "2023-12-03 13:01:25,018 INFO     Training average positive_sample_loss at step 34900: 0.047971\n",
      "2023-12-03 13:01:25,019 INFO     Training average negative_sample_loss at step 34900: 0.017905\n",
      "2023-12-03 13:01:25,019 INFO     Training average loss at step 34900: 0.032938\n",
      "2023-12-03 13:01:33,056 INFO     Training average positive_sample_loss at step 35000: 0.049073\n",
      "2023-12-03 13:01:33,056 INFO     Training average negative_sample_loss at step 35000: 0.017862\n",
      "2023-12-03 13:01:33,056 INFO     Training average loss at step 35000: 0.033467\n",
      "2023-12-03 13:01:42,492 INFO     Training average positive_sample_loss at step 35100: 0.045824\n",
      "2023-12-03 13:01:42,492 INFO     Training average negative_sample_loss at step 35100: 0.017920\n",
      "2023-12-03 13:01:42,492 INFO     Training average loss at step 35100: 0.031872\n",
      "2023-12-03 13:01:50,349 INFO     Training average positive_sample_loss at step 35200: 0.047205\n",
      "2023-12-03 13:01:50,349 INFO     Training average negative_sample_loss at step 35200: 0.017814\n",
      "2023-12-03 13:01:50,349 INFO     Training average loss at step 35200: 0.032510\n",
      "2023-12-03 13:01:58,189 INFO     Training average positive_sample_loss at step 35300: 0.048385\n",
      "2023-12-03 13:01:58,189 INFO     Training average negative_sample_loss at step 35300: 0.017861\n",
      "2023-12-03 13:01:58,190 INFO     Training average loss at step 35300: 0.033123\n",
      "2023-12-03 13:02:07,829 INFO     Training average positive_sample_loss at step 35400: 0.047407\n",
      "2023-12-03 13:02:07,830 INFO     Training average negative_sample_loss at step 35400: 0.017952\n",
      "2023-12-03 13:02:07,830 INFO     Training average loss at step 35400: 0.032679\n",
      "2023-12-03 13:02:15,538 INFO     Training average positive_sample_loss at step 35500: 0.046173\n",
      "2023-12-03 13:02:15,538 INFO     Training average negative_sample_loss at step 35500: 0.017847\n",
      "2023-12-03 13:02:15,538 INFO     Training average loss at step 35500: 0.032010\n",
      "2023-12-03 13:02:23,192 INFO     Training average positive_sample_loss at step 35600: 0.047912\n",
      "2023-12-03 13:02:23,192 INFO     Training average negative_sample_loss at step 35600: 0.017791\n",
      "2023-12-03 13:02:23,192 INFO     Training average loss at step 35600: 0.032851\n",
      "2023-12-03 13:02:32,561 INFO     Training average positive_sample_loss at step 35700: 0.048897\n",
      "2023-12-03 13:02:32,561 INFO     Training average negative_sample_loss at step 35700: 0.017990\n",
      "2023-12-03 13:02:32,562 INFO     Training average loss at step 35700: 0.033444\n",
      "2023-12-03 13:02:40,874 INFO     Training average positive_sample_loss at step 35800: 0.045389\n",
      "2023-12-03 13:02:40,874 INFO     Training average negative_sample_loss at step 35800: 0.017954\n",
      "2023-12-03 13:02:40,874 INFO     Training average loss at step 35800: 0.031671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:02:48,380 INFO     Training average positive_sample_loss at step 35900: 0.047389\n",
      "2023-12-03 13:02:48,380 INFO     Training average negative_sample_loss at step 35900: 0.017818\n",
      "2023-12-03 13:02:48,380 INFO     Training average loss at step 35900: 0.032604\n",
      "2023-12-03 13:02:55,874 INFO     Training average positive_sample_loss at step 36000: 0.048346\n",
      "2023-12-03 13:02:55,874 INFO     Training average negative_sample_loss at step 36000: 0.017874\n",
      "2023-12-03 13:02:55,874 INFO     Training average loss at step 36000: 0.033110\n",
      "2023-12-03 13:03:05,323 INFO     Training average positive_sample_loss at step 36100: 0.045935\n",
      "2023-12-03 13:03:05,324 INFO     Training average negative_sample_loss at step 36100: 0.017757\n",
      "2023-12-03 13:03:05,324 INFO     Training average loss at step 36100: 0.031846\n",
      "2023-12-03 13:03:13,055 INFO     Training average positive_sample_loss at step 36200: 0.046709\n",
      "2023-12-03 13:03:13,056 INFO     Training average negative_sample_loss at step 36200: 0.017625\n",
      "2023-12-03 13:03:13,056 INFO     Training average loss at step 36200: 0.032167\n",
      "2023-12-03 13:03:20,867 INFO     Training average positive_sample_loss at step 36300: 0.047955\n",
      "2023-12-03 13:03:20,868 INFO     Training average negative_sample_loss at step 36300: 0.017824\n",
      "2023-12-03 13:03:20,868 INFO     Training average loss at step 36300: 0.032889\n",
      "2023-12-03 13:03:30,417 INFO     Training average positive_sample_loss at step 36400: 0.047584\n",
      "2023-12-03 13:03:30,417 INFO     Training average negative_sample_loss at step 36400: 0.017995\n",
      "2023-12-03 13:03:30,417 INFO     Training average loss at step 36400: 0.032790\n",
      "2023-12-03 13:03:38,003 INFO     Training average positive_sample_loss at step 36500: 0.045643\n",
      "2023-12-03 13:03:38,004 INFO     Training average negative_sample_loss at step 36500: 0.017826\n",
      "2023-12-03 13:03:38,004 INFO     Training average loss at step 36500: 0.031735\n",
      "2023-12-03 13:03:45,861 INFO     Training average positive_sample_loss at step 36600: 0.047426\n",
      "2023-12-03 13:03:45,861 INFO     Training average negative_sample_loss at step 36600: 0.017614\n",
      "2023-12-03 13:03:45,861 INFO     Training average loss at step 36600: 0.032520\n",
      "2023-12-03 13:03:53,703 INFO     Training average positive_sample_loss at step 36700: 0.048301\n",
      "2023-12-03 13:03:53,704 INFO     Training average negative_sample_loss at step 36700: 0.017965\n",
      "2023-12-03 13:03:53,704 INFO     Training average loss at step 36700: 0.033133\n",
      "2023-12-03 13:04:02,818 INFO     Training average positive_sample_loss at step 36800: 0.045292\n",
      "2023-12-03 13:04:02,819 INFO     Training average negative_sample_loss at step 36800: 0.017795\n",
      "2023-12-03 13:04:02,819 INFO     Training average loss at step 36800: 0.031543\n",
      "2023-12-03 13:04:10,557 INFO     Training average positive_sample_loss at step 36900: 0.046457\n",
      "2023-12-03 13:04:10,558 INFO     Training average negative_sample_loss at step 36900: 0.017683\n",
      "2023-12-03 13:04:10,558 INFO     Training average loss at step 36900: 0.032070\n",
      "2023-12-03 13:04:18,516 INFO     Training average positive_sample_loss at step 37000: 0.048076\n",
      "2023-12-03 13:04:18,517 INFO     Training average negative_sample_loss at step 37000: 0.017613\n",
      "2023-12-03 13:04:18,517 INFO     Training average loss at step 37000: 0.032845\n",
      "2023-12-03 13:04:28,410 INFO     Training average positive_sample_loss at step 37100: 0.047015\n",
      "2023-12-03 13:04:28,410 INFO     Training average negative_sample_loss at step 37100: 0.017830\n",
      "2023-12-03 13:04:28,410 INFO     Training average loss at step 37100: 0.032422\n",
      "2023-12-03 13:04:36,432 INFO     Training average positive_sample_loss at step 37200: 0.045839\n",
      "2023-12-03 13:04:36,433 INFO     Training average negative_sample_loss at step 37200: 0.017720\n",
      "2023-12-03 13:04:36,433 INFO     Training average loss at step 37200: 0.031780\n",
      "2023-12-03 13:04:44,214 INFO     Training average positive_sample_loss at step 37300: 0.047223\n",
      "2023-12-03 13:04:44,215 INFO     Training average negative_sample_loss at step 37300: 0.017694\n",
      "2023-12-03 13:04:44,215 INFO     Training average loss at step 37300: 0.032459\n",
      "2023-12-03 13:04:53,044 INFO     Training average positive_sample_loss at step 37400: 0.048335\n",
      "2023-12-03 13:04:53,044 INFO     Training average negative_sample_loss at step 37400: 0.017863\n",
      "2023-12-03 13:04:53,044 INFO     Training average loss at step 37400: 0.033099\n",
      "2023-12-03 13:05:01,423 INFO     Training average positive_sample_loss at step 37500: 0.044799\n",
      "2023-12-03 13:05:01,423 INFO     Training average negative_sample_loss at step 37500: 0.017832\n",
      "2023-12-03 13:05:01,423 INFO     Training average loss at step 37500: 0.031316\n",
      "2023-12-03 13:05:08,917 INFO     Training average positive_sample_loss at step 37600: 0.046811\n",
      "2023-12-03 13:05:08,918 INFO     Training average negative_sample_loss at step 37600: 0.017678\n",
      "2023-12-03 13:05:08,918 INFO     Training average loss at step 37600: 0.032245\n",
      "2023-12-03 13:05:16,638 INFO     Training average positive_sample_loss at step 37700: 0.047872\n",
      "2023-12-03 13:05:16,638 INFO     Training average negative_sample_loss at step 37700: 0.017683\n",
      "2023-12-03 13:05:16,638 INFO     Training average loss at step 37700: 0.032777\n",
      "2023-12-03 13:05:26,038 INFO     Training average positive_sample_loss at step 37800: 0.045879\n",
      "2023-12-03 13:05:26,038 INFO     Training average negative_sample_loss at step 37800: 0.017705\n",
      "2023-12-03 13:05:26,038 INFO     Training average loss at step 37800: 0.031792\n",
      "2023-12-03 13:05:33,631 INFO     Training average positive_sample_loss at step 37900: 0.046194\n",
      "2023-12-03 13:05:33,631 INFO     Training average negative_sample_loss at step 37900: 0.017765\n",
      "2023-12-03 13:05:33,631 INFO     Training average loss at step 37900: 0.031979\n",
      "2023-12-03 13:05:41,191 INFO     Training average positive_sample_loss at step 38000: 0.047355\n",
      "2023-12-03 13:05:41,192 INFO     Training average negative_sample_loss at step 38000: 0.017599\n",
      "2023-12-03 13:05:41,192 INFO     Training average loss at step 38000: 0.032477\n",
      "2023-12-03 13:05:50,893 INFO     Training average positive_sample_loss at step 38100: 0.046975\n",
      "2023-12-03 13:05:50,893 INFO     Training average negative_sample_loss at step 38100: 0.017746\n",
      "2023-12-03 13:05:50,893 INFO     Training average loss at step 38100: 0.032360\n",
      "2023-12-03 13:05:58,760 INFO     Training average positive_sample_loss at step 38200: 0.045143\n",
      "2023-12-03 13:05:58,761 INFO     Training average negative_sample_loss at step 38200: 0.017570\n",
      "2023-12-03 13:05:58,761 INFO     Training average loss at step 38200: 0.031356\n",
      "2023-12-03 13:06:06,854 INFO     Training average positive_sample_loss at step 38300: 0.046933\n",
      "2023-12-03 13:06:06,855 INFO     Training average negative_sample_loss at step 38300: 0.017590\n",
      "2023-12-03 13:06:06,855 INFO     Training average loss at step 38300: 0.032261\n",
      "2023-12-03 13:06:14,729 INFO     Training average positive_sample_loss at step 38400: 0.048025\n",
      "2023-12-03 13:06:14,729 INFO     Training average negative_sample_loss at step 38400: 0.017674\n",
      "2023-12-03 13:06:14,730 INFO     Training average loss at step 38400: 0.032849\n",
      "2023-12-03 13:06:23,884 INFO     Training average positive_sample_loss at step 38500: 0.045071\n",
      "2023-12-03 13:06:23,884 INFO     Training average negative_sample_loss at step 38500: 0.017756\n",
      "2023-12-03 13:06:23,884 INFO     Training average loss at step 38500: 0.031414\n",
      "2023-12-03 13:06:31,653 INFO     Training average positive_sample_loss at step 38600: 0.046055\n",
      "2023-12-03 13:06:31,653 INFO     Training average negative_sample_loss at step 38600: 0.017584\n",
      "2023-12-03 13:06:31,653 INFO     Training average loss at step 38600: 0.031820\n",
      "2023-12-03 13:06:39,554 INFO     Training average positive_sample_loss at step 38700: 0.047534\n",
      "2023-12-03 13:06:39,554 INFO     Training average negative_sample_loss at step 38700: 0.017613\n",
      "2023-12-03 13:06:39,554 INFO     Training average loss at step 38700: 0.032573\n",
      "2023-12-03 13:06:49,064 INFO     Training average positive_sample_loss at step 38800: 0.046305\n",
      "2023-12-03 13:06:49,065 INFO     Training average negative_sample_loss at step 38800: 0.017661\n",
      "2023-12-03 13:06:49,065 INFO     Training average loss at step 38800: 0.031983\n",
      "2023-12-03 13:06:56,749 INFO     Training average positive_sample_loss at step 38900: 0.045272\n",
      "2023-12-03 13:06:56,749 INFO     Training average negative_sample_loss at step 38900: 0.017611\n",
      "2023-12-03 13:06:56,749 INFO     Training average loss at step 38900: 0.031441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:07:04,310 INFO     Training average positive_sample_loss at step 39000: 0.047191\n",
      "2023-12-03 13:07:04,311 INFO     Training average negative_sample_loss at step 39000: 0.017438\n",
      "2023-12-03 13:07:04,311 INFO     Training average loss at step 39000: 0.032315\n",
      "2023-12-03 13:07:13,274 INFO     Training average positive_sample_loss at step 39100: 0.047885\n",
      "2023-12-03 13:07:13,275 INFO     Training average negative_sample_loss at step 39100: 0.017699\n",
      "2023-12-03 13:07:13,275 INFO     Training average loss at step 39100: 0.032792\n",
      "2023-12-03 13:07:22,133 INFO     Training average positive_sample_loss at step 39200: 0.044191\n",
      "2023-12-03 13:07:22,134 INFO     Training average negative_sample_loss at step 39200: 0.017643\n",
      "2023-12-03 13:07:22,134 INFO     Training average loss at step 39200: 0.030917\n",
      "2023-12-03 13:07:29,744 INFO     Training average positive_sample_loss at step 39300: 0.046409\n",
      "2023-12-03 13:07:29,745 INFO     Training average negative_sample_loss at step 39300: 0.017412\n",
      "2023-12-03 13:07:29,745 INFO     Training average loss at step 39300: 0.031911\n",
      "2023-12-03 13:07:37,623 INFO     Training average positive_sample_loss at step 39400: 0.047545\n",
      "2023-12-03 13:07:37,624 INFO     Training average negative_sample_loss at step 39400: 0.017637\n",
      "2023-12-03 13:07:37,624 INFO     Training average loss at step 39400: 0.032591\n",
      "2023-12-03 13:07:46,805 INFO     Training average positive_sample_loss at step 39500: 0.045441\n",
      "2023-12-03 13:07:46,806 INFO     Training average negative_sample_loss at step 39500: 0.017639\n",
      "2023-12-03 13:07:46,806 INFO     Training average loss at step 39500: 0.031540\n",
      "2023-12-03 13:07:55,229 INFO     Training average positive_sample_loss at step 39600: 0.045783\n",
      "2023-12-03 13:07:55,230 INFO     Training average negative_sample_loss at step 39600: 0.017519\n",
      "2023-12-03 13:07:55,230 INFO     Training average loss at step 39600: 0.031651\n",
      "2023-12-03 13:08:04,376 INFO     Training average positive_sample_loss at step 39700: 0.046940\n",
      "2023-12-03 13:08:04,377 INFO     Training average negative_sample_loss at step 39700: 0.017629\n",
      "2023-12-03 13:08:04,377 INFO     Training average loss at step 39700: 0.032285\n",
      "2023-12-03 13:08:15,712 INFO     Training average positive_sample_loss at step 39800: 0.046799\n",
      "2023-12-03 13:08:15,713 INFO     Training average negative_sample_loss at step 39800: 0.017648\n",
      "2023-12-03 13:08:15,713 INFO     Training average loss at step 39800: 0.032223\n",
      "2023-12-03 13:08:24,492 INFO     Training average positive_sample_loss at step 39900: 0.044624\n",
      "2023-12-03 13:08:24,492 INFO     Training average negative_sample_loss at step 39900: 0.017498\n",
      "2023-12-03 13:08:24,493 INFO     Training average loss at step 39900: 0.031061\n",
      "2023-12-03 13:08:33,172 INFO     Change learning_rate to 0.000005 at step 40000\n",
      "2023-12-03 13:08:40,273 INFO     Training average positive_sample_loss at step 40000: 0.046389\n",
      "2023-12-03 13:08:40,273 INFO     Training average negative_sample_loss at step 40000: 0.017404\n",
      "2023-12-03 13:08:40,273 INFO     Training average loss at step 40000: 0.031896\n",
      "2023-12-03 13:08:40,273 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 13:08:40,837 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 13:09:14,552 INFO     Valid MRR at step 40000: 0.481177\n",
      "2023-12-03 13:09:14,553 INFO     Valid MR at step 40000: 1844.472808\n",
      "2023-12-03 13:09:14,553 INFO     Valid HITS@1 at step 40000: 0.436058\n",
      "2023-12-03 13:09:14,553 INFO     Valid HITS@3 at step 40000: 0.494232\n",
      "2023-12-03 13:09:14,553 INFO     Valid HITS@10 at step 40000: 0.569875\n",
      "2023-12-03 13:09:23,231 INFO     Training average positive_sample_loss at step 40100: 0.047919\n",
      "2023-12-03 13:09:23,231 INFO     Training average negative_sample_loss at step 40100: 0.017075\n",
      "2023-12-03 13:09:23,231 INFO     Training average loss at step 40100: 0.032497\n",
      "2023-12-03 13:09:33,977 INFO     Training average positive_sample_loss at step 40200: 0.044158\n",
      "2023-12-03 13:09:33,977 INFO     Training average negative_sample_loss at step 40200: 0.016881\n",
      "2023-12-03 13:09:33,977 INFO     Training average loss at step 40200: 0.030520\n",
      "2023-12-03 13:09:42,741 INFO     Training average positive_sample_loss at step 40300: 0.043456\n",
      "2023-12-03 13:09:42,742 INFO     Training average negative_sample_loss at step 40300: 0.016722\n",
      "2023-12-03 13:09:42,742 INFO     Training average loss at step 40300: 0.030089\n",
      "2023-12-03 13:09:51,392 INFO     Training average positive_sample_loss at step 40400: 0.043140\n",
      "2023-12-03 13:09:51,392 INFO     Training average negative_sample_loss at step 40400: 0.016694\n",
      "2023-12-03 13:09:51,392 INFO     Training average loss at step 40400: 0.029917\n",
      "2023-12-03 13:10:02,081 INFO     Training average positive_sample_loss at step 40500: 0.042754\n",
      "2023-12-03 13:10:02,081 INFO     Training average negative_sample_loss at step 40500: 0.016811\n",
      "2023-12-03 13:10:02,081 INFO     Training average loss at step 40500: 0.029782\n",
      "2023-12-03 13:10:10,763 INFO     Training average positive_sample_loss at step 40600: 0.042222\n",
      "2023-12-03 13:10:10,763 INFO     Training average negative_sample_loss at step 40600: 0.016819\n",
      "2023-12-03 13:10:10,763 INFO     Training average loss at step 40600: 0.029520\n",
      "2023-12-03 13:10:19,437 INFO     Training average positive_sample_loss at step 40700: 0.042425\n",
      "2023-12-03 13:10:19,437 INFO     Training average negative_sample_loss at step 40700: 0.016670\n",
      "2023-12-03 13:10:19,437 INFO     Training average loss at step 40700: 0.029547\n",
      "2023-12-03 13:10:29,096 INFO     Training average positive_sample_loss at step 40800: 0.042771\n",
      "2023-12-03 13:10:29,097 INFO     Training average negative_sample_loss at step 40800: 0.016676\n",
      "2023-12-03 13:10:29,097 INFO     Training average loss at step 40800: 0.029724\n",
      "2023-12-03 13:10:38,929 INFO     Training average positive_sample_loss at step 40900: 0.041427\n",
      "2023-12-03 13:10:38,929 INFO     Training average negative_sample_loss at step 40900: 0.016780\n",
      "2023-12-03 13:10:38,929 INFO     Training average loss at step 40900: 0.029103\n",
      "2023-12-03 13:10:47,634 INFO     Training average positive_sample_loss at step 41000: 0.042139\n",
      "2023-12-03 13:10:47,635 INFO     Training average negative_sample_loss at step 41000: 0.016765\n",
      "2023-12-03 13:10:47,635 INFO     Training average loss at step 41000: 0.029452\n",
      "2023-12-03 13:10:56,328 INFO     Training average positive_sample_loss at step 41100: 0.042154\n",
      "2023-12-03 13:10:56,328 INFO     Training average negative_sample_loss at step 41100: 0.016726\n",
      "2023-12-03 13:10:56,328 INFO     Training average loss at step 41100: 0.029440\n",
      "2023-12-03 13:11:07,264 INFO     Training average positive_sample_loss at step 41200: 0.041659\n",
      "2023-12-03 13:11:07,265 INFO     Training average negative_sample_loss at step 41200: 0.016879\n",
      "2023-12-03 13:11:07,265 INFO     Training average loss at step 41200: 0.029269\n",
      "2023-12-03 13:11:16,077 INFO     Training average positive_sample_loss at step 41300: 0.041738\n",
      "2023-12-03 13:11:16,077 INFO     Training average negative_sample_loss at step 41300: 0.016734\n",
      "2023-12-03 13:11:16,077 INFO     Training average loss at step 41300: 0.029236\n",
      "2023-12-03 13:11:24,564 INFO     Training average positive_sample_loss at step 41400: 0.041791\n",
      "2023-12-03 13:11:24,564 INFO     Training average negative_sample_loss at step 41400: 0.016743\n",
      "2023-12-03 13:11:24,564 INFO     Training average loss at step 41400: 0.029267\n",
      "2023-12-03 13:11:35,389 INFO     Training average positive_sample_loss at step 41500: 0.041744\n",
      "2023-12-03 13:11:35,390 INFO     Training average negative_sample_loss at step 41500: 0.016770\n",
      "2023-12-03 13:11:35,390 INFO     Training average loss at step 41500: 0.029257\n",
      "2023-12-03 13:11:44,167 INFO     Training average positive_sample_loss at step 41600: 0.041296\n",
      "2023-12-03 13:11:44,168 INFO     Training average negative_sample_loss at step 41600: 0.016664\n",
      "2023-12-03 13:11:44,168 INFO     Training average loss at step 41600: 0.028980\n",
      "2023-12-03 13:11:52,956 INFO     Training average positive_sample_loss at step 41700: 0.041636\n",
      "2023-12-03 13:11:52,956 INFO     Training average negative_sample_loss at step 41700: 0.016713\n",
      "2023-12-03 13:11:52,956 INFO     Training average loss at step 41700: 0.029174\n",
      "2023-12-03 13:12:01,747 INFO     Training average positive_sample_loss at step 41800: 0.041805\n",
      "2023-12-03 13:12:01,748 INFO     Training average negative_sample_loss at step 41800: 0.016688\n",
      "2023-12-03 13:12:01,748 INFO     Training average loss at step 41800: 0.029246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:12:12,717 INFO     Training average positive_sample_loss at step 41900: 0.040897\n",
      "2023-12-03 13:12:12,717 INFO     Training average negative_sample_loss at step 41900: 0.016662\n",
      "2023-12-03 13:12:12,717 INFO     Training average loss at step 41900: 0.028779\n",
      "2023-12-03 13:12:21,396 INFO     Training average positive_sample_loss at step 42000: 0.041341\n",
      "2023-12-03 13:12:21,396 INFO     Training average negative_sample_loss at step 42000: 0.016837\n",
      "2023-12-03 13:12:21,396 INFO     Training average loss at step 42000: 0.029089\n",
      "2023-12-03 13:12:29,872 INFO     Training average positive_sample_loss at step 42100: 0.041710\n",
      "2023-12-03 13:12:29,873 INFO     Training average negative_sample_loss at step 42100: 0.016834\n",
      "2023-12-03 13:12:29,873 INFO     Training average loss at step 42100: 0.029272\n",
      "2023-12-03 13:12:40,565 INFO     Training average positive_sample_loss at step 42200: 0.041406\n",
      "2023-12-03 13:12:40,566 INFO     Training average negative_sample_loss at step 42200: 0.016737\n",
      "2023-12-03 13:12:40,566 INFO     Training average loss at step 42200: 0.029072\n",
      "2023-12-03 13:12:49,325 INFO     Training average positive_sample_loss at step 42300: 0.040940\n",
      "2023-12-03 13:12:49,326 INFO     Training average negative_sample_loss at step 42300: 0.016758\n",
      "2023-12-03 13:12:49,326 INFO     Training average loss at step 42300: 0.028849\n",
      "2023-12-03 13:12:58,033 INFO     Training average positive_sample_loss at step 42400: 0.041283\n",
      "2023-12-03 13:12:58,033 INFO     Training average negative_sample_loss at step 42400: 0.016818\n",
      "2023-12-03 13:12:58,033 INFO     Training average loss at step 42400: 0.029050\n",
      "2023-12-03 13:13:07,652 INFO     Training average positive_sample_loss at step 42500: 0.041784\n",
      "2023-12-03 13:13:07,653 INFO     Training average negative_sample_loss at step 42500: 0.016818\n",
      "2023-12-03 13:13:07,653 INFO     Training average loss at step 42500: 0.029301\n",
      "2023-12-03 13:13:17,555 INFO     Training average positive_sample_loss at step 42600: 0.040904\n",
      "2023-12-03 13:13:17,555 INFO     Training average negative_sample_loss at step 42600: 0.016817\n",
      "2023-12-03 13:13:17,555 INFO     Training average loss at step 42600: 0.028860\n",
      "2023-12-03 13:13:26,270 INFO     Training average positive_sample_loss at step 42700: 0.040978\n",
      "2023-12-03 13:13:26,270 INFO     Training average negative_sample_loss at step 42700: 0.016708\n",
      "2023-12-03 13:13:26,270 INFO     Training average loss at step 42700: 0.028843\n",
      "2023-12-03 13:13:34,986 INFO     Training average positive_sample_loss at step 42800: 0.041501\n",
      "2023-12-03 13:13:34,987 INFO     Training average negative_sample_loss at step 42800: 0.016650\n",
      "2023-12-03 13:13:34,987 INFO     Training average loss at step 42800: 0.029076\n",
      "2023-12-03 13:13:45,428 INFO     Training average positive_sample_loss at step 42900: 0.041311\n",
      "2023-12-03 13:13:45,428 INFO     Training average negative_sample_loss at step 42900: 0.016823\n",
      "2023-12-03 13:13:45,428 INFO     Training average loss at step 42900: 0.029067\n",
      "2023-12-03 13:13:54,166 INFO     Training average positive_sample_loss at step 43000: 0.040964\n",
      "2023-12-03 13:13:54,166 INFO     Training average negative_sample_loss at step 43000: 0.016833\n",
      "2023-12-03 13:13:54,166 INFO     Training average loss at step 43000: 0.028899\n",
      "2023-12-03 13:14:02,875 INFO     Training average positive_sample_loss at step 43100: 0.041090\n",
      "2023-12-03 13:14:02,875 INFO     Training average negative_sample_loss at step 43100: 0.016708\n",
      "2023-12-03 13:14:02,875 INFO     Training average loss at step 43100: 0.028899\n",
      "2023-12-03 13:14:13,603 INFO     Training average positive_sample_loss at step 43200: 0.041554\n",
      "2023-12-03 13:14:13,604 INFO     Training average negative_sample_loss at step 43200: 0.016690\n",
      "2023-12-03 13:14:13,604 INFO     Training average loss at step 43200: 0.029122\n",
      "2023-12-03 13:14:22,380 INFO     Training average positive_sample_loss at step 43300: 0.040734\n",
      "2023-12-03 13:14:22,381 INFO     Training average negative_sample_loss at step 43300: 0.016750\n",
      "2023-12-03 13:14:22,381 INFO     Training average loss at step 43300: 0.028742\n",
      "2023-12-03 13:14:31,090 INFO     Training average positive_sample_loss at step 43400: 0.041057\n",
      "2023-12-03 13:14:31,090 INFO     Training average negative_sample_loss at step 43400: 0.016674\n",
      "2023-12-03 13:14:31,090 INFO     Training average loss at step 43400: 0.028866\n",
      "2023-12-03 13:14:39,810 INFO     Training average positive_sample_loss at step 43500: 0.041426\n",
      "2023-12-03 13:14:39,811 INFO     Training average negative_sample_loss at step 43500: 0.016667\n",
      "2023-12-03 13:14:39,811 INFO     Training average loss at step 43500: 0.029047\n",
      "2023-12-03 13:14:50,609 INFO     Training average positive_sample_loss at step 43600: 0.040603\n",
      "2023-12-03 13:14:50,609 INFO     Training average negative_sample_loss at step 43600: 0.016807\n",
      "2023-12-03 13:14:50,610 INFO     Training average loss at step 43600: 0.028705\n",
      "2023-12-03 13:14:59,297 INFO     Training average positive_sample_loss at step 43700: 0.040999\n",
      "2023-12-03 13:14:59,298 INFO     Training average negative_sample_loss at step 43700: 0.016715\n",
      "2023-12-03 13:14:59,298 INFO     Training average loss at step 43700: 0.028857\n",
      "2023-12-03 13:15:07,957 INFO     Training average positive_sample_loss at step 43800: 0.041506\n",
      "2023-12-03 13:15:07,958 INFO     Training average negative_sample_loss at step 43800: 0.016768\n",
      "2023-12-03 13:15:07,958 INFO     Training average loss at step 43800: 0.029137\n",
      "2023-12-03 13:15:17,845 INFO     Training average positive_sample_loss at step 43900: 0.041157\n",
      "2023-12-03 13:15:17,845 INFO     Training average negative_sample_loss at step 43900: 0.016717\n",
      "2023-12-03 13:15:17,845 INFO     Training average loss at step 43900: 0.028937\n",
      "2023-12-03 13:15:25,606 INFO     Training average positive_sample_loss at step 44000: 0.040797\n",
      "2023-12-03 13:15:25,607 INFO     Training average negative_sample_loss at step 44000: 0.016836\n",
      "2023-12-03 13:15:25,607 INFO     Training average loss at step 44000: 0.028816\n",
      "2023-12-03 13:15:33,499 INFO     Training average positive_sample_loss at step 44100: 0.041088\n",
      "2023-12-03 13:15:33,500 INFO     Training average negative_sample_loss at step 44100: 0.016753\n",
      "2023-12-03 13:15:33,500 INFO     Training average loss at step 44100: 0.028921\n",
      "2023-12-03 13:15:43,091 INFO     Training average positive_sample_loss at step 44200: 0.041296\n",
      "2023-12-03 13:15:43,091 INFO     Training average negative_sample_loss at step 44200: 0.016752\n",
      "2023-12-03 13:15:43,091 INFO     Training average loss at step 44200: 0.029024\n",
      "2023-12-03 13:15:51,763 INFO     Training average positive_sample_loss at step 44300: 0.040703\n",
      "2023-12-03 13:15:51,764 INFO     Training average negative_sample_loss at step 44300: 0.016718\n",
      "2023-12-03 13:15:51,764 INFO     Training average loss at step 44300: 0.028711\n",
      "2023-12-03 13:15:59,399 INFO     Training average positive_sample_loss at step 44400: 0.041160\n",
      "2023-12-03 13:15:59,399 INFO     Training average negative_sample_loss at step 44400: 0.016713\n",
      "2023-12-03 13:15:59,399 INFO     Training average loss at step 44400: 0.028937\n",
      "2023-12-03 13:16:07,379 INFO     Training average positive_sample_loss at step 44500: 0.040988\n",
      "2023-12-03 13:16:07,379 INFO     Training average negative_sample_loss at step 44500: 0.016523\n",
      "2023-12-03 13:16:07,379 INFO     Training average loss at step 44500: 0.028755\n",
      "2023-12-03 13:16:16,670 INFO     Training average positive_sample_loss at step 44600: 0.040946\n",
      "2023-12-03 13:16:16,671 INFO     Training average negative_sample_loss at step 44600: 0.016569\n",
      "2023-12-03 13:16:16,671 INFO     Training average loss at step 44600: 0.028758\n",
      "2023-12-03 13:16:24,252 INFO     Training average positive_sample_loss at step 44700: 0.040799\n",
      "2023-12-03 13:16:24,252 INFO     Training average negative_sample_loss at step 44700: 0.016519\n",
      "2023-12-03 13:16:24,253 INFO     Training average loss at step 44700: 0.028659\n",
      "2023-12-03 13:16:32,405 INFO     Training average positive_sample_loss at step 44800: 0.041213\n",
      "2023-12-03 13:16:32,406 INFO     Training average negative_sample_loss at step 44800: 0.016764\n",
      "2023-12-03 13:16:32,406 INFO     Training average loss at step 44800: 0.028988\n",
      "2023-12-03 13:16:41,880 INFO     Training average positive_sample_loss at step 44900: 0.041292\n",
      "2023-12-03 13:16:41,880 INFO     Training average negative_sample_loss at step 44900: 0.016690\n",
      "2023-12-03 13:16:41,880 INFO     Training average loss at step 44900: 0.028991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:16:49,688 INFO     Training average positive_sample_loss at step 45000: 0.040741\n",
      "2023-12-03 13:16:49,688 INFO     Training average negative_sample_loss at step 45000: 0.016751\n",
      "2023-12-03 13:16:49,688 INFO     Training average loss at step 45000: 0.028746\n",
      "2023-12-03 13:16:57,490 INFO     Training average positive_sample_loss at step 45100: 0.041008\n",
      "2023-12-03 13:16:57,491 INFO     Training average negative_sample_loss at step 45100: 0.016701\n",
      "2023-12-03 13:16:57,491 INFO     Training average loss at step 45100: 0.028854\n",
      "2023-12-03 13:17:05,596 INFO     Training average positive_sample_loss at step 45200: 0.041214\n",
      "2023-12-03 13:17:05,596 INFO     Training average negative_sample_loss at step 45200: 0.016636\n",
      "2023-12-03 13:17:05,596 INFO     Training average loss at step 45200: 0.028925\n",
      "2023-12-03 13:17:15,105 INFO     Training average positive_sample_loss at step 45300: 0.040697\n",
      "2023-12-03 13:17:15,105 INFO     Training average negative_sample_loss at step 45300: 0.016590\n",
      "2023-12-03 13:17:15,105 INFO     Training average loss at step 45300: 0.028643\n",
      "2023-12-03 13:17:22,857 INFO     Training average positive_sample_loss at step 45400: 0.040654\n",
      "2023-12-03 13:17:22,858 INFO     Training average negative_sample_loss at step 45400: 0.016574\n",
      "2023-12-03 13:17:22,858 INFO     Training average loss at step 45400: 0.028614\n",
      "2023-12-03 13:17:31,113 INFO     Training average positive_sample_loss at step 45500: 0.041348\n",
      "2023-12-03 13:17:31,114 INFO     Training average negative_sample_loss at step 45500: 0.016764\n",
      "2023-12-03 13:17:31,114 INFO     Training average loss at step 45500: 0.029056\n",
      "2023-12-03 13:17:40,819 INFO     Training average positive_sample_loss at step 45600: 0.041136\n",
      "2023-12-03 13:17:40,819 INFO     Training average negative_sample_loss at step 45600: 0.016643\n",
      "2023-12-03 13:17:40,819 INFO     Training average loss at step 45600: 0.028890\n",
      "2023-12-03 13:17:48,520 INFO     Training average positive_sample_loss at step 45700: 0.040661\n",
      "2023-12-03 13:17:48,521 INFO     Training average negative_sample_loss at step 45700: 0.016573\n",
      "2023-12-03 13:17:48,521 INFO     Training average loss at step 45700: 0.028617\n",
      "2023-12-03 13:17:56,232 INFO     Training average positive_sample_loss at step 45800: 0.040838\n",
      "2023-12-03 13:17:56,233 INFO     Training average negative_sample_loss at step 45800: 0.016642\n",
      "2023-12-03 13:17:56,233 INFO     Training average loss at step 45800: 0.028740\n",
      "2023-12-03 13:18:05,496 INFO     Training average positive_sample_loss at step 45900: 0.041328\n",
      "2023-12-03 13:18:05,497 INFO     Training average negative_sample_loss at step 45900: 0.016673\n",
      "2023-12-03 13:18:05,497 INFO     Training average loss at step 45900: 0.029001\n",
      "2023-12-03 13:18:14,193 INFO     Training average positive_sample_loss at step 46000: 0.040741\n",
      "2023-12-03 13:18:14,194 INFO     Training average negative_sample_loss at step 46000: 0.016602\n",
      "2023-12-03 13:18:14,194 INFO     Training average loss at step 46000: 0.028671\n",
      "2023-12-03 13:18:21,874 INFO     Training average positive_sample_loss at step 46100: 0.041027\n",
      "2023-12-03 13:18:21,874 INFO     Training average negative_sample_loss at step 46100: 0.016542\n",
      "2023-12-03 13:18:21,874 INFO     Training average loss at step 46100: 0.028784\n",
      "2023-12-03 13:18:30,198 INFO     Training average positive_sample_loss at step 46200: 0.040882\n",
      "2023-12-03 13:18:30,199 INFO     Training average negative_sample_loss at step 46200: 0.016601\n",
      "2023-12-03 13:18:30,199 INFO     Training average loss at step 46200: 0.028742\n",
      "2023-12-03 13:18:39,819 INFO     Training average positive_sample_loss at step 46300: 0.040937\n",
      "2023-12-03 13:18:39,819 INFO     Training average negative_sample_loss at step 46300: 0.016542\n",
      "2023-12-03 13:18:39,819 INFO     Training average loss at step 46300: 0.028739\n",
      "2023-12-03 13:18:48,223 INFO     Training average positive_sample_loss at step 46400: 0.040930\n",
      "2023-12-03 13:18:48,223 INFO     Training average negative_sample_loss at step 46400: 0.016522\n",
      "2023-12-03 13:18:48,223 INFO     Training average loss at step 46400: 0.028726\n",
      "2023-12-03 13:18:56,234 INFO     Training average positive_sample_loss at step 46500: 0.041183\n",
      "2023-12-03 13:18:56,234 INFO     Training average negative_sample_loss at step 46500: 0.016718\n",
      "2023-12-03 13:18:56,234 INFO     Training average loss at step 46500: 0.028951\n",
      "2023-12-03 13:19:06,365 INFO     Training average positive_sample_loss at step 46600: 0.040861\n",
      "2023-12-03 13:19:06,365 INFO     Training average negative_sample_loss at step 46600: 0.016548\n",
      "2023-12-03 13:19:06,365 INFO     Training average loss at step 46600: 0.028705\n",
      "2023-12-03 13:19:14,187 INFO     Training average positive_sample_loss at step 46700: 0.040355\n",
      "2023-12-03 13:19:14,188 INFO     Training average negative_sample_loss at step 46700: 0.016505\n",
      "2023-12-03 13:19:14,188 INFO     Training average loss at step 46700: 0.028430\n",
      "2023-12-03 13:19:21,811 INFO     Training average positive_sample_loss at step 46800: 0.041097\n",
      "2023-12-03 13:19:21,811 INFO     Training average negative_sample_loss at step 46800: 0.016585\n",
      "2023-12-03 13:19:21,811 INFO     Training average loss at step 46800: 0.028841\n",
      "2023-12-03 13:19:29,732 INFO     Training average positive_sample_loss at step 46900: 0.041261\n",
      "2023-12-03 13:19:29,732 INFO     Training average negative_sample_loss at step 46900: 0.016442\n",
      "2023-12-03 13:19:29,732 INFO     Training average loss at step 46900: 0.028852\n",
      "2023-12-03 13:19:39,403 INFO     Training average positive_sample_loss at step 47000: 0.040934\n",
      "2023-12-03 13:19:39,403 INFO     Training average negative_sample_loss at step 47000: 0.016525\n",
      "2023-12-03 13:19:39,403 INFO     Training average loss at step 47000: 0.028729\n",
      "2023-12-03 13:19:47,309 INFO     Training average positive_sample_loss at step 47100: 0.040772\n",
      "2023-12-03 13:19:47,310 INFO     Training average negative_sample_loss at step 47100: 0.016488\n",
      "2023-12-03 13:19:47,310 INFO     Training average loss at step 47100: 0.028630\n",
      "2023-12-03 13:19:55,277 INFO     Training average positive_sample_loss at step 47200: 0.041103\n",
      "2023-12-03 13:19:55,277 INFO     Training average negative_sample_loss at step 47200: 0.016584\n",
      "2023-12-03 13:19:55,277 INFO     Training average loss at step 47200: 0.028844\n",
      "2023-12-03 13:20:04,382 INFO     Training average positive_sample_loss at step 47300: 0.040890\n",
      "2023-12-03 13:20:04,383 INFO     Training average negative_sample_loss at step 47300: 0.016346\n",
      "2023-12-03 13:20:04,383 INFO     Training average loss at step 47300: 0.028618\n",
      "2023-12-03 13:20:11,879 INFO     Training average positive_sample_loss at step 47400: 0.040749\n",
      "2023-12-03 13:20:11,879 INFO     Training average negative_sample_loss at step 47400: 0.016473\n",
      "2023-12-03 13:20:11,879 INFO     Training average loss at step 47400: 0.028611\n",
      "2023-12-03 13:20:19,356 INFO     Training average positive_sample_loss at step 47500: 0.040847\n",
      "2023-12-03 13:20:19,356 INFO     Training average negative_sample_loss at step 47500: 0.016689\n",
      "2023-12-03 13:20:19,356 INFO     Training average loss at step 47500: 0.028768\n",
      "2023-12-03 13:20:28,163 INFO     Training average positive_sample_loss at step 47600: 0.041301\n",
      "2023-12-03 13:20:28,163 INFO     Training average negative_sample_loss at step 47600: 0.016538\n",
      "2023-12-03 13:20:28,164 INFO     Training average loss at step 47600: 0.028920\n",
      "2023-12-03 13:20:36,642 INFO     Training average positive_sample_loss at step 47700: 0.040724\n",
      "2023-12-03 13:20:36,642 INFO     Training average negative_sample_loss at step 47700: 0.016539\n",
      "2023-12-03 13:20:36,642 INFO     Training average loss at step 47700: 0.028632\n",
      "2023-12-03 13:20:44,699 INFO     Training average positive_sample_loss at step 47800: 0.040842\n",
      "2023-12-03 13:20:44,699 INFO     Training average negative_sample_loss at step 47800: 0.016525\n",
      "2023-12-03 13:20:44,699 INFO     Training average loss at step 47800: 0.028684\n",
      "2023-12-03 13:20:52,500 INFO     Training average positive_sample_loss at step 47900: 0.041030\n",
      "2023-12-03 13:20:52,500 INFO     Training average negative_sample_loss at step 47900: 0.016643\n",
      "2023-12-03 13:20:52,500 INFO     Training average loss at step 47900: 0.028837\n",
      "2023-12-03 13:21:02,411 INFO     Training average positive_sample_loss at step 48000: 0.040976\n",
      "2023-12-03 13:21:02,412 INFO     Training average negative_sample_loss at step 48000: 0.016512\n",
      "2023-12-03 13:21:02,412 INFO     Training average loss at step 48000: 0.028744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:21:10,567 INFO     Training average positive_sample_loss at step 48100: 0.040978\n",
      "2023-12-03 13:21:10,567 INFO     Training average negative_sample_loss at step 48100: 0.016523\n",
      "2023-12-03 13:21:10,567 INFO     Training average loss at step 48100: 0.028750\n",
      "2023-12-03 13:21:17,981 INFO     Training average positive_sample_loss at step 48200: 0.040717\n",
      "2023-12-03 13:21:17,981 INFO     Training average negative_sample_loss at step 48200: 0.016378\n",
      "2023-12-03 13:21:17,981 INFO     Training average loss at step 48200: 0.028548\n",
      "2023-12-03 13:21:27,360 INFO     Training average positive_sample_loss at step 48300: 0.041051\n",
      "2023-12-03 13:21:27,361 INFO     Training average negative_sample_loss at step 48300: 0.016579\n",
      "2023-12-03 13:21:27,361 INFO     Training average loss at step 48300: 0.028815\n",
      "2023-12-03 13:21:34,990 INFO     Training average positive_sample_loss at step 48400: 0.040804\n",
      "2023-12-03 13:21:34,991 INFO     Training average negative_sample_loss at step 48400: 0.016494\n",
      "2023-12-03 13:21:34,991 INFO     Training average loss at step 48400: 0.028649\n",
      "2023-12-03 13:21:42,505 INFO     Training average positive_sample_loss at step 48500: 0.040855\n",
      "2023-12-03 13:21:42,506 INFO     Training average negative_sample_loss at step 48500: 0.016542\n",
      "2023-12-03 13:21:42,506 INFO     Training average loss at step 48500: 0.028699\n",
      "2023-12-03 13:21:50,289 INFO     Training average positive_sample_loss at step 48600: 0.041088\n",
      "2023-12-03 13:21:50,290 INFO     Training average negative_sample_loss at step 48600: 0.016460\n",
      "2023-12-03 13:21:50,290 INFO     Training average loss at step 48600: 0.028774\n",
      "2023-12-03 13:21:59,657 INFO     Training average positive_sample_loss at step 48700: 0.041093\n",
      "2023-12-03 13:21:59,657 INFO     Training average negative_sample_loss at step 48700: 0.016558\n",
      "2023-12-03 13:21:59,657 INFO     Training average loss at step 48700: 0.028825\n",
      "2023-12-03 13:22:07,462 INFO     Training average positive_sample_loss at step 48800: 0.040789\n",
      "2023-12-03 13:22:07,463 INFO     Training average negative_sample_loss at step 48800: 0.016419\n",
      "2023-12-03 13:22:07,463 INFO     Training average loss at step 48800: 0.028604\n",
      "2023-12-03 13:22:15,411 INFO     Training average positive_sample_loss at step 48900: 0.041012\n",
      "2023-12-03 13:22:15,411 INFO     Training average negative_sample_loss at step 48900: 0.016443\n",
      "2023-12-03 13:22:15,411 INFO     Training average loss at step 48900: 0.028727\n",
      "2023-12-03 13:22:24,648 INFO     Training average positive_sample_loss at step 49000: 0.040678\n",
      "2023-12-03 13:22:24,648 INFO     Training average negative_sample_loss at step 49000: 0.016397\n",
      "2023-12-03 13:22:24,648 INFO     Training average loss at step 49000: 0.028537\n",
      "2023-12-03 13:22:32,760 INFO     Training average positive_sample_loss at step 49100: 0.040963\n",
      "2023-12-03 13:22:32,760 INFO     Training average negative_sample_loss at step 49100: 0.016401\n",
      "2023-12-03 13:22:32,760 INFO     Training average loss at step 49100: 0.028682\n",
      "2023-12-03 13:22:40,527 INFO     Training average positive_sample_loss at step 49200: 0.040970\n",
      "2023-12-03 13:22:40,528 INFO     Training average negative_sample_loss at step 49200: 0.016433\n",
      "2023-12-03 13:22:40,528 INFO     Training average loss at step 49200: 0.028701\n",
      "2023-12-03 13:22:49,243 INFO     Training average positive_sample_loss at step 49300: 0.040942\n",
      "2023-12-03 13:22:49,243 INFO     Training average negative_sample_loss at step 49300: 0.016361\n",
      "2023-12-03 13:22:49,243 INFO     Training average loss at step 49300: 0.028652\n",
      "2023-12-03 13:22:57,735 INFO     Training average positive_sample_loss at step 49400: 0.040706\n",
      "2023-12-03 13:22:57,735 INFO     Training average negative_sample_loss at step 49400: 0.016536\n",
      "2023-12-03 13:22:57,735 INFO     Training average loss at step 49400: 0.028621\n",
      "2023-12-03 13:23:05,571 INFO     Training average positive_sample_loss at step 49500: 0.040883\n",
      "2023-12-03 13:23:05,572 INFO     Training average negative_sample_loss at step 49500: 0.016392\n",
      "2023-12-03 13:23:05,572 INFO     Training average loss at step 49500: 0.028637\n",
      "2023-12-03 13:23:13,635 INFO     Training average positive_sample_loss at step 49600: 0.040955\n",
      "2023-12-03 13:23:13,636 INFO     Training average negative_sample_loss at step 49600: 0.016529\n",
      "2023-12-03 13:23:13,636 INFO     Training average loss at step 49600: 0.028742\n",
      "2023-12-03 13:23:23,912 INFO     Training average positive_sample_loss at step 49700: 0.040813\n",
      "2023-12-03 13:23:23,913 INFO     Training average negative_sample_loss at step 49700: 0.016465\n",
      "2023-12-03 13:23:23,913 INFO     Training average loss at step 49700: 0.028639\n",
      "2023-12-03 13:23:31,333 INFO     Training average positive_sample_loss at step 49800: 0.040901\n",
      "2023-12-03 13:23:31,334 INFO     Training average negative_sample_loss at step 49800: 0.016545\n",
      "2023-12-03 13:23:31,334 INFO     Training average loss at step 49800: 0.028723\n",
      "2023-12-03 13:23:39,388 INFO     Training average positive_sample_loss at step 49900: 0.041192\n",
      "2023-12-03 13:23:39,389 INFO     Training average negative_sample_loss at step 49900: 0.016472\n",
      "2023-12-03 13:23:39,389 INFO     Training average loss at step 49900: 0.028832\n",
      "2023-12-03 13:24:01,448 INFO     Training average positive_sample_loss at step 50000: 0.040768\n",
      "2023-12-03 13:24:01,448 INFO     Training average negative_sample_loss at step 50000: 0.016441\n",
      "2023-12-03 13:24:01,448 INFO     Training average loss at step 50000: 0.028605\n",
      "2023-12-03 13:24:01,448 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 13:24:01,930 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 13:24:35,606 INFO     Valid MRR at step 50000: 0.482137\n",
      "2023-12-03 13:24:35,606 INFO     Valid MR at step 50000: 1789.701055\n",
      "2023-12-03 13:24:35,606 INFO     Valid HITS@1 at step 50000: 0.436882\n",
      "2023-12-03 13:24:35,606 INFO     Valid HITS@3 at step 50000: 0.496704\n",
      "2023-12-03 13:24:35,606 INFO     Valid HITS@10 at step 50000: 0.570699\n",
      "2023-12-03 13:24:42,527 INFO     Training average positive_sample_loss at step 50100: 0.040797\n",
      "2023-12-03 13:24:42,527 INFO     Training average negative_sample_loss at step 50100: 0.016425\n",
      "2023-12-03 13:24:42,527 INFO     Training average loss at step 50100: 0.028611\n",
      "2023-12-03 13:24:50,470 INFO     Training average positive_sample_loss at step 50200: 0.040764\n",
      "2023-12-03 13:24:50,471 INFO     Training average negative_sample_loss at step 50200: 0.016307\n",
      "2023-12-03 13:24:50,471 INFO     Training average loss at step 50200: 0.028535\n",
      "2023-12-03 13:24:58,388 INFO     Training average positive_sample_loss at step 50300: 0.041194\n",
      "2023-12-03 13:24:58,388 INFO     Training average negative_sample_loss at step 50300: 0.016551\n",
      "2023-12-03 13:24:58,388 INFO     Training average loss at step 50300: 0.028873\n",
      "2023-12-03 13:25:07,802 INFO     Training average positive_sample_loss at step 50400: 0.040777\n",
      "2023-12-03 13:25:07,803 INFO     Training average negative_sample_loss at step 50400: 0.016284\n",
      "2023-12-03 13:25:07,803 INFO     Training average loss at step 50400: 0.028531\n",
      "2023-12-03 13:25:16,091 INFO     Training average positive_sample_loss at step 50500: 0.041012\n",
      "2023-12-03 13:25:16,092 INFO     Training average negative_sample_loss at step 50500: 0.016473\n",
      "2023-12-03 13:25:16,092 INFO     Training average loss at step 50500: 0.028742\n",
      "2023-12-03 13:25:23,986 INFO     Training average positive_sample_loss at step 50600: 0.040885\n",
      "2023-12-03 13:25:23,987 INFO     Training average negative_sample_loss at step 50600: 0.016526\n",
      "2023-12-03 13:25:23,987 INFO     Training average loss at step 50600: 0.028706\n",
      "2023-12-03 13:25:33,373 INFO     Training average positive_sample_loss at step 50700: 0.040892\n",
      "2023-12-03 13:25:33,373 INFO     Training average negative_sample_loss at step 50700: 0.016346\n",
      "2023-12-03 13:25:33,373 INFO     Training average loss at step 50700: 0.028619\n",
      "2023-12-03 13:25:41,055 INFO     Training average positive_sample_loss at step 50800: 0.040733\n",
      "2023-12-03 13:25:41,056 INFO     Training average negative_sample_loss at step 50800: 0.016516\n",
      "2023-12-03 13:25:41,056 INFO     Training average loss at step 50800: 0.028625\n",
      "2023-12-03 13:25:49,002 INFO     Training average positive_sample_loss at step 50900: 0.041026\n",
      "2023-12-03 13:25:49,002 INFO     Training average negative_sample_loss at step 50900: 0.016391\n",
      "2023-12-03 13:25:49,002 INFO     Training average loss at step 50900: 0.028708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:25:57,792 INFO     Training average positive_sample_loss at step 51000: 0.041050\n",
      "2023-12-03 13:25:57,793 INFO     Training average negative_sample_loss at step 51000: 0.016357\n",
      "2023-12-03 13:25:57,793 INFO     Training average loss at step 51000: 0.028704\n",
      "2023-12-03 13:26:07,080 INFO     Training average positive_sample_loss at step 51100: 0.040846\n",
      "2023-12-03 13:26:07,081 INFO     Training average negative_sample_loss at step 51100: 0.016447\n",
      "2023-12-03 13:26:07,081 INFO     Training average loss at step 51100: 0.028647\n",
      "2023-12-03 13:26:14,589 INFO     Training average positive_sample_loss at step 51200: 0.040889\n",
      "2023-12-03 13:26:14,590 INFO     Training average negative_sample_loss at step 51200: 0.016429\n",
      "2023-12-03 13:26:14,590 INFO     Training average loss at step 51200: 0.028659\n",
      "2023-12-03 13:26:22,515 INFO     Training average positive_sample_loss at step 51300: 0.040965\n",
      "2023-12-03 13:26:22,516 INFO     Training average negative_sample_loss at step 51300: 0.016360\n",
      "2023-12-03 13:26:22,516 INFO     Training average loss at step 51300: 0.028662\n",
      "2023-12-03 13:26:31,941 INFO     Training average positive_sample_loss at step 51400: 0.040701\n",
      "2023-12-03 13:26:31,941 INFO     Training average negative_sample_loss at step 51400: 0.016251\n",
      "2023-12-03 13:26:31,941 INFO     Training average loss at step 51400: 0.028476\n",
      "2023-12-03 13:26:39,911 INFO     Training average positive_sample_loss at step 51500: 0.041092\n",
      "2023-12-03 13:26:39,911 INFO     Training average negative_sample_loss at step 51500: 0.016362\n",
      "2023-12-03 13:26:39,911 INFO     Training average loss at step 51500: 0.028727\n",
      "2023-12-03 13:26:48,315 INFO     Training average positive_sample_loss at step 51600: 0.040858\n",
      "2023-12-03 13:26:48,315 INFO     Training average negative_sample_loss at step 51600: 0.016339\n",
      "2023-12-03 13:26:48,316 INFO     Training average loss at step 51600: 0.028598\n",
      "2023-12-03 13:26:57,613 INFO     Training average positive_sample_loss at step 51700: 0.040891\n",
      "2023-12-03 13:26:57,613 INFO     Training average negative_sample_loss at step 51700: 0.016494\n",
      "2023-12-03 13:26:57,613 INFO     Training average loss at step 51700: 0.028693\n",
      "2023-12-03 13:27:05,351 INFO     Training average positive_sample_loss at step 51800: 0.040799\n",
      "2023-12-03 13:27:05,351 INFO     Training average negative_sample_loss at step 51800: 0.016264\n",
      "2023-12-03 13:27:05,351 INFO     Training average loss at step 51800: 0.028531\n",
      "2023-12-03 13:27:13,243 INFO     Training average positive_sample_loss at step 51900: 0.041008\n",
      "2023-12-03 13:27:13,244 INFO     Training average negative_sample_loss at step 51900: 0.016431\n",
      "2023-12-03 13:27:13,244 INFO     Training average loss at step 51900: 0.028719\n",
      "2023-12-03 13:27:21,161 INFO     Training average positive_sample_loss at step 52000: 0.040912\n",
      "2023-12-03 13:27:21,161 INFO     Training average negative_sample_loss at step 52000: 0.016296\n",
      "2023-12-03 13:27:21,161 INFO     Training average loss at step 52000: 0.028604\n",
      "2023-12-03 13:27:30,751 INFO     Training average positive_sample_loss at step 52100: 0.040394\n",
      "2023-12-03 13:27:30,752 INFO     Training average negative_sample_loss at step 52100: 0.016306\n",
      "2023-12-03 13:27:30,752 INFO     Training average loss at step 52100: 0.028350\n",
      "2023-12-03 13:27:38,656 INFO     Training average positive_sample_loss at step 52200: 0.040951\n",
      "2023-12-03 13:27:38,657 INFO     Training average negative_sample_loss at step 52200: 0.016313\n",
      "2023-12-03 13:27:38,657 INFO     Training average loss at step 52200: 0.028632\n",
      "2023-12-03 13:27:46,863 INFO     Training average positive_sample_loss at step 52300: 0.041104\n",
      "2023-12-03 13:27:46,864 INFO     Training average negative_sample_loss at step 52300: 0.016380\n",
      "2023-12-03 13:27:46,864 INFO     Training average loss at step 52300: 0.028742\n",
      "2023-12-03 13:27:56,158 INFO     Training average positive_sample_loss at step 52400: 0.040938\n",
      "2023-12-03 13:27:56,158 INFO     Training average negative_sample_loss at step 52400: 0.016300\n",
      "2023-12-03 13:27:56,158 INFO     Training average loss at step 52400: 0.028619\n",
      "2023-12-03 13:28:04,057 INFO     Training average positive_sample_loss at step 52500: 0.040803\n",
      "2023-12-03 13:28:04,058 INFO     Training average negative_sample_loss at step 52500: 0.016370\n",
      "2023-12-03 13:28:04,058 INFO     Training average loss at step 52500: 0.028586\n",
      "2023-12-03 13:28:12,054 INFO     Training average positive_sample_loss at step 52600: 0.040912\n",
      "2023-12-03 13:28:12,054 INFO     Training average negative_sample_loss at step 52600: 0.016289\n",
      "2023-12-03 13:28:12,054 INFO     Training average loss at step 52600: 0.028600\n",
      "2023-12-03 13:28:20,548 INFO     Training average positive_sample_loss at step 52700: 0.041197\n",
      "2023-12-03 13:28:20,549 INFO     Training average negative_sample_loss at step 52700: 0.016175\n",
      "2023-12-03 13:28:20,549 INFO     Training average loss at step 52700: 0.028686\n",
      "2023-12-03 13:28:29,363 INFO     Training average positive_sample_loss at step 52800: 0.040601\n",
      "2023-12-03 13:28:29,363 INFO     Training average negative_sample_loss at step 52800: 0.016405\n",
      "2023-12-03 13:28:29,363 INFO     Training average loss at step 52800: 0.028503\n",
      "2023-12-03 13:28:36,972 INFO     Training average positive_sample_loss at step 52900: 0.040897\n",
      "2023-12-03 13:28:36,972 INFO     Training average negative_sample_loss at step 52900: 0.016313\n",
      "2023-12-03 13:28:36,972 INFO     Training average loss at step 52900: 0.028605\n",
      "2023-12-03 13:28:44,786 INFO     Training average positive_sample_loss at step 53000: 0.040985\n",
      "2023-12-03 13:28:44,786 INFO     Training average negative_sample_loss at step 53000: 0.016276\n",
      "2023-12-03 13:28:44,786 INFO     Training average loss at step 53000: 0.028630\n",
      "2023-12-03 13:28:53,985 INFO     Training average positive_sample_loss at step 53100: 0.040973\n",
      "2023-12-03 13:28:53,985 INFO     Training average negative_sample_loss at step 53100: 0.016445\n",
      "2023-12-03 13:28:53,985 INFO     Training average loss at step 53100: 0.028709\n",
      "2023-12-03 13:29:01,940 INFO     Training average positive_sample_loss at step 53200: 0.040797\n",
      "2023-12-03 13:29:01,941 INFO     Training average negative_sample_loss at step 53200: 0.016271\n",
      "2023-12-03 13:29:01,941 INFO     Training average loss at step 53200: 0.028534\n",
      "2023-12-03 13:29:09,872 INFO     Training average positive_sample_loss at step 53300: 0.040910\n",
      "2023-12-03 13:29:09,872 INFO     Training average negative_sample_loss at step 53300: 0.016327\n",
      "2023-12-03 13:29:09,872 INFO     Training average loss at step 53300: 0.028619\n",
      "2023-12-03 13:29:19,654 INFO     Training average positive_sample_loss at step 53400: 0.041067\n",
      "2023-12-03 13:29:19,654 INFO     Training average negative_sample_loss at step 53400: 0.016340\n",
      "2023-12-03 13:29:19,654 INFO     Training average loss at step 53400: 0.028703\n",
      "2023-12-03 13:29:27,815 INFO     Training average positive_sample_loss at step 53500: 0.040794\n",
      "2023-12-03 13:29:27,816 INFO     Training average negative_sample_loss at step 53500: 0.016246\n",
      "2023-12-03 13:29:27,816 INFO     Training average loss at step 53500: 0.028520\n",
      "2023-12-03 13:29:35,490 INFO     Training average positive_sample_loss at step 53600: 0.040862\n",
      "2023-12-03 13:29:35,490 INFO     Training average negative_sample_loss at step 53600: 0.016248\n",
      "2023-12-03 13:29:35,490 INFO     Training average loss at step 53600: 0.028555\n",
      "2023-12-03 13:29:43,023 INFO     Training average positive_sample_loss at step 53700: 0.041004\n",
      "2023-12-03 13:29:43,024 INFO     Training average negative_sample_loss at step 53700: 0.016413\n",
      "2023-12-03 13:29:43,024 INFO     Training average loss at step 53700: 0.028708\n",
      "2023-12-03 13:29:53,575 INFO     Training average positive_sample_loss at step 53800: 0.040771\n",
      "2023-12-03 13:29:53,575 INFO     Training average negative_sample_loss at step 53800: 0.016358\n",
      "2023-12-03 13:29:53,575 INFO     Training average loss at step 53800: 0.028564\n",
      "2023-12-03 13:30:01,279 INFO     Training average positive_sample_loss at step 53900: 0.040896\n",
      "2023-12-03 13:30:01,280 INFO     Training average negative_sample_loss at step 53900: 0.016400\n",
      "2023-12-03 13:30:01,280 INFO     Training average loss at step 53900: 0.028648\n",
      "2023-12-03 13:30:09,305 INFO     Training average positive_sample_loss at step 54000: 0.041033\n",
      "2023-12-03 13:30:09,305 INFO     Training average negative_sample_loss at step 54000: 0.016341\n",
      "2023-12-03 13:30:09,305 INFO     Training average loss at step 54000: 0.028687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:30:18,650 INFO     Training average positive_sample_loss at step 54100: 0.040801\n",
      "2023-12-03 13:30:18,651 INFO     Training average negative_sample_loss at step 54100: 0.016220\n",
      "2023-12-03 13:30:18,651 INFO     Training average loss at step 54100: 0.028511\n",
      "2023-12-03 13:30:26,393 INFO     Training average positive_sample_loss at step 54200: 0.040755\n",
      "2023-12-03 13:30:26,393 INFO     Training average negative_sample_loss at step 54200: 0.016385\n",
      "2023-12-03 13:30:26,393 INFO     Training average loss at step 54200: 0.028570\n",
      "2023-12-03 13:30:34,496 INFO     Training average positive_sample_loss at step 54300: 0.040886\n",
      "2023-12-03 13:30:34,497 INFO     Training average negative_sample_loss at step 54300: 0.016259\n",
      "2023-12-03 13:30:34,497 INFO     Training average loss at step 54300: 0.028572\n",
      "2023-12-03 13:30:43,218 INFO     Training average positive_sample_loss at step 54400: 0.041038\n",
      "2023-12-03 13:30:43,219 INFO     Training average negative_sample_loss at step 54400: 0.016337\n",
      "2023-12-03 13:30:43,219 INFO     Training average loss at step 54400: 0.028687\n",
      "2023-12-03 13:30:51,984 INFO     Training average positive_sample_loss at step 54500: 0.040526\n",
      "2023-12-03 13:30:51,984 INFO     Training average negative_sample_loss at step 54500: 0.016544\n",
      "2023-12-03 13:30:51,984 INFO     Training average loss at step 54500: 0.028535\n",
      "2023-12-03 13:30:59,832 INFO     Training average positive_sample_loss at step 54600: 0.040754\n",
      "2023-12-03 13:30:59,833 INFO     Training average negative_sample_loss at step 54600: 0.016185\n",
      "2023-12-03 13:30:59,833 INFO     Training average loss at step 54600: 0.028469\n",
      "2023-12-03 13:31:07,776 INFO     Training average positive_sample_loss at step 54700: 0.041237\n",
      "2023-12-03 13:31:07,777 INFO     Training average negative_sample_loss at step 54700: 0.016289\n",
      "2023-12-03 13:31:07,777 INFO     Training average loss at step 54700: 0.028763\n",
      "2023-12-03 13:31:17,164 INFO     Training average positive_sample_loss at step 54800: 0.040767\n",
      "2023-12-03 13:31:17,164 INFO     Training average negative_sample_loss at step 54800: 0.016306\n",
      "2023-12-03 13:31:17,164 INFO     Training average loss at step 54800: 0.028536\n",
      "2023-12-03 13:31:24,885 INFO     Training average positive_sample_loss at step 54900: 0.040899\n",
      "2023-12-03 13:31:24,885 INFO     Training average negative_sample_loss at step 54900: 0.016233\n",
      "2023-12-03 13:31:24,885 INFO     Training average loss at step 54900: 0.028566\n",
      "2023-12-03 13:31:32,795 INFO     Training average positive_sample_loss at step 55000: 0.040942\n",
      "2023-12-03 13:31:32,796 INFO     Training average negative_sample_loss at step 55000: 0.016333\n",
      "2023-12-03 13:31:32,796 INFO     Training average loss at step 55000: 0.028637\n",
      "2023-12-03 13:31:42,676 INFO     Training average positive_sample_loss at step 55100: 0.040966\n",
      "2023-12-03 13:31:42,676 INFO     Training average negative_sample_loss at step 55100: 0.016253\n",
      "2023-12-03 13:31:42,676 INFO     Training average loss at step 55100: 0.028610\n",
      "2023-12-03 13:31:50,417 INFO     Training average positive_sample_loss at step 55200: 0.040851\n",
      "2023-12-03 13:31:50,418 INFO     Training average negative_sample_loss at step 55200: 0.016228\n",
      "2023-12-03 13:31:50,418 INFO     Training average loss at step 55200: 0.028539\n",
      "2023-12-03 13:31:58,237 INFO     Training average positive_sample_loss at step 55300: 0.040827\n",
      "2023-12-03 13:31:58,237 INFO     Training average negative_sample_loss at step 55300: 0.016202\n",
      "2023-12-03 13:31:58,237 INFO     Training average loss at step 55300: 0.028514\n",
      "2023-12-03 13:32:05,926 INFO     Training average positive_sample_loss at step 55400: 0.041014\n",
      "2023-12-03 13:32:05,926 INFO     Training average negative_sample_loss at step 55400: 0.016342\n",
      "2023-12-03 13:32:05,926 INFO     Training average loss at step 55400: 0.028678\n",
      "2023-12-03 13:32:15,282 INFO     Training average positive_sample_loss at step 55500: 0.040365\n",
      "2023-12-03 13:32:15,282 INFO     Training average negative_sample_loss at step 55500: 0.016223\n",
      "2023-12-03 13:32:15,282 INFO     Training average loss at step 55500: 0.028294\n",
      "2023-12-03 13:32:23,047 INFO     Training average positive_sample_loss at step 55600: 0.040646\n",
      "2023-12-03 13:32:23,048 INFO     Training average negative_sample_loss at step 55600: 0.016214\n",
      "2023-12-03 13:32:23,048 INFO     Training average loss at step 55600: 0.028430\n",
      "2023-12-03 13:32:30,912 INFO     Training average positive_sample_loss at step 55700: 0.041292\n",
      "2023-12-03 13:32:30,913 INFO     Training average negative_sample_loss at step 55700: 0.016236\n",
      "2023-12-03 13:32:30,913 INFO     Training average loss at step 55700: 0.028764\n",
      "2023-12-03 13:32:40,834 INFO     Training average positive_sample_loss at step 55800: 0.040980\n",
      "2023-12-03 13:32:40,834 INFO     Training average negative_sample_loss at step 55800: 0.016186\n",
      "2023-12-03 13:32:40,834 INFO     Training average loss at step 55800: 0.028583\n",
      "2023-12-03 13:32:48,430 INFO     Training average positive_sample_loss at step 55900: 0.040929\n",
      "2023-12-03 13:32:48,430 INFO     Training average negative_sample_loss at step 55900: 0.016252\n",
      "2023-12-03 13:32:48,430 INFO     Training average loss at step 55900: 0.028591\n",
      "2023-12-03 13:32:56,423 INFO     Training average positive_sample_loss at step 56000: 0.040914\n",
      "2023-12-03 13:32:56,423 INFO     Training average negative_sample_loss at step 56000: 0.016273\n",
      "2023-12-03 13:32:56,423 INFO     Training average loss at step 56000: 0.028593\n",
      "2023-12-03 13:33:05,042 INFO     Training average positive_sample_loss at step 56100: 0.040944\n",
      "2023-12-03 13:33:05,042 INFO     Training average negative_sample_loss at step 56100: 0.016146\n",
      "2023-12-03 13:33:05,042 INFO     Training average loss at step 56100: 0.028545\n",
      "2023-12-03 13:33:13,791 INFO     Training average positive_sample_loss at step 56200: 0.040616\n",
      "2023-12-03 13:33:13,791 INFO     Training average negative_sample_loss at step 56200: 0.016105\n",
      "2023-12-03 13:33:13,791 INFO     Training average loss at step 56200: 0.028360\n",
      "2023-12-03 13:33:21,612 INFO     Training average positive_sample_loss at step 56300: 0.040700\n",
      "2023-12-03 13:33:21,613 INFO     Training average negative_sample_loss at step 56300: 0.016202\n",
      "2023-12-03 13:33:21,613 INFO     Training average loss at step 56300: 0.028451\n",
      "2023-12-03 13:33:29,497 INFO     Training average positive_sample_loss at step 56400: 0.041110\n",
      "2023-12-03 13:33:29,497 INFO     Training average negative_sample_loss at step 56400: 0.016294\n",
      "2023-12-03 13:33:29,497 INFO     Training average loss at step 56400: 0.028702\n",
      "2023-12-03 13:33:38,872 INFO     Training average positive_sample_loss at step 56500: 0.041108\n",
      "2023-12-03 13:33:38,872 INFO     Training average negative_sample_loss at step 56500: 0.016276\n",
      "2023-12-03 13:33:38,872 INFO     Training average loss at step 56500: 0.028692\n",
      "2023-12-03 13:33:46,880 INFO     Training average positive_sample_loss at step 56600: 0.040642\n",
      "2023-12-03 13:33:46,881 INFO     Training average negative_sample_loss at step 56600: 0.016312\n",
      "2023-12-03 13:33:46,881 INFO     Training average loss at step 56600: 0.028477\n",
      "2023-12-03 13:33:54,747 INFO     Training average positive_sample_loss at step 56700: 0.040721\n",
      "2023-12-03 13:33:54,748 INFO     Training average negative_sample_loss at step 56700: 0.016212\n",
      "2023-12-03 13:33:54,748 INFO     Training average loss at step 56700: 0.028467\n",
      "2023-12-03 13:34:04,378 INFO     Training average positive_sample_loss at step 56800: 0.041094\n",
      "2023-12-03 13:34:04,379 INFO     Training average negative_sample_loss at step 56800: 0.016205\n",
      "2023-12-03 13:34:04,379 INFO     Training average loss at step 56800: 0.028649\n",
      "2023-12-03 13:34:11,997 INFO     Training average positive_sample_loss at step 56900: 0.040918\n",
      "2023-12-03 13:34:11,997 INFO     Training average negative_sample_loss at step 56900: 0.016272\n",
      "2023-12-03 13:34:11,997 INFO     Training average loss at step 56900: 0.028595\n",
      "2023-12-03 13:34:20,218 INFO     Training average positive_sample_loss at step 57000: 0.040695\n",
      "2023-12-03 13:34:20,218 INFO     Training average negative_sample_loss at step 57000: 0.016002\n",
      "2023-12-03 13:34:20,218 INFO     Training average loss at step 57000: 0.028348\n",
      "2023-12-03 13:34:28,042 INFO     Training average positive_sample_loss at step 57100: 0.040989\n",
      "2023-12-03 13:34:28,042 INFO     Training average negative_sample_loss at step 57100: 0.016115\n",
      "2023-12-03 13:34:28,042 INFO     Training average loss at step 57100: 0.028552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:34:37,455 INFO     Training average positive_sample_loss at step 57200: 0.040825\n",
      "2023-12-03 13:34:37,456 INFO     Training average negative_sample_loss at step 57200: 0.016195\n",
      "2023-12-03 13:34:37,456 INFO     Training average loss at step 57200: 0.028510\n",
      "2023-12-03 13:34:45,008 INFO     Training average positive_sample_loss at step 57300: 0.040693\n",
      "2023-12-03 13:34:45,008 INFO     Training average negative_sample_loss at step 57300: 0.016189\n",
      "2023-12-03 13:34:45,008 INFO     Training average loss at step 57300: 0.028441\n",
      "2023-12-03 13:34:54,157 INFO     Training average positive_sample_loss at step 57400: 0.041020\n",
      "2023-12-03 13:34:54,158 INFO     Training average negative_sample_loss at step 57400: 0.016198\n",
      "2023-12-03 13:34:54,158 INFO     Training average loss at step 57400: 0.028609\n",
      "2023-12-03 13:35:03,676 INFO     Training average positive_sample_loss at step 57500: 0.040860\n",
      "2023-12-03 13:35:03,677 INFO     Training average negative_sample_loss at step 57500: 0.016208\n",
      "2023-12-03 13:35:03,677 INFO     Training average loss at step 57500: 0.028534\n",
      "2023-12-03 13:35:11,622 INFO     Training average positive_sample_loss at step 57600: 0.040609\n",
      "2023-12-03 13:35:11,623 INFO     Training average negative_sample_loss at step 57600: 0.016068\n",
      "2023-12-03 13:35:11,623 INFO     Training average loss at step 57600: 0.028339\n",
      "2023-12-03 13:35:20,256 INFO     Training average positive_sample_loss at step 57700: 0.040706\n",
      "2023-12-03 13:35:20,257 INFO     Training average negative_sample_loss at step 57700: 0.016239\n",
      "2023-12-03 13:35:20,257 INFO     Training average loss at step 57700: 0.028472\n",
      "2023-12-03 13:35:28,841 INFO     Training average positive_sample_loss at step 57800: 0.041318\n",
      "2023-12-03 13:35:28,841 INFO     Training average negative_sample_loss at step 57800: 0.016225\n",
      "2023-12-03 13:35:28,841 INFO     Training average loss at step 57800: 0.028771\n",
      "2023-12-03 13:35:37,300 INFO     Training average positive_sample_loss at step 57900: 0.040185\n",
      "2023-12-03 13:35:37,301 INFO     Training average negative_sample_loss at step 57900: 0.016159\n",
      "2023-12-03 13:35:37,301 INFO     Training average loss at step 57900: 0.028172\n",
      "2023-12-03 13:35:45,254 INFO     Training average positive_sample_loss at step 58000: 0.041220\n",
      "2023-12-03 13:35:45,255 INFO     Training average negative_sample_loss at step 58000: 0.016162\n",
      "2023-12-03 13:35:45,255 INFO     Training average loss at step 58000: 0.028691\n",
      "2023-12-03 13:35:53,266 INFO     Training average positive_sample_loss at step 58100: 0.040938\n",
      "2023-12-03 13:35:53,267 INFO     Training average negative_sample_loss at step 58100: 0.016055\n",
      "2023-12-03 13:35:53,267 INFO     Training average loss at step 58100: 0.028496\n",
      "2023-12-03 13:36:02,357 INFO     Training average positive_sample_loss at step 58200: 0.040804\n",
      "2023-12-03 13:36:02,357 INFO     Training average negative_sample_loss at step 58200: 0.016022\n",
      "2023-12-03 13:36:02,357 INFO     Training average loss at step 58200: 0.028413\n",
      "2023-12-03 13:36:10,097 INFO     Training average positive_sample_loss at step 58300: 0.040664\n",
      "2023-12-03 13:36:10,098 INFO     Training average negative_sample_loss at step 58300: 0.016183\n",
      "2023-12-03 13:36:10,098 INFO     Training average loss at step 58300: 0.028424\n",
      "2023-12-03 13:36:18,399 INFO     Training average positive_sample_loss at step 58400: 0.041029\n",
      "2023-12-03 13:36:18,399 INFO     Training average negative_sample_loss at step 58400: 0.016158\n",
      "2023-12-03 13:36:18,399 INFO     Training average loss at step 58400: 0.028594\n",
      "2023-12-03 13:36:27,605 INFO     Training average positive_sample_loss at step 58500: 0.041104\n",
      "2023-12-03 13:36:27,605 INFO     Training average negative_sample_loss at step 58500: 0.016160\n",
      "2023-12-03 13:36:27,605 INFO     Training average loss at step 58500: 0.028632\n",
      "2023-12-03 13:36:36,200 INFO     Training average positive_sample_loss at step 58600: 0.040387\n",
      "2023-12-03 13:36:36,200 INFO     Training average negative_sample_loss at step 58600: 0.016177\n",
      "2023-12-03 13:36:36,200 INFO     Training average loss at step 58600: 0.028282\n",
      "2023-12-03 13:36:44,409 INFO     Training average positive_sample_loss at step 58700: 0.040850\n",
      "2023-12-03 13:36:44,410 INFO     Training average negative_sample_loss at step 58700: 0.016215\n",
      "2023-12-03 13:36:44,410 INFO     Training average loss at step 58700: 0.028532\n",
      "2023-12-03 13:36:52,202 INFO     Training average positive_sample_loss at step 58800: 0.041180\n",
      "2023-12-03 13:36:52,203 INFO     Training average negative_sample_loss at step 58800: 0.016214\n",
      "2023-12-03 13:36:52,203 INFO     Training average loss at step 58800: 0.028697\n",
      "2023-12-03 13:37:01,379 INFO     Training average positive_sample_loss at step 58900: 0.040727\n",
      "2023-12-03 13:37:01,380 INFO     Training average negative_sample_loss at step 58900: 0.016187\n",
      "2023-12-03 13:37:01,380 INFO     Training average loss at step 58900: 0.028457\n",
      "2023-12-03 13:37:09,290 INFO     Training average positive_sample_loss at step 59000: 0.040666\n",
      "2023-12-03 13:37:09,290 INFO     Training average negative_sample_loss at step 59000: 0.016236\n",
      "2023-12-03 13:37:09,291 INFO     Training average loss at step 59000: 0.028451\n",
      "2023-12-03 13:37:17,685 INFO     Training average positive_sample_loss at step 59100: 0.041095\n",
      "2023-12-03 13:37:17,686 INFO     Training average negative_sample_loss at step 59100: 0.016209\n",
      "2023-12-03 13:37:17,686 INFO     Training average loss at step 59100: 0.028652\n",
      "2023-12-03 13:37:27,565 INFO     Training average positive_sample_loss at step 59200: 0.040832\n",
      "2023-12-03 13:37:27,566 INFO     Training average negative_sample_loss at step 59200: 0.016217\n",
      "2023-12-03 13:37:27,566 INFO     Training average loss at step 59200: 0.028524\n",
      "2023-12-03 13:37:35,239 INFO     Training average positive_sample_loss at step 59300: 0.040484\n",
      "2023-12-03 13:37:35,240 INFO     Training average negative_sample_loss at step 59300: 0.016094\n",
      "2023-12-03 13:37:35,240 INFO     Training average loss at step 59300: 0.028289\n",
      "2023-12-03 13:37:44,402 INFO     Training average positive_sample_loss at step 59400: 0.041022\n",
      "2023-12-03 13:37:44,403 INFO     Training average negative_sample_loss at step 59400: 0.016294\n",
      "2023-12-03 13:37:44,403 INFO     Training average loss at step 59400: 0.028658\n",
      "2023-12-03 13:37:52,948 INFO     Training average positive_sample_loss at step 59500: 0.041110\n",
      "2023-12-03 13:37:52,949 INFO     Training average negative_sample_loss at step 59500: 0.016235\n",
      "2023-12-03 13:37:52,949 INFO     Training average loss at step 59500: 0.028673\n",
      "2023-12-03 13:38:01,332 INFO     Training average positive_sample_loss at step 59600: 0.040477\n",
      "2023-12-03 13:38:01,333 INFO     Training average negative_sample_loss at step 59600: 0.016234\n",
      "2023-12-03 13:38:01,333 INFO     Training average loss at step 59600: 0.028356\n",
      "2023-12-03 13:38:08,823 INFO     Training average positive_sample_loss at step 59700: 0.040721\n",
      "2023-12-03 13:38:08,823 INFO     Training average negative_sample_loss at step 59700: 0.016113\n",
      "2023-12-03 13:38:08,823 INFO     Training average loss at step 59700: 0.028417\n",
      "2023-12-03 13:38:16,820 INFO     Training average positive_sample_loss at step 59800: 0.041183\n",
      "2023-12-03 13:38:16,821 INFO     Training average negative_sample_loss at step 59800: 0.016296\n",
      "2023-12-03 13:38:16,821 INFO     Training average loss at step 59800: 0.028739\n",
      "2023-12-03 13:38:26,534 INFO     Training average positive_sample_loss at step 59900: 0.040897\n",
      "2023-12-03 13:38:26,534 INFO     Training average negative_sample_loss at step 59900: 0.016243\n",
      "2023-12-03 13:38:26,534 INFO     Training average loss at step 59900: 0.028570\n",
      "2023-12-03 13:38:45,198 INFO     Training average positive_sample_loss at step 60000: 0.040665\n",
      "2023-12-03 13:38:45,198 INFO     Training average negative_sample_loss at step 60000: 0.016216\n",
      "2023-12-03 13:38:45,198 INFO     Training average loss at step 60000: 0.028440\n",
      "2023-12-03 13:38:45,198 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 13:38:45,830 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 13:39:18,777 INFO     Valid MRR at step 60000: 0.481812\n",
      "2023-12-03 13:39:18,778 INFO     Valid MR at step 60000: 1778.859921\n",
      "2023-12-03 13:39:18,778 INFO     Valid HITS@1 at step 60000: 0.436223\n",
      "2023-12-03 13:39:18,778 INFO     Valid HITS@3 at step 60000: 0.496210\n",
      "2023-12-03 13:39:18,778 INFO     Valid HITS@10 at step 60000: 0.570204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:39:26,613 INFO     Training average positive_sample_loss at step 60100: 0.040687\n",
      "2023-12-03 13:39:26,613 INFO     Training average negative_sample_loss at step 60100: 0.016016\n",
      "2023-12-03 13:39:26,613 INFO     Training average loss at step 60100: 0.028351\n",
      "2023-12-03 13:39:36,250 INFO     Training average positive_sample_loss at step 60200: 0.041129\n",
      "2023-12-03 13:39:36,250 INFO     Training average negative_sample_loss at step 60200: 0.016188\n",
      "2023-12-03 13:39:36,251 INFO     Training average loss at step 60200: 0.028658\n",
      "2023-12-03 13:39:44,068 INFO     Training average positive_sample_loss at step 60300: 0.040645\n",
      "2023-12-03 13:39:44,069 INFO     Training average negative_sample_loss at step 60300: 0.016251\n",
      "2023-12-03 13:39:44,069 INFO     Training average loss at step 60300: 0.028448\n",
      "2023-12-03 13:39:52,131 INFO     Training average positive_sample_loss at step 60400: 0.040614\n",
      "2023-12-03 13:39:52,131 INFO     Training average negative_sample_loss at step 60400: 0.016213\n",
      "2023-12-03 13:39:52,131 INFO     Training average loss at step 60400: 0.028413\n",
      "2023-12-03 13:39:59,798 INFO     Training average positive_sample_loss at step 60500: 0.041271\n",
      "2023-12-03 13:39:59,799 INFO     Training average negative_sample_loss at step 60500: 0.016179\n",
      "2023-12-03 13:39:59,799 INFO     Training average loss at step 60500: 0.028725\n",
      "2023-12-03 13:40:09,245 INFO     Training average positive_sample_loss at step 60600: 0.040624\n",
      "2023-12-03 13:40:09,245 INFO     Training average negative_sample_loss at step 60600: 0.016120\n",
      "2023-12-03 13:40:09,245 INFO     Training average loss at step 60600: 0.028372\n",
      "2023-12-03 13:40:17,659 INFO     Training average positive_sample_loss at step 60700: 0.040822\n",
      "2023-12-03 13:40:17,660 INFO     Training average negative_sample_loss at step 60700: 0.016086\n",
      "2023-12-03 13:40:17,660 INFO     Training average loss at step 60700: 0.028454\n",
      "2023-12-03 13:40:26,023 INFO     Training average positive_sample_loss at step 60800: 0.040833\n",
      "2023-12-03 13:40:26,024 INFO     Training average negative_sample_loss at step 60800: 0.016102\n",
      "2023-12-03 13:40:26,024 INFO     Training average loss at step 60800: 0.028468\n",
      "2023-12-03 13:40:35,175 INFO     Training average positive_sample_loss at step 60900: 0.041011\n",
      "2023-12-03 13:40:35,175 INFO     Training average negative_sample_loss at step 60900: 0.016257\n",
      "2023-12-03 13:40:35,175 INFO     Training average loss at step 60900: 0.028634\n",
      "2023-12-03 13:40:43,095 INFO     Training average positive_sample_loss at step 61000: 0.040258\n",
      "2023-12-03 13:40:43,096 INFO     Training average negative_sample_loss at step 61000: 0.016151\n",
      "2023-12-03 13:40:43,096 INFO     Training average loss at step 61000: 0.028204\n",
      "2023-12-03 13:40:50,995 INFO     Training average positive_sample_loss at step 61100: 0.040815\n",
      "2023-12-03 13:40:50,995 INFO     Training average negative_sample_loss at step 61100: 0.016046\n",
      "2023-12-03 13:40:50,995 INFO     Training average loss at step 61100: 0.028430\n",
      "2023-12-03 13:40:59,713 INFO     Training average positive_sample_loss at step 61200: 0.041367\n",
      "2023-12-03 13:40:59,713 INFO     Training average negative_sample_loss at step 61200: 0.016042\n",
      "2023-12-03 13:40:59,714 INFO     Training average loss at step 61200: 0.028704\n",
      "2023-12-03 13:41:07,971 INFO     Training average positive_sample_loss at step 61300: 0.040675\n",
      "2023-12-03 13:41:07,971 INFO     Training average negative_sample_loss at step 61300: 0.016107\n",
      "2023-12-03 13:41:07,971 INFO     Training average loss at step 61300: 0.028391\n",
      "2023-12-03 13:41:15,482 INFO     Training average positive_sample_loss at step 61400: 0.040699\n",
      "2023-12-03 13:41:15,482 INFO     Training average negative_sample_loss at step 61400: 0.015956\n",
      "2023-12-03 13:41:15,482 INFO     Training average loss at step 61400: 0.028327\n",
      "2023-12-03 13:41:23,198 INFO     Training average positive_sample_loss at step 61500: 0.040990\n",
      "2023-12-03 13:41:23,199 INFO     Training average negative_sample_loss at step 61500: 0.016107\n",
      "2023-12-03 13:41:23,199 INFO     Training average loss at step 61500: 0.028549\n",
      "2023-12-03 13:41:32,752 INFO     Training average positive_sample_loss at step 61600: 0.040668\n",
      "2023-12-03 13:41:32,752 INFO     Training average negative_sample_loss at step 61600: 0.016179\n",
      "2023-12-03 13:41:32,752 INFO     Training average loss at step 61600: 0.028424\n",
      "2023-12-03 13:41:40,407 INFO     Training average positive_sample_loss at step 61700: 0.040665\n",
      "2023-12-03 13:41:40,408 INFO     Training average negative_sample_loss at step 61700: 0.016177\n",
      "2023-12-03 13:41:40,408 INFO     Training average loss at step 61700: 0.028421\n",
      "2023-12-03 13:41:48,599 INFO     Training average positive_sample_loss at step 61800: 0.040712\n",
      "2023-12-03 13:41:48,600 INFO     Training average negative_sample_loss at step 61800: 0.016178\n",
      "2023-12-03 13:41:48,600 INFO     Training average loss at step 61800: 0.028445\n",
      "2023-12-03 13:41:58,219 INFO     Training average positive_sample_loss at step 61900: 0.041171\n",
      "2023-12-03 13:41:58,219 INFO     Training average negative_sample_loss at step 61900: 0.016293\n",
      "2023-12-03 13:41:58,219 INFO     Training average loss at step 61900: 0.028732\n",
      "2023-12-03 13:42:05,975 INFO     Training average positive_sample_loss at step 62000: 0.040526\n",
      "2023-12-03 13:42:05,976 INFO     Training average negative_sample_loss at step 62000: 0.016065\n",
      "2023-12-03 13:42:05,976 INFO     Training average loss at step 62000: 0.028295\n",
      "2023-12-03 13:42:13,647 INFO     Training average positive_sample_loss at step 62100: 0.040834\n",
      "2023-12-03 13:42:13,648 INFO     Training average negative_sample_loss at step 62100: 0.016126\n",
      "2023-12-03 13:42:13,648 INFO     Training average loss at step 62100: 0.028480\n",
      "2023-12-03 13:42:21,913 INFO     Training average positive_sample_loss at step 62200: 0.041184\n",
      "2023-12-03 13:42:21,914 INFO     Training average negative_sample_loss at step 62200: 0.015978\n",
      "2023-12-03 13:42:21,914 INFO     Training average loss at step 62200: 0.028581\n",
      "2023-12-03 13:42:31,030 INFO     Training average positive_sample_loss at step 62300: 0.040374\n",
      "2023-12-03 13:42:31,031 INFO     Training average negative_sample_loss at step 62300: 0.016034\n",
      "2023-12-03 13:42:31,031 INFO     Training average loss at step 62300: 0.028204\n",
      "2023-12-03 13:42:38,512 INFO     Training average positive_sample_loss at step 62400: 0.040920\n",
      "2023-12-03 13:42:38,513 INFO     Training average negative_sample_loss at step 62400: 0.016218\n",
      "2023-12-03 13:42:38,513 INFO     Training average loss at step 62400: 0.028569\n",
      "2023-12-03 13:42:46,175 INFO     Training average positive_sample_loss at step 62500: 0.040919\n",
      "2023-12-03 13:42:46,176 INFO     Training average negative_sample_loss at step 62500: 0.016180\n",
      "2023-12-03 13:42:46,176 INFO     Training average loss at step 62500: 0.028549\n",
      "2023-12-03 13:42:56,095 INFO     Training average positive_sample_loss at step 62600: 0.040735\n",
      "2023-12-03 13:42:56,095 INFO     Training average negative_sample_loss at step 62600: 0.016222\n",
      "2023-12-03 13:42:56,095 INFO     Training average loss at step 62600: 0.028478\n",
      "2023-12-03 13:43:03,765 INFO     Training average positive_sample_loss at step 62700: 0.040512\n",
      "2023-12-03 13:43:03,765 INFO     Training average negative_sample_loss at step 62700: 0.016167\n",
      "2023-12-03 13:43:03,765 INFO     Training average loss at step 62700: 0.028340\n",
      "2023-12-03 13:43:11,674 INFO     Training average positive_sample_loss at step 62800: 0.040925\n",
      "2023-12-03 13:43:11,675 INFO     Training average negative_sample_loss at step 62800: 0.016229\n",
      "2023-12-03 13:43:11,675 INFO     Training average loss at step 62800: 0.028577\n",
      "2023-12-03 13:43:20,192 INFO     Training average positive_sample_loss at step 62900: 0.041120\n",
      "2023-12-03 13:43:20,192 INFO     Training average negative_sample_loss at step 62900: 0.016207\n",
      "2023-12-03 13:43:20,192 INFO     Training average loss at step 62900: 0.028664\n",
      "2023-12-03 13:43:28,634 INFO     Training average positive_sample_loss at step 63000: 0.040671\n",
      "2023-12-03 13:43:28,635 INFO     Training average negative_sample_loss at step 63000: 0.016140\n",
      "2023-12-03 13:43:28,635 INFO     Training average loss at step 63000: 0.028406\n",
      "2023-12-03 13:43:36,172 INFO     Training average positive_sample_loss at step 63100: 0.040706\n",
      "2023-12-03 13:43:36,172 INFO     Training average negative_sample_loss at step 63100: 0.016271\n",
      "2023-12-03 13:43:36,172 INFO     Training average loss at step 63100: 0.028489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:43:44,353 INFO     Training average positive_sample_loss at step 63200: 0.040971\n",
      "2023-12-03 13:43:44,353 INFO     Training average negative_sample_loss at step 63200: 0.015987\n",
      "2023-12-03 13:43:44,353 INFO     Training average loss at step 63200: 0.028479\n",
      "2023-12-03 13:43:54,140 INFO     Training average positive_sample_loss at step 63300: 0.040635\n",
      "2023-12-03 13:43:54,140 INFO     Training average negative_sample_loss at step 63300: 0.016032\n",
      "2023-12-03 13:43:54,140 INFO     Training average loss at step 63300: 0.028333\n",
      "2023-12-03 13:44:01,978 INFO     Training average positive_sample_loss at step 63400: 0.040671\n",
      "2023-12-03 13:44:01,979 INFO     Training average negative_sample_loss at step 63400: 0.016078\n",
      "2023-12-03 13:44:01,979 INFO     Training average loss at step 63400: 0.028375\n",
      "2023-12-03 13:44:10,142 INFO     Training average positive_sample_loss at step 63500: 0.040825\n",
      "2023-12-03 13:44:10,142 INFO     Training average negative_sample_loss at step 63500: 0.016190\n",
      "2023-12-03 13:44:10,142 INFO     Training average loss at step 63500: 0.028507\n",
      "2023-12-03 13:44:19,621 INFO     Training average positive_sample_loss at step 63600: 0.040939\n",
      "2023-12-03 13:44:19,621 INFO     Training average negative_sample_loss at step 63600: 0.016145\n",
      "2023-12-03 13:44:19,621 INFO     Training average loss at step 63600: 0.028542\n",
      "2023-12-03 13:44:27,273 INFO     Training average positive_sample_loss at step 63700: 0.040574\n",
      "2023-12-03 13:44:27,273 INFO     Training average negative_sample_loss at step 63700: 0.016144\n",
      "2023-12-03 13:44:27,273 INFO     Training average loss at step 63700: 0.028359\n",
      "2023-12-03 13:44:34,944 INFO     Training average positive_sample_loss at step 63800: 0.040733\n",
      "2023-12-03 13:44:34,944 INFO     Training average negative_sample_loss at step 63800: 0.016231\n",
      "2023-12-03 13:44:34,944 INFO     Training average loss at step 63800: 0.028482\n",
      "2023-12-03 13:44:42,583 INFO     Training average positive_sample_loss at step 63900: 0.041229\n",
      "2023-12-03 13:44:42,583 INFO     Training average negative_sample_loss at step 63900: 0.016159\n",
      "2023-12-03 13:44:42,583 INFO     Training average loss at step 63900: 0.028694\n",
      "2023-12-03 13:44:52,281 INFO     Training average positive_sample_loss at step 64000: 0.040485\n",
      "2023-12-03 13:44:52,282 INFO     Training average negative_sample_loss at step 64000: 0.016200\n",
      "2023-12-03 13:44:52,282 INFO     Training average loss at step 64000: 0.028343\n",
      "2023-12-03 13:44:59,749 INFO     Training average positive_sample_loss at step 64100: 0.040683\n",
      "2023-12-03 13:44:59,749 INFO     Training average negative_sample_loss at step 64100: 0.016142\n",
      "2023-12-03 13:44:59,750 INFO     Training average loss at step 64100: 0.028413\n",
      "2023-12-03 13:45:07,367 INFO     Training average positive_sample_loss at step 64200: 0.040907\n",
      "2023-12-03 13:45:07,368 INFO     Training average negative_sample_loss at step 64200: 0.016067\n",
      "2023-12-03 13:45:07,368 INFO     Training average loss at step 64200: 0.028487\n",
      "2023-12-03 13:45:16,732 INFO     Training average positive_sample_loss at step 64300: 0.040632\n",
      "2023-12-03 13:45:16,732 INFO     Training average negative_sample_loss at step 64300: 0.016154\n",
      "2023-12-03 13:45:16,732 INFO     Training average loss at step 64300: 0.028393\n",
      "2023-12-03 13:45:24,373 INFO     Training average positive_sample_loss at step 64400: 0.040497\n",
      "2023-12-03 13:45:24,374 INFO     Training average negative_sample_loss at step 64400: 0.016183\n",
      "2023-12-03 13:45:24,374 INFO     Training average loss at step 64400: 0.028340\n",
      "2023-12-03 13:45:32,067 INFO     Training average positive_sample_loss at step 64500: 0.040981\n",
      "2023-12-03 13:45:32,068 INFO     Training average negative_sample_loss at step 64500: 0.016135\n",
      "2023-12-03 13:45:32,068 INFO     Training average loss at step 64500: 0.028558\n",
      "2023-12-03 13:45:41,166 INFO     Training average positive_sample_loss at step 64600: 0.041158\n",
      "2023-12-03 13:45:41,166 INFO     Training average negative_sample_loss at step 64600: 0.016301\n",
      "2023-12-03 13:45:41,166 INFO     Training average loss at step 64600: 0.028729\n",
      "2023-12-03 13:45:49,905 INFO     Training average positive_sample_loss at step 64700: 0.040519\n",
      "2023-12-03 13:45:49,905 INFO     Training average negative_sample_loss at step 64700: 0.016031\n",
      "2023-12-03 13:45:49,905 INFO     Training average loss at step 64700: 0.028275\n",
      "2023-12-03 13:45:57,701 INFO     Training average positive_sample_loss at step 64800: 0.040803\n",
      "2023-12-03 13:45:57,701 INFO     Training average negative_sample_loss at step 64800: 0.016137\n",
      "2023-12-03 13:45:57,701 INFO     Training average loss at step 64800: 0.028470\n",
      "2023-12-03 13:46:05,522 INFO     Training average positive_sample_loss at step 64900: 0.040636\n",
      "2023-12-03 13:46:05,523 INFO     Training average negative_sample_loss at step 64900: 0.016116\n",
      "2023-12-03 13:46:05,523 INFO     Training average loss at step 64900: 0.028376\n",
      "2023-12-03 13:46:14,656 INFO     Training average positive_sample_loss at step 65000: 0.040890\n",
      "2023-12-03 13:46:14,656 INFO     Training average negative_sample_loss at step 65000: 0.016298\n",
      "2023-12-03 13:46:14,656 INFO     Training average loss at step 65000: 0.028594\n",
      "2023-12-03 13:46:22,382 INFO     Training average positive_sample_loss at step 65100: 0.040731\n",
      "2023-12-03 13:46:22,382 INFO     Training average negative_sample_loss at step 65100: 0.016151\n",
      "2023-12-03 13:46:22,382 INFO     Training average loss at step 65100: 0.028441\n",
      "2023-12-03 13:46:29,978 INFO     Training average positive_sample_loss at step 65200: 0.040799\n",
      "2023-12-03 13:46:29,979 INFO     Training average negative_sample_loss at step 65200: 0.016130\n",
      "2023-12-03 13:46:29,979 INFO     Training average loss at step 65200: 0.028464\n",
      "2023-12-03 13:46:39,406 INFO     Training average positive_sample_loss at step 65300: 0.040959\n",
      "2023-12-03 13:46:39,407 INFO     Training average negative_sample_loss at step 65300: 0.016154\n",
      "2023-12-03 13:46:39,407 INFO     Training average loss at step 65300: 0.028557\n",
      "2023-12-03 13:46:46,983 INFO     Training average positive_sample_loss at step 65400: 0.040497\n",
      "2023-12-03 13:46:46,984 INFO     Training average negative_sample_loss at step 65400: 0.016029\n",
      "2023-12-03 13:46:46,984 INFO     Training average loss at step 65400: 0.028263\n",
      "2023-12-03 13:46:54,863 INFO     Training average positive_sample_loss at step 65500: 0.040893\n",
      "2023-12-03 13:46:54,863 INFO     Training average negative_sample_loss at step 65500: 0.015941\n",
      "2023-12-03 13:46:54,863 INFO     Training average loss at step 65500: 0.028417\n",
      "2023-12-03 13:47:02,674 INFO     Training average positive_sample_loss at step 65600: 0.041015\n",
      "2023-12-03 13:47:02,674 INFO     Training average negative_sample_loss at step 65600: 0.016161\n",
      "2023-12-03 13:47:02,674 INFO     Training average loss at step 65600: 0.028588\n",
      "2023-12-03 13:47:12,516 INFO     Training average positive_sample_loss at step 65700: 0.040374\n",
      "2023-12-03 13:47:12,516 INFO     Training average negative_sample_loss at step 65700: 0.016182\n",
      "2023-12-03 13:47:12,516 INFO     Training average loss at step 65700: 0.028278\n",
      "2023-12-03 13:47:20,347 INFO     Training average positive_sample_loss at step 65800: 0.040669\n",
      "2023-12-03 13:47:20,347 INFO     Training average negative_sample_loss at step 65800: 0.016006\n",
      "2023-12-03 13:47:20,347 INFO     Training average loss at step 65800: 0.028338\n",
      "2023-12-03 13:47:28,328 INFO     Training average positive_sample_loss at step 65900: 0.041194\n",
      "2023-12-03 13:47:28,329 INFO     Training average negative_sample_loss at step 65900: 0.016079\n",
      "2023-12-03 13:47:28,329 INFO     Training average loss at step 65900: 0.028637\n",
      "2023-12-03 13:47:37,958 INFO     Training average positive_sample_loss at step 66000: 0.040674\n",
      "2023-12-03 13:47:37,958 INFO     Training average negative_sample_loss at step 66000: 0.016051\n",
      "2023-12-03 13:47:37,958 INFO     Training average loss at step 66000: 0.028363\n",
      "2023-12-03 13:47:45,773 INFO     Training average positive_sample_loss at step 66100: 0.040725\n",
      "2023-12-03 13:47:45,773 INFO     Training average negative_sample_loss at step 66100: 0.016072\n",
      "2023-12-03 13:47:45,773 INFO     Training average loss at step 66100: 0.028398\n",
      "2023-12-03 13:47:54,183 INFO     Training average positive_sample_loss at step 66200: 0.040818\n",
      "2023-12-03 13:47:54,183 INFO     Training average negative_sample_loss at step 66200: 0.016094\n",
      "2023-12-03 13:47:54,184 INFO     Training average loss at step 66200: 0.028456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:48:03,064 INFO     Training average positive_sample_loss at step 66300: 0.040844\n",
      "2023-12-03 13:48:03,064 INFO     Training average negative_sample_loss at step 66300: 0.016112\n",
      "2023-12-03 13:48:03,065 INFO     Training average loss at step 66300: 0.028478\n",
      "2023-12-03 13:48:11,497 INFO     Training average positive_sample_loss at step 66400: 0.040415\n",
      "2023-12-03 13:48:11,497 INFO     Training average negative_sample_loss at step 66400: 0.015899\n",
      "2023-12-03 13:48:11,497 INFO     Training average loss at step 66400: 0.028157\n",
      "2023-12-03 13:48:19,166 INFO     Training average positive_sample_loss at step 66500: 0.040808\n",
      "2023-12-03 13:48:19,167 INFO     Training average negative_sample_loss at step 66500: 0.016112\n",
      "2023-12-03 13:48:19,167 INFO     Training average loss at step 66500: 0.028460\n",
      "2023-12-03 13:48:27,184 INFO     Training average positive_sample_loss at step 66600: 0.040778\n",
      "2023-12-03 13:48:27,184 INFO     Training average negative_sample_loss at step 66600: 0.016148\n",
      "2023-12-03 13:48:27,184 INFO     Training average loss at step 66600: 0.028463\n",
      "2023-12-03 13:48:36,908 INFO     Training average positive_sample_loss at step 66700: 0.040841\n",
      "2023-12-03 13:48:36,908 INFO     Training average negative_sample_loss at step 66700: 0.016218\n",
      "2023-12-03 13:48:36,908 INFO     Training average loss at step 66700: 0.028530\n",
      "2023-12-03 13:48:44,561 INFO     Training average positive_sample_loss at step 66800: 0.040570\n",
      "2023-12-03 13:48:44,561 INFO     Training average negative_sample_loss at step 66800: 0.016079\n",
      "2023-12-03 13:48:44,561 INFO     Training average loss at step 66800: 0.028325\n",
      "2023-12-03 13:48:52,504 INFO     Training average positive_sample_loss at step 66900: 0.040867\n",
      "2023-12-03 13:48:52,504 INFO     Training average negative_sample_loss at step 66900: 0.016219\n",
      "2023-12-03 13:48:52,504 INFO     Training average loss at step 66900: 0.028543\n",
      "2023-12-03 13:49:02,140 INFO     Training average positive_sample_loss at step 67000: 0.041006\n",
      "2023-12-03 13:49:02,140 INFO     Training average negative_sample_loss at step 67000: 0.015973\n",
      "2023-12-03 13:49:02,140 INFO     Training average loss at step 67000: 0.028489\n",
      "2023-12-03 13:49:09,825 INFO     Training average positive_sample_loss at step 67100: 0.040280\n",
      "2023-12-03 13:49:09,825 INFO     Training average negative_sample_loss at step 67100: 0.016099\n",
      "2023-12-03 13:49:09,825 INFO     Training average loss at step 67100: 0.028189\n",
      "2023-12-03 13:49:17,383 INFO     Training average positive_sample_loss at step 67200: 0.041040\n",
      "2023-12-03 13:49:17,383 INFO     Training average negative_sample_loss at step 67200: 0.016026\n",
      "2023-12-03 13:49:17,383 INFO     Training average loss at step 67200: 0.028533\n",
      "2023-12-03 13:49:25,141 INFO     Training average positive_sample_loss at step 67300: 0.040817\n",
      "2023-12-03 13:49:25,142 INFO     Training average negative_sample_loss at step 67300: 0.016068\n",
      "2023-12-03 13:49:25,142 INFO     Training average loss at step 67300: 0.028443\n",
      "2023-12-03 13:49:34,488 INFO     Training average positive_sample_loss at step 67400: 0.040624\n",
      "2023-12-03 13:49:34,488 INFO     Training average negative_sample_loss at step 67400: 0.016206\n",
      "2023-12-03 13:49:34,488 INFO     Training average loss at step 67400: 0.028415\n",
      "2023-12-03 13:49:42,248 INFO     Training average positive_sample_loss at step 67500: 0.040724\n",
      "2023-12-03 13:49:42,249 INFO     Training average negative_sample_loss at step 67500: 0.016010\n",
      "2023-12-03 13:49:42,249 INFO     Training average loss at step 67500: 0.028367\n",
      "2023-12-03 13:49:50,060 INFO     Training average positive_sample_loss at step 67600: 0.040734\n",
      "2023-12-03 13:49:50,061 INFO     Training average negative_sample_loss at step 67600: 0.016270\n",
      "2023-12-03 13:49:50,061 INFO     Training average loss at step 67600: 0.028502\n",
      "2023-12-03 13:49:59,932 INFO     Training average positive_sample_loss at step 67700: 0.040816\n",
      "2023-12-03 13:49:59,932 INFO     Training average negative_sample_loss at step 67700: 0.015952\n",
      "2023-12-03 13:49:59,932 INFO     Training average loss at step 67700: 0.028384\n",
      "2023-12-03 13:50:07,615 INFO     Training average positive_sample_loss at step 67800: 0.040458\n",
      "2023-12-03 13:50:07,616 INFO     Training average negative_sample_loss at step 67800: 0.016092\n",
      "2023-12-03 13:50:07,616 INFO     Training average loss at step 67800: 0.028275\n",
      "2023-12-03 13:50:16,682 INFO     Training average positive_sample_loss at step 67900: 0.041062\n",
      "2023-12-03 13:50:16,683 INFO     Training average negative_sample_loss at step 67900: 0.016194\n",
      "2023-12-03 13:50:16,683 INFO     Training average loss at step 67900: 0.028628\n",
      "2023-12-03 13:50:25,797 INFO     Training average positive_sample_loss at step 68000: 0.040768\n",
      "2023-12-03 13:50:25,798 INFO     Training average negative_sample_loss at step 68000: 0.016138\n",
      "2023-12-03 13:50:25,798 INFO     Training average loss at step 68000: 0.028453\n",
      "2023-12-03 13:50:34,542 INFO     Training average positive_sample_loss at step 68100: 0.040409\n",
      "2023-12-03 13:50:34,543 INFO     Training average negative_sample_loss at step 68100: 0.015967\n",
      "2023-12-03 13:50:34,543 INFO     Training average loss at step 68100: 0.028188\n",
      "2023-12-03 13:50:42,656 INFO     Training average positive_sample_loss at step 68200: 0.040973\n",
      "2023-12-03 13:50:42,657 INFO     Training average negative_sample_loss at step 68200: 0.016060\n",
      "2023-12-03 13:50:42,657 INFO     Training average loss at step 68200: 0.028517\n",
      "2023-12-03 13:50:50,505 INFO     Training average positive_sample_loss at step 68300: 0.040883\n",
      "2023-12-03 13:50:50,505 INFO     Training average negative_sample_loss at step 68300: 0.016085\n",
      "2023-12-03 13:50:50,505 INFO     Training average loss at step 68300: 0.028484\n",
      "2023-12-03 13:50:59,804 INFO     Training average positive_sample_loss at step 68400: 0.040498\n",
      "2023-12-03 13:50:59,805 INFO     Training average negative_sample_loss at step 68400: 0.016023\n",
      "2023-12-03 13:50:59,805 INFO     Training average loss at step 68400: 0.028261\n",
      "2023-12-03 13:51:07,677 INFO     Training average positive_sample_loss at step 68500: 0.040597\n",
      "2023-12-03 13:51:07,677 INFO     Training average negative_sample_loss at step 68500: 0.016073\n",
      "2023-12-03 13:51:07,677 INFO     Training average loss at step 68500: 0.028335\n",
      "2023-12-03 13:51:15,697 INFO     Training average positive_sample_loss at step 68600: 0.040841\n",
      "2023-12-03 13:51:15,698 INFO     Training average negative_sample_loss at step 68600: 0.016096\n",
      "2023-12-03 13:51:15,698 INFO     Training average loss at step 68600: 0.028469\n",
      "2023-12-03 13:51:24,749 INFO     Training average positive_sample_loss at step 68700: 0.040886\n",
      "2023-12-03 13:51:24,750 INFO     Training average negative_sample_loss at step 68700: 0.016069\n",
      "2023-12-03 13:51:24,750 INFO     Training average loss at step 68700: 0.028477\n",
      "2023-12-03 13:51:32,770 INFO     Training average positive_sample_loss at step 68800: 0.040470\n",
      "2023-12-03 13:51:32,770 INFO     Training average negative_sample_loss at step 68800: 0.015976\n",
      "2023-12-03 13:51:32,770 INFO     Training average loss at step 68800: 0.028223\n",
      "2023-12-03 13:51:40,307 INFO     Training average positive_sample_loss at step 68900: 0.040716\n",
      "2023-12-03 13:51:40,307 INFO     Training average negative_sample_loss at step 68900: 0.016276\n",
      "2023-12-03 13:51:40,307 INFO     Training average loss at step 68900: 0.028496\n",
      "2023-12-03 13:51:47,975 INFO     Training average positive_sample_loss at step 69000: 0.040848\n",
      "2023-12-03 13:51:47,976 INFO     Training average negative_sample_loss at step 69000: 0.015968\n",
      "2023-12-03 13:51:47,976 INFO     Training average loss at step 69000: 0.028408\n",
      "2023-12-03 13:51:56,917 INFO     Training average positive_sample_loss at step 69100: 0.040603\n",
      "2023-12-03 13:51:56,918 INFO     Training average negative_sample_loss at step 69100: 0.016012\n",
      "2023-12-03 13:51:56,918 INFO     Training average loss at step 69100: 0.028308\n",
      "2023-12-03 13:52:04,628 INFO     Training average positive_sample_loss at step 69200: 0.040641\n",
      "2023-12-03 13:52:04,629 INFO     Training average negative_sample_loss at step 69200: 0.015989\n",
      "2023-12-03 13:52:04,629 INFO     Training average loss at step 69200: 0.028315\n",
      "2023-12-03 13:52:12,334 INFO     Training average positive_sample_loss at step 69300: 0.040838\n",
      "2023-12-03 13:52:12,334 INFO     Training average negative_sample_loss at step 69300: 0.016306\n",
      "2023-12-03 13:52:12,334 INFO     Training average loss at step 69300: 0.028572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:52:21,842 INFO     Training average positive_sample_loss at step 69400: 0.040908\n",
      "2023-12-03 13:52:21,842 INFO     Training average negative_sample_loss at step 69400: 0.016255\n",
      "2023-12-03 13:52:21,842 INFO     Training average loss at step 69400: 0.028582\n",
      "2023-12-03 13:52:29,451 INFO     Training average positive_sample_loss at step 69500: 0.040290\n",
      "2023-12-03 13:52:29,451 INFO     Training average negative_sample_loss at step 69500: 0.015982\n",
      "2023-12-03 13:52:29,451 INFO     Training average loss at step 69500: 0.028136\n",
      "2023-12-03 13:52:38,107 INFO     Training average positive_sample_loss at step 69600: 0.040886\n",
      "2023-12-03 13:52:38,108 INFO     Training average negative_sample_loss at step 69600: 0.016060\n",
      "2023-12-03 13:52:38,108 INFO     Training average loss at step 69600: 0.028473\n",
      "2023-12-03 13:52:46,896 INFO     Training average positive_sample_loss at step 69700: 0.040997\n",
      "2023-12-03 13:52:46,897 INFO     Training average negative_sample_loss at step 69700: 0.015933\n",
      "2023-12-03 13:52:46,897 INFO     Training average loss at step 69700: 0.028465\n",
      "2023-12-03 13:52:55,589 INFO     Training average positive_sample_loss at step 69800: 0.040435\n",
      "2023-12-03 13:52:55,590 INFO     Training average negative_sample_loss at step 69800: 0.015975\n",
      "2023-12-03 13:52:55,590 INFO     Training average loss at step 69800: 0.028205\n",
      "2023-12-03 13:53:03,333 INFO     Training average positive_sample_loss at step 69900: 0.040763\n",
      "2023-12-03 13:53:03,334 INFO     Training average negative_sample_loss at step 69900: 0.016061\n",
      "2023-12-03 13:53:03,334 INFO     Training average loss at step 69900: 0.028412\n",
      "2023-12-03 13:53:23,898 INFO     Training average positive_sample_loss at step 70000: 0.040731\n",
      "2023-12-03 13:53:23,899 INFO     Training average negative_sample_loss at step 70000: 0.016077\n",
      "2023-12-03 13:53:23,899 INFO     Training average loss at step 70000: 0.028404\n",
      "2023-12-03 13:53:23,899 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 13:53:24,581 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 13:53:56,875 INFO     Valid MRR at step 70000: 0.481441\n",
      "2023-12-03 13:53:56,876 INFO     Valid MR at step 70000: 1769.362393\n",
      "2023-12-03 13:53:56,876 INFO     Valid HITS@1 at step 70000: 0.435564\n",
      "2023-12-03 13:53:56,876 INFO     Valid HITS@3 at step 70000: 0.496539\n",
      "2023-12-03 13:53:56,876 INFO     Valid HITS@10 at step 70000: 0.569216\n",
      "2023-12-03 13:54:05,783 INFO     Training average positive_sample_loss at step 70100: 0.040852\n",
      "2023-12-03 13:54:05,783 INFO     Training average negative_sample_loss at step 70100: 0.016095\n",
      "2023-12-03 13:54:05,784 INFO     Training average loss at step 70100: 0.028474\n",
      "2023-12-03 13:54:13,755 INFO     Training average positive_sample_loss at step 70200: 0.040522\n",
      "2023-12-03 13:54:13,755 INFO     Training average negative_sample_loss at step 70200: 0.016166\n",
      "2023-12-03 13:54:13,755 INFO     Training average loss at step 70200: 0.028344\n",
      "2023-12-03 13:54:22,551 INFO     Training average positive_sample_loss at step 70300: 0.040465\n",
      "2023-12-03 13:54:22,552 INFO     Training average negative_sample_loss at step 70300: 0.015993\n",
      "2023-12-03 13:54:22,552 INFO     Training average loss at step 70300: 0.028229\n",
      "2023-12-03 13:54:31,572 INFO     Training average positive_sample_loss at step 70400: 0.041126\n",
      "2023-12-03 13:54:31,573 INFO     Training average negative_sample_loss at step 70400: 0.016055\n",
      "2023-12-03 13:54:31,573 INFO     Training average loss at step 70400: 0.028591\n",
      "2023-12-03 13:54:39,236 INFO     Training average positive_sample_loss at step 70500: 0.040501\n",
      "2023-12-03 13:54:39,237 INFO     Training average negative_sample_loss at step 70500: 0.016062\n",
      "2023-12-03 13:54:39,237 INFO     Training average loss at step 70500: 0.028281\n",
      "2023-12-03 13:54:47,517 INFO     Training average positive_sample_loss at step 70600: 0.040611\n",
      "2023-12-03 13:54:47,517 INFO     Training average negative_sample_loss at step 70600: 0.016021\n",
      "2023-12-03 13:54:47,517 INFO     Training average loss at step 70600: 0.028316\n",
      "2023-12-03 13:54:55,099 INFO     Training average positive_sample_loss at step 70700: 0.041016\n",
      "2023-12-03 13:54:55,099 INFO     Training average negative_sample_loss at step 70700: 0.016253\n",
      "2023-12-03 13:54:55,099 INFO     Training average loss at step 70700: 0.028635\n",
      "2023-12-03 13:55:04,151 INFO     Training average positive_sample_loss at step 70800: 0.040582\n",
      "2023-12-03 13:55:04,152 INFO     Training average negative_sample_loss at step 70800: 0.016105\n",
      "2023-12-03 13:55:04,152 INFO     Training average loss at step 70800: 0.028343\n",
      "2023-12-03 13:55:11,726 INFO     Training average positive_sample_loss at step 70900: 0.040524\n",
      "2023-12-03 13:55:11,727 INFO     Training average negative_sample_loss at step 70900: 0.015898\n",
      "2023-12-03 13:55:11,727 INFO     Training average loss at step 70900: 0.028211\n",
      "2023-12-03 13:55:19,463 INFO     Training average positive_sample_loss at step 71000: 0.040869\n",
      "2023-12-03 13:55:19,464 INFO     Training average negative_sample_loss at step 71000: 0.015967\n",
      "2023-12-03 13:55:19,464 INFO     Training average loss at step 71000: 0.028418\n",
      "2023-12-03 13:55:28,915 INFO     Training average positive_sample_loss at step 71100: 0.040736\n",
      "2023-12-03 13:55:28,915 INFO     Training average negative_sample_loss at step 71100: 0.016146\n",
      "2023-12-03 13:55:28,915 INFO     Training average loss at step 71100: 0.028441\n",
      "2023-12-03 13:55:36,865 INFO     Training average positive_sample_loss at step 71200: 0.040443\n",
      "2023-12-03 13:55:36,865 INFO     Training average negative_sample_loss at step 71200: 0.015902\n",
      "2023-12-03 13:55:36,865 INFO     Training average loss at step 71200: 0.028172\n",
      "2023-12-03 13:55:44,651 INFO     Training average positive_sample_loss at step 71300: 0.040446\n",
      "2023-12-03 13:55:44,652 INFO     Training average negative_sample_loss at step 71300: 0.016071\n",
      "2023-12-03 13:55:44,652 INFO     Training average loss at step 71300: 0.028259\n",
      "2023-12-03 13:55:53,166 INFO     Training average positive_sample_loss at step 71400: 0.041280\n",
      "2023-12-03 13:55:53,167 INFO     Training average negative_sample_loss at step 71400: 0.016138\n",
      "2023-12-03 13:55:53,167 INFO     Training average loss at step 71400: 0.028709\n",
      "2023-12-03 13:56:02,416 INFO     Training average positive_sample_loss at step 71500: 0.040197\n",
      "2023-12-03 13:56:02,417 INFO     Training average negative_sample_loss at step 71500: 0.016017\n",
      "2023-12-03 13:56:02,417 INFO     Training average loss at step 71500: 0.028107\n",
      "2023-12-03 13:56:10,483 INFO     Training average positive_sample_loss at step 71600: 0.040960\n",
      "2023-12-03 13:56:10,483 INFO     Training average negative_sample_loss at step 71600: 0.016003\n",
      "2023-12-03 13:56:10,483 INFO     Training average loss at step 71600: 0.028482\n",
      "2023-12-03 13:56:18,202 INFO     Training average positive_sample_loss at step 71700: 0.040763\n",
      "2023-12-03 13:56:18,203 INFO     Training average negative_sample_loss at step 71700: 0.016015\n",
      "2023-12-03 13:56:18,203 INFO     Training average loss at step 71700: 0.028389\n",
      "2023-12-03 13:56:27,325 INFO     Training average positive_sample_loss at step 71800: 0.040633\n",
      "2023-12-03 13:56:27,326 INFO     Training average negative_sample_loss at step 71800: 0.016088\n",
      "2023-12-03 13:56:27,326 INFO     Training average loss at step 71800: 0.028361\n",
      "2023-12-03 13:56:34,927 INFO     Training average positive_sample_loss at step 71900: 0.040793\n",
      "2023-12-03 13:56:34,928 INFO     Training average negative_sample_loss at step 71900: 0.016115\n",
      "2023-12-03 13:56:34,928 INFO     Training average loss at step 71900: 0.028454\n",
      "2023-12-03 13:56:42,649 INFO     Training average positive_sample_loss at step 72000: 0.040939\n",
      "2023-12-03 13:56:42,649 INFO     Training average negative_sample_loss at step 72000: 0.016009\n",
      "2023-12-03 13:56:42,649 INFO     Training average loss at step 72000: 0.028474\n",
      "2023-12-03 13:56:52,026 INFO     Training average positive_sample_loss at step 72100: 0.040449\n",
      "2023-12-03 13:56:52,026 INFO     Training average negative_sample_loss at step 72100: 0.016114\n",
      "2023-12-03 13:56:52,026 INFO     Training average loss at step 72100: 0.028281\n",
      "2023-12-03 13:56:59,694 INFO     Training average positive_sample_loss at step 72200: 0.040647\n",
      "2023-12-03 13:56:59,694 INFO     Training average negative_sample_loss at step 72200: 0.015949\n",
      "2023-12-03 13:56:59,694 INFO     Training average loss at step 72200: 0.028298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 13:57:07,756 INFO     Training average positive_sample_loss at step 72300: 0.040507\n",
      "2023-12-03 13:57:07,757 INFO     Training average negative_sample_loss at step 72300: 0.015900\n",
      "2023-12-03 13:57:07,757 INFO     Training average loss at step 72300: 0.028204\n",
      "2023-12-03 13:57:15,528 INFO     Training average positive_sample_loss at step 72400: 0.041005\n",
      "2023-12-03 13:57:15,528 INFO     Training average negative_sample_loss at step 72400: 0.016016\n",
      "2023-12-03 13:57:15,528 INFO     Training average loss at step 72400: 0.028510\n",
      "2023-12-03 13:57:24,609 INFO     Training average positive_sample_loss at step 72500: 0.040364\n",
      "2023-12-03 13:57:24,610 INFO     Training average negative_sample_loss at step 72500: 0.016030\n",
      "2023-12-03 13:57:24,610 INFO     Training average loss at step 72500: 0.028197\n",
      "2023-12-03 13:57:33,050 INFO     Training average positive_sample_loss at step 72600: 0.040475\n",
      "2023-12-03 13:57:33,051 INFO     Training average negative_sample_loss at step 72600: 0.016079\n",
      "2023-12-03 13:57:33,051 INFO     Training average loss at step 72600: 0.028277\n",
      "2023-12-03 13:57:41,190 INFO     Training average positive_sample_loss at step 72700: 0.040887\n",
      "2023-12-03 13:57:41,190 INFO     Training average negative_sample_loss at step 72700: 0.016000\n",
      "2023-12-03 13:57:41,190 INFO     Training average loss at step 72700: 0.028443\n",
      "2023-12-03 13:57:50,564 INFO     Training average positive_sample_loss at step 72800: 0.040773\n",
      "2023-12-03 13:57:50,565 INFO     Training average negative_sample_loss at step 72800: 0.015907\n",
      "2023-12-03 13:57:50,565 INFO     Training average loss at step 72800: 0.028340\n",
      "2023-12-03 13:57:58,102 INFO     Training average positive_sample_loss at step 72900: 0.040581\n",
      "2023-12-03 13:57:58,102 INFO     Training average negative_sample_loss at step 72900: 0.015975\n",
      "2023-12-03 13:57:58,102 INFO     Training average loss at step 72900: 0.028278\n",
      "2023-12-03 13:58:05,967 INFO     Training average positive_sample_loss at step 73000: 0.040669\n",
      "2023-12-03 13:58:05,967 INFO     Training average negative_sample_loss at step 73000: 0.016057\n",
      "2023-12-03 13:58:05,967 INFO     Training average loss at step 73000: 0.028363\n",
      "2023-12-03 13:58:14,674 INFO     Training average positive_sample_loss at step 73100: 0.040783\n",
      "2023-12-03 13:58:14,675 INFO     Training average negative_sample_loss at step 73100: 0.016043\n",
      "2023-12-03 13:58:14,675 INFO     Training average loss at step 73100: 0.028413\n",
      "2023-12-03 13:58:23,270 INFO     Training average positive_sample_loss at step 73200: 0.040166\n",
      "2023-12-03 13:58:23,270 INFO     Training average negative_sample_loss at step 73200: 0.016065\n",
      "2023-12-03 13:58:23,270 INFO     Training average loss at step 73200: 0.028116\n",
      "2023-12-03 13:58:31,169 INFO     Training average positive_sample_loss at step 73300: 0.040621\n",
      "2023-12-03 13:58:31,169 INFO     Training average negative_sample_loss at step 73300: 0.015952\n",
      "2023-12-03 13:58:31,169 INFO     Training average loss at step 73300: 0.028286\n",
      "2023-12-03 13:58:38,855 INFO     Training average positive_sample_loss at step 73400: 0.040908\n",
      "2023-12-03 13:58:38,856 INFO     Training average negative_sample_loss at step 73400: 0.015966\n",
      "2023-12-03 13:58:38,856 INFO     Training average loss at step 73400: 0.028437\n",
      "2023-12-03 13:58:48,124 INFO     Training average positive_sample_loss at step 73500: 0.040869\n",
      "2023-12-03 13:58:48,124 INFO     Training average negative_sample_loss at step 73500: 0.016005\n",
      "2023-12-03 13:58:48,124 INFO     Training average loss at step 73500: 0.028437\n",
      "2023-12-03 13:58:55,648 INFO     Training average positive_sample_loss at step 73600: 0.040517\n",
      "2023-12-03 13:58:55,649 INFO     Training average negative_sample_loss at step 73600: 0.015939\n",
      "2023-12-03 13:58:55,649 INFO     Training average loss at step 73600: 0.028228\n",
      "2023-12-03 13:59:03,496 INFO     Training average positive_sample_loss at step 73700: 0.041017\n",
      "2023-12-03 13:59:03,496 INFO     Training average negative_sample_loss at step 73700: 0.016003\n",
      "2023-12-03 13:59:03,496 INFO     Training average loss at step 73700: 0.028510\n",
      "2023-12-03 13:59:13,205 INFO     Training average positive_sample_loss at step 73800: 0.040449\n",
      "2023-12-03 13:59:13,205 INFO     Training average negative_sample_loss at step 73800: 0.015960\n",
      "2023-12-03 13:59:13,205 INFO     Training average loss at step 73800: 0.028205\n",
      "2023-12-03 13:59:21,005 INFO     Training average positive_sample_loss at step 73900: 0.040685\n",
      "2023-12-03 13:59:21,005 INFO     Training average negative_sample_loss at step 73900: 0.016030\n",
      "2023-12-03 13:59:21,005 INFO     Training average loss at step 73900: 0.028357\n",
      "2023-12-03 13:59:28,998 INFO     Training average positive_sample_loss at step 74000: 0.040326\n",
      "2023-12-03 13:59:28,999 INFO     Training average negative_sample_loss at step 74000: 0.015928\n",
      "2023-12-03 13:59:28,999 INFO     Training average loss at step 74000: 0.028127\n",
      "2023-12-03 13:59:36,653 INFO     Training average positive_sample_loss at step 74100: 0.040945\n",
      "2023-12-03 13:59:36,653 INFO     Training average negative_sample_loss at step 74100: 0.016247\n",
      "2023-12-03 13:59:36,653 INFO     Training average loss at step 74100: 0.028596\n",
      "2023-12-03 13:59:46,087 INFO     Training average positive_sample_loss at step 74200: 0.040320\n",
      "2023-12-03 13:59:46,088 INFO     Training average negative_sample_loss at step 74200: 0.015965\n",
      "2023-12-03 13:59:46,088 INFO     Training average loss at step 74200: 0.028143\n",
      "2023-12-03 13:59:54,165 INFO     Training average positive_sample_loss at step 74300: 0.040715\n",
      "2023-12-03 13:59:54,165 INFO     Training average negative_sample_loss at step 74300: 0.015969\n",
      "2023-12-03 13:59:54,165 INFO     Training average loss at step 74300: 0.028342\n",
      "2023-12-03 14:00:01,847 INFO     Training average positive_sample_loss at step 74400: 0.040891\n",
      "2023-12-03 14:00:01,847 INFO     Training average negative_sample_loss at step 74400: 0.015971\n",
      "2023-12-03 14:00:01,847 INFO     Training average loss at step 74400: 0.028431\n",
      "2023-12-03 14:00:11,554 INFO     Training average positive_sample_loss at step 74500: 0.040646\n",
      "2023-12-03 14:00:11,554 INFO     Training average negative_sample_loss at step 74500: 0.015932\n",
      "2023-12-03 14:00:11,554 INFO     Training average loss at step 74500: 0.028289\n",
      "2023-12-03 14:00:19,647 INFO     Training average positive_sample_loss at step 74600: 0.040326\n",
      "2023-12-03 14:00:19,647 INFO     Training average negative_sample_loss at step 74600: 0.016057\n",
      "2023-12-03 14:00:19,647 INFO     Training average loss at step 74600: 0.028191\n",
      "2023-12-03 14:00:27,396 INFO     Training average positive_sample_loss at step 74700: 0.040747\n",
      "2023-12-03 14:00:27,397 INFO     Training average negative_sample_loss at step 74700: 0.015837\n",
      "2023-12-03 14:00:27,397 INFO     Training average loss at step 74700: 0.028292\n",
      "2023-12-03 14:00:35,881 INFO     Training average positive_sample_loss at step 74800: 0.040938\n",
      "2023-12-03 14:00:35,882 INFO     Training average negative_sample_loss at step 74800: 0.016146\n",
      "2023-12-03 14:00:35,882 INFO     Training average loss at step 74800: 0.028542\n",
      "2023-12-03 14:00:44,403 INFO     Training average positive_sample_loss at step 74900: 0.040391\n",
      "2023-12-03 14:00:44,403 INFO     Training average negative_sample_loss at step 74900: 0.015992\n",
      "2023-12-03 14:00:44,403 INFO     Training average loss at step 74900: 0.028191\n",
      "2023-12-03 14:00:52,165 INFO     Training average positive_sample_loss at step 75000: 0.040924\n",
      "2023-12-03 14:00:52,165 INFO     Training average negative_sample_loss at step 75000: 0.016076\n",
      "2023-12-03 14:00:52,165 INFO     Training average loss at step 75000: 0.028500\n",
      "2023-12-03 14:01:00,095 INFO     Training average positive_sample_loss at step 75100: 0.040531\n",
      "2023-12-03 14:01:00,096 INFO     Training average negative_sample_loss at step 75100: 0.016036\n",
      "2023-12-03 14:01:00,096 INFO     Training average loss at step 75100: 0.028283\n",
      "2023-12-03 14:01:09,997 INFO     Training average positive_sample_loss at step 75200: 0.040290\n",
      "2023-12-03 14:01:09,997 INFO     Training average negative_sample_loss at step 75200: 0.015882\n",
      "2023-12-03 14:01:09,997 INFO     Training average loss at step 75200: 0.028086\n",
      "2023-12-03 14:01:17,735 INFO     Training average positive_sample_loss at step 75300: 0.040672\n",
      "2023-12-03 14:01:17,735 INFO     Training average negative_sample_loss at step 75300: 0.015993\n",
      "2023-12-03 14:01:17,735 INFO     Training average loss at step 75300: 0.028333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 14:01:25,306 INFO     Training average positive_sample_loss at step 75400: 0.040811\n",
      "2023-12-03 14:01:25,306 INFO     Training average negative_sample_loss at step 75400: 0.016040\n",
      "2023-12-03 14:01:25,306 INFO     Training average loss at step 75400: 0.028426\n",
      "2023-12-03 14:01:34,661 INFO     Training average positive_sample_loss at step 75500: 0.040776\n",
      "2023-12-03 14:01:34,661 INFO     Training average negative_sample_loss at step 75500: 0.016251\n",
      "2023-12-03 14:01:34,661 INFO     Training average loss at step 75500: 0.028513\n",
      "2023-12-03 14:01:42,393 INFO     Training average positive_sample_loss at step 75600: 0.040698\n",
      "2023-12-03 14:01:42,393 INFO     Training average negative_sample_loss at step 75600: 0.015956\n",
      "2023-12-03 14:01:42,393 INFO     Training average loss at step 75600: 0.028327\n",
      "2023-12-03 14:01:50,500 INFO     Training average positive_sample_loss at step 75700: 0.040460\n",
      "2023-12-03 14:01:50,500 INFO     Training average negative_sample_loss at step 75700: 0.015952\n",
      "2023-12-03 14:01:50,500 INFO     Training average loss at step 75700: 0.028206\n",
      "2023-12-03 14:01:58,148 INFO     Training average positive_sample_loss at step 75800: 0.040853\n",
      "2023-12-03 14:01:58,148 INFO     Training average negative_sample_loss at step 75800: 0.016025\n",
      "2023-12-03 14:01:58,148 INFO     Training average loss at step 75800: 0.028439\n",
      "2023-12-03 14:02:07,708 INFO     Training average positive_sample_loss at step 75900: 0.040389\n",
      "2023-12-03 14:02:07,709 INFO     Training average negative_sample_loss at step 75900: 0.016086\n",
      "2023-12-03 14:02:07,709 INFO     Training average loss at step 75900: 0.028238\n",
      "2023-12-03 14:02:15,922 INFO     Training average positive_sample_loss at step 76000: 0.040520\n",
      "2023-12-03 14:02:15,923 INFO     Training average negative_sample_loss at step 76000: 0.016013\n",
      "2023-12-03 14:02:15,923 INFO     Training average loss at step 76000: 0.028267\n",
      "2023-12-03 14:02:23,373 INFO     Training average positive_sample_loss at step 76100: 0.040780\n",
      "2023-12-03 14:02:23,373 INFO     Training average negative_sample_loss at step 76100: 0.016059\n",
      "2023-12-03 14:02:23,373 INFO     Training average loss at step 76100: 0.028419\n",
      "2023-12-03 14:02:32,774 INFO     Training average positive_sample_loss at step 76200: 0.040688\n",
      "2023-12-03 14:02:32,775 INFO     Training average negative_sample_loss at step 76200: 0.016060\n",
      "2023-12-03 14:02:32,775 INFO     Training average loss at step 76200: 0.028374\n",
      "2023-12-03 14:02:40,320 INFO     Training average positive_sample_loss at step 76300: 0.040369\n",
      "2023-12-03 14:02:40,321 INFO     Training average negative_sample_loss at step 76300: 0.016071\n",
      "2023-12-03 14:02:40,321 INFO     Training average loss at step 76300: 0.028220\n",
      "2023-12-03 14:02:47,901 INFO     Training average positive_sample_loss at step 76400: 0.040653\n",
      "2023-12-03 14:02:47,902 INFO     Training average negative_sample_loss at step 76400: 0.015937\n",
      "2023-12-03 14:02:47,902 INFO     Training average loss at step 76400: 0.028295\n",
      "2023-12-03 14:02:56,539 INFO     Training average positive_sample_loss at step 76500: 0.040881\n",
      "2023-12-03 14:02:56,540 INFO     Training average negative_sample_loss at step 76500: 0.016194\n",
      "2023-12-03 14:02:56,540 INFO     Training average loss at step 76500: 0.028538\n",
      "2023-12-03 14:03:05,152 INFO     Training average positive_sample_loss at step 76600: 0.040398\n",
      "2023-12-03 14:03:05,152 INFO     Training average negative_sample_loss at step 76600: 0.016034\n",
      "2023-12-03 14:03:05,153 INFO     Training average loss at step 76600: 0.028216\n",
      "2023-12-03 14:03:13,536 INFO     Training average positive_sample_loss at step 76700: 0.040653\n",
      "2023-12-03 14:03:13,536 INFO     Training average negative_sample_loss at step 76700: 0.016062\n",
      "2023-12-03 14:03:13,536 INFO     Training average loss at step 76700: 0.028357\n",
      "2023-12-03 14:03:21,144 INFO     Training average positive_sample_loss at step 76800: 0.040767\n",
      "2023-12-03 14:03:21,145 INFO     Training average negative_sample_loss at step 76800: 0.015978\n",
      "2023-12-03 14:03:21,145 INFO     Training average loss at step 76800: 0.028372\n",
      "2023-12-03 14:03:30,067 INFO     Training average positive_sample_loss at step 76900: 0.040348\n",
      "2023-12-03 14:03:30,067 INFO     Training average negative_sample_loss at step 76900: 0.016057\n",
      "2023-12-03 14:03:30,067 INFO     Training average loss at step 76900: 0.028202\n",
      "2023-12-03 14:03:37,742 INFO     Training average positive_sample_loss at step 77000: 0.040480\n",
      "2023-12-03 14:03:37,742 INFO     Training average negative_sample_loss at step 77000: 0.015881\n",
      "2023-12-03 14:03:37,742 INFO     Training average loss at step 77000: 0.028181\n",
      "2023-12-03 14:03:45,575 INFO     Training average positive_sample_loss at step 77100: 0.040869\n",
      "2023-12-03 14:03:45,575 INFO     Training average negative_sample_loss at step 77100: 0.016102\n",
      "2023-12-03 14:03:45,575 INFO     Training average loss at step 77100: 0.028486\n",
      "2023-12-03 14:03:55,176 INFO     Training average positive_sample_loss at step 77200: 0.040679\n",
      "2023-12-03 14:03:55,176 INFO     Training average negative_sample_loss at step 77200: 0.016100\n",
      "2023-12-03 14:03:55,176 INFO     Training average loss at step 77200: 0.028389\n",
      "2023-12-03 14:04:02,747 INFO     Training average positive_sample_loss at step 77300: 0.040360\n",
      "2023-12-03 14:04:02,747 INFO     Training average negative_sample_loss at step 77300: 0.016201\n",
      "2023-12-03 14:04:02,747 INFO     Training average loss at step 77300: 0.028281\n",
      "2023-12-03 14:04:10,604 INFO     Training average positive_sample_loss at step 77400: 0.040625\n",
      "2023-12-03 14:04:10,604 INFO     Training average negative_sample_loss at step 77400: 0.015889\n",
      "2023-12-03 14:04:10,604 INFO     Training average loss at step 77400: 0.028257\n",
      "2023-12-03 14:04:18,390 INFO     Training average positive_sample_loss at step 77500: 0.040891\n",
      "2023-12-03 14:04:18,390 INFO     Training average negative_sample_loss at step 77500: 0.015975\n",
      "2023-12-03 14:04:18,390 INFO     Training average loss at step 77500: 0.028433\n",
      "2023-12-03 14:04:27,492 INFO     Training average positive_sample_loss at step 77600: 0.040398\n",
      "2023-12-03 14:04:27,493 INFO     Training average negative_sample_loss at step 77600: 0.015999\n",
      "2023-12-03 14:04:27,493 INFO     Training average loss at step 77600: 0.028199\n",
      "2023-12-03 14:04:35,520 INFO     Training average positive_sample_loss at step 77700: 0.040470\n",
      "2023-12-03 14:04:35,520 INFO     Training average negative_sample_loss at step 77700: 0.016004\n",
      "2023-12-03 14:04:35,520 INFO     Training average loss at step 77700: 0.028237\n",
      "2023-12-03 14:04:43,311 INFO     Training average positive_sample_loss at step 77800: 0.040848\n",
      "2023-12-03 14:04:43,311 INFO     Training average negative_sample_loss at step 77800: 0.016026\n",
      "2023-12-03 14:04:43,311 INFO     Training average loss at step 77800: 0.028437\n",
      "2023-12-03 14:04:52,546 INFO     Training average positive_sample_loss at step 77900: 0.040616\n",
      "2023-12-03 14:04:52,546 INFO     Training average negative_sample_loss at step 77900: 0.015953\n",
      "2023-12-03 14:04:52,546 INFO     Training average loss at step 77900: 0.028284\n",
      "2023-12-03 14:05:00,016 INFO     Training average positive_sample_loss at step 78000: 0.040404\n",
      "2023-12-03 14:05:00,017 INFO     Training average negative_sample_loss at step 78000: 0.016032\n",
      "2023-12-03 14:05:00,017 INFO     Training average loss at step 78000: 0.028218\n",
      "2023-12-03 14:05:07,569 INFO     Training average positive_sample_loss at step 78100: 0.040608\n",
      "2023-12-03 14:05:07,570 INFO     Training average negative_sample_loss at step 78100: 0.015896\n",
      "2023-12-03 14:05:07,570 INFO     Training average loss at step 78100: 0.028252\n",
      "2023-12-03 14:05:15,987 INFO     Training average positive_sample_loss at step 78200: 0.040883\n",
      "2023-12-03 14:05:15,987 INFO     Training average negative_sample_loss at step 78200: 0.016079\n",
      "2023-12-03 14:05:15,987 INFO     Training average loss at step 78200: 0.028481\n",
      "2023-12-03 14:05:24,356 INFO     Training average positive_sample_loss at step 78300: 0.040387\n",
      "2023-12-03 14:05:24,357 INFO     Training average negative_sample_loss at step 78300: 0.015975\n",
      "2023-12-03 14:05:24,357 INFO     Training average loss at step 78300: 0.028181\n",
      "2023-12-03 14:05:32,699 INFO     Training average positive_sample_loss at step 78400: 0.040501\n",
      "2023-12-03 14:05:32,699 INFO     Training average negative_sample_loss at step 78400: 0.015958\n",
      "2023-12-03 14:05:32,699 INFO     Training average loss at step 78400: 0.028229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-03 14:05:40,259 INFO     Training average positive_sample_loss at step 78500: 0.040864\n",
      "2023-12-03 14:05:40,260 INFO     Training average negative_sample_loss at step 78500: 0.015976\n",
      "2023-12-03 14:05:40,260 INFO     Training average loss at step 78500: 0.028420\n",
      "2023-12-03 14:05:49,878 INFO     Training average positive_sample_loss at step 78600: 0.040404\n",
      "2023-12-03 14:05:49,879 INFO     Training average negative_sample_loss at step 78600: 0.016034\n",
      "2023-12-03 14:05:49,879 INFO     Training average loss at step 78600: 0.028219\n",
      "2023-12-03 14:05:57,595 INFO     Training average positive_sample_loss at step 78700: 0.040378\n",
      "2023-12-03 14:05:57,595 INFO     Training average negative_sample_loss at step 78700: 0.015941\n",
      "2023-12-03 14:05:57,595 INFO     Training average loss at step 78700: 0.028160\n",
      "2023-12-03 14:06:05,461 INFO     Training average positive_sample_loss at step 78800: 0.040947\n",
      "2023-12-03 14:06:05,461 INFO     Training average negative_sample_loss at step 78800: 0.015859\n",
      "2023-12-03 14:06:05,461 INFO     Training average loss at step 78800: 0.028403\n",
      "2023-12-03 14:06:14,979 INFO     Training average positive_sample_loss at step 78900: 0.040553\n",
      "2023-12-03 14:06:14,979 INFO     Training average negative_sample_loss at step 78900: 0.015945\n",
      "2023-12-03 14:06:14,979 INFO     Training average loss at step 78900: 0.028249\n",
      "2023-12-03 14:06:22,829 INFO     Training average positive_sample_loss at step 79000: 0.040404\n",
      "2023-12-03 14:06:22,829 INFO     Training average negative_sample_loss at step 79000: 0.016072\n",
      "2023-12-03 14:06:22,829 INFO     Training average loss at step 79000: 0.028238\n",
      "2023-12-03 14:06:30,623 INFO     Training average positive_sample_loss at step 79100: 0.040737\n",
      "2023-12-03 14:06:30,623 INFO     Training average negative_sample_loss at step 79100: 0.016020\n",
      "2023-12-03 14:06:30,623 INFO     Training average loss at step 79100: 0.028379\n",
      "2023-12-03 14:06:38,387 INFO     Training average positive_sample_loss at step 79200: 0.040686\n",
      "2023-12-03 14:06:38,387 INFO     Training average negative_sample_loss at step 79200: 0.015944\n",
      "2023-12-03 14:06:38,387 INFO     Training average loss at step 79200: 0.028315\n",
      "2023-12-03 14:06:48,200 INFO     Training average positive_sample_loss at step 79300: 0.040294\n",
      "2023-12-03 14:06:48,201 INFO     Training average negative_sample_loss at step 79300: 0.016091\n",
      "2023-12-03 14:06:48,201 INFO     Training average loss at step 79300: 0.028193\n",
      "2023-12-03 14:06:55,804 INFO     Training average positive_sample_loss at step 79400: 0.040456\n",
      "2023-12-03 14:06:55,804 INFO     Training average negative_sample_loss at step 79400: 0.015940\n",
      "2023-12-03 14:06:55,804 INFO     Training average loss at step 79400: 0.028198\n",
      "2023-12-03 14:07:03,485 INFO     Training average positive_sample_loss at step 79500: 0.040799\n",
      "2023-12-03 14:07:03,486 INFO     Training average negative_sample_loss at step 79500: 0.015945\n",
      "2023-12-03 14:07:03,486 INFO     Training average loss at step 79500: 0.028372\n",
      "2023-12-03 14:07:13,044 INFO     Training average positive_sample_loss at step 79600: 0.040644\n",
      "2023-12-03 14:07:13,044 INFO     Training average negative_sample_loss at step 79600: 0.015981\n",
      "2023-12-03 14:07:13,044 INFO     Training average loss at step 79600: 0.028312\n",
      "2023-12-03 14:07:20,614 INFO     Training average positive_sample_loss at step 79700: 0.040357\n",
      "2023-12-03 14:07:20,615 INFO     Training average negative_sample_loss at step 79700: 0.015917\n",
      "2023-12-03 14:07:20,615 INFO     Training average loss at step 79700: 0.028137\n",
      "2023-12-03 14:07:28,242 INFO     Training average positive_sample_loss at step 79800: 0.040677\n",
      "2023-12-03 14:07:28,242 INFO     Training average negative_sample_loss at step 79800: 0.015965\n",
      "2023-12-03 14:07:28,242 INFO     Training average loss at step 79800: 0.028321\n",
      "2023-12-03 14:07:37,005 INFO     Training average positive_sample_loss at step 79900: 0.040777\n",
      "2023-12-03 14:07:37,005 INFO     Training average negative_sample_loss at step 79900: 0.015810\n",
      "2023-12-03 14:07:37,005 INFO     Training average loss at step 79900: 0.028294\n",
      "2023-12-03 14:07:54,002 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-03 14:07:54,736 INFO     Evaluating the model... (0/760)\n",
      "2023-12-03 14:08:26,552 INFO     Valid MRR at step 79999: 0.481636\n",
      "2023-12-03 14:08:26,552 INFO     Valid MR at step 79999: 1763.595089\n",
      "2023-12-03 14:08:26,553 INFO     Valid HITS@1 at step 79999: 0.436058\n",
      "2023-12-03 14:08:26,553 INFO     Valid HITS@3 at step 79999: 0.495550\n",
      "2023-12-03 14:08:26,553 INFO     Valid HITS@10 at step 79999: 0.570534\n",
      "2023-12-03 14:08:26,553 INFO     Evaluating on Test Dataset...\n",
      "2023-12-03 14:08:26,978 INFO     Evaluating the model... (0/784)\n",
      "2023-12-03 14:08:57,107 INFO     Test MRR at step 79999: 0.480907\n",
      "2023-12-03 14:08:57,107 INFO     Test MR at step 79999: 1829.338864\n",
      "2023-12-03 14:08:57,107 INFO     Test HITS@1 at step 79999: 0.433791\n",
      "2023-12-03 14:08:57,107 INFO     Test HITS@3 at step 79999: 0.497128\n",
      "2023-12-03 14:08:57,107 INFO     Test HITS@10 at step 79999: 0.575463\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE wn18rr 0 0 512 1024 500 6.0 0.5 0.00005 80000 8 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
