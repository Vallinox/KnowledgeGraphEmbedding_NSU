{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con Self-Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-02 16:48:27,274 INFO     Model: RotatE\n",
      "2023-12-02 16:48:27,274 INFO     Data Path: data/FB15k\n",
      "2023-12-02 16:48:27,275 INFO     #entity: 14951\n",
      "2023-12-02 16:48:27,275 INFO     #relation: 1345\n",
      "2023-12-02 16:48:27,650 INFO     #train: 483142\n",
      "2023-12-02 16:48:27,687 INFO     #valid: 50000\n",
      "2023-12-02 16:48:27,733 INFO     #test: 59071\n",
      "2023-12-02 16:48:27,921 INFO     Model Parameter Configuration:\n",
      "2023-12-02 16:48:27,922 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-02 16:48:27,922 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-02 16:48:27,922 INFO     Parameter entity_embedding: torch.Size([14951, 2000]), require_grad = True\n",
      "2023-12-02 16:48:27,922 INFO     Parameter relation_embedding: torch.Size([1345, 1000]), require_grad = True\n",
      "2023-12-02 16:48:34,010 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-02 16:48:34,010 INFO     Start Training...\n",
      "2023-12-02 16:48:34,010 INFO     init_step = 0\n",
      "2023-12-02 16:48:34,010 INFO     batch_size = 1024\n",
      "2023-12-02 16:48:34,010 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-02 16:48:34,010 INFO     hidden_dim = 1000\n",
      "2023-12-02 16:48:34,011 INFO     gamma = 24.000000\n",
      "2023-12-02 16:48:34,011 INFO     negative_adversarial_sampling = True\n",
      "2023-12-02 16:48:34,011 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-02 16:48:34,011 INFO     learning_rate = 0\n",
      "2023-12-02 16:48:49,531 INFO     Training average positive_sample_loss at step 0: 3.206776\n",
      "2023-12-02 16:48:49,531 INFO     Training average negative_sample_loss at step 0: 0.052437\n",
      "2023-12-02 16:48:49,532 INFO     Training average loss at step 0: 1.629606\n",
      "2023-12-02 16:48:49,532 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 16:48:50,813 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 16:50:02,130 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 16:51:18,191 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 16:52:29,933 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 16:53:45,430 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 16:55:04,192 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 16:56:15,206 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 16:56:29,129 INFO     Valid MRR at step 0: 0.004065\n",
      "2023-12-02 16:56:29,130 INFO     Valid MR at step 0: 7118.354630\n",
      "2023-12-02 16:56:29,130 INFO     Valid HITS@1 at step 0: 0.003140\n",
      "2023-12-02 16:56:29,130 INFO     Valid HITS@3 at step 0: 0.003610\n",
      "2023-12-02 16:56:29,130 INFO     Valid HITS@10 at step 0: 0.004640\n",
      "2023-12-02 16:56:35,552 INFO     Training average positive_sample_loss at step 100: 2.325286\n",
      "2023-12-02 16:56:35,553 INFO     Training average negative_sample_loss at step 100: 0.247071\n",
      "2023-12-02 16:56:35,553 INFO     Training average loss at step 100: 1.286179\n",
      "2023-12-02 16:56:43,605 INFO     Training average positive_sample_loss at step 200: 1.071349\n",
      "2023-12-02 16:56:43,605 INFO     Training average negative_sample_loss at step 200: 0.584348\n",
      "2023-12-02 16:56:43,605 INFO     Training average loss at step 200: 0.827849\n",
      "2023-12-02 16:56:52,032 INFO     Training average positive_sample_loss at step 300: 0.810464\n",
      "2023-12-02 16:56:52,032 INFO     Training average negative_sample_loss at step 300: 0.650270\n",
      "2023-12-02 16:56:52,032 INFO     Training average loss at step 300: 0.730367\n",
      "2023-12-02 16:57:00,358 INFO     Training average positive_sample_loss at step 400: 0.725295\n",
      "2023-12-02 16:57:00,359 INFO     Training average negative_sample_loss at step 400: 0.656252\n",
      "2023-12-02 16:57:00,359 INFO     Training average loss at step 400: 0.690773\n",
      "2023-12-02 16:57:08,974 INFO     Training average positive_sample_loss at step 500: 0.675923\n",
      "2023-12-02 16:57:08,974 INFO     Training average negative_sample_loss at step 500: 0.646100\n",
      "2023-12-02 16:57:08,974 INFO     Training average loss at step 500: 0.661012\n",
      "2023-12-02 16:57:17,878 INFO     Training average positive_sample_loss at step 600: 0.644640\n",
      "2023-12-02 16:57:17,879 INFO     Training average negative_sample_loss at step 600: 0.630188\n",
      "2023-12-02 16:57:17,879 INFO     Training average loss at step 600: 0.637414\n",
      "2023-12-02 16:57:29,625 INFO     Training average positive_sample_loss at step 700: 0.616620\n",
      "2023-12-02 16:57:29,626 INFO     Training average negative_sample_loss at step 700: 0.609020\n",
      "2023-12-02 16:57:29,626 INFO     Training average loss at step 700: 0.612820\n",
      "2023-12-02 16:57:41,210 INFO     Training average positive_sample_loss at step 800: 0.591260\n",
      "2023-12-02 16:57:41,210 INFO     Training average negative_sample_loss at step 800: 0.586707\n",
      "2023-12-02 16:57:41,210 INFO     Training average loss at step 800: 0.588984\n",
      "2023-12-02 16:57:50,712 INFO     Training average positive_sample_loss at step 900: 0.561564\n",
      "2023-12-02 16:57:50,713 INFO     Training average negative_sample_loss at step 900: 0.559817\n",
      "2023-12-02 16:57:50,713 INFO     Training average loss at step 900: 0.560691\n",
      "2023-12-02 16:58:03,485 INFO     Training average positive_sample_loss at step 1000: 0.480821\n",
      "2023-12-02 16:58:03,486 INFO     Training average negative_sample_loss at step 1000: 0.515442\n",
      "2023-12-02 16:58:03,486 INFO     Training average loss at step 1000: 0.498132\n",
      "2023-12-02 16:58:15,418 INFO     Training average positive_sample_loss at step 1100: 0.455086\n",
      "2023-12-02 16:58:15,418 INFO     Training average negative_sample_loss at step 1100: 0.454691\n",
      "2023-12-02 16:58:15,418 INFO     Training average loss at step 1100: 0.454888\n",
      "2023-12-02 16:58:25,351 INFO     Training average positive_sample_loss at step 1200: 0.446359\n",
      "2023-12-02 16:58:25,351 INFO     Training average negative_sample_loss at step 1200: 0.439541\n",
      "2023-12-02 16:58:25,352 INFO     Training average loss at step 1200: 0.442950\n",
      "2023-12-02 16:58:36,567 INFO     Training average positive_sample_loss at step 1300: 0.432216\n",
      "2023-12-02 16:58:36,568 INFO     Training average negative_sample_loss at step 1300: 0.421890\n",
      "2023-12-02 16:58:36,568 INFO     Training average loss at step 1300: 0.427053\n",
      "2023-12-02 16:58:48,606 INFO     Training average positive_sample_loss at step 1400: 0.417995\n",
      "2023-12-02 16:58:48,606 INFO     Training average negative_sample_loss at step 1400: 0.405628\n",
      "2023-12-02 16:58:48,606 INFO     Training average loss at step 1400: 0.411811\n",
      "2023-12-02 16:59:00,650 INFO     Training average positive_sample_loss at step 1500: 0.401884\n",
      "2023-12-02 16:59:00,651 INFO     Training average negative_sample_loss at step 1500: 0.389584\n",
      "2023-12-02 16:59:00,651 INFO     Training average loss at step 1500: 0.395734\n",
      "2023-12-02 16:59:10,046 INFO     Training average positive_sample_loss at step 1600: 0.385158\n",
      "2023-12-02 16:59:10,046 INFO     Training average negative_sample_loss at step 1600: 0.372136\n",
      "2023-12-02 16:59:10,046 INFO     Training average loss at step 1600: 0.378647\n",
      "2023-12-02 16:59:21,967 INFO     Training average positive_sample_loss at step 1700: 0.368463\n",
      "2023-12-02 16:59:21,967 INFO     Training average negative_sample_loss at step 1700: 0.353918\n",
      "2023-12-02 16:59:21,967 INFO     Training average loss at step 1700: 0.361191\n",
      "2023-12-02 16:59:33,851 INFO     Training average positive_sample_loss at step 1800: 0.350399\n",
      "2023-12-02 16:59:33,851 INFO     Training average negative_sample_loss at step 1800: 0.335763\n",
      "2023-12-02 16:59:33,851 INFO     Training average loss at step 1800: 0.343081\n",
      "2023-12-02 16:59:46,454 INFO     Training average positive_sample_loss at step 1900: 0.324724\n",
      "2023-12-02 16:59:46,454 INFO     Training average negative_sample_loss at step 1900: 0.319062\n",
      "2023-12-02 16:59:46,454 INFO     Training average loss at step 1900: 0.321893\n",
      "2023-12-02 16:59:55,682 INFO     Training average positive_sample_loss at step 2000: 0.282212\n",
      "2023-12-02 16:59:55,683 INFO     Training average negative_sample_loss at step 2000: 0.277815\n",
      "2023-12-02 16:59:55,683 INFO     Training average loss at step 2000: 0.280013\n",
      "2023-12-02 17:00:07,673 INFO     Training average positive_sample_loss at step 2100: 0.279324\n",
      "2023-12-02 17:00:07,673 INFO     Training average negative_sample_loss at step 2100: 0.264851\n",
      "2023-12-02 17:00:07,673 INFO     Training average loss at step 2100: 0.272087\n",
      "2023-12-02 17:00:19,745 INFO     Training average positive_sample_loss at step 2200: 0.271101\n",
      "2023-12-02 17:00:19,746 INFO     Training average negative_sample_loss at step 2200: 0.255591\n",
      "2023-12-02 17:00:19,746 INFO     Training average loss at step 2200: 0.263346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:00:31,730 INFO     Training average positive_sample_loss at step 2300: 0.262526\n",
      "2023-12-02 17:00:31,731 INFO     Training average negative_sample_loss at step 2300: 0.247376\n",
      "2023-12-02 17:00:31,731 INFO     Training average loss at step 2300: 0.254951\n",
      "2023-12-02 17:00:41,222 INFO     Training average positive_sample_loss at step 2400: 0.252241\n",
      "2023-12-02 17:00:41,222 INFO     Training average negative_sample_loss at step 2400: 0.238089\n",
      "2023-12-02 17:00:41,222 INFO     Training average loss at step 2400: 0.245165\n",
      "2023-12-02 17:00:53,218 INFO     Training average positive_sample_loss at step 2500: 0.242211\n",
      "2023-12-02 17:00:53,219 INFO     Training average negative_sample_loss at step 2500: 0.229752\n",
      "2023-12-02 17:00:53,219 INFO     Training average loss at step 2500: 0.235981\n",
      "2023-12-02 17:01:05,168 INFO     Training average positive_sample_loss at step 2600: 0.232540\n",
      "2023-12-02 17:01:05,169 INFO     Training average negative_sample_loss at step 2600: 0.220988\n",
      "2023-12-02 17:01:05,169 INFO     Training average loss at step 2600: 0.226764\n",
      "2023-12-02 17:01:16,895 INFO     Training average positive_sample_loss at step 2700: 0.223215\n",
      "2023-12-02 17:01:16,896 INFO     Training average negative_sample_loss at step 2700: 0.212924\n",
      "2023-12-02 17:01:16,896 INFO     Training average loss at step 2700: 0.218069\n",
      "2023-12-02 17:01:26,268 INFO     Training average positive_sample_loss at step 2800: 0.214074\n",
      "2023-12-02 17:01:26,268 INFO     Training average negative_sample_loss at step 2800: 0.206169\n",
      "2023-12-02 17:01:26,268 INFO     Training average loss at step 2800: 0.210121\n",
      "2023-12-02 17:01:38,984 INFO     Training average positive_sample_loss at step 2900: 0.187474\n",
      "2023-12-02 17:01:38,984 INFO     Training average negative_sample_loss at step 2900: 0.191731\n",
      "2023-12-02 17:01:38,985 INFO     Training average loss at step 2900: 0.189603\n",
      "2023-12-02 17:01:51,039 INFO     Training average positive_sample_loss at step 3000: 0.182331\n",
      "2023-12-02 17:01:51,039 INFO     Training average negative_sample_loss at step 3000: 0.177762\n",
      "2023-12-02 17:01:51,039 INFO     Training average loss at step 3000: 0.180047\n",
      "2023-12-02 17:02:00,984 INFO     Training average positive_sample_loss at step 3100: 0.179763\n",
      "2023-12-02 17:02:00,984 INFO     Training average negative_sample_loss at step 3100: 0.175967\n",
      "2023-12-02 17:02:00,984 INFO     Training average loss at step 3100: 0.177865\n",
      "2023-12-02 17:02:12,371 INFO     Training average positive_sample_loss at step 3200: 0.176538\n",
      "2023-12-02 17:02:12,372 INFO     Training average negative_sample_loss at step 3200: 0.172549\n",
      "2023-12-02 17:02:12,372 INFO     Training average loss at step 3200: 0.174544\n",
      "2023-12-02 17:02:24,326 INFO     Training average positive_sample_loss at step 3300: 0.172007\n",
      "2023-12-02 17:02:24,326 INFO     Training average negative_sample_loss at step 3300: 0.170300\n",
      "2023-12-02 17:02:24,326 INFO     Training average loss at step 3300: 0.171153\n",
      "2023-12-02 17:02:36,224 INFO     Training average positive_sample_loss at step 3400: 0.167797\n",
      "2023-12-02 17:02:36,224 INFO     Training average negative_sample_loss at step 3400: 0.167004\n",
      "2023-12-02 17:02:36,224 INFO     Training average loss at step 3400: 0.167401\n",
      "2023-12-02 17:02:45,534 INFO     Training average positive_sample_loss at step 3500: 0.163810\n",
      "2023-12-02 17:02:45,534 INFO     Training average negative_sample_loss at step 3500: 0.164971\n",
      "2023-12-02 17:02:45,534 INFO     Training average loss at step 3500: 0.164391\n",
      "2023-12-02 17:02:57,527 INFO     Training average positive_sample_loss at step 3600: 0.160200\n",
      "2023-12-02 17:02:57,527 INFO     Training average negative_sample_loss at step 3600: 0.162242\n",
      "2023-12-02 17:02:57,527 INFO     Training average loss at step 3600: 0.161221\n",
      "2023-12-02 17:03:09,437 INFO     Training average positive_sample_loss at step 3700: 0.155898\n",
      "2023-12-02 17:03:09,438 INFO     Training average negative_sample_loss at step 3700: 0.159928\n",
      "2023-12-02 17:03:09,438 INFO     Training average loss at step 3700: 0.157913\n",
      "2023-12-02 17:03:22,197 INFO     Training average positive_sample_loss at step 3800: 0.146184\n",
      "2023-12-02 17:03:22,198 INFO     Training average negative_sample_loss at step 3800: 0.155228\n",
      "2023-12-02 17:03:22,198 INFO     Training average loss at step 3800: 0.150706\n",
      "2023-12-02 17:03:31,372 INFO     Training average positive_sample_loss at step 3900: 0.136234\n",
      "2023-12-02 17:03:31,373 INFO     Training average negative_sample_loss at step 3900: 0.144807\n",
      "2023-12-02 17:03:31,373 INFO     Training average loss at step 3900: 0.140520\n",
      "2023-12-02 17:03:43,281 INFO     Training average positive_sample_loss at step 4000: 0.137390\n",
      "2023-12-02 17:03:43,282 INFO     Training average negative_sample_loss at step 4000: 0.143229\n",
      "2023-12-02 17:03:43,282 INFO     Training average loss at step 4000: 0.140309\n",
      "2023-12-02 17:03:55,318 INFO     Training average positive_sample_loss at step 4100: 0.136388\n",
      "2023-12-02 17:03:55,319 INFO     Training average negative_sample_loss at step 4100: 0.142639\n",
      "2023-12-02 17:03:55,319 INFO     Training average loss at step 4100: 0.139513\n",
      "2023-12-02 17:04:07,228 INFO     Training average positive_sample_loss at step 4200: 0.134783\n",
      "2023-12-02 17:04:07,228 INFO     Training average negative_sample_loss at step 4200: 0.141438\n",
      "2023-12-02 17:04:07,228 INFO     Training average loss at step 4200: 0.138110\n",
      "2023-12-02 17:04:16,277 INFO     Training average positive_sample_loss at step 4300: 0.134001\n",
      "2023-12-02 17:04:16,277 INFO     Training average negative_sample_loss at step 4300: 0.141163\n",
      "2023-12-02 17:04:16,277 INFO     Training average loss at step 4300: 0.137582\n",
      "2023-12-02 17:04:28,190 INFO     Training average positive_sample_loss at step 4400: 0.133290\n",
      "2023-12-02 17:04:28,190 INFO     Training average negative_sample_loss at step 4400: 0.141840\n",
      "2023-12-02 17:04:28,190 INFO     Training average loss at step 4400: 0.137565\n",
      "2023-12-02 17:04:40,093 INFO     Training average positive_sample_loss at step 4500: 0.130619\n",
      "2023-12-02 17:04:40,093 INFO     Training average negative_sample_loss at step 4500: 0.140141\n",
      "2023-12-02 17:04:40,093 INFO     Training average loss at step 4500: 0.135380\n",
      "2023-12-02 17:04:51,897 INFO     Training average positive_sample_loss at step 4600: 0.129380\n",
      "2023-12-02 17:04:51,898 INFO     Training average negative_sample_loss at step 4600: 0.139546\n",
      "2023-12-02 17:04:51,898 INFO     Training average loss at step 4600: 0.134463\n",
      "2023-12-02 17:05:01,188 INFO     Training average positive_sample_loss at step 4700: 0.127551\n",
      "2023-12-02 17:05:01,189 INFO     Training average negative_sample_loss at step 4700: 0.139394\n",
      "2023-12-02 17:05:01,189 INFO     Training average loss at step 4700: 0.133473\n",
      "2023-12-02 17:05:13,735 INFO     Training average positive_sample_loss at step 4800: 0.115277\n",
      "2023-12-02 17:05:13,735 INFO     Training average negative_sample_loss at step 4800: 0.130984\n",
      "2023-12-02 17:05:13,735 INFO     Training average loss at step 4800: 0.123130\n",
      "2023-12-02 17:05:25,857 INFO     Training average positive_sample_loss at step 4900: 0.117340\n",
      "2023-12-02 17:05:25,857 INFO     Training average negative_sample_loss at step 4900: 0.127734\n",
      "2023-12-02 17:05:25,858 INFO     Training average loss at step 4900: 0.122537\n",
      "2023-12-02 17:05:36,648 INFO     Training average positive_sample_loss at step 5000: 0.118081\n",
      "2023-12-02 17:05:36,648 INFO     Training average negative_sample_loss at step 5000: 0.128379\n",
      "2023-12-02 17:05:36,648 INFO     Training average loss at step 5000: 0.123230\n",
      "2023-12-02 17:05:47,052 INFO     Training average positive_sample_loss at step 5100: 0.118090\n",
      "2023-12-02 17:05:47,052 INFO     Training average negative_sample_loss at step 5100: 0.129604\n",
      "2023-12-02 17:05:47,052 INFO     Training average loss at step 5100: 0.123847\n",
      "2023-12-02 17:05:59,053 INFO     Training average positive_sample_loss at step 5200: 0.118438\n",
      "2023-12-02 17:05:59,053 INFO     Training average negative_sample_loss at step 5200: 0.129081\n",
      "2023-12-02 17:05:59,053 INFO     Training average loss at step 5200: 0.123759\n",
      "2023-12-02 17:06:11,138 INFO     Training average positive_sample_loss at step 5300: 0.117965\n",
      "2023-12-02 17:06:11,138 INFO     Training average negative_sample_loss at step 5300: 0.129035\n",
      "2023-12-02 17:06:11,138 INFO     Training average loss at step 5300: 0.123500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:06:21,045 INFO     Training average positive_sample_loss at step 5400: 0.116765\n",
      "2023-12-02 17:06:21,045 INFO     Training average negative_sample_loss at step 5400: 0.129120\n",
      "2023-12-02 17:06:21,045 INFO     Training average loss at step 5400: 0.122943\n",
      "2023-12-02 17:06:32,377 INFO     Training average positive_sample_loss at step 5500: 0.116269\n",
      "2023-12-02 17:06:32,377 INFO     Training average negative_sample_loss at step 5500: 0.128166\n",
      "2023-12-02 17:06:32,377 INFO     Training average loss at step 5500: 0.122217\n",
      "2023-12-02 17:06:44,310 INFO     Training average positive_sample_loss at step 5600: 0.115063\n",
      "2023-12-02 17:06:44,310 INFO     Training average negative_sample_loss at step 5600: 0.127861\n",
      "2023-12-02 17:06:44,310 INFO     Training average loss at step 5600: 0.121462\n",
      "2023-12-02 17:06:56,945 INFO     Training average positive_sample_loss at step 5700: 0.108718\n",
      "2023-12-02 17:06:56,945 INFO     Training average negative_sample_loss at step 5700: 0.125318\n",
      "2023-12-02 17:06:56,945 INFO     Training average loss at step 5700: 0.117018\n",
      "2023-12-02 17:07:06,058 INFO     Training average positive_sample_loss at step 5800: 0.106294\n",
      "2023-12-02 17:07:06,059 INFO     Training average negative_sample_loss at step 5800: 0.118188\n",
      "2023-12-02 17:07:06,059 INFO     Training average loss at step 5800: 0.112241\n",
      "2023-12-02 17:07:18,004 INFO     Training average positive_sample_loss at step 5900: 0.107670\n",
      "2023-12-02 17:07:18,005 INFO     Training average negative_sample_loss at step 5900: 0.118687\n",
      "2023-12-02 17:07:18,005 INFO     Training average loss at step 5900: 0.113178\n",
      "2023-12-02 17:07:29,999 INFO     Training average positive_sample_loss at step 6000: 0.109111\n",
      "2023-12-02 17:07:29,999 INFO     Training average negative_sample_loss at step 6000: 0.121129\n",
      "2023-12-02 17:07:29,999 INFO     Training average loss at step 6000: 0.115120\n",
      "2023-12-02 17:07:41,871 INFO     Training average positive_sample_loss at step 6100: 0.109357\n",
      "2023-12-02 17:07:41,871 INFO     Training average negative_sample_loss at step 6100: 0.120872\n",
      "2023-12-02 17:07:41,871 INFO     Training average loss at step 6100: 0.115115\n",
      "2023-12-02 17:07:51,157 INFO     Training average positive_sample_loss at step 6200: 0.109298\n",
      "2023-12-02 17:07:51,157 INFO     Training average negative_sample_loss at step 6200: 0.121988\n",
      "2023-12-02 17:07:51,157 INFO     Training average loss at step 6200: 0.115643\n",
      "2023-12-02 17:08:03,080 INFO     Training average positive_sample_loss at step 6300: 0.108871\n",
      "2023-12-02 17:08:03,081 INFO     Training average negative_sample_loss at step 6300: 0.121177\n",
      "2023-12-02 17:08:03,081 INFO     Training average loss at step 6300: 0.115024\n",
      "2023-12-02 17:08:14,913 INFO     Training average positive_sample_loss at step 6400: 0.108748\n",
      "2023-12-02 17:08:14,913 INFO     Training average negative_sample_loss at step 6400: 0.121591\n",
      "2023-12-02 17:08:14,913 INFO     Training average loss at step 6400: 0.115170\n",
      "2023-12-02 17:08:26,874 INFO     Training average positive_sample_loss at step 6500: 0.107837\n",
      "2023-12-02 17:08:26,874 INFO     Training average negative_sample_loss at step 6500: 0.120698\n",
      "2023-12-02 17:08:26,874 INFO     Training average loss at step 6500: 0.114268\n",
      "2023-12-02 17:08:36,033 INFO     Training average positive_sample_loss at step 6600: 0.107830\n",
      "2023-12-02 17:08:36,034 INFO     Training average negative_sample_loss at step 6600: 0.121867\n",
      "2023-12-02 17:08:36,034 INFO     Training average loss at step 6600: 0.114849\n",
      "2023-12-02 17:08:48,678 INFO     Training average positive_sample_loss at step 6700: 0.098582\n",
      "2023-12-02 17:08:48,678 INFO     Training average negative_sample_loss at step 6700: 0.114859\n",
      "2023-12-02 17:08:48,678 INFO     Training average loss at step 6700: 0.106721\n",
      "2023-12-02 17:09:00,503 INFO     Training average positive_sample_loss at step 6800: 0.101700\n",
      "2023-12-02 17:09:00,503 INFO     Training average negative_sample_loss at step 6800: 0.113502\n",
      "2023-12-02 17:09:00,503 INFO     Training average loss at step 6800: 0.107601\n",
      "2023-12-02 17:09:12,245 INFO     Training average positive_sample_loss at step 6900: 0.102832\n",
      "2023-12-02 17:09:12,246 INFO     Training average negative_sample_loss at step 6900: 0.113936\n",
      "2023-12-02 17:09:12,246 INFO     Training average loss at step 6900: 0.108384\n",
      "2023-12-02 17:09:21,474 INFO     Training average positive_sample_loss at step 7000: 0.103366\n",
      "2023-12-02 17:09:21,474 INFO     Training average negative_sample_loss at step 7000: 0.114942\n",
      "2023-12-02 17:09:21,474 INFO     Training average loss at step 7000: 0.109154\n",
      "2023-12-02 17:09:33,367 INFO     Training average positive_sample_loss at step 7100: 0.103654\n",
      "2023-12-02 17:09:33,368 INFO     Training average negative_sample_loss at step 7100: 0.115829\n",
      "2023-12-02 17:09:33,368 INFO     Training average loss at step 7100: 0.109741\n",
      "2023-12-02 17:09:45,245 INFO     Training average positive_sample_loss at step 7200: 0.104173\n",
      "2023-12-02 17:09:45,246 INFO     Training average negative_sample_loss at step 7200: 0.116092\n",
      "2023-12-02 17:09:45,246 INFO     Training average loss at step 7200: 0.110132\n",
      "2023-12-02 17:09:56,620 INFO     Training average positive_sample_loss at step 7300: 0.104086\n",
      "2023-12-02 17:09:56,620 INFO     Training average negative_sample_loss at step 7300: 0.116479\n",
      "2023-12-02 17:09:56,620 INFO     Training average loss at step 7300: 0.110282\n",
      "2023-12-02 17:10:06,511 INFO     Training average positive_sample_loss at step 7400: 0.103789\n",
      "2023-12-02 17:10:06,511 INFO     Training average negative_sample_loss at step 7400: 0.116631\n",
      "2023-12-02 17:10:06,511 INFO     Training average loss at step 7400: 0.110210\n",
      "2023-12-02 17:10:18,443 INFO     Training average positive_sample_loss at step 7500: 0.104015\n",
      "2023-12-02 17:10:18,443 INFO     Training average negative_sample_loss at step 7500: 0.115727\n",
      "2023-12-02 17:10:18,443 INFO     Training average loss at step 7500: 0.109871\n",
      "2023-12-02 17:10:31,214 INFO     Training average positive_sample_loss at step 7600: 0.097986\n",
      "2023-12-02 17:10:31,215 INFO     Training average negative_sample_loss at step 7600: 0.113294\n",
      "2023-12-02 17:10:31,215 INFO     Training average loss at step 7600: 0.105640\n",
      "2023-12-02 17:10:40,757 INFO     Training average positive_sample_loss at step 7700: 0.096471\n",
      "2023-12-02 17:10:40,758 INFO     Training average negative_sample_loss at step 7700: 0.108474\n",
      "2023-12-02 17:10:40,758 INFO     Training average loss at step 7700: 0.102472\n",
      "2023-12-02 17:10:52,289 INFO     Training average positive_sample_loss at step 7800: 0.098731\n",
      "2023-12-02 17:10:52,289 INFO     Training average negative_sample_loss at step 7800: 0.109698\n",
      "2023-12-02 17:10:52,289 INFO     Training average loss at step 7800: 0.104214\n",
      "2023-12-02 17:11:04,246 INFO     Training average positive_sample_loss at step 7900: 0.099402\n",
      "2023-12-02 17:11:04,247 INFO     Training average negative_sample_loss at step 7900: 0.109862\n",
      "2023-12-02 17:11:04,247 INFO     Training average loss at step 7900: 0.104632\n",
      "2023-12-02 17:11:16,166 INFO     Training average positive_sample_loss at step 8000: 0.099590\n",
      "2023-12-02 17:11:16,166 INFO     Training average negative_sample_loss at step 8000: 0.110110\n",
      "2023-12-02 17:11:16,166 INFO     Training average loss at step 8000: 0.104850\n",
      "2023-12-02 17:11:25,424 INFO     Training average positive_sample_loss at step 8100: 0.100076\n",
      "2023-12-02 17:11:25,424 INFO     Training average negative_sample_loss at step 8100: 0.111756\n",
      "2023-12-02 17:11:25,424 INFO     Training average loss at step 8100: 0.105916\n",
      "2023-12-02 17:11:37,293 INFO     Training average positive_sample_loss at step 8200: 0.100477\n",
      "2023-12-02 17:11:37,294 INFO     Training average negative_sample_loss at step 8200: 0.111799\n",
      "2023-12-02 17:11:37,294 INFO     Training average loss at step 8200: 0.106138\n",
      "2023-12-02 17:11:49,310 INFO     Training average positive_sample_loss at step 8300: 0.099645\n",
      "2023-12-02 17:11:49,310 INFO     Training average negative_sample_loss at step 8300: 0.111074\n",
      "2023-12-02 17:11:49,310 INFO     Training average loss at step 8300: 0.105359\n",
      "2023-12-02 17:12:01,192 INFO     Training average positive_sample_loss at step 8400: 0.099709\n",
      "2023-12-02 17:12:01,192 INFO     Training average negative_sample_loss at step 8400: 0.110799\n",
      "2023-12-02 17:12:01,192 INFO     Training average loss at step 8400: 0.105254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:12:11,204 INFO     Training average positive_sample_loss at step 8500: 0.098665\n",
      "2023-12-02 17:12:11,204 INFO     Training average negative_sample_loss at step 8500: 0.111296\n",
      "2023-12-02 17:12:11,204 INFO     Training average loss at step 8500: 0.104981\n",
      "2023-12-02 17:12:23,018 INFO     Training average positive_sample_loss at step 8600: 0.091494\n",
      "2023-12-02 17:12:23,019 INFO     Training average negative_sample_loss at step 8600: 0.105137\n",
      "2023-12-02 17:12:23,019 INFO     Training average loss at step 8600: 0.098315\n",
      "2023-12-02 17:12:34,980 INFO     Training average positive_sample_loss at step 8700: 0.094406\n",
      "2023-12-02 17:12:34,980 INFO     Training average negative_sample_loss at step 8700: 0.104053\n",
      "2023-12-02 17:12:34,980 INFO     Training average loss at step 8700: 0.099230\n",
      "2023-12-02 17:12:46,948 INFO     Training average positive_sample_loss at step 8800: 0.095624\n",
      "2023-12-02 17:12:46,948 INFO     Training average negative_sample_loss at step 8800: 0.106312\n",
      "2023-12-02 17:12:46,948 INFO     Training average loss at step 8800: 0.100968\n",
      "2023-12-02 17:12:56,271 INFO     Training average positive_sample_loss at step 8900: 0.096394\n",
      "2023-12-02 17:12:56,271 INFO     Training average negative_sample_loss at step 8900: 0.106531\n",
      "2023-12-02 17:12:56,271 INFO     Training average loss at step 8900: 0.101462\n",
      "2023-12-02 17:13:08,270 INFO     Training average positive_sample_loss at step 9000: 0.096927\n",
      "2023-12-02 17:13:08,270 INFO     Training average negative_sample_loss at step 9000: 0.106838\n",
      "2023-12-02 17:13:08,270 INFO     Training average loss at step 9000: 0.101882\n",
      "2023-12-02 17:13:20,154 INFO     Training average positive_sample_loss at step 9100: 0.097204\n",
      "2023-12-02 17:13:20,155 INFO     Training average negative_sample_loss at step 9100: 0.108352\n",
      "2023-12-02 17:13:20,155 INFO     Training average loss at step 9100: 0.102778\n",
      "2023-12-02 17:13:32,070 INFO     Training average positive_sample_loss at step 9200: 0.098516\n",
      "2023-12-02 17:13:32,070 INFO     Training average negative_sample_loss at step 9200: 0.109152\n",
      "2023-12-02 17:13:32,070 INFO     Training average loss at step 9200: 0.103834\n",
      "2023-12-02 17:13:41,415 INFO     Training average positive_sample_loss at step 9300: 0.097094\n",
      "2023-12-02 17:13:41,415 INFO     Training average negative_sample_loss at step 9300: 0.107955\n",
      "2023-12-02 17:13:41,415 INFO     Training average loss at step 9300: 0.102525\n",
      "2023-12-02 17:13:53,568 INFO     Training average positive_sample_loss at step 9400: 0.097224\n",
      "2023-12-02 17:13:53,568 INFO     Training average negative_sample_loss at step 9400: 0.108917\n",
      "2023-12-02 17:13:53,568 INFO     Training average loss at step 9400: 0.103070\n",
      "2023-12-02 17:14:06,248 INFO     Training average positive_sample_loss at step 9500: 0.091349\n",
      "2023-12-02 17:14:06,248 INFO     Training average negative_sample_loss at step 9500: 0.104803\n",
      "2023-12-02 17:14:06,248 INFO     Training average loss at step 9500: 0.098076\n",
      "2023-12-02 17:14:16,546 INFO     Training average positive_sample_loss at step 9600: 0.091882\n",
      "2023-12-02 17:14:16,546 INFO     Training average negative_sample_loss at step 9600: 0.102458\n",
      "2023-12-02 17:14:16,546 INFO     Training average loss at step 9600: 0.097170\n",
      "2023-12-02 17:14:27,404 INFO     Training average positive_sample_loss at step 9700: 0.093123\n",
      "2023-12-02 17:14:27,405 INFO     Training average negative_sample_loss at step 9700: 0.102649\n",
      "2023-12-02 17:14:27,405 INFO     Training average loss at step 9700: 0.097886\n",
      "2023-12-02 17:14:39,328 INFO     Training average positive_sample_loss at step 9800: 0.094306\n",
      "2023-12-02 17:14:39,328 INFO     Training average negative_sample_loss at step 9800: 0.104741\n",
      "2023-12-02 17:14:39,328 INFO     Training average loss at step 9800: 0.099524\n",
      "2023-12-02 17:14:51,289 INFO     Training average positive_sample_loss at step 9900: 0.094958\n",
      "2023-12-02 17:14:51,290 INFO     Training average negative_sample_loss at step 9900: 0.104296\n",
      "2023-12-02 17:14:51,290 INFO     Training average loss at step 9900: 0.099627\n",
      "2023-12-02 17:15:20,777 INFO     Training average positive_sample_loss at step 10000: 0.094551\n",
      "2023-12-02 17:15:20,778 INFO     Training average negative_sample_loss at step 10000: 0.103367\n",
      "2023-12-02 17:15:20,778 INFO     Training average loss at step 10000: 0.098959\n",
      "2023-12-02 17:15:20,778 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 17:15:21,593 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 17:16:37,099 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 17:17:47,285 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 17:18:30,369 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 17:19:43,044 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 17:20:57,196 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 17:22:11,815 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 17:22:29,180 INFO     Valid MRR at step 10000: 0.730603\n",
      "2023-12-02 17:22:29,181 INFO     Valid MR at step 10000: 57.441670\n",
      "2023-12-02 17:22:29,181 INFO     Valid HITS@1 at step 10000: 0.655780\n",
      "2023-12-02 17:22:29,181 INFO     Valid HITS@3 at step 10000: 0.782300\n",
      "2023-12-02 17:22:29,181 INFO     Valid HITS@10 at step 10000: 0.854490\n",
      "2023-12-02 17:22:40,944 INFO     Training average positive_sample_loss at step 10100: 0.094725\n",
      "2023-12-02 17:22:40,944 INFO     Training average negative_sample_loss at step 10100: 0.105707\n",
      "2023-12-02 17:22:40,944 INFO     Training average loss at step 10100: 0.100216\n",
      "2023-12-02 17:22:50,468 INFO     Training average positive_sample_loss at step 10200: 0.094881\n",
      "2023-12-02 17:22:50,468 INFO     Training average negative_sample_loss at step 10200: 0.105138\n",
      "2023-12-02 17:22:50,468 INFO     Training average loss at step 10200: 0.100010\n",
      "2023-12-02 17:23:02,085 INFO     Training average positive_sample_loss at step 10300: 0.095068\n",
      "2023-12-02 17:23:02,085 INFO     Training average negative_sample_loss at step 10300: 0.106315\n",
      "2023-12-02 17:23:02,085 INFO     Training average loss at step 10300: 0.100691\n",
      "2023-12-02 17:23:14,927 INFO     Training average positive_sample_loss at step 10400: 0.092933\n",
      "2023-12-02 17:23:14,928 INFO     Training average negative_sample_loss at step 10400: 0.105387\n",
      "2023-12-02 17:23:14,928 INFO     Training average loss at step 10400: 0.099160\n",
      "2023-12-02 17:23:26,751 INFO     Training average positive_sample_loss at step 10500: 0.088416\n",
      "2023-12-02 17:23:26,751 INFO     Training average negative_sample_loss at step 10500: 0.099377\n",
      "2023-12-02 17:23:26,751 INFO     Training average loss at step 10500: 0.093897\n",
      "2023-12-02 17:23:35,986 INFO     Training average positive_sample_loss at step 10600: 0.090082\n",
      "2023-12-02 17:23:35,986 INFO     Training average negative_sample_loss at step 10600: 0.098164\n",
      "2023-12-02 17:23:35,986 INFO     Training average loss at step 10600: 0.094123\n",
      "2023-12-02 17:23:47,947 INFO     Training average positive_sample_loss at step 10700: 0.091314\n",
      "2023-12-02 17:23:47,948 INFO     Training average negative_sample_loss at step 10700: 0.101027\n",
      "2023-12-02 17:23:47,948 INFO     Training average loss at step 10700: 0.096170\n",
      "2023-12-02 17:23:59,983 INFO     Training average positive_sample_loss at step 10800: 0.092596\n",
      "2023-12-02 17:23:59,983 INFO     Training average negative_sample_loss at step 10800: 0.101294\n",
      "2023-12-02 17:23:59,983 INFO     Training average loss at step 10800: 0.096945\n",
      "2023-12-02 17:24:12,031 INFO     Training average positive_sample_loss at step 10900: 0.093610\n",
      "2023-12-02 17:24:12,031 INFO     Training average negative_sample_loss at step 10900: 0.102949\n",
      "2023-12-02 17:24:12,031 INFO     Training average loss at step 10900: 0.098280\n",
      "2023-12-02 17:24:21,296 INFO     Training average positive_sample_loss at step 11000: 0.093791\n",
      "2023-12-02 17:24:21,296 INFO     Training average negative_sample_loss at step 11000: 0.103147\n",
      "2023-12-02 17:24:21,296 INFO     Training average loss at step 11000: 0.098469\n",
      "2023-12-02 17:24:33,194 INFO     Training average positive_sample_loss at step 11100: 0.093436\n",
      "2023-12-02 17:24:33,195 INFO     Training average negative_sample_loss at step 11100: 0.102254\n",
      "2023-12-02 17:24:33,195 INFO     Training average loss at step 11100: 0.097845\n",
      "2023-12-02 17:24:45,028 INFO     Training average positive_sample_loss at step 11200: 0.093254\n",
      "2023-12-02 17:24:45,028 INFO     Training average negative_sample_loss at step 11200: 0.102151\n",
      "2023-12-02 17:24:45,028 INFO     Training average loss at step 11200: 0.097702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:24:56,898 INFO     Training average positive_sample_loss at step 11300: 0.092708\n",
      "2023-12-02 17:24:56,899 INFO     Training average negative_sample_loss at step 11300: 0.103205\n",
      "2023-12-02 17:24:56,899 INFO     Training average loss at step 11300: 0.097956\n",
      "2023-12-02 17:25:07,717 INFO     Training average positive_sample_loss at step 11400: 0.086857\n",
      "2023-12-02 17:25:07,718 INFO     Training average negative_sample_loss at step 11400: 0.100254\n",
      "2023-12-02 17:25:07,718 INFO     Training average loss at step 11400: 0.093555\n",
      "2023-12-02 17:25:19,444 INFO     Training average positive_sample_loss at step 11500: 0.088479\n",
      "2023-12-02 17:25:19,444 INFO     Training average negative_sample_loss at step 11500: 0.096667\n",
      "2023-12-02 17:25:19,444 INFO     Training average loss at step 11500: 0.092573\n",
      "2023-12-02 17:25:31,107 INFO     Training average positive_sample_loss at step 11600: 0.089258\n",
      "2023-12-02 17:25:31,107 INFO     Training average negative_sample_loss at step 11600: 0.098346\n",
      "2023-12-02 17:25:31,107 INFO     Training average loss at step 11600: 0.093802\n",
      "2023-12-02 17:25:42,687 INFO     Training average positive_sample_loss at step 11700: 0.090474\n",
      "2023-12-02 17:25:42,687 INFO     Training average negative_sample_loss at step 11700: 0.097842\n",
      "2023-12-02 17:25:42,687 INFO     Training average loss at step 11700: 0.094158\n",
      "2023-12-02 17:25:51,845 INFO     Training average positive_sample_loss at step 11800: 0.091218\n",
      "2023-12-02 17:25:51,845 INFO     Training average negative_sample_loss at step 11800: 0.099931\n",
      "2023-12-02 17:25:51,845 INFO     Training average loss at step 11800: 0.095574\n",
      "2023-12-02 17:26:03,743 INFO     Training average positive_sample_loss at step 11900: 0.091730\n",
      "2023-12-02 17:26:03,743 INFO     Training average negative_sample_loss at step 11900: 0.100728\n",
      "2023-12-02 17:26:03,743 INFO     Training average loss at step 11900: 0.096229\n",
      "2023-12-02 17:26:15,571 INFO     Training average positive_sample_loss at step 12000: 0.091305\n",
      "2023-12-02 17:26:15,571 INFO     Training average negative_sample_loss at step 12000: 0.100175\n",
      "2023-12-02 17:26:15,571 INFO     Training average loss at step 12000: 0.095740\n",
      "2023-12-02 17:26:26,974 INFO     Training average positive_sample_loss at step 12100: 0.091706\n",
      "2023-12-02 17:26:26,974 INFO     Training average negative_sample_loss at step 12100: 0.100201\n",
      "2023-12-02 17:26:26,974 INFO     Training average loss at step 12100: 0.095953\n",
      "2023-12-02 17:26:36,556 INFO     Training average positive_sample_loss at step 12200: 0.091366\n",
      "2023-12-02 17:26:36,556 INFO     Training average negative_sample_loss at step 12200: 0.100241\n",
      "2023-12-02 17:26:36,556 INFO     Training average loss at step 12200: 0.095804\n",
      "2023-12-02 17:26:49,086 INFO     Training average positive_sample_loss at step 12300: 0.088640\n",
      "2023-12-02 17:26:49,086 INFO     Training average negative_sample_loss at step 12300: 0.099698\n",
      "2023-12-02 17:26:49,086 INFO     Training average loss at step 12300: 0.094169\n",
      "2023-12-02 17:27:00,884 INFO     Training average positive_sample_loss at step 12400: 0.085902\n",
      "2023-12-02 17:27:00,885 INFO     Training average negative_sample_loss at step 12400: 0.095605\n",
      "2023-12-02 17:27:00,885 INFO     Training average loss at step 12400: 0.090753\n",
      "2023-12-02 17:27:11,114 INFO     Training average positive_sample_loss at step 12500: 0.087232\n",
      "2023-12-02 17:27:11,115 INFO     Training average negative_sample_loss at step 12500: 0.094648\n",
      "2023-12-02 17:27:11,115 INFO     Training average loss at step 12500: 0.090940\n",
      "2023-12-02 17:27:21,998 INFO     Training average positive_sample_loss at step 12600: 0.088507\n",
      "2023-12-02 17:27:21,999 INFO     Training average negative_sample_loss at step 12600: 0.096221\n",
      "2023-12-02 17:27:21,999 INFO     Training average loss at step 12600: 0.092364\n",
      "2023-12-02 17:27:33,938 INFO     Training average positive_sample_loss at step 12700: 0.089164\n",
      "2023-12-02 17:27:33,939 INFO     Training average negative_sample_loss at step 12700: 0.096910\n",
      "2023-12-02 17:27:33,939 INFO     Training average loss at step 12700: 0.093037\n",
      "2023-12-02 17:27:46,002 INFO     Training average positive_sample_loss at step 12800: 0.090296\n",
      "2023-12-02 17:27:46,002 INFO     Training average negative_sample_loss at step 12800: 0.097827\n",
      "2023-12-02 17:27:46,002 INFO     Training average loss at step 12800: 0.094062\n",
      "2023-12-02 17:27:55,466 INFO     Training average positive_sample_loss at step 12900: 0.090263\n",
      "2023-12-02 17:27:55,466 INFO     Training average negative_sample_loss at step 12900: 0.099883\n",
      "2023-12-02 17:27:55,466 INFO     Training average loss at step 12900: 0.095073\n",
      "2023-12-02 17:28:07,340 INFO     Training average positive_sample_loss at step 13000: 0.090794\n",
      "2023-12-02 17:28:07,341 INFO     Training average negative_sample_loss at step 13000: 0.098622\n",
      "2023-12-02 17:28:07,341 INFO     Training average loss at step 13000: 0.094708\n",
      "2023-12-02 17:28:19,185 INFO     Training average positive_sample_loss at step 13100: 0.090835\n",
      "2023-12-02 17:28:19,185 INFO     Training average negative_sample_loss at step 13100: 0.098460\n",
      "2023-12-02 17:28:19,185 INFO     Training average loss at step 13100: 0.094647\n",
      "2023-12-02 17:28:31,186 INFO     Training average positive_sample_loss at step 13200: 0.090087\n",
      "2023-12-02 17:28:31,186 INFO     Training average negative_sample_loss at step 13200: 0.098390\n",
      "2023-12-02 17:28:31,187 INFO     Training average loss at step 13200: 0.094239\n",
      "2023-12-02 17:28:41,189 INFO     Training average positive_sample_loss at step 13300: 0.083876\n",
      "2023-12-02 17:28:41,190 INFO     Training average negative_sample_loss at step 13300: 0.095975\n",
      "2023-12-02 17:28:41,190 INFO     Training average loss at step 13300: 0.089925\n",
      "2023-12-02 17:28:53,168 INFO     Training average positive_sample_loss at step 13400: 0.086289\n",
      "2023-12-02 17:28:53,169 INFO     Training average negative_sample_loss at step 13400: 0.094230\n",
      "2023-12-02 17:28:53,169 INFO     Training average loss at step 13400: 0.090259\n",
      "2023-12-02 17:29:05,023 INFO     Training average positive_sample_loss at step 13500: 0.087619\n",
      "2023-12-02 17:29:05,023 INFO     Training average negative_sample_loss at step 13500: 0.094583\n",
      "2023-12-02 17:29:05,023 INFO     Training average loss at step 13500: 0.091101\n",
      "2023-12-02 17:29:16,930 INFO     Training average positive_sample_loss at step 13600: 0.087964\n",
      "2023-12-02 17:29:16,930 INFO     Training average negative_sample_loss at step 13600: 0.095179\n",
      "2023-12-02 17:29:16,930 INFO     Training average loss at step 13600: 0.091572\n",
      "2023-12-02 17:29:26,190 INFO     Training average positive_sample_loss at step 13700: 0.088347\n",
      "2023-12-02 17:29:26,190 INFO     Training average negative_sample_loss at step 13700: 0.095979\n",
      "2023-12-02 17:29:26,190 INFO     Training average loss at step 13700: 0.092163\n",
      "2023-12-02 17:29:38,179 INFO     Training average positive_sample_loss at step 13800: 0.089034\n",
      "2023-12-02 17:29:38,179 INFO     Training average negative_sample_loss at step 13800: 0.096659\n",
      "2023-12-02 17:29:38,179 INFO     Training average loss at step 13800: 0.092847\n",
      "2023-12-02 17:29:50,128 INFO     Training average positive_sample_loss at step 13900: 0.089838\n",
      "2023-12-02 17:29:50,128 INFO     Training average negative_sample_loss at step 13900: 0.097822\n",
      "2023-12-02 17:29:50,128 INFO     Training average loss at step 13900: 0.093830\n",
      "2023-12-02 17:30:02,115 INFO     Training average positive_sample_loss at step 14000: 0.089059\n",
      "2023-12-02 17:30:02,115 INFO     Training average negative_sample_loss at step 14000: 0.097727\n",
      "2023-12-02 17:30:02,115 INFO     Training average loss at step 14000: 0.093393\n",
      "2023-12-02 17:30:11,299 INFO     Training average positive_sample_loss at step 14100: 0.089571\n",
      "2023-12-02 17:30:11,300 INFO     Training average negative_sample_loss at step 14100: 0.097832\n",
      "2023-12-02 17:30:11,300 INFO     Training average loss at step 14100: 0.093701\n",
      "2023-12-02 17:30:24,093 INFO     Training average positive_sample_loss at step 14200: 0.084991\n",
      "2023-12-02 17:30:24,093 INFO     Training average negative_sample_loss at step 14200: 0.094577\n",
      "2023-12-02 17:30:24,093 INFO     Training average loss at step 14200: 0.089784\n",
      "2023-12-02 17:30:36,119 INFO     Training average positive_sample_loss at step 14300: 0.083856\n",
      "2023-12-02 17:30:36,119 INFO     Training average negative_sample_loss at step 14300: 0.091116\n",
      "2023-12-02 17:30:36,119 INFO     Training average loss at step 14300: 0.087486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:30:46,870 INFO     Training average positive_sample_loss at step 14400: 0.085172\n",
      "2023-12-02 17:30:46,870 INFO     Training average negative_sample_loss at step 14400: 0.091944\n",
      "2023-12-02 17:30:46,870 INFO     Training average loss at step 14400: 0.088558\n",
      "2023-12-02 17:30:57,473 INFO     Training average positive_sample_loss at step 14500: 0.086133\n",
      "2023-12-02 17:30:57,473 INFO     Training average negative_sample_loss at step 14500: 0.093233\n",
      "2023-12-02 17:30:57,473 INFO     Training average loss at step 14500: 0.089683\n",
      "2023-12-02 17:31:09,372 INFO     Training average positive_sample_loss at step 14600: 0.087801\n",
      "2023-12-02 17:31:09,372 INFO     Training average negative_sample_loss at step 14600: 0.095090\n",
      "2023-12-02 17:31:09,372 INFO     Training average loss at step 14600: 0.091445\n",
      "2023-12-02 17:31:21,314 INFO     Training average positive_sample_loss at step 14700: 0.087596\n",
      "2023-12-02 17:31:21,314 INFO     Training average negative_sample_loss at step 14700: 0.094558\n",
      "2023-12-02 17:31:21,314 INFO     Training average loss at step 14700: 0.091077\n",
      "2023-12-02 17:31:31,235 INFO     Training average positive_sample_loss at step 14800: 0.088191\n",
      "2023-12-02 17:31:31,236 INFO     Training average negative_sample_loss at step 14800: 0.095041\n",
      "2023-12-02 17:31:31,236 INFO     Training average loss at step 14800: 0.091616\n",
      "2023-12-02 17:31:42,377 INFO     Training average positive_sample_loss at step 14900: 0.088340\n",
      "2023-12-02 17:31:42,377 INFO     Training average negative_sample_loss at step 14900: 0.096771\n",
      "2023-12-02 17:31:42,378 INFO     Training average loss at step 14900: 0.092555\n",
      "2023-12-02 17:31:54,370 INFO     Training average positive_sample_loss at step 15000: 0.088621\n",
      "2023-12-02 17:31:54,370 INFO     Training average negative_sample_loss at step 15000: 0.096016\n",
      "2023-12-02 17:31:54,371 INFO     Training average loss at step 15000: 0.092318\n",
      "2023-12-02 17:32:06,450 INFO     Training average positive_sample_loss at step 15100: 0.088067\n",
      "2023-12-02 17:32:06,450 INFO     Training average negative_sample_loss at step 15100: 0.095253\n",
      "2023-12-02 17:32:06,450 INFO     Training average loss at step 15100: 0.091660\n",
      "2023-12-02 17:32:16,477 INFO     Training average positive_sample_loss at step 15200: 0.080937\n",
      "2023-12-02 17:32:16,477 INFO     Training average negative_sample_loss at step 15200: 0.091730\n",
      "2023-12-02 17:32:16,477 INFO     Training average loss at step 15200: 0.086334\n",
      "2023-12-02 17:32:28,436 INFO     Training average positive_sample_loss at step 15300: 0.084403\n",
      "2023-12-02 17:32:28,436 INFO     Training average negative_sample_loss at step 15300: 0.091414\n",
      "2023-12-02 17:32:28,436 INFO     Training average loss at step 15300: 0.087908\n",
      "2023-12-02 17:32:40,365 INFO     Training average positive_sample_loss at step 15400: 0.085581\n",
      "2023-12-02 17:32:40,365 INFO     Training average negative_sample_loss at step 15400: 0.091519\n",
      "2023-12-02 17:32:40,365 INFO     Training average loss at step 15400: 0.088550\n",
      "2023-12-02 17:32:52,415 INFO     Training average positive_sample_loss at step 15500: 0.086863\n",
      "2023-12-02 17:32:52,415 INFO     Training average negative_sample_loss at step 15500: 0.093347\n",
      "2023-12-02 17:32:52,415 INFO     Training average loss at step 15500: 0.090105\n",
      "2023-12-02 17:33:01,674 INFO     Training average positive_sample_loss at step 15600: 0.087092\n",
      "2023-12-02 17:33:01,674 INFO     Training average negative_sample_loss at step 15600: 0.094825\n",
      "2023-12-02 17:33:01,674 INFO     Training average loss at step 15600: 0.090959\n",
      "2023-12-02 17:33:13,538 INFO     Training average positive_sample_loss at step 15700: 0.087131\n",
      "2023-12-02 17:33:13,539 INFO     Training average negative_sample_loss at step 15700: 0.094837\n",
      "2023-12-02 17:33:13,539 INFO     Training average loss at step 15700: 0.090984\n",
      "2023-12-02 17:33:25,396 INFO     Training average positive_sample_loss at step 15800: 0.087161\n",
      "2023-12-02 17:33:25,397 INFO     Training average negative_sample_loss at step 15800: 0.094150\n",
      "2023-12-02 17:33:25,397 INFO     Training average loss at step 15800: 0.090656\n",
      "2023-12-02 17:33:37,325 INFO     Training average positive_sample_loss at step 15900: 0.086866\n",
      "2023-12-02 17:33:37,326 INFO     Training average negative_sample_loss at step 15900: 0.094489\n",
      "2023-12-02 17:33:37,326 INFO     Training average loss at step 15900: 0.090678\n",
      "2023-12-02 17:33:46,523 INFO     Training average positive_sample_loss at step 16000: 0.087461\n",
      "2023-12-02 17:33:46,523 INFO     Training average negative_sample_loss at step 16000: 0.094289\n",
      "2023-12-02 17:33:46,523 INFO     Training average loss at step 16000: 0.090875\n",
      "2023-12-02 17:33:59,337 INFO     Training average positive_sample_loss at step 16100: 0.082410\n",
      "2023-12-02 17:33:59,337 INFO     Training average negative_sample_loss at step 16100: 0.092602\n",
      "2023-12-02 17:33:59,337 INFO     Training average loss at step 16100: 0.087506\n",
      "2023-12-02 17:34:11,329 INFO     Training average positive_sample_loss at step 16200: 0.082461\n",
      "2023-12-02 17:34:11,330 INFO     Training average negative_sample_loss at step 16200: 0.088489\n",
      "2023-12-02 17:34:11,330 INFO     Training average loss at step 16200: 0.085475\n",
      "2023-12-02 17:34:22,651 INFO     Training average positive_sample_loss at step 16300: 0.084200\n",
      "2023-12-02 17:34:22,651 INFO     Training average negative_sample_loss at step 16300: 0.089942\n",
      "2023-12-02 17:34:22,651 INFO     Training average loss at step 16300: 0.087071\n",
      "2023-12-02 17:34:32,568 INFO     Training average positive_sample_loss at step 16400: 0.084592\n",
      "2023-12-02 17:34:32,569 INFO     Training average negative_sample_loss at step 16400: 0.090411\n",
      "2023-12-02 17:34:32,569 INFO     Training average loss at step 16400: 0.087502\n",
      "2023-12-02 17:34:44,500 INFO     Training average positive_sample_loss at step 16500: 0.085762\n",
      "2023-12-02 17:34:44,500 INFO     Training average negative_sample_loss at step 16500: 0.092170\n",
      "2023-12-02 17:34:44,500 INFO     Training average loss at step 16500: 0.088966\n",
      "2023-12-02 17:34:56,507 INFO     Training average positive_sample_loss at step 16600: 0.086336\n",
      "2023-12-02 17:34:56,508 INFO     Training average negative_sample_loss at step 16600: 0.092559\n",
      "2023-12-02 17:34:56,508 INFO     Training average loss at step 16600: 0.089448\n",
      "2023-12-02 17:35:07,014 INFO     Training average positive_sample_loss at step 16700: 0.086245\n",
      "2023-12-02 17:35:07,015 INFO     Training average negative_sample_loss at step 16700: 0.093571\n",
      "2023-12-02 17:35:07,015 INFO     Training average loss at step 16700: 0.089908\n",
      "2023-12-02 17:35:17,750 INFO     Training average positive_sample_loss at step 16800: 0.086911\n",
      "2023-12-02 17:35:17,750 INFO     Training average negative_sample_loss at step 16800: 0.092896\n",
      "2023-12-02 17:35:17,751 INFO     Training average loss at step 16800: 0.089904\n",
      "2023-12-02 17:35:29,853 INFO     Training average positive_sample_loss at step 16900: 0.086428\n",
      "2023-12-02 17:35:29,853 INFO     Training average negative_sample_loss at step 16900: 0.092356\n",
      "2023-12-02 17:35:29,853 INFO     Training average loss at step 16900: 0.089392\n",
      "2023-12-02 17:35:42,703 INFO     Training average positive_sample_loss at step 17000: 0.084813\n",
      "2023-12-02 17:35:42,703 INFO     Training average negative_sample_loss at step 17000: 0.092141\n",
      "2023-12-02 17:35:42,703 INFO     Training average loss at step 17000: 0.088477\n",
      "2023-12-02 17:35:51,989 INFO     Training average positive_sample_loss at step 17100: 0.080150\n",
      "2023-12-02 17:35:51,990 INFO     Training average negative_sample_loss at step 17100: 0.088728\n",
      "2023-12-02 17:35:51,990 INFO     Training average loss at step 17100: 0.084439\n",
      "2023-12-02 17:36:03,948 INFO     Training average positive_sample_loss at step 17200: 0.083052\n",
      "2023-12-02 17:36:03,948 INFO     Training average negative_sample_loss at step 17200: 0.088385\n",
      "2023-12-02 17:36:03,948 INFO     Training average loss at step 17200: 0.085719\n",
      "2023-12-02 17:36:15,885 INFO     Training average positive_sample_loss at step 17300: 0.084381\n",
      "2023-12-02 17:36:15,886 INFO     Training average negative_sample_loss at step 17300: 0.090086\n",
      "2023-12-02 17:36:15,886 INFO     Training average loss at step 17300: 0.087234\n",
      "2023-12-02 17:36:27,757 INFO     Training average positive_sample_loss at step 17400: 0.084560\n",
      "2023-12-02 17:36:27,757 INFO     Training average negative_sample_loss at step 17400: 0.091368\n",
      "2023-12-02 17:36:27,757 INFO     Training average loss at step 17400: 0.087964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:36:36,995 INFO     Training average positive_sample_loss at step 17500: 0.085941\n",
      "2023-12-02 17:36:36,996 INFO     Training average negative_sample_loss at step 17500: 0.092857\n",
      "2023-12-02 17:36:36,996 INFO     Training average loss at step 17500: 0.089399\n",
      "2023-12-02 17:36:49,064 INFO     Training average positive_sample_loss at step 17600: 0.085375\n",
      "2023-12-02 17:36:49,064 INFO     Training average negative_sample_loss at step 17600: 0.091192\n",
      "2023-12-02 17:36:49,064 INFO     Training average loss at step 17600: 0.088284\n",
      "2023-12-02 17:37:00,998 INFO     Training average positive_sample_loss at step 17700: 0.085999\n",
      "2023-12-02 17:37:00,999 INFO     Training average negative_sample_loss at step 17700: 0.092208\n",
      "2023-12-02 17:37:00,999 INFO     Training average loss at step 17700: 0.089104\n",
      "2023-12-02 17:37:12,736 INFO     Training average positive_sample_loss at step 17800: 0.085722\n",
      "2023-12-02 17:37:12,737 INFO     Training average negative_sample_loss at step 17800: 0.091826\n",
      "2023-12-02 17:37:12,737 INFO     Training average loss at step 17800: 0.088774\n",
      "2023-12-02 17:37:21,887 INFO     Training average positive_sample_loss at step 17900: 0.085691\n",
      "2023-12-02 17:37:21,887 INFO     Training average negative_sample_loss at step 17900: 0.092033\n",
      "2023-12-02 17:37:21,887 INFO     Training average loss at step 17900: 0.088862\n",
      "2023-12-02 17:37:34,667 INFO     Training average positive_sample_loss at step 18000: 0.080273\n",
      "2023-12-02 17:37:34,667 INFO     Training average negative_sample_loss at step 18000: 0.089248\n",
      "2023-12-02 17:37:34,667 INFO     Training average loss at step 18000: 0.084761\n",
      "2023-12-02 17:37:46,646 INFO     Training average positive_sample_loss at step 18100: 0.080755\n",
      "2023-12-02 17:37:46,646 INFO     Training average negative_sample_loss at step 18100: 0.086129\n",
      "2023-12-02 17:37:46,646 INFO     Training average loss at step 18100: 0.083442\n",
      "2023-12-02 17:37:58,480 INFO     Training average positive_sample_loss at step 18200: 0.082389\n",
      "2023-12-02 17:37:58,481 INFO     Training average negative_sample_loss at step 18200: 0.089133\n",
      "2023-12-02 17:37:58,481 INFO     Training average loss at step 18200: 0.085761\n",
      "2023-12-02 17:38:07,764 INFO     Training average positive_sample_loss at step 18300: 0.084141\n",
      "2023-12-02 17:38:07,765 INFO     Training average negative_sample_loss at step 18300: 0.089222\n",
      "2023-12-02 17:38:07,765 INFO     Training average loss at step 18300: 0.086682\n",
      "2023-12-02 17:38:16,495 INFO     Training average positive_sample_loss at step 18400: 0.084770\n",
      "2023-12-02 17:38:16,495 INFO     Training average negative_sample_loss at step 18400: 0.091140\n",
      "2023-12-02 17:38:16,495 INFO     Training average loss at step 18400: 0.087955\n",
      "2023-12-02 17:38:24,984 INFO     Training average positive_sample_loss at step 18500: 0.085352\n",
      "2023-12-02 17:38:24,984 INFO     Training average negative_sample_loss at step 18500: 0.090533\n",
      "2023-12-02 17:38:24,984 INFO     Training average loss at step 18500: 0.087943\n",
      "2023-12-02 17:38:33,253 INFO     Training average positive_sample_loss at step 18600: 0.085052\n",
      "2023-12-02 17:38:33,253 INFO     Training average negative_sample_loss at step 18600: 0.090773\n",
      "2023-12-02 17:38:33,253 INFO     Training average loss at step 18600: 0.087913\n",
      "2023-12-02 17:38:41,683 INFO     Training average positive_sample_loss at step 18700: 0.085560\n",
      "2023-12-02 17:38:41,683 INFO     Training average negative_sample_loss at step 18700: 0.091580\n",
      "2023-12-02 17:38:41,683 INFO     Training average loss at step 18700: 0.088570\n",
      "2023-12-02 17:38:50,339 INFO     Training average positive_sample_loss at step 18800: 0.084940\n",
      "2023-12-02 17:38:50,339 INFO     Training average negative_sample_loss at step 18800: 0.090763\n",
      "2023-12-02 17:38:50,339 INFO     Training average loss at step 18800: 0.087851\n",
      "2023-12-02 17:38:59,593 INFO     Training average positive_sample_loss at step 18900: 0.082451\n",
      "2023-12-02 17:38:59,594 INFO     Training average negative_sample_loss at step 18900: 0.090768\n",
      "2023-12-02 17:38:59,594 INFO     Training average loss at step 18900: 0.086609\n",
      "2023-12-02 17:39:11,365 INFO     Training average positive_sample_loss at step 19000: 0.079928\n",
      "2023-12-02 17:39:11,366 INFO     Training average negative_sample_loss at step 19000: 0.085950\n",
      "2023-12-02 17:39:11,366 INFO     Training average loss at step 19000: 0.082939\n",
      "2023-12-02 17:39:23,260 INFO     Training average positive_sample_loss at step 19100: 0.081646\n",
      "2023-12-02 17:39:23,260 INFO     Training average negative_sample_loss at step 19100: 0.087897\n",
      "2023-12-02 17:39:23,260 INFO     Training average loss at step 19100: 0.084772\n",
      "2023-12-02 17:39:33,131 INFO     Training average positive_sample_loss at step 19200: 0.083444\n",
      "2023-12-02 17:39:33,131 INFO     Training average negative_sample_loss at step 19200: 0.089331\n",
      "2023-12-02 17:39:33,132 INFO     Training average loss at step 19200: 0.086387\n",
      "2023-12-02 17:39:44,354 INFO     Training average positive_sample_loss at step 19300: 0.083584\n",
      "2023-12-02 17:39:44,355 INFO     Training average negative_sample_loss at step 19300: 0.088114\n",
      "2023-12-02 17:39:44,355 INFO     Training average loss at step 19300: 0.085849\n",
      "2023-12-02 17:39:56,244 INFO     Training average positive_sample_loss at step 19400: 0.084029\n",
      "2023-12-02 17:39:56,244 INFO     Training average negative_sample_loss at step 19400: 0.089109\n",
      "2023-12-02 17:39:56,244 INFO     Training average loss at step 19400: 0.086569\n",
      "2023-12-02 17:40:08,080 INFO     Training average positive_sample_loss at step 19500: 0.083511\n",
      "2023-12-02 17:40:08,080 INFO     Training average negative_sample_loss at step 19500: 0.089965\n",
      "2023-12-02 17:40:08,080 INFO     Training average loss at step 19500: 0.086738\n",
      "2023-12-02 17:40:17,385 INFO     Training average positive_sample_loss at step 19600: 0.084885\n",
      "2023-12-02 17:40:17,386 INFO     Training average negative_sample_loss at step 19600: 0.090372\n",
      "2023-12-02 17:40:17,386 INFO     Training average loss at step 19600: 0.087628\n",
      "2023-12-02 17:40:28,952 INFO     Training average positive_sample_loss at step 19700: 0.085210\n",
      "2023-12-02 17:40:28,952 INFO     Training average negative_sample_loss at step 19700: 0.091320\n",
      "2023-12-02 17:40:28,952 INFO     Training average loss at step 19700: 0.088265\n",
      "2023-12-02 17:40:40,643 INFO     Training average positive_sample_loss at step 19800: 0.085267\n",
      "2023-12-02 17:40:40,643 INFO     Training average negative_sample_loss at step 19800: 0.091359\n",
      "2023-12-02 17:40:40,643 INFO     Training average loss at step 19800: 0.088313\n",
      "2023-12-02 17:40:53,122 INFO     Training average positive_sample_loss at step 19900: 0.078769\n",
      "2023-12-02 17:40:53,122 INFO     Training average negative_sample_loss at step 19900: 0.086773\n",
      "2023-12-02 17:40:53,122 INFO     Training average loss at step 19900: 0.082771\n",
      "2023-12-02 17:41:17,734 INFO     Training average positive_sample_loss at step 20000: 0.080666\n",
      "2023-12-02 17:41:17,734 INFO     Training average negative_sample_loss at step 20000: 0.086170\n",
      "2023-12-02 17:41:17,734 INFO     Training average loss at step 20000: 0.083418\n",
      "2023-12-02 17:41:17,734 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 17:41:18,508 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 17:42:36,592 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 17:43:47,222 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 17:45:03,646 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 17:46:17,999 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 17:47:34,439 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 17:48:52,271 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 17:49:08,734 INFO     Valid MRR at step 20000: 0.741744\n",
      "2023-12-02 17:49:08,734 INFO     Valid MR at step 20000: 50.720860\n",
      "2023-12-02 17:49:08,734 INFO     Valid HITS@1 at step 20000: 0.674050\n",
      "2023-12-02 17:49:08,734 INFO     Valid HITS@3 at step 20000: 0.785850\n",
      "2023-12-02 17:49:08,734 INFO     Valid HITS@10 at step 20000: 0.858190\n",
      "2023-12-02 17:49:20,520 INFO     Training average positive_sample_loss at step 20100: 0.081682\n",
      "2023-12-02 17:49:20,520 INFO     Training average negative_sample_loss at step 20100: 0.086694\n",
      "2023-12-02 17:49:20,521 INFO     Training average loss at step 20100: 0.084188\n",
      "2023-12-02 17:49:32,437 INFO     Training average positive_sample_loss at step 20200: 0.082428\n",
      "2023-12-02 17:49:32,438 INFO     Training average negative_sample_loss at step 20200: 0.087425\n",
      "2023-12-02 17:49:32,438 INFO     Training average loss at step 20200: 0.084927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:49:41,601 INFO     Training average positive_sample_loss at step 20300: 0.083049\n",
      "2023-12-02 17:49:41,601 INFO     Training average negative_sample_loss at step 20300: 0.088761\n",
      "2023-12-02 17:49:41,601 INFO     Training average loss at step 20300: 0.085905\n",
      "2023-12-02 17:49:53,437 INFO     Training average positive_sample_loss at step 20400: 0.083922\n",
      "2023-12-02 17:49:53,438 INFO     Training average negative_sample_loss at step 20400: 0.088999\n",
      "2023-12-02 17:49:53,438 INFO     Training average loss at step 20400: 0.086460\n",
      "2023-12-02 17:50:05,232 INFO     Training average positive_sample_loss at step 20500: 0.084905\n",
      "2023-12-02 17:50:05,232 INFO     Training average negative_sample_loss at step 20500: 0.090481\n",
      "2023-12-02 17:50:05,232 INFO     Training average loss at step 20500: 0.087693\n",
      "2023-12-02 17:50:17,205 INFO     Training average positive_sample_loss at step 20600: 0.084199\n",
      "2023-12-02 17:50:17,206 INFO     Training average negative_sample_loss at step 20600: 0.089601\n",
      "2023-12-02 17:50:17,206 INFO     Training average loss at step 20600: 0.086900\n",
      "2023-12-02 17:50:26,466 INFO     Training average positive_sample_loss at step 20700: 0.084599\n",
      "2023-12-02 17:50:26,466 INFO     Training average negative_sample_loss at step 20700: 0.090947\n",
      "2023-12-02 17:50:26,466 INFO     Training average loss at step 20700: 0.087773\n",
      "2023-12-02 17:50:39,112 INFO     Training average positive_sample_loss at step 20800: 0.081265\n",
      "2023-12-02 17:50:39,113 INFO     Training average negative_sample_loss at step 20800: 0.089139\n",
      "2023-12-02 17:50:39,113 INFO     Training average loss at step 20800: 0.085202\n",
      "2023-12-02 17:50:51,097 INFO     Training average positive_sample_loss at step 20900: 0.078620\n",
      "2023-12-02 17:50:51,098 INFO     Training average negative_sample_loss at step 20900: 0.084282\n",
      "2023-12-02 17:50:51,098 INFO     Training average loss at step 20900: 0.081451\n",
      "2023-12-02 17:51:01,800 INFO     Training average positive_sample_loss at step 21000: 0.080894\n",
      "2023-12-02 17:51:01,800 INFO     Training average negative_sample_loss at step 21000: 0.085664\n",
      "2023-12-02 17:51:01,800 INFO     Training average loss at step 21000: 0.083279\n",
      "2023-12-02 17:51:12,315 INFO     Training average positive_sample_loss at step 21100: 0.081893\n",
      "2023-12-02 17:51:12,316 INFO     Training average negative_sample_loss at step 21100: 0.087408\n",
      "2023-12-02 17:51:12,316 INFO     Training average loss at step 21100: 0.084650\n",
      "2023-12-02 17:51:24,083 INFO     Training average positive_sample_loss at step 21200: 0.083382\n",
      "2023-12-02 17:51:24,083 INFO     Training average negative_sample_loss at step 21200: 0.087935\n",
      "2023-12-02 17:51:24,083 INFO     Training average loss at step 21200: 0.085659\n",
      "2023-12-02 17:51:36,017 INFO     Training average positive_sample_loss at step 21300: 0.083574\n",
      "2023-12-02 17:51:36,018 INFO     Training average negative_sample_loss at step 21300: 0.088175\n",
      "2023-12-02 17:51:36,018 INFO     Training average loss at step 21300: 0.085874\n",
      "2023-12-02 17:51:46,170 INFO     Training average positive_sample_loss at step 21400: 0.083407\n",
      "2023-12-02 17:51:46,170 INFO     Training average negative_sample_loss at step 21400: 0.088295\n",
      "2023-12-02 17:51:46,170 INFO     Training average loss at step 21400: 0.085851\n",
      "2023-12-02 17:51:57,041 INFO     Training average positive_sample_loss at step 21500: 0.083731\n",
      "2023-12-02 17:51:57,041 INFO     Training average negative_sample_loss at step 21500: 0.088824\n",
      "2023-12-02 17:51:57,041 INFO     Training average loss at step 21500: 0.086277\n",
      "2023-12-02 17:52:08,921 INFO     Training average positive_sample_loss at step 21600: 0.083577\n",
      "2023-12-02 17:52:08,922 INFO     Training average negative_sample_loss at step 21600: 0.088706\n",
      "2023-12-02 17:52:08,922 INFO     Training average loss at step 21600: 0.086142\n",
      "2023-12-02 17:52:20,783 INFO     Training average positive_sample_loss at step 21700: 0.083598\n",
      "2023-12-02 17:52:20,783 INFO     Training average negative_sample_loss at step 21700: 0.090177\n",
      "2023-12-02 17:52:20,783 INFO     Training average loss at step 21700: 0.086888\n",
      "2023-12-02 17:52:30,636 INFO     Training average positive_sample_loss at step 21800: 0.077765\n",
      "2023-12-02 17:52:30,637 INFO     Training average negative_sample_loss at step 21800: 0.085149\n",
      "2023-12-02 17:52:30,637 INFO     Training average loss at step 21800: 0.081457\n",
      "2023-12-02 17:52:42,600 INFO     Training average positive_sample_loss at step 21900: 0.080637\n",
      "2023-12-02 17:52:42,600 INFO     Training average negative_sample_loss at step 21900: 0.085212\n",
      "2023-12-02 17:52:42,600 INFO     Training average loss at step 21900: 0.082924\n",
      "2023-12-02 17:52:54,538 INFO     Training average positive_sample_loss at step 22000: 0.080912\n",
      "2023-12-02 17:52:54,538 INFO     Training average negative_sample_loss at step 22000: 0.085884\n",
      "2023-12-02 17:52:54,538 INFO     Training average loss at step 22000: 0.083398\n",
      "2023-12-02 17:53:06,562 INFO     Training average positive_sample_loss at step 22100: 0.081779\n",
      "2023-12-02 17:53:06,563 INFO     Training average negative_sample_loss at step 22100: 0.085669\n",
      "2023-12-02 17:53:06,563 INFO     Training average loss at step 22100: 0.083724\n",
      "2023-12-02 17:53:15,757 INFO     Training average positive_sample_loss at step 22200: 0.082457\n",
      "2023-12-02 17:53:15,757 INFO     Training average negative_sample_loss at step 22200: 0.086252\n",
      "2023-12-02 17:53:15,757 INFO     Training average loss at step 22200: 0.084355\n",
      "2023-12-02 17:53:27,746 INFO     Training average positive_sample_loss at step 22300: 0.082508\n",
      "2023-12-02 17:53:27,746 INFO     Training average negative_sample_loss at step 22300: 0.087423\n",
      "2023-12-02 17:53:27,746 INFO     Training average loss at step 22300: 0.084965\n",
      "2023-12-02 17:53:39,636 INFO     Training average positive_sample_loss at step 22400: 0.083224\n",
      "2023-12-02 17:53:39,637 INFO     Training average negative_sample_loss at step 22400: 0.088330\n",
      "2023-12-02 17:53:39,637 INFO     Training average loss at step 22400: 0.085777\n",
      "2023-12-02 17:53:51,563 INFO     Training average positive_sample_loss at step 22500: 0.082779\n",
      "2023-12-02 17:53:51,563 INFO     Training average negative_sample_loss at step 22500: 0.088508\n",
      "2023-12-02 17:53:51,563 INFO     Training average loss at step 22500: 0.085643\n",
      "2023-12-02 17:54:00,810 INFO     Training average positive_sample_loss at step 22600: 0.082900\n",
      "2023-12-02 17:54:00,811 INFO     Training average negative_sample_loss at step 22600: 0.088711\n",
      "2023-12-02 17:54:00,811 INFO     Training average loss at step 22600: 0.085806\n",
      "2023-12-02 17:54:13,466 INFO     Training average positive_sample_loss at step 22700: 0.079411\n",
      "2023-12-02 17:54:13,466 INFO     Training average negative_sample_loss at step 22700: 0.087477\n",
      "2023-12-02 17:54:13,466 INFO     Training average loss at step 22700: 0.083444\n",
      "2023-12-02 17:54:25,251 INFO     Training average positive_sample_loss at step 22800: 0.079169\n",
      "2023-12-02 17:54:25,251 INFO     Training average negative_sample_loss at step 22800: 0.083954\n",
      "2023-12-02 17:54:25,251 INFO     Training average loss at step 22800: 0.081562\n",
      "2023-12-02 17:54:37,066 INFO     Training average positive_sample_loss at step 22900: 0.080650\n",
      "2023-12-02 17:54:37,066 INFO     Training average negative_sample_loss at step 22900: 0.084770\n",
      "2023-12-02 17:54:37,066 INFO     Training average loss at step 22900: 0.082710\n",
      "2023-12-02 17:54:46,407 INFO     Training average positive_sample_loss at step 23000: 0.081038\n",
      "2023-12-02 17:54:46,407 INFO     Training average negative_sample_loss at step 23000: 0.085473\n",
      "2023-12-02 17:54:46,407 INFO     Training average loss at step 23000: 0.083255\n",
      "2023-12-02 17:54:58,412 INFO     Training average positive_sample_loss at step 23100: 0.081627\n",
      "2023-12-02 17:54:58,412 INFO     Training average negative_sample_loss at step 23100: 0.085800\n",
      "2023-12-02 17:54:58,412 INFO     Training average loss at step 23100: 0.083713\n",
      "2023-12-02 17:55:10,480 INFO     Training average positive_sample_loss at step 23200: 0.081975\n",
      "2023-12-02 17:55:10,480 INFO     Training average negative_sample_loss at step 23200: 0.086038\n",
      "2023-12-02 17:55:10,480 INFO     Training average loss at step 23200: 0.084006\n",
      "2023-12-02 17:55:21,953 INFO     Training average positive_sample_loss at step 23300: 0.082629\n",
      "2023-12-02 17:55:21,954 INFO     Training average negative_sample_loss at step 23300: 0.086634\n",
      "2023-12-02 17:55:21,954 INFO     Training average loss at step 23300: 0.084632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 17:55:31,593 INFO     Training average positive_sample_loss at step 23400: 0.082661\n",
      "2023-12-02 17:55:31,593 INFO     Training average negative_sample_loss at step 23400: 0.088433\n",
      "2023-12-02 17:55:31,593 INFO     Training average loss at step 23400: 0.085547\n",
      "2023-12-02 17:55:43,476 INFO     Training average positive_sample_loss at step 23500: 0.083098\n",
      "2023-12-02 17:55:43,476 INFO     Training average negative_sample_loss at step 23500: 0.087387\n",
      "2023-12-02 17:55:43,476 INFO     Training average loss at step 23500: 0.085242\n",
      "2023-12-02 17:55:55,871 INFO     Training average positive_sample_loss at step 23600: 0.082557\n",
      "2023-12-02 17:55:55,872 INFO     Training average negative_sample_loss at step 23600: 0.087974\n",
      "2023-12-02 17:55:55,872 INFO     Training average loss at step 23600: 0.085265\n",
      "2023-12-02 17:56:06,107 INFO     Training average positive_sample_loss at step 23700: 0.076549\n",
      "2023-12-02 17:56:06,108 INFO     Training average negative_sample_loss at step 23700: 0.083836\n",
      "2023-12-02 17:56:06,108 INFO     Training average loss at step 23700: 0.080193\n",
      "2023-12-02 17:56:17,198 INFO     Training average positive_sample_loss at step 23800: 0.079628\n",
      "2023-12-02 17:56:17,198 INFO     Training average negative_sample_loss at step 23800: 0.084136\n",
      "2023-12-02 17:56:17,198 INFO     Training average loss at step 23800: 0.081882\n",
      "2023-12-02 17:56:29,034 INFO     Training average positive_sample_loss at step 23900: 0.080274\n",
      "2023-12-02 17:56:29,035 INFO     Training average negative_sample_loss at step 23900: 0.084753\n",
      "2023-12-02 17:56:29,035 INFO     Training average loss at step 23900: 0.082514\n",
      "2023-12-02 17:56:40,925 INFO     Training average positive_sample_loss at step 24000: 0.081433\n",
      "2023-12-02 17:56:40,925 INFO     Training average negative_sample_loss at step 24000: 0.084913\n",
      "2023-12-02 17:56:40,925 INFO     Training average loss at step 24000: 0.083173\n",
      "2023-12-02 17:56:50,384 INFO     Training average positive_sample_loss at step 24100: 0.082130\n",
      "2023-12-02 17:56:50,385 INFO     Training average negative_sample_loss at step 24100: 0.086681\n",
      "2023-12-02 17:56:50,385 INFO     Training average loss at step 24100: 0.084406\n",
      "2023-12-02 17:57:01,985 INFO     Training average positive_sample_loss at step 24200: 0.083008\n",
      "2023-12-02 17:57:01,985 INFO     Training average negative_sample_loss at step 24200: 0.087843\n",
      "2023-12-02 17:57:01,985 INFO     Training average loss at step 24200: 0.085426\n",
      "2023-12-02 17:57:13,858 INFO     Training average positive_sample_loss at step 24300: 0.082526\n",
      "2023-12-02 17:57:13,858 INFO     Training average negative_sample_loss at step 24300: 0.087570\n",
      "2023-12-02 17:57:13,858 INFO     Training average loss at step 24300: 0.085048\n",
      "2023-12-02 17:57:21,911 INFO     Training average positive_sample_loss at step 24400: 0.082349\n",
      "2023-12-02 17:57:21,912 INFO     Training average negative_sample_loss at step 24400: 0.087201\n",
      "2023-12-02 17:57:21,912 INFO     Training average loss at step 24400: 0.084775\n",
      "2023-12-02 17:57:28,087 INFO     Training average positive_sample_loss at step 24500: 0.082579\n",
      "2023-12-02 17:57:28,087 INFO     Training average negative_sample_loss at step 24500: 0.087191\n",
      "2023-12-02 17:57:28,087 INFO     Training average loss at step 24500: 0.084885\n",
      "2023-12-02 17:57:37,930 INFO     Training average positive_sample_loss at step 24600: 0.078386\n",
      "2023-12-02 17:57:37,931 INFO     Training average negative_sample_loss at step 24600: 0.086335\n",
      "2023-12-02 17:57:37,931 INFO     Training average loss at step 24600: 0.082360\n",
      "2023-12-02 17:57:46,729 INFO     Training average positive_sample_loss at step 24700: 0.078766\n",
      "2023-12-02 17:57:46,730 INFO     Training average negative_sample_loss at step 24700: 0.083314\n",
      "2023-12-02 17:57:46,730 INFO     Training average loss at step 24700: 0.081040\n",
      "2023-12-02 17:57:55,379 INFO     Training average positive_sample_loss at step 24800: 0.079524\n",
      "2023-12-02 17:57:55,379 INFO     Training average negative_sample_loss at step 24800: 0.084137\n",
      "2023-12-02 17:57:55,379 INFO     Training average loss at step 24800: 0.081831\n",
      "2023-12-02 17:58:04,503 INFO     Training average positive_sample_loss at step 24900: 0.080597\n",
      "2023-12-02 17:58:04,504 INFO     Training average negative_sample_loss at step 24900: 0.084377\n",
      "2023-12-02 17:58:04,504 INFO     Training average loss at step 24900: 0.082487\n",
      "2023-12-02 17:58:15,942 INFO     Training average positive_sample_loss at step 25000: 0.081151\n",
      "2023-12-02 17:58:15,943 INFO     Training average negative_sample_loss at step 25000: 0.085343\n",
      "2023-12-02 17:58:15,943 INFO     Training average loss at step 25000: 0.083247\n",
      "2023-12-02 17:58:25,088 INFO     Training average positive_sample_loss at step 25100: 0.081250\n",
      "2023-12-02 17:58:25,088 INFO     Training average negative_sample_loss at step 25100: 0.085327\n",
      "2023-12-02 17:58:25,089 INFO     Training average loss at step 25100: 0.083288\n",
      "2023-12-02 17:58:36,976 INFO     Training average positive_sample_loss at step 25200: 0.081852\n",
      "2023-12-02 17:58:36,976 INFO     Training average negative_sample_loss at step 25200: 0.086394\n",
      "2023-12-02 17:58:36,976 INFO     Training average loss at step 25200: 0.084123\n",
      "2023-12-02 17:58:48,843 INFO     Training average positive_sample_loss at step 25300: 0.082799\n",
      "2023-12-02 17:58:48,843 INFO     Training average negative_sample_loss at step 25300: 0.087218\n",
      "2023-12-02 17:58:48,843 INFO     Training average loss at step 25300: 0.085009\n",
      "2023-12-02 17:59:00,674 INFO     Training average positive_sample_loss at step 25400: 0.081951\n",
      "2023-12-02 17:59:00,674 INFO     Training average negative_sample_loss at step 25400: 0.086449\n",
      "2023-12-02 17:59:00,674 INFO     Training average loss at step 25400: 0.084200\n",
      "2023-12-02 17:59:10,798 INFO     Training average positive_sample_loss at step 25500: 0.080373\n",
      "2023-12-02 17:59:10,798 INFO     Training average negative_sample_loss at step 25500: 0.086526\n",
      "2023-12-02 17:59:10,798 INFO     Training average loss at step 25500: 0.083449\n",
      "2023-12-02 17:59:22,725 INFO     Training average positive_sample_loss at step 25600: 0.076428\n",
      "2023-12-02 17:59:22,725 INFO     Training average negative_sample_loss at step 25600: 0.082790\n",
      "2023-12-02 17:59:22,725 INFO     Training average loss at step 25600: 0.079609\n",
      "2023-12-02 17:59:34,626 INFO     Training average positive_sample_loss at step 25700: 0.079193\n",
      "2023-12-02 17:59:34,626 INFO     Training average negative_sample_loss at step 25700: 0.082584\n",
      "2023-12-02 17:59:34,626 INFO     Training average loss at step 25700: 0.080888\n",
      "2023-12-02 17:59:46,484 INFO     Training average positive_sample_loss at step 25800: 0.079790\n",
      "2023-12-02 17:59:46,484 INFO     Training average negative_sample_loss at step 25800: 0.082682\n",
      "2023-12-02 17:59:46,484 INFO     Training average loss at step 25800: 0.081236\n",
      "2023-12-02 17:59:55,809 INFO     Training average positive_sample_loss at step 25900: 0.080319\n",
      "2023-12-02 17:59:55,809 INFO     Training average negative_sample_loss at step 25900: 0.084535\n",
      "2023-12-02 17:59:55,809 INFO     Training average loss at step 25900: 0.082427\n",
      "2023-12-02 18:00:07,726 INFO     Training average positive_sample_loss at step 26000: 0.080796\n",
      "2023-12-02 18:00:07,726 INFO     Training average negative_sample_loss at step 26000: 0.083958\n",
      "2023-12-02 18:00:07,726 INFO     Training average loss at step 26000: 0.082377\n",
      "2023-12-02 18:00:19,786 INFO     Training average positive_sample_loss at step 26100: 0.081267\n",
      "2023-12-02 18:00:19,786 INFO     Training average negative_sample_loss at step 26100: 0.086424\n",
      "2023-12-02 18:00:19,786 INFO     Training average loss at step 26100: 0.083846\n",
      "2023-12-02 18:00:31,174 INFO     Training average positive_sample_loss at step 26200: 0.081918\n",
      "2023-12-02 18:00:31,174 INFO     Training average negative_sample_loss at step 26200: 0.084687\n",
      "2023-12-02 18:00:31,174 INFO     Training average loss at step 26200: 0.083302\n",
      "2023-12-02 18:00:41,010 INFO     Training average positive_sample_loss at step 26300: 0.080743\n",
      "2023-12-02 18:00:41,010 INFO     Training average negative_sample_loss at step 26300: 0.086005\n",
      "2023-12-02 18:00:41,010 INFO     Training average loss at step 26300: 0.083374\n",
      "2023-12-02 18:00:53,053 INFO     Training average positive_sample_loss at step 26400: 0.081444\n",
      "2023-12-02 18:00:53,053 INFO     Training average negative_sample_loss at step 26400: 0.086528\n",
      "2023-12-02 18:00:53,053 INFO     Training average loss at step 26400: 0.083986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 18:01:05,868 INFO     Training average positive_sample_loss at step 26500: 0.076983\n",
      "2023-12-02 18:01:05,868 INFO     Training average negative_sample_loss at step 26500: 0.084107\n",
      "2023-12-02 18:01:05,868 INFO     Training average loss at step 26500: 0.080545\n",
      "2023-12-02 18:01:15,300 INFO     Training average positive_sample_loss at step 26600: 0.077971\n",
      "2023-12-02 18:01:15,301 INFO     Training average negative_sample_loss at step 26600: 0.080949\n",
      "2023-12-02 18:01:15,301 INFO     Training average loss at step 26600: 0.079460\n",
      "2023-12-02 18:01:26,888 INFO     Training average positive_sample_loss at step 26700: 0.078416\n",
      "2023-12-02 18:01:26,888 INFO     Training average negative_sample_loss at step 26700: 0.082123\n",
      "2023-12-02 18:01:26,888 INFO     Training average loss at step 26700: 0.080269\n",
      "2023-12-02 18:01:38,749 INFO     Training average positive_sample_loss at step 26800: 0.079774\n",
      "2023-12-02 18:01:38,749 INFO     Training average negative_sample_loss at step 26800: 0.083823\n",
      "2023-12-02 18:01:38,749 INFO     Training average loss at step 26800: 0.081798\n",
      "2023-12-02 18:01:50,742 INFO     Training average positive_sample_loss at step 26900: 0.080765\n",
      "2023-12-02 18:01:50,742 INFO     Training average negative_sample_loss at step 26900: 0.083583\n",
      "2023-12-02 18:01:50,742 INFO     Training average loss at step 26900: 0.082174\n",
      "2023-12-02 18:01:59,890 INFO     Training average positive_sample_loss at step 27000: 0.081088\n",
      "2023-12-02 18:01:59,890 INFO     Training average negative_sample_loss at step 27000: 0.085583\n",
      "2023-12-02 18:01:59,890 INFO     Training average loss at step 27000: 0.083336\n",
      "2023-12-02 18:02:11,740 INFO     Training average positive_sample_loss at step 27100: 0.081989\n",
      "2023-12-02 18:02:11,741 INFO     Training average negative_sample_loss at step 27100: 0.086010\n",
      "2023-12-02 18:02:11,741 INFO     Training average loss at step 27100: 0.084000\n",
      "2023-12-02 18:02:23,541 INFO     Training average positive_sample_loss at step 27200: 0.081540\n",
      "2023-12-02 18:02:23,541 INFO     Training average negative_sample_loss at step 27200: 0.086010\n",
      "2023-12-02 18:02:23,541 INFO     Training average loss at step 27200: 0.083775\n",
      "2023-12-02 18:02:35,433 INFO     Training average positive_sample_loss at step 27300: 0.081558\n",
      "2023-12-02 18:02:35,434 INFO     Training average negative_sample_loss at step 27300: 0.085960\n",
      "2023-12-02 18:02:35,434 INFO     Training average loss at step 27300: 0.083759\n",
      "2023-12-02 18:02:46,429 INFO     Training average positive_sample_loss at step 27400: 0.079041\n",
      "2023-12-02 18:02:46,429 INFO     Training average negative_sample_loss at step 27400: 0.086229\n",
      "2023-12-02 18:02:46,429 INFO     Training average loss at step 27400: 0.082635\n",
      "2023-12-02 18:02:58,259 INFO     Training average positive_sample_loss at step 27500: 0.077372\n",
      "2023-12-02 18:02:58,259 INFO     Training average negative_sample_loss at step 27500: 0.081209\n",
      "2023-12-02 18:02:58,259 INFO     Training average loss at step 27500: 0.079291\n",
      "2023-12-02 18:03:10,272 INFO     Training average positive_sample_loss at step 27600: 0.078115\n",
      "2023-12-02 18:03:10,272 INFO     Training average negative_sample_loss at step 27600: 0.082377\n",
      "2023-12-02 18:03:10,272 INFO     Training average loss at step 27600: 0.080246\n",
      "2023-12-02 18:03:22,232 INFO     Training average positive_sample_loss at step 27700: 0.079693\n",
      "2023-12-02 18:03:22,232 INFO     Training average negative_sample_loss at step 27700: 0.083790\n",
      "2023-12-02 18:03:22,232 INFO     Training average loss at step 27700: 0.081741\n",
      "2023-12-02 18:03:31,209 INFO     Training average positive_sample_loss at step 27800: 0.080155\n",
      "2023-12-02 18:03:31,210 INFO     Training average negative_sample_loss at step 27800: 0.082473\n",
      "2023-12-02 18:03:31,210 INFO     Training average loss at step 27800: 0.081314\n",
      "2023-12-02 18:03:42,911 INFO     Training average positive_sample_loss at step 27900: 0.080860\n",
      "2023-12-02 18:03:42,911 INFO     Training average negative_sample_loss at step 27900: 0.084842\n",
      "2023-12-02 18:03:42,911 INFO     Training average loss at step 27900: 0.082851\n",
      "2023-12-02 18:03:54,645 INFO     Training average positive_sample_loss at step 28000: 0.080694\n",
      "2023-12-02 18:03:54,646 INFO     Training average negative_sample_loss at step 28000: 0.084402\n",
      "2023-12-02 18:03:54,646 INFO     Training average loss at step 28000: 0.082548\n",
      "2023-12-02 18:04:06,369 INFO     Training average positive_sample_loss at step 28100: 0.080748\n",
      "2023-12-02 18:04:06,369 INFO     Training average negative_sample_loss at step 28100: 0.084867\n",
      "2023-12-02 18:04:06,369 INFO     Training average loss at step 28100: 0.082808\n",
      "2023-12-02 18:04:15,462 INFO     Training average positive_sample_loss at step 28200: 0.080154\n",
      "2023-12-02 18:04:15,462 INFO     Training average negative_sample_loss at step 28200: 0.083708\n",
      "2023-12-02 18:04:15,462 INFO     Training average loss at step 28200: 0.081931\n",
      "2023-12-02 18:04:27,370 INFO     Training average positive_sample_loss at step 28300: 0.080906\n",
      "2023-12-02 18:04:27,370 INFO     Training average negative_sample_loss at step 28300: 0.085298\n",
      "2023-12-02 18:04:27,371 INFO     Training average loss at step 28300: 0.083102\n",
      "2023-12-02 18:04:39,901 INFO     Training average positive_sample_loss at step 28400: 0.075558\n",
      "2023-12-02 18:04:39,901 INFO     Training average negative_sample_loss at step 28400: 0.082293\n",
      "2023-12-02 18:04:39,901 INFO     Training average loss at step 28400: 0.078926\n",
      "2023-12-02 18:04:51,694 INFO     Training average positive_sample_loss at step 28500: 0.077153\n",
      "2023-12-02 18:04:51,694 INFO     Training average negative_sample_loss at step 28500: 0.081115\n",
      "2023-12-02 18:04:51,694 INFO     Training average loss at step 28500: 0.079134\n",
      "2023-12-02 18:05:00,744 INFO     Training average positive_sample_loss at step 28600: 0.079352\n",
      "2023-12-02 18:05:00,744 INFO     Training average negative_sample_loss at step 28600: 0.083120\n",
      "2023-12-02 18:05:00,744 INFO     Training average loss at step 28600: 0.081236\n",
      "2023-12-02 18:05:12,597 INFO     Training average positive_sample_loss at step 28700: 0.080028\n",
      "2023-12-02 18:05:12,598 INFO     Training average negative_sample_loss at step 28700: 0.082936\n",
      "2023-12-02 18:05:12,598 INFO     Training average loss at step 28700: 0.081482\n",
      "2023-12-02 18:05:24,453 INFO     Training average positive_sample_loss at step 28800: 0.080259\n",
      "2023-12-02 18:05:24,454 INFO     Training average negative_sample_loss at step 28800: 0.083655\n",
      "2023-12-02 18:05:24,454 INFO     Training average loss at step 28800: 0.081957\n",
      "2023-12-02 18:05:36,281 INFO     Training average positive_sample_loss at step 28900: 0.080617\n",
      "2023-12-02 18:05:36,281 INFO     Training average negative_sample_loss at step 28900: 0.083375\n",
      "2023-12-02 18:05:36,281 INFO     Training average loss at step 28900: 0.081996\n",
      "2023-12-02 18:05:45,482 INFO     Training average positive_sample_loss at step 29000: 0.081016\n",
      "2023-12-02 18:05:45,482 INFO     Training average negative_sample_loss at step 29000: 0.085254\n",
      "2023-12-02 18:05:45,482 INFO     Training average loss at step 29000: 0.083135\n",
      "2023-12-02 18:05:57,495 INFO     Training average positive_sample_loss at step 29100: 0.080612\n",
      "2023-12-02 18:05:57,495 INFO     Training average negative_sample_loss at step 29100: 0.085289\n",
      "2023-12-02 18:05:57,495 INFO     Training average loss at step 29100: 0.082951\n",
      "2023-12-02 18:06:09,307 INFO     Training average positive_sample_loss at step 29200: 0.081362\n",
      "2023-12-02 18:06:09,308 INFO     Training average negative_sample_loss at step 29200: 0.086643\n",
      "2023-12-02 18:06:09,308 INFO     Training average loss at step 29200: 0.084002\n",
      "2023-12-02 18:06:20,561 INFO     Training average positive_sample_loss at step 29300: 0.078278\n",
      "2023-12-02 18:06:20,561 INFO     Training average negative_sample_loss at step 29300: 0.084168\n",
      "2023-12-02 18:06:20,561 INFO     Training average loss at step 29300: 0.081223\n",
      "2023-12-02 18:06:31,100 INFO     Training average positive_sample_loss at step 29400: 0.076598\n",
      "2023-12-02 18:06:31,101 INFO     Training average negative_sample_loss at step 29400: 0.079480\n",
      "2023-12-02 18:06:31,101 INFO     Training average loss at step 29400: 0.078039\n",
      "2023-12-02 18:06:42,994 INFO     Training average positive_sample_loss at step 29500: 0.077649\n",
      "2023-12-02 18:06:42,995 INFO     Training average negative_sample_loss at step 29500: 0.081243\n",
      "2023-12-02 18:06:42,995 INFO     Training average loss at step 29500: 0.079446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 18:06:54,749 INFO     Training average positive_sample_loss at step 29600: 0.078947\n",
      "2023-12-02 18:06:54,749 INFO     Training average negative_sample_loss at step 29600: 0.082291\n",
      "2023-12-02 18:06:54,749 INFO     Training average loss at step 29600: 0.080619\n",
      "2023-12-02 18:07:04,894 INFO     Training average positive_sample_loss at step 29700: 0.079423\n",
      "2023-12-02 18:07:04,894 INFO     Training average negative_sample_loss at step 29700: 0.082619\n",
      "2023-12-02 18:07:04,894 INFO     Training average loss at step 29700: 0.081021\n",
      "2023-12-02 18:07:15,856 INFO     Training average positive_sample_loss at step 29800: 0.079896\n",
      "2023-12-02 18:07:15,856 INFO     Training average negative_sample_loss at step 29800: 0.083875\n",
      "2023-12-02 18:07:15,856 INFO     Training average loss at step 29800: 0.081886\n",
      "2023-12-02 18:07:27,747 INFO     Training average positive_sample_loss at step 29900: 0.080784\n",
      "2023-12-02 18:07:27,748 INFO     Training average negative_sample_loss at step 29900: 0.084635\n",
      "2023-12-02 18:07:27,748 INFO     Training average loss at step 29900: 0.082710\n",
      "2023-12-02 18:07:52,266 INFO     Training average positive_sample_loss at step 30000: 0.080511\n",
      "2023-12-02 18:07:52,266 INFO     Training average negative_sample_loss at step 30000: 0.084425\n",
      "2023-12-02 18:07:52,266 INFO     Training average loss at step 30000: 0.082468\n",
      "2023-12-02 18:07:52,266 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 18:07:53,284 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 18:09:08,392 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 18:10:24,901 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 18:11:35,936 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 18:12:49,232 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 18:14:05,106 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 18:15:15,111 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 18:15:36,573 INFO     Valid MRR at step 30000: 0.746916\n",
      "2023-12-02 18:15:36,573 INFO     Valid MR at step 30000: 50.165730\n",
      "2023-12-02 18:15:36,573 INFO     Valid HITS@1 at step 30000: 0.682120\n",
      "2023-12-02 18:15:36,573 INFO     Valid HITS@3 at step 30000: 0.788350\n",
      "2023-12-02 18:15:36,573 INFO     Valid HITS@10 at step 30000: 0.858780\n",
      "2023-12-02 18:15:48,028 INFO     Training average positive_sample_loss at step 30100: 0.080983\n",
      "2023-12-02 18:15:48,028 INFO     Training average negative_sample_loss at step 30100: 0.084243\n",
      "2023-12-02 18:15:48,028 INFO     Training average loss at step 30100: 0.082613\n",
      "2023-12-02 18:15:57,756 INFO     Training average positive_sample_loss at step 30200: 0.080612\n",
      "2023-12-02 18:15:57,756 INFO     Training average negative_sample_loss at step 30200: 0.084519\n",
      "2023-12-02 18:15:57,756 INFO     Training average loss at step 30200: 0.082566\n",
      "2023-12-02 18:16:10,742 INFO     Training average positive_sample_loss at step 30300: 0.074724\n",
      "2023-12-02 18:16:10,743 INFO     Training average negative_sample_loss at step 30300: 0.080956\n",
      "2023-12-02 18:16:10,743 INFO     Training average loss at step 30300: 0.077840\n",
      "2023-12-02 18:16:22,846 INFO     Training average positive_sample_loss at step 30400: 0.077543\n",
      "2023-12-02 18:16:22,846 INFO     Training average negative_sample_loss at step 30400: 0.080531\n",
      "2023-12-02 18:16:22,847 INFO     Training average loss at step 30400: 0.079037\n",
      "2023-12-02 18:16:32,217 INFO     Training average positive_sample_loss at step 30500: 0.077920\n",
      "2023-12-02 18:16:32,218 INFO     Training average negative_sample_loss at step 30500: 0.081447\n",
      "2023-12-02 18:16:32,218 INFO     Training average loss at step 30500: 0.079683\n",
      "2023-12-02 18:16:40,082 INFO     Training average positive_sample_loss at step 30600: 0.079434\n",
      "2023-12-02 18:16:40,082 INFO     Training average negative_sample_loss at step 30600: 0.081949\n",
      "2023-12-02 18:16:40,082 INFO     Training average loss at step 30600: 0.080692\n",
      "2023-12-02 18:16:47,062 INFO     Training average positive_sample_loss at step 30700: 0.079206\n",
      "2023-12-02 18:16:47,062 INFO     Training average negative_sample_loss at step 30700: 0.082485\n",
      "2023-12-02 18:16:47,062 INFO     Training average loss at step 30700: 0.080845\n",
      "2023-12-02 18:16:54,549 INFO     Training average positive_sample_loss at step 30800: 0.080002\n",
      "2023-12-02 18:16:54,549 INFO     Training average negative_sample_loss at step 30800: 0.083440\n",
      "2023-12-02 18:16:54,550 INFO     Training average loss at step 30800: 0.081721\n",
      "2023-12-02 18:17:03,311 INFO     Training average positive_sample_loss at step 30900: 0.080378\n",
      "2023-12-02 18:17:03,312 INFO     Training average negative_sample_loss at step 30900: 0.084472\n",
      "2023-12-02 18:17:03,312 INFO     Training average loss at step 30900: 0.082425\n",
      "2023-12-02 18:17:11,670 INFO     Training average positive_sample_loss at step 31000: 0.080131\n",
      "2023-12-02 18:17:11,671 INFO     Training average negative_sample_loss at step 31000: 0.084407\n",
      "2023-12-02 18:17:11,671 INFO     Training average loss at step 31000: 0.082269\n",
      "2023-12-02 18:17:20,326 INFO     Training average positive_sample_loss at step 31100: 0.080695\n",
      "2023-12-02 18:17:20,326 INFO     Training average negative_sample_loss at step 31100: 0.084382\n",
      "2023-12-02 18:17:20,326 INFO     Training average loss at step 31100: 0.082538\n",
      "2023-12-02 18:17:31,092 INFO     Training average positive_sample_loss at step 31200: 0.076864\n",
      "2023-12-02 18:17:31,093 INFO     Training average negative_sample_loss at step 31200: 0.083625\n",
      "2023-12-02 18:17:31,093 INFO     Training average loss at step 31200: 0.080245\n",
      "2023-12-02 18:17:43,081 INFO     Training average positive_sample_loss at step 31300: 0.076388\n",
      "2023-12-02 18:17:43,081 INFO     Training average negative_sample_loss at step 31300: 0.079857\n",
      "2023-12-02 18:17:43,081 INFO     Training average loss at step 31300: 0.078123\n",
      "2023-12-02 18:17:55,085 INFO     Training average positive_sample_loss at step 31400: 0.077537\n",
      "2023-12-02 18:17:55,085 INFO     Training average negative_sample_loss at step 31400: 0.080674\n",
      "2023-12-02 18:17:55,085 INFO     Training average loss at step 31400: 0.079106\n",
      "2023-12-02 18:18:04,824 INFO     Training average positive_sample_loss at step 31500: 0.078833\n",
      "2023-12-02 18:18:04,824 INFO     Training average negative_sample_loss at step 31500: 0.081051\n",
      "2023-12-02 18:18:04,824 INFO     Training average loss at step 31500: 0.079942\n",
      "2023-12-02 18:18:16,184 INFO     Training average positive_sample_loss at step 31600: 0.078971\n",
      "2023-12-02 18:18:16,184 INFO     Training average negative_sample_loss at step 31600: 0.081182\n",
      "2023-12-02 18:18:16,184 INFO     Training average loss at step 31600: 0.080077\n",
      "2023-12-02 18:18:28,019 INFO     Training average positive_sample_loss at step 31700: 0.079304\n",
      "2023-12-02 18:18:28,019 INFO     Training average negative_sample_loss at step 31700: 0.082325\n",
      "2023-12-02 18:18:28,019 INFO     Training average loss at step 31700: 0.080815\n",
      "2023-12-02 18:18:40,000 INFO     Training average positive_sample_loss at step 31800: 0.080139\n",
      "2023-12-02 18:18:40,001 INFO     Training average negative_sample_loss at step 31800: 0.083154\n",
      "2023-12-02 18:18:40,001 INFO     Training average loss at step 31800: 0.081647\n",
      "2023-12-02 18:18:49,258 INFO     Training average positive_sample_loss at step 31900: 0.079471\n",
      "2023-12-02 18:18:49,258 INFO     Training average negative_sample_loss at step 31900: 0.083351\n",
      "2023-12-02 18:18:49,258 INFO     Training average loss at step 31900: 0.081411\n",
      "2023-12-02 18:19:01,171 INFO     Training average positive_sample_loss at step 32000: 0.080618\n",
      "2023-12-02 18:19:01,172 INFO     Training average negative_sample_loss at step 32000: 0.084568\n",
      "2023-12-02 18:19:01,172 INFO     Training average loss at step 32000: 0.082593\n",
      "2023-12-02 18:19:14,041 INFO     Training average positive_sample_loss at step 32100: 0.079411\n",
      "2023-12-02 18:19:14,041 INFO     Training average negative_sample_loss at step 32100: 0.083121\n",
      "2023-12-02 18:19:14,041 INFO     Training average loss at step 32100: 0.081266\n",
      "2023-12-02 18:19:25,932 INFO     Training average positive_sample_loss at step 32200: 0.074360\n",
      "2023-12-02 18:19:25,932 INFO     Training average negative_sample_loss at step 32200: 0.080042\n",
      "2023-12-02 18:19:25,932 INFO     Training average loss at step 32200: 0.077201\n",
      "2023-12-02 18:19:34,912 INFO     Training average positive_sample_loss at step 32300: 0.076938\n",
      "2023-12-02 18:19:34,912 INFO     Training average negative_sample_loss at step 32300: 0.079580\n",
      "2023-12-02 18:19:34,912 INFO     Training average loss at step 32300: 0.078259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 18:19:46,985 INFO     Training average positive_sample_loss at step 32400: 0.077516\n",
      "2023-12-02 18:19:46,986 INFO     Training average negative_sample_loss at step 32400: 0.080399\n",
      "2023-12-02 18:19:46,986 INFO     Training average loss at step 32400: 0.078958\n",
      "2023-12-02 18:19:59,001 INFO     Training average positive_sample_loss at step 32500: 0.079247\n",
      "2023-12-02 18:19:59,001 INFO     Training average negative_sample_loss at step 32500: 0.082551\n",
      "2023-12-02 18:19:59,001 INFO     Training average loss at step 32500: 0.080899\n",
      "2023-12-02 18:20:10,934 INFO     Training average positive_sample_loss at step 32600: 0.079003\n",
      "2023-12-02 18:20:10,935 INFO     Training average negative_sample_loss at step 32600: 0.082604\n",
      "2023-12-02 18:20:10,935 INFO     Training average loss at step 32600: 0.080804\n",
      "2023-12-02 18:20:20,173 INFO     Training average positive_sample_loss at step 32700: 0.079552\n",
      "2023-12-02 18:20:20,173 INFO     Training average negative_sample_loss at step 32700: 0.082326\n",
      "2023-12-02 18:20:20,173 INFO     Training average loss at step 32700: 0.080939\n",
      "2023-12-02 18:20:32,096 INFO     Training average positive_sample_loss at step 32800: 0.079807\n",
      "2023-12-02 18:20:32,097 INFO     Training average negative_sample_loss at step 32800: 0.083169\n",
      "2023-12-02 18:20:32,097 INFO     Training average loss at step 32800: 0.081488\n",
      "2023-12-02 18:20:44,025 INFO     Training average positive_sample_loss at step 32900: 0.079921\n",
      "2023-12-02 18:20:44,025 INFO     Training average negative_sample_loss at step 32900: 0.084305\n",
      "2023-12-02 18:20:44,025 INFO     Training average loss at step 32900: 0.082113\n",
      "2023-12-02 18:20:55,965 INFO     Training average positive_sample_loss at step 33000: 0.080789\n",
      "2023-12-02 18:20:55,965 INFO     Training average negative_sample_loss at step 33000: 0.084192\n",
      "2023-12-02 18:20:55,965 INFO     Training average loss at step 33000: 0.082491\n",
      "2023-12-02 18:21:06,586 INFO     Training average positive_sample_loss at step 33100: 0.075272\n",
      "2023-12-02 18:21:06,586 INFO     Training average negative_sample_loss at step 33100: 0.080827\n",
      "2023-12-02 18:21:06,586 INFO     Training average loss at step 33100: 0.078050\n",
      "2023-12-02 18:21:18,396 INFO     Training average positive_sample_loss at step 33200: 0.076088\n",
      "2023-12-02 18:21:18,396 INFO     Training average negative_sample_loss at step 33200: 0.079354\n",
      "2023-12-02 18:21:18,396 INFO     Training average loss at step 33200: 0.077721\n",
      "2023-12-02 18:21:30,291 INFO     Training average positive_sample_loss at step 33300: 0.077346\n",
      "2023-12-02 18:21:30,292 INFO     Training average negative_sample_loss at step 33300: 0.080675\n",
      "2023-12-02 18:21:30,292 INFO     Training average loss at step 33300: 0.079010\n",
      "2023-12-02 18:21:41,222 INFO     Training average positive_sample_loss at step 33400: 0.078900\n",
      "2023-12-02 18:21:41,222 INFO     Training average negative_sample_loss at step 33400: 0.080633\n",
      "2023-12-02 18:21:41,222 INFO     Training average loss at step 33400: 0.079766\n",
      "2023-12-02 18:21:51,402 INFO     Training average positive_sample_loss at step 33500: 0.078821\n",
      "2023-12-02 18:21:51,403 INFO     Training average negative_sample_loss at step 33500: 0.081391\n",
      "2023-12-02 18:21:51,403 INFO     Training average loss at step 33500: 0.080106\n",
      "2023-12-02 18:22:03,228 INFO     Training average positive_sample_loss at step 33600: 0.078997\n",
      "2023-12-02 18:22:03,228 INFO     Training average negative_sample_loss at step 33600: 0.081558\n",
      "2023-12-02 18:22:03,228 INFO     Training average loss at step 33600: 0.080277\n",
      "2023-12-02 18:22:14,995 INFO     Training average positive_sample_loss at step 33700: 0.078891\n",
      "2023-12-02 18:22:14,995 INFO     Training average negative_sample_loss at step 33700: 0.082509\n",
      "2023-12-02 18:22:14,995 INFO     Training average loss at step 33700: 0.080700\n",
      "2023-12-02 18:22:25,546 INFO     Training average positive_sample_loss at step 33800: 0.079364\n",
      "2023-12-02 18:22:25,546 INFO     Training average negative_sample_loss at step 33800: 0.082860\n",
      "2023-12-02 18:22:25,546 INFO     Training average loss at step 33800: 0.081112\n",
      "2023-12-02 18:22:36,093 INFO     Training average positive_sample_loss at step 33900: 0.080120\n",
      "2023-12-02 18:22:36,093 INFO     Training average negative_sample_loss at step 33900: 0.083905\n",
      "2023-12-02 18:22:36,093 INFO     Training average loss at step 33900: 0.082013\n",
      "2023-12-02 18:22:49,696 INFO     Training average positive_sample_loss at step 34000: 0.078099\n",
      "2023-12-02 18:22:49,696 INFO     Training average negative_sample_loss at step 34000: 0.082021\n",
      "2023-12-02 18:22:49,696 INFO     Training average loss at step 34000: 0.080060\n",
      "2023-12-02 18:23:01,649 INFO     Training average positive_sample_loss at step 34100: 0.074224\n",
      "2023-12-02 18:23:01,649 INFO     Training average negative_sample_loss at step 34100: 0.078067\n",
      "2023-12-02 18:23:01,649 INFO     Training average loss at step 34100: 0.076146\n",
      "2023-12-02 18:23:10,973 INFO     Training average positive_sample_loss at step 34200: 0.076727\n",
      "2023-12-02 18:23:10,973 INFO     Training average negative_sample_loss at step 34200: 0.079201\n",
      "2023-12-02 18:23:10,973 INFO     Training average loss at step 34200: 0.077964\n",
      "2023-12-02 18:23:22,854 INFO     Training average positive_sample_loss at step 34300: 0.077394\n",
      "2023-12-02 18:23:22,854 INFO     Training average negative_sample_loss at step 34300: 0.080811\n",
      "2023-12-02 18:23:22,854 INFO     Training average loss at step 34300: 0.079103\n",
      "2023-12-02 18:23:34,806 INFO     Training average positive_sample_loss at step 34400: 0.078840\n",
      "2023-12-02 18:23:34,807 INFO     Training average negative_sample_loss at step 34400: 0.082108\n",
      "2023-12-02 18:23:34,807 INFO     Training average loss at step 34400: 0.080474\n",
      "2023-12-02 18:23:46,726 INFO     Training average positive_sample_loss at step 34500: 0.078782\n",
      "2023-12-02 18:23:46,727 INFO     Training average negative_sample_loss at step 34500: 0.081238\n",
      "2023-12-02 18:23:46,727 INFO     Training average loss at step 34500: 0.080010\n",
      "2023-12-02 18:23:55,899 INFO     Training average positive_sample_loss at step 34600: 0.078641\n",
      "2023-12-02 18:23:55,899 INFO     Training average negative_sample_loss at step 34600: 0.082007\n",
      "2023-12-02 18:23:55,899 INFO     Training average loss at step 34600: 0.080324\n",
      "2023-12-02 18:24:07,685 INFO     Training average positive_sample_loss at step 34700: 0.079073\n",
      "2023-12-02 18:24:07,686 INFO     Training average negative_sample_loss at step 34700: 0.081774\n",
      "2023-12-02 18:24:07,686 INFO     Training average loss at step 34700: 0.080423\n",
      "2023-12-02 18:24:19,542 INFO     Training average positive_sample_loss at step 34800: 0.079883\n",
      "2023-12-02 18:24:19,542 INFO     Training average negative_sample_loss at step 34800: 0.083003\n",
      "2023-12-02 18:24:19,542 INFO     Training average loss at step 34800: 0.081443\n",
      "2023-12-02 18:24:31,326 INFO     Training average positive_sample_loss at step 34900: 0.079667\n",
      "2023-12-02 18:24:31,326 INFO     Training average negative_sample_loss at step 34900: 0.082908\n",
      "2023-12-02 18:24:31,326 INFO     Training average loss at step 34900: 0.081287\n",
      "2023-12-02 18:24:43,159 INFO     Training average positive_sample_loss at step 35000: 0.074733\n",
      "2023-12-02 18:24:43,159 INFO     Training average negative_sample_loss at step 35000: 0.080573\n",
      "2023-12-02 18:24:43,159 INFO     Training average loss at step 35000: 0.077653\n",
      "2023-12-02 18:24:54,952 INFO     Training average positive_sample_loss at step 35100: 0.075117\n",
      "2023-12-02 18:24:54,953 INFO     Training average negative_sample_loss at step 35100: 0.076972\n",
      "2023-12-02 18:24:54,953 INFO     Training average loss at step 35100: 0.076044\n",
      "2023-12-02 18:25:06,713 INFO     Training average positive_sample_loss at step 35200: 0.077025\n",
      "2023-12-02 18:25:06,713 INFO     Training average negative_sample_loss at step 35200: 0.079573\n",
      "2023-12-02 18:25:06,713 INFO     Training average loss at step 35200: 0.078299\n",
      "2023-12-02 18:25:18,028 INFO     Training average positive_sample_loss at step 35300: 0.077714\n",
      "2023-12-02 18:25:18,028 INFO     Training average negative_sample_loss at step 35300: 0.080130\n",
      "2023-12-02 18:25:18,028 INFO     Training average loss at step 35300: 0.078922\n",
      "2023-12-02 18:25:27,513 INFO     Training average positive_sample_loss at step 35400: 0.078333\n",
      "2023-12-02 18:25:27,514 INFO     Training average negative_sample_loss at step 35400: 0.081359\n",
      "2023-12-02 18:25:27,514 INFO     Training average loss at step 35400: 0.079846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 18:25:39,349 INFO     Training average positive_sample_loss at step 35500: 0.079022\n",
      "2023-12-02 18:25:39,349 INFO     Training average negative_sample_loss at step 35500: 0.081659\n",
      "2023-12-02 18:25:39,349 INFO     Training average loss at step 35500: 0.080340\n",
      "2023-12-02 18:25:51,119 INFO     Training average positive_sample_loss at step 35600: 0.078905\n",
      "2023-12-02 18:25:51,119 INFO     Training average negative_sample_loss at step 35600: 0.081922\n",
      "2023-12-02 18:25:51,119 INFO     Training average loss at step 35600: 0.080414\n",
      "2023-12-02 18:26:02,249 INFO     Training average positive_sample_loss at step 35700: 0.079699\n",
      "2023-12-02 18:26:02,249 INFO     Training average negative_sample_loss at step 35700: 0.082364\n",
      "2023-12-02 18:26:02,249 INFO     Training average loss at step 35700: 0.081031\n",
      "2023-12-02 18:26:12,092 INFO     Training average positive_sample_loss at step 35800: 0.079490\n",
      "2023-12-02 18:26:12,092 INFO     Training average negative_sample_loss at step 35800: 0.082412\n",
      "2023-12-02 18:26:12,092 INFO     Training average loss at step 35800: 0.080951\n",
      "2023-12-02 18:26:25,162 INFO     Training average positive_sample_loss at step 35900: 0.076439\n",
      "2023-12-02 18:26:25,162 INFO     Training average negative_sample_loss at step 35900: 0.081841\n",
      "2023-12-02 18:26:25,162 INFO     Training average loss at step 35900: 0.079140\n",
      "2023-12-02 18:26:36,991 INFO     Training average positive_sample_loss at step 36000: 0.075049\n",
      "2023-12-02 18:26:36,992 INFO     Training average negative_sample_loss at step 36000: 0.078034\n",
      "2023-12-02 18:26:36,992 INFO     Training average loss at step 36000: 0.076541\n",
      "2023-12-02 18:26:46,330 INFO     Training average positive_sample_loss at step 36100: 0.076344\n",
      "2023-12-02 18:26:46,330 INFO     Training average negative_sample_loss at step 36100: 0.079381\n",
      "2023-12-02 18:26:46,330 INFO     Training average loss at step 36100: 0.077862\n",
      "2023-12-02 18:26:58,105 INFO     Training average positive_sample_loss at step 36200: 0.077862\n",
      "2023-12-02 18:26:58,105 INFO     Training average negative_sample_loss at step 36200: 0.080600\n",
      "2023-12-02 18:26:58,105 INFO     Training average loss at step 36200: 0.079231\n",
      "2023-12-02 18:27:10,044 INFO     Training average positive_sample_loss at step 36300: 0.077819\n",
      "2023-12-02 18:27:10,044 INFO     Training average negative_sample_loss at step 36300: 0.080644\n",
      "2023-12-02 18:27:10,044 INFO     Training average loss at step 36300: 0.079231\n",
      "2023-12-02 18:27:21,893 INFO     Training average positive_sample_loss at step 36400: 0.079028\n",
      "2023-12-02 18:27:21,894 INFO     Training average negative_sample_loss at step 36400: 0.081592\n",
      "2023-12-02 18:27:21,894 INFO     Training average loss at step 36400: 0.080310\n",
      "2023-12-02 18:27:31,175 INFO     Training average positive_sample_loss at step 36500: 0.078328\n",
      "2023-12-02 18:27:31,175 INFO     Training average negative_sample_loss at step 36500: 0.081466\n",
      "2023-12-02 18:27:31,175 INFO     Training average loss at step 36500: 0.079897\n",
      "2023-12-02 18:27:42,954 INFO     Training average positive_sample_loss at step 36600: 0.078755\n",
      "2023-12-02 18:27:42,954 INFO     Training average negative_sample_loss at step 36600: 0.081522\n",
      "2023-12-02 18:27:42,954 INFO     Training average loss at step 36600: 0.080138\n",
      "2023-12-02 18:27:54,726 INFO     Training average positive_sample_loss at step 36700: 0.078960\n",
      "2023-12-02 18:27:54,726 INFO     Training average negative_sample_loss at step 36700: 0.081918\n",
      "2023-12-02 18:27:54,726 INFO     Training average loss at step 36700: 0.080439\n",
      "2023-12-02 18:28:06,593 INFO     Training average positive_sample_loss at step 36800: 0.079227\n",
      "2023-12-02 18:28:06,593 INFO     Training average negative_sample_loss at step 36800: 0.082795\n",
      "2023-12-02 18:28:06,593 INFO     Training average loss at step 36800: 0.081011\n",
      "2023-12-02 18:28:16,574 INFO     Training average positive_sample_loss at step 36900: 0.074280\n",
      "2023-12-02 18:28:16,574 INFO     Training average negative_sample_loss at step 36900: 0.080188\n",
      "2023-12-02 18:28:16,575 INFO     Training average loss at step 36900: 0.077234\n",
      "2023-12-02 18:28:28,349 INFO     Training average positive_sample_loss at step 37000: 0.074992\n",
      "2023-12-02 18:28:28,349 INFO     Training average negative_sample_loss at step 37000: 0.077499\n",
      "2023-12-02 18:28:28,349 INFO     Training average loss at step 37000: 0.076246\n",
      "2023-12-02 18:28:40,425 INFO     Training average positive_sample_loss at step 37100: 0.077134\n",
      "2023-12-02 18:28:40,425 INFO     Training average negative_sample_loss at step 37100: 0.079670\n",
      "2023-12-02 18:28:40,425 INFO     Training average loss at step 37100: 0.078402\n",
      "2023-12-02 18:28:52,365 INFO     Training average positive_sample_loss at step 37200: 0.077864\n",
      "2023-12-02 18:28:52,366 INFO     Training average negative_sample_loss at step 37200: 0.079869\n",
      "2023-12-02 18:28:52,366 INFO     Training average loss at step 37200: 0.078867\n",
      "2023-12-02 18:29:01,659 INFO     Training average positive_sample_loss at step 37300: 0.077868\n",
      "2023-12-02 18:29:01,660 INFO     Training average negative_sample_loss at step 37300: 0.080231\n",
      "2023-12-02 18:29:01,660 INFO     Training average loss at step 37300: 0.079050\n",
      "2023-12-02 18:29:13,566 INFO     Training average positive_sample_loss at step 37400: 0.078424\n",
      "2023-12-02 18:29:13,567 INFO     Training average negative_sample_loss at step 37400: 0.081249\n",
      "2023-12-02 18:29:13,567 INFO     Training average loss at step 37400: 0.079836\n",
      "2023-12-02 18:29:25,467 INFO     Training average positive_sample_loss at step 37500: 0.079575\n",
      "2023-12-02 18:29:25,468 INFO     Training average negative_sample_loss at step 37500: 0.082980\n",
      "2023-12-02 18:29:25,468 INFO     Training average loss at step 37500: 0.081277\n",
      "2023-12-02 18:29:37,500 INFO     Training average positive_sample_loss at step 37600: 0.079483\n",
      "2023-12-02 18:29:37,500 INFO     Training average negative_sample_loss at step 37600: 0.082284\n",
      "2023-12-02 18:29:37,500 INFO     Training average loss at step 37600: 0.080883\n",
      "2023-12-02 18:29:46,738 INFO     Training average positive_sample_loss at step 37700: 0.078991\n",
      "2023-12-02 18:29:46,739 INFO     Training average negative_sample_loss at step 37700: 0.081967\n",
      "2023-12-02 18:29:46,739 INFO     Training average loss at step 37700: 0.080479\n",
      "2023-12-02 18:29:59,561 INFO     Training average positive_sample_loss at step 37800: 0.075827\n",
      "2023-12-02 18:29:59,561 INFO     Training average negative_sample_loss at step 37800: 0.081433\n",
      "2023-12-02 18:29:59,561 INFO     Training average loss at step 37800: 0.078630\n",
      "2023-12-02 18:30:11,336 INFO     Training average positive_sample_loss at step 37900: 0.074524\n",
      "2023-12-02 18:30:11,336 INFO     Training average negative_sample_loss at step 37900: 0.077720\n",
      "2023-12-02 18:30:11,336 INFO     Training average loss at step 37900: 0.076122\n",
      "2023-12-02 18:30:21,905 INFO     Training average positive_sample_loss at step 38000: 0.076520\n",
      "2023-12-02 18:30:21,905 INFO     Training average negative_sample_loss at step 38000: 0.078255\n",
      "2023-12-02 18:30:21,906 INFO     Training average loss at step 38000: 0.077387\n",
      "2023-12-02 18:30:32,546 INFO     Training average positive_sample_loss at step 38100: 0.077160\n",
      "2023-12-02 18:30:32,546 INFO     Training average negative_sample_loss at step 38100: 0.079579\n",
      "2023-12-02 18:30:32,547 INFO     Training average loss at step 38100: 0.078370\n",
      "2023-12-02 18:30:44,411 INFO     Training average positive_sample_loss at step 38200: 0.077484\n",
      "2023-12-02 18:30:44,412 INFO     Training average negative_sample_loss at step 38200: 0.079521\n",
      "2023-12-02 18:30:44,412 INFO     Training average loss at step 38200: 0.078503\n",
      "2023-12-02 18:30:56,184 INFO     Training average positive_sample_loss at step 38300: 0.078603\n",
      "2023-12-02 18:30:56,184 INFO     Training average negative_sample_loss at step 38300: 0.081909\n",
      "2023-12-02 18:30:56,184 INFO     Training average loss at step 38300: 0.080256\n",
      "2023-12-02 18:31:06,286 INFO     Training average positive_sample_loss at step 38400: 0.078995\n",
      "2023-12-02 18:31:06,287 INFO     Training average negative_sample_loss at step 38400: 0.081442\n",
      "2023-12-02 18:31:06,287 INFO     Training average loss at step 38400: 0.080218\n",
      "2023-12-02 18:31:17,514 INFO     Training average positive_sample_loss at step 38500: 0.079100\n",
      "2023-12-02 18:31:17,515 INFO     Training average negative_sample_loss at step 38500: 0.082742\n",
      "2023-12-02 18:31:17,515 INFO     Training average loss at step 38500: 0.080921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 18:31:29,562 INFO     Training average positive_sample_loss at step 38600: 0.078725\n",
      "2023-12-02 18:31:29,562 INFO     Training average negative_sample_loss at step 38600: 0.081139\n",
      "2023-12-02 18:31:29,562 INFO     Training average loss at step 38600: 0.079932\n",
      "2023-12-02 18:31:41,565 INFO     Training average positive_sample_loss at step 38700: 0.078094\n",
      "2023-12-02 18:31:41,565 INFO     Training average negative_sample_loss at step 38700: 0.081664\n",
      "2023-12-02 18:31:41,565 INFO     Training average loss at step 38700: 0.079879\n",
      "2023-12-02 18:31:51,692 INFO     Training average positive_sample_loss at step 38800: 0.072713\n",
      "2023-12-02 18:31:51,692 INFO     Training average negative_sample_loss at step 38800: 0.077657\n",
      "2023-12-02 18:31:51,692 INFO     Training average loss at step 38800: 0.075185\n",
      "2023-12-02 18:32:03,730 INFO     Training average positive_sample_loss at step 38900: 0.075428\n",
      "2023-12-02 18:32:03,730 INFO     Training average negative_sample_loss at step 38900: 0.077569\n",
      "2023-12-02 18:32:03,730 INFO     Training average loss at step 38900: 0.076498\n",
      "2023-12-02 18:32:15,819 INFO     Training average positive_sample_loss at step 39000: 0.076780\n",
      "2023-12-02 18:32:15,819 INFO     Training average negative_sample_loss at step 39000: 0.078433\n",
      "2023-12-02 18:32:15,819 INFO     Training average loss at step 39000: 0.077607\n",
      "2023-12-02 18:32:27,844 INFO     Training average positive_sample_loss at step 39100: 0.077445\n",
      "2023-12-02 18:32:27,845 INFO     Training average negative_sample_loss at step 39100: 0.079420\n",
      "2023-12-02 18:32:27,845 INFO     Training average loss at step 39100: 0.078433\n",
      "2023-12-02 18:32:37,095 INFO     Training average positive_sample_loss at step 39200: 0.077613\n",
      "2023-12-02 18:32:37,096 INFO     Training average negative_sample_loss at step 39200: 0.080226\n",
      "2023-12-02 18:32:37,096 INFO     Training average loss at step 39200: 0.078920\n",
      "2023-12-02 18:32:49,018 INFO     Training average positive_sample_loss at step 39300: 0.078391\n",
      "2023-12-02 18:32:49,019 INFO     Training average negative_sample_loss at step 39300: 0.080445\n",
      "2023-12-02 18:32:49,019 INFO     Training average loss at step 39300: 0.079418\n",
      "2023-12-02 18:33:01,133 INFO     Training average positive_sample_loss at step 39400: 0.078248\n",
      "2023-12-02 18:33:01,133 INFO     Training average negative_sample_loss at step 39400: 0.081342\n",
      "2023-12-02 18:33:01,133 INFO     Training average loss at step 39400: 0.079795\n",
      "2023-12-02 18:33:12,999 INFO     Training average positive_sample_loss at step 39500: 0.078802\n",
      "2023-12-02 18:33:13,000 INFO     Training average negative_sample_loss at step 39500: 0.080927\n",
      "2023-12-02 18:33:13,000 INFO     Training average loss at step 39500: 0.079864\n",
      "2023-12-02 18:33:22,266 INFO     Training average positive_sample_loss at step 39600: 0.078942\n",
      "2023-12-02 18:33:22,266 INFO     Training average negative_sample_loss at step 39600: 0.082190\n",
      "2023-12-02 18:33:22,266 INFO     Training average loss at step 39600: 0.080566\n",
      "2023-12-02 18:33:35,111 INFO     Training average positive_sample_loss at step 39700: 0.074628\n",
      "2023-12-02 18:33:35,112 INFO     Training average negative_sample_loss at step 39700: 0.080226\n",
      "2023-12-02 18:33:35,112 INFO     Training average loss at step 39700: 0.077427\n",
      "2023-12-02 18:33:47,012 INFO     Training average positive_sample_loss at step 39800: 0.074851\n",
      "2023-12-02 18:33:47,013 INFO     Training average negative_sample_loss at step 39800: 0.077673\n",
      "2023-12-02 18:33:47,013 INFO     Training average loss at step 39800: 0.076262\n",
      "2023-12-02 18:33:57,665 INFO     Training average positive_sample_loss at step 39900: 0.076255\n",
      "2023-12-02 18:33:57,665 INFO     Training average negative_sample_loss at step 39900: 0.078074\n",
      "2023-12-02 18:33:57,665 INFO     Training average loss at step 39900: 0.077164\n",
      "2023-12-02 18:34:19,650 INFO     Training average positive_sample_loss at step 40000: 0.076857\n",
      "2023-12-02 18:34:19,650 INFO     Training average negative_sample_loss at step 40000: 0.078804\n",
      "2023-12-02 18:34:19,651 INFO     Training average loss at step 40000: 0.077831\n",
      "2023-12-02 18:34:19,651 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 18:34:20,952 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 18:35:35,431 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 18:36:46,402 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 18:37:45,164 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 18:38:25,000 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 18:39:38,107 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 18:40:51,221 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 18:41:12,249 INFO     Valid MRR at step 40000: 0.740428\n",
      "2023-12-02 18:41:12,249 INFO     Valid MR at step 40000: 50.495850\n",
      "2023-12-02 18:41:12,249 INFO     Valid HITS@1 at step 40000: 0.676010\n",
      "2023-12-02 18:41:12,249 INFO     Valid HITS@3 at step 40000: 0.779900\n",
      "2023-12-02 18:41:12,249 INFO     Valid HITS@10 at step 40000: 0.853460\n",
      "2023-12-02 18:41:21,930 INFO     Training average positive_sample_loss at step 40100: 0.077938\n",
      "2023-12-02 18:41:21,931 INFO     Training average negative_sample_loss at step 40100: 0.080559\n",
      "2023-12-02 18:41:21,931 INFO     Training average loss at step 40100: 0.079248\n",
      "2023-12-02 18:41:33,878 INFO     Training average positive_sample_loss at step 40200: 0.077743\n",
      "2023-12-02 18:41:33,879 INFO     Training average negative_sample_loss at step 40200: 0.080231\n",
      "2023-12-02 18:41:33,879 INFO     Training average loss at step 40200: 0.078987\n",
      "2023-12-02 18:41:45,880 INFO     Training average positive_sample_loss at step 40300: 0.078190\n",
      "2023-12-02 18:41:45,881 INFO     Training average negative_sample_loss at step 40300: 0.081039\n",
      "2023-12-02 18:41:45,881 INFO     Training average loss at step 40300: 0.079614\n",
      "2023-12-02 18:41:56,491 INFO     Training average positive_sample_loss at step 40400: 0.079341\n",
      "2023-12-02 18:41:56,491 INFO     Training average negative_sample_loss at step 40400: 0.081805\n",
      "2023-12-02 18:41:56,491 INFO     Training average loss at step 40400: 0.080573\n",
      "2023-12-02 18:42:06,976 INFO     Training average positive_sample_loss at step 40500: 0.078638\n",
      "2023-12-02 18:42:06,976 INFO     Training average negative_sample_loss at step 40500: 0.080441\n",
      "2023-12-02 18:42:06,976 INFO     Training average loss at step 40500: 0.079540\n",
      "2023-12-02 18:42:19,657 INFO     Training average positive_sample_loss at step 40600: 0.077807\n",
      "2023-12-02 18:42:19,657 INFO     Training average negative_sample_loss at step 40600: 0.081911\n",
      "2023-12-02 18:42:19,657 INFO     Training average loss at step 40600: 0.079859\n",
      "2023-12-02 18:42:31,552 INFO     Training average positive_sample_loss at step 40700: 0.073349\n",
      "2023-12-02 18:42:31,552 INFO     Training average negative_sample_loss at step 40700: 0.077464\n",
      "2023-12-02 18:42:31,552 INFO     Training average loss at step 40700: 0.075406\n",
      "2023-12-02 18:42:40,819 INFO     Training average positive_sample_loss at step 40800: 0.075219\n",
      "2023-12-02 18:42:40,819 INFO     Training average negative_sample_loss at step 40800: 0.076329\n",
      "2023-12-02 18:42:40,819 INFO     Training average loss at step 40800: 0.075774\n",
      "2023-12-02 18:42:52,719 INFO     Training average positive_sample_loss at step 40900: 0.075803\n",
      "2023-12-02 18:42:52,719 INFO     Training average negative_sample_loss at step 40900: 0.078295\n",
      "2023-12-02 18:42:52,719 INFO     Training average loss at step 40900: 0.077049\n",
      "2023-12-02 18:43:04,816 INFO     Training average positive_sample_loss at step 41000: 0.077513\n",
      "2023-12-02 18:43:04,817 INFO     Training average negative_sample_loss at step 41000: 0.079009\n",
      "2023-12-02 18:43:04,817 INFO     Training average loss at step 41000: 0.078261\n",
      "2023-12-02 18:43:16,737 INFO     Training average positive_sample_loss at step 41100: 0.077546\n",
      "2023-12-02 18:43:16,738 INFO     Training average negative_sample_loss at step 41100: 0.080444\n",
      "2023-12-02 18:43:16,738 INFO     Training average loss at step 41100: 0.078995\n",
      "2023-12-02 18:43:26,135 INFO     Training average positive_sample_loss at step 41200: 0.078360\n",
      "2023-12-02 18:43:26,135 INFO     Training average negative_sample_loss at step 41200: 0.080724\n",
      "2023-12-02 18:43:26,135 INFO     Training average loss at step 41200: 0.079542\n",
      "2023-12-02 18:43:37,928 INFO     Training average positive_sample_loss at step 41300: 0.078045\n",
      "2023-12-02 18:43:37,929 INFO     Training average negative_sample_loss at step 41300: 0.080286\n",
      "2023-12-02 18:43:37,929 INFO     Training average loss at step 41300: 0.079165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 18:43:49,933 INFO     Training average positive_sample_loss at step 41400: 0.078797\n",
      "2023-12-02 18:43:49,933 INFO     Training average negative_sample_loss at step 41400: 0.081221\n",
      "2023-12-02 18:43:49,933 INFO     Training average loss at step 41400: 0.080009\n",
      "2023-12-02 18:44:01,943 INFO     Training average positive_sample_loss at step 41500: 0.078089\n",
      "2023-12-02 18:44:01,944 INFO     Training average negative_sample_loss at step 41500: 0.081021\n",
      "2023-12-02 18:44:01,944 INFO     Training average loss at step 41500: 0.079555\n",
      "2023-12-02 18:44:13,067 INFO     Training average positive_sample_loss at step 41600: 0.074189\n",
      "2023-12-02 18:44:13,067 INFO     Training average negative_sample_loss at step 41600: 0.078845\n",
      "2023-12-02 18:44:13,067 INFO     Training average loss at step 41600: 0.076517\n",
      "2023-12-02 18:44:24,953 INFO     Training average positive_sample_loss at step 41700: 0.074517\n",
      "2023-12-02 18:44:24,953 INFO     Training average negative_sample_loss at step 41700: 0.076403\n",
      "2023-12-02 18:44:24,953 INFO     Training average loss at step 41700: 0.075460\n",
      "2023-12-02 18:44:36,925 INFO     Training average positive_sample_loss at step 41800: 0.075043\n",
      "2023-12-02 18:44:36,926 INFO     Training average negative_sample_loss at step 41800: 0.077333\n",
      "2023-12-02 18:44:36,926 INFO     Training average loss at step 41800: 0.076188\n",
      "2023-12-02 18:44:48,932 INFO     Training average positive_sample_loss at step 41900: 0.077117\n",
      "2023-12-02 18:44:48,932 INFO     Training average negative_sample_loss at step 41900: 0.078799\n",
      "2023-12-02 18:44:48,932 INFO     Training average loss at step 41900: 0.077958\n",
      "2023-12-02 18:44:57,993 INFO     Training average positive_sample_loss at step 42000: 0.076962\n",
      "2023-12-02 18:44:57,993 INFO     Training average negative_sample_loss at step 42000: 0.079336\n",
      "2023-12-02 18:44:57,993 INFO     Training average loss at step 42000: 0.078149\n",
      "2023-12-02 18:45:09,889 INFO     Training average positive_sample_loss at step 42100: 0.077793\n",
      "2023-12-02 18:45:09,889 INFO     Training average negative_sample_loss at step 42100: 0.079537\n",
      "2023-12-02 18:45:09,889 INFO     Training average loss at step 42100: 0.078665\n",
      "2023-12-02 18:45:21,717 INFO     Training average positive_sample_loss at step 42200: 0.077581\n",
      "2023-12-02 18:45:21,718 INFO     Training average negative_sample_loss at step 42200: 0.081056\n",
      "2023-12-02 18:45:21,718 INFO     Training average loss at step 42200: 0.079319\n",
      "2023-12-02 18:45:33,334 INFO     Training average positive_sample_loss at step 42300: 0.078664\n",
      "2023-12-02 18:45:33,334 INFO     Training average negative_sample_loss at step 42300: 0.080534\n",
      "2023-12-02 18:45:33,335 INFO     Training average loss at step 42300: 0.079599\n",
      "2023-12-02 18:45:42,777 INFO     Training average positive_sample_loss at step 42400: 0.078087\n",
      "2023-12-02 18:45:42,777 INFO     Training average negative_sample_loss at step 42400: 0.080765\n",
      "2023-12-02 18:45:42,778 INFO     Training average loss at step 42400: 0.079426\n",
      "2023-12-02 18:45:55,512 INFO     Training average positive_sample_loss at step 42500: 0.076486\n",
      "2023-12-02 18:45:55,512 INFO     Training average negative_sample_loss at step 42500: 0.081091\n",
      "2023-12-02 18:45:55,512 INFO     Training average loss at step 42500: 0.078788\n",
      "2023-12-02 18:46:07,488 INFO     Training average positive_sample_loss at step 42600: 0.073193\n",
      "2023-12-02 18:46:07,489 INFO     Training average negative_sample_loss at step 42600: 0.075804\n",
      "2023-12-02 18:46:07,489 INFO     Training average loss at step 42600: 0.074499\n",
      "2023-12-02 18:46:17,489 INFO     Training average positive_sample_loss at step 42700: 0.075493\n",
      "2023-12-02 18:46:17,490 INFO     Training average negative_sample_loss at step 42700: 0.077653\n",
      "2023-12-02 18:46:17,490 INFO     Training average loss at step 42700: 0.076573\n",
      "2023-12-02 18:46:28,580 INFO     Training average positive_sample_loss at step 42800: 0.076737\n",
      "2023-12-02 18:46:28,580 INFO     Training average negative_sample_loss at step 42800: 0.078556\n",
      "2023-12-02 18:46:28,580 INFO     Training average loss at step 42800: 0.077647\n",
      "2023-12-02 18:46:40,588 INFO     Training average positive_sample_loss at step 42900: 0.077179\n",
      "2023-12-02 18:46:40,588 INFO     Training average negative_sample_loss at step 42900: 0.078728\n",
      "2023-12-02 18:46:40,589 INFO     Training average loss at step 42900: 0.077953\n",
      "2023-12-02 18:46:52,607 INFO     Training average positive_sample_loss at step 43000: 0.077757\n",
      "2023-12-02 18:46:52,607 INFO     Training average negative_sample_loss at step 43000: 0.080444\n",
      "2023-12-02 18:46:52,607 INFO     Training average loss at step 43000: 0.079100\n",
      "2023-12-02 18:47:01,806 INFO     Training average positive_sample_loss at step 43100: 0.077528\n",
      "2023-12-02 18:47:01,807 INFO     Training average negative_sample_loss at step 43100: 0.079201\n",
      "2023-12-02 18:47:01,807 INFO     Training average loss at step 43100: 0.078365\n",
      "2023-12-02 18:47:13,638 INFO     Training average positive_sample_loss at step 43200: 0.077721\n",
      "2023-12-02 18:47:13,639 INFO     Training average negative_sample_loss at step 43200: 0.079863\n",
      "2023-12-02 18:47:13,639 INFO     Training average loss at step 43200: 0.078792\n",
      "2023-12-02 18:47:25,628 INFO     Training average positive_sample_loss at step 43300: 0.078450\n",
      "2023-12-02 18:47:25,628 INFO     Training average negative_sample_loss at step 43300: 0.081373\n",
      "2023-12-02 18:47:25,628 INFO     Training average loss at step 43300: 0.079912\n",
      "2023-12-02 18:47:37,595 INFO     Training average positive_sample_loss at step 43400: 0.078131\n",
      "2023-12-02 18:47:37,596 INFO     Training average negative_sample_loss at step 43400: 0.080938\n",
      "2023-12-02 18:47:37,596 INFO     Training average loss at step 43400: 0.079535\n",
      "2023-12-02 18:47:47,690 INFO     Training average positive_sample_loss at step 43500: 0.073135\n",
      "2023-12-02 18:47:47,690 INFO     Training average negative_sample_loss at step 43500: 0.078125\n",
      "2023-12-02 18:47:47,690 INFO     Training average loss at step 43500: 0.075630\n",
      "2023-12-02 18:47:59,724 INFO     Training average positive_sample_loss at step 43600: 0.074625\n",
      "2023-12-02 18:47:59,724 INFO     Training average negative_sample_loss at step 43600: 0.076118\n",
      "2023-12-02 18:47:59,724 INFO     Training average loss at step 43600: 0.075371\n",
      "2023-12-02 18:48:11,719 INFO     Training average positive_sample_loss at step 43700: 0.075852\n",
      "2023-12-02 18:48:11,719 INFO     Training average negative_sample_loss at step 43700: 0.077555\n",
      "2023-12-02 18:48:11,719 INFO     Training average loss at step 43700: 0.076703\n",
      "2023-12-02 18:48:23,722 INFO     Training average positive_sample_loss at step 43800: 0.077098\n",
      "2023-12-02 18:48:23,722 INFO     Training average negative_sample_loss at step 43800: 0.078100\n",
      "2023-12-02 18:48:23,722 INFO     Training average loss at step 43800: 0.077599\n",
      "2023-12-02 18:48:32,886 INFO     Training average positive_sample_loss at step 43900: 0.076888\n",
      "2023-12-02 18:48:32,887 INFO     Training average negative_sample_loss at step 43900: 0.079369\n",
      "2023-12-02 18:48:32,887 INFO     Training average loss at step 43900: 0.078128\n",
      "2023-12-02 18:48:44,855 INFO     Training average positive_sample_loss at step 44000: 0.077931\n",
      "2023-12-02 18:48:44,856 INFO     Training average negative_sample_loss at step 44000: 0.080698\n",
      "2023-12-02 18:48:44,856 INFO     Training average loss at step 44000: 0.079314\n",
      "2023-12-02 18:48:56,927 INFO     Training average positive_sample_loss at step 44100: 0.077562\n",
      "2023-12-02 18:48:56,927 INFO     Training average negative_sample_loss at step 44100: 0.080114\n",
      "2023-12-02 18:48:56,927 INFO     Training average loss at step 44100: 0.078838\n",
      "2023-12-02 18:49:08,961 INFO     Training average positive_sample_loss at step 44200: 0.078033\n",
      "2023-12-02 18:49:08,962 INFO     Training average negative_sample_loss at step 44200: 0.080541\n",
      "2023-12-02 18:49:08,962 INFO     Training average loss at step 44200: 0.079287\n",
      "2023-12-02 18:49:18,314 INFO     Training average positive_sample_loss at step 44300: 0.078077\n",
      "2023-12-02 18:49:18,314 INFO     Training average negative_sample_loss at step 44300: 0.080870\n",
      "2023-12-02 18:49:18,314 INFO     Training average loss at step 44300: 0.079473\n",
      "2023-12-02 18:49:31,109 INFO     Training average positive_sample_loss at step 44400: 0.075723\n",
      "2023-12-02 18:49:31,109 INFO     Training average negative_sample_loss at step 44400: 0.079943\n",
      "2023-12-02 18:49:31,109 INFO     Training average loss at step 44400: 0.077833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 18:49:42,979 INFO     Training average positive_sample_loss at step 44500: 0.073445\n",
      "2023-12-02 18:49:42,980 INFO     Training average negative_sample_loss at step 44500: 0.076348\n",
      "2023-12-02 18:49:42,980 INFO     Training average loss at step 44500: 0.074897\n",
      "2023-12-02 18:49:53,288 INFO     Training average positive_sample_loss at step 44600: 0.075214\n",
      "2023-12-02 18:49:53,288 INFO     Training average negative_sample_loss at step 44600: 0.077497\n",
      "2023-12-02 18:49:53,288 INFO     Training average loss at step 44600: 0.076355\n",
      "2023-12-02 18:50:04,113 INFO     Training average positive_sample_loss at step 44700: 0.076163\n",
      "2023-12-02 18:50:04,114 INFO     Training average negative_sample_loss at step 44700: 0.078769\n",
      "2023-12-02 18:50:04,114 INFO     Training average loss at step 44700: 0.077466\n",
      "2023-12-02 18:50:16,065 INFO     Training average positive_sample_loss at step 44800: 0.076545\n",
      "2023-12-02 18:50:16,065 INFO     Training average negative_sample_loss at step 44800: 0.077763\n",
      "2023-12-02 18:50:16,065 INFO     Training average loss at step 44800: 0.077154\n",
      "2023-12-02 18:50:28,127 INFO     Training average positive_sample_loss at step 44900: 0.077337\n",
      "2023-12-02 18:50:28,128 INFO     Training average negative_sample_loss at step 44900: 0.079763\n",
      "2023-12-02 18:50:28,128 INFO     Training average loss at step 44900: 0.078550\n",
      "2023-12-02 18:50:37,547 INFO     Training average positive_sample_loss at step 45000: 0.078018\n",
      "2023-12-02 18:50:37,547 INFO     Training average negative_sample_loss at step 45000: 0.080132\n",
      "2023-12-02 18:50:37,547 INFO     Training average loss at step 45000: 0.079075\n",
      "2023-12-02 18:50:49,464 INFO     Training average positive_sample_loss at step 45100: 0.077806\n",
      "2023-12-02 18:50:49,464 INFO     Training average negative_sample_loss at step 45100: 0.080001\n",
      "2023-12-02 18:50:49,464 INFO     Training average loss at step 45100: 0.078904\n",
      "2023-12-02 18:51:01,433 INFO     Training average positive_sample_loss at step 45200: 0.077854\n",
      "2023-12-02 18:51:01,434 INFO     Training average negative_sample_loss at step 45200: 0.080825\n",
      "2023-12-02 18:51:01,434 INFO     Training average loss at step 45200: 0.079339\n",
      "2023-12-02 18:51:13,393 INFO     Training average positive_sample_loss at step 45300: 0.077699\n",
      "2023-12-02 18:51:13,394 INFO     Training average negative_sample_loss at step 45300: 0.080680\n",
      "2023-12-02 18:51:13,394 INFO     Training average loss at step 45300: 0.079190\n",
      "2023-12-02 18:51:23,298 INFO     Training average positive_sample_loss at step 45400: 0.072434\n",
      "2023-12-02 18:51:23,298 INFO     Training average negative_sample_loss at step 45400: 0.077558\n",
      "2023-12-02 18:51:23,298 INFO     Training average loss at step 45400: 0.074996\n",
      "2023-12-02 18:51:35,395 INFO     Training average positive_sample_loss at step 45500: 0.074412\n",
      "2023-12-02 18:51:35,396 INFO     Training average negative_sample_loss at step 45500: 0.076606\n",
      "2023-12-02 18:51:35,396 INFO     Training average loss at step 45500: 0.075509\n",
      "2023-12-02 18:51:47,310 INFO     Training average positive_sample_loss at step 45600: 0.075984\n",
      "2023-12-02 18:51:47,310 INFO     Training average negative_sample_loss at step 45600: 0.077548\n",
      "2023-12-02 18:51:47,310 INFO     Training average loss at step 45600: 0.076766\n",
      "2023-12-02 18:51:59,141 INFO     Training average positive_sample_loss at step 45700: 0.076236\n",
      "2023-12-02 18:51:59,141 INFO     Training average negative_sample_loss at step 45700: 0.078378\n",
      "2023-12-02 18:51:59,142 INFO     Training average loss at step 45700: 0.077307\n",
      "2023-12-02 18:52:08,315 INFO     Training average positive_sample_loss at step 45800: 0.077137\n",
      "2023-12-02 18:52:08,315 INFO     Training average negative_sample_loss at step 45800: 0.079212\n",
      "2023-12-02 18:52:08,315 INFO     Training average loss at step 45800: 0.078174\n",
      "2023-12-02 18:52:20,339 INFO     Training average positive_sample_loss at step 45900: 0.078089\n",
      "2023-12-02 18:52:20,339 INFO     Training average negative_sample_loss at step 45900: 0.079245\n",
      "2023-12-02 18:52:20,339 INFO     Training average loss at step 45900: 0.078667\n",
      "2023-12-02 18:52:32,319 INFO     Training average positive_sample_loss at step 46000: 0.077698\n",
      "2023-12-02 18:52:32,320 INFO     Training average negative_sample_loss at step 46000: 0.080412\n",
      "2023-12-02 18:52:32,320 INFO     Training average loss at step 46000: 0.079055\n",
      "2023-12-02 18:52:44,321 INFO     Training average positive_sample_loss at step 46100: 0.077346\n",
      "2023-12-02 18:52:44,321 INFO     Training average negative_sample_loss at step 46100: 0.080195\n",
      "2023-12-02 18:52:44,321 INFO     Training average loss at step 46100: 0.078771\n",
      "2023-12-02 18:52:53,685 INFO     Training average positive_sample_loss at step 46200: 0.076981\n",
      "2023-12-02 18:52:53,685 INFO     Training average negative_sample_loss at step 46200: 0.078832\n",
      "2023-12-02 18:52:53,685 INFO     Training average loss at step 46200: 0.077907\n",
      "2023-12-02 18:53:06,251 INFO     Training average positive_sample_loss at step 46300: 0.074080\n",
      "2023-12-02 18:53:06,251 INFO     Training average negative_sample_loss at step 46300: 0.079280\n",
      "2023-12-02 18:53:06,251 INFO     Training average loss at step 46300: 0.076680\n",
      "2023-12-02 18:53:18,154 INFO     Training average positive_sample_loss at step 46400: 0.073876\n",
      "2023-12-02 18:53:18,154 INFO     Training average negative_sample_loss at step 46400: 0.075788\n",
      "2023-12-02 18:53:18,155 INFO     Training average loss at step 46400: 0.074832\n",
      "2023-12-02 18:53:28,872 INFO     Training average positive_sample_loss at step 46500: 0.075073\n",
      "2023-12-02 18:53:28,872 INFO     Training average negative_sample_loss at step 46500: 0.076758\n",
      "2023-12-02 18:53:28,872 INFO     Training average loss at step 46500: 0.075915\n",
      "2023-12-02 18:53:39,430 INFO     Training average positive_sample_loss at step 46600: 0.076546\n",
      "2023-12-02 18:53:39,431 INFO     Training average negative_sample_loss at step 46600: 0.078244\n",
      "2023-12-02 18:53:39,431 INFO     Training average loss at step 46600: 0.077395\n",
      "2023-12-02 18:53:51,230 INFO     Training average positive_sample_loss at step 46700: 0.076494\n",
      "2023-12-02 18:53:51,230 INFO     Training average negative_sample_loss at step 46700: 0.078710\n",
      "2023-12-02 18:53:51,230 INFO     Training average loss at step 46700: 0.077602\n",
      "2023-12-02 18:54:03,156 INFO     Training average positive_sample_loss at step 46800: 0.077491\n",
      "2023-12-02 18:54:03,157 INFO     Training average negative_sample_loss at step 46800: 0.079111\n",
      "2023-12-02 18:54:03,157 INFO     Training average loss at step 46800: 0.078301\n",
      "2023-12-02 18:54:13,206 INFO     Training average positive_sample_loss at step 46900: 0.076976\n",
      "2023-12-02 18:54:13,207 INFO     Training average negative_sample_loss at step 46900: 0.079174\n",
      "2023-12-02 18:54:13,207 INFO     Training average loss at step 46900: 0.078075\n",
      "2023-12-02 18:54:24,347 INFO     Training average positive_sample_loss at step 47000: 0.077074\n",
      "2023-12-02 18:54:24,347 INFO     Training average negative_sample_loss at step 47000: 0.078728\n",
      "2023-12-02 18:54:24,347 INFO     Training average loss at step 47000: 0.077901\n",
      "2023-12-02 18:54:36,325 INFO     Training average positive_sample_loss at step 47100: 0.078088\n",
      "2023-12-02 18:54:36,325 INFO     Training average negative_sample_loss at step 47100: 0.080418\n",
      "2023-12-02 18:54:36,325 INFO     Training average loss at step 47100: 0.079253\n",
      "2023-12-02 18:54:48,800 INFO     Training average positive_sample_loss at step 47200: 0.077236\n",
      "2023-12-02 18:54:48,800 INFO     Training average negative_sample_loss at step 47200: 0.079620\n",
      "2023-12-02 18:54:48,800 INFO     Training average loss at step 47200: 0.078428\n",
      "2023-12-02 18:54:58,458 INFO     Training average positive_sample_loss at step 47300: 0.072212\n",
      "2023-12-02 18:54:58,459 INFO     Training average negative_sample_loss at step 47300: 0.076421\n",
      "2023-12-02 18:54:58,459 INFO     Training average loss at step 47300: 0.074316\n",
      "2023-12-02 18:55:10,498 INFO     Training average positive_sample_loss at step 47400: 0.074153\n",
      "2023-12-02 18:55:10,498 INFO     Training average negative_sample_loss at step 47400: 0.075921\n",
      "2023-12-02 18:55:10,498 INFO     Training average loss at step 47400: 0.075037\n",
      "2023-12-02 18:55:22,506 INFO     Training average positive_sample_loss at step 47500: 0.075052\n",
      "2023-12-02 18:55:22,506 INFO     Training average negative_sample_loss at step 47500: 0.076585\n",
      "2023-12-02 18:55:22,506 INFO     Training average loss at step 47500: 0.075819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 18:55:34,365 INFO     Training average positive_sample_loss at step 47600: 0.076008\n",
      "2023-12-02 18:55:34,365 INFO     Training average negative_sample_loss at step 47600: 0.077776\n",
      "2023-12-02 18:55:34,365 INFO     Training average loss at step 47600: 0.076892\n",
      "2023-12-02 18:55:43,746 INFO     Training average positive_sample_loss at step 47700: 0.076795\n",
      "2023-12-02 18:55:43,747 INFO     Training average negative_sample_loss at step 47700: 0.078600\n",
      "2023-12-02 18:55:43,747 INFO     Training average loss at step 47700: 0.077698\n",
      "2023-12-02 18:55:55,687 INFO     Training average positive_sample_loss at step 47800: 0.077275\n",
      "2023-12-02 18:55:55,688 INFO     Training average negative_sample_loss at step 47800: 0.079637\n",
      "2023-12-02 18:55:55,688 INFO     Training average loss at step 47800: 0.078456\n",
      "2023-12-02 18:56:07,657 INFO     Training average positive_sample_loss at step 47900: 0.078064\n",
      "2023-12-02 18:56:07,657 INFO     Training average negative_sample_loss at step 47900: 0.079731\n",
      "2023-12-02 18:56:07,657 INFO     Training average loss at step 47900: 0.078897\n",
      "2023-12-02 18:56:19,471 INFO     Training average positive_sample_loss at step 48000: 0.077365\n",
      "2023-12-02 18:56:19,472 INFO     Training average negative_sample_loss at step 48000: 0.079600\n",
      "2023-12-02 18:56:19,472 INFO     Training average loss at step 48000: 0.078482\n",
      "2023-12-02 18:56:28,613 INFO     Training average positive_sample_loss at step 48100: 0.078019\n",
      "2023-12-02 18:56:28,613 INFO     Training average negative_sample_loss at step 48100: 0.080434\n",
      "2023-12-02 18:56:28,613 INFO     Training average loss at step 48100: 0.079227\n",
      "2023-12-02 18:56:41,399 INFO     Training average positive_sample_loss at step 48200: 0.073683\n",
      "2023-12-02 18:56:41,399 INFO     Training average negative_sample_loss at step 48200: 0.078646\n",
      "2023-12-02 18:56:41,399 INFO     Training average loss at step 48200: 0.076165\n",
      "2023-12-02 18:56:53,355 INFO     Training average positive_sample_loss at step 48300: 0.073863\n",
      "2023-12-02 18:56:53,355 INFO     Training average negative_sample_loss at step 48300: 0.076097\n",
      "2023-12-02 18:56:53,355 INFO     Training average loss at step 48300: 0.074980\n",
      "2023-12-02 18:57:04,625 INFO     Training average positive_sample_loss at step 48400: 0.075415\n",
      "2023-12-02 18:57:04,625 INFO     Training average negative_sample_loss at step 48400: 0.077211\n",
      "2023-12-02 18:57:04,626 INFO     Training average loss at step 48400: 0.076313\n",
      "2023-12-02 18:57:14,621 INFO     Training average positive_sample_loss at step 48500: 0.076255\n",
      "2023-12-02 18:57:14,622 INFO     Training average negative_sample_loss at step 48500: 0.077011\n",
      "2023-12-02 18:57:14,622 INFO     Training average loss at step 48500: 0.076633\n",
      "2023-12-02 18:57:26,569 INFO     Training average positive_sample_loss at step 48600: 0.076204\n",
      "2023-12-02 18:57:26,569 INFO     Training average negative_sample_loss at step 48600: 0.077821\n",
      "2023-12-02 18:57:26,569 INFO     Training average loss at step 48600: 0.077013\n",
      "2023-12-02 18:57:38,372 INFO     Training average positive_sample_loss at step 48700: 0.077401\n",
      "2023-12-02 18:57:38,373 INFO     Training average negative_sample_loss at step 48700: 0.079458\n",
      "2023-12-02 18:57:38,373 INFO     Training average loss at step 48700: 0.078429\n",
      "2023-12-02 18:57:48,912 INFO     Training average positive_sample_loss at step 48800: 0.077702\n",
      "2023-12-02 18:57:48,912 INFO     Training average negative_sample_loss at step 48800: 0.078949\n",
      "2023-12-02 18:57:48,912 INFO     Training average loss at step 48800: 0.078325\n",
      "2023-12-02 18:57:59,424 INFO     Training average positive_sample_loss at step 48900: 0.077427\n",
      "2023-12-02 18:57:59,424 INFO     Training average negative_sample_loss at step 48900: 0.080076\n",
      "2023-12-02 18:57:59,424 INFO     Training average loss at step 48900: 0.078751\n",
      "2023-12-02 18:58:11,292 INFO     Training average positive_sample_loss at step 49000: 0.077150\n",
      "2023-12-02 18:58:11,292 INFO     Training average negative_sample_loss at step 49000: 0.079889\n",
      "2023-12-02 18:58:11,292 INFO     Training average loss at step 49000: 0.078520\n",
      "2023-12-02 18:58:23,974 INFO     Training average positive_sample_loss at step 49100: 0.076511\n",
      "2023-12-02 18:58:23,975 INFO     Training average negative_sample_loss at step 49100: 0.079909\n",
      "2023-12-02 18:58:23,975 INFO     Training average loss at step 49100: 0.078210\n",
      "2023-12-02 18:58:31,114 INFO     Training average positive_sample_loss at step 49200: 0.072686\n",
      "2023-12-02 18:58:31,114 INFO     Training average negative_sample_loss at step 49200: 0.074583\n",
      "2023-12-02 18:58:31,114 INFO     Training average loss at step 49200: 0.073635\n",
      "2023-12-02 18:58:39,525 INFO     Training average positive_sample_loss at step 49300: 0.074108\n",
      "2023-12-02 18:58:39,525 INFO     Training average negative_sample_loss at step 49300: 0.076132\n",
      "2023-12-02 18:58:39,525 INFO     Training average loss at step 49300: 0.075120\n",
      "2023-12-02 18:58:48,034 INFO     Training average positive_sample_loss at step 49400: 0.075336\n",
      "2023-12-02 18:58:48,035 INFO     Training average negative_sample_loss at step 49400: 0.077235\n",
      "2023-12-02 18:58:48,035 INFO     Training average loss at step 49400: 0.076286\n",
      "2023-12-02 18:58:56,388 INFO     Training average positive_sample_loss at step 49500: 0.076139\n",
      "2023-12-02 18:58:56,388 INFO     Training average negative_sample_loss at step 49500: 0.077750\n",
      "2023-12-02 18:58:56,388 INFO     Training average loss at step 49500: 0.076944\n",
      "2023-12-02 18:59:04,938 INFO     Training average positive_sample_loss at step 49600: 0.076743\n",
      "2023-12-02 18:59:04,938 INFO     Training average negative_sample_loss at step 49600: 0.077860\n",
      "2023-12-02 18:59:04,938 INFO     Training average loss at step 49600: 0.077301\n",
      "2023-12-02 18:59:13,115 INFO     Training average positive_sample_loss at step 49700: 0.077250\n",
      "2023-12-02 18:59:13,115 INFO     Training average negative_sample_loss at step 49700: 0.079243\n",
      "2023-12-02 18:59:13,115 INFO     Training average loss at step 49700: 0.078246\n",
      "2023-12-02 18:59:21,711 INFO     Training average positive_sample_loss at step 49800: 0.077259\n",
      "2023-12-02 18:59:21,711 INFO     Training average negative_sample_loss at step 49800: 0.079373\n",
      "2023-12-02 18:59:21,711 INFO     Training average loss at step 49800: 0.078316\n",
      "2023-12-02 18:59:33,328 INFO     Training average positive_sample_loss at step 49900: 0.077629\n",
      "2023-12-02 18:59:33,328 INFO     Training average negative_sample_loss at step 49900: 0.079468\n",
      "2023-12-02 18:59:33,328 INFO     Training average loss at step 49900: 0.078548\n",
      "2023-12-02 18:59:56,055 INFO     Training average positive_sample_loss at step 50000: 0.077122\n",
      "2023-12-02 18:59:56,056 INFO     Training average negative_sample_loss at step 50000: 0.079409\n",
      "2023-12-02 18:59:56,056 INFO     Training average loss at step 50000: 0.078266\n",
      "2023-12-02 18:59:56,056 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 18:59:56,958 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 19:01:07,981 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 19:02:19,575 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 19:03:33,452 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 19:04:47,811 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 19:05:59,992 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 19:07:15,269 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 19:07:30,795 INFO     Valid MRR at step 50000: 0.744142\n",
      "2023-12-02 19:07:30,795 INFO     Valid MR at step 50000: 49.066940\n",
      "2023-12-02 19:07:30,795 INFO     Valid HITS@1 at step 50000: 0.678740\n",
      "2023-12-02 19:07:30,796 INFO     Valid HITS@3 at step 50000: 0.786170\n",
      "2023-12-02 19:07:30,796 INFO     Valid HITS@10 at step 50000: 0.857700\n",
      "2023-12-02 19:07:43,132 INFO     Training average positive_sample_loss at step 50100: 0.072927\n",
      "2023-12-02 19:07:43,132 INFO     Training average negative_sample_loss at step 50100: 0.076635\n",
      "2023-12-02 19:07:43,132 INFO     Training average loss at step 50100: 0.074781\n",
      "2023-12-02 19:07:54,806 INFO     Training average positive_sample_loss at step 50200: 0.073927\n",
      "2023-12-02 19:07:54,807 INFO     Training average negative_sample_loss at step 50200: 0.076165\n",
      "2023-12-02 19:07:54,807 INFO     Training average loss at step 50200: 0.075046\n",
      "2023-12-02 19:08:06,577 INFO     Training average positive_sample_loss at step 50300: 0.074931\n",
      "2023-12-02 19:08:06,578 INFO     Training average negative_sample_loss at step 50300: 0.077421\n",
      "2023-12-02 19:08:06,578 INFO     Training average loss at step 50300: 0.076176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 19:08:15,820 INFO     Training average positive_sample_loss at step 50400: 0.076252\n",
      "2023-12-02 19:08:15,820 INFO     Training average negative_sample_loss at step 50400: 0.077855\n",
      "2023-12-02 19:08:15,820 INFO     Training average loss at step 50400: 0.077054\n",
      "2023-12-02 19:08:27,701 INFO     Training average positive_sample_loss at step 50500: 0.076647\n",
      "2023-12-02 19:08:27,701 INFO     Training average negative_sample_loss at step 50500: 0.077832\n",
      "2023-12-02 19:08:27,701 INFO     Training average loss at step 50500: 0.077239\n",
      "2023-12-02 19:08:39,513 INFO     Training average positive_sample_loss at step 50600: 0.076823\n",
      "2023-12-02 19:08:39,514 INFO     Training average negative_sample_loss at step 50600: 0.078366\n",
      "2023-12-02 19:08:39,514 INFO     Training average loss at step 50600: 0.077595\n",
      "2023-12-02 19:08:51,272 INFO     Training average positive_sample_loss at step 50700: 0.077017\n",
      "2023-12-02 19:08:51,272 INFO     Training average negative_sample_loss at step 50700: 0.078839\n",
      "2023-12-02 19:08:51,272 INFO     Training average loss at step 50700: 0.077928\n",
      "2023-12-02 19:09:00,514 INFO     Training average positive_sample_loss at step 50800: 0.077304\n",
      "2023-12-02 19:09:00,515 INFO     Training average negative_sample_loss at step 50800: 0.079349\n",
      "2023-12-02 19:09:00,515 INFO     Training average loss at step 50800: 0.078326\n",
      "2023-12-02 19:09:12,265 INFO     Training average positive_sample_loss at step 50900: 0.077552\n",
      "2023-12-02 19:09:12,266 INFO     Training average negative_sample_loss at step 50900: 0.079298\n",
      "2023-12-02 19:09:12,266 INFO     Training average loss at step 50900: 0.078425\n",
      "2023-12-02 19:09:24,684 INFO     Training average positive_sample_loss at step 51000: 0.075498\n",
      "2023-12-02 19:09:24,684 INFO     Training average negative_sample_loss at step 51000: 0.078948\n",
      "2023-12-02 19:09:24,684 INFO     Training average loss at step 51000: 0.077223\n",
      "2023-12-02 19:09:36,558 INFO     Training average positive_sample_loss at step 51100: 0.072901\n",
      "2023-12-02 19:09:36,559 INFO     Training average negative_sample_loss at step 51100: 0.075198\n",
      "2023-12-02 19:09:36,559 INFO     Training average loss at step 51100: 0.074049\n",
      "2023-12-02 19:09:45,901 INFO     Training average positive_sample_loss at step 51200: 0.074250\n",
      "2023-12-02 19:09:45,902 INFO     Training average negative_sample_loss at step 51200: 0.075589\n",
      "2023-12-02 19:09:45,902 INFO     Training average loss at step 51200: 0.074920\n",
      "2023-12-02 19:09:57,676 INFO     Training average positive_sample_loss at step 51300: 0.074870\n",
      "2023-12-02 19:09:57,676 INFO     Training average negative_sample_loss at step 51300: 0.076498\n",
      "2023-12-02 19:09:57,676 INFO     Training average loss at step 51300: 0.075684\n",
      "2023-12-02 19:10:09,601 INFO     Training average positive_sample_loss at step 51400: 0.076363\n",
      "2023-12-02 19:10:09,601 INFO     Training average negative_sample_loss at step 51400: 0.077359\n",
      "2023-12-02 19:10:09,601 INFO     Training average loss at step 51400: 0.076861\n",
      "2023-12-02 19:10:21,515 INFO     Training average positive_sample_loss at step 51500: 0.076625\n",
      "2023-12-02 19:10:21,515 INFO     Training average negative_sample_loss at step 51500: 0.077151\n",
      "2023-12-02 19:10:21,515 INFO     Training average loss at step 51500: 0.076888\n",
      "2023-12-02 19:10:30,901 INFO     Training average positive_sample_loss at step 51600: 0.076286\n",
      "2023-12-02 19:10:30,901 INFO     Training average negative_sample_loss at step 51600: 0.077869\n",
      "2023-12-02 19:10:30,902 INFO     Training average loss at step 51600: 0.077078\n",
      "2023-12-02 19:10:42,849 INFO     Training average positive_sample_loss at step 51700: 0.076891\n",
      "2023-12-02 19:10:42,849 INFO     Training average negative_sample_loss at step 51700: 0.079248\n",
      "2023-12-02 19:10:42,849 INFO     Training average loss at step 51700: 0.078069\n",
      "2023-12-02 19:10:54,974 INFO     Training average positive_sample_loss at step 51800: 0.076626\n",
      "2023-12-02 19:10:54,974 INFO     Training average negative_sample_loss at step 51800: 0.078414\n",
      "2023-12-02 19:10:54,974 INFO     Training average loss at step 51800: 0.077520\n",
      "2023-12-02 19:11:05,869 INFO     Training average positive_sample_loss at step 51900: 0.077093\n",
      "2023-12-02 19:11:05,870 INFO     Training average negative_sample_loss at step 51900: 0.079274\n",
      "2023-12-02 19:11:05,870 INFO     Training average loss at step 51900: 0.078183\n",
      "2023-12-02 19:11:17,089 INFO     Training average positive_sample_loss at step 52000: 0.072393\n",
      "2023-12-02 19:11:17,089 INFO     Training average negative_sample_loss at step 52000: 0.077095\n",
      "2023-12-02 19:11:17,089 INFO     Training average loss at step 52000: 0.074744\n",
      "2023-12-02 19:11:28,804 INFO     Training average positive_sample_loss at step 52100: 0.073947\n",
      "2023-12-02 19:11:28,804 INFO     Training average negative_sample_loss at step 52100: 0.075006\n",
      "2023-12-02 19:11:28,804 INFO     Training average loss at step 52100: 0.074476\n",
      "2023-12-02 19:11:40,531 INFO     Training average positive_sample_loss at step 52200: 0.075178\n",
      "2023-12-02 19:11:40,532 INFO     Training average negative_sample_loss at step 52200: 0.075837\n",
      "2023-12-02 19:11:40,532 INFO     Training average loss at step 52200: 0.075508\n",
      "2023-12-02 19:11:50,438 INFO     Training average positive_sample_loss at step 52300: 0.075792\n",
      "2023-12-02 19:11:50,439 INFO     Training average negative_sample_loss at step 52300: 0.077750\n",
      "2023-12-02 19:11:50,439 INFO     Training average loss at step 52300: 0.076771\n",
      "2023-12-02 19:12:01,487 INFO     Training average positive_sample_loss at step 52400: 0.076571\n",
      "2023-12-02 19:12:01,487 INFO     Training average negative_sample_loss at step 52400: 0.077627\n",
      "2023-12-02 19:12:01,487 INFO     Training average loss at step 52400: 0.077099\n",
      "2023-12-02 19:12:13,258 INFO     Training average positive_sample_loss at step 52500: 0.076185\n",
      "2023-12-02 19:12:13,258 INFO     Training average negative_sample_loss at step 52500: 0.077507\n",
      "2023-12-02 19:12:13,258 INFO     Training average loss at step 52500: 0.076846\n",
      "2023-12-02 19:12:25,000 INFO     Training average positive_sample_loss at step 52600: 0.076962\n",
      "2023-12-02 19:12:25,000 INFO     Training average negative_sample_loss at step 52600: 0.078647\n",
      "2023-12-02 19:12:25,000 INFO     Training average loss at step 52600: 0.077804\n",
      "2023-12-02 19:12:34,746 INFO     Training average positive_sample_loss at step 52700: 0.077539\n",
      "2023-12-02 19:12:34,747 INFO     Training average negative_sample_loss at step 52700: 0.079442\n",
      "2023-12-02 19:12:34,747 INFO     Training average loss at step 52700: 0.078490\n",
      "2023-12-02 19:12:45,869 INFO     Training average positive_sample_loss at step 52800: 0.076942\n",
      "2023-12-02 19:12:45,869 INFO     Training average negative_sample_loss at step 52800: 0.079357\n",
      "2023-12-02 19:12:45,869 INFO     Training average loss at step 52800: 0.078150\n",
      "2023-12-02 19:12:58,354 INFO     Training average positive_sample_loss at step 52900: 0.074259\n",
      "2023-12-02 19:12:58,354 INFO     Training average negative_sample_loss at step 52900: 0.078244\n",
      "2023-12-02 19:12:58,354 INFO     Training average loss at step 52900: 0.076251\n",
      "2023-12-02 19:13:10,188 INFO     Training average positive_sample_loss at step 53000: 0.073086\n",
      "2023-12-02 19:13:10,188 INFO     Training average negative_sample_loss at step 53000: 0.074940\n",
      "2023-12-02 19:13:10,189 INFO     Training average loss at step 53000: 0.074013\n",
      "2023-12-02 19:13:19,327 INFO     Training average positive_sample_loss at step 53100: 0.074678\n",
      "2023-12-02 19:13:19,327 INFO     Training average negative_sample_loss at step 53100: 0.075768\n",
      "2023-12-02 19:13:19,327 INFO     Training average loss at step 53100: 0.075223\n",
      "2023-12-02 19:13:31,056 INFO     Training average positive_sample_loss at step 53200: 0.075226\n",
      "2023-12-02 19:13:31,056 INFO     Training average negative_sample_loss at step 53200: 0.076254\n",
      "2023-12-02 19:13:31,056 INFO     Training average loss at step 53200: 0.075740\n",
      "2023-12-02 19:13:42,806 INFO     Training average positive_sample_loss at step 53300: 0.075717\n",
      "2023-12-02 19:13:42,807 INFO     Training average negative_sample_loss at step 53300: 0.076811\n",
      "2023-12-02 19:13:42,807 INFO     Training average loss at step 53300: 0.076264\n",
      "2023-12-02 19:13:54,670 INFO     Training average positive_sample_loss at step 53400: 0.076257\n",
      "2023-12-02 19:13:54,671 INFO     Training average negative_sample_loss at step 53400: 0.077670\n",
      "2023-12-02 19:13:54,671 INFO     Training average loss at step 53400: 0.076963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 19:14:03,814 INFO     Training average positive_sample_loss at step 53500: 0.076885\n",
      "2023-12-02 19:14:03,814 INFO     Training average negative_sample_loss at step 53500: 0.078721\n",
      "2023-12-02 19:14:03,814 INFO     Training average loss at step 53500: 0.077803\n",
      "2023-12-02 19:14:15,617 INFO     Training average positive_sample_loss at step 53600: 0.076778\n",
      "2023-12-02 19:14:15,618 INFO     Training average negative_sample_loss at step 53600: 0.079074\n",
      "2023-12-02 19:14:15,618 INFO     Training average loss at step 53600: 0.077926\n",
      "2023-12-02 19:14:27,638 INFO     Training average positive_sample_loss at step 53700: 0.077047\n",
      "2023-12-02 19:14:27,638 INFO     Training average negative_sample_loss at step 53700: 0.078317\n",
      "2023-12-02 19:14:27,638 INFO     Training average loss at step 53700: 0.077682\n",
      "2023-12-02 19:14:39,477 INFO     Training average positive_sample_loss at step 53800: 0.076957\n",
      "2023-12-02 19:14:39,477 INFO     Training average negative_sample_loss at step 53800: 0.079212\n",
      "2023-12-02 19:14:39,477 INFO     Training average loss at step 53800: 0.078084\n",
      "2023-12-02 19:14:49,340 INFO     Training average positive_sample_loss at step 53900: 0.072017\n",
      "2023-12-02 19:14:49,340 INFO     Training average negative_sample_loss at step 53900: 0.075844\n",
      "2023-12-02 19:14:49,341 INFO     Training average loss at step 53900: 0.073930\n",
      "2023-12-02 19:15:01,389 INFO     Training average positive_sample_loss at step 54000: 0.073276\n",
      "2023-12-02 19:15:01,389 INFO     Training average negative_sample_loss at step 54000: 0.074871\n",
      "2023-12-02 19:15:01,389 INFO     Training average loss at step 54000: 0.074074\n",
      "2023-12-02 19:15:13,442 INFO     Training average positive_sample_loss at step 54100: 0.074657\n",
      "2023-12-02 19:15:13,442 INFO     Training average negative_sample_loss at step 54100: 0.075764\n",
      "2023-12-02 19:15:13,442 INFO     Training average loss at step 54100: 0.075211\n",
      "2023-12-02 19:15:25,298 INFO     Training average positive_sample_loss at step 54200: 0.075231\n",
      "2023-12-02 19:15:25,298 INFO     Training average negative_sample_loss at step 54200: 0.076167\n",
      "2023-12-02 19:15:25,298 INFO     Training average loss at step 54200: 0.075699\n",
      "2023-12-02 19:15:34,509 INFO     Training average positive_sample_loss at step 54300: 0.075545\n",
      "2023-12-02 19:15:34,510 INFO     Training average negative_sample_loss at step 54300: 0.077361\n",
      "2023-12-02 19:15:34,510 INFO     Training average loss at step 54300: 0.076453\n",
      "2023-12-02 19:15:46,578 INFO     Training average positive_sample_loss at step 54400: 0.076648\n",
      "2023-12-02 19:15:46,579 INFO     Training average negative_sample_loss at step 54400: 0.077750\n",
      "2023-12-02 19:15:46,579 INFO     Training average loss at step 54400: 0.077199\n",
      "2023-12-02 19:15:58,657 INFO     Training average positive_sample_loss at step 54500: 0.076544\n",
      "2023-12-02 19:15:58,658 INFO     Training average negative_sample_loss at step 54500: 0.077680\n",
      "2023-12-02 19:15:58,658 INFO     Training average loss at step 54500: 0.077112\n",
      "2023-12-02 19:16:10,509 INFO     Training average positive_sample_loss at step 54600: 0.077031\n",
      "2023-12-02 19:16:10,509 INFO     Training average negative_sample_loss at step 54600: 0.078558\n",
      "2023-12-02 19:16:10,509 INFO     Training average loss at step 54600: 0.077795\n",
      "2023-12-02 19:16:19,731 INFO     Training average positive_sample_loss at step 54700: 0.077371\n",
      "2023-12-02 19:16:19,732 INFO     Training average negative_sample_loss at step 54700: 0.080049\n",
      "2023-12-02 19:16:19,732 INFO     Training average loss at step 54700: 0.078710\n",
      "2023-12-02 19:16:32,443 INFO     Training average positive_sample_loss at step 54800: 0.073139\n",
      "2023-12-02 19:16:32,444 INFO     Training average negative_sample_loss at step 54800: 0.077247\n",
      "2023-12-02 19:16:32,444 INFO     Training average loss at step 54800: 0.075193\n",
      "2023-12-02 19:16:44,171 INFO     Training average positive_sample_loss at step 54900: 0.073021\n",
      "2023-12-02 19:16:44,172 INFO     Training average negative_sample_loss at step 54900: 0.074336\n",
      "2023-12-02 19:16:44,172 INFO     Training average loss at step 54900: 0.073679\n",
      "2023-12-02 19:16:54,631 INFO     Training average positive_sample_loss at step 55000: 0.074215\n",
      "2023-12-02 19:16:54,631 INFO     Training average negative_sample_loss at step 55000: 0.075041\n",
      "2023-12-02 19:16:54,631 INFO     Training average loss at step 55000: 0.074628\n",
      "2023-12-02 19:17:05,270 INFO     Training average positive_sample_loss at step 55100: 0.075262\n",
      "2023-12-02 19:17:05,270 INFO     Training average negative_sample_loss at step 55100: 0.077785\n",
      "2023-12-02 19:17:05,270 INFO     Training average loss at step 55100: 0.076524\n",
      "2023-12-02 19:17:17,415 INFO     Training average positive_sample_loss at step 55200: 0.075709\n",
      "2023-12-02 19:17:17,415 INFO     Training average negative_sample_loss at step 55200: 0.076454\n",
      "2023-12-02 19:17:17,415 INFO     Training average loss at step 55200: 0.076081\n",
      "2023-12-02 19:17:29,471 INFO     Training average positive_sample_loss at step 55300: 0.076606\n",
      "2023-12-02 19:17:29,471 INFO     Training average negative_sample_loss at step 55300: 0.077966\n",
      "2023-12-02 19:17:29,471 INFO     Training average loss at step 55300: 0.077286\n",
      "2023-12-02 19:17:39,088 INFO     Training average positive_sample_loss at step 55400: 0.076794\n",
      "2023-12-02 19:17:39,088 INFO     Training average negative_sample_loss at step 55400: 0.077792\n",
      "2023-12-02 19:17:39,088 INFO     Training average loss at step 55400: 0.077293\n",
      "2023-12-02 19:17:50,531 INFO     Training average positive_sample_loss at step 55500: 0.076948\n",
      "2023-12-02 19:17:50,531 INFO     Training average negative_sample_loss at step 55500: 0.078847\n",
      "2023-12-02 19:17:50,531 INFO     Training average loss at step 55500: 0.077898\n",
      "2023-12-02 19:17:57,191 INFO     Training average positive_sample_loss at step 55600: 0.076323\n",
      "2023-12-02 19:17:57,255 INFO     Training average negative_sample_loss at step 55600: 0.077849\n",
      "2023-12-02 19:17:57,255 INFO     Training average loss at step 55600: 0.077086\n",
      "2023-12-02 19:18:05,087 INFO     Training average positive_sample_loss at step 55700: 0.076103\n",
      "2023-12-02 19:18:05,087 INFO     Training average negative_sample_loss at step 55700: 0.079429\n",
      "2023-12-02 19:18:05,087 INFO     Training average loss at step 55700: 0.077766\n",
      "2023-12-02 19:18:12,999 INFO     Training average positive_sample_loss at step 55800: 0.071309\n",
      "2023-12-02 19:18:12,999 INFO     Training average negative_sample_loss at step 55800: 0.074536\n",
      "2023-12-02 19:18:12,999 INFO     Training average loss at step 55800: 0.072923\n",
      "2023-12-02 19:18:21,395 INFO     Training average positive_sample_loss at step 55900: 0.073602\n",
      "2023-12-02 19:18:21,395 INFO     Training average negative_sample_loss at step 55900: 0.074335\n",
      "2023-12-02 19:18:21,395 INFO     Training average loss at step 55900: 0.073969\n",
      "2023-12-02 19:18:29,581 INFO     Training average positive_sample_loss at step 56000: 0.074764\n",
      "2023-12-02 19:18:29,581 INFO     Training average negative_sample_loss at step 56000: 0.076015\n",
      "2023-12-02 19:18:29,581 INFO     Training average loss at step 56000: 0.075389\n",
      "2023-12-02 19:18:38,077 INFO     Training average positive_sample_loss at step 56100: 0.075576\n",
      "2023-12-02 19:18:38,077 INFO     Training average negative_sample_loss at step 56100: 0.076496\n",
      "2023-12-02 19:18:38,077 INFO     Training average loss at step 56100: 0.076036\n",
      "2023-12-02 19:18:46,809 INFO     Training average positive_sample_loss at step 56200: 0.076171\n",
      "2023-12-02 19:18:46,809 INFO     Training average negative_sample_loss at step 56200: 0.076701\n",
      "2023-12-02 19:18:46,809 INFO     Training average loss at step 56200: 0.076436\n",
      "2023-12-02 19:18:55,122 INFO     Training average positive_sample_loss at step 56300: 0.076237\n",
      "2023-12-02 19:18:55,122 INFO     Training average negative_sample_loss at step 56300: 0.077831\n",
      "2023-12-02 19:18:55,123 INFO     Training average loss at step 56300: 0.077034\n",
      "2023-12-02 19:19:03,777 INFO     Training average positive_sample_loss at step 56400: 0.076863\n",
      "2023-12-02 19:19:03,777 INFO     Training average negative_sample_loss at step 56400: 0.079460\n",
      "2023-12-02 19:19:03,777 INFO     Training average loss at step 56400: 0.078162\n",
      "2023-12-02 19:19:12,087 INFO     Training average positive_sample_loss at step 56500: 0.076582\n",
      "2023-12-02 19:19:12,087 INFO     Training average negative_sample_loss at step 56500: 0.077360\n",
      "2023-12-02 19:19:12,087 INFO     Training average loss at step 56500: 0.076971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 19:19:20,698 INFO     Training average positive_sample_loss at step 56600: 0.076814\n",
      "2023-12-02 19:19:20,699 INFO     Training average negative_sample_loss at step 56600: 0.079288\n",
      "2023-12-02 19:19:20,699 INFO     Training average loss at step 56600: 0.078051\n",
      "2023-12-02 19:19:28,621 INFO     Training average positive_sample_loss at step 56700: 0.072750\n",
      "2023-12-02 19:19:28,621 INFO     Training average negative_sample_loss at step 56700: 0.077399\n",
      "2023-12-02 19:19:28,621 INFO     Training average loss at step 56700: 0.075074\n",
      "2023-12-02 19:19:34,042 INFO     Training average positive_sample_loss at step 56800: 0.072980\n",
      "2023-12-02 19:19:34,043 INFO     Training average negative_sample_loss at step 56800: 0.074372\n",
      "2023-12-02 19:19:34,043 INFO     Training average loss at step 56800: 0.073676\n",
      "2023-12-02 19:19:42,305 INFO     Training average positive_sample_loss at step 56900: 0.074543\n",
      "2023-12-02 19:19:42,305 INFO     Training average negative_sample_loss at step 56900: 0.074822\n",
      "2023-12-02 19:19:42,305 INFO     Training average loss at step 56900: 0.074682\n",
      "2023-12-02 19:19:50,115 INFO     Training average positive_sample_loss at step 57000: 0.074689\n",
      "2023-12-02 19:19:50,115 INFO     Training average negative_sample_loss at step 57000: 0.075842\n",
      "2023-12-02 19:19:50,115 INFO     Training average loss at step 57000: 0.075266\n",
      "2023-12-02 19:19:58,725 INFO     Training average positive_sample_loss at step 57100: 0.075649\n",
      "2023-12-02 19:19:58,725 INFO     Training average negative_sample_loss at step 57100: 0.077151\n",
      "2023-12-02 19:19:58,725 INFO     Training average loss at step 57100: 0.076400\n",
      "2023-12-02 19:20:07,261 INFO     Training average positive_sample_loss at step 57200: 0.076070\n",
      "2023-12-02 19:20:07,261 INFO     Training average negative_sample_loss at step 57200: 0.077547\n",
      "2023-12-02 19:20:07,261 INFO     Training average loss at step 57200: 0.076809\n",
      "2023-12-02 19:20:15,809 INFO     Training average positive_sample_loss at step 57300: 0.076289\n",
      "2023-12-02 19:20:15,809 INFO     Training average negative_sample_loss at step 57300: 0.077670\n",
      "2023-12-02 19:20:15,809 INFO     Training average loss at step 57300: 0.076980\n",
      "2023-12-02 19:20:24,289 INFO     Training average positive_sample_loss at step 57400: 0.076146\n",
      "2023-12-02 19:20:24,289 INFO     Training average negative_sample_loss at step 57400: 0.077536\n",
      "2023-12-02 19:20:24,289 INFO     Training average loss at step 57400: 0.076841\n",
      "2023-12-02 19:20:35,640 INFO     Training average positive_sample_loss at step 57500: 0.076767\n",
      "2023-12-02 19:20:35,641 INFO     Training average negative_sample_loss at step 57500: 0.078576\n",
      "2023-12-02 19:20:35,641 INFO     Training average loss at step 57500: 0.077671\n",
      "2023-12-02 19:20:48,253 INFO     Training average positive_sample_loss at step 57600: 0.075073\n",
      "2023-12-02 19:20:48,253 INFO     Training average negative_sample_loss at step 57600: 0.079176\n",
      "2023-12-02 19:20:48,253 INFO     Training average loss at step 57600: 0.077124\n",
      "2023-12-02 19:21:00,253 INFO     Training average positive_sample_loss at step 57700: 0.072792\n",
      "2023-12-02 19:21:00,253 INFO     Training average negative_sample_loss at step 57700: 0.075311\n",
      "2023-12-02 19:21:00,253 INFO     Training average loss at step 57700: 0.074051\n",
      "2023-12-02 19:21:11,515 INFO     Training average positive_sample_loss at step 57800: 0.073913\n",
      "2023-12-02 19:21:11,516 INFO     Training average negative_sample_loss at step 57800: 0.074913\n",
      "2023-12-02 19:21:11,516 INFO     Training average loss at step 57800: 0.074413\n",
      "2023-12-02 19:21:23,434 INFO     Training average positive_sample_loss at step 57900: 0.074685\n",
      "2023-12-02 19:21:23,434 INFO     Training average negative_sample_loss at step 57900: 0.076117\n",
      "2023-12-02 19:21:23,434 INFO     Training average loss at step 57900: 0.075401\n",
      "2023-12-02 19:21:35,324 INFO     Training average positive_sample_loss at step 58000: 0.075602\n",
      "2023-12-02 19:21:35,324 INFO     Training average negative_sample_loss at step 58000: 0.076715\n",
      "2023-12-02 19:21:35,324 INFO     Training average loss at step 58000: 0.076159\n",
      "2023-12-02 19:21:47,131 INFO     Training average positive_sample_loss at step 58100: 0.075423\n",
      "2023-12-02 19:21:47,131 INFO     Training average negative_sample_loss at step 58100: 0.076057\n",
      "2023-12-02 19:21:47,131 INFO     Training average loss at step 58100: 0.075740\n",
      "2023-12-02 19:21:58,288 INFO     Training average positive_sample_loss at step 58200: 0.076451\n",
      "2023-12-02 19:21:58,288 INFO     Training average negative_sample_loss at step 58200: 0.077903\n",
      "2023-12-02 19:21:58,288 INFO     Training average loss at step 58200: 0.077177\n",
      "2023-12-02 19:22:10,123 INFO     Training average positive_sample_loss at step 58300: 0.076572\n",
      "2023-12-02 19:22:10,123 INFO     Training average negative_sample_loss at step 58300: 0.077777\n",
      "2023-12-02 19:22:10,123 INFO     Training average loss at step 58300: 0.077174\n",
      "2023-12-02 19:22:21,915 INFO     Training average positive_sample_loss at step 58400: 0.076522\n",
      "2023-12-02 19:22:21,915 INFO     Training average negative_sample_loss at step 58400: 0.078403\n",
      "2023-12-02 19:22:21,915 INFO     Training average loss at step 58400: 0.077462\n",
      "2023-12-02 19:22:33,092 INFO     Training average positive_sample_loss at step 58500: 0.075922\n",
      "2023-12-02 19:22:33,092 INFO     Training average negative_sample_loss at step 58500: 0.077578\n",
      "2023-12-02 19:22:33,092 INFO     Training average loss at step 58500: 0.076750\n",
      "2023-12-02 19:22:45,728 INFO     Training average positive_sample_loss at step 58600: 0.072775\n",
      "2023-12-02 19:22:45,729 INFO     Training average negative_sample_loss at step 58600: 0.077125\n",
      "2023-12-02 19:22:45,729 INFO     Training average loss at step 58600: 0.074950\n",
      "2023-12-02 19:22:57,527 INFO     Training average positive_sample_loss at step 58700: 0.073165\n",
      "2023-12-02 19:22:57,527 INFO     Training average negative_sample_loss at step 58700: 0.074540\n",
      "2023-12-02 19:22:57,527 INFO     Training average loss at step 58700: 0.073853\n",
      "2023-12-02 19:23:09,372 INFO     Training average positive_sample_loss at step 58800: 0.074050\n",
      "2023-12-02 19:23:09,373 INFO     Training average negative_sample_loss at step 58800: 0.075153\n",
      "2023-12-02 19:23:09,373 INFO     Training average loss at step 58800: 0.074601\n",
      "2023-12-02 19:23:20,539 INFO     Training average positive_sample_loss at step 58900: 0.074716\n",
      "2023-12-02 19:23:20,540 INFO     Training average negative_sample_loss at step 58900: 0.075219\n",
      "2023-12-02 19:23:20,540 INFO     Training average loss at step 58900: 0.074968\n",
      "2023-12-02 19:23:32,385 INFO     Training average positive_sample_loss at step 59000: 0.075404\n",
      "2023-12-02 19:23:32,385 INFO     Training average negative_sample_loss at step 59000: 0.076395\n",
      "2023-12-02 19:23:32,385 INFO     Training average loss at step 59000: 0.075899\n",
      "2023-12-02 19:23:44,169 INFO     Training average positive_sample_loss at step 59100: 0.075944\n",
      "2023-12-02 19:23:44,169 INFO     Training average negative_sample_loss at step 59100: 0.077744\n",
      "2023-12-02 19:23:44,169 INFO     Training average loss at step 59100: 0.076844\n",
      "2023-12-02 19:23:55,324 INFO     Training average positive_sample_loss at step 59200: 0.076231\n",
      "2023-12-02 19:23:55,324 INFO     Training average negative_sample_loss at step 59200: 0.078072\n",
      "2023-12-02 19:23:55,324 INFO     Training average loss at step 59200: 0.077151\n",
      "2023-12-02 19:24:07,139 INFO     Training average positive_sample_loss at step 59300: 0.076401\n",
      "2023-12-02 19:24:07,139 INFO     Training average negative_sample_loss at step 59300: 0.078145\n",
      "2023-12-02 19:24:07,139 INFO     Training average loss at step 59300: 0.077273\n",
      "2023-12-02 19:24:18,911 INFO     Training average positive_sample_loss at step 59400: 0.076923\n",
      "2023-12-02 19:24:18,911 INFO     Training average negative_sample_loss at step 59400: 0.078071\n",
      "2023-12-02 19:24:18,911 INFO     Training average loss at step 59400: 0.077497\n",
      "2023-12-02 19:24:31,471 INFO     Training average positive_sample_loss at step 59500: 0.074231\n",
      "2023-12-02 19:24:31,471 INFO     Training average negative_sample_loss at step 59500: 0.078221\n",
      "2023-12-02 19:24:31,472 INFO     Training average loss at step 59500: 0.076226\n",
      "2023-12-02 19:24:42,660 INFO     Training average positive_sample_loss at step 59600: 0.072182\n",
      "2023-12-02 19:24:42,660 INFO     Training average negative_sample_loss at step 59600: 0.073861\n",
      "2023-12-02 19:24:42,660 INFO     Training average loss at step 59600: 0.073021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 19:24:54,736 INFO     Training average positive_sample_loss at step 59700: 0.073589\n",
      "2023-12-02 19:24:54,736 INFO     Training average negative_sample_loss at step 59700: 0.074380\n",
      "2023-12-02 19:24:54,736 INFO     Training average loss at step 59700: 0.073985\n",
      "2023-12-02 19:25:06,758 INFO     Training average positive_sample_loss at step 59800: 0.074712\n",
      "2023-12-02 19:25:06,758 INFO     Training average negative_sample_loss at step 59800: 0.075702\n",
      "2023-12-02 19:25:06,758 INFO     Training average loss at step 59800: 0.075207\n",
      "2023-12-02 19:25:18,142 INFO     Training average positive_sample_loss at step 59900: 0.075962\n",
      "2023-12-02 19:25:18,142 INFO     Training average negative_sample_loss at step 59900: 0.077058\n",
      "2023-12-02 19:25:18,142 INFO     Training average loss at step 59900: 0.076510\n",
      "2023-12-02 19:25:43,012 INFO     Training average positive_sample_loss at step 60000: 0.076213\n",
      "2023-12-02 19:25:43,012 INFO     Training average negative_sample_loss at step 60000: 0.077758\n",
      "2023-12-02 19:25:43,012 INFO     Training average loss at step 60000: 0.076985\n",
      "2023-12-02 19:25:43,013 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 19:25:44,262 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 19:27:07,591 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 19:28:30,936 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 19:29:53,400 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 19:31:18,827 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 19:32:42,746 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 19:34:06,557 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 19:34:28,544 INFO     Valid MRR at step 60000: 0.744826\n",
      "2023-12-02 19:34:28,544 INFO     Valid MR at step 60000: 47.427210\n",
      "2023-12-02 19:34:28,544 INFO     Valid HITS@1 at step 60000: 0.683030\n",
      "2023-12-02 19:34:28,544 INFO     Valid HITS@3 at step 60000: 0.782860\n",
      "2023-12-02 19:34:28,544 INFO     Valid HITS@10 at step 60000: 0.854610\n",
      "2023-12-02 19:34:40,501 INFO     Training average positive_sample_loss at step 60100: 0.075905\n",
      "2023-12-02 19:34:40,501 INFO     Training average negative_sample_loss at step 60100: 0.077739\n",
      "2023-12-02 19:34:40,501 INFO     Training average loss at step 60100: 0.076822\n",
      "2023-12-02 19:34:52,428 INFO     Training average positive_sample_loss at step 60200: 0.075945\n",
      "2023-12-02 19:34:52,429 INFO     Training average negative_sample_loss at step 60200: 0.076965\n",
      "2023-12-02 19:34:52,429 INFO     Training average loss at step 60200: 0.076455\n",
      "2023-12-02 19:35:03,730 INFO     Training average positive_sample_loss at step 60300: 0.076394\n",
      "2023-12-02 19:35:03,730 INFO     Training average negative_sample_loss at step 60300: 0.078091\n",
      "2023-12-02 19:35:03,730 INFO     Training average loss at step 60300: 0.077242\n",
      "2023-12-02 19:35:15,632 INFO     Training average positive_sample_loss at step 60400: 0.076568\n",
      "2023-12-02 19:35:15,633 INFO     Training average negative_sample_loss at step 60400: 0.077548\n",
      "2023-12-02 19:35:15,633 INFO     Training average loss at step 60400: 0.077058\n",
      "2023-12-02 19:35:28,264 INFO     Training average positive_sample_loss at step 60500: 0.071264\n",
      "2023-12-02 19:35:28,265 INFO     Training average negative_sample_loss at step 60500: 0.074726\n",
      "2023-12-02 19:35:28,265 INFO     Training average loss at step 60500: 0.072995\n",
      "2023-12-02 19:35:39,508 INFO     Training average positive_sample_loss at step 60600: 0.072775\n",
      "2023-12-02 19:35:39,508 INFO     Training average negative_sample_loss at step 60600: 0.074199\n",
      "2023-12-02 19:35:39,508 INFO     Training average loss at step 60600: 0.073487\n",
      "2023-12-02 19:35:51,534 INFO     Training average positive_sample_loss at step 60700: 0.073835\n",
      "2023-12-02 19:35:51,535 INFO     Training average negative_sample_loss at step 60700: 0.074500\n",
      "2023-12-02 19:35:51,535 INFO     Training average loss at step 60700: 0.074167\n",
      "2023-12-02 19:36:03,521 INFO     Training average positive_sample_loss at step 60800: 0.075424\n",
      "2023-12-02 19:36:03,521 INFO     Training average negative_sample_loss at step 60800: 0.076304\n",
      "2023-12-02 19:36:03,521 INFO     Training average loss at step 60800: 0.075864\n",
      "2023-12-02 19:36:15,576 INFO     Training average positive_sample_loss at step 60900: 0.075579\n",
      "2023-12-02 19:36:15,576 INFO     Training average negative_sample_loss at step 60900: 0.077234\n",
      "2023-12-02 19:36:15,576 INFO     Training average loss at step 60900: 0.076407\n",
      "2023-12-02 19:36:26,831 INFO     Training average positive_sample_loss at step 61000: 0.075832\n",
      "2023-12-02 19:36:26,831 INFO     Training average negative_sample_loss at step 61000: 0.076391\n",
      "2023-12-02 19:36:26,832 INFO     Training average loss at step 61000: 0.076112\n",
      "2023-12-02 19:36:38,609 INFO     Training average positive_sample_loss at step 61100: 0.075965\n",
      "2023-12-02 19:36:38,609 INFO     Training average negative_sample_loss at step 61100: 0.077627\n",
      "2023-12-02 19:36:38,609 INFO     Training average loss at step 61100: 0.076796\n",
      "2023-12-02 19:36:50,495 INFO     Training average positive_sample_loss at step 61200: 0.076266\n",
      "2023-12-02 19:36:50,496 INFO     Training average negative_sample_loss at step 61200: 0.078341\n",
      "2023-12-02 19:36:50,496 INFO     Training average loss at step 61200: 0.077304\n",
      "2023-12-02 19:37:02,371 INFO     Training average positive_sample_loss at step 61300: 0.076616\n",
      "2023-12-02 19:37:02,372 INFO     Training average negative_sample_loss at step 61300: 0.078062\n",
      "2023-12-02 19:37:02,372 INFO     Training average loss at step 61300: 0.077339\n",
      "2023-12-02 19:37:14,351 INFO     Training average positive_sample_loss at step 61400: 0.073142\n",
      "2023-12-02 19:37:14,351 INFO     Training average negative_sample_loss at step 61400: 0.076818\n",
      "2023-12-02 19:37:14,351 INFO     Training average loss at step 61400: 0.074980\n",
      "2023-12-02 19:37:24,193 INFO     Training average positive_sample_loss at step 61500: 0.071730\n",
      "2023-12-02 19:37:24,193 INFO     Training average negative_sample_loss at step 61500: 0.073038\n",
      "2023-12-02 19:37:24,193 INFO     Training average loss at step 61500: 0.072384\n",
      "2023-12-02 19:37:30,982 INFO     Training average positive_sample_loss at step 61600: 0.073468\n",
      "2023-12-02 19:37:30,983 INFO     Training average negative_sample_loss at step 61600: 0.074275\n",
      "2023-12-02 19:37:30,983 INFO     Training average loss at step 61600: 0.073872\n",
      "2023-12-02 19:37:38,855 INFO     Training average positive_sample_loss at step 61700: 0.074684\n",
      "2023-12-02 19:37:38,855 INFO     Training average negative_sample_loss at step 61700: 0.075768\n",
      "2023-12-02 19:37:38,855 INFO     Training average loss at step 61700: 0.075226\n",
      "2023-12-02 19:37:47,369 INFO     Training average positive_sample_loss at step 61800: 0.075261\n",
      "2023-12-02 19:37:47,370 INFO     Training average negative_sample_loss at step 61800: 0.075529\n",
      "2023-12-02 19:37:47,370 INFO     Training average loss at step 61800: 0.075395\n",
      "2023-12-02 19:37:55,891 INFO     Training average positive_sample_loss at step 61900: 0.075091\n",
      "2023-12-02 19:37:55,892 INFO     Training average negative_sample_loss at step 61900: 0.076090\n",
      "2023-12-02 19:37:55,892 INFO     Training average loss at step 61900: 0.075590\n",
      "2023-12-02 19:38:04,535 INFO     Training average positive_sample_loss at step 62000: 0.075801\n",
      "2023-12-02 19:38:04,535 INFO     Training average negative_sample_loss at step 62000: 0.077386\n",
      "2023-12-02 19:38:04,535 INFO     Training average loss at step 62000: 0.076594\n",
      "2023-12-02 19:38:13,051 INFO     Training average positive_sample_loss at step 62100: 0.076494\n",
      "2023-12-02 19:38:13,052 INFO     Training average negative_sample_loss at step 62100: 0.078009\n",
      "2023-12-02 19:38:13,052 INFO     Training average loss at step 62100: 0.077251\n",
      "2023-12-02 19:38:24,879 INFO     Training average positive_sample_loss at step 62200: 0.076489\n",
      "2023-12-02 19:38:24,879 INFO     Training average negative_sample_loss at step 62200: 0.077985\n",
      "2023-12-02 19:38:24,879 INFO     Training average loss at step 62200: 0.077237\n",
      "2023-12-02 19:38:36,878 INFO     Training average positive_sample_loss at step 62300: 0.076991\n",
      "2023-12-02 19:38:36,878 INFO     Training average negative_sample_loss at step 62300: 0.078886\n",
      "2023-12-02 19:38:36,878 INFO     Training average loss at step 62300: 0.077939\n",
      "2023-12-02 19:38:49,535 INFO     Training average positive_sample_loss at step 62400: 0.070386\n",
      "2023-12-02 19:38:49,535 INFO     Training average negative_sample_loss at step 62400: 0.073972\n",
      "2023-12-02 19:38:49,535 INFO     Training average loss at step 62400: 0.072179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 19:39:01,367 INFO     Training average positive_sample_loss at step 62500: 0.073245\n",
      "2023-12-02 19:39:01,368 INFO     Training average negative_sample_loss at step 62500: 0.074389\n",
      "2023-12-02 19:39:01,368 INFO     Training average loss at step 62500: 0.073817\n",
      "2023-12-02 19:39:13,176 INFO     Training average positive_sample_loss at step 62600: 0.074628\n",
      "2023-12-02 19:39:13,177 INFO     Training average negative_sample_loss at step 62600: 0.074933\n",
      "2023-12-02 19:39:13,177 INFO     Training average loss at step 62600: 0.074780\n",
      "2023-12-02 19:39:24,397 INFO     Training average positive_sample_loss at step 62700: 0.074840\n",
      "2023-12-02 19:39:24,397 INFO     Training average negative_sample_loss at step 62700: 0.076777\n",
      "2023-12-02 19:39:24,397 INFO     Training average loss at step 62700: 0.075809\n",
      "2023-12-02 19:39:36,443 INFO     Training average positive_sample_loss at step 62800: 0.075718\n",
      "2023-12-02 19:39:36,443 INFO     Training average negative_sample_loss at step 62800: 0.076896\n",
      "2023-12-02 19:39:36,443 INFO     Training average loss at step 62800: 0.076307\n",
      "2023-12-02 19:39:48,511 INFO     Training average positive_sample_loss at step 62900: 0.075913\n",
      "2023-12-02 19:39:48,511 INFO     Training average negative_sample_loss at step 62900: 0.077156\n",
      "2023-12-02 19:39:48,511 INFO     Training average loss at step 62900: 0.076535\n",
      "2023-12-02 19:40:00,399 INFO     Training average positive_sample_loss at step 63000: 0.076033\n",
      "2023-12-02 19:40:00,400 INFO     Training average negative_sample_loss at step 63000: 0.077711\n",
      "2023-12-02 19:40:00,400 INFO     Training average loss at step 63000: 0.076872\n",
      "2023-12-02 19:40:11,735 INFO     Training average positive_sample_loss at step 63100: 0.075992\n",
      "2023-12-02 19:40:11,735 INFO     Training average negative_sample_loss at step 63100: 0.077335\n",
      "2023-12-02 19:40:11,736 INFO     Training average loss at step 63100: 0.076663\n",
      "2023-12-02 19:40:23,665 INFO     Training average positive_sample_loss at step 63200: 0.076196\n",
      "2023-12-02 19:40:23,666 INFO     Training average negative_sample_loss at step 63200: 0.077357\n",
      "2023-12-02 19:40:23,666 INFO     Training average loss at step 63200: 0.076777\n",
      "2023-12-02 19:40:36,417 INFO     Training average positive_sample_loss at step 63300: 0.072591\n",
      "2023-12-02 19:40:36,418 INFO     Training average negative_sample_loss at step 63300: 0.076623\n",
      "2023-12-02 19:40:36,418 INFO     Training average loss at step 63300: 0.074607\n",
      "2023-12-02 19:40:47,613 INFO     Training average positive_sample_loss at step 63400: 0.072496\n",
      "2023-12-02 19:40:47,613 INFO     Training average negative_sample_loss at step 63400: 0.073394\n",
      "2023-12-02 19:40:47,613 INFO     Training average loss at step 63400: 0.072945\n",
      "2023-12-02 19:40:59,637 INFO     Training average positive_sample_loss at step 63500: 0.073444\n",
      "2023-12-02 19:40:59,637 INFO     Training average negative_sample_loss at step 63500: 0.073336\n",
      "2023-12-02 19:40:59,637 INFO     Training average loss at step 63500: 0.073390\n",
      "2023-12-02 19:41:11,591 INFO     Training average positive_sample_loss at step 63600: 0.074635\n",
      "2023-12-02 19:41:11,591 INFO     Training average negative_sample_loss at step 63600: 0.075810\n",
      "2023-12-02 19:41:11,591 INFO     Training average loss at step 63600: 0.075222\n",
      "2023-12-02 19:41:23,733 INFO     Training average positive_sample_loss at step 63700: 0.075246\n",
      "2023-12-02 19:41:23,733 INFO     Training average negative_sample_loss at step 63700: 0.076349\n",
      "2023-12-02 19:41:23,733 INFO     Training average loss at step 63700: 0.075797\n",
      "2023-12-02 19:41:34,913 INFO     Training average positive_sample_loss at step 63800: 0.076223\n",
      "2023-12-02 19:41:34,913 INFO     Training average negative_sample_loss at step 63800: 0.077417\n",
      "2023-12-02 19:41:34,913 INFO     Training average loss at step 63800: 0.076820\n",
      "2023-12-02 19:41:46,879 INFO     Training average positive_sample_loss at step 63900: 0.076225\n",
      "2023-12-02 19:41:46,880 INFO     Training average negative_sample_loss at step 63900: 0.077785\n",
      "2023-12-02 19:41:46,880 INFO     Training average loss at step 63900: 0.077005\n",
      "2023-12-02 19:41:58,870 INFO     Training average positive_sample_loss at step 64000: 0.076109\n",
      "2023-12-02 19:41:58,870 INFO     Training average negative_sample_loss at step 64000: 0.077080\n",
      "2023-12-02 19:41:58,870 INFO     Training average loss at step 64000: 0.076594\n",
      "2023-12-02 19:42:10,025 INFO     Training average positive_sample_loss at step 64100: 0.076441\n",
      "2023-12-02 19:42:10,026 INFO     Training average negative_sample_loss at step 64100: 0.077917\n",
      "2023-12-02 19:42:10,026 INFO     Training average loss at step 64100: 0.077179\n",
      "2023-12-02 19:42:22,767 INFO     Training average positive_sample_loss at step 64200: 0.075199\n",
      "2023-12-02 19:42:22,767 INFO     Training average negative_sample_loss at step 64200: 0.077390\n",
      "2023-12-02 19:42:22,767 INFO     Training average loss at step 64200: 0.076295\n",
      "2023-12-02 19:42:34,809 INFO     Training average positive_sample_loss at step 64300: 0.070585\n",
      "2023-12-02 19:42:34,809 INFO     Training average negative_sample_loss at step 64300: 0.073338\n",
      "2023-12-02 19:42:34,809 INFO     Training average loss at step 64300: 0.071962\n",
      "2023-12-02 19:42:46,805 INFO     Training average positive_sample_loss at step 64400: 0.072790\n",
      "2023-12-02 19:42:46,805 INFO     Training average negative_sample_loss at step 64400: 0.074006\n",
      "2023-12-02 19:42:46,805 INFO     Training average loss at step 64400: 0.073398\n",
      "2023-12-02 19:42:58,042 INFO     Training average positive_sample_loss at step 64500: 0.074721\n",
      "2023-12-02 19:42:58,043 INFO     Training average negative_sample_loss at step 64500: 0.075706\n",
      "2023-12-02 19:42:58,043 INFO     Training average loss at step 64500: 0.075213\n",
      "2023-12-02 19:43:09,995 INFO     Training average positive_sample_loss at step 64600: 0.074950\n",
      "2023-12-02 19:43:09,995 INFO     Training average negative_sample_loss at step 64600: 0.075649\n",
      "2023-12-02 19:43:09,995 INFO     Training average loss at step 64600: 0.075300\n",
      "2023-12-02 19:43:21,869 INFO     Training average positive_sample_loss at step 64700: 0.075443\n",
      "2023-12-02 19:43:21,869 INFO     Training average negative_sample_loss at step 64700: 0.077605\n",
      "2023-12-02 19:43:21,869 INFO     Training average loss at step 64700: 0.076524\n",
      "2023-12-02 19:43:33,148 INFO     Training average positive_sample_loss at step 64800: 0.075954\n",
      "2023-12-02 19:43:33,148 INFO     Training average negative_sample_loss at step 64800: 0.076921\n",
      "2023-12-02 19:43:33,148 INFO     Training average loss at step 64800: 0.076437\n",
      "2023-12-02 19:43:45,232 INFO     Training average positive_sample_loss at step 64900: 0.076708\n",
      "2023-12-02 19:43:45,233 INFO     Training average negative_sample_loss at step 64900: 0.077761\n",
      "2023-12-02 19:43:45,233 INFO     Training average loss at step 64900: 0.077234\n",
      "2023-12-02 19:43:57,356 INFO     Training average positive_sample_loss at step 65000: 0.076204\n",
      "2023-12-02 19:43:57,356 INFO     Training average negative_sample_loss at step 65000: 0.077564\n",
      "2023-12-02 19:43:57,356 INFO     Training average loss at step 65000: 0.076884\n",
      "2023-12-02 19:44:09,373 INFO     Training average positive_sample_loss at step 65100: 0.075980\n",
      "2023-12-02 19:44:09,374 INFO     Training average negative_sample_loss at step 65100: 0.077900\n",
      "2023-12-02 19:44:09,374 INFO     Training average loss at step 65100: 0.076940\n",
      "2023-12-02 19:44:21,391 INFO     Training average positive_sample_loss at step 65200: 0.071905\n",
      "2023-12-02 19:44:21,391 INFO     Training average negative_sample_loss at step 65200: 0.075200\n",
      "2023-12-02 19:44:21,391 INFO     Training average loss at step 65200: 0.073552\n",
      "2023-12-02 19:44:33,384 INFO     Training average positive_sample_loss at step 65300: 0.072691\n",
      "2023-12-02 19:44:33,384 INFO     Training average negative_sample_loss at step 65300: 0.073476\n",
      "2023-12-02 19:44:33,384 INFO     Training average loss at step 65300: 0.073084\n",
      "2023-12-02 19:44:45,258 INFO     Training average positive_sample_loss at step 65400: 0.073741\n",
      "2023-12-02 19:44:45,258 INFO     Training average negative_sample_loss at step 65400: 0.074312\n",
      "2023-12-02 19:44:45,258 INFO     Training average loss at step 65400: 0.074026\n",
      "2023-12-02 19:44:56,501 INFO     Training average positive_sample_loss at step 65500: 0.074920\n",
      "2023-12-02 19:44:56,501 INFO     Training average negative_sample_loss at step 65500: 0.076204\n",
      "2023-12-02 19:44:56,501 INFO     Training average loss at step 65500: 0.075562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 19:45:08,435 INFO     Training average positive_sample_loss at step 65600: 0.075240\n",
      "2023-12-02 19:45:08,435 INFO     Training average negative_sample_loss at step 65600: 0.076493\n",
      "2023-12-02 19:45:08,435 INFO     Training average loss at step 65600: 0.075867\n",
      "2023-12-02 19:45:20,224 INFO     Training average positive_sample_loss at step 65700: 0.075588\n",
      "2023-12-02 19:45:20,225 INFO     Training average negative_sample_loss at step 65700: 0.076354\n",
      "2023-12-02 19:45:20,225 INFO     Training average loss at step 65700: 0.075971\n",
      "2023-12-02 19:45:32,099 INFO     Training average positive_sample_loss at step 65800: 0.075597\n",
      "2023-12-02 19:45:32,099 INFO     Training average negative_sample_loss at step 65800: 0.076418\n",
      "2023-12-02 19:45:32,100 INFO     Training average loss at step 65800: 0.076008\n",
      "2023-12-02 19:45:43,245 INFO     Training average positive_sample_loss at step 65900: 0.075517\n",
      "2023-12-02 19:45:43,245 INFO     Training average negative_sample_loss at step 65900: 0.077194\n",
      "2023-12-02 19:45:43,245 INFO     Training average loss at step 65900: 0.076356\n",
      "2023-12-02 19:45:55,047 INFO     Training average positive_sample_loss at step 66000: 0.075672\n",
      "2023-12-02 19:45:55,048 INFO     Training average negative_sample_loss at step 66000: 0.076809\n",
      "2023-12-02 19:45:55,048 INFO     Training average loss at step 66000: 0.076240\n",
      "2023-12-02 19:46:07,642 INFO     Training average positive_sample_loss at step 66100: 0.073998\n",
      "2023-12-02 19:46:07,642 INFO     Training average negative_sample_loss at step 66100: 0.077314\n",
      "2023-12-02 19:46:07,642 INFO     Training average loss at step 66100: 0.075656\n",
      "2023-12-02 19:46:18,854 INFO     Training average positive_sample_loss at step 66200: 0.071487\n",
      "2023-12-02 19:46:18,854 INFO     Training average negative_sample_loss at step 66200: 0.073350\n",
      "2023-12-02 19:46:18,854 INFO     Training average loss at step 66200: 0.072419\n",
      "2023-12-02 19:46:30,788 INFO     Training average positive_sample_loss at step 66300: 0.073766\n",
      "2023-12-02 19:46:30,788 INFO     Training average negative_sample_loss at step 66300: 0.073778\n",
      "2023-12-02 19:46:30,788 INFO     Training average loss at step 66300: 0.073772\n",
      "2023-12-02 19:46:42,717 INFO     Training average positive_sample_loss at step 66400: 0.073637\n",
      "2023-12-02 19:46:42,717 INFO     Training average negative_sample_loss at step 66400: 0.074399\n",
      "2023-12-02 19:46:42,717 INFO     Training average loss at step 66400: 0.074018\n",
      "2023-12-02 19:46:54,680 INFO     Training average positive_sample_loss at step 66500: 0.075175\n",
      "2023-12-02 19:46:54,680 INFO     Training average negative_sample_loss at step 66500: 0.077128\n",
      "2023-12-02 19:46:54,680 INFO     Training average loss at step 66500: 0.076152\n",
      "2023-12-02 19:47:05,877 INFO     Training average positive_sample_loss at step 66600: 0.075480\n",
      "2023-12-02 19:47:05,878 INFO     Training average negative_sample_loss at step 66600: 0.076034\n",
      "2023-12-02 19:47:05,878 INFO     Training average loss at step 66600: 0.075757\n",
      "2023-12-02 19:47:17,857 INFO     Training average positive_sample_loss at step 66700: 0.075445\n",
      "2023-12-02 19:47:17,858 INFO     Training average negative_sample_loss at step 66700: 0.076665\n",
      "2023-12-02 19:47:17,858 INFO     Training average loss at step 66700: 0.076055\n",
      "2023-12-02 19:47:29,872 INFO     Training average positive_sample_loss at step 66800: 0.076202\n",
      "2023-12-02 19:47:29,872 INFO     Training average negative_sample_loss at step 66800: 0.077618\n",
      "2023-12-02 19:47:29,872 INFO     Training average loss at step 66800: 0.076910\n",
      "2023-12-02 19:47:41,448 INFO     Training average positive_sample_loss at step 66900: 0.075262\n",
      "2023-12-02 19:47:41,448 INFO     Training average negative_sample_loss at step 66900: 0.076615\n",
      "2023-12-02 19:47:41,448 INFO     Training average loss at step 66900: 0.075939\n",
      "2023-12-02 19:47:52,967 INFO     Training average positive_sample_loss at step 67000: 0.076463\n",
      "2023-12-02 19:47:52,967 INFO     Training average negative_sample_loss at step 67000: 0.077748\n",
      "2023-12-02 19:47:52,967 INFO     Training average loss at step 67000: 0.077106\n",
      "2023-12-02 19:48:05,746 INFO     Training average positive_sample_loss at step 67100: 0.071303\n",
      "2023-12-02 19:48:05,747 INFO     Training average negative_sample_loss at step 67100: 0.074723\n",
      "2023-12-02 19:48:05,747 INFO     Training average loss at step 67100: 0.073013\n",
      "2023-12-02 19:48:17,667 INFO     Training average positive_sample_loss at step 67200: 0.072426\n",
      "2023-12-02 19:48:17,668 INFO     Training average negative_sample_loss at step 67200: 0.073421\n",
      "2023-12-02 19:48:17,668 INFO     Training average loss at step 67200: 0.072923\n",
      "2023-12-02 19:48:28,968 INFO     Training average positive_sample_loss at step 67300: 0.073581\n",
      "2023-12-02 19:48:28,968 INFO     Training average negative_sample_loss at step 67300: 0.074233\n",
      "2023-12-02 19:48:28,969 INFO     Training average loss at step 67300: 0.073907\n",
      "2023-12-02 19:48:41,001 INFO     Training average positive_sample_loss at step 67400: 0.074316\n",
      "2023-12-02 19:48:41,001 INFO     Training average negative_sample_loss at step 67400: 0.074894\n",
      "2023-12-02 19:48:41,001 INFO     Training average loss at step 67400: 0.074605\n",
      "2023-12-02 19:48:53,046 INFO     Training average positive_sample_loss at step 67500: 0.075689\n",
      "2023-12-02 19:48:53,046 INFO     Training average negative_sample_loss at step 67500: 0.077157\n",
      "2023-12-02 19:48:53,046 INFO     Training average loss at step 67500: 0.076423\n",
      "2023-12-02 19:49:04,685 INFO     Training average positive_sample_loss at step 67600: 0.075559\n",
      "2023-12-02 19:49:04,685 INFO     Training average negative_sample_loss at step 67600: 0.076756\n",
      "2023-12-02 19:49:04,685 INFO     Training average loss at step 67600: 0.076157\n",
      "2023-12-02 19:49:16,394 INFO     Training average positive_sample_loss at step 67700: 0.076129\n",
      "2023-12-02 19:49:16,394 INFO     Training average negative_sample_loss at step 67700: 0.077318\n",
      "2023-12-02 19:49:16,394 INFO     Training average loss at step 67700: 0.076723\n",
      "2023-12-02 19:49:28,442 INFO     Training average positive_sample_loss at step 67800: 0.075700\n",
      "2023-12-02 19:49:28,442 INFO     Training average negative_sample_loss at step 67800: 0.077245\n",
      "2023-12-02 19:49:28,442 INFO     Training average loss at step 67800: 0.076472\n",
      "2023-12-02 19:49:40,462 INFO     Training average positive_sample_loss at step 67900: 0.076676\n",
      "2023-12-02 19:49:40,462 INFO     Training average negative_sample_loss at step 67900: 0.078065\n",
      "2023-12-02 19:49:40,462 INFO     Training average loss at step 67900: 0.077371\n",
      "2023-12-02 19:49:52,493 INFO     Training average positive_sample_loss at step 68000: 0.073534\n",
      "2023-12-02 19:49:52,494 INFO     Training average negative_sample_loss at step 68000: 0.077386\n",
      "2023-12-02 19:49:52,494 INFO     Training average loss at step 68000: 0.075460\n",
      "2023-12-02 19:50:04,368 INFO     Training average positive_sample_loss at step 68100: 0.071925\n",
      "2023-12-02 19:50:04,368 INFO     Training average negative_sample_loss at step 68100: 0.073301\n",
      "2023-12-02 19:50:04,368 INFO     Training average loss at step 68100: 0.072613\n",
      "2023-12-02 19:50:16,357 INFO     Training average positive_sample_loss at step 68200: 0.073190\n",
      "2023-12-02 19:50:16,358 INFO     Training average negative_sample_loss at step 68200: 0.073589\n",
      "2023-12-02 19:50:16,358 INFO     Training average loss at step 68200: 0.073390\n",
      "2023-12-02 19:50:27,917 INFO     Training average positive_sample_loss at step 68300: 0.074202\n",
      "2023-12-02 19:50:27,917 INFO     Training average negative_sample_loss at step 68300: 0.075300\n",
      "2023-12-02 19:50:27,917 INFO     Training average loss at step 68300: 0.074751\n",
      "2023-12-02 19:50:39,625 INFO     Training average positive_sample_loss at step 68400: 0.074640\n",
      "2023-12-02 19:50:39,626 INFO     Training average negative_sample_loss at step 68400: 0.076097\n",
      "2023-12-02 19:50:39,626 INFO     Training average loss at step 68400: 0.075368\n",
      "2023-12-02 19:50:51,578 INFO     Training average positive_sample_loss at step 68500: 0.075842\n",
      "2023-12-02 19:50:51,578 INFO     Training average negative_sample_loss at step 68500: 0.077010\n",
      "2023-12-02 19:50:51,578 INFO     Training average loss at step 68500: 0.076426\n",
      "2023-12-02 19:51:03,604 INFO     Training average positive_sample_loss at step 68600: 0.075957\n",
      "2023-12-02 19:51:03,605 INFO     Training average negative_sample_loss at step 68600: 0.076514\n",
      "2023-12-02 19:51:03,605 INFO     Training average loss at step 68600: 0.076236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 19:51:14,788 INFO     Training average positive_sample_loss at step 68700: 0.075117\n",
      "2023-12-02 19:51:14,788 INFO     Training average negative_sample_loss at step 68700: 0.075677\n",
      "2023-12-02 19:51:14,788 INFO     Training average loss at step 68700: 0.075397\n",
      "2023-12-02 19:51:26,710 INFO     Training average positive_sample_loss at step 68800: 0.075779\n",
      "2023-12-02 19:51:26,711 INFO     Training average negative_sample_loss at step 68800: 0.076435\n",
      "2023-12-02 19:51:26,711 INFO     Training average loss at step 68800: 0.076107\n",
      "2023-12-02 19:51:38,694 INFO     Training average positive_sample_loss at step 68900: 0.075446\n",
      "2023-12-02 19:51:38,694 INFO     Training average negative_sample_loss at step 68900: 0.077249\n",
      "2023-12-02 19:51:38,694 INFO     Training average loss at step 68900: 0.076347\n",
      "2023-12-02 19:51:51,107 INFO     Training average positive_sample_loss at step 69000: 0.070745\n",
      "2023-12-02 19:51:51,107 INFO     Training average negative_sample_loss at step 69000: 0.073508\n",
      "2023-12-02 19:51:51,108 INFO     Training average loss at step 69000: 0.072127\n",
      "2023-12-02 19:52:02,574 INFO     Training average positive_sample_loss at step 69100: 0.072213\n",
      "2023-12-02 19:52:02,575 INFO     Training average negative_sample_loss at step 69100: 0.073134\n",
      "2023-12-02 19:52:02,575 INFO     Training average loss at step 69100: 0.072673\n",
      "2023-12-02 19:52:14,558 INFO     Training average positive_sample_loss at step 69200: 0.073527\n",
      "2023-12-02 19:52:14,559 INFO     Training average negative_sample_loss at step 69200: 0.074412\n",
      "2023-12-02 19:52:14,559 INFO     Training average loss at step 69200: 0.073969\n",
      "2023-12-02 19:52:26,504 INFO     Training average positive_sample_loss at step 69300: 0.074676\n",
      "2023-12-02 19:52:26,504 INFO     Training average negative_sample_loss at step 69300: 0.075528\n",
      "2023-12-02 19:52:26,504 INFO     Training average loss at step 69300: 0.075102\n",
      "2023-12-02 19:52:37,741 INFO     Training average positive_sample_loss at step 69400: 0.075046\n",
      "2023-12-02 19:52:37,741 INFO     Training average negative_sample_loss at step 69400: 0.076141\n",
      "2023-12-02 19:52:37,741 INFO     Training average loss at step 69400: 0.075593\n",
      "2023-12-02 19:52:49,673 INFO     Training average positive_sample_loss at step 69500: 0.075046\n",
      "2023-12-02 19:52:49,674 INFO     Training average negative_sample_loss at step 69500: 0.076241\n",
      "2023-12-02 19:52:49,674 INFO     Training average loss at step 69500: 0.075644\n",
      "2023-12-02 19:53:01,598 INFO     Training average positive_sample_loss at step 69600: 0.075976\n",
      "2023-12-02 19:53:01,599 INFO     Training average negative_sample_loss at step 69600: 0.077069\n",
      "2023-12-02 19:53:01,599 INFO     Training average loss at step 69600: 0.076523\n",
      "2023-12-02 19:53:13,487 INFO     Training average positive_sample_loss at step 69700: 0.075211\n",
      "2023-12-02 19:53:13,487 INFO     Training average negative_sample_loss at step 69700: 0.075767\n",
      "2023-12-02 19:53:13,488 INFO     Training average loss at step 69700: 0.075489\n",
      "2023-12-02 19:53:24,807 INFO     Training average positive_sample_loss at step 69800: 0.075481\n",
      "2023-12-02 19:53:24,807 INFO     Training average negative_sample_loss at step 69800: 0.077452\n",
      "2023-12-02 19:53:24,807 INFO     Training average loss at step 69800: 0.076466\n",
      "2023-12-02 19:53:37,534 INFO     Training average positive_sample_loss at step 69900: 0.073243\n",
      "2023-12-02 19:53:37,534 INFO     Training average negative_sample_loss at step 69900: 0.075690\n",
      "2023-12-02 19:53:37,534 INFO     Training average loss at step 69900: 0.074466\n",
      "2023-12-02 19:54:04,392 INFO     Training average positive_sample_loss at step 70000: 0.071780\n",
      "2023-12-02 19:54:04,393 INFO     Training average negative_sample_loss at step 70000: 0.072904\n",
      "2023-12-02 19:54:04,393 INFO     Training average loss at step 70000: 0.072342\n",
      "2023-12-02 19:54:04,393 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 19:54:05,304 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 19:55:27,950 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 19:56:52,854 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 19:57:50,368 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 19:58:58,199 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 20:00:20,723 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 20:01:43,567 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 20:02:05,988 INFO     Valid MRR at step 70000: 0.744345\n",
      "2023-12-02 20:02:05,988 INFO     Valid MR at step 70000: 48.636760\n",
      "2023-12-02 20:02:05,988 INFO     Valid HITS@1 at step 70000: 0.681790\n",
      "2023-12-02 20:02:05,988 INFO     Valid HITS@3 at step 70000: 0.783350\n",
      "2023-12-02 20:02:05,988 INFO     Valid HITS@10 at step 70000: 0.854760\n",
      "2023-12-02 20:02:17,306 INFO     Training average positive_sample_loss at step 70100: 0.073107\n",
      "2023-12-02 20:02:17,306 INFO     Training average negative_sample_loss at step 70100: 0.073485\n",
      "2023-12-02 20:02:17,306 INFO     Training average loss at step 70100: 0.073296\n",
      "2023-12-02 20:02:29,235 INFO     Training average positive_sample_loss at step 70200: 0.073963\n",
      "2023-12-02 20:02:29,235 INFO     Training average negative_sample_loss at step 70200: 0.073984\n",
      "2023-12-02 20:02:29,235 INFO     Training average loss at step 70200: 0.073973\n",
      "2023-12-02 20:02:41,086 INFO     Training average positive_sample_loss at step 70300: 0.075390\n",
      "2023-12-02 20:02:41,087 INFO     Training average negative_sample_loss at step 70300: 0.075726\n",
      "2023-12-02 20:02:41,087 INFO     Training average loss at step 70300: 0.075558\n",
      "2023-12-02 20:02:52,808 INFO     Training average positive_sample_loss at step 70400: 0.075094\n",
      "2023-12-02 20:02:52,808 INFO     Training average negative_sample_loss at step 70400: 0.076196\n",
      "2023-12-02 20:02:52,808 INFO     Training average loss at step 70400: 0.075645\n",
      "2023-12-02 20:03:04,096 INFO     Training average positive_sample_loss at step 70500: 0.075236\n",
      "2023-12-02 20:03:04,096 INFO     Training average negative_sample_loss at step 70500: 0.076457\n",
      "2023-12-02 20:03:04,096 INFO     Training average loss at step 70500: 0.075847\n",
      "2023-12-02 20:03:16,008 INFO     Training average positive_sample_loss at step 70600: 0.075763\n",
      "2023-12-02 20:03:16,008 INFO     Training average negative_sample_loss at step 70600: 0.076608\n",
      "2023-12-02 20:03:16,008 INFO     Training average loss at step 70600: 0.076185\n",
      "2023-12-02 20:03:27,853 INFO     Training average positive_sample_loss at step 70700: 0.075198\n",
      "2023-12-02 20:03:27,854 INFO     Training average negative_sample_loss at step 70700: 0.076984\n",
      "2023-12-02 20:03:27,854 INFO     Training average loss at step 70700: 0.076091\n",
      "2023-12-02 20:03:39,336 INFO     Training average positive_sample_loss at step 70800: 0.076063\n",
      "2023-12-02 20:03:39,336 INFO     Training average negative_sample_loss at step 70800: 0.077267\n",
      "2023-12-02 20:03:39,336 INFO     Training average loss at step 70800: 0.076665\n",
      "2023-12-02 20:03:51,725 INFO     Training average positive_sample_loss at step 70900: 0.070533\n",
      "2023-12-02 20:03:51,726 INFO     Training average negative_sample_loss at step 70900: 0.073601\n",
      "2023-12-02 20:03:51,726 INFO     Training average loss at step 70900: 0.072067\n",
      "2023-12-02 20:04:03,805 INFO     Training average positive_sample_loss at step 71000: 0.073531\n",
      "2023-12-02 20:04:03,805 INFO     Training average negative_sample_loss at step 71000: 0.074216\n",
      "2023-12-02 20:04:03,805 INFO     Training average loss at step 71000: 0.073873\n",
      "2023-12-02 20:04:15,619 INFO     Training average positive_sample_loss at step 71100: 0.073749\n",
      "2023-12-02 20:04:15,619 INFO     Training average negative_sample_loss at step 71100: 0.074046\n",
      "2023-12-02 20:04:15,619 INFO     Training average loss at step 71100: 0.073897\n",
      "2023-12-02 20:04:26,881 INFO     Training average positive_sample_loss at step 71200: 0.074030\n",
      "2023-12-02 20:04:26,882 INFO     Training average negative_sample_loss at step 71200: 0.075295\n",
      "2023-12-02 20:04:26,882 INFO     Training average loss at step 71200: 0.074663\n",
      "2023-12-02 20:04:38,685 INFO     Training average positive_sample_loss at step 71300: 0.075014\n",
      "2023-12-02 20:04:38,685 INFO     Training average negative_sample_loss at step 71300: 0.075370\n",
      "2023-12-02 20:04:38,685 INFO     Training average loss at step 71300: 0.075192\n",
      "2023-12-02 20:04:50,448 INFO     Training average positive_sample_loss at step 71400: 0.075053\n",
      "2023-12-02 20:04:50,448 INFO     Training average negative_sample_loss at step 71400: 0.076220\n",
      "2023-12-02 20:04:50,448 INFO     Training average loss at step 71400: 0.075636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 20:05:01,552 INFO     Training average positive_sample_loss at step 71500: 0.075441\n",
      "2023-12-02 20:05:01,552 INFO     Training average negative_sample_loss at step 71500: 0.076467\n",
      "2023-12-02 20:05:01,553 INFO     Training average loss at step 71500: 0.075954\n",
      "2023-12-02 20:05:13,455 INFO     Training average positive_sample_loss at step 71600: 0.075608\n",
      "2023-12-02 20:05:13,455 INFO     Training average negative_sample_loss at step 71600: 0.076480\n",
      "2023-12-02 20:05:13,455 INFO     Training average loss at step 71600: 0.076044\n",
      "2023-12-02 20:05:25,382 INFO     Training average positive_sample_loss at step 71700: 0.075532\n",
      "2023-12-02 20:05:25,382 INFO     Training average negative_sample_loss at step 71700: 0.076388\n",
      "2023-12-02 20:05:25,382 INFO     Training average loss at step 71700: 0.075960\n",
      "2023-12-02 20:05:38,114 INFO     Training average positive_sample_loss at step 71800: 0.071858\n",
      "2023-12-02 20:05:38,114 INFO     Training average negative_sample_loss at step 71800: 0.075144\n",
      "2023-12-02 20:05:38,114 INFO     Training average loss at step 71800: 0.073501\n",
      "2023-12-02 20:05:49,370 INFO     Training average positive_sample_loss at step 71900: 0.071801\n",
      "2023-12-02 20:05:49,370 INFO     Training average negative_sample_loss at step 71900: 0.072279\n",
      "2023-12-02 20:05:49,370 INFO     Training average loss at step 71900: 0.072040\n",
      "2023-12-02 20:06:01,426 INFO     Training average positive_sample_loss at step 72000: 0.073634\n",
      "2023-12-02 20:06:01,426 INFO     Training average negative_sample_loss at step 72000: 0.074942\n",
      "2023-12-02 20:06:01,426 INFO     Training average loss at step 72000: 0.074288\n",
      "2023-12-02 20:06:13,337 INFO     Training average positive_sample_loss at step 72100: 0.073863\n",
      "2023-12-02 20:06:13,337 INFO     Training average negative_sample_loss at step 72100: 0.075119\n",
      "2023-12-02 20:06:13,337 INFO     Training average loss at step 72100: 0.074491\n",
      "2023-12-02 20:06:24,506 INFO     Training average positive_sample_loss at step 72200: 0.074662\n",
      "2023-12-02 20:06:24,506 INFO     Training average negative_sample_loss at step 72200: 0.074934\n",
      "2023-12-02 20:06:24,506 INFO     Training average loss at step 72200: 0.074798\n",
      "2023-12-02 20:06:36,562 INFO     Training average positive_sample_loss at step 72300: 0.075459\n",
      "2023-12-02 20:06:36,563 INFO     Training average negative_sample_loss at step 72300: 0.075621\n",
      "2023-12-02 20:06:36,563 INFO     Training average loss at step 72300: 0.075540\n",
      "2023-12-02 20:06:48,654 INFO     Training average positive_sample_loss at step 72400: 0.075346\n",
      "2023-12-02 20:06:48,654 INFO     Training average negative_sample_loss at step 72400: 0.076000\n",
      "2023-12-02 20:06:48,654 INFO     Training average loss at step 72400: 0.075673\n",
      "2023-12-02 20:07:00,592 INFO     Training average positive_sample_loss at step 72500: 0.075319\n",
      "2023-12-02 20:07:00,592 INFO     Training average negative_sample_loss at step 72500: 0.077548\n",
      "2023-12-02 20:07:00,592 INFO     Training average loss at step 72500: 0.076433\n",
      "2023-12-02 20:07:11,802 INFO     Training average positive_sample_loss at step 72600: 0.076096\n",
      "2023-12-02 20:07:11,803 INFO     Training average negative_sample_loss at step 72600: 0.077149\n",
      "2023-12-02 20:07:11,803 INFO     Training average loss at step 72600: 0.076623\n",
      "2023-12-02 20:07:24,583 INFO     Training average positive_sample_loss at step 72700: 0.073954\n",
      "2023-12-02 20:07:24,584 INFO     Training average negative_sample_loss at step 72700: 0.076340\n",
      "2023-12-02 20:07:24,584 INFO     Training average loss at step 72700: 0.075147\n",
      "2023-12-02 20:07:36,557 INFO     Training average positive_sample_loss at step 72800: 0.070559\n",
      "2023-12-02 20:07:36,558 INFO     Training average negative_sample_loss at step 72800: 0.072493\n",
      "2023-12-02 20:07:36,558 INFO     Training average loss at step 72800: 0.071526\n",
      "2023-12-02 20:07:47,896 INFO     Training average positive_sample_loss at step 72900: 0.073203\n",
      "2023-12-02 20:07:47,897 INFO     Training average negative_sample_loss at step 72900: 0.073542\n",
      "2023-12-02 20:07:47,897 INFO     Training average loss at step 72900: 0.073372\n",
      "2023-12-02 20:07:59,812 INFO     Training average positive_sample_loss at step 73000: 0.074038\n",
      "2023-12-02 20:07:59,812 INFO     Training average negative_sample_loss at step 73000: 0.074664\n",
      "2023-12-02 20:07:59,812 INFO     Training average loss at step 73000: 0.074351\n",
      "2023-12-02 20:08:11,740 INFO     Training average positive_sample_loss at step 73100: 0.074599\n",
      "2023-12-02 20:08:11,740 INFO     Training average negative_sample_loss at step 73100: 0.075924\n",
      "2023-12-02 20:08:11,740 INFO     Training average loss at step 73100: 0.075261\n",
      "2023-12-02 20:08:23,579 INFO     Training average positive_sample_loss at step 73200: 0.075412\n",
      "2023-12-02 20:08:23,579 INFO     Training average negative_sample_loss at step 73200: 0.075655\n",
      "2023-12-02 20:08:23,579 INFO     Training average loss at step 73200: 0.075533\n",
      "2023-12-02 20:08:34,839 INFO     Training average positive_sample_loss at step 73300: 0.075517\n",
      "2023-12-02 20:08:34,839 INFO     Training average negative_sample_loss at step 73300: 0.075848\n",
      "2023-12-02 20:08:34,839 INFO     Training average loss at step 73300: 0.075682\n",
      "2023-12-02 20:08:46,829 INFO     Training average positive_sample_loss at step 73400: 0.075532\n",
      "2023-12-02 20:08:46,829 INFO     Training average negative_sample_loss at step 73400: 0.077263\n",
      "2023-12-02 20:08:46,829 INFO     Training average loss at step 73400: 0.076397\n",
      "2023-12-02 20:08:58,819 INFO     Training average positive_sample_loss at step 73500: 0.075678\n",
      "2023-12-02 20:08:58,820 INFO     Training average negative_sample_loss at step 73500: 0.075619\n",
      "2023-12-02 20:08:58,820 INFO     Training average loss at step 73500: 0.075649\n",
      "2023-12-02 20:09:10,249 INFO     Training average positive_sample_loss at step 73600: 0.074606\n",
      "2023-12-02 20:09:10,249 INFO     Training average negative_sample_loss at step 73600: 0.076356\n",
      "2023-12-02 20:09:10,249 INFO     Training average loss at step 73600: 0.075481\n",
      "2023-12-02 20:09:22,874 INFO     Training average positive_sample_loss at step 73700: 0.071146\n",
      "2023-12-02 20:09:22,875 INFO     Training average negative_sample_loss at step 73700: 0.074443\n",
      "2023-12-02 20:09:22,875 INFO     Training average loss at step 73700: 0.072794\n",
      "2023-12-02 20:09:34,929 INFO     Training average positive_sample_loss at step 73800: 0.072437\n",
      "2023-12-02 20:09:34,929 INFO     Training average negative_sample_loss at step 73800: 0.073351\n",
      "2023-12-02 20:09:34,929 INFO     Training average loss at step 73800: 0.072894\n",
      "2023-12-02 20:09:46,969 INFO     Training average positive_sample_loss at step 73900: 0.073241\n",
      "2023-12-02 20:09:46,969 INFO     Training average negative_sample_loss at step 73900: 0.073442\n",
      "2023-12-02 20:09:46,969 INFO     Training average loss at step 73900: 0.073342\n",
      "2023-12-02 20:09:58,292 INFO     Training average positive_sample_loss at step 74000: 0.074548\n",
      "2023-12-02 20:09:58,292 INFO     Training average negative_sample_loss at step 74000: 0.075496\n",
      "2023-12-02 20:09:58,292 INFO     Training average loss at step 74000: 0.075022\n",
      "2023-12-02 20:10:10,358 INFO     Training average positive_sample_loss at step 74100: 0.074711\n",
      "2023-12-02 20:10:10,358 INFO     Training average negative_sample_loss at step 74100: 0.076117\n",
      "2023-12-02 20:10:10,358 INFO     Training average loss at step 74100: 0.075414\n",
      "2023-12-02 20:10:22,518 INFO     Training average positive_sample_loss at step 74200: 0.075267\n",
      "2023-12-02 20:10:22,518 INFO     Training average negative_sample_loss at step 74200: 0.076110\n",
      "2023-12-02 20:10:22,518 INFO     Training average loss at step 74200: 0.075688\n",
      "2023-12-02 20:10:33,769 INFO     Training average positive_sample_loss at step 74300: 0.075432\n",
      "2023-12-02 20:10:33,769 INFO     Training average negative_sample_loss at step 74300: 0.076374\n",
      "2023-12-02 20:10:33,769 INFO     Training average loss at step 74300: 0.075903\n",
      "2023-12-02 20:10:45,706 INFO     Training average positive_sample_loss at step 74400: 0.075377\n",
      "2023-12-02 20:10:45,707 INFO     Training average negative_sample_loss at step 74400: 0.076430\n",
      "2023-12-02 20:10:45,707 INFO     Training average loss at step 74400: 0.075903\n",
      "2023-12-02 20:10:57,739 INFO     Training average positive_sample_loss at step 74500: 0.075719\n",
      "2023-12-02 20:10:57,739 INFO     Training average negative_sample_loss at step 74500: 0.076784\n",
      "2023-12-02 20:10:57,739 INFO     Training average loss at step 74500: 0.076252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 20:11:10,663 INFO     Training average positive_sample_loss at step 74600: 0.073450\n",
      "2023-12-02 20:11:10,663 INFO     Training average negative_sample_loss at step 74600: 0.076270\n",
      "2023-12-02 20:11:10,663 INFO     Training average loss at step 74600: 0.074860\n",
      "2023-12-02 20:11:21,950 INFO     Training average positive_sample_loss at step 74700: 0.070613\n",
      "2023-12-02 20:11:21,950 INFO     Training average negative_sample_loss at step 74700: 0.072708\n",
      "2023-12-02 20:11:21,950 INFO     Training average loss at step 74700: 0.071661\n",
      "2023-12-02 20:11:34,005 INFO     Training average positive_sample_loss at step 74800: 0.072967\n",
      "2023-12-02 20:11:34,005 INFO     Training average negative_sample_loss at step 74800: 0.073561\n",
      "2023-12-02 20:11:34,005 INFO     Training average loss at step 74800: 0.073264\n",
      "2023-12-02 20:11:46,066 INFO     Training average positive_sample_loss at step 74900: 0.073966\n",
      "2023-12-02 20:11:46,066 INFO     Training average negative_sample_loss at step 74900: 0.074457\n",
      "2023-12-02 20:11:46,066 INFO     Training average loss at step 74900: 0.074212\n",
      "2023-12-02 20:11:57,447 INFO     Change learning_rate to 0.000010 at step 75000\n",
      "2023-12-02 20:11:57,448 INFO     Training average positive_sample_loss at step 75000: 0.074657\n",
      "2023-12-02 20:11:57,448 INFO     Training average negative_sample_loss at step 75000: 0.074948\n",
      "2023-12-02 20:11:57,448 INFO     Training average loss at step 75000: 0.074802\n",
      "2023-12-02 20:12:09,420 INFO     Training average positive_sample_loss at step 75100: 0.074486\n",
      "2023-12-02 20:12:09,420 INFO     Training average negative_sample_loss at step 75100: 0.073067\n",
      "2023-12-02 20:12:09,420 INFO     Training average loss at step 75100: 0.073777\n",
      "2023-12-02 20:12:21,406 INFO     Training average positive_sample_loss at step 75200: 0.072666\n",
      "2023-12-02 20:12:21,407 INFO     Training average negative_sample_loss at step 75200: 0.073707\n",
      "2023-12-02 20:12:21,407 INFO     Training average loss at step 75200: 0.073186\n",
      "2023-12-02 20:12:33,275 INFO     Training average positive_sample_loss at step 75300: 0.071722\n",
      "2023-12-02 20:12:33,275 INFO     Training average negative_sample_loss at step 75300: 0.073683\n",
      "2023-12-02 20:12:33,275 INFO     Training average loss at step 75300: 0.072703\n",
      "2023-12-02 20:12:44,522 INFO     Training average positive_sample_loss at step 75400: 0.070374\n",
      "2023-12-02 20:12:44,522 INFO     Training average negative_sample_loss at step 75400: 0.073431\n",
      "2023-12-02 20:12:44,522 INFO     Training average loss at step 75400: 0.071903\n",
      "2023-12-02 20:12:56,548 INFO     Training average positive_sample_loss at step 75500: 0.069756\n",
      "2023-12-02 20:12:56,549 INFO     Training average negative_sample_loss at step 75500: 0.072900\n",
      "2023-12-02 20:12:56,549 INFO     Training average loss at step 75500: 0.071328\n",
      "2023-12-02 20:13:09,239 INFO     Training average positive_sample_loss at step 75600: 0.064575\n",
      "2023-12-02 20:13:09,240 INFO     Training average negative_sample_loss at step 75600: 0.072358\n",
      "2023-12-02 20:13:09,240 INFO     Training average loss at step 75600: 0.068466\n",
      "2023-12-02 20:13:20,516 INFO     Training average positive_sample_loss at step 75700: 0.064185\n",
      "2023-12-02 20:13:20,517 INFO     Training average negative_sample_loss at step 75700: 0.071419\n",
      "2023-12-02 20:13:20,517 INFO     Training average loss at step 75700: 0.067802\n",
      "2023-12-02 20:13:32,625 INFO     Training average positive_sample_loss at step 75800: 0.064617\n",
      "2023-12-02 20:13:32,625 INFO     Training average negative_sample_loss at step 75800: 0.070694\n",
      "2023-12-02 20:13:32,625 INFO     Training average loss at step 75800: 0.067656\n",
      "2023-12-02 20:13:44,544 INFO     Training average positive_sample_loss at step 75900: 0.065158\n",
      "2023-12-02 20:13:44,545 INFO     Training average negative_sample_loss at step 75900: 0.070684\n",
      "2023-12-02 20:13:44,545 INFO     Training average loss at step 75900: 0.067921\n",
      "2023-12-02 20:13:56,474 INFO     Training average positive_sample_loss at step 76000: 0.065352\n",
      "2023-12-02 20:13:56,475 INFO     Training average negative_sample_loss at step 76000: 0.069985\n",
      "2023-12-02 20:13:56,475 INFO     Training average loss at step 76000: 0.067669\n",
      "2023-12-02 20:14:07,759 INFO     Training average positive_sample_loss at step 76100: 0.065448\n",
      "2023-12-02 20:14:07,760 INFO     Training average negative_sample_loss at step 76100: 0.068655\n",
      "2023-12-02 20:14:07,760 INFO     Training average loss at step 76100: 0.067052\n",
      "2023-12-02 20:14:19,719 INFO     Training average positive_sample_loss at step 76200: 0.065387\n",
      "2023-12-02 20:14:19,720 INFO     Training average negative_sample_loss at step 76200: 0.069841\n",
      "2023-12-02 20:14:19,720 INFO     Training average loss at step 76200: 0.067614\n",
      "2023-12-02 20:14:31,692 INFO     Training average positive_sample_loss at step 76300: 0.065774\n",
      "2023-12-02 20:14:31,693 INFO     Training average negative_sample_loss at step 76300: 0.068673\n",
      "2023-12-02 20:14:31,693 INFO     Training average loss at step 76300: 0.067224\n",
      "2023-12-02 20:14:43,290 INFO     Training average positive_sample_loss at step 76400: 0.065444\n",
      "2023-12-02 20:14:43,290 INFO     Training average negative_sample_loss at step 76400: 0.068093\n",
      "2023-12-02 20:14:43,290 INFO     Training average loss at step 76400: 0.066769\n",
      "2023-12-02 20:14:55,714 INFO     Training average positive_sample_loss at step 76500: 0.064938\n",
      "2023-12-02 20:14:55,714 INFO     Training average negative_sample_loss at step 76500: 0.068221\n",
      "2023-12-02 20:14:55,714 INFO     Training average loss at step 76500: 0.066579\n",
      "2023-12-02 20:15:07,810 INFO     Training average positive_sample_loss at step 76600: 0.063887\n",
      "2023-12-02 20:15:07,810 INFO     Training average negative_sample_loss at step 76600: 0.068367\n",
      "2023-12-02 20:15:07,810 INFO     Training average loss at step 76600: 0.066127\n",
      "2023-12-02 20:15:19,835 INFO     Training average positive_sample_loss at step 76700: 0.064575\n",
      "2023-12-02 20:15:19,836 INFO     Training average negative_sample_loss at step 76700: 0.068775\n",
      "2023-12-02 20:15:19,836 INFO     Training average loss at step 76700: 0.066675\n",
      "2023-12-02 20:15:31,049 INFO     Training average positive_sample_loss at step 76800: 0.064619\n",
      "2023-12-02 20:15:31,050 INFO     Training average negative_sample_loss at step 76800: 0.067234\n",
      "2023-12-02 20:15:31,050 INFO     Training average loss at step 76800: 0.065926\n",
      "2023-12-02 20:15:43,120 INFO     Training average positive_sample_loss at step 76900: 0.064563\n",
      "2023-12-02 20:15:43,120 INFO     Training average negative_sample_loss at step 76900: 0.068096\n",
      "2023-12-02 20:15:43,120 INFO     Training average loss at step 76900: 0.066330\n",
      "2023-12-02 20:15:55,124 INFO     Training average positive_sample_loss at step 77000: 0.065169\n",
      "2023-12-02 20:15:55,124 INFO     Training average negative_sample_loss at step 77000: 0.066799\n",
      "2023-12-02 20:15:55,124 INFO     Training average loss at step 77000: 0.065984\n",
      "2023-12-02 20:16:06,546 INFO     Training average positive_sample_loss at step 77100: 0.065194\n",
      "2023-12-02 20:16:06,546 INFO     Training average negative_sample_loss at step 77100: 0.067361\n",
      "2023-12-02 20:16:06,546 INFO     Training average loss at step 77100: 0.066277\n",
      "2023-12-02 20:16:18,489 INFO     Training average positive_sample_loss at step 77200: 0.065129\n",
      "2023-12-02 20:16:18,490 INFO     Training average negative_sample_loss at step 77200: 0.068382\n",
      "2023-12-02 20:16:18,490 INFO     Training average loss at step 77200: 0.066755\n",
      "2023-12-02 20:16:30,488 INFO     Training average positive_sample_loss at step 77300: 0.065225\n",
      "2023-12-02 20:16:30,488 INFO     Training average negative_sample_loss at step 77300: 0.067531\n",
      "2023-12-02 20:16:30,488 INFO     Training average loss at step 77300: 0.066378\n",
      "2023-12-02 20:16:42,470 INFO     Training average positive_sample_loss at step 77400: 0.064950\n",
      "2023-12-02 20:16:42,471 INFO     Training average negative_sample_loss at step 77400: 0.067490\n",
      "2023-12-02 20:16:42,471 INFO     Training average loss at step 77400: 0.066220\n",
      "2023-12-02 20:16:54,567 INFO     Training average positive_sample_loss at step 77500: 0.063586\n",
      "2023-12-02 20:16:54,568 INFO     Training average negative_sample_loss at step 77500: 0.067665\n",
      "2023-12-02 20:16:54,568 INFO     Training average loss at step 77500: 0.065625\n",
      "2023-12-02 20:17:04,126 INFO     Training average positive_sample_loss at step 77600: 0.063785\n",
      "2023-12-02 20:17:04,126 INFO     Training average negative_sample_loss at step 77600: 0.066985\n",
      "2023-12-02 20:17:04,126 INFO     Training average loss at step 77600: 0.065385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 20:17:11,208 INFO     Training average positive_sample_loss at step 77700: 0.064095\n",
      "2023-12-02 20:17:11,208 INFO     Training average negative_sample_loss at step 77700: 0.066437\n",
      "2023-12-02 20:17:11,208 INFO     Training average loss at step 77700: 0.065266\n",
      "2023-12-02 20:17:20,084 INFO     Training average positive_sample_loss at step 77800: 0.064526\n",
      "2023-12-02 20:17:20,085 INFO     Training average negative_sample_loss at step 77800: 0.067969\n",
      "2023-12-02 20:17:20,085 INFO     Training average loss at step 77800: 0.066248\n",
      "2023-12-02 20:17:29,015 INFO     Training average positive_sample_loss at step 77900: 0.064453\n",
      "2023-12-02 20:17:29,015 INFO     Training average negative_sample_loss at step 77900: 0.067320\n",
      "2023-12-02 20:17:29,015 INFO     Training average loss at step 77900: 0.065887\n",
      "2023-12-02 20:17:37,331 INFO     Training average positive_sample_loss at step 78000: 0.064955\n",
      "2023-12-02 20:17:37,332 INFO     Training average negative_sample_loss at step 78000: 0.066362\n",
      "2023-12-02 20:17:37,332 INFO     Training average loss at step 78000: 0.065659\n",
      "2023-12-02 20:17:45,897 INFO     Training average positive_sample_loss at step 78100: 0.064820\n",
      "2023-12-02 20:17:45,897 INFO     Training average negative_sample_loss at step 78100: 0.067068\n",
      "2023-12-02 20:17:45,897 INFO     Training average loss at step 78100: 0.065944\n",
      "2023-12-02 20:17:56,569 INFO     Training average positive_sample_loss at step 78200: 0.065093\n",
      "2023-12-02 20:17:56,569 INFO     Training average negative_sample_loss at step 78200: 0.067362\n",
      "2023-12-02 20:17:56,569 INFO     Training average loss at step 78200: 0.066227\n",
      "2023-12-02 20:18:08,307 INFO     Training average positive_sample_loss at step 78300: 0.064729\n",
      "2023-12-02 20:18:08,308 INFO     Training average negative_sample_loss at step 78300: 0.067410\n",
      "2023-12-02 20:18:08,308 INFO     Training average loss at step 78300: 0.066070\n",
      "2023-12-02 20:18:20,350 INFO     Training average positive_sample_loss at step 78400: 0.063881\n",
      "2023-12-02 20:18:20,351 INFO     Training average negative_sample_loss at step 78400: 0.066903\n",
      "2023-12-02 20:18:20,351 INFO     Training average loss at step 78400: 0.065392\n",
      "2023-12-02 20:18:32,027 INFO     Training average positive_sample_loss at step 78500: 0.063290\n",
      "2023-12-02 20:18:32,027 INFO     Training average negative_sample_loss at step 78500: 0.067242\n",
      "2023-12-02 20:18:32,027 INFO     Training average loss at step 78500: 0.065266\n",
      "2023-12-02 20:18:43,925 INFO     Training average positive_sample_loss at step 78600: 0.063984\n",
      "2023-12-02 20:18:43,925 INFO     Training average negative_sample_loss at step 78600: 0.066153\n",
      "2023-12-02 20:18:43,926 INFO     Training average loss at step 78600: 0.065068\n",
      "2023-12-02 20:18:55,656 INFO     Training average positive_sample_loss at step 78700: 0.064052\n",
      "2023-12-02 20:18:55,656 INFO     Training average negative_sample_loss at step 78700: 0.065950\n",
      "2023-12-02 20:18:55,656 INFO     Training average loss at step 78700: 0.065001\n",
      "2023-12-02 20:19:06,886 INFO     Training average positive_sample_loss at step 78800: 0.064182\n",
      "2023-12-02 20:19:06,886 INFO     Training average negative_sample_loss at step 78800: 0.066704\n",
      "2023-12-02 20:19:06,886 INFO     Training average loss at step 78800: 0.065443\n",
      "2023-12-02 20:19:18,714 INFO     Training average positive_sample_loss at step 78900: 0.064371\n",
      "2023-12-02 20:19:18,714 INFO     Training average negative_sample_loss at step 78900: 0.065361\n",
      "2023-12-02 20:19:18,714 INFO     Training average loss at step 78900: 0.064866\n",
      "2023-12-02 20:19:30,508 INFO     Training average positive_sample_loss at step 79000: 0.064784\n",
      "2023-12-02 20:19:30,509 INFO     Training average negative_sample_loss at step 79000: 0.066965\n",
      "2023-12-02 20:19:30,509 INFO     Training average loss at step 79000: 0.065874\n",
      "2023-12-02 20:19:42,289 INFO     Training average positive_sample_loss at step 79100: 0.064515\n",
      "2023-12-02 20:19:42,289 INFO     Training average negative_sample_loss at step 79100: 0.065694\n",
      "2023-12-02 20:19:42,289 INFO     Training average loss at step 79100: 0.065104\n",
      "2023-12-02 20:19:53,382 INFO     Training average positive_sample_loss at step 79200: 0.064708\n",
      "2023-12-02 20:19:53,382 INFO     Training average negative_sample_loss at step 79200: 0.067061\n",
      "2023-12-02 20:19:53,382 INFO     Training average loss at step 79200: 0.065884\n",
      "2023-12-02 20:20:06,118 INFO     Training average positive_sample_loss at step 79300: 0.064895\n",
      "2023-12-02 20:20:06,119 INFO     Training average negative_sample_loss at step 79300: 0.067116\n",
      "2023-12-02 20:20:06,119 INFO     Training average loss at step 79300: 0.066005\n",
      "2023-12-02 20:20:17,841 INFO     Training average positive_sample_loss at step 79400: 0.062935\n",
      "2023-12-02 20:20:17,841 INFO     Training average negative_sample_loss at step 79400: 0.065379\n",
      "2023-12-02 20:20:17,841 INFO     Training average loss at step 79400: 0.064157\n",
      "2023-12-02 20:20:29,030 INFO     Training average positive_sample_loss at step 79500: 0.063309\n",
      "2023-12-02 20:20:29,030 INFO     Training average negative_sample_loss at step 79500: 0.065271\n",
      "2023-12-02 20:20:29,030 INFO     Training average loss at step 79500: 0.064290\n",
      "2023-12-02 20:20:40,924 INFO     Training average positive_sample_loss at step 79600: 0.064060\n",
      "2023-12-02 20:20:40,924 INFO     Training average negative_sample_loss at step 79600: 0.066806\n",
      "2023-12-02 20:20:40,924 INFO     Training average loss at step 79600: 0.065433\n",
      "2023-12-02 20:20:52,777 INFO     Training average positive_sample_loss at step 79700: 0.064286\n",
      "2023-12-02 20:20:52,777 INFO     Training average negative_sample_loss at step 79700: 0.066358\n",
      "2023-12-02 20:20:52,777 INFO     Training average loss at step 79700: 0.065322\n",
      "2023-12-02 20:21:04,592 INFO     Training average positive_sample_loss at step 79800: 0.064036\n",
      "2023-12-02 20:21:04,592 INFO     Training average negative_sample_loss at step 79800: 0.065590\n",
      "2023-12-02 20:21:04,592 INFO     Training average loss at step 79800: 0.064813\n",
      "2023-12-02 20:21:15,793 INFO     Training average positive_sample_loss at step 79900: 0.064163\n",
      "2023-12-02 20:21:15,794 INFO     Training average negative_sample_loss at step 79900: 0.066725\n",
      "2023-12-02 20:21:15,794 INFO     Training average loss at step 79900: 0.065444\n",
      "2023-12-02 20:21:35,176 INFO     Training average positive_sample_loss at step 80000: 0.064547\n",
      "2023-12-02 20:21:35,177 INFO     Training average negative_sample_loss at step 80000: 0.065336\n",
      "2023-12-02 20:21:35,177 INFO     Training average loss at step 80000: 0.064941\n",
      "2023-12-02 20:21:35,177 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 20:21:36,493 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 20:22:57,403 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 20:24:20,219 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 20:25:45,099 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 20:27:08,616 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 20:28:31,949 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 20:29:55,773 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 20:30:16,172 INFO     Valid MRR at step 80000: 0.782949\n",
      "2023-12-02 20:30:16,173 INFO     Valid MR at step 80000: 40.957030\n",
      "2023-12-02 20:30:16,173 INFO     Valid HITS@1 at step 80000: 0.727100\n",
      "2023-12-02 20:30:16,173 INFO     Valid HITS@3 at step 80000: 0.819990\n",
      "2023-12-02 20:30:16,173 INFO     Valid HITS@10 at step 80000: 0.878250\n",
      "2023-12-02 20:30:28,031 INFO     Training average positive_sample_loss at step 80100: 0.064368\n",
      "2023-12-02 20:30:28,032 INFO     Training average negative_sample_loss at step 80100: 0.066609\n",
      "2023-12-02 20:30:28,032 INFO     Training average loss at step 80100: 0.065489\n",
      "2023-12-02 20:30:39,879 INFO     Training average positive_sample_loss at step 80200: 0.064341\n",
      "2023-12-02 20:30:39,879 INFO     Training average negative_sample_loss at step 80200: 0.065714\n",
      "2023-12-02 20:30:39,879 INFO     Training average loss at step 80200: 0.065027\n",
      "2023-12-02 20:30:52,575 INFO     Training average positive_sample_loss at step 80300: 0.063828\n",
      "2023-12-02 20:30:52,576 INFO     Training average negative_sample_loss at step 80300: 0.066591\n",
      "2023-12-02 20:30:52,576 INFO     Training average loss at step 80300: 0.065209\n",
      "2023-12-02 20:31:03,862 INFO     Training average positive_sample_loss at step 80400: 0.063436\n",
      "2023-12-02 20:31:03,862 INFO     Training average negative_sample_loss at step 80400: 0.065029\n",
      "2023-12-02 20:31:03,862 INFO     Training average loss at step 80400: 0.064233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 20:31:15,975 INFO     Training average positive_sample_loss at step 80500: 0.063285\n",
      "2023-12-02 20:31:15,975 INFO     Training average negative_sample_loss at step 80500: 0.066203\n",
      "2023-12-02 20:31:15,975 INFO     Training average loss at step 80500: 0.064744\n",
      "2023-12-02 20:31:27,912 INFO     Training average positive_sample_loss at step 80600: 0.063734\n",
      "2023-12-02 20:31:27,912 INFO     Training average negative_sample_loss at step 80600: 0.066547\n",
      "2023-12-02 20:31:27,912 INFO     Training average loss at step 80600: 0.065140\n",
      "2023-12-02 20:31:39,247 INFO     Training average positive_sample_loss at step 80700: 0.064482\n",
      "2023-12-02 20:31:39,248 INFO     Training average negative_sample_loss at step 80700: 0.066784\n",
      "2023-12-02 20:31:39,248 INFO     Training average loss at step 80700: 0.065633\n",
      "2023-12-02 20:31:50,939 INFO     Training average positive_sample_loss at step 80800: 0.064281\n",
      "2023-12-02 20:31:50,940 INFO     Training average negative_sample_loss at step 80800: 0.065974\n",
      "2023-12-02 20:31:50,940 INFO     Training average loss at step 80800: 0.065128\n",
      "2023-12-02 20:32:02,838 INFO     Training average positive_sample_loss at step 80900: 0.064289\n",
      "2023-12-02 20:32:02,838 INFO     Training average negative_sample_loss at step 80900: 0.065587\n",
      "2023-12-02 20:32:02,838 INFO     Training average loss at step 80900: 0.064938\n",
      "2023-12-02 20:32:14,958 INFO     Training average positive_sample_loss at step 81000: 0.063809\n",
      "2023-12-02 20:32:14,959 INFO     Training average negative_sample_loss at step 81000: 0.065687\n",
      "2023-12-02 20:32:14,959 INFO     Training average loss at step 81000: 0.064748\n",
      "2023-12-02 20:32:26,183 INFO     Training average positive_sample_loss at step 81100: 0.064540\n",
      "2023-12-02 20:32:26,183 INFO     Training average negative_sample_loss at step 81100: 0.065733\n",
      "2023-12-02 20:32:26,184 INFO     Training average loss at step 81100: 0.065137\n",
      "2023-12-02 20:32:38,790 INFO     Training average positive_sample_loss at step 81200: 0.064519\n",
      "2023-12-02 20:32:38,791 INFO     Training average negative_sample_loss at step 81200: 0.065693\n",
      "2023-12-02 20:32:38,791 INFO     Training average loss at step 81200: 0.065106\n",
      "2023-12-02 20:32:50,816 INFO     Training average positive_sample_loss at step 81300: 0.062623\n",
      "2023-12-02 20:32:50,816 INFO     Training average negative_sample_loss at step 81300: 0.065380\n",
      "2023-12-02 20:32:50,816 INFO     Training average loss at step 81300: 0.064001\n",
      "2023-12-02 20:33:02,554 INFO     Training average positive_sample_loss at step 81400: 0.063711\n",
      "2023-12-02 20:33:02,554 INFO     Training average negative_sample_loss at step 81400: 0.065600\n",
      "2023-12-02 20:33:02,554 INFO     Training average loss at step 81400: 0.064656\n",
      "2023-12-02 20:33:14,185 INFO     Training average positive_sample_loss at step 81500: 0.063692\n",
      "2023-12-02 20:33:14,186 INFO     Training average negative_sample_loss at step 81500: 0.065845\n",
      "2023-12-02 20:33:14,186 INFO     Training average loss at step 81500: 0.064769\n",
      "2023-12-02 20:33:26,106 INFO     Training average positive_sample_loss at step 81600: 0.063858\n",
      "2023-12-02 20:33:26,106 INFO     Training average negative_sample_loss at step 81600: 0.065975\n",
      "2023-12-02 20:33:26,106 INFO     Training average loss at step 81600: 0.064916\n",
      "2023-12-02 20:33:37,907 INFO     Training average positive_sample_loss at step 81700: 0.064136\n",
      "2023-12-02 20:33:37,908 INFO     Training average negative_sample_loss at step 81700: 0.064789\n",
      "2023-12-02 20:33:37,908 INFO     Training average loss at step 81700: 0.064463\n",
      "2023-12-02 20:33:49,098 INFO     Training average positive_sample_loss at step 81800: 0.064001\n",
      "2023-12-02 20:33:49,098 INFO     Training average negative_sample_loss at step 81800: 0.066133\n",
      "2023-12-02 20:33:49,098 INFO     Training average loss at step 81800: 0.065067\n",
      "2023-12-02 20:34:01,168 INFO     Training average positive_sample_loss at step 81900: 0.064220\n",
      "2023-12-02 20:34:01,168 INFO     Training average negative_sample_loss at step 81900: 0.065202\n",
      "2023-12-02 20:34:01,168 INFO     Training average loss at step 81900: 0.064711\n",
      "2023-12-02 20:34:13,208 INFO     Training average positive_sample_loss at step 82000: 0.064080\n",
      "2023-12-02 20:34:13,208 INFO     Training average negative_sample_loss at step 82000: 0.065466\n",
      "2023-12-02 20:34:13,208 INFO     Training average loss at step 82000: 0.064773\n",
      "2023-12-02 20:34:25,095 INFO     Training average positive_sample_loss at step 82100: 0.064614\n",
      "2023-12-02 20:34:25,095 INFO     Training average negative_sample_loss at step 82100: 0.065237\n",
      "2023-12-02 20:34:25,095 INFO     Training average loss at step 82100: 0.064926\n",
      "2023-12-02 20:34:37,247 INFO     Training average positive_sample_loss at step 82200: 0.062929\n",
      "2023-12-02 20:34:37,247 INFO     Training average negative_sample_loss at step 82200: 0.065678\n",
      "2023-12-02 20:34:37,247 INFO     Training average loss at step 82200: 0.064303\n",
      "2023-12-02 20:34:49,382 INFO     Training average positive_sample_loss at step 82300: 0.062876\n",
      "2023-12-02 20:34:49,383 INFO     Training average negative_sample_loss at step 82300: 0.065081\n",
      "2023-12-02 20:34:49,383 INFO     Training average loss at step 82300: 0.063979\n",
      "2023-12-02 20:34:58,084 INFO     Training average positive_sample_loss at step 82400: 0.063797\n",
      "2023-12-02 20:34:58,084 INFO     Training average negative_sample_loss at step 82400: 0.065814\n",
      "2023-12-02 20:34:58,084 INFO     Training average loss at step 82400: 0.064805\n",
      "2023-12-02 20:35:05,000 INFO     Training average positive_sample_loss at step 82500: 0.063574\n",
      "2023-12-02 20:35:05,001 INFO     Training average negative_sample_loss at step 82500: 0.065272\n",
      "2023-12-02 20:35:05,001 INFO     Training average loss at step 82500: 0.064423\n",
      "2023-12-02 20:35:13,629 INFO     Training average positive_sample_loss at step 82600: 0.063879\n",
      "2023-12-02 20:35:13,629 INFO     Training average negative_sample_loss at step 82600: 0.065069\n",
      "2023-12-02 20:35:13,629 INFO     Training average loss at step 82600: 0.064474\n",
      "2023-12-02 20:35:22,061 INFO     Training average positive_sample_loss at step 82700: 0.063977\n",
      "2023-12-02 20:35:22,062 INFO     Training average negative_sample_loss at step 82700: 0.064768\n",
      "2023-12-02 20:35:22,062 INFO     Training average loss at step 82700: 0.064372\n",
      "2023-12-02 20:35:30,293 INFO     Training average positive_sample_loss at step 82800: 0.064185\n",
      "2023-12-02 20:35:30,293 INFO     Training average negative_sample_loss at step 82800: 0.064903\n",
      "2023-12-02 20:35:30,294 INFO     Training average loss at step 82800: 0.064544\n",
      "2023-12-02 20:35:38,747 INFO     Training average positive_sample_loss at step 82900: 0.064304\n",
      "2023-12-02 20:35:38,747 INFO     Training average negative_sample_loss at step 82900: 0.064738\n",
      "2023-12-02 20:35:38,747 INFO     Training average loss at step 82900: 0.064521\n",
      "2023-12-02 20:35:48,819 INFO     Training average positive_sample_loss at step 83000: 0.064063\n",
      "2023-12-02 20:35:48,820 INFO     Training average negative_sample_loss at step 83000: 0.065036\n",
      "2023-12-02 20:35:48,820 INFO     Training average loss at step 83000: 0.064550\n",
      "2023-12-02 20:36:01,463 INFO     Training average positive_sample_loss at step 83100: 0.063652\n",
      "2023-12-02 20:36:01,463 INFO     Training average negative_sample_loss at step 83100: 0.066275\n",
      "2023-12-02 20:36:01,463 INFO     Training average loss at step 83100: 0.064964\n",
      "2023-12-02 20:36:13,409 INFO     Training average positive_sample_loss at step 83200: 0.062677\n",
      "2023-12-02 20:36:13,410 INFO     Training average negative_sample_loss at step 83200: 0.066802\n",
      "2023-12-02 20:36:13,410 INFO     Training average loss at step 83200: 0.064739\n",
      "2023-12-02 20:36:25,286 INFO     Training average positive_sample_loss at step 83300: 0.063641\n",
      "2023-12-02 20:36:25,286 INFO     Training average negative_sample_loss at step 83300: 0.064747\n",
      "2023-12-02 20:36:25,286 INFO     Training average loss at step 83300: 0.064194\n",
      "2023-12-02 20:36:37,080 INFO     Training average positive_sample_loss at step 83400: 0.063504\n",
      "2023-12-02 20:36:37,080 INFO     Training average negative_sample_loss at step 83400: 0.064873\n",
      "2023-12-02 20:36:37,080 INFO     Training average loss at step 83400: 0.064189\n",
      "2023-12-02 20:36:48,365 INFO     Training average positive_sample_loss at step 83500: 0.064066\n",
      "2023-12-02 20:36:48,366 INFO     Training average negative_sample_loss at step 83500: 0.065047\n",
      "2023-12-02 20:36:48,366 INFO     Training average loss at step 83500: 0.064557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 20:37:00,264 INFO     Training average positive_sample_loss at step 83600: 0.063626\n",
      "2023-12-02 20:37:00,265 INFO     Training average negative_sample_loss at step 83600: 0.064756\n",
      "2023-12-02 20:37:00,265 INFO     Training average loss at step 83600: 0.064191\n",
      "2023-12-02 20:37:12,164 INFO     Training average positive_sample_loss at step 83700: 0.064092\n",
      "2023-12-02 20:37:12,164 INFO     Training average negative_sample_loss at step 83700: 0.064835\n",
      "2023-12-02 20:37:12,164 INFO     Training average loss at step 83700: 0.064463\n",
      "2023-12-02 20:37:23,305 INFO     Training average positive_sample_loss at step 83800: 0.063900\n",
      "2023-12-02 20:37:23,305 INFO     Training average negative_sample_loss at step 83800: 0.064960\n",
      "2023-12-02 20:37:23,305 INFO     Training average loss at step 83800: 0.064430\n",
      "2023-12-02 20:37:35,087 INFO     Training average positive_sample_loss at step 83900: 0.063924\n",
      "2023-12-02 20:37:35,088 INFO     Training average negative_sample_loss at step 83900: 0.065147\n",
      "2023-12-02 20:37:35,088 INFO     Training average loss at step 83900: 0.064535\n",
      "2023-12-02 20:37:47,003 INFO     Training average positive_sample_loss at step 84000: 0.064447\n",
      "2023-12-02 20:37:47,003 INFO     Training average negative_sample_loss at step 84000: 0.065349\n",
      "2023-12-02 20:37:47,003 INFO     Training average loss at step 84000: 0.064898\n",
      "2023-12-02 20:37:59,726 INFO     Training average positive_sample_loss at step 84100: 0.062908\n",
      "2023-12-02 20:37:59,727 INFO     Training average negative_sample_loss at step 84100: 0.064277\n",
      "2023-12-02 20:37:59,727 INFO     Training average loss at step 84100: 0.063592\n",
      "2023-12-02 20:38:10,858 INFO     Training average positive_sample_loss at step 84200: 0.062730\n",
      "2023-12-02 20:38:10,858 INFO     Training average negative_sample_loss at step 84200: 0.064864\n",
      "2023-12-02 20:38:10,858 INFO     Training average loss at step 84200: 0.063797\n",
      "2023-12-02 20:38:22,685 INFO     Training average positive_sample_loss at step 84300: 0.063233\n",
      "2023-12-02 20:38:22,686 INFO     Training average negative_sample_loss at step 84300: 0.064823\n",
      "2023-12-02 20:38:22,686 INFO     Training average loss at step 84300: 0.064028\n",
      "2023-12-02 20:38:34,500 INFO     Training average positive_sample_loss at step 84400: 0.063342\n",
      "2023-12-02 20:38:34,500 INFO     Training average negative_sample_loss at step 84400: 0.064432\n",
      "2023-12-02 20:38:34,500 INFO     Training average loss at step 84400: 0.063887\n",
      "2023-12-02 20:38:45,807 INFO     Training average positive_sample_loss at step 84500: 0.063770\n",
      "2023-12-02 20:38:45,808 INFO     Training average negative_sample_loss at step 84500: 0.065367\n",
      "2023-12-02 20:38:45,808 INFO     Training average loss at step 84500: 0.064568\n",
      "2023-12-02 20:38:57,598 INFO     Training average positive_sample_loss at step 84600: 0.063871\n",
      "2023-12-02 20:38:57,599 INFO     Training average negative_sample_loss at step 84600: 0.063942\n",
      "2023-12-02 20:38:57,599 INFO     Training average loss at step 84600: 0.063906\n",
      "2023-12-02 20:39:09,479 INFO     Training average positive_sample_loss at step 84700: 0.063337\n",
      "2023-12-02 20:39:09,479 INFO     Training average negative_sample_loss at step 84700: 0.064682\n",
      "2023-12-02 20:39:09,479 INFO     Training average loss at step 84700: 0.064010\n",
      "2023-12-02 20:39:21,302 INFO     Training average positive_sample_loss at step 84800: 0.064310\n",
      "2023-12-02 20:39:21,302 INFO     Training average negative_sample_loss at step 84800: 0.065807\n",
      "2023-12-02 20:39:21,302 INFO     Training average loss at step 84800: 0.065059\n",
      "2023-12-02 20:39:32,494 INFO     Training average positive_sample_loss at step 84900: 0.064606\n",
      "2023-12-02 20:39:32,495 INFO     Training average negative_sample_loss at step 84900: 0.065414\n",
      "2023-12-02 20:39:32,495 INFO     Training average loss at step 84900: 0.065010\n",
      "2023-12-02 20:39:45,214 INFO     Training average positive_sample_loss at step 85000: 0.063415\n",
      "2023-12-02 20:39:45,214 INFO     Training average negative_sample_loss at step 85000: 0.065323\n",
      "2023-12-02 20:39:45,214 INFO     Training average loss at step 85000: 0.064369\n",
      "2023-12-02 20:39:57,023 INFO     Training average positive_sample_loss at step 85100: 0.062547\n",
      "2023-12-02 20:39:57,024 INFO     Training average negative_sample_loss at step 85100: 0.064712\n",
      "2023-12-02 20:39:57,024 INFO     Training average loss at step 85100: 0.063630\n",
      "2023-12-02 20:40:08,857 INFO     Training average positive_sample_loss at step 85200: 0.063074\n",
      "2023-12-02 20:40:08,858 INFO     Training average negative_sample_loss at step 85200: 0.064838\n",
      "2023-12-02 20:40:08,858 INFO     Training average loss at step 85200: 0.063956\n",
      "2023-12-02 20:40:20,204 INFO     Training average positive_sample_loss at step 85300: 0.063445\n",
      "2023-12-02 20:40:20,204 INFO     Training average negative_sample_loss at step 85300: 0.064069\n",
      "2023-12-02 20:40:20,205 INFO     Training average loss at step 85300: 0.063757\n",
      "2023-12-02 20:40:32,180 INFO     Training average positive_sample_loss at step 85400: 0.063292\n",
      "2023-12-02 20:40:32,180 INFO     Training average negative_sample_loss at step 85400: 0.064515\n",
      "2023-12-02 20:40:32,180 INFO     Training average loss at step 85400: 0.063903\n",
      "2023-12-02 20:40:44,145 INFO     Training average positive_sample_loss at step 85500: 0.063631\n",
      "2023-12-02 20:40:44,146 INFO     Training average negative_sample_loss at step 85500: 0.064798\n",
      "2023-12-02 20:40:44,146 INFO     Training average loss at step 85500: 0.064214\n",
      "2023-12-02 20:40:55,390 INFO     Training average positive_sample_loss at step 85600: 0.064106\n",
      "2023-12-02 20:40:55,390 INFO     Training average negative_sample_loss at step 85600: 0.064750\n",
      "2023-12-02 20:40:55,390 INFO     Training average loss at step 85600: 0.064428\n",
      "2023-12-02 20:41:07,457 INFO     Training average positive_sample_loss at step 85700: 0.063648\n",
      "2023-12-02 20:41:07,457 INFO     Training average negative_sample_loss at step 85700: 0.064846\n",
      "2023-12-02 20:41:07,457 INFO     Training average loss at step 85700: 0.064247\n",
      "2023-12-02 20:41:19,329 INFO     Training average positive_sample_loss at step 85800: 0.064047\n",
      "2023-12-02 20:41:19,330 INFO     Training average negative_sample_loss at step 85800: 0.064984\n",
      "2023-12-02 20:41:19,330 INFO     Training average loss at step 85800: 0.064515\n",
      "2023-12-02 20:41:31,306 INFO     Training average positive_sample_loss at step 85900: 0.064163\n",
      "2023-12-02 20:41:31,306 INFO     Training average negative_sample_loss at step 85900: 0.064913\n",
      "2023-12-02 20:41:31,306 INFO     Training average loss at step 85900: 0.064538\n",
      "2023-12-02 20:41:43,596 INFO     Training average positive_sample_loss at step 86000: 0.062556\n",
      "2023-12-02 20:41:43,596 INFO     Training average negative_sample_loss at step 86000: 0.064833\n",
      "2023-12-02 20:41:43,596 INFO     Training average loss at step 86000: 0.063695\n",
      "2023-12-02 20:41:55,734 INFO     Training average positive_sample_loss at step 86100: 0.062693\n",
      "2023-12-02 20:41:55,734 INFO     Training average negative_sample_loss at step 86100: 0.064846\n",
      "2023-12-02 20:41:55,734 INFO     Training average loss at step 86100: 0.063770\n",
      "2023-12-02 20:42:07,796 INFO     Training average positive_sample_loss at step 86200: 0.063208\n",
      "2023-12-02 20:42:07,796 INFO     Training average negative_sample_loss at step 86200: 0.064098\n",
      "2023-12-02 20:42:07,796 INFO     Training average loss at step 86200: 0.063653\n",
      "2023-12-02 20:42:19,087 INFO     Training average positive_sample_loss at step 86300: 0.063661\n",
      "2023-12-02 20:42:19,088 INFO     Training average negative_sample_loss at step 86300: 0.064699\n",
      "2023-12-02 20:42:19,088 INFO     Training average loss at step 86300: 0.064180\n",
      "2023-12-02 20:42:31,125 INFO     Training average positive_sample_loss at step 86400: 0.063981\n",
      "2023-12-02 20:42:31,125 INFO     Training average negative_sample_loss at step 86400: 0.065163\n",
      "2023-12-02 20:42:31,125 INFO     Training average loss at step 86400: 0.064572\n",
      "2023-12-02 20:42:43,102 INFO     Training average positive_sample_loss at step 86500: 0.063509\n",
      "2023-12-02 20:42:43,102 INFO     Training average negative_sample_loss at step 86500: 0.065130\n",
      "2023-12-02 20:42:43,102 INFO     Training average loss at step 86500: 0.064320\n",
      "2023-12-02 20:42:55,029 INFO     Training average positive_sample_loss at step 86600: 0.064049\n",
      "2023-12-02 20:42:55,029 INFO     Training average negative_sample_loss at step 86600: 0.064464\n",
      "2023-12-02 20:42:55,030 INFO     Training average loss at step 86600: 0.064256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 20:43:06,400 INFO     Training average positive_sample_loss at step 86700: 0.064012\n",
      "2023-12-02 20:43:06,401 INFO     Training average negative_sample_loss at step 86700: 0.064584\n",
      "2023-12-02 20:43:06,401 INFO     Training average loss at step 86700: 0.064298\n",
      "2023-12-02 20:43:18,451 INFO     Training average positive_sample_loss at step 86800: 0.063618\n",
      "2023-12-02 20:43:18,452 INFO     Training average negative_sample_loss at step 86800: 0.064029\n",
      "2023-12-02 20:43:18,452 INFO     Training average loss at step 86800: 0.063823\n",
      "2023-12-02 20:43:31,237 INFO     Training average positive_sample_loss at step 86900: 0.063250\n",
      "2023-12-02 20:43:31,238 INFO     Training average negative_sample_loss at step 86900: 0.065508\n",
      "2023-12-02 20:43:31,238 INFO     Training average loss at step 86900: 0.064379\n",
      "2023-12-02 20:43:42,554 INFO     Training average positive_sample_loss at step 87000: 0.062581\n",
      "2023-12-02 20:43:42,555 INFO     Training average negative_sample_loss at step 87000: 0.064901\n",
      "2023-12-02 20:43:42,555 INFO     Training average loss at step 87000: 0.063741\n",
      "2023-12-02 20:43:54,563 INFO     Training average positive_sample_loss at step 87100: 0.063241\n",
      "2023-12-02 20:43:54,564 INFO     Training average negative_sample_loss at step 87100: 0.063563\n",
      "2023-12-02 20:43:54,564 INFO     Training average loss at step 87100: 0.063402\n",
      "2023-12-02 20:44:06,649 INFO     Training average positive_sample_loss at step 87200: 0.063294\n",
      "2023-12-02 20:44:06,649 INFO     Training average negative_sample_loss at step 87200: 0.064177\n",
      "2023-12-02 20:44:06,649 INFO     Training average loss at step 87200: 0.063736\n",
      "2023-12-02 20:44:18,685 INFO     Training average positive_sample_loss at step 87300: 0.063486\n",
      "2023-12-02 20:44:18,685 INFO     Training average negative_sample_loss at step 87300: 0.064971\n",
      "2023-12-02 20:44:18,685 INFO     Training average loss at step 87300: 0.064229\n",
      "2023-12-02 20:44:29,873 INFO     Training average positive_sample_loss at step 87400: 0.064201\n",
      "2023-12-02 20:44:29,873 INFO     Training average negative_sample_loss at step 87400: 0.064204\n",
      "2023-12-02 20:44:29,873 INFO     Training average loss at step 87400: 0.064202\n",
      "2023-12-02 20:44:41,653 INFO     Training average positive_sample_loss at step 87500: 0.063469\n",
      "2023-12-02 20:44:41,653 INFO     Training average negative_sample_loss at step 87500: 0.064077\n",
      "2023-12-02 20:44:41,653 INFO     Training average loss at step 87500: 0.063773\n",
      "2023-12-02 20:44:53,581 INFO     Training average positive_sample_loss at step 87600: 0.063919\n",
      "2023-12-02 20:44:53,581 INFO     Training average negative_sample_loss at step 87600: 0.065046\n",
      "2023-12-02 20:44:53,581 INFO     Training average loss at step 87600: 0.064483\n",
      "2023-12-02 20:45:04,851 INFO     Training average positive_sample_loss at step 87700: 0.063848\n",
      "2023-12-02 20:45:04,851 INFO     Training average negative_sample_loss at step 87700: 0.064725\n",
      "2023-12-02 20:45:04,851 INFO     Training average loss at step 87700: 0.064286\n",
      "2023-12-02 20:45:17,603 INFO     Training average positive_sample_loss at step 87800: 0.063789\n",
      "2023-12-02 20:45:17,604 INFO     Training average negative_sample_loss at step 87800: 0.064581\n",
      "2023-12-02 20:45:17,604 INFO     Training average loss at step 87800: 0.064185\n",
      "2023-12-02 20:45:29,381 INFO     Training average positive_sample_loss at step 87900: 0.062273\n",
      "2023-12-02 20:45:29,381 INFO     Training average negative_sample_loss at step 87900: 0.065195\n",
      "2023-12-02 20:45:29,381 INFO     Training average loss at step 87900: 0.063734\n",
      "2023-12-02 20:45:41,204 INFO     Training average positive_sample_loss at step 88000: 0.062706\n",
      "2023-12-02 20:45:41,204 INFO     Training average negative_sample_loss at step 88000: 0.063882\n",
      "2023-12-02 20:45:41,204 INFO     Training average loss at step 88000: 0.063294\n",
      "2023-12-02 20:45:52,529 INFO     Training average positive_sample_loss at step 88100: 0.063230\n",
      "2023-12-02 20:45:52,529 INFO     Training average negative_sample_loss at step 88100: 0.064418\n",
      "2023-12-02 20:45:52,529 INFO     Training average loss at step 88100: 0.063824\n",
      "2023-12-02 20:46:04,546 INFO     Training average positive_sample_loss at step 88200: 0.063532\n",
      "2023-12-02 20:46:04,546 INFO     Training average negative_sample_loss at step 88200: 0.064457\n",
      "2023-12-02 20:46:04,546 INFO     Training average loss at step 88200: 0.063995\n",
      "2023-12-02 20:46:16,481 INFO     Training average positive_sample_loss at step 88300: 0.063475\n",
      "2023-12-02 20:46:16,481 INFO     Training average negative_sample_loss at step 88300: 0.064791\n",
      "2023-12-02 20:46:16,481 INFO     Training average loss at step 88300: 0.064133\n",
      "2023-12-02 20:46:27,817 INFO     Training average positive_sample_loss at step 88400: 0.063718\n",
      "2023-12-02 20:46:27,817 INFO     Training average negative_sample_loss at step 88400: 0.064614\n",
      "2023-12-02 20:46:27,818 INFO     Training average loss at step 88400: 0.064166\n",
      "2023-12-02 20:46:39,709 INFO     Training average positive_sample_loss at step 88500: 0.063658\n",
      "2023-12-02 20:46:39,709 INFO     Training average negative_sample_loss at step 88500: 0.064260\n",
      "2023-12-02 20:46:39,709 INFO     Training average loss at step 88500: 0.063959\n",
      "2023-12-02 20:46:51,642 INFO     Training average positive_sample_loss at step 88600: 0.064076\n",
      "2023-12-02 20:46:51,642 INFO     Training average negative_sample_loss at step 88600: 0.064394\n",
      "2023-12-02 20:46:51,642 INFO     Training average loss at step 88600: 0.064235\n",
      "2023-12-02 20:47:03,492 INFO     Training average positive_sample_loss at step 88700: 0.063714\n",
      "2023-12-02 20:47:03,492 INFO     Training average negative_sample_loss at step 88700: 0.064100\n",
      "2023-12-02 20:47:03,492 INFO     Training average loss at step 88700: 0.063907\n",
      "2023-12-02 20:47:16,173 INFO     Training average positive_sample_loss at step 88800: 0.062377\n",
      "2023-12-02 20:47:16,173 INFO     Training average negative_sample_loss at step 88800: 0.063845\n",
      "2023-12-02 20:47:16,173 INFO     Training average loss at step 88800: 0.063111\n",
      "2023-12-02 20:47:28,117 INFO     Training average positive_sample_loss at step 88900: 0.062527\n",
      "2023-12-02 20:47:28,117 INFO     Training average negative_sample_loss at step 88900: 0.064288\n",
      "2023-12-02 20:47:28,117 INFO     Training average loss at step 88900: 0.063408\n",
      "2023-12-02 20:47:40,143 INFO     Training average positive_sample_loss at step 89000: 0.062972\n",
      "2023-12-02 20:47:40,144 INFO     Training average negative_sample_loss at step 89000: 0.064145\n",
      "2023-12-02 20:47:40,144 INFO     Training average loss at step 89000: 0.063558\n",
      "2023-12-02 20:47:51,354 INFO     Training average positive_sample_loss at step 89100: 0.063447\n",
      "2023-12-02 20:47:51,354 INFO     Training average negative_sample_loss at step 89100: 0.065028\n",
      "2023-12-02 20:47:51,354 INFO     Training average loss at step 89100: 0.064238\n",
      "2023-12-02 20:48:03,338 INFO     Training average positive_sample_loss at step 89200: 0.063553\n",
      "2023-12-02 20:48:03,338 INFO     Training average negative_sample_loss at step 89200: 0.064897\n",
      "2023-12-02 20:48:03,339 INFO     Training average loss at step 89200: 0.064225\n",
      "2023-12-02 20:48:15,268 INFO     Training average positive_sample_loss at step 89300: 0.063875\n",
      "2023-12-02 20:48:15,268 INFO     Training average negative_sample_loss at step 89300: 0.064844\n",
      "2023-12-02 20:48:15,268 INFO     Training average loss at step 89300: 0.064359\n",
      "2023-12-02 20:48:27,252 INFO     Training average positive_sample_loss at step 89400: 0.064137\n",
      "2023-12-02 20:48:27,252 INFO     Training average negative_sample_loss at step 89400: 0.064914\n",
      "2023-12-02 20:48:27,252 INFO     Training average loss at step 89400: 0.064525\n",
      "2023-12-02 20:48:38,524 INFO     Training average positive_sample_loss at step 89500: 0.063869\n",
      "2023-12-02 20:48:38,524 INFO     Training average negative_sample_loss at step 89500: 0.064732\n",
      "2023-12-02 20:48:38,524 INFO     Training average loss at step 89500: 0.064300\n",
      "2023-12-02 20:48:50,409 INFO     Training average positive_sample_loss at step 89600: 0.063895\n",
      "2023-12-02 20:48:50,409 INFO     Training average negative_sample_loss at step 89600: 0.063979\n",
      "2023-12-02 20:48:50,409 INFO     Training average loss at step 89600: 0.063937\n",
      "2023-12-02 20:49:03,064 INFO     Training average positive_sample_loss at step 89700: 0.063287\n",
      "2023-12-02 20:49:03,065 INFO     Training average negative_sample_loss at step 89700: 0.065650\n",
      "2023-12-02 20:49:03,065 INFO     Training average loss at step 89700: 0.064468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 20:49:14,472 INFO     Training average positive_sample_loss at step 89800: 0.062629\n",
      "2023-12-02 20:49:14,472 INFO     Training average negative_sample_loss at step 89800: 0.064877\n",
      "2023-12-02 20:49:14,472 INFO     Training average loss at step 89800: 0.063753\n",
      "2023-12-02 20:49:26,485 INFO     Training average positive_sample_loss at step 89900: 0.063227\n",
      "2023-12-02 20:49:26,486 INFO     Training average negative_sample_loss at step 89900: 0.064999\n",
      "2023-12-02 20:49:26,486 INFO     Training average loss at step 89900: 0.064113\n",
      "2023-12-02 20:49:49,702 INFO     Training average positive_sample_loss at step 90000: 0.063428\n",
      "2023-12-02 20:49:49,702 INFO     Training average negative_sample_loss at step 90000: 0.065519\n",
      "2023-12-02 20:49:49,702 INFO     Training average loss at step 90000: 0.064474\n",
      "2023-12-02 20:49:49,702 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 20:49:50,867 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 20:51:15,156 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 20:52:39,081 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 20:54:01,823 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 20:54:55,120 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 20:56:10,359 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 20:57:33,214 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 20:57:55,160 INFO     Valid MRR at step 90000: 0.788430\n",
      "2023-12-02 20:57:55,161 INFO     Valid MR at step 90000: 40.939560\n",
      "2023-12-02 20:57:55,161 INFO     Valid HITS@1 at step 90000: 0.735250\n",
      "2023-12-02 20:57:55,161 INFO     Valid HITS@3 at step 90000: 0.822410\n",
      "2023-12-02 20:57:55,161 INFO     Valid HITS@10 at step 90000: 0.880190\n",
      "2023-12-02 20:58:06,157 INFO     Training average positive_sample_loss at step 90100: 0.063381\n",
      "2023-12-02 20:58:06,157 INFO     Training average negative_sample_loss at step 90100: 0.062889\n",
      "2023-12-02 20:58:06,157 INFO     Training average loss at step 90100: 0.063135\n",
      "2023-12-02 20:58:17,947 INFO     Training average positive_sample_loss at step 90200: 0.063469\n",
      "2023-12-02 20:58:17,947 INFO     Training average negative_sample_loss at step 90200: 0.064341\n",
      "2023-12-02 20:58:17,947 INFO     Training average loss at step 90200: 0.063905\n",
      "2023-12-02 20:58:29,772 INFO     Training average positive_sample_loss at step 90300: 0.063654\n",
      "2023-12-02 20:58:29,772 INFO     Training average negative_sample_loss at step 90300: 0.064828\n",
      "2023-12-02 20:58:29,772 INFO     Training average loss at step 90300: 0.064241\n",
      "2023-12-02 20:58:41,672 INFO     Training average positive_sample_loss at step 90400: 0.063737\n",
      "2023-12-02 20:58:41,672 INFO     Training average negative_sample_loss at step 90400: 0.063865\n",
      "2023-12-02 20:58:41,672 INFO     Training average loss at step 90400: 0.063801\n",
      "2023-12-02 20:58:52,838 INFO     Training average positive_sample_loss at step 90500: 0.063764\n",
      "2023-12-02 20:58:52,838 INFO     Training average negative_sample_loss at step 90500: 0.064716\n",
      "2023-12-02 20:58:52,838 INFO     Training average loss at step 90500: 0.064240\n",
      "2023-12-02 20:59:04,646 INFO     Training average positive_sample_loss at step 90600: 0.064153\n",
      "2023-12-02 20:59:04,646 INFO     Training average negative_sample_loss at step 90600: 0.065073\n",
      "2023-12-02 20:59:04,646 INFO     Training average loss at step 90600: 0.064613\n",
      "2023-12-02 20:59:17,311 INFO     Training average positive_sample_loss at step 90700: 0.062771\n",
      "2023-12-02 20:59:17,311 INFO     Training average negative_sample_loss at step 90700: 0.065195\n",
      "2023-12-02 20:59:17,311 INFO     Training average loss at step 90700: 0.063983\n",
      "2023-12-02 20:59:28,632 INFO     Training average positive_sample_loss at step 90800: 0.062836\n",
      "2023-12-02 20:59:28,633 INFO     Training average negative_sample_loss at step 90800: 0.064639\n",
      "2023-12-02 20:59:28,633 INFO     Training average loss at step 90800: 0.063738\n",
      "2023-12-02 20:59:40,597 INFO     Training average positive_sample_loss at step 90900: 0.062870\n",
      "2023-12-02 20:59:40,597 INFO     Training average negative_sample_loss at step 90900: 0.064064\n",
      "2023-12-02 20:59:40,597 INFO     Training average loss at step 90900: 0.063467\n",
      "2023-12-02 20:59:52,489 INFO     Training average positive_sample_loss at step 91000: 0.063269\n",
      "2023-12-02 20:59:52,490 INFO     Training average negative_sample_loss at step 91000: 0.064133\n",
      "2023-12-02 20:59:52,490 INFO     Training average loss at step 91000: 0.063701\n",
      "2023-12-02 21:00:04,427 INFO     Training average positive_sample_loss at step 91100: 0.063636\n",
      "2023-12-02 21:00:04,427 INFO     Training average negative_sample_loss at step 91100: 0.064767\n",
      "2023-12-02 21:00:04,427 INFO     Training average loss at step 91100: 0.064202\n",
      "2023-12-02 21:00:15,692 INFO     Training average positive_sample_loss at step 91200: 0.063940\n",
      "2023-12-02 21:00:15,693 INFO     Training average negative_sample_loss at step 91200: 0.065218\n",
      "2023-12-02 21:00:15,693 INFO     Training average loss at step 91200: 0.064579\n",
      "2023-12-02 21:00:27,662 INFO     Training average positive_sample_loss at step 91300: 0.063686\n",
      "2023-12-02 21:00:27,663 INFO     Training average negative_sample_loss at step 91300: 0.064154\n",
      "2023-12-02 21:00:27,663 INFO     Training average loss at step 91300: 0.063920\n",
      "2023-12-02 21:00:39,627 INFO     Training average positive_sample_loss at step 91400: 0.063937\n",
      "2023-12-02 21:00:39,627 INFO     Training average negative_sample_loss at step 91400: 0.064048\n",
      "2023-12-02 21:00:39,627 INFO     Training average loss at step 91400: 0.063993\n",
      "2023-12-02 21:00:51,376 INFO     Training average positive_sample_loss at step 91500: 0.063914\n",
      "2023-12-02 21:00:51,376 INFO     Training average negative_sample_loss at step 91500: 0.064396\n",
      "2023-12-02 21:00:51,376 INFO     Training average loss at step 91500: 0.064155\n",
      "2023-12-02 21:01:03,753 INFO     Training average positive_sample_loss at step 91600: 0.062977\n",
      "2023-12-02 21:01:03,753 INFO     Training average negative_sample_loss at step 91600: 0.063905\n",
      "2023-12-02 21:01:03,753 INFO     Training average loss at step 91600: 0.063441\n",
      "2023-12-02 21:01:15,821 INFO     Training average positive_sample_loss at step 91700: 0.062521\n",
      "2023-12-02 21:01:15,821 INFO     Training average negative_sample_loss at step 91700: 0.064324\n",
      "2023-12-02 21:01:15,821 INFO     Training average loss at step 91700: 0.063422\n",
      "2023-12-02 21:01:27,946 INFO     Training average positive_sample_loss at step 91800: 0.062938\n",
      "2023-12-02 21:01:27,946 INFO     Training average negative_sample_loss at step 91800: 0.063558\n",
      "2023-12-02 21:01:27,946 INFO     Training average loss at step 91800: 0.063248\n",
      "2023-12-02 21:01:39,310 INFO     Training average positive_sample_loss at step 91900: 0.063205\n",
      "2023-12-02 21:01:39,311 INFO     Training average negative_sample_loss at step 91900: 0.064483\n",
      "2023-12-02 21:01:39,311 INFO     Training average loss at step 91900: 0.063844\n",
      "2023-12-02 21:01:51,344 INFO     Training average positive_sample_loss at step 92000: 0.063317\n",
      "2023-12-02 21:01:51,345 INFO     Training average negative_sample_loss at step 92000: 0.064483\n",
      "2023-12-02 21:01:51,345 INFO     Training average loss at step 92000: 0.063900\n",
      "2023-12-02 21:02:03,398 INFO     Training average positive_sample_loss at step 92100: 0.063629\n",
      "2023-12-02 21:02:03,398 INFO     Training average negative_sample_loss at step 92100: 0.064113\n",
      "2023-12-02 21:02:03,398 INFO     Training average loss at step 92100: 0.063871\n",
      "2023-12-02 21:02:14,702 INFO     Training average positive_sample_loss at step 92200: 0.063605\n",
      "2023-12-02 21:02:14,702 INFO     Training average negative_sample_loss at step 92200: 0.064440\n",
      "2023-12-02 21:02:14,702 INFO     Training average loss at step 92200: 0.064022\n",
      "2023-12-02 21:02:26,554 INFO     Training average positive_sample_loss at step 92300: 0.063737\n",
      "2023-12-02 21:02:26,554 INFO     Training average negative_sample_loss at step 92300: 0.064679\n",
      "2023-12-02 21:02:26,554 INFO     Training average loss at step 92300: 0.064208\n",
      "2023-12-02 21:02:38,436 INFO     Training average positive_sample_loss at step 92400: 0.063659\n",
      "2023-12-02 21:02:38,437 INFO     Training average negative_sample_loss at step 92400: 0.063548\n",
      "2023-12-02 21:02:38,437 INFO     Training average loss at step 92400: 0.063604\n",
      "2023-12-02 21:02:50,521 INFO     Training average positive_sample_loss at step 92500: 0.064075\n",
      "2023-12-02 21:02:50,521 INFO     Training average negative_sample_loss at step 92500: 0.064867\n",
      "2023-12-02 21:02:50,521 INFO     Training average loss at step 92500: 0.064471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:03:02,410 INFO     Training average positive_sample_loss at step 92600: 0.062376\n",
      "2023-12-02 21:03:02,411 INFO     Training average negative_sample_loss at step 92600: 0.064983\n",
      "2023-12-02 21:03:02,411 INFO     Training average loss at step 92600: 0.063679\n",
      "2023-12-02 21:03:14,409 INFO     Training average positive_sample_loss at step 92700: 0.062782\n",
      "2023-12-02 21:03:14,409 INFO     Training average negative_sample_loss at step 92700: 0.063987\n",
      "2023-12-02 21:03:14,409 INFO     Training average loss at step 92700: 0.063385\n",
      "2023-12-02 21:03:26,305 INFO     Training average positive_sample_loss at step 92800: 0.062772\n",
      "2023-12-02 21:03:26,306 INFO     Training average negative_sample_loss at step 92800: 0.063448\n",
      "2023-12-02 21:03:26,306 INFO     Training average loss at step 92800: 0.063110\n",
      "2023-12-02 21:03:37,803 INFO     Training average positive_sample_loss at step 92900: 0.063269\n",
      "2023-12-02 21:03:37,804 INFO     Training average negative_sample_loss at step 92900: 0.064613\n",
      "2023-12-02 21:03:37,804 INFO     Training average loss at step 92900: 0.063941\n",
      "2023-12-02 21:03:49,322 INFO     Training average positive_sample_loss at step 93000: 0.063655\n",
      "2023-12-02 21:03:49,322 INFO     Training average negative_sample_loss at step 93000: 0.064242\n",
      "2023-12-02 21:03:49,322 INFO     Training average loss at step 93000: 0.063948\n",
      "2023-12-02 21:04:01,240 INFO     Training average positive_sample_loss at step 93100: 0.063419\n",
      "2023-12-02 21:04:01,241 INFO     Training average negative_sample_loss at step 93100: 0.064440\n",
      "2023-12-02 21:04:01,241 INFO     Training average loss at step 93100: 0.063930\n",
      "2023-12-02 21:04:13,132 INFO     Training average positive_sample_loss at step 93200: 0.063777\n",
      "2023-12-02 21:04:13,133 INFO     Training average negative_sample_loss at step 93200: 0.064550\n",
      "2023-12-02 21:04:13,133 INFO     Training average loss at step 93200: 0.064164\n",
      "2023-12-02 21:04:24,308 INFO     Training average positive_sample_loss at step 93300: 0.063729\n",
      "2023-12-02 21:04:24,308 INFO     Training average negative_sample_loss at step 93300: 0.064198\n",
      "2023-12-02 21:04:24,308 INFO     Training average loss at step 93300: 0.063963\n",
      "2023-12-02 21:04:36,455 INFO     Training average positive_sample_loss at step 93400: 0.063671\n",
      "2023-12-02 21:04:36,455 INFO     Training average negative_sample_loss at step 93400: 0.063898\n",
      "2023-12-02 21:04:36,455 INFO     Training average loss at step 93400: 0.063785\n",
      "2023-12-02 21:04:49,283 INFO     Training average positive_sample_loss at step 93500: 0.062724\n",
      "2023-12-02 21:04:49,283 INFO     Training average negative_sample_loss at step 93500: 0.063918\n",
      "2023-12-02 21:04:49,283 INFO     Training average loss at step 93500: 0.063321\n",
      "2023-12-02 21:05:00,987 INFO     Training average positive_sample_loss at step 93600: 0.062318\n",
      "2023-12-02 21:05:00,988 INFO     Training average negative_sample_loss at step 93600: 0.065091\n",
      "2023-12-02 21:05:00,988 INFO     Training average loss at step 93600: 0.063704\n",
      "2023-12-02 21:05:12,464 INFO     Training average positive_sample_loss at step 93700: 0.062795\n",
      "2023-12-02 21:05:12,464 INFO     Training average negative_sample_loss at step 93700: 0.063774\n",
      "2023-12-02 21:05:12,464 INFO     Training average loss at step 93700: 0.063285\n",
      "2023-12-02 21:05:24,487 INFO     Training average positive_sample_loss at step 93800: 0.063360\n",
      "2023-12-02 21:05:24,487 INFO     Training average negative_sample_loss at step 93800: 0.063885\n",
      "2023-12-02 21:05:24,487 INFO     Training average loss at step 93800: 0.063622\n",
      "2023-12-02 21:05:36,408 INFO     Training average positive_sample_loss at step 93900: 0.063368\n",
      "2023-12-02 21:05:36,409 INFO     Training average negative_sample_loss at step 93900: 0.063551\n",
      "2023-12-02 21:05:36,409 INFO     Training average loss at step 93900: 0.063460\n",
      "2023-12-02 21:05:47,609 INFO     Training average positive_sample_loss at step 94000: 0.063577\n",
      "2023-12-02 21:05:47,610 INFO     Training average negative_sample_loss at step 94000: 0.064354\n",
      "2023-12-02 21:05:47,610 INFO     Training average loss at step 94000: 0.063965\n",
      "2023-12-02 21:05:59,421 INFO     Training average positive_sample_loss at step 94100: 0.063565\n",
      "2023-12-02 21:05:59,421 INFO     Training average negative_sample_loss at step 94100: 0.065340\n",
      "2023-12-02 21:05:59,421 INFO     Training average loss at step 94100: 0.064453\n",
      "2023-12-02 21:06:11,437 INFO     Training average positive_sample_loss at step 94200: 0.063575\n",
      "2023-12-02 21:06:11,438 INFO     Training average negative_sample_loss at step 94200: 0.064127\n",
      "2023-12-02 21:06:11,438 INFO     Training average loss at step 94200: 0.063851\n",
      "2023-12-02 21:06:23,301 INFO     Training average positive_sample_loss at step 94300: 0.063920\n",
      "2023-12-02 21:06:23,301 INFO     Training average negative_sample_loss at step 94300: 0.064873\n",
      "2023-12-02 21:06:23,301 INFO     Training average loss at step 94300: 0.064396\n",
      "2023-12-02 21:06:35,123 INFO     Training average positive_sample_loss at step 94400: 0.064063\n",
      "2023-12-02 21:06:35,123 INFO     Training average negative_sample_loss at step 94400: 0.064746\n",
      "2023-12-02 21:06:35,123 INFO     Training average loss at step 94400: 0.064404\n",
      "2023-12-02 21:06:47,450 INFO     Training average positive_sample_loss at step 94500: 0.062434\n",
      "2023-12-02 21:06:47,451 INFO     Training average negative_sample_loss at step 94500: 0.064962\n",
      "2023-12-02 21:06:47,451 INFO     Training average loss at step 94500: 0.063698\n",
      "2023-12-02 21:06:59,291 INFO     Training average positive_sample_loss at step 94600: 0.062747\n",
      "2023-12-02 21:06:59,291 INFO     Training average negative_sample_loss at step 94600: 0.065480\n",
      "2023-12-02 21:06:59,291 INFO     Training average loss at step 94600: 0.064113\n",
      "2023-12-02 21:07:10,495 INFO     Training average positive_sample_loss at step 94700: 0.063171\n",
      "2023-12-02 21:07:10,496 INFO     Training average negative_sample_loss at step 94700: 0.063855\n",
      "2023-12-02 21:07:10,496 INFO     Training average loss at step 94700: 0.063513\n",
      "2023-12-02 21:07:22,372 INFO     Training average positive_sample_loss at step 94800: 0.063593\n",
      "2023-12-02 21:07:22,372 INFO     Training average negative_sample_loss at step 94800: 0.064089\n",
      "2023-12-02 21:07:22,372 INFO     Training average loss at step 94800: 0.063841\n",
      "2023-12-02 21:07:34,328 INFO     Training average positive_sample_loss at step 94900: 0.063214\n",
      "2023-12-02 21:07:34,328 INFO     Training average negative_sample_loss at step 94900: 0.063726\n",
      "2023-12-02 21:07:34,328 INFO     Training average loss at step 94900: 0.063470\n",
      "2023-12-02 21:07:46,356 INFO     Training average positive_sample_loss at step 95000: 0.063461\n",
      "2023-12-02 21:07:46,356 INFO     Training average negative_sample_loss at step 95000: 0.063422\n",
      "2023-12-02 21:07:46,356 INFO     Training average loss at step 95000: 0.063441\n",
      "2023-12-02 21:07:57,692 INFO     Training average positive_sample_loss at step 95100: 0.063779\n",
      "2023-12-02 21:07:57,692 INFO     Training average negative_sample_loss at step 95100: 0.064764\n",
      "2023-12-02 21:07:57,692 INFO     Training average loss at step 95100: 0.064272\n",
      "2023-12-02 21:08:09,612 INFO     Training average positive_sample_loss at step 95200: 0.063904\n",
      "2023-12-02 21:08:09,612 INFO     Training average negative_sample_loss at step 95200: 0.064797\n",
      "2023-12-02 21:08:09,612 INFO     Training average loss at step 95200: 0.064350\n",
      "2023-12-02 21:08:21,399 INFO     Training average positive_sample_loss at step 95300: 0.063887\n",
      "2023-12-02 21:08:21,399 INFO     Training average negative_sample_loss at step 95300: 0.064312\n",
      "2023-12-02 21:08:21,399 INFO     Training average loss at step 95300: 0.064100\n",
      "2023-12-02 21:08:33,396 INFO     Training average positive_sample_loss at step 95400: 0.062966\n",
      "2023-12-02 21:08:33,396 INFO     Training average negative_sample_loss at step 95400: 0.063685\n",
      "2023-12-02 21:08:33,396 INFO     Training average loss at step 95400: 0.063326\n",
      "2023-12-02 21:08:45,515 INFO     Training average positive_sample_loss at step 95500: 0.062485\n",
      "2023-12-02 21:08:45,515 INFO     Training average negative_sample_loss at step 95500: 0.064649\n",
      "2023-12-02 21:08:45,515 INFO     Training average loss at step 95500: 0.063567\n",
      "2023-12-02 21:08:57,468 INFO     Training average positive_sample_loss at step 95600: 0.062728\n",
      "2023-12-02 21:08:57,468 INFO     Training average negative_sample_loss at step 95600: 0.064313\n",
      "2023-12-02 21:08:57,468 INFO     Training average loss at step 95600: 0.063521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:09:09,349 INFO     Training average positive_sample_loss at step 95700: 0.063423\n",
      "2023-12-02 21:09:09,349 INFO     Training average negative_sample_loss at step 95700: 0.064563\n",
      "2023-12-02 21:09:09,349 INFO     Training average loss at step 95700: 0.063993\n",
      "2023-12-02 21:09:20,648 INFO     Training average positive_sample_loss at step 95800: 0.063176\n",
      "2023-12-02 21:09:20,648 INFO     Training average negative_sample_loss at step 95800: 0.063086\n",
      "2023-12-02 21:09:20,648 INFO     Training average loss at step 95800: 0.063131\n",
      "2023-12-02 21:09:32,622 INFO     Training average positive_sample_loss at step 95900: 0.063550\n",
      "2023-12-02 21:09:32,622 INFO     Training average negative_sample_loss at step 95900: 0.064655\n",
      "2023-12-02 21:09:32,622 INFO     Training average loss at step 95900: 0.064103\n",
      "2023-12-02 21:09:44,550 INFO     Training average positive_sample_loss at step 96000: 0.063465\n",
      "2023-12-02 21:09:44,551 INFO     Training average negative_sample_loss at step 96000: 0.063848\n",
      "2023-12-02 21:09:44,551 INFO     Training average loss at step 96000: 0.063657\n",
      "2023-12-02 21:09:55,885 INFO     Training average positive_sample_loss at step 96100: 0.063824\n",
      "2023-12-02 21:09:55,885 INFO     Training average negative_sample_loss at step 96100: 0.064284\n",
      "2023-12-02 21:09:55,885 INFO     Training average loss at step 96100: 0.064054\n",
      "2023-12-02 21:10:07,862 INFO     Training average positive_sample_loss at step 96200: 0.063766\n",
      "2023-12-02 21:10:07,863 INFO     Training average negative_sample_loss at step 96200: 0.063975\n",
      "2023-12-02 21:10:07,863 INFO     Training average loss at step 96200: 0.063870\n",
      "2023-12-02 21:10:20,591 INFO     Training average positive_sample_loss at step 96300: 0.063613\n",
      "2023-12-02 21:10:20,591 INFO     Training average negative_sample_loss at step 96300: 0.064597\n",
      "2023-12-02 21:10:20,591 INFO     Training average loss at step 96300: 0.064105\n",
      "2023-12-02 21:10:32,356 INFO     Training average positive_sample_loss at step 96400: 0.062270\n",
      "2023-12-02 21:10:32,356 INFO     Training average negative_sample_loss at step 96400: 0.064155\n",
      "2023-12-02 21:10:32,356 INFO     Training average loss at step 96400: 0.063213\n",
      "2023-12-02 21:10:43,684 INFO     Training average positive_sample_loss at step 96500: 0.062854\n",
      "2023-12-02 21:10:43,684 INFO     Training average negative_sample_loss at step 96500: 0.064134\n",
      "2023-12-02 21:10:43,684 INFO     Training average loss at step 96500: 0.063494\n",
      "2023-12-02 21:10:55,761 INFO     Training average positive_sample_loss at step 96600: 0.062934\n",
      "2023-12-02 21:10:55,762 INFO     Training average negative_sample_loss at step 96600: 0.063925\n",
      "2023-12-02 21:10:55,762 INFO     Training average loss at step 96600: 0.063430\n",
      "2023-12-02 21:11:07,765 INFO     Training average positive_sample_loss at step 96700: 0.063084\n",
      "2023-12-02 21:11:07,765 INFO     Training average negative_sample_loss at step 96700: 0.064060\n",
      "2023-12-02 21:11:07,765 INFO     Training average loss at step 96700: 0.063572\n",
      "2023-12-02 21:11:18,963 INFO     Training average positive_sample_loss at step 96800: 0.063742\n",
      "2023-12-02 21:11:18,964 INFO     Training average negative_sample_loss at step 96800: 0.065063\n",
      "2023-12-02 21:11:18,964 INFO     Training average loss at step 96800: 0.064403\n",
      "2023-12-02 21:11:31,011 INFO     Training average positive_sample_loss at step 96900: 0.063323\n",
      "2023-12-02 21:11:31,011 INFO     Training average negative_sample_loss at step 96900: 0.063441\n",
      "2023-12-02 21:11:31,011 INFO     Training average loss at step 96900: 0.063382\n",
      "2023-12-02 21:11:42,877 INFO     Training average positive_sample_loss at step 97000: 0.063486\n",
      "2023-12-02 21:11:42,878 INFO     Training average negative_sample_loss at step 97000: 0.064461\n",
      "2023-12-02 21:11:42,878 INFO     Training average loss at step 97000: 0.063973\n",
      "2023-12-02 21:11:54,885 INFO     Training average positive_sample_loss at step 97100: 0.063955\n",
      "2023-12-02 21:11:54,886 INFO     Training average negative_sample_loss at step 97100: 0.064145\n",
      "2023-12-02 21:11:54,886 INFO     Training average loss at step 97100: 0.064050\n",
      "2023-12-02 21:12:06,276 INFO     Training average positive_sample_loss at step 97200: 0.063711\n",
      "2023-12-02 21:12:06,276 INFO     Training average negative_sample_loss at step 97200: 0.064452\n",
      "2023-12-02 21:12:06,277 INFO     Training average loss at step 97200: 0.064082\n",
      "2023-12-02 21:12:19,119 INFO     Training average positive_sample_loss at step 97300: 0.062332\n",
      "2023-12-02 21:12:19,119 INFO     Training average negative_sample_loss at step 97300: 0.064300\n",
      "2023-12-02 21:12:19,119 INFO     Training average loss at step 97300: 0.063316\n",
      "2023-12-02 21:12:31,121 INFO     Training average positive_sample_loss at step 97400: 0.062497\n",
      "2023-12-02 21:12:31,121 INFO     Training average negative_sample_loss at step 97400: 0.063245\n",
      "2023-12-02 21:12:31,121 INFO     Training average loss at step 97400: 0.062871\n",
      "2023-12-02 21:12:42,527 INFO     Training average positive_sample_loss at step 97500: 0.062804\n",
      "2023-12-02 21:12:42,528 INFO     Training average negative_sample_loss at step 97500: 0.064632\n",
      "2023-12-02 21:12:42,528 INFO     Training average loss at step 97500: 0.063718\n",
      "2023-12-02 21:12:54,594 INFO     Training average positive_sample_loss at step 97600: 0.063469\n",
      "2023-12-02 21:12:54,594 INFO     Training average negative_sample_loss at step 97600: 0.064665\n",
      "2023-12-02 21:12:54,594 INFO     Training average loss at step 97600: 0.064067\n",
      "2023-12-02 21:13:06,528 INFO     Training average positive_sample_loss at step 97700: 0.063137\n",
      "2023-12-02 21:13:06,528 INFO     Training average negative_sample_loss at step 97700: 0.063971\n",
      "2023-12-02 21:13:06,528 INFO     Training average loss at step 97700: 0.063554\n",
      "2023-12-02 21:13:18,580 INFO     Training average positive_sample_loss at step 97800: 0.063659\n",
      "2023-12-02 21:13:18,581 INFO     Training average negative_sample_loss at step 97800: 0.064612\n",
      "2023-12-02 21:13:18,581 INFO     Training average loss at step 97800: 0.064135\n",
      "2023-12-02 21:13:29,936 INFO     Training average positive_sample_loss at step 97900: 0.063803\n",
      "2023-12-02 21:13:29,937 INFO     Training average negative_sample_loss at step 97900: 0.064641\n",
      "2023-12-02 21:13:29,937 INFO     Training average loss at step 97900: 0.064222\n",
      "2023-12-02 21:13:41,906 INFO     Training average positive_sample_loss at step 98000: 0.063803\n",
      "2023-12-02 21:13:41,906 INFO     Training average negative_sample_loss at step 98000: 0.064747\n",
      "2023-12-02 21:13:41,906 INFO     Training average loss at step 98000: 0.064275\n",
      "2023-12-02 21:13:53,793 INFO     Training average positive_sample_loss at step 98100: 0.063604\n",
      "2023-12-02 21:13:53,794 INFO     Training average negative_sample_loss at step 98100: 0.064575\n",
      "2023-12-02 21:13:53,794 INFO     Training average loss at step 98100: 0.064090\n",
      "2023-12-02 21:14:05,859 INFO     Training average positive_sample_loss at step 98200: 0.063399\n",
      "2023-12-02 21:14:05,859 INFO     Training average negative_sample_loss at step 98200: 0.064438\n",
      "2023-12-02 21:14:05,859 INFO     Training average loss at step 98200: 0.063918\n",
      "2023-12-02 21:14:17,848 INFO     Training average positive_sample_loss at step 98300: 0.062572\n",
      "2023-12-02 21:14:17,849 INFO     Training average negative_sample_loss at step 98300: 0.065134\n",
      "2023-12-02 21:14:17,849 INFO     Training average loss at step 98300: 0.063853\n",
      "2023-12-02 21:14:27,237 INFO     Training average positive_sample_loss at step 98400: 0.062852\n",
      "2023-12-02 21:14:29,202 INFO     Training average negative_sample_loss at step 98400: 0.064224\n",
      "2023-12-02 21:14:29,202 INFO     Training average loss at step 98400: 0.063538\n",
      "2023-12-02 21:14:37,456 INFO     Training average positive_sample_loss at step 98500: 0.063168\n",
      "2023-12-02 21:14:37,457 INFO     Training average negative_sample_loss at step 98500: 0.063231\n",
      "2023-12-02 21:14:37,457 INFO     Training average loss at step 98500: 0.063200\n",
      "2023-12-02 21:14:45,603 INFO     Training average positive_sample_loss at step 98600: 0.063298\n",
      "2023-12-02 21:14:45,604 INFO     Training average negative_sample_loss at step 98600: 0.063252\n",
      "2023-12-02 21:14:45,604 INFO     Training average loss at step 98600: 0.063275\n",
      "2023-12-02 21:14:53,794 INFO     Training average positive_sample_loss at step 98700: 0.063389\n",
      "2023-12-02 21:14:53,794 INFO     Training average negative_sample_loss at step 98700: 0.064267\n",
      "2023-12-02 21:14:53,794 INFO     Training average loss at step 98700: 0.063828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:15:02,156 INFO     Training average positive_sample_loss at step 98800: 0.063426\n",
      "2023-12-02 21:15:02,157 INFO     Training average negative_sample_loss at step 98800: 0.064677\n",
      "2023-12-02 21:15:02,157 INFO     Training average loss at step 98800: 0.064052\n",
      "2023-12-02 21:15:10,418 INFO     Training average positive_sample_loss at step 98900: 0.063463\n",
      "2023-12-02 21:15:10,418 INFO     Training average negative_sample_loss at step 98900: 0.063569\n",
      "2023-12-02 21:15:10,418 INFO     Training average loss at step 98900: 0.063516\n",
      "2023-12-02 21:15:21,141 INFO     Training average positive_sample_loss at step 99000: 0.063808\n",
      "2023-12-02 21:15:21,141 INFO     Training average negative_sample_loss at step 99000: 0.063554\n",
      "2023-12-02 21:15:21,142 INFO     Training average loss at step 99000: 0.063681\n",
      "2023-12-02 21:15:32,991 INFO     Training average positive_sample_loss at step 99100: 0.063987\n",
      "2023-12-02 21:15:32,992 INFO     Training average negative_sample_loss at step 99100: 0.065069\n",
      "2023-12-02 21:15:32,992 INFO     Training average loss at step 99100: 0.064528\n",
      "2023-12-02 21:15:45,564 INFO     Training average positive_sample_loss at step 99200: 0.062522\n",
      "2023-12-02 21:15:45,565 INFO     Training average negative_sample_loss at step 99200: 0.064956\n",
      "2023-12-02 21:15:45,565 INFO     Training average loss at step 99200: 0.063739\n",
      "2023-12-02 21:15:57,487 INFO     Training average positive_sample_loss at step 99300: 0.062625\n",
      "2023-12-02 21:15:57,487 INFO     Training average negative_sample_loss at step 99300: 0.063609\n",
      "2023-12-02 21:15:57,487 INFO     Training average loss at step 99300: 0.063117\n",
      "2023-12-02 21:16:09,483 INFO     Training average positive_sample_loss at step 99400: 0.063087\n",
      "2023-12-02 21:16:09,484 INFO     Training average negative_sample_loss at step 99400: 0.064408\n",
      "2023-12-02 21:16:09,484 INFO     Training average loss at step 99400: 0.063748\n",
      "2023-12-02 21:16:20,752 INFO     Training average positive_sample_loss at step 99500: 0.063060\n",
      "2023-12-02 21:16:20,752 INFO     Training average negative_sample_loss at step 99500: 0.064064\n",
      "2023-12-02 21:16:20,752 INFO     Training average loss at step 99500: 0.063562\n",
      "2023-12-02 21:16:32,770 INFO     Training average positive_sample_loss at step 99600: 0.063232\n",
      "2023-12-02 21:16:32,771 INFO     Training average negative_sample_loss at step 99600: 0.063722\n",
      "2023-12-02 21:16:32,771 INFO     Training average loss at step 99600: 0.063477\n",
      "2023-12-02 21:16:44,816 INFO     Training average positive_sample_loss at step 99700: 0.063354\n",
      "2023-12-02 21:16:44,816 INFO     Training average negative_sample_loss at step 99700: 0.063308\n",
      "2023-12-02 21:16:44,816 INFO     Training average loss at step 99700: 0.063331\n",
      "2023-12-02 21:16:56,677 INFO     Training average positive_sample_loss at step 99800: 0.063637\n",
      "2023-12-02 21:16:56,677 INFO     Training average negative_sample_loss at step 99800: 0.063296\n",
      "2023-12-02 21:16:56,677 INFO     Training average loss at step 99800: 0.063466\n",
      "2023-12-02 21:17:08,085 INFO     Training average positive_sample_loss at step 99900: 0.063399\n",
      "2023-12-02 21:17:08,085 INFO     Training average negative_sample_loss at step 99900: 0.064466\n",
      "2023-12-02 21:17:08,085 INFO     Training average loss at step 99900: 0.063932\n",
      "2023-12-02 21:17:32,336 INFO     Training average positive_sample_loss at step 100000: 0.063837\n",
      "2023-12-02 21:17:32,337 INFO     Training average negative_sample_loss at step 100000: 0.064070\n",
      "2023-12-02 21:17:32,337 INFO     Training average loss at step 100000: 0.063953\n",
      "2023-12-02 21:17:32,337 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 21:17:33,339 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 21:18:58,081 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 21:20:20,627 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 21:21:42,304 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 21:23:05,669 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 21:24:30,451 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 21:25:52,789 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 21:26:13,265 INFO     Valid MRR at step 100000: 0.790305\n",
      "2023-12-02 21:26:13,265 INFO     Valid MR at step 100000: 40.914910\n",
      "2023-12-02 21:26:13,265 INFO     Valid HITS@1 at step 100000: 0.738180\n",
      "2023-12-02 21:26:13,265 INFO     Valid HITS@3 at step 100000: 0.823710\n",
      "2023-12-02 21:26:13,265 INFO     Valid HITS@10 at step 100000: 0.880800\n",
      "2023-12-02 21:26:26,073 INFO     Training average positive_sample_loss at step 100100: 0.063162\n",
      "2023-12-02 21:26:26,073 INFO     Training average negative_sample_loss at step 100100: 0.064204\n",
      "2023-12-02 21:26:26,073 INFO     Training average loss at step 100100: 0.063683\n",
      "2023-12-02 21:26:37,865 INFO     Training average positive_sample_loss at step 100200: 0.062352\n",
      "2023-12-02 21:26:37,865 INFO     Training average negative_sample_loss at step 100200: 0.063549\n",
      "2023-12-02 21:26:37,865 INFO     Training average loss at step 100200: 0.062950\n",
      "2023-12-02 21:26:48,894 INFO     Training average positive_sample_loss at step 100300: 0.062806\n",
      "2023-12-02 21:26:48,894 INFO     Training average negative_sample_loss at step 100300: 0.063835\n",
      "2023-12-02 21:26:48,895 INFO     Training average loss at step 100300: 0.063321\n",
      "2023-12-02 21:27:00,724 INFO     Training average positive_sample_loss at step 100400: 0.062935\n",
      "2023-12-02 21:27:00,725 INFO     Training average negative_sample_loss at step 100400: 0.064205\n",
      "2023-12-02 21:27:00,725 INFO     Training average loss at step 100400: 0.063570\n",
      "2023-12-02 21:27:12,601 INFO     Training average positive_sample_loss at step 100500: 0.063036\n",
      "2023-12-02 21:27:12,601 INFO     Training average negative_sample_loss at step 100500: 0.064102\n",
      "2023-12-02 21:27:12,601 INFO     Training average loss at step 100500: 0.063569\n",
      "2023-12-02 21:27:24,505 INFO     Training average positive_sample_loss at step 100600: 0.063249\n",
      "2023-12-02 21:27:24,505 INFO     Training average negative_sample_loss at step 100600: 0.063635\n",
      "2023-12-02 21:27:24,505 INFO     Training average loss at step 100600: 0.063442\n",
      "2023-12-02 21:27:35,796 INFO     Training average positive_sample_loss at step 100700: 0.063375\n",
      "2023-12-02 21:27:35,796 INFO     Training average negative_sample_loss at step 100700: 0.063703\n",
      "2023-12-02 21:27:35,797 INFO     Training average loss at step 100700: 0.063539\n",
      "2023-12-02 21:27:47,739 INFO     Training average positive_sample_loss at step 100800: 0.063424\n",
      "2023-12-02 21:27:47,739 INFO     Training average negative_sample_loss at step 100800: 0.064459\n",
      "2023-12-02 21:27:47,739 INFO     Training average loss at step 100800: 0.063941\n",
      "2023-12-02 21:27:59,552 INFO     Training average positive_sample_loss at step 100900: 0.063435\n",
      "2023-12-02 21:27:59,552 INFO     Training average negative_sample_loss at step 100900: 0.063867\n",
      "2023-12-02 21:27:59,552 INFO     Training average loss at step 100900: 0.063651\n",
      "2023-12-02 21:28:10,788 INFO     Training average positive_sample_loss at step 101000: 0.063769\n",
      "2023-12-02 21:28:10,788 INFO     Training average negative_sample_loss at step 101000: 0.064449\n",
      "2023-12-02 21:28:10,788 INFO     Training average loss at step 101000: 0.064109\n",
      "2023-12-02 21:28:23,378 INFO     Training average positive_sample_loss at step 101100: 0.062245\n",
      "2023-12-02 21:28:23,379 INFO     Training average negative_sample_loss at step 101100: 0.064265\n",
      "2023-12-02 21:28:23,379 INFO     Training average loss at step 101100: 0.063255\n",
      "2023-12-02 21:28:35,337 INFO     Training average positive_sample_loss at step 101200: 0.062780\n",
      "2023-12-02 21:28:35,340 INFO     Training average negative_sample_loss at step 101200: 0.063402\n",
      "2023-12-02 21:28:35,340 INFO     Training average loss at step 101200: 0.063091\n",
      "2023-12-02 21:28:47,111 INFO     Training average positive_sample_loss at step 101300: 0.062854\n",
      "2023-12-02 21:28:47,115 INFO     Training average negative_sample_loss at step 101300: 0.062722\n",
      "2023-12-02 21:28:47,115 INFO     Training average loss at step 101300: 0.062788\n",
      "2023-12-02 21:28:58,253 INFO     Training average positive_sample_loss at step 101400: 0.063068\n",
      "2023-12-02 21:28:58,253 INFO     Training average negative_sample_loss at step 101400: 0.063827\n",
      "2023-12-02 21:28:58,253 INFO     Training average loss at step 101400: 0.063448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:29:10,072 INFO     Training average positive_sample_loss at step 101500: 0.062946\n",
      "2023-12-02 21:29:10,072 INFO     Training average negative_sample_loss at step 101500: 0.063307\n",
      "2023-12-02 21:29:10,072 INFO     Training average loss at step 101500: 0.063127\n",
      "2023-12-02 21:29:21,926 INFO     Training average positive_sample_loss at step 101600: 0.063644\n",
      "2023-12-02 21:29:21,926 INFO     Training average negative_sample_loss at step 101600: 0.064658\n",
      "2023-12-02 21:29:21,927 INFO     Training average loss at step 101600: 0.064151\n",
      "2023-12-02 21:29:33,033 INFO     Training average positive_sample_loss at step 101700: 0.063726\n",
      "2023-12-02 21:29:33,033 INFO     Training average negative_sample_loss at step 101700: 0.064120\n",
      "2023-12-02 21:29:33,033 INFO     Training average loss at step 101700: 0.063923\n",
      "2023-12-02 21:29:44,839 INFO     Training average positive_sample_loss at step 101800: 0.063731\n",
      "2023-12-02 21:29:44,840 INFO     Training average negative_sample_loss at step 101800: 0.063699\n",
      "2023-12-02 21:29:44,840 INFO     Training average loss at step 101800: 0.063715\n",
      "2023-12-02 21:29:56,606 INFO     Training average positive_sample_loss at step 101900: 0.063474\n",
      "2023-12-02 21:29:56,606 INFO     Training average negative_sample_loss at step 101900: 0.064526\n",
      "2023-12-02 21:29:56,606 INFO     Training average loss at step 101900: 0.064000\n",
      "2023-12-02 21:30:09,351 INFO     Training average positive_sample_loss at step 102000: 0.062933\n",
      "2023-12-02 21:30:09,351 INFO     Training average negative_sample_loss at step 102000: 0.064549\n",
      "2023-12-02 21:30:09,351 INFO     Training average loss at step 102000: 0.063741\n",
      "2023-12-02 21:30:20,548 INFO     Training average positive_sample_loss at step 102100: 0.062334\n",
      "2023-12-02 21:30:20,549 INFO     Training average negative_sample_loss at step 102100: 0.062892\n",
      "2023-12-02 21:30:20,549 INFO     Training average loss at step 102100: 0.062613\n",
      "2023-12-02 21:30:32,482 INFO     Training average positive_sample_loss at step 102200: 0.062737\n",
      "2023-12-02 21:30:32,482 INFO     Training average negative_sample_loss at step 102200: 0.064042\n",
      "2023-12-02 21:30:32,482 INFO     Training average loss at step 102200: 0.063389\n",
      "2023-12-02 21:30:44,337 INFO     Training average positive_sample_loss at step 102300: 0.062830\n",
      "2023-12-02 21:30:44,338 INFO     Training average negative_sample_loss at step 102300: 0.064642\n",
      "2023-12-02 21:30:44,338 INFO     Training average loss at step 102300: 0.063736\n",
      "2023-12-02 21:30:55,875 INFO     Training average positive_sample_loss at step 102400: 0.063160\n",
      "2023-12-02 21:30:55,876 INFO     Training average negative_sample_loss at step 102400: 0.064025\n",
      "2023-12-02 21:30:55,876 INFO     Training average loss at step 102400: 0.063592\n",
      "2023-12-02 21:31:07,340 INFO     Training average positive_sample_loss at step 102500: 0.063538\n",
      "2023-12-02 21:31:07,341 INFO     Training average negative_sample_loss at step 102500: 0.064594\n",
      "2023-12-02 21:31:07,341 INFO     Training average loss at step 102500: 0.064066\n",
      "2023-12-02 21:31:19,290 INFO     Training average positive_sample_loss at step 102600: 0.063719\n",
      "2023-12-02 21:31:19,291 INFO     Training average negative_sample_loss at step 102600: 0.064472\n",
      "2023-12-02 21:31:19,291 INFO     Training average loss at step 102600: 0.064095\n",
      "2023-12-02 21:31:31,081 INFO     Training average positive_sample_loss at step 102700: 0.063599\n",
      "2023-12-02 21:31:31,082 INFO     Training average negative_sample_loss at step 102700: 0.063706\n",
      "2023-12-02 21:31:31,082 INFO     Training average loss at step 102700: 0.063653\n",
      "2023-12-02 21:31:42,151 INFO     Training average positive_sample_loss at step 102800: 0.063850\n",
      "2023-12-02 21:31:42,151 INFO     Training average negative_sample_loss at step 102800: 0.063765\n",
      "2023-12-02 21:31:42,151 INFO     Training average loss at step 102800: 0.063808\n",
      "2023-12-02 21:31:54,816 INFO     Training average positive_sample_loss at step 102900: 0.064159\n",
      "2023-12-02 21:31:54,816 INFO     Training average negative_sample_loss at step 102900: 0.064585\n",
      "2023-12-02 21:31:54,817 INFO     Training average loss at step 102900: 0.064372\n",
      "2023-12-02 21:32:06,647 INFO     Training average positive_sample_loss at step 103000: 0.061973\n",
      "2023-12-02 21:32:06,647 INFO     Training average negative_sample_loss at step 103000: 0.062782\n",
      "2023-12-02 21:32:06,647 INFO     Training average loss at step 103000: 0.062377\n",
      "2023-12-02 21:32:16,950 INFO     Training average positive_sample_loss at step 103100: 0.062530\n",
      "2023-12-02 21:32:16,950 INFO     Training average negative_sample_loss at step 103100: 0.063985\n",
      "2023-12-02 21:32:16,950 INFO     Training average loss at step 103100: 0.063258\n",
      "2023-12-02 21:32:22,993 INFO     Training average positive_sample_loss at step 103200: 0.062852\n",
      "2023-12-02 21:32:22,994 INFO     Training average negative_sample_loss at step 103200: 0.063917\n",
      "2023-12-02 21:32:22,994 INFO     Training average loss at step 103200: 0.063385\n",
      "2023-12-02 21:32:29,070 INFO     Training average positive_sample_loss at step 103300: 0.063076\n",
      "2023-12-02 21:32:29,071 INFO     Training average negative_sample_loss at step 103300: 0.063644\n",
      "2023-12-02 21:32:29,071 INFO     Training average loss at step 103300: 0.063360\n",
      "2023-12-02 21:32:36,607 INFO     Training average positive_sample_loss at step 103400: 0.063297\n",
      "2023-12-02 21:32:36,607 INFO     Training average negative_sample_loss at step 103400: 0.064102\n",
      "2023-12-02 21:32:36,607 INFO     Training average loss at step 103400: 0.063699\n",
      "2023-12-02 21:32:44,776 INFO     Training average positive_sample_loss at step 103500: 0.063637\n",
      "2023-12-02 21:32:44,776 INFO     Training average negative_sample_loss at step 103500: 0.064750\n",
      "2023-12-02 21:32:44,776 INFO     Training average loss at step 103500: 0.064194\n",
      "2023-12-02 21:32:53,172 INFO     Training average positive_sample_loss at step 103600: 0.063760\n",
      "2023-12-02 21:32:53,172 INFO     Training average negative_sample_loss at step 103600: 0.064082\n",
      "2023-12-02 21:32:53,172 INFO     Training average loss at step 103600: 0.063921\n",
      "2023-12-02 21:33:01,567 INFO     Training average positive_sample_loss at step 103700: 0.063787\n",
      "2023-12-02 21:33:01,567 INFO     Training average negative_sample_loss at step 103700: 0.064294\n",
      "2023-12-02 21:33:01,567 INFO     Training average loss at step 103700: 0.064040\n",
      "2023-12-02 21:33:09,960 INFO     Training average positive_sample_loss at step 103800: 0.063689\n",
      "2023-12-02 21:33:09,961 INFO     Training average negative_sample_loss at step 103800: 0.064130\n",
      "2023-12-02 21:33:09,961 INFO     Training average loss at step 103800: 0.063909\n",
      "2023-12-02 21:33:22,380 INFO     Training average positive_sample_loss at step 103900: 0.062641\n",
      "2023-12-02 21:33:22,381 INFO     Training average negative_sample_loss at step 103900: 0.063813\n",
      "2023-12-02 21:33:22,381 INFO     Training average loss at step 103900: 0.063227\n",
      "2023-12-02 21:33:34,390 INFO     Training average positive_sample_loss at step 104000: 0.062352\n",
      "2023-12-02 21:33:34,390 INFO     Training average negative_sample_loss at step 104000: 0.063056\n",
      "2023-12-02 21:33:34,390 INFO     Training average loss at step 104000: 0.062704\n",
      "2023-12-02 21:33:46,219 INFO     Training average positive_sample_loss at step 104100: 0.062660\n",
      "2023-12-02 21:33:46,220 INFO     Training average negative_sample_loss at step 104100: 0.063922\n",
      "2023-12-02 21:33:46,220 INFO     Training average loss at step 104100: 0.063291\n",
      "2023-12-02 21:33:57,489 INFO     Training average positive_sample_loss at step 104200: 0.062831\n",
      "2023-12-02 21:33:57,489 INFO     Training average negative_sample_loss at step 104200: 0.063709\n",
      "2023-12-02 21:33:57,489 INFO     Training average loss at step 104200: 0.063270\n",
      "2023-12-02 21:34:09,470 INFO     Training average positive_sample_loss at step 104300: 0.063572\n",
      "2023-12-02 21:34:09,470 INFO     Training average negative_sample_loss at step 104300: 0.063866\n",
      "2023-12-02 21:34:09,470 INFO     Training average loss at step 104300: 0.063719\n",
      "2023-12-02 21:34:21,310 INFO     Training average positive_sample_loss at step 104400: 0.063483\n",
      "2023-12-02 21:34:21,310 INFO     Training average negative_sample_loss at step 104400: 0.064019\n",
      "2023-12-02 21:34:21,310 INFO     Training average loss at step 104400: 0.063751\n",
      "2023-12-02 21:34:33,205 INFO     Training average positive_sample_loss at step 104500: 0.063255\n",
      "2023-12-02 21:34:33,205 INFO     Training average negative_sample_loss at step 104500: 0.062863\n",
      "2023-12-02 21:34:33,205 INFO     Training average loss at step 104500: 0.063059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:34:44,411 INFO     Training average positive_sample_loss at step 104600: 0.063370\n",
      "2023-12-02 21:34:44,411 INFO     Training average negative_sample_loss at step 104600: 0.064165\n",
      "2023-12-02 21:34:44,412 INFO     Training average loss at step 104600: 0.063768\n",
      "2023-12-02 21:34:56,503 INFO     Training average positive_sample_loss at step 104700: 0.063963\n",
      "2023-12-02 21:34:56,504 INFO     Training average negative_sample_loss at step 104700: 0.064954\n",
      "2023-12-02 21:34:56,504 INFO     Training average loss at step 104700: 0.064459\n",
      "2023-12-02 21:35:09,454 INFO     Training average positive_sample_loss at step 104800: 0.063292\n",
      "2023-12-02 21:35:09,454 INFO     Training average negative_sample_loss at step 104800: 0.063658\n",
      "2023-12-02 21:35:09,454 INFO     Training average loss at step 104800: 0.063475\n",
      "2023-12-02 21:35:20,783 INFO     Training average positive_sample_loss at step 104900: 0.062527\n",
      "2023-12-02 21:35:20,783 INFO     Training average negative_sample_loss at step 104900: 0.064666\n",
      "2023-12-02 21:35:20,783 INFO     Training average loss at step 104900: 0.063597\n",
      "2023-12-02 21:35:32,280 INFO     Training average positive_sample_loss at step 105000: 0.062749\n",
      "2023-12-02 21:35:32,280 INFO     Training average negative_sample_loss at step 105000: 0.064638\n",
      "2023-12-02 21:35:32,281 INFO     Training average loss at step 105000: 0.063693\n",
      "2023-12-02 21:35:44,164 INFO     Training average positive_sample_loss at step 105100: 0.063016\n",
      "2023-12-02 21:35:44,165 INFO     Training average negative_sample_loss at step 105100: 0.064488\n",
      "2023-12-02 21:35:44,165 INFO     Training average loss at step 105100: 0.063752\n",
      "2023-12-02 21:35:56,165 INFO     Training average positive_sample_loss at step 105200: 0.063277\n",
      "2023-12-02 21:35:56,165 INFO     Training average negative_sample_loss at step 105200: 0.063988\n",
      "2023-12-02 21:35:56,165 INFO     Training average loss at step 105200: 0.063632\n",
      "2023-12-02 21:36:07,280 INFO     Training average positive_sample_loss at step 105300: 0.063739\n",
      "2023-12-02 21:36:07,280 INFO     Training average negative_sample_loss at step 105300: 0.064231\n",
      "2023-12-02 21:36:07,280 INFO     Training average loss at step 105300: 0.063985\n",
      "2023-12-02 21:36:19,314 INFO     Training average positive_sample_loss at step 105400: 0.063785\n",
      "2023-12-02 21:36:19,314 INFO     Training average negative_sample_loss at step 105400: 0.064776\n",
      "2023-12-02 21:36:19,314 INFO     Training average loss at step 105400: 0.064280\n",
      "2023-12-02 21:36:31,421 INFO     Training average positive_sample_loss at step 105500: 0.063559\n",
      "2023-12-02 21:36:31,421 INFO     Training average negative_sample_loss at step 105500: 0.064179\n",
      "2023-12-02 21:36:31,421 INFO     Training average loss at step 105500: 0.063869\n",
      "2023-12-02 21:36:43,281 INFO     Training average positive_sample_loss at step 105600: 0.063446\n",
      "2023-12-02 21:36:43,281 INFO     Training average negative_sample_loss at step 105600: 0.063751\n",
      "2023-12-02 21:36:43,281 INFO     Training average loss at step 105600: 0.063599\n",
      "2023-12-02 21:36:54,558 INFO     Training average positive_sample_loss at step 105700: 0.063913\n",
      "2023-12-02 21:36:54,558 INFO     Training average negative_sample_loss at step 105700: 0.064133\n",
      "2023-12-02 21:36:54,558 INFO     Training average loss at step 105700: 0.064023\n",
      "2023-12-02 21:37:07,251 INFO     Training average positive_sample_loss at step 105800: 0.062113\n",
      "2023-12-02 21:37:07,252 INFO     Training average negative_sample_loss at step 105800: 0.062839\n",
      "2023-12-02 21:37:07,252 INFO     Training average loss at step 105800: 0.062476\n",
      "2023-12-02 21:37:19,196 INFO     Training average positive_sample_loss at step 105900: 0.062626\n",
      "2023-12-02 21:37:19,196 INFO     Training average negative_sample_loss at step 105900: 0.063740\n",
      "2023-12-02 21:37:19,196 INFO     Training average loss at step 105900: 0.063183\n",
      "2023-12-02 21:37:30,376 INFO     Training average positive_sample_loss at step 106000: 0.062452\n",
      "2023-12-02 21:37:30,376 INFO     Training average negative_sample_loss at step 106000: 0.063123\n",
      "2023-12-02 21:37:30,376 INFO     Training average loss at step 106000: 0.062788\n",
      "2023-12-02 21:37:42,286 INFO     Training average positive_sample_loss at step 106100: 0.063179\n",
      "2023-12-02 21:37:42,287 INFO     Training average negative_sample_loss at step 106100: 0.063580\n",
      "2023-12-02 21:37:42,287 INFO     Training average loss at step 106100: 0.063379\n",
      "2023-12-02 21:37:54,163 INFO     Training average positive_sample_loss at step 106200: 0.063563\n",
      "2023-12-02 21:37:54,163 INFO     Training average negative_sample_loss at step 106200: 0.064158\n",
      "2023-12-02 21:37:54,163 INFO     Training average loss at step 106200: 0.063861\n",
      "2023-12-02 21:38:06,036 INFO     Training average positive_sample_loss at step 106300: 0.063341\n",
      "2023-12-02 21:38:06,037 INFO     Training average negative_sample_loss at step 106300: 0.064314\n",
      "2023-12-02 21:38:06,037 INFO     Training average loss at step 106300: 0.063827\n",
      "2023-12-02 21:38:17,216 INFO     Training average positive_sample_loss at step 106400: 0.063555\n",
      "2023-12-02 21:38:17,217 INFO     Training average negative_sample_loss at step 106400: 0.064152\n",
      "2023-12-02 21:38:17,217 INFO     Training average loss at step 106400: 0.063854\n",
      "2023-12-02 21:38:29,138 INFO     Training average positive_sample_loss at step 106500: 0.063346\n",
      "2023-12-02 21:38:29,138 INFO     Training average negative_sample_loss at step 106500: 0.063609\n",
      "2023-12-02 21:38:29,138 INFO     Training average loss at step 106500: 0.063477\n",
      "2023-12-02 21:38:40,937 INFO     Training average positive_sample_loss at step 106600: 0.063161\n",
      "2023-12-02 21:38:40,937 INFO     Training average negative_sample_loss at step 106600: 0.063704\n",
      "2023-12-02 21:38:40,937 INFO     Training average loss at step 106600: 0.063433\n",
      "2023-12-02 21:38:53,276 INFO     Training average positive_sample_loss at step 106700: 0.063485\n",
      "2023-12-02 21:38:53,277 INFO     Training average negative_sample_loss at step 106700: 0.064711\n",
      "2023-12-02 21:38:53,277 INFO     Training average loss at step 106700: 0.064098\n",
      "2023-12-02 21:39:05,284 INFO     Training average positive_sample_loss at step 106800: 0.062189\n",
      "2023-12-02 21:39:05,285 INFO     Training average negative_sample_loss at step 106800: 0.064404\n",
      "2023-12-02 21:39:05,285 INFO     Training average loss at step 106800: 0.063297\n",
      "2023-12-02 21:39:17,414 INFO     Training average positive_sample_loss at step 106900: 0.062513\n",
      "2023-12-02 21:39:17,415 INFO     Training average negative_sample_loss at step 106900: 0.063678\n",
      "2023-12-02 21:39:17,415 INFO     Training average loss at step 106900: 0.063096\n",
      "2023-12-02 21:39:29,332 INFO     Training average positive_sample_loss at step 107000: 0.062957\n",
      "2023-12-02 21:39:29,332 INFO     Training average negative_sample_loss at step 107000: 0.063693\n",
      "2023-12-02 21:39:29,332 INFO     Training average loss at step 107000: 0.063325\n",
      "2023-12-02 21:39:40,612 INFO     Training average positive_sample_loss at step 107100: 0.063017\n",
      "2023-12-02 21:39:40,613 INFO     Training average negative_sample_loss at step 107100: 0.064069\n",
      "2023-12-02 21:39:40,613 INFO     Training average loss at step 107100: 0.063543\n",
      "2023-12-02 21:39:52,513 INFO     Training average positive_sample_loss at step 107200: 0.063012\n",
      "2023-12-02 21:39:52,514 INFO     Training average negative_sample_loss at step 107200: 0.063689\n",
      "2023-12-02 21:39:52,514 INFO     Training average loss at step 107200: 0.063350\n",
      "2023-12-02 21:40:04,382 INFO     Training average positive_sample_loss at step 107300: 0.063463\n",
      "2023-12-02 21:40:04,382 INFO     Training average negative_sample_loss at step 107300: 0.064033\n",
      "2023-12-02 21:40:04,382 INFO     Training average loss at step 107300: 0.063748\n",
      "2023-12-02 21:40:15,563 INFO     Training average positive_sample_loss at step 107400: 0.063504\n",
      "2023-12-02 21:40:15,563 INFO     Training average negative_sample_loss at step 107400: 0.064313\n",
      "2023-12-02 21:40:15,563 INFO     Training average loss at step 107400: 0.063908\n",
      "2023-12-02 21:40:27,410 INFO     Training average positive_sample_loss at step 107500: 0.063797\n",
      "2023-12-02 21:40:27,411 INFO     Training average negative_sample_loss at step 107500: 0.063231\n",
      "2023-12-02 21:40:27,411 INFO     Training average loss at step 107500: 0.063514\n",
      "2023-12-02 21:40:39,388 INFO     Training average positive_sample_loss at step 107600: 0.063589\n",
      "2023-12-02 21:40:39,389 INFO     Training average negative_sample_loss at step 107600: 0.063764\n",
      "2023-12-02 21:40:39,389 INFO     Training average loss at step 107600: 0.063677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:40:51,992 INFO     Training average positive_sample_loss at step 107700: 0.062252\n",
      "2023-12-02 21:40:51,993 INFO     Training average negative_sample_loss at step 107700: 0.063775\n",
      "2023-12-02 21:40:51,993 INFO     Training average loss at step 107700: 0.063014\n",
      "2023-12-02 21:41:03,251 INFO     Training average positive_sample_loss at step 107800: 0.062426\n",
      "2023-12-02 21:41:03,252 INFO     Training average negative_sample_loss at step 107800: 0.064134\n",
      "2023-12-02 21:41:03,252 INFO     Training average loss at step 107800: 0.063280\n",
      "2023-12-02 21:41:15,243 INFO     Training average positive_sample_loss at step 107900: 0.063066\n",
      "2023-12-02 21:41:15,243 INFO     Training average negative_sample_loss at step 107900: 0.064038\n",
      "2023-12-02 21:41:15,243 INFO     Training average loss at step 107900: 0.063552\n",
      "2023-12-02 21:41:27,155 INFO     Training average positive_sample_loss at step 108000: 0.063157\n",
      "2023-12-02 21:41:27,155 INFO     Training average negative_sample_loss at step 108000: 0.064269\n",
      "2023-12-02 21:41:27,155 INFO     Training average loss at step 108000: 0.063713\n",
      "2023-12-02 21:41:38,551 INFO     Training average positive_sample_loss at step 108100: 0.063147\n",
      "2023-12-02 21:41:38,552 INFO     Training average negative_sample_loss at step 108100: 0.063341\n",
      "2023-12-02 21:41:38,552 INFO     Training average loss at step 108100: 0.063244\n",
      "2023-12-02 21:41:50,306 INFO     Training average positive_sample_loss at step 108200: 0.063624\n",
      "2023-12-02 21:41:50,306 INFO     Training average negative_sample_loss at step 108200: 0.063677\n",
      "2023-12-02 21:41:50,306 INFO     Training average loss at step 108200: 0.063651\n",
      "2023-12-02 21:42:02,259 INFO     Training average positive_sample_loss at step 108300: 0.063340\n",
      "2023-12-02 21:42:02,259 INFO     Training average negative_sample_loss at step 108300: 0.064424\n",
      "2023-12-02 21:42:02,259 INFO     Training average loss at step 108300: 0.063882\n",
      "2023-12-02 21:42:14,033 INFO     Training average positive_sample_loss at step 108400: 0.063177\n",
      "2023-12-02 21:42:14,034 INFO     Training average negative_sample_loss at step 108400: 0.064588\n",
      "2023-12-02 21:42:14,034 INFO     Training average loss at step 108400: 0.063882\n",
      "2023-12-02 21:42:25,290 INFO     Training average positive_sample_loss at step 108500: 0.063988\n",
      "2023-12-02 21:42:25,290 INFO     Training average negative_sample_loss at step 108500: 0.064573\n",
      "2023-12-02 21:42:25,290 INFO     Training average loss at step 108500: 0.064281\n",
      "2023-12-02 21:42:37,996 INFO     Training average positive_sample_loss at step 108600: 0.063066\n",
      "2023-12-02 21:42:37,996 INFO     Training average negative_sample_loss at step 108600: 0.064014\n",
      "2023-12-02 21:42:37,996 INFO     Training average loss at step 108600: 0.063540\n",
      "2023-12-02 21:42:49,921 INFO     Training average positive_sample_loss at step 108700: 0.062281\n",
      "2023-12-02 21:42:49,922 INFO     Training average negative_sample_loss at step 108700: 0.064685\n",
      "2023-12-02 21:42:49,922 INFO     Training average loss at step 108700: 0.063483\n",
      "2023-12-02 21:43:01,724 INFO     Training average positive_sample_loss at step 108800: 0.062746\n",
      "2023-12-02 21:43:01,724 INFO     Training average negative_sample_loss at step 108800: 0.063488\n",
      "2023-12-02 21:43:01,724 INFO     Training average loss at step 108800: 0.063117\n",
      "2023-12-02 21:43:13,165 INFO     Training average positive_sample_loss at step 108900: 0.063016\n",
      "2023-12-02 21:43:13,166 INFO     Training average negative_sample_loss at step 108900: 0.063298\n",
      "2023-12-02 21:43:13,166 INFO     Training average loss at step 108900: 0.063157\n",
      "2023-12-02 21:43:25,071 INFO     Training average positive_sample_loss at step 109000: 0.063218\n",
      "2023-12-02 21:43:25,071 INFO     Training average negative_sample_loss at step 109000: 0.065424\n",
      "2023-12-02 21:43:25,071 INFO     Training average loss at step 109000: 0.064321\n",
      "2023-12-02 21:43:36,884 INFO     Training average positive_sample_loss at step 109100: 0.063642\n",
      "2023-12-02 21:43:36,884 INFO     Training average negative_sample_loss at step 109100: 0.063105\n",
      "2023-12-02 21:43:36,884 INFO     Training average loss at step 109100: 0.063373\n",
      "2023-12-02 21:43:48,010 INFO     Training average positive_sample_loss at step 109200: 0.063184\n",
      "2023-12-02 21:43:48,011 INFO     Training average negative_sample_loss at step 109200: 0.062914\n",
      "2023-12-02 21:43:48,011 INFO     Training average loss at step 109200: 0.063049\n",
      "2023-12-02 21:43:59,933 INFO     Training average positive_sample_loss at step 109300: 0.063767\n",
      "2023-12-02 21:43:59,934 INFO     Training average negative_sample_loss at step 109300: 0.064527\n",
      "2023-12-02 21:43:59,934 INFO     Training average loss at step 109300: 0.064147\n",
      "2023-12-02 21:44:11,781 INFO     Training average positive_sample_loss at step 109400: 0.063658\n",
      "2023-12-02 21:44:11,781 INFO     Training average negative_sample_loss at step 109400: 0.063397\n",
      "2023-12-02 21:44:11,781 INFO     Training average loss at step 109400: 0.063527\n",
      "2023-12-02 21:44:23,687 INFO     Training average positive_sample_loss at step 109500: 0.063609\n",
      "2023-12-02 21:44:23,687 INFO     Training average negative_sample_loss at step 109500: 0.063866\n",
      "2023-12-02 21:44:23,687 INFO     Training average loss at step 109500: 0.063737\n",
      "2023-12-02 21:44:35,883 INFO     Training average positive_sample_loss at step 109600: 0.062253\n",
      "2023-12-02 21:44:35,883 INFO     Training average negative_sample_loss at step 109600: 0.063747\n",
      "2023-12-02 21:44:35,884 INFO     Training average loss at step 109600: 0.063000\n",
      "2023-12-02 21:44:48,053 INFO     Training average positive_sample_loss at step 109700: 0.062369\n",
      "2023-12-02 21:44:48,053 INFO     Training average negative_sample_loss at step 109700: 0.064403\n",
      "2023-12-02 21:44:48,053 INFO     Training average loss at step 109700: 0.063386\n",
      "2023-12-02 21:44:59,950 INFO     Training average positive_sample_loss at step 109800: 0.063106\n",
      "2023-12-02 21:44:59,950 INFO     Training average negative_sample_loss at step 109800: 0.064143\n",
      "2023-12-02 21:44:59,950 INFO     Training average loss at step 109800: 0.063625\n",
      "2023-12-02 21:45:11,242 INFO     Training average positive_sample_loss at step 109900: 0.063220\n",
      "2023-12-02 21:45:11,242 INFO     Training average negative_sample_loss at step 109900: 0.064028\n",
      "2023-12-02 21:45:11,242 INFO     Training average loss at step 109900: 0.063624\n",
      "2023-12-02 21:45:35,766 INFO     Training average positive_sample_loss at step 110000: 0.063350\n",
      "2023-12-02 21:45:35,766 INFO     Training average negative_sample_loss at step 110000: 0.063698\n",
      "2023-12-02 21:45:35,766 INFO     Training average loss at step 110000: 0.063524\n",
      "2023-12-02 21:45:35,766 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 21:45:36,710 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 21:46:58,844 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 21:48:22,178 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 21:49:44,998 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 21:51:10,204 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 21:51:56,018 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 21:52:34,155 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 21:52:42,788 INFO     Valid MRR at step 110000: 0.789671\n",
      "2023-12-02 21:52:42,788 INFO     Valid MR at step 110000: 40.914280\n",
      "2023-12-02 21:52:42,788 INFO     Valid HITS@1 at step 110000: 0.737530\n",
      "2023-12-02 21:52:42,788 INFO     Valid HITS@3 at step 110000: 0.823100\n",
      "2023-12-02 21:52:42,788 INFO     Valid HITS@10 at step 110000: 0.880110\n",
      "2023-12-02 21:52:48,087 INFO     Training average positive_sample_loss at step 110100: 0.063551\n",
      "2023-12-02 21:52:48,088 INFO     Training average negative_sample_loss at step 110100: 0.063961\n",
      "2023-12-02 21:52:48,088 INFO     Training average loss at step 110100: 0.063756\n",
      "2023-12-02 21:52:54,356 INFO     Training average positive_sample_loss at step 110200: 0.063600\n",
      "2023-12-02 21:52:54,356 INFO     Training average negative_sample_loss at step 110200: 0.064219\n",
      "2023-12-02 21:52:54,356 INFO     Training average loss at step 110200: 0.063910\n",
      "2023-12-02 21:53:00,047 INFO     Training average positive_sample_loss at step 110300: 0.063652\n",
      "2023-12-02 21:53:00,047 INFO     Training average negative_sample_loss at step 110300: 0.064081\n",
      "2023-12-02 21:53:00,047 INFO     Training average loss at step 110300: 0.063867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:53:07,572 INFO     Training average positive_sample_loss at step 110400: 0.063573\n",
      "2023-12-02 21:53:07,572 INFO     Training average negative_sample_loss at step 110400: 0.064950\n",
      "2023-12-02 21:53:07,572 INFO     Training average loss at step 110400: 0.064262\n",
      "2023-12-02 21:53:17,048 INFO     Training average positive_sample_loss at step 110500: 0.062637\n",
      "2023-12-02 21:53:17,049 INFO     Training average negative_sample_loss at step 110500: 0.063964\n",
      "2023-12-02 21:53:17,049 INFO     Training average loss at step 110500: 0.063301\n",
      "2023-12-02 21:53:25,582 INFO     Training average positive_sample_loss at step 110600: 0.062413\n",
      "2023-12-02 21:53:25,582 INFO     Training average negative_sample_loss at step 110600: 0.063916\n",
      "2023-12-02 21:53:25,583 INFO     Training average loss at step 110600: 0.063164\n",
      "2023-12-02 21:53:34,373 INFO     Training average positive_sample_loss at step 110700: 0.062656\n",
      "2023-12-02 21:53:34,374 INFO     Training average negative_sample_loss at step 110700: 0.063786\n",
      "2023-12-02 21:53:34,374 INFO     Training average loss at step 110700: 0.063221\n",
      "2023-12-02 21:53:44,453 INFO     Training average positive_sample_loss at step 110800: 0.062920\n",
      "2023-12-02 21:53:44,453 INFO     Training average negative_sample_loss at step 110800: 0.062899\n",
      "2023-12-02 21:53:44,453 INFO     Training average loss at step 110800: 0.062910\n",
      "2023-12-02 21:53:56,357 INFO     Training average positive_sample_loss at step 110900: 0.063272\n",
      "2023-12-02 21:53:56,357 INFO     Training average negative_sample_loss at step 110900: 0.063704\n",
      "2023-12-02 21:53:56,357 INFO     Training average loss at step 110900: 0.063488\n",
      "2023-12-02 21:54:08,269 INFO     Training average positive_sample_loss at step 111000: 0.063357\n",
      "2023-12-02 21:54:08,270 INFO     Training average negative_sample_loss at step 111000: 0.064230\n",
      "2023-12-02 21:54:08,270 INFO     Training average loss at step 111000: 0.063794\n",
      "2023-12-02 21:54:20,043 INFO     Training average positive_sample_loss at step 111100: 0.063249\n",
      "2023-12-02 21:54:20,044 INFO     Training average negative_sample_loss at step 111100: 0.063830\n",
      "2023-12-02 21:54:20,044 INFO     Training average loss at step 111100: 0.063540\n",
      "2023-12-02 21:54:31,175 INFO     Training average positive_sample_loss at step 111200: 0.063419\n",
      "2023-12-02 21:54:31,175 INFO     Training average negative_sample_loss at step 111200: 0.063975\n",
      "2023-12-02 21:54:31,175 INFO     Training average loss at step 111200: 0.063697\n",
      "2023-12-02 21:54:42,999 INFO     Training average positive_sample_loss at step 111300: 0.064079\n",
      "2023-12-02 21:54:42,999 INFO     Training average negative_sample_loss at step 111300: 0.064827\n",
      "2023-12-02 21:54:42,999 INFO     Training average loss at step 111300: 0.064453\n",
      "2023-12-02 21:54:55,754 INFO     Training average positive_sample_loss at step 111400: 0.063510\n",
      "2023-12-02 21:54:55,754 INFO     Training average negative_sample_loss at step 111400: 0.063182\n",
      "2023-12-02 21:54:55,755 INFO     Training average loss at step 111400: 0.063346\n",
      "2023-12-02 21:55:06,989 INFO     Training average positive_sample_loss at step 111500: 0.061994\n",
      "2023-12-02 21:55:06,990 INFO     Training average negative_sample_loss at step 111500: 0.064286\n",
      "2023-12-02 21:55:06,990 INFO     Training average loss at step 111500: 0.063140\n",
      "2023-12-02 21:55:18,912 INFO     Training average positive_sample_loss at step 111600: 0.062696\n",
      "2023-12-02 21:55:18,912 INFO     Training average negative_sample_loss at step 111600: 0.063633\n",
      "2023-12-02 21:55:18,912 INFO     Training average loss at step 111600: 0.063164\n",
      "2023-12-02 21:55:30,885 INFO     Training average positive_sample_loss at step 111700: 0.062842\n",
      "2023-12-02 21:55:30,885 INFO     Training average negative_sample_loss at step 111700: 0.063573\n",
      "2023-12-02 21:55:30,885 INFO     Training average loss at step 111700: 0.063207\n",
      "2023-12-02 21:55:42,729 INFO     Training average positive_sample_loss at step 111800: 0.063176\n",
      "2023-12-02 21:55:42,729 INFO     Training average negative_sample_loss at step 111800: 0.063535\n",
      "2023-12-02 21:55:42,729 INFO     Training average loss at step 111800: 0.063355\n",
      "2023-12-02 21:55:53,809 INFO     Training average positive_sample_loss at step 111900: 0.063405\n",
      "2023-12-02 21:55:53,809 INFO     Training average negative_sample_loss at step 111900: 0.064068\n",
      "2023-12-02 21:55:53,810 INFO     Training average loss at step 111900: 0.063737\n",
      "2023-12-02 21:56:05,649 INFO     Training average positive_sample_loss at step 112000: 0.063294\n",
      "2023-12-02 21:56:05,649 INFO     Training average negative_sample_loss at step 112000: 0.063195\n",
      "2023-12-02 21:56:05,649 INFO     Training average loss at step 112000: 0.063244\n",
      "2023-12-02 21:56:17,438 INFO     Training average positive_sample_loss at step 112100: 0.063351\n",
      "2023-12-02 21:56:17,438 INFO     Training average negative_sample_loss at step 112100: 0.063494\n",
      "2023-12-02 21:56:17,438 INFO     Training average loss at step 112100: 0.063423\n",
      "2023-12-02 21:56:28,605 INFO     Training average positive_sample_loss at step 112200: 0.063778\n",
      "2023-12-02 21:56:28,605 INFO     Training average negative_sample_loss at step 112200: 0.065181\n",
      "2023-12-02 21:56:28,606 INFO     Training average loss at step 112200: 0.064479\n",
      "2023-12-02 21:56:40,456 INFO     Training average positive_sample_loss at step 112300: 0.063827\n",
      "2023-12-02 21:56:40,456 INFO     Training average negative_sample_loss at step 112300: 0.064276\n",
      "2023-12-02 21:56:40,456 INFO     Training average loss at step 112300: 0.064052\n",
      "2023-12-02 21:56:53,043 INFO     Training average positive_sample_loss at step 112400: 0.062700\n",
      "2023-12-02 21:56:53,044 INFO     Training average negative_sample_loss at step 112400: 0.064084\n",
      "2023-12-02 21:56:53,044 INFO     Training average loss at step 112400: 0.063392\n",
      "2023-12-02 21:57:04,819 INFO     Training average positive_sample_loss at step 112500: 0.062348\n",
      "2023-12-02 21:57:04,819 INFO     Training average negative_sample_loss at step 112500: 0.063281\n",
      "2023-12-02 21:57:04,819 INFO     Training average loss at step 112500: 0.062814\n",
      "2023-12-02 21:57:15,968 INFO     Training average positive_sample_loss at step 112600: 0.062461\n",
      "2023-12-02 21:57:15,969 INFO     Training average negative_sample_loss at step 112600: 0.062857\n",
      "2023-12-02 21:57:15,969 INFO     Training average loss at step 112600: 0.062659\n",
      "2023-12-02 21:57:27,739 INFO     Training average positive_sample_loss at step 112700: 0.062755\n",
      "2023-12-02 21:57:27,739 INFO     Training average negative_sample_loss at step 112700: 0.063474\n",
      "2023-12-02 21:57:27,739 INFO     Training average loss at step 112700: 0.063114\n",
      "2023-12-02 21:57:39,503 INFO     Training average positive_sample_loss at step 112800: 0.063087\n",
      "2023-12-02 21:57:39,503 INFO     Training average negative_sample_loss at step 112800: 0.063817\n",
      "2023-12-02 21:57:39,503 INFO     Training average loss at step 112800: 0.063452\n",
      "2023-12-02 21:57:50,914 INFO     Training average positive_sample_loss at step 112900: 0.063507\n",
      "2023-12-02 21:57:50,915 INFO     Training average negative_sample_loss at step 112900: 0.063540\n",
      "2023-12-02 21:57:50,915 INFO     Training average loss at step 112900: 0.063523\n",
      "2023-12-02 21:58:02,331 INFO     Training average positive_sample_loss at step 113000: 0.063592\n",
      "2023-12-02 21:58:02,331 INFO     Training average negative_sample_loss at step 113000: 0.064292\n",
      "2023-12-02 21:58:02,331 INFO     Training average loss at step 113000: 0.063942\n",
      "2023-12-02 21:58:14,116 INFO     Training average positive_sample_loss at step 113100: 0.063403\n",
      "2023-12-02 21:58:14,117 INFO     Training average negative_sample_loss at step 113100: 0.063721\n",
      "2023-12-02 21:58:14,117 INFO     Training average loss at step 113100: 0.063562\n",
      "2023-12-02 21:58:25,922 INFO     Training average positive_sample_loss at step 113200: 0.063663\n",
      "2023-12-02 21:58:25,922 INFO     Training average negative_sample_loss at step 113200: 0.064496\n",
      "2023-12-02 21:58:25,922 INFO     Training average loss at step 113200: 0.064079\n",
      "2023-12-02 21:58:37,727 INFO     Training average positive_sample_loss at step 113300: 0.063265\n",
      "2023-12-02 21:58:37,727 INFO     Training average negative_sample_loss at step 113300: 0.063830\n",
      "2023-12-02 21:58:37,727 INFO     Training average loss at step 113300: 0.063548\n",
      "2023-12-02 21:58:49,574 INFO     Training average positive_sample_loss at step 113400: 0.062373\n",
      "2023-12-02 21:58:49,575 INFO     Training average negative_sample_loss at step 113400: 0.063798\n",
      "2023-12-02 21:58:49,575 INFO     Training average loss at step 113400: 0.063085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:59:01,496 INFO     Training average positive_sample_loss at step 113500: 0.062568\n",
      "2023-12-02 21:59:01,496 INFO     Training average negative_sample_loss at step 113500: 0.063932\n",
      "2023-12-02 21:59:01,496 INFO     Training average loss at step 113500: 0.063250\n",
      "2023-12-02 21:59:13,445 INFO     Training average positive_sample_loss at step 113600: 0.062992\n",
      "2023-12-02 21:59:13,446 INFO     Training average negative_sample_loss at step 113600: 0.063055\n",
      "2023-12-02 21:59:13,446 INFO     Training average loss at step 113600: 0.063023\n",
      "2023-12-02 21:59:24,574 INFO     Training average positive_sample_loss at step 113700: 0.063165\n",
      "2023-12-02 21:59:24,574 INFO     Training average negative_sample_loss at step 113700: 0.063177\n",
      "2023-12-02 21:59:24,574 INFO     Training average loss at step 113700: 0.063171\n",
      "2023-12-02 21:59:36,387 INFO     Training average positive_sample_loss at step 113800: 0.063056\n",
      "2023-12-02 21:59:36,388 INFO     Training average negative_sample_loss at step 113800: 0.063465\n",
      "2023-12-02 21:59:36,388 INFO     Training average loss at step 113800: 0.063260\n",
      "2023-12-02 21:59:48,200 INFO     Training average positive_sample_loss at step 113900: 0.063507\n",
      "2023-12-02 21:59:48,201 INFO     Training average negative_sample_loss at step 113900: 0.063923\n",
      "2023-12-02 21:59:48,201 INFO     Training average loss at step 113900: 0.063715\n",
      "2023-12-02 21:59:59,285 INFO     Training average positive_sample_loss at step 114000: 0.063512\n",
      "2023-12-02 21:59:59,286 INFO     Training average negative_sample_loss at step 114000: 0.064150\n",
      "2023-12-02 21:59:59,286 INFO     Training average loss at step 114000: 0.063831\n",
      "2023-12-02 22:00:11,232 INFO     Training average positive_sample_loss at step 114100: 0.063171\n",
      "2023-12-02 22:00:11,233 INFO     Training average negative_sample_loss at step 114100: 0.063630\n",
      "2023-12-02 22:00:11,233 INFO     Training average loss at step 114100: 0.063401\n",
      "2023-12-02 22:00:23,147 INFO     Training average positive_sample_loss at step 114200: 0.063610\n",
      "2023-12-02 22:00:23,147 INFO     Training average negative_sample_loss at step 114200: 0.063999\n",
      "2023-12-02 22:00:23,147 INFO     Training average loss at step 114200: 0.063805\n",
      "2023-12-02 22:00:35,768 INFO     Training average positive_sample_loss at step 114300: 0.062686\n",
      "2023-12-02 22:00:35,768 INFO     Training average negative_sample_loss at step 114300: 0.064650\n",
      "2023-12-02 22:00:35,769 INFO     Training average loss at step 114300: 0.063668\n",
      "2023-12-02 22:00:46,979 INFO     Training average positive_sample_loss at step 114400: 0.062171\n",
      "2023-12-02 22:00:46,980 INFO     Training average negative_sample_loss at step 114400: 0.063392\n",
      "2023-12-02 22:00:46,980 INFO     Training average loss at step 114400: 0.062781\n",
      "2023-12-02 22:00:58,755 INFO     Training average positive_sample_loss at step 114500: 0.063192\n",
      "2023-12-02 22:00:58,756 INFO     Training average negative_sample_loss at step 114500: 0.064484\n",
      "2023-12-02 22:00:58,756 INFO     Training average loss at step 114500: 0.063838\n",
      "2023-12-02 22:01:10,653 INFO     Training average positive_sample_loss at step 114600: 0.063319\n",
      "2023-12-02 22:01:10,653 INFO     Training average negative_sample_loss at step 114600: 0.064025\n",
      "2023-12-02 22:01:10,653 INFO     Training average loss at step 114600: 0.063672\n",
      "2023-12-02 22:01:21,954 INFO     Training average positive_sample_loss at step 114700: 0.063116\n",
      "2023-12-02 22:01:21,954 INFO     Training average negative_sample_loss at step 114700: 0.063701\n",
      "2023-12-02 22:01:21,954 INFO     Training average loss at step 114700: 0.063408\n",
      "2023-12-02 22:01:33,824 INFO     Training average positive_sample_loss at step 114800: 0.063218\n",
      "2023-12-02 22:01:33,825 INFO     Training average negative_sample_loss at step 114800: 0.063065\n",
      "2023-12-02 22:01:33,825 INFO     Training average loss at step 114800: 0.063141\n",
      "2023-12-02 22:01:45,837 INFO     Training average positive_sample_loss at step 114900: 0.063341\n",
      "2023-12-02 22:01:45,837 INFO     Training average negative_sample_loss at step 114900: 0.063521\n",
      "2023-12-02 22:01:45,837 INFO     Training average loss at step 114900: 0.063431\n",
      "2023-12-02 22:01:57,841 INFO     Training average positive_sample_loss at step 115000: 0.063737\n",
      "2023-12-02 22:01:57,842 INFO     Training average negative_sample_loss at step 115000: 0.064720\n",
      "2023-12-02 22:01:57,842 INFO     Training average loss at step 115000: 0.064228\n",
      "2023-12-02 22:02:09,032 INFO     Training average positive_sample_loss at step 115100: 0.063368\n",
      "2023-12-02 22:02:09,032 INFO     Training average negative_sample_loss at step 115100: 0.063280\n",
      "2023-12-02 22:02:09,033 INFO     Training average loss at step 115100: 0.063324\n",
      "2023-12-02 22:02:21,751 INFO     Training average positive_sample_loss at step 115200: 0.062911\n",
      "2023-12-02 22:02:21,751 INFO     Training average negative_sample_loss at step 115200: 0.064229\n",
      "2023-12-02 22:02:21,751 INFO     Training average loss at step 115200: 0.063570\n",
      "2023-12-02 22:02:33,610 INFO     Training average positive_sample_loss at step 115300: 0.062335\n",
      "2023-12-02 22:02:33,611 INFO     Training average negative_sample_loss at step 115300: 0.063739\n",
      "2023-12-02 22:02:33,611 INFO     Training average loss at step 115300: 0.063037\n",
      "2023-12-02 22:02:44,863 INFO     Training average positive_sample_loss at step 115400: 0.062478\n",
      "2023-12-02 22:02:44,863 INFO     Training average negative_sample_loss at step 115400: 0.063353\n",
      "2023-12-02 22:02:44,863 INFO     Training average loss at step 115400: 0.062916\n",
      "2023-12-02 22:02:56,605 INFO     Training average positive_sample_loss at step 115500: 0.063230\n",
      "2023-12-02 22:02:56,605 INFO     Training average negative_sample_loss at step 115500: 0.064012\n",
      "2023-12-02 22:02:56,605 INFO     Training average loss at step 115500: 0.063621\n",
      "2023-12-02 22:03:08,468 INFO     Training average positive_sample_loss at step 115600: 0.063228\n",
      "2023-12-02 22:03:08,469 INFO     Training average negative_sample_loss at step 115600: 0.063449\n",
      "2023-12-02 22:03:08,469 INFO     Training average loss at step 115600: 0.063338\n",
      "2023-12-02 22:03:20,302 INFO     Training average positive_sample_loss at step 115700: 0.063298\n",
      "2023-12-02 22:03:20,302 INFO     Training average negative_sample_loss at step 115700: 0.062973\n",
      "2023-12-02 22:03:20,302 INFO     Training average loss at step 115700: 0.063136\n",
      "2023-12-02 22:03:31,478 INFO     Training average positive_sample_loss at step 115800: 0.063687\n",
      "2023-12-02 22:03:31,479 INFO     Training average negative_sample_loss at step 115800: 0.064124\n",
      "2023-12-02 22:03:31,479 INFO     Training average loss at step 115800: 0.063906\n",
      "2023-12-02 22:03:43,331 INFO     Training average positive_sample_loss at step 115900: 0.063533\n",
      "2023-12-02 22:03:43,332 INFO     Training average negative_sample_loss at step 115900: 0.063494\n",
      "2023-12-02 22:03:43,332 INFO     Training average loss at step 115900: 0.063514\n",
      "2023-12-02 22:03:55,223 INFO     Training average positive_sample_loss at step 116000: 0.063579\n",
      "2023-12-02 22:03:55,224 INFO     Training average negative_sample_loss at step 116000: 0.063975\n",
      "2023-12-02 22:03:55,224 INFO     Training average loss at step 116000: 0.063777\n",
      "2023-12-02 22:04:07,174 INFO     Training average positive_sample_loss at step 116100: 0.063597\n",
      "2023-12-02 22:04:07,174 INFO     Training average negative_sample_loss at step 116100: 0.064229\n",
      "2023-12-02 22:04:07,174 INFO     Training average loss at step 116100: 0.063913\n",
      "2023-12-02 22:04:19,932 INFO     Training average positive_sample_loss at step 116200: 0.062314\n",
      "2023-12-02 22:04:19,933 INFO     Training average negative_sample_loss at step 116200: 0.065276\n",
      "2023-12-02 22:04:19,933 INFO     Training average loss at step 116200: 0.063795\n",
      "2023-12-02 22:04:31,889 INFO     Training average positive_sample_loss at step 116300: 0.062849\n",
      "2023-12-02 22:04:31,889 INFO     Training average negative_sample_loss at step 116300: 0.063414\n",
      "2023-12-02 22:04:31,889 INFO     Training average loss at step 116300: 0.063131\n",
      "2023-12-02 22:04:43,853 INFO     Training average positive_sample_loss at step 116400: 0.062608\n",
      "2023-12-02 22:04:43,854 INFO     Training average negative_sample_loss at step 116400: 0.063353\n",
      "2023-12-02 22:04:43,854 INFO     Training average loss at step 116400: 0.062981\n",
      "2023-12-02 22:04:55,010 INFO     Training average positive_sample_loss at step 116500: 0.063048\n",
      "2023-12-02 22:04:55,010 INFO     Training average negative_sample_loss at step 116500: 0.063772\n",
      "2023-12-02 22:04:55,010 INFO     Training average loss at step 116500: 0.063410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 22:05:07,015 INFO     Training average positive_sample_loss at step 116600: 0.062999\n",
      "2023-12-02 22:05:07,016 INFO     Training average negative_sample_loss at step 116600: 0.062803\n",
      "2023-12-02 22:05:07,016 INFO     Training average loss at step 116600: 0.062901\n",
      "2023-12-02 22:05:18,952 INFO     Training average positive_sample_loss at step 116700: 0.063076\n",
      "2023-12-02 22:05:18,952 INFO     Training average negative_sample_loss at step 116700: 0.063166\n",
      "2023-12-02 22:05:18,952 INFO     Training average loss at step 116700: 0.063121\n",
      "2023-12-02 22:05:30,800 INFO     Training average positive_sample_loss at step 116800: 0.063391\n",
      "2023-12-02 22:05:30,800 INFO     Training average negative_sample_loss at step 116800: 0.063431\n",
      "2023-12-02 22:05:30,800 INFO     Training average loss at step 116800: 0.063411\n",
      "2023-12-02 22:05:42,052 INFO     Training average positive_sample_loss at step 116900: 0.063544\n",
      "2023-12-02 22:05:42,052 INFO     Training average negative_sample_loss at step 116900: 0.064124\n",
      "2023-12-02 22:05:42,052 INFO     Training average loss at step 116900: 0.063834\n",
      "2023-12-02 22:05:53,906 INFO     Training average positive_sample_loss at step 117000: 0.063656\n",
      "2023-12-02 22:05:53,906 INFO     Training average negative_sample_loss at step 117000: 0.064741\n",
      "2023-12-02 22:05:53,906 INFO     Training average loss at step 117000: 0.064198\n",
      "2023-12-02 22:06:06,542 INFO     Training average positive_sample_loss at step 117100: 0.062752\n",
      "2023-12-02 22:06:06,542 INFO     Training average negative_sample_loss at step 117100: 0.064209\n",
      "2023-12-02 22:06:06,542 INFO     Training average loss at step 117100: 0.063480\n",
      "2023-12-02 22:06:17,645 INFO     Training average positive_sample_loss at step 117200: 0.062459\n",
      "2023-12-02 22:06:17,646 INFO     Training average negative_sample_loss at step 117200: 0.063707\n",
      "2023-12-02 22:06:17,646 INFO     Training average loss at step 117200: 0.063083\n",
      "2023-12-02 22:06:29,476 INFO     Training average positive_sample_loss at step 117300: 0.062548\n",
      "2023-12-02 22:06:29,476 INFO     Training average negative_sample_loss at step 117300: 0.063349\n",
      "2023-12-02 22:06:29,476 INFO     Training average loss at step 117300: 0.062948\n",
      "2023-12-02 22:06:41,310 INFO     Training average positive_sample_loss at step 117400: 0.062903\n",
      "2023-12-02 22:06:41,311 INFO     Training average negative_sample_loss at step 117400: 0.063765\n",
      "2023-12-02 22:06:41,311 INFO     Training average loss at step 117400: 0.063334\n",
      "2023-12-02 22:06:53,229 INFO     Training average positive_sample_loss at step 117500: 0.063200\n",
      "2023-12-02 22:06:53,229 INFO     Training average negative_sample_loss at step 117500: 0.063393\n",
      "2023-12-02 22:06:53,229 INFO     Training average loss at step 117500: 0.063296\n",
      "2023-12-02 22:07:04,411 INFO     Training average positive_sample_loss at step 117600: 0.063242\n",
      "2023-12-02 22:07:04,411 INFO     Training average negative_sample_loss at step 117600: 0.062938\n",
      "2023-12-02 22:07:04,411 INFO     Training average loss at step 117600: 0.063090\n",
      "2023-12-02 22:07:16,254 INFO     Training average positive_sample_loss at step 117700: 0.063087\n",
      "2023-12-02 22:07:16,255 INFO     Training average negative_sample_loss at step 117700: 0.062951\n",
      "2023-12-02 22:07:16,255 INFO     Training average loss at step 117700: 0.063019\n",
      "2023-12-02 22:07:28,180 INFO     Training average positive_sample_loss at step 117800: 0.063118\n",
      "2023-12-02 22:07:28,181 INFO     Training average negative_sample_loss at step 117800: 0.063706\n",
      "2023-12-02 22:07:28,181 INFO     Training average loss at step 117800: 0.063412\n",
      "2023-12-02 22:07:39,423 INFO     Training average positive_sample_loss at step 117900: 0.063666\n",
      "2023-12-02 22:07:39,423 INFO     Training average negative_sample_loss at step 117900: 0.064170\n",
      "2023-12-02 22:07:39,423 INFO     Training average loss at step 117900: 0.063918\n",
      "2023-12-02 22:07:51,565 INFO     Training average positive_sample_loss at step 118000: 0.063627\n",
      "2023-12-02 22:07:51,565 INFO     Training average negative_sample_loss at step 118000: 0.064521\n",
      "2023-12-02 22:07:51,565 INFO     Training average loss at step 118000: 0.064074\n",
      "2023-12-02 22:08:03,930 INFO     Training average positive_sample_loss at step 118100: 0.061940\n",
      "2023-12-02 22:08:03,930 INFO     Training average negative_sample_loss at step 118100: 0.063677\n",
      "2023-12-02 22:08:03,930 INFO     Training average loss at step 118100: 0.062809\n",
      "2023-12-02 22:08:15,737 INFO     Training average positive_sample_loss at step 118200: 0.062326\n",
      "2023-12-02 22:08:15,738 INFO     Training average negative_sample_loss at step 118200: 0.063897\n",
      "2023-12-02 22:08:15,738 INFO     Training average loss at step 118200: 0.063111\n",
      "2023-12-02 22:08:26,800 INFO     Training average positive_sample_loss at step 118300: 0.062859\n",
      "2023-12-02 22:08:26,801 INFO     Training average negative_sample_loss at step 118300: 0.063553\n",
      "2023-12-02 22:08:26,801 INFO     Training average loss at step 118300: 0.063206\n",
      "2023-12-02 22:08:38,700 INFO     Training average positive_sample_loss at step 118400: 0.063203\n",
      "2023-12-02 22:08:38,700 INFO     Training average negative_sample_loss at step 118400: 0.064144\n",
      "2023-12-02 22:08:38,700 INFO     Training average loss at step 118400: 0.063674\n",
      "2023-12-02 22:08:50,555 INFO     Training average positive_sample_loss at step 118500: 0.063278\n",
      "2023-12-02 22:08:50,555 INFO     Training average negative_sample_loss at step 118500: 0.063265\n",
      "2023-12-02 22:08:50,556 INFO     Training average loss at step 118500: 0.063271\n",
      "2023-12-02 22:09:02,406 INFO     Training average positive_sample_loss at step 118600: 0.063268\n",
      "2023-12-02 22:09:02,406 INFO     Training average negative_sample_loss at step 118600: 0.063233\n",
      "2023-12-02 22:09:02,406 INFO     Training average loss at step 118600: 0.063251\n",
      "2023-12-02 22:09:13,457 INFO     Training average positive_sample_loss at step 118700: 0.063246\n",
      "2023-12-02 22:09:13,458 INFO     Training average negative_sample_loss at step 118700: 0.063650\n",
      "2023-12-02 22:09:13,458 INFO     Training average loss at step 118700: 0.063448\n",
      "2023-12-02 22:09:25,400 INFO     Training average positive_sample_loss at step 118800: 0.063128\n",
      "2023-12-02 22:09:25,400 INFO     Training average negative_sample_loss at step 118800: 0.064076\n",
      "2023-12-02 22:09:25,400 INFO     Training average loss at step 118800: 0.063602\n",
      "2023-12-02 22:09:37,217 INFO     Training average positive_sample_loss at step 118900: 0.063507\n",
      "2023-12-02 22:09:37,217 INFO     Training average negative_sample_loss at step 118900: 0.062819\n",
      "2023-12-02 22:09:37,217 INFO     Training average loss at step 118900: 0.063163\n",
      "2023-12-02 22:09:49,071 INFO     Training average positive_sample_loss at step 119000: 0.062958\n",
      "2023-12-02 22:09:49,072 INFO     Training average negative_sample_loss at step 119000: 0.064549\n",
      "2023-12-02 22:09:49,072 INFO     Training average loss at step 119000: 0.063753\n",
      "2023-12-02 22:10:00,923 INFO     Training average positive_sample_loss at step 119100: 0.062417\n",
      "2023-12-02 22:10:00,923 INFO     Training average negative_sample_loss at step 119100: 0.063686\n",
      "2023-12-02 22:10:00,923 INFO     Training average loss at step 119100: 0.063051\n",
      "2023-12-02 22:10:12,790 INFO     Training average positive_sample_loss at step 119200: 0.062439\n",
      "2023-12-02 22:10:12,790 INFO     Training average negative_sample_loss at step 119200: 0.063571\n",
      "2023-12-02 22:10:12,790 INFO     Training average loss at step 119200: 0.063005\n",
      "2023-12-02 22:10:24,670 INFO     Training average positive_sample_loss at step 119300: 0.062609\n",
      "2023-12-02 22:10:24,670 INFO     Training average negative_sample_loss at step 119300: 0.063773\n",
      "2023-12-02 22:10:24,670 INFO     Training average loss at step 119300: 0.063191\n",
      "2023-12-02 22:10:35,959 INFO     Training average positive_sample_loss at step 119400: 0.063242\n",
      "2023-12-02 22:10:35,959 INFO     Training average negative_sample_loss at step 119400: 0.063819\n",
      "2023-12-02 22:10:35,960 INFO     Training average loss at step 119400: 0.063531\n",
      "2023-12-02 22:10:47,989 INFO     Training average positive_sample_loss at step 119500: 0.063300\n",
      "2023-12-02 22:10:47,989 INFO     Training average negative_sample_loss at step 119500: 0.062846\n",
      "2023-12-02 22:10:47,989 INFO     Training average loss at step 119500: 0.063073\n",
      "2023-12-02 22:10:59,898 INFO     Training average positive_sample_loss at step 119600: 0.063595\n",
      "2023-12-02 22:10:59,899 INFO     Training average negative_sample_loss at step 119600: 0.063507\n",
      "2023-12-02 22:10:59,899 INFO     Training average loss at step 119600: 0.063551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 22:11:11,089 INFO     Training average positive_sample_loss at step 119700: 0.063353\n",
      "2023-12-02 22:11:11,089 INFO     Training average negative_sample_loss at step 119700: 0.064314\n",
      "2023-12-02 22:11:11,089 INFO     Training average loss at step 119700: 0.063833\n",
      "2023-12-02 22:11:22,856 INFO     Training average positive_sample_loss at step 119800: 0.063707\n",
      "2023-12-02 22:11:22,857 INFO     Training average negative_sample_loss at step 119800: 0.064096\n",
      "2023-12-02 22:11:22,857 INFO     Training average loss at step 119800: 0.063901\n",
      "2023-12-02 22:11:35,499 INFO     Training average positive_sample_loss at step 119900: 0.063368\n",
      "2023-12-02 22:11:35,500 INFO     Training average negative_sample_loss at step 119900: 0.064741\n",
      "2023-12-02 22:11:35,500 INFO     Training average loss at step 119900: 0.064055\n",
      "2023-12-02 22:11:53,784 INFO     Training average positive_sample_loss at step 120000: 0.061998\n",
      "2023-12-02 22:11:53,784 INFO     Training average negative_sample_loss at step 120000: 0.062662\n",
      "2023-12-02 22:11:53,784 INFO     Training average loss at step 120000: 0.062330\n",
      "2023-12-02 22:11:53,784 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 22:11:54,804 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 22:13:17,707 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 22:14:07,767 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 22:15:27,663 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 22:16:50,602 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 22:18:13,091 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 22:19:35,086 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 22:19:57,003 INFO     Valid MRR at step 120000: 0.790691\n",
      "2023-12-02 22:19:57,003 INFO     Valid MR at step 120000: 41.132360\n",
      "2023-12-02 22:19:57,003 INFO     Valid HITS@1 at step 120000: 0.739180\n",
      "2023-12-02 22:19:57,003 INFO     Valid HITS@3 at step 120000: 0.823750\n",
      "2023-12-02 22:19:57,003 INFO     Valid HITS@10 at step 120000: 0.880270\n",
      "2023-12-02 22:20:08,171 INFO     Training average positive_sample_loss at step 120100: 0.062255\n",
      "2023-12-02 22:20:08,171 INFO     Training average negative_sample_loss at step 120100: 0.063323\n",
      "2023-12-02 22:20:08,171 INFO     Training average loss at step 120100: 0.062789\n",
      "2023-12-02 22:20:19,974 INFO     Training average positive_sample_loss at step 120200: 0.062846\n",
      "2023-12-02 22:20:19,974 INFO     Training average negative_sample_loss at step 120200: 0.063055\n",
      "2023-12-02 22:20:19,974 INFO     Training average loss at step 120200: 0.062950\n",
      "2023-12-02 22:20:31,871 INFO     Training average positive_sample_loss at step 120300: 0.063226\n",
      "2023-12-02 22:20:31,871 INFO     Training average negative_sample_loss at step 120300: 0.063581\n",
      "2023-12-02 22:20:31,871 INFO     Training average loss at step 120300: 0.063404\n",
      "2023-12-02 22:20:43,707 INFO     Training average positive_sample_loss at step 120400: 0.063163\n",
      "2023-12-02 22:20:43,707 INFO     Training average negative_sample_loss at step 120400: 0.063411\n",
      "2023-12-02 22:20:43,707 INFO     Training average loss at step 120400: 0.063287\n",
      "2023-12-02 22:20:54,778 INFO     Training average positive_sample_loss at step 120500: 0.063173\n",
      "2023-12-02 22:20:54,778 INFO     Training average negative_sample_loss at step 120500: 0.062937\n",
      "2023-12-02 22:20:54,778 INFO     Training average loss at step 120500: 0.063055\n",
      "2023-12-02 22:21:06,649 INFO     Training average positive_sample_loss at step 120600: 0.063274\n",
      "2023-12-02 22:21:06,649 INFO     Training average negative_sample_loss at step 120600: 0.063201\n",
      "2023-12-02 22:21:06,649 INFO     Training average loss at step 120600: 0.063238\n",
      "2023-12-02 22:21:18,512 INFO     Training average positive_sample_loss at step 120700: 0.063366\n",
      "2023-12-02 22:21:18,512 INFO     Training average negative_sample_loss at step 120700: 0.063371\n",
      "2023-12-02 22:21:18,512 INFO     Training average loss at step 120700: 0.063368\n",
      "2023-12-02 22:21:29,709 INFO     Training average positive_sample_loss at step 120800: 0.063539\n",
      "2023-12-02 22:21:29,709 INFO     Training average negative_sample_loss at step 120800: 0.064002\n",
      "2023-12-02 22:21:29,709 INFO     Training average loss at step 120800: 0.063770\n",
      "2023-12-02 22:21:42,533 INFO     Training average positive_sample_loss at step 120900: 0.062310\n",
      "2023-12-02 22:21:42,533 INFO     Training average negative_sample_loss at step 120900: 0.064171\n",
      "2023-12-02 22:21:42,533 INFO     Training average loss at step 120900: 0.063240\n",
      "2023-12-02 22:21:54,482 INFO     Training average positive_sample_loss at step 121000: 0.062405\n",
      "2023-12-02 22:21:54,482 INFO     Training average negative_sample_loss at step 121000: 0.063582\n",
      "2023-12-02 22:21:54,482 INFO     Training average loss at step 121000: 0.062994\n",
      "2023-12-02 22:22:06,307 INFO     Training average positive_sample_loss at step 121100: 0.062772\n",
      "2023-12-02 22:22:06,307 INFO     Training average negative_sample_loss at step 121100: 0.063995\n",
      "2023-12-02 22:22:06,307 INFO     Training average loss at step 121100: 0.063384\n",
      "2023-12-02 22:22:17,519 INFO     Training average positive_sample_loss at step 121200: 0.062599\n",
      "2023-12-02 22:22:17,520 INFO     Training average negative_sample_loss at step 121200: 0.062539\n",
      "2023-12-02 22:22:17,520 INFO     Training average loss at step 121200: 0.062569\n",
      "2023-12-02 22:22:29,314 INFO     Training average positive_sample_loss at step 121300: 0.063194\n",
      "2023-12-02 22:22:29,314 INFO     Training average negative_sample_loss at step 121300: 0.063581\n",
      "2023-12-02 22:22:29,315 INFO     Training average loss at step 121300: 0.063387\n",
      "2023-12-02 22:22:41,107 INFO     Training average positive_sample_loss at step 121400: 0.063204\n",
      "2023-12-02 22:22:41,108 INFO     Training average negative_sample_loss at step 121400: 0.064134\n",
      "2023-12-02 22:22:41,108 INFO     Training average loss at step 121400: 0.063669\n",
      "2023-12-02 22:22:52,247 INFO     Training average positive_sample_loss at step 121500: 0.063312\n",
      "2023-12-02 22:22:52,247 INFO     Training average negative_sample_loss at step 121500: 0.063714\n",
      "2023-12-02 22:22:52,247 INFO     Training average loss at step 121500: 0.063513\n",
      "2023-12-02 22:23:04,052 INFO     Training average positive_sample_loss at step 121600: 0.063259\n",
      "2023-12-02 22:23:04,052 INFO     Training average negative_sample_loss at step 121600: 0.063120\n",
      "2023-12-02 22:23:04,052 INFO     Training average loss at step 121600: 0.063189\n",
      "2023-12-02 22:23:15,978 INFO     Training average positive_sample_loss at step 121700: 0.063618\n",
      "2023-12-02 22:23:15,978 INFO     Training average negative_sample_loss at step 121700: 0.064758\n",
      "2023-12-02 22:23:15,978 INFO     Training average loss at step 121700: 0.064188\n",
      "2023-12-02 22:23:28,815 INFO     Training average positive_sample_loss at step 121800: 0.063125\n",
      "2023-12-02 22:23:28,815 INFO     Training average negative_sample_loss at step 121800: 0.063640\n",
      "2023-12-02 22:23:28,815 INFO     Training average loss at step 121800: 0.063382\n",
      "2023-12-02 22:23:39,882 INFO     Training average positive_sample_loss at step 121900: 0.062020\n",
      "2023-12-02 22:23:39,882 INFO     Training average negative_sample_loss at step 121900: 0.063588\n",
      "2023-12-02 22:23:39,882 INFO     Training average loss at step 121900: 0.062804\n",
      "2023-12-02 22:23:51,813 INFO     Training average positive_sample_loss at step 122000: 0.062336\n",
      "2023-12-02 22:23:51,813 INFO     Training average negative_sample_loss at step 122000: 0.063605\n",
      "2023-12-02 22:23:51,813 INFO     Training average loss at step 122000: 0.062970\n",
      "2023-12-02 22:24:03,709 INFO     Training average positive_sample_loss at step 122100: 0.063095\n",
      "2023-12-02 22:24:03,710 INFO     Training average negative_sample_loss at step 122100: 0.063908\n",
      "2023-12-02 22:24:03,710 INFO     Training average loss at step 122100: 0.063502\n",
      "2023-12-02 22:24:14,830 INFO     Training average positive_sample_loss at step 122200: 0.063056\n",
      "2023-12-02 22:24:14,830 INFO     Training average negative_sample_loss at step 122200: 0.063598\n",
      "2023-12-02 22:24:14,830 INFO     Training average loss at step 122200: 0.063327\n",
      "2023-12-02 22:24:26,787 INFO     Training average positive_sample_loss at step 122300: 0.062982\n",
      "2023-12-02 22:24:26,787 INFO     Training average negative_sample_loss at step 122300: 0.062355\n",
      "2023-12-02 22:24:26,787 INFO     Training average loss at step 122300: 0.062669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 22:24:38,827 INFO     Training average positive_sample_loss at step 122400: 0.063337\n",
      "2023-12-02 22:24:38,827 INFO     Training average negative_sample_loss at step 122400: 0.063536\n",
      "2023-12-02 22:24:38,827 INFO     Training average loss at step 122400: 0.063436\n",
      "2023-12-02 22:24:50,780 INFO     Training average positive_sample_loss at step 122500: 0.063190\n",
      "2023-12-02 22:24:50,781 INFO     Training average negative_sample_loss at step 122500: 0.063821\n",
      "2023-12-02 22:24:50,781 INFO     Training average loss at step 122500: 0.063505\n",
      "2023-12-02 22:25:02,020 INFO     Training average positive_sample_loss at step 122600: 0.063374\n",
      "2023-12-02 22:25:02,021 INFO     Training average negative_sample_loss at step 122600: 0.063386\n",
      "2023-12-02 22:25:02,021 INFO     Training average loss at step 122600: 0.063380\n",
      "2023-12-02 22:25:13,963 INFO     Training average positive_sample_loss at step 122700: 0.063545\n",
      "2023-12-02 22:25:13,964 INFO     Training average negative_sample_loss at step 122700: 0.063814\n",
      "2023-12-02 22:25:13,964 INFO     Training average loss at step 122700: 0.063679\n",
      "2023-12-02 22:25:26,616 INFO     Training average positive_sample_loss at step 122800: 0.061895\n",
      "2023-12-02 22:25:26,617 INFO     Training average negative_sample_loss at step 122800: 0.063322\n",
      "2023-12-02 22:25:26,617 INFO     Training average loss at step 122800: 0.062608\n",
      "2023-12-02 22:25:37,877 INFO     Training average positive_sample_loss at step 122900: 0.062550\n",
      "2023-12-02 22:25:37,877 INFO     Training average negative_sample_loss at step 122900: 0.063186\n",
      "2023-12-02 22:25:37,878 INFO     Training average loss at step 122900: 0.062868\n",
      "2023-12-02 22:25:49,718 INFO     Training average positive_sample_loss at step 123000: 0.062704\n",
      "2023-12-02 22:25:49,719 INFO     Training average negative_sample_loss at step 123000: 0.063782\n",
      "2023-12-02 22:25:49,719 INFO     Training average loss at step 123000: 0.063243\n",
      "2023-12-02 22:26:01,673 INFO     Training average positive_sample_loss at step 123100: 0.062798\n",
      "2023-12-02 22:26:01,674 INFO     Training average negative_sample_loss at step 123100: 0.063234\n",
      "2023-12-02 22:26:01,674 INFO     Training average loss at step 123100: 0.063016\n",
      "2023-12-02 22:26:13,487 INFO     Training average positive_sample_loss at step 123200: 0.063009\n",
      "2023-12-02 22:26:13,488 INFO     Training average negative_sample_loss at step 123200: 0.063656\n",
      "2023-12-02 22:26:13,488 INFO     Training average loss at step 123200: 0.063332\n",
      "2023-12-02 22:26:24,623 INFO     Training average positive_sample_loss at step 123300: 0.063197\n",
      "2023-12-02 22:26:24,623 INFO     Training average negative_sample_loss at step 123300: 0.062638\n",
      "2023-12-02 22:26:24,623 INFO     Training average loss at step 123300: 0.062918\n",
      "2023-12-02 22:26:36,536 INFO     Training average positive_sample_loss at step 123400: 0.062928\n",
      "2023-12-02 22:26:36,536 INFO     Training average negative_sample_loss at step 123400: 0.063166\n",
      "2023-12-02 22:26:36,536 INFO     Training average loss at step 123400: 0.063047\n",
      "2023-12-02 22:26:48,330 INFO     Training average positive_sample_loss at step 123500: 0.063429\n",
      "2023-12-02 22:26:48,331 INFO     Training average negative_sample_loss at step 123500: 0.063751\n",
      "2023-12-02 22:26:48,331 INFO     Training average loss at step 123500: 0.063590\n",
      "2023-12-02 22:27:00,108 INFO     Training average positive_sample_loss at step 123600: 0.063296\n",
      "2023-12-02 22:27:00,108 INFO     Training average negative_sample_loss at step 123600: 0.063519\n",
      "2023-12-02 22:27:00,108 INFO     Training average loss at step 123600: 0.063407\n",
      "2023-12-02 22:27:12,001 INFO     Training average positive_sample_loss at step 123700: 0.062871\n",
      "2023-12-02 22:27:12,001 INFO     Training average negative_sample_loss at step 123700: 0.064876\n",
      "2023-12-02 22:27:12,001 INFO     Training average loss at step 123700: 0.063873\n",
      "2023-12-02 22:27:24,038 INFO     Training average positive_sample_loss at step 123800: 0.062171\n",
      "2023-12-02 22:27:24,038 INFO     Training average negative_sample_loss at step 123800: 0.063348\n",
      "2023-12-02 22:27:24,038 INFO     Training average loss at step 123800: 0.062759\n",
      "2023-12-02 22:27:36,022 INFO     Training average positive_sample_loss at step 123900: 0.062283\n",
      "2023-12-02 22:27:36,022 INFO     Training average negative_sample_loss at step 123900: 0.062947\n",
      "2023-12-02 22:27:36,022 INFO     Training average loss at step 123900: 0.062615\n",
      "2023-12-02 22:27:47,180 INFO     Training average positive_sample_loss at step 124000: 0.062578\n",
      "2023-12-02 22:27:47,180 INFO     Training average negative_sample_loss at step 124000: 0.063823\n",
      "2023-12-02 22:27:47,180 INFO     Training average loss at step 124000: 0.063200\n",
      "2023-12-02 22:27:59,174 INFO     Training average positive_sample_loss at step 124100: 0.063073\n",
      "2023-12-02 22:27:59,174 INFO     Training average negative_sample_loss at step 124100: 0.063251\n",
      "2023-12-02 22:27:59,174 INFO     Training average loss at step 124100: 0.063162\n",
      "2023-12-02 22:28:11,021 INFO     Training average positive_sample_loss at step 124200: 0.063034\n",
      "2023-12-02 22:28:11,021 INFO     Training average negative_sample_loss at step 124200: 0.063334\n",
      "2023-12-02 22:28:11,021 INFO     Training average loss at step 124200: 0.063184\n",
      "2023-12-02 22:28:22,871 INFO     Training average positive_sample_loss at step 124300: 0.063340\n",
      "2023-12-02 22:28:22,872 INFO     Training average negative_sample_loss at step 124300: 0.062617\n",
      "2023-12-02 22:28:22,872 INFO     Training average loss at step 124300: 0.062978\n",
      "2023-12-02 22:28:34,128 INFO     Training average positive_sample_loss at step 124400: 0.063256\n",
      "2023-12-02 22:28:34,128 INFO     Training average negative_sample_loss at step 124400: 0.064106\n",
      "2023-12-02 22:28:34,128 INFO     Training average loss at step 124400: 0.063681\n",
      "2023-12-02 22:28:46,134 INFO     Training average positive_sample_loss at step 124500: 0.063618\n",
      "2023-12-02 22:28:46,134 INFO     Training average negative_sample_loss at step 124500: 0.063645\n",
      "2023-12-02 22:28:46,134 INFO     Training average loss at step 124500: 0.063631\n",
      "2023-12-02 22:28:58,138 INFO     Training average positive_sample_loss at step 124600: 0.063601\n",
      "2023-12-02 22:28:58,139 INFO     Training average negative_sample_loss at step 124600: 0.064337\n",
      "2023-12-02 22:28:58,139 INFO     Training average loss at step 124600: 0.063969\n",
      "2023-12-02 22:29:10,109 INFO     Training average positive_sample_loss at step 124700: 0.062079\n",
      "2023-12-02 22:29:10,110 INFO     Training average negative_sample_loss at step 124700: 0.063838\n",
      "2023-12-02 22:29:10,110 INFO     Training average loss at step 124700: 0.062958\n",
      "2023-12-02 22:29:22,147 INFO     Training average positive_sample_loss at step 124800: 0.062306\n",
      "2023-12-02 22:29:22,148 INFO     Training average negative_sample_loss at step 124800: 0.063314\n",
      "2023-12-02 22:29:22,148 INFO     Training average loss at step 124800: 0.062810\n",
      "2023-12-02 22:29:34,135 INFO     Training average positive_sample_loss at step 124900: 0.062903\n",
      "2023-12-02 22:29:34,135 INFO     Training average negative_sample_loss at step 124900: 0.062796\n",
      "2023-12-02 22:29:34,135 INFO     Training average loss at step 124900: 0.062849\n",
      "2023-12-02 22:29:46,055 INFO     Training average positive_sample_loss at step 125000: 0.063110\n",
      "2023-12-02 22:29:46,055 INFO     Training average negative_sample_loss at step 125000: 0.064537\n",
      "2023-12-02 22:29:46,055 INFO     Training average loss at step 125000: 0.063824\n",
      "2023-12-02 22:29:57,277 INFO     Training average positive_sample_loss at step 125100: 0.063017\n",
      "2023-12-02 22:29:57,278 INFO     Training average negative_sample_loss at step 125100: 0.063061\n",
      "2023-12-02 22:29:57,278 INFO     Training average loss at step 125100: 0.063039\n",
      "2023-12-02 22:30:09,259 INFO     Training average positive_sample_loss at step 125200: 0.063424\n",
      "2023-12-02 22:30:09,260 INFO     Training average negative_sample_loss at step 125200: 0.063649\n",
      "2023-12-02 22:30:09,260 INFO     Training average loss at step 125200: 0.063536\n",
      "2023-12-02 22:30:21,122 INFO     Training average positive_sample_loss at step 125300: 0.063158\n",
      "2023-12-02 22:30:21,122 INFO     Training average negative_sample_loss at step 125300: 0.063074\n",
      "2023-12-02 22:30:21,122 INFO     Training average loss at step 125300: 0.063116\n",
      "2023-12-02 22:30:32,271 INFO     Training average positive_sample_loss at step 125400: 0.063589\n",
      "2023-12-02 22:30:32,271 INFO     Training average negative_sample_loss at step 125400: 0.063865\n",
      "2023-12-02 22:30:32,272 INFO     Training average loss at step 125400: 0.063727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 22:30:44,120 INFO     Training average positive_sample_loss at step 125500: 0.063379\n",
      "2023-12-02 22:30:44,120 INFO     Training average negative_sample_loss at step 125500: 0.063847\n",
      "2023-12-02 22:30:44,120 INFO     Training average loss at step 125500: 0.063613\n",
      "2023-12-02 22:30:56,867 INFO     Training average positive_sample_loss at step 125600: 0.062698\n",
      "2023-12-02 22:30:56,867 INFO     Training average negative_sample_loss at step 125600: 0.063834\n",
      "2023-12-02 22:30:56,867 INFO     Training average loss at step 125600: 0.063266\n",
      "2023-12-02 22:31:08,856 INFO     Training average positive_sample_loss at step 125700: 0.062154\n",
      "2023-12-02 22:31:08,856 INFO     Training average negative_sample_loss at step 125700: 0.063578\n",
      "2023-12-02 22:31:08,856 INFO     Training average loss at step 125700: 0.062866\n",
      "2023-12-02 22:31:20,108 INFO     Training average positive_sample_loss at step 125800: 0.062502\n",
      "2023-12-02 22:31:20,108 INFO     Training average negative_sample_loss at step 125800: 0.063153\n",
      "2023-12-02 22:31:20,108 INFO     Training average loss at step 125800: 0.062827\n",
      "2023-12-02 22:31:31,957 INFO     Training average positive_sample_loss at step 125900: 0.062911\n",
      "2023-12-02 22:31:31,957 INFO     Training average negative_sample_loss at step 125900: 0.062666\n",
      "2023-12-02 22:31:31,957 INFO     Training average loss at step 125900: 0.062788\n",
      "2023-12-02 22:31:43,754 INFO     Training average positive_sample_loss at step 126000: 0.062828\n",
      "2023-12-02 22:31:43,755 INFO     Training average negative_sample_loss at step 126000: 0.063793\n",
      "2023-12-02 22:31:43,755 INFO     Training average loss at step 126000: 0.063311\n",
      "2023-12-02 22:31:55,106 INFO     Training average positive_sample_loss at step 126100: 0.063165\n",
      "2023-12-02 22:31:55,106 INFO     Training average negative_sample_loss at step 126100: 0.063311\n",
      "2023-12-02 22:31:55,106 INFO     Training average loss at step 126100: 0.063238\n",
      "2023-12-02 22:32:06,806 INFO     Training average positive_sample_loss at step 126200: 0.063344\n",
      "2023-12-02 22:32:06,806 INFO     Training average negative_sample_loss at step 126200: 0.063037\n",
      "2023-12-02 22:32:06,806 INFO     Training average loss at step 126200: 0.063191\n",
      "2023-12-02 22:32:18,628 INFO     Training average positive_sample_loss at step 126300: 0.063325\n",
      "2023-12-02 22:32:18,629 INFO     Training average negative_sample_loss at step 126300: 0.064225\n",
      "2023-12-02 22:32:18,629 INFO     Training average loss at step 126300: 0.063775\n",
      "2023-12-02 22:32:30,501 INFO     Training average positive_sample_loss at step 126400: 0.063519\n",
      "2023-12-02 22:32:30,501 INFO     Training average negative_sample_loss at step 126400: 0.064347\n",
      "2023-12-02 22:32:30,501 INFO     Training average loss at step 126400: 0.063933\n",
      "2023-12-02 22:32:38,353 INFO     Training average positive_sample_loss at step 126500: 0.063183\n",
      "2023-12-02 22:32:38,354 INFO     Training average negative_sample_loss at step 126500: 0.063776\n",
      "2023-12-02 22:32:38,354 INFO     Training average loss at step 126500: 0.063479\n",
      "2023-12-02 22:32:47,370 INFO     Training average positive_sample_loss at step 126600: 0.061719\n",
      "2023-12-02 22:32:47,370 INFO     Training average negative_sample_loss at step 126600: 0.062900\n",
      "2023-12-02 22:32:47,370 INFO     Training average loss at step 126600: 0.062310\n",
      "2023-12-02 22:32:55,715 INFO     Training average positive_sample_loss at step 126700: 0.062411\n",
      "2023-12-02 22:32:55,715 INFO     Training average negative_sample_loss at step 126700: 0.063017\n",
      "2023-12-02 22:32:55,716 INFO     Training average loss at step 126700: 0.062714\n",
      "2023-12-02 22:33:04,380 INFO     Training average positive_sample_loss at step 126800: 0.062566\n",
      "2023-12-02 22:33:04,380 INFO     Training average negative_sample_loss at step 126800: 0.063339\n",
      "2023-12-02 22:33:04,380 INFO     Training average loss at step 126800: 0.062952\n",
      "2023-12-02 22:33:13,318 INFO     Training average positive_sample_loss at step 126900: 0.063061\n",
      "2023-12-02 22:33:13,319 INFO     Training average negative_sample_loss at step 126900: 0.064160\n",
      "2023-12-02 22:33:13,319 INFO     Training average loss at step 126900: 0.063611\n",
      "2023-12-02 22:33:22,689 INFO     Training average positive_sample_loss at step 127000: 0.063221\n",
      "2023-12-02 22:33:22,690 INFO     Training average negative_sample_loss at step 127000: 0.063440\n",
      "2023-12-02 22:33:22,690 INFO     Training average loss at step 127000: 0.063331\n",
      "2023-12-02 22:33:33,822 INFO     Training average positive_sample_loss at step 127100: 0.063211\n",
      "2023-12-02 22:33:33,822 INFO     Training average negative_sample_loss at step 127100: 0.064251\n",
      "2023-12-02 22:33:33,822 INFO     Training average loss at step 127100: 0.063731\n",
      "2023-12-02 22:33:45,621 INFO     Training average positive_sample_loss at step 127200: 0.063369\n",
      "2023-12-02 22:33:45,621 INFO     Training average negative_sample_loss at step 127200: 0.063491\n",
      "2023-12-02 22:33:45,622 INFO     Training average loss at step 127200: 0.063430\n",
      "2023-12-02 22:33:57,598 INFO     Training average positive_sample_loss at step 127300: 0.063661\n",
      "2023-12-02 22:33:57,599 INFO     Training average negative_sample_loss at step 127300: 0.062983\n",
      "2023-12-02 22:33:57,599 INFO     Training average loss at step 127300: 0.063322\n",
      "2023-12-02 22:34:09,415 INFO     Training average positive_sample_loss at step 127400: 0.063554\n",
      "2023-12-02 22:34:09,415 INFO     Training average negative_sample_loss at step 127400: 0.063702\n",
      "2023-12-02 22:34:09,415 INFO     Training average loss at step 127400: 0.063628\n",
      "2023-12-02 22:34:21,464 INFO     Training average positive_sample_loss at step 127500: 0.062426\n",
      "2023-12-02 22:34:21,464 INFO     Training average negative_sample_loss at step 127500: 0.063352\n",
      "2023-12-02 22:34:21,464 INFO     Training average loss at step 127500: 0.062889\n",
      "2023-12-02 22:34:33,493 INFO     Training average positive_sample_loss at step 127600: 0.062240\n",
      "2023-12-02 22:34:33,494 INFO     Training average negative_sample_loss at step 127600: 0.064374\n",
      "2023-12-02 22:34:33,494 INFO     Training average loss at step 127600: 0.063307\n",
      "2023-12-02 22:34:45,556 INFO     Training average positive_sample_loss at step 127700: 0.062565\n",
      "2023-12-02 22:34:45,557 INFO     Training average negative_sample_loss at step 127700: 0.063776\n",
      "2023-12-02 22:34:45,557 INFO     Training average loss at step 127700: 0.063171\n",
      "2023-12-02 22:34:56,699 INFO     Training average positive_sample_loss at step 127800: 0.063039\n",
      "2023-12-02 22:34:56,699 INFO     Training average negative_sample_loss at step 127800: 0.063643\n",
      "2023-12-02 22:34:56,699 INFO     Training average loss at step 127800: 0.063341\n",
      "2023-12-02 22:35:08,589 INFO     Training average positive_sample_loss at step 127900: 0.063180\n",
      "2023-12-02 22:35:08,590 INFO     Training average negative_sample_loss at step 127900: 0.062506\n",
      "2023-12-02 22:35:08,590 INFO     Training average loss at step 127900: 0.062843\n",
      "2023-12-02 22:35:20,406 INFO     Training average positive_sample_loss at step 128000: 0.063097\n",
      "2023-12-02 22:35:20,407 INFO     Training average negative_sample_loss at step 128000: 0.063330\n",
      "2023-12-02 22:35:20,407 INFO     Training average loss at step 128000: 0.063213\n",
      "2023-12-02 22:35:32,289 INFO     Training average positive_sample_loss at step 128100: 0.063168\n",
      "2023-12-02 22:35:32,290 INFO     Training average negative_sample_loss at step 128100: 0.063577\n",
      "2023-12-02 22:35:32,290 INFO     Training average loss at step 128100: 0.063373\n",
      "2023-12-02 22:35:43,422 INFO     Training average positive_sample_loss at step 128200: 0.063323\n",
      "2023-12-02 22:35:43,422 INFO     Training average negative_sample_loss at step 128200: 0.062797\n",
      "2023-12-02 22:35:43,422 INFO     Training average loss at step 128200: 0.063060\n",
      "2023-12-02 22:35:55,501 INFO     Training average positive_sample_loss at step 128300: 0.063783\n",
      "2023-12-02 22:35:55,501 INFO     Training average negative_sample_loss at step 128300: 0.064304\n",
      "2023-12-02 22:35:55,501 INFO     Training average loss at step 128300: 0.064043\n",
      "2023-12-02 22:36:08,323 INFO     Training average positive_sample_loss at step 128400: 0.063327\n",
      "2023-12-02 22:36:08,323 INFO     Training average negative_sample_loss at step 128400: 0.064742\n",
      "2023-12-02 22:36:08,323 INFO     Training average loss at step 128400: 0.064034\n",
      "2023-12-02 22:36:19,555 INFO     Training average positive_sample_loss at step 128500: 0.061950\n",
      "2023-12-02 22:36:19,555 INFO     Training average negative_sample_loss at step 128500: 0.063475\n",
      "2023-12-02 22:36:19,556 INFO     Training average loss at step 128500: 0.062712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 22:36:31,397 INFO     Training average positive_sample_loss at step 128600: 0.062727\n",
      "2023-12-02 22:36:31,397 INFO     Training average negative_sample_loss at step 128600: 0.063608\n",
      "2023-12-02 22:36:31,397 INFO     Training average loss at step 128600: 0.063167\n",
      "2023-12-02 22:36:43,278 INFO     Training average positive_sample_loss at step 128700: 0.062648\n",
      "2023-12-02 22:36:43,278 INFO     Training average negative_sample_loss at step 128700: 0.063245\n",
      "2023-12-02 22:36:43,279 INFO     Training average loss at step 128700: 0.062946\n",
      "2023-12-02 22:36:55,197 INFO     Training average positive_sample_loss at step 128800: 0.063032\n",
      "2023-12-02 22:36:55,197 INFO     Training average negative_sample_loss at step 128800: 0.062836\n",
      "2023-12-02 22:36:55,197 INFO     Training average loss at step 128800: 0.062934\n",
      "2023-12-02 22:37:06,310 INFO     Training average positive_sample_loss at step 128900: 0.063002\n",
      "2023-12-02 22:37:06,310 INFO     Training average negative_sample_loss at step 128900: 0.063984\n",
      "2023-12-02 22:37:06,310 INFO     Training average loss at step 128900: 0.063493\n",
      "2023-12-02 22:37:18,077 INFO     Training average positive_sample_loss at step 129000: 0.063105\n",
      "2023-12-02 22:37:18,077 INFO     Training average negative_sample_loss at step 129000: 0.064065\n",
      "2023-12-02 22:37:18,077 INFO     Training average loss at step 129000: 0.063585\n",
      "2023-12-02 22:37:29,908 INFO     Training average positive_sample_loss at step 129100: 0.063518\n",
      "2023-12-02 22:37:29,908 INFO     Training average negative_sample_loss at step 129100: 0.063909\n",
      "2023-12-02 22:37:29,908 INFO     Training average loss at step 129100: 0.063714\n",
      "2023-12-02 22:37:41,009 INFO     Training average positive_sample_loss at step 129200: 0.063657\n",
      "2023-12-02 22:37:41,009 INFO     Training average negative_sample_loss at step 129200: 0.062990\n",
      "2023-12-02 22:37:41,009 INFO     Training average loss at step 129200: 0.063324\n",
      "2023-12-02 22:37:52,834 INFO     Training average positive_sample_loss at step 129300: 0.063458\n",
      "2023-12-02 22:37:52,834 INFO     Training average negative_sample_loss at step 129300: 0.064292\n",
      "2023-12-02 22:37:52,834 INFO     Training average loss at step 129300: 0.063875\n",
      "2023-12-02 22:38:05,428 INFO     Training average positive_sample_loss at step 129400: 0.062265\n",
      "2023-12-02 22:38:05,428 INFO     Training average negative_sample_loss at step 129400: 0.063583\n",
      "2023-12-02 22:38:05,428 INFO     Training average loss at step 129400: 0.062924\n",
      "2023-12-02 22:38:17,428 INFO     Training average positive_sample_loss at step 129500: 0.062341\n",
      "2023-12-02 22:38:17,428 INFO     Training average negative_sample_loss at step 129500: 0.063660\n",
      "2023-12-02 22:38:17,428 INFO     Training average loss at step 129500: 0.063000\n",
      "2023-12-02 22:38:28,655 INFO     Training average positive_sample_loss at step 129600: 0.062540\n",
      "2023-12-02 22:38:28,656 INFO     Training average negative_sample_loss at step 129600: 0.063908\n",
      "2023-12-02 22:38:28,656 INFO     Training average loss at step 129600: 0.063224\n",
      "2023-12-02 22:38:40,551 INFO     Training average positive_sample_loss at step 129700: 0.062867\n",
      "2023-12-02 22:38:40,551 INFO     Training average negative_sample_loss at step 129700: 0.063440\n",
      "2023-12-02 22:38:40,551 INFO     Training average loss at step 129700: 0.063153\n",
      "2023-12-02 22:38:52,413 INFO     Training average positive_sample_loss at step 129800: 0.063455\n",
      "2023-12-02 22:38:52,413 INFO     Training average negative_sample_loss at step 129800: 0.063661\n",
      "2023-12-02 22:38:52,413 INFO     Training average loss at step 129800: 0.063558\n",
      "2023-12-02 22:39:03,590 INFO     Training average positive_sample_loss at step 129900: 0.062973\n",
      "2023-12-02 22:39:03,590 INFO     Training average negative_sample_loss at step 129900: 0.061942\n",
      "2023-12-02 22:39:03,590 INFO     Training average loss at step 129900: 0.062458\n",
      "2023-12-02 22:39:32,604 INFO     Training average positive_sample_loss at step 130000: 0.063074\n",
      "2023-12-02 22:39:32,605 INFO     Training average negative_sample_loss at step 130000: 0.063347\n",
      "2023-12-02 22:39:32,605 INFO     Training average loss at step 130000: 0.063210\n",
      "2023-12-02 22:39:32,605 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 22:39:33,531 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 22:40:58,032 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 22:42:21,248 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 22:43:43,964 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 22:45:07,513 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 22:46:31,413 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 22:47:54,294 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 22:48:14,673 INFO     Valid MRR at step 130000: 0.790519\n",
      "2023-12-02 22:48:14,674 INFO     Valid MR at step 130000: 41.066070\n",
      "2023-12-02 22:48:14,674 INFO     Valid HITS@1 at step 130000: 0.738680\n",
      "2023-12-02 22:48:14,674 INFO     Valid HITS@3 at step 130000: 0.823160\n",
      "2023-12-02 22:48:14,674 INFO     Valid HITS@10 at step 130000: 0.880210\n",
      "2023-12-02 22:48:26,477 INFO     Training average positive_sample_loss at step 130100: 0.063595\n",
      "2023-12-02 22:48:26,478 INFO     Training average negative_sample_loss at step 130100: 0.064619\n",
      "2023-12-02 22:48:26,478 INFO     Training average loss at step 130100: 0.064107\n",
      "2023-12-02 22:48:38,228 INFO     Training average positive_sample_loss at step 130200: 0.063350\n",
      "2023-12-02 22:48:38,228 INFO     Training average negative_sample_loss at step 130200: 0.063599\n",
      "2023-12-02 22:48:38,228 INFO     Training average loss at step 130200: 0.063475\n",
      "2023-12-02 22:48:50,349 INFO     Training average positive_sample_loss at step 130300: 0.063270\n",
      "2023-12-02 22:48:50,349 INFO     Training average negative_sample_loss at step 130300: 0.063700\n",
      "2023-12-02 22:48:50,349 INFO     Training average loss at step 130300: 0.063485\n",
      "2023-12-02 22:49:02,219 INFO     Training average positive_sample_loss at step 130400: 0.061904\n",
      "2023-12-02 22:49:02,219 INFO     Training average negative_sample_loss at step 130400: 0.063168\n",
      "2023-12-02 22:49:02,219 INFO     Training average loss at step 130400: 0.062536\n",
      "2023-12-02 22:49:14,073 INFO     Training average positive_sample_loss at step 130500: 0.062662\n",
      "2023-12-02 22:49:14,074 INFO     Training average negative_sample_loss at step 130500: 0.064498\n",
      "2023-12-02 22:49:14,074 INFO     Training average loss at step 130500: 0.063580\n",
      "2023-12-02 22:49:25,159 INFO     Training average positive_sample_loss at step 130600: 0.062884\n",
      "2023-12-02 22:49:25,159 INFO     Training average negative_sample_loss at step 130600: 0.063022\n",
      "2023-12-02 22:49:25,159 INFO     Training average loss at step 130600: 0.062953\n",
      "2023-12-02 22:49:37,031 INFO     Training average positive_sample_loss at step 130700: 0.062899\n",
      "2023-12-02 22:49:37,031 INFO     Training average negative_sample_loss at step 130700: 0.062694\n",
      "2023-12-02 22:49:37,031 INFO     Training average loss at step 130700: 0.062796\n",
      "2023-12-02 22:49:48,918 INFO     Training average positive_sample_loss at step 130800: 0.063042\n",
      "2023-12-02 22:49:48,918 INFO     Training average negative_sample_loss at step 130800: 0.063008\n",
      "2023-12-02 22:49:48,918 INFO     Training average loss at step 130800: 0.063025\n",
      "2023-12-02 22:50:00,757 INFO     Training average positive_sample_loss at step 130900: 0.063239\n",
      "2023-12-02 22:50:00,758 INFO     Training average negative_sample_loss at step 130900: 0.063255\n",
      "2023-12-02 22:50:00,758 INFO     Training average loss at step 130900: 0.063247\n",
      "2023-12-02 22:50:11,925 INFO     Training average positive_sample_loss at step 131000: 0.063155\n",
      "2023-12-02 22:50:11,925 INFO     Training average negative_sample_loss at step 131000: 0.062970\n",
      "2023-12-02 22:50:11,925 INFO     Training average loss at step 131000: 0.063063\n",
      "2023-12-02 22:50:20,630 INFO     Training average positive_sample_loss at step 131100: 0.063275\n",
      "2023-12-02 22:50:20,631 INFO     Training average negative_sample_loss at step 131100: 0.064079\n",
      "2023-12-02 22:50:20,631 INFO     Training average loss at step 131100: 0.063677\n",
      "2023-12-02 22:50:29,106 INFO     Training average positive_sample_loss at step 131200: 0.063366\n",
      "2023-12-02 22:50:29,107 INFO     Training average negative_sample_loss at step 131200: 0.063542\n",
      "2023-12-02 22:50:29,107 INFO     Training average loss at step 131200: 0.063454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 22:50:39,861 INFO     Training average positive_sample_loss at step 131300: 0.062051\n",
      "2023-12-02 22:50:39,862 INFO     Training average negative_sample_loss at step 131300: 0.063331\n",
      "2023-12-02 22:50:39,862 INFO     Training average loss at step 131300: 0.062691\n",
      "2023-12-02 22:50:49,238 INFO     Training average positive_sample_loss at step 131400: 0.062349\n",
      "2023-12-02 22:50:49,238 INFO     Training average negative_sample_loss at step 131400: 0.062819\n",
      "2023-12-02 22:50:49,238 INFO     Training average loss at step 131400: 0.062584\n",
      "2023-12-02 22:50:57,899 INFO     Training average positive_sample_loss at step 131500: 0.062315\n",
      "2023-12-02 22:50:57,899 INFO     Training average negative_sample_loss at step 131500: 0.062618\n",
      "2023-12-02 22:50:57,899 INFO     Training average loss at step 131500: 0.062466\n",
      "2023-12-02 22:51:08,157 INFO     Training average positive_sample_loss at step 131600: 0.062817\n",
      "2023-12-02 22:51:08,157 INFO     Training average negative_sample_loss at step 131600: 0.063136\n",
      "2023-12-02 22:51:08,157 INFO     Training average loss at step 131600: 0.062976\n",
      "2023-12-02 22:51:19,974 INFO     Training average positive_sample_loss at step 131700: 0.063214\n",
      "2023-12-02 22:51:19,975 INFO     Training average negative_sample_loss at step 131700: 0.063688\n",
      "2023-12-02 22:51:19,975 INFO     Training average loss at step 131700: 0.063451\n",
      "2023-12-02 22:51:31,718 INFO     Training average positive_sample_loss at step 131800: 0.063055\n",
      "2023-12-02 22:51:31,719 INFO     Training average negative_sample_loss at step 131800: 0.063082\n",
      "2023-12-02 22:51:31,719 INFO     Training average loss at step 131800: 0.063069\n",
      "2023-12-02 22:51:42,754 INFO     Training average positive_sample_loss at step 131900: 0.063242\n",
      "2023-12-02 22:51:42,754 INFO     Training average negative_sample_loss at step 131900: 0.062880\n",
      "2023-12-02 22:51:42,754 INFO     Training average loss at step 131900: 0.063061\n",
      "2023-12-02 22:51:54,496 INFO     Training average positive_sample_loss at step 132000: 0.063215\n",
      "2023-12-02 22:51:54,497 INFO     Training average negative_sample_loss at step 132000: 0.063946\n",
      "2023-12-02 22:51:54,497 INFO     Training average loss at step 132000: 0.063581\n",
      "2023-12-02 22:52:06,341 INFO     Training average positive_sample_loss at step 132100: 0.063681\n",
      "2023-12-02 22:52:06,342 INFO     Training average negative_sample_loss at step 132100: 0.063911\n",
      "2023-12-02 22:52:06,342 INFO     Training average loss at step 132100: 0.063796\n",
      "2023-12-02 22:52:18,368 INFO     Training average positive_sample_loss at step 132200: 0.062839\n",
      "2023-12-02 22:52:18,368 INFO     Training average negative_sample_loss at step 132200: 0.063255\n",
      "2023-12-02 22:52:18,368 INFO     Training average loss at step 132200: 0.063047\n",
      "2023-12-02 22:52:30,207 INFO     Training average positive_sample_loss at step 132300: 0.062042\n",
      "2023-12-02 22:52:30,207 INFO     Training average negative_sample_loss at step 132300: 0.063783\n",
      "2023-12-02 22:52:30,207 INFO     Training average loss at step 132300: 0.062913\n",
      "2023-12-02 22:52:42,164 INFO     Training average positive_sample_loss at step 132400: 0.062368\n",
      "2023-12-02 22:52:42,164 INFO     Training average negative_sample_loss at step 132400: 0.063146\n",
      "2023-12-02 22:52:42,164 INFO     Training average loss at step 132400: 0.062757\n",
      "2023-12-02 22:52:54,003 INFO     Training average positive_sample_loss at step 132500: 0.062526\n",
      "2023-12-02 22:52:54,003 INFO     Training average negative_sample_loss at step 132500: 0.062887\n",
      "2023-12-02 22:52:54,003 INFO     Training average loss at step 132500: 0.062706\n",
      "2023-12-02 22:53:05,234 INFO     Training average positive_sample_loss at step 132600: 0.063146\n",
      "2023-12-02 22:53:05,234 INFO     Training average negative_sample_loss at step 132600: 0.063048\n",
      "2023-12-02 22:53:05,234 INFO     Training average loss at step 132600: 0.063097\n",
      "2023-12-02 22:53:17,157 INFO     Training average positive_sample_loss at step 132700: 0.063142\n",
      "2023-12-02 22:53:17,157 INFO     Training average negative_sample_loss at step 132700: 0.064101\n",
      "2023-12-02 22:53:17,157 INFO     Training average loss at step 132700: 0.063621\n",
      "2023-12-02 22:53:29,057 INFO     Training average positive_sample_loss at step 132800: 0.063027\n",
      "2023-12-02 22:53:29,057 INFO     Training average negative_sample_loss at step 132800: 0.063169\n",
      "2023-12-02 22:53:29,057 INFO     Training average loss at step 132800: 0.063098\n",
      "2023-12-02 22:53:40,690 INFO     Training average positive_sample_loss at step 132900: 0.063207\n",
      "2023-12-02 22:53:40,690 INFO     Training average negative_sample_loss at step 132900: 0.063474\n",
      "2023-12-02 22:53:40,690 INFO     Training average loss at step 132900: 0.063340\n",
      "2023-12-02 22:53:51,978 INFO     Training average positive_sample_loss at step 133000: 0.063540\n",
      "2023-12-02 22:53:51,978 INFO     Training average negative_sample_loss at step 133000: 0.063987\n",
      "2023-12-02 22:53:51,978 INFO     Training average loss at step 133000: 0.063764\n",
      "2023-12-02 22:54:03,964 INFO     Training average positive_sample_loss at step 133100: 0.063511\n",
      "2023-12-02 22:54:03,965 INFO     Training average negative_sample_loss at step 133100: 0.064121\n",
      "2023-12-02 22:54:03,965 INFO     Training average loss at step 133100: 0.063816\n",
      "2023-12-02 22:54:16,482 INFO     Training average positive_sample_loss at step 133200: 0.061930\n",
      "2023-12-02 22:54:16,483 INFO     Training average negative_sample_loss at step 133200: 0.063629\n",
      "2023-12-02 22:54:16,483 INFO     Training average loss at step 133200: 0.062780\n",
      "2023-12-02 22:54:27,718 INFO     Training average positive_sample_loss at step 133300: 0.062191\n",
      "2023-12-02 22:54:27,719 INFO     Training average negative_sample_loss at step 133300: 0.062880\n",
      "2023-12-02 22:54:27,719 INFO     Training average loss at step 133300: 0.062536\n",
      "2023-12-02 22:54:39,715 INFO     Training average positive_sample_loss at step 133400: 0.062688\n",
      "2023-12-02 22:54:39,716 INFO     Training average negative_sample_loss at step 133400: 0.063452\n",
      "2023-12-02 22:54:39,716 INFO     Training average loss at step 133400: 0.063070\n",
      "2023-12-02 22:54:51,650 INFO     Training average positive_sample_loss at step 133500: 0.062853\n",
      "2023-12-02 22:54:51,650 INFO     Training average negative_sample_loss at step 133500: 0.063963\n",
      "2023-12-02 22:54:51,651 INFO     Training average loss at step 133500: 0.063408\n",
      "2023-12-02 22:55:03,572 INFO     Training average positive_sample_loss at step 133600: 0.063056\n",
      "2023-12-02 22:55:03,572 INFO     Training average negative_sample_loss at step 133600: 0.063310\n",
      "2023-12-02 22:55:03,572 INFO     Training average loss at step 133600: 0.063183\n",
      "2023-12-02 22:55:14,792 INFO     Training average positive_sample_loss at step 133700: 0.063298\n",
      "2023-12-02 22:55:14,792 INFO     Training average negative_sample_loss at step 133700: 0.063317\n",
      "2023-12-02 22:55:14,792 INFO     Training average loss at step 133700: 0.063308\n",
      "2023-12-02 22:55:26,580 INFO     Training average positive_sample_loss at step 133800: 0.063264\n",
      "2023-12-02 22:55:26,580 INFO     Training average negative_sample_loss at step 133800: 0.063429\n",
      "2023-12-02 22:55:26,580 INFO     Training average loss at step 133800: 0.063347\n",
      "2023-12-02 22:55:38,358 INFO     Training average positive_sample_loss at step 133900: 0.063186\n",
      "2023-12-02 22:55:38,358 INFO     Training average negative_sample_loss at step 133900: 0.063688\n",
      "2023-12-02 22:55:38,358 INFO     Training average loss at step 133900: 0.063437\n",
      "2023-12-02 22:55:49,461 INFO     Training average positive_sample_loss at step 134000: 0.063479\n",
      "2023-12-02 22:55:49,461 INFO     Training average negative_sample_loss at step 134000: 0.063475\n",
      "2023-12-02 22:55:49,461 INFO     Training average loss at step 134000: 0.063477\n",
      "2023-12-02 22:56:02,229 INFO     Training average positive_sample_loss at step 134100: 0.062716\n",
      "2023-12-02 22:56:02,229 INFO     Training average negative_sample_loss at step 134100: 0.063526\n",
      "2023-12-02 22:56:02,229 INFO     Training average loss at step 134100: 0.063121\n",
      "2023-12-02 22:56:14,208 INFO     Training average positive_sample_loss at step 134200: 0.062161\n",
      "2023-12-02 22:56:14,208 INFO     Training average negative_sample_loss at step 134200: 0.063624\n",
      "2023-12-02 22:56:14,208 INFO     Training average loss at step 134200: 0.062893\n",
      "2023-12-02 22:56:26,221 INFO     Training average positive_sample_loss at step 134300: 0.062392\n",
      "2023-12-02 22:56:26,221 INFO     Training average negative_sample_loss at step 134300: 0.063018\n",
      "2023-12-02 22:56:26,221 INFO     Training average loss at step 134300: 0.062705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 22:56:37,444 INFO     Training average positive_sample_loss at step 134400: 0.062906\n",
      "2023-12-02 22:56:37,444 INFO     Training average negative_sample_loss at step 134400: 0.063110\n",
      "2023-12-02 22:56:37,444 INFO     Training average loss at step 134400: 0.063008\n",
      "2023-12-02 22:56:49,329 INFO     Training average positive_sample_loss at step 134500: 0.062637\n",
      "2023-12-02 22:56:49,329 INFO     Training average negative_sample_loss at step 134500: 0.063037\n",
      "2023-12-02 22:56:49,329 INFO     Training average loss at step 134500: 0.062837\n",
      "2023-12-02 22:57:01,200 INFO     Training average positive_sample_loss at step 134600: 0.063078\n",
      "2023-12-02 22:57:01,200 INFO     Training average negative_sample_loss at step 134600: 0.063636\n",
      "2023-12-02 22:57:01,200 INFO     Training average loss at step 134600: 0.063357\n",
      "2023-12-02 22:57:12,465 INFO     Training average positive_sample_loss at step 134700: 0.063162\n",
      "2023-12-02 22:57:12,466 INFO     Training average negative_sample_loss at step 134700: 0.063511\n",
      "2023-12-02 22:57:12,466 INFO     Training average loss at step 134700: 0.063336\n",
      "2023-12-02 22:57:24,261 INFO     Training average positive_sample_loss at step 134800: 0.063452\n",
      "2023-12-02 22:57:24,261 INFO     Training average negative_sample_loss at step 134800: 0.063739\n",
      "2023-12-02 22:57:24,261 INFO     Training average loss at step 134800: 0.063596\n",
      "2023-12-02 22:57:36,094 INFO     Training average positive_sample_loss at step 134900: 0.063716\n",
      "2023-12-02 22:57:36,094 INFO     Training average negative_sample_loss at step 134900: 0.064557\n",
      "2023-12-02 22:57:36,094 INFO     Training average loss at step 134900: 0.064137\n",
      "2023-12-02 22:57:48,683 INFO     Training average positive_sample_loss at step 135000: 0.063596\n",
      "2023-12-02 22:57:48,683 INFO     Training average negative_sample_loss at step 135000: 0.065087\n",
      "2023-12-02 22:57:48,683 INFO     Training average loss at step 135000: 0.064341\n",
      "2023-12-02 22:57:59,872 INFO     Training average positive_sample_loss at step 135100: 0.061736\n",
      "2023-12-02 22:57:59,873 INFO     Training average negative_sample_loss at step 135100: 0.062880\n",
      "2023-12-02 22:57:59,873 INFO     Training average loss at step 135100: 0.062308\n",
      "2023-12-02 22:58:11,786 INFO     Training average positive_sample_loss at step 135200: 0.062426\n",
      "2023-12-02 22:58:11,786 INFO     Training average negative_sample_loss at step 135200: 0.063629\n",
      "2023-12-02 22:58:11,786 INFO     Training average loss at step 135200: 0.063027\n",
      "2023-12-02 22:58:23,755 INFO     Training average positive_sample_loss at step 135300: 0.062808\n",
      "2023-12-02 22:58:23,755 INFO     Training average negative_sample_loss at step 135300: 0.063579\n",
      "2023-12-02 22:58:23,756 INFO     Training average loss at step 135300: 0.063194\n",
      "2023-12-02 22:58:35,015 INFO     Training average positive_sample_loss at step 135400: 0.062960\n",
      "2023-12-02 22:58:35,015 INFO     Training average negative_sample_loss at step 135400: 0.063069\n",
      "2023-12-02 22:58:35,015 INFO     Training average loss at step 135400: 0.063015\n",
      "2023-12-02 22:58:46,936 INFO     Training average positive_sample_loss at step 135500: 0.062749\n",
      "2023-12-02 22:58:46,937 INFO     Training average negative_sample_loss at step 135500: 0.062742\n",
      "2023-12-02 22:58:46,937 INFO     Training average loss at step 135500: 0.062745\n",
      "2023-12-02 22:58:58,875 INFO     Training average positive_sample_loss at step 135600: 0.063206\n",
      "2023-12-02 22:58:58,876 INFO     Training average negative_sample_loss at step 135600: 0.063589\n",
      "2023-12-02 22:58:58,876 INFO     Training average loss at step 135600: 0.063398\n",
      "2023-12-02 22:59:10,984 INFO     Training average positive_sample_loss at step 135700: 0.063448\n",
      "2023-12-02 22:59:10,984 INFO     Training average negative_sample_loss at step 135700: 0.064036\n",
      "2023-12-02 22:59:10,984 INFO     Training average loss at step 135700: 0.063742\n",
      "2023-12-02 22:59:22,245 INFO     Training average positive_sample_loss at step 135800: 0.063570\n",
      "2023-12-02 22:59:22,245 INFO     Training average negative_sample_loss at step 135800: 0.064092\n",
      "2023-12-02 22:59:22,245 INFO     Training average loss at step 135800: 0.063831\n",
      "2023-12-02 22:59:34,241 INFO     Training average positive_sample_loss at step 135900: 0.063810\n",
      "2023-12-02 22:59:34,242 INFO     Training average negative_sample_loss at step 135900: 0.063267\n",
      "2023-12-02 22:59:34,242 INFO     Training average loss at step 135900: 0.063538\n",
      "2023-12-02 22:59:46,950 INFO     Training average positive_sample_loss at step 136000: 0.062402\n",
      "2023-12-02 22:59:46,950 INFO     Training average negative_sample_loss at step 136000: 0.063411\n",
      "2023-12-02 22:59:46,950 INFO     Training average loss at step 136000: 0.062907\n",
      "2023-12-02 22:59:58,264 INFO     Training average positive_sample_loss at step 136100: 0.062185\n",
      "2023-12-02 22:59:58,264 INFO     Training average negative_sample_loss at step 136100: 0.063363\n",
      "2023-12-02 22:59:58,264 INFO     Training average loss at step 136100: 0.062774\n",
      "2023-12-02 23:00:10,166 INFO     Training average positive_sample_loss at step 136200: 0.062280\n",
      "2023-12-02 23:00:10,166 INFO     Training average negative_sample_loss at step 136200: 0.063196\n",
      "2023-12-02 23:00:10,166 INFO     Training average loss at step 136200: 0.062738\n",
      "2023-12-02 23:00:22,051 INFO     Training average positive_sample_loss at step 136300: 0.062529\n",
      "2023-12-02 23:00:22,051 INFO     Training average negative_sample_loss at step 136300: 0.063203\n",
      "2023-12-02 23:00:22,051 INFO     Training average loss at step 136300: 0.062866\n",
      "2023-12-02 23:00:34,034 INFO     Training average positive_sample_loss at step 136400: 0.063414\n",
      "2023-12-02 23:00:34,034 INFO     Training average negative_sample_loss at step 136400: 0.063833\n",
      "2023-12-02 23:00:34,035 INFO     Training average loss at step 136400: 0.063624\n",
      "2023-12-02 23:00:45,339 INFO     Training average positive_sample_loss at step 136500: 0.063000\n",
      "2023-12-02 23:00:45,340 INFO     Training average negative_sample_loss at step 136500: 0.062720\n",
      "2023-12-02 23:00:45,340 INFO     Training average loss at step 136500: 0.062860\n",
      "2023-12-02 23:00:57,481 INFO     Training average positive_sample_loss at step 136600: 0.063306\n",
      "2023-12-02 23:00:57,482 INFO     Training average negative_sample_loss at step 136600: 0.063523\n",
      "2023-12-02 23:00:57,482 INFO     Training average loss at step 136600: 0.063414\n",
      "2023-12-02 23:01:09,356 INFO     Training average positive_sample_loss at step 136700: 0.063344\n",
      "2023-12-02 23:01:09,356 INFO     Training average negative_sample_loss at step 136700: 0.063298\n",
      "2023-12-02 23:01:09,356 INFO     Training average loss at step 136700: 0.063321\n",
      "2023-12-02 23:01:21,170 INFO     Training average positive_sample_loss at step 136800: 0.063752\n",
      "2023-12-02 23:01:21,170 INFO     Training average negative_sample_loss at step 136800: 0.064257\n",
      "2023-12-02 23:01:21,170 INFO     Training average loss at step 136800: 0.064004\n",
      "2023-12-02 23:01:33,247 INFO     Training average positive_sample_loss at step 136900: 0.062933\n",
      "2023-12-02 23:01:33,247 INFO     Training average negative_sample_loss at step 136900: 0.064219\n",
      "2023-12-02 23:01:33,247 INFO     Training average loss at step 136900: 0.063576\n",
      "2023-12-02 23:01:45,095 INFO     Training average positive_sample_loss at step 137000: 0.062040\n",
      "2023-12-02 23:01:45,095 INFO     Training average negative_sample_loss at step 137000: 0.062829\n",
      "2023-12-02 23:01:45,095 INFO     Training average loss at step 137000: 0.062435\n",
      "2023-12-02 23:01:57,039 INFO     Training average positive_sample_loss at step 137100: 0.062167\n",
      "2023-12-02 23:01:57,039 INFO     Training average negative_sample_loss at step 137100: 0.063296\n",
      "2023-12-02 23:01:57,039 INFO     Training average loss at step 137100: 0.062732\n",
      "2023-12-02 23:02:08,183 INFO     Training average positive_sample_loss at step 137200: 0.062675\n",
      "2023-12-02 23:02:08,183 INFO     Training average negative_sample_loss at step 137200: 0.063827\n",
      "2023-12-02 23:02:08,183 INFO     Training average loss at step 137200: 0.063251\n",
      "2023-12-02 23:02:20,069 INFO     Training average positive_sample_loss at step 137300: 0.062744\n",
      "2023-12-02 23:02:20,070 INFO     Training average negative_sample_loss at step 137300: 0.061939\n",
      "2023-12-02 23:02:20,070 INFO     Training average loss at step 137300: 0.062341\n",
      "2023-12-02 23:02:31,927 INFO     Training average positive_sample_loss at step 137400: 0.063189\n",
      "2023-12-02 23:02:31,928 INFO     Training average negative_sample_loss at step 137400: 0.063499\n",
      "2023-12-02 23:02:31,928 INFO     Training average loss at step 137400: 0.063344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 23:02:43,775 INFO     Training average positive_sample_loss at step 137500: 0.063347\n",
      "2023-12-02 23:02:43,775 INFO     Training average negative_sample_loss at step 137500: 0.064393\n",
      "2023-12-02 23:02:43,775 INFO     Training average loss at step 137500: 0.063870\n",
      "2023-12-02 23:02:54,929 INFO     Training average positive_sample_loss at step 137600: 0.063462\n",
      "2023-12-02 23:02:54,930 INFO     Training average negative_sample_loss at step 137600: 0.063519\n",
      "2023-12-02 23:02:54,930 INFO     Training average loss at step 137600: 0.063490\n",
      "2023-12-02 23:03:06,877 INFO     Training average positive_sample_loss at step 137700: 0.063064\n",
      "2023-12-02 23:03:06,878 INFO     Training average negative_sample_loss at step 137700: 0.063193\n",
      "2023-12-02 23:03:06,878 INFO     Training average loss at step 137700: 0.063128\n",
      "2023-12-02 23:03:18,746 INFO     Training average positive_sample_loss at step 137800: 0.063667\n",
      "2023-12-02 23:03:18,747 INFO     Training average negative_sample_loss at step 137800: 0.063909\n",
      "2023-12-02 23:03:18,747 INFO     Training average loss at step 137800: 0.063788\n",
      "2023-12-02 23:03:30,754 INFO     Training average positive_sample_loss at step 137900: 0.062063\n",
      "2023-12-02 23:03:30,755 INFO     Training average negative_sample_loss at step 137900: 0.064109\n",
      "2023-12-02 23:03:30,755 INFO     Training average loss at step 137900: 0.063086\n",
      "2023-12-02 23:03:42,533 INFO     Training average positive_sample_loss at step 138000: 0.062110\n",
      "2023-12-02 23:03:42,533 INFO     Training average negative_sample_loss at step 138000: 0.063249\n",
      "2023-12-02 23:03:42,533 INFO     Training average loss at step 138000: 0.062680\n",
      "2023-12-02 23:03:54,372 INFO     Training average positive_sample_loss at step 138100: 0.062825\n",
      "2023-12-02 23:03:54,373 INFO     Training average negative_sample_loss at step 138100: 0.063678\n",
      "2023-12-02 23:03:54,373 INFO     Training average loss at step 138100: 0.063252\n",
      "2023-12-02 23:04:06,120 INFO     Training average positive_sample_loss at step 138200: 0.062806\n",
      "2023-12-02 23:04:06,120 INFO     Training average negative_sample_loss at step 138200: 0.063380\n",
      "2023-12-02 23:04:06,120 INFO     Training average loss at step 138200: 0.063093\n",
      "2023-12-02 23:04:17,248 INFO     Training average positive_sample_loss at step 138300: 0.063012\n",
      "2023-12-02 23:04:17,248 INFO     Training average negative_sample_loss at step 138300: 0.063246\n",
      "2023-12-02 23:04:17,249 INFO     Training average loss at step 138300: 0.063129\n",
      "2023-12-02 23:04:29,187 INFO     Training average positive_sample_loss at step 138400: 0.063012\n",
      "2023-12-02 23:04:29,188 INFO     Training average negative_sample_loss at step 138400: 0.063319\n",
      "2023-12-02 23:04:29,188 INFO     Training average loss at step 138400: 0.063165\n",
      "2023-12-02 23:04:41,037 INFO     Training average positive_sample_loss at step 138500: 0.063417\n",
      "2023-12-02 23:04:41,037 INFO     Training average negative_sample_loss at step 138500: 0.062867\n",
      "2023-12-02 23:04:41,037 INFO     Training average loss at step 138500: 0.063142\n",
      "2023-12-02 23:04:52,404 INFO     Training average positive_sample_loss at step 138600: 0.063398\n",
      "2023-12-02 23:04:52,404 INFO     Training average negative_sample_loss at step 138600: 0.063345\n",
      "2023-12-02 23:04:52,404 INFO     Training average loss at step 138600: 0.063371\n",
      "2023-12-02 23:05:04,047 INFO     Training average positive_sample_loss at step 138700: 0.063448\n",
      "2023-12-02 23:05:04,047 INFO     Training average negative_sample_loss at step 138700: 0.063952\n",
      "2023-12-02 23:05:04,047 INFO     Training average loss at step 138700: 0.063700\n",
      "2023-12-02 23:05:16,767 INFO     Training average positive_sample_loss at step 138800: 0.062801\n",
      "2023-12-02 23:05:16,767 INFO     Training average negative_sample_loss at step 138800: 0.063268\n",
      "2023-12-02 23:05:16,767 INFO     Training average loss at step 138800: 0.063034\n",
      "2023-12-02 23:05:28,827 INFO     Training average positive_sample_loss at step 138900: 0.061745\n",
      "2023-12-02 23:05:28,828 INFO     Training average negative_sample_loss at step 138900: 0.063262\n",
      "2023-12-02 23:05:28,828 INFO     Training average loss at step 138900: 0.062503\n",
      "2023-12-02 23:05:40,019 INFO     Training average positive_sample_loss at step 139000: 0.062682\n",
      "2023-12-02 23:05:40,019 INFO     Training average negative_sample_loss at step 139000: 0.063738\n",
      "2023-12-02 23:05:40,019 INFO     Training average loss at step 139000: 0.063210\n",
      "2023-12-02 23:05:51,836 INFO     Training average positive_sample_loss at step 139100: 0.062657\n",
      "2023-12-02 23:05:51,836 INFO     Training average negative_sample_loss at step 139100: 0.062739\n",
      "2023-12-02 23:05:51,836 INFO     Training average loss at step 139100: 0.062698\n",
      "2023-12-02 23:06:03,791 INFO     Training average positive_sample_loss at step 139200: 0.062665\n",
      "2023-12-02 23:06:03,791 INFO     Training average negative_sample_loss at step 139200: 0.063023\n",
      "2023-12-02 23:06:03,791 INFO     Training average loss at step 139200: 0.062844\n",
      "2023-12-02 23:06:15,540 INFO     Training average positive_sample_loss at step 139300: 0.062996\n",
      "2023-12-02 23:06:15,541 INFO     Training average negative_sample_loss at step 139300: 0.064057\n",
      "2023-12-02 23:06:15,541 INFO     Training average loss at step 139300: 0.063526\n",
      "2023-12-02 23:06:26,673 INFO     Training average positive_sample_loss at step 139400: 0.063054\n",
      "2023-12-02 23:06:26,674 INFO     Training average negative_sample_loss at step 139400: 0.062402\n",
      "2023-12-02 23:06:26,674 INFO     Training average loss at step 139400: 0.062728\n",
      "2023-12-02 23:06:38,506 INFO     Training average positive_sample_loss at step 139500: 0.063439\n",
      "2023-12-02 23:06:38,506 INFO     Training average negative_sample_loss at step 139500: 0.062498\n",
      "2023-12-02 23:06:38,506 INFO     Training average loss at step 139500: 0.062969\n",
      "2023-12-02 23:06:50,317 INFO     Training average positive_sample_loss at step 139600: 0.063264\n",
      "2023-12-02 23:06:50,317 INFO     Training average negative_sample_loss at step 139600: 0.063591\n",
      "2023-12-02 23:06:50,318 INFO     Training average loss at step 139600: 0.063428\n",
      "2023-12-02 23:07:01,375 INFO     Training average positive_sample_loss at step 139700: 0.063426\n",
      "2023-12-02 23:07:01,375 INFO     Training average negative_sample_loss at step 139700: 0.063825\n",
      "2023-12-02 23:07:01,375 INFO     Training average loss at step 139700: 0.063626\n",
      "2023-12-02 23:07:13,985 INFO     Training average positive_sample_loss at step 139800: 0.062046\n",
      "2023-12-02 23:07:13,986 INFO     Training average negative_sample_loss at step 139800: 0.063618\n",
      "2023-12-02 23:07:13,986 INFO     Training average loss at step 139800: 0.062832\n",
      "2023-12-02 23:07:26,073 INFO     Training average positive_sample_loss at step 139900: 0.062302\n",
      "2023-12-02 23:07:26,074 INFO     Training average negative_sample_loss at step 139900: 0.063433\n",
      "2023-12-02 23:07:26,074 INFO     Training average loss at step 139900: 0.062867\n",
      "2023-12-02 23:07:49,880 INFO     Training average positive_sample_loss at step 140000: 0.062730\n",
      "2023-12-02 23:07:49,881 INFO     Training average negative_sample_loss at step 140000: 0.063468\n",
      "2023-12-02 23:07:49,881 INFO     Training average loss at step 140000: 0.063099\n",
      "2023-12-02 23:07:49,881 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 23:07:51,238 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 23:09:13,880 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 23:10:32,641 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 23:11:16,317 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 23:12:39,022 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 23:14:01,256 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 23:15:24,715 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 23:15:46,626 INFO     Valid MRR at step 140000: 0.790400\n",
      "2023-12-02 23:15:46,627 INFO     Valid MR at step 140000: 41.030770\n",
      "2023-12-02 23:15:46,627 INFO     Valid HITS@1 at step 140000: 0.737970\n",
      "2023-12-02 23:15:46,627 INFO     Valid HITS@3 at step 140000: 0.824220\n",
      "2023-12-02 23:15:46,627 INFO     Valid HITS@10 at step 140000: 0.880240\n",
      "2023-12-02 23:15:57,825 INFO     Training average positive_sample_loss at step 140100: 0.062728\n",
      "2023-12-02 23:15:57,826 INFO     Training average negative_sample_loss at step 140100: 0.063128\n",
      "2023-12-02 23:15:57,826 INFO     Training average loss at step 140100: 0.062928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 23:16:09,576 INFO     Training average positive_sample_loss at step 140200: 0.063009\n",
      "2023-12-02 23:16:09,576 INFO     Training average negative_sample_loss at step 140200: 0.063018\n",
      "2023-12-02 23:16:09,576 INFO     Training average loss at step 140200: 0.063014\n",
      "2023-12-02 23:16:21,433 INFO     Training average positive_sample_loss at step 140300: 0.063296\n",
      "2023-12-02 23:16:21,433 INFO     Training average negative_sample_loss at step 140300: 0.063171\n",
      "2023-12-02 23:16:21,434 INFO     Training average loss at step 140300: 0.063234\n",
      "2023-12-02 23:16:32,580 INFO     Training average positive_sample_loss at step 140400: 0.062686\n",
      "2023-12-02 23:16:32,580 INFO     Training average negative_sample_loss at step 140400: 0.062843\n",
      "2023-12-02 23:16:32,580 INFO     Training average loss at step 140400: 0.062764\n",
      "2023-12-02 23:16:44,373 INFO     Training average positive_sample_loss at step 140500: 0.063385\n",
      "2023-12-02 23:16:44,373 INFO     Training average negative_sample_loss at step 140500: 0.063020\n",
      "2023-12-02 23:16:44,374 INFO     Training average loss at step 140500: 0.063202\n",
      "2023-12-02 23:16:56,189 INFO     Training average positive_sample_loss at step 140600: 0.063024\n",
      "2023-12-02 23:16:56,190 INFO     Training average negative_sample_loss at step 140600: 0.063240\n",
      "2023-12-02 23:16:56,190 INFO     Training average loss at step 140600: 0.063132\n",
      "2023-12-02 23:17:08,865 INFO     Training average positive_sample_loss at step 140700: 0.062383\n",
      "2023-12-02 23:17:08,866 INFO     Training average negative_sample_loss at step 140700: 0.063265\n",
      "2023-12-02 23:17:08,866 INFO     Training average loss at step 140700: 0.062824\n",
      "2023-12-02 23:17:20,106 INFO     Training average positive_sample_loss at step 140800: 0.061876\n",
      "2023-12-02 23:17:20,107 INFO     Training average negative_sample_loss at step 140800: 0.063465\n",
      "2023-12-02 23:17:20,107 INFO     Training average loss at step 140800: 0.062670\n",
      "2023-12-02 23:17:32,043 INFO     Training average positive_sample_loss at step 140900: 0.062606\n",
      "2023-12-02 23:17:32,043 INFO     Training average negative_sample_loss at step 140900: 0.063120\n",
      "2023-12-02 23:17:32,043 INFO     Training average loss at step 140900: 0.062863\n",
      "2023-12-02 23:17:43,963 INFO     Training average positive_sample_loss at step 141000: 0.062411\n",
      "2023-12-02 23:17:43,963 INFO     Training average negative_sample_loss at step 141000: 0.063118\n",
      "2023-12-02 23:17:43,963 INFO     Training average loss at step 141000: 0.062765\n",
      "2023-12-02 23:17:55,161 INFO     Training average positive_sample_loss at step 141100: 0.063244\n",
      "2023-12-02 23:17:55,161 INFO     Training average negative_sample_loss at step 141100: 0.063618\n",
      "2023-12-02 23:17:55,162 INFO     Training average loss at step 141100: 0.063431\n",
      "2023-12-02 23:18:07,174 INFO     Training average positive_sample_loss at step 141200: 0.063162\n",
      "2023-12-02 23:18:07,174 INFO     Training average negative_sample_loss at step 141200: 0.063052\n",
      "2023-12-02 23:18:07,174 INFO     Training average loss at step 141200: 0.063107\n",
      "2023-12-02 23:18:19,068 INFO     Training average positive_sample_loss at step 141300: 0.063153\n",
      "2023-12-02 23:18:19,068 INFO     Training average negative_sample_loss at step 141300: 0.063494\n",
      "2023-12-02 23:18:19,068 INFO     Training average loss at step 141300: 0.063323\n",
      "2023-12-02 23:18:30,970 INFO     Training average positive_sample_loss at step 141400: 0.063201\n",
      "2023-12-02 23:18:30,970 INFO     Training average negative_sample_loss at step 141400: 0.063415\n",
      "2023-12-02 23:18:30,970 INFO     Training average loss at step 141400: 0.063308\n",
      "2023-12-02 23:18:42,121 INFO     Training average positive_sample_loss at step 141500: 0.063395\n",
      "2023-12-02 23:18:42,122 INFO     Training average negative_sample_loss at step 141500: 0.063514\n",
      "2023-12-02 23:18:42,122 INFO     Training average loss at step 141500: 0.063455\n",
      "2023-12-02 23:18:54,413 INFO     Training average positive_sample_loss at step 141600: 0.063470\n",
      "2023-12-02 23:18:54,414 INFO     Training average negative_sample_loss at step 141600: 0.063677\n",
      "2023-12-02 23:18:54,414 INFO     Training average loss at step 141600: 0.063574\n",
      "2023-12-02 23:19:06,915 INFO     Training average positive_sample_loss at step 141700: 0.062110\n",
      "2023-12-02 23:19:06,915 INFO     Training average negative_sample_loss at step 141700: 0.063817\n",
      "2023-12-02 23:19:06,915 INFO     Training average loss at step 141700: 0.062964\n",
      "2023-12-02 23:19:18,298 INFO     Training average positive_sample_loss at step 141800: 0.062445\n",
      "2023-12-02 23:19:18,298 INFO     Training average negative_sample_loss at step 141800: 0.063148\n",
      "2023-12-02 23:19:18,298 INFO     Training average loss at step 141800: 0.062796\n",
      "2023-12-02 23:19:30,015 INFO     Training average positive_sample_loss at step 141900: 0.062788\n",
      "2023-12-02 23:19:30,015 INFO     Training average negative_sample_loss at step 141900: 0.062961\n",
      "2023-12-02 23:19:30,015 INFO     Training average loss at step 141900: 0.062875\n",
      "2023-12-02 23:19:41,953 INFO     Training average positive_sample_loss at step 142000: 0.062559\n",
      "2023-12-02 23:19:41,954 INFO     Training average negative_sample_loss at step 142000: 0.062926\n",
      "2023-12-02 23:19:41,954 INFO     Training average loss at step 142000: 0.062743\n",
      "2023-12-02 23:19:53,802 INFO     Training average positive_sample_loss at step 142100: 0.062764\n",
      "2023-12-02 23:19:53,803 INFO     Training average negative_sample_loss at step 142100: 0.063330\n",
      "2023-12-02 23:19:53,803 INFO     Training average loss at step 142100: 0.063047\n",
      "2023-12-02 23:20:05,043 INFO     Training average positive_sample_loss at step 142200: 0.063590\n",
      "2023-12-02 23:20:05,043 INFO     Training average negative_sample_loss at step 142200: 0.063968\n",
      "2023-12-02 23:20:05,043 INFO     Training average loss at step 142200: 0.063779\n",
      "2023-12-02 23:20:16,936 INFO     Training average positive_sample_loss at step 142300: 0.063380\n",
      "2023-12-02 23:20:16,936 INFO     Training average negative_sample_loss at step 142300: 0.064032\n",
      "2023-12-02 23:20:16,936 INFO     Training average loss at step 142300: 0.063706\n",
      "2023-12-02 23:20:28,763 INFO     Training average positive_sample_loss at step 142400: 0.063046\n",
      "2023-12-02 23:20:28,763 INFO     Training average negative_sample_loss at step 142400: 0.063830\n",
      "2023-12-02 23:20:28,763 INFO     Training average loss at step 142400: 0.063438\n",
      "2023-12-02 23:20:40,570 INFO     Training average positive_sample_loss at step 142500: 0.063262\n",
      "2023-12-02 23:20:40,571 INFO     Training average negative_sample_loss at step 142500: 0.062804\n",
      "2023-12-02 23:20:40,571 INFO     Training average loss at step 142500: 0.063033\n",
      "2023-12-02 23:20:52,659 INFO     Training average positive_sample_loss at step 142600: 0.062460\n",
      "2023-12-02 23:20:52,660 INFO     Training average negative_sample_loss at step 142600: 0.063561\n",
      "2023-12-02 23:20:52,660 INFO     Training average loss at step 142600: 0.063011\n",
      "2023-12-02 23:21:04,526 INFO     Training average positive_sample_loss at step 142700: 0.061949\n",
      "2023-12-02 23:21:04,527 INFO     Training average negative_sample_loss at step 142700: 0.061990\n",
      "2023-12-02 23:21:04,527 INFO     Training average loss at step 142700: 0.061970\n",
      "2023-12-02 23:21:16,365 INFO     Training average positive_sample_loss at step 142800: 0.062339\n",
      "2023-12-02 23:21:16,365 INFO     Training average negative_sample_loss at step 142800: 0.063154\n",
      "2023-12-02 23:21:16,365 INFO     Training average loss at step 142800: 0.062747\n",
      "2023-12-02 23:21:27,502 INFO     Training average positive_sample_loss at step 142900: 0.062547\n",
      "2023-12-02 23:21:27,503 INFO     Training average negative_sample_loss at step 142900: 0.062658\n",
      "2023-12-02 23:21:27,503 INFO     Training average loss at step 142900: 0.062603\n",
      "2023-12-02 23:21:39,397 INFO     Training average positive_sample_loss at step 143000: 0.062993\n",
      "2023-12-02 23:21:39,397 INFO     Training average negative_sample_loss at step 143000: 0.063762\n",
      "2023-12-02 23:21:39,397 INFO     Training average loss at step 143000: 0.063377\n",
      "2023-12-02 23:21:51,361 INFO     Training average positive_sample_loss at step 143100: 0.062696\n",
      "2023-12-02 23:21:51,361 INFO     Training average negative_sample_loss at step 143100: 0.062823\n",
      "2023-12-02 23:21:51,361 INFO     Training average loss at step 143100: 0.062759\n",
      "2023-12-02 23:22:03,371 INFO     Training average positive_sample_loss at step 143200: 0.063053\n",
      "2023-12-02 23:22:03,371 INFO     Training average negative_sample_loss at step 143200: 0.062950\n",
      "2023-12-02 23:22:03,371 INFO     Training average loss at step 143200: 0.063002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 23:22:14,475 INFO     Training average positive_sample_loss at step 143300: 0.063272\n",
      "2023-12-02 23:22:14,475 INFO     Training average negative_sample_loss at step 143300: 0.062891\n",
      "2023-12-02 23:22:14,475 INFO     Training average loss at step 143300: 0.063081\n",
      "2023-12-02 23:22:26,248 INFO     Training average positive_sample_loss at step 143400: 0.063398\n",
      "2023-12-02 23:22:26,248 INFO     Training average negative_sample_loss at step 143400: 0.063094\n",
      "2023-12-02 23:22:26,248 INFO     Training average loss at step 143400: 0.063246\n",
      "2023-12-02 23:22:38,918 INFO     Training average positive_sample_loss at step 143500: 0.063337\n",
      "2023-12-02 23:22:38,918 INFO     Training average negative_sample_loss at step 143500: 0.064073\n",
      "2023-12-02 23:22:38,918 INFO     Training average loss at step 143500: 0.063705\n",
      "2023-12-02 23:22:50,051 INFO     Training average positive_sample_loss at step 143600: 0.061893\n",
      "2023-12-02 23:22:50,051 INFO     Training average negative_sample_loss at step 143600: 0.062824\n",
      "2023-12-02 23:22:50,051 INFO     Training average loss at step 143600: 0.062358\n",
      "2023-12-02 23:23:01,971 INFO     Training average positive_sample_loss at step 143700: 0.062058\n",
      "2023-12-02 23:23:01,972 INFO     Training average negative_sample_loss at step 143700: 0.063702\n",
      "2023-12-02 23:23:01,972 INFO     Training average loss at step 143700: 0.062880\n",
      "2023-12-02 23:23:13,813 INFO     Training average positive_sample_loss at step 143800: 0.062639\n",
      "2023-12-02 23:23:13,813 INFO     Training average negative_sample_loss at step 143800: 0.063548\n",
      "2023-12-02 23:23:13,813 INFO     Training average loss at step 143800: 0.063093\n",
      "2023-12-02 23:23:25,603 INFO     Training average positive_sample_loss at step 143900: 0.062747\n",
      "2023-12-02 23:23:25,603 INFO     Training average negative_sample_loss at step 143900: 0.063039\n",
      "2023-12-02 23:23:25,603 INFO     Training average loss at step 143900: 0.062893\n",
      "2023-12-02 23:23:36,690 INFO     Training average positive_sample_loss at step 144000: 0.063243\n",
      "2023-12-02 23:23:36,690 INFO     Training average negative_sample_loss at step 144000: 0.063472\n",
      "2023-12-02 23:23:36,690 INFO     Training average loss at step 144000: 0.063358\n",
      "2023-12-02 23:23:48,563 INFO     Training average positive_sample_loss at step 144100: 0.063117\n",
      "2023-12-02 23:23:48,563 INFO     Training average negative_sample_loss at step 144100: 0.063445\n",
      "2023-12-02 23:23:48,563 INFO     Training average loss at step 144100: 0.063281\n",
      "2023-12-02 23:24:00,527 INFO     Training average positive_sample_loss at step 144200: 0.063361\n",
      "2023-12-02 23:24:00,527 INFO     Training average negative_sample_loss at step 144200: 0.062614\n",
      "2023-12-02 23:24:00,527 INFO     Training average loss at step 144200: 0.062988\n",
      "2023-12-02 23:24:12,438 INFO     Training average positive_sample_loss at step 144300: 0.063432\n",
      "2023-12-02 23:24:12,438 INFO     Training average negative_sample_loss at step 144300: 0.064257\n",
      "2023-12-02 23:24:12,438 INFO     Training average loss at step 144300: 0.063845\n",
      "2023-12-02 23:24:23,765 INFO     Training average positive_sample_loss at step 144400: 0.063708\n",
      "2023-12-02 23:24:23,765 INFO     Training average negative_sample_loss at step 144400: 0.063364\n",
      "2023-12-02 23:24:23,765 INFO     Training average loss at step 144400: 0.063536\n",
      "2023-12-02 23:24:36,628 INFO     Training average positive_sample_loss at step 144500: 0.061850\n",
      "2023-12-02 23:24:36,629 INFO     Training average negative_sample_loss at step 144500: 0.063240\n",
      "2023-12-02 23:24:36,629 INFO     Training average loss at step 144500: 0.062545\n",
      "2023-12-02 23:24:48,574 INFO     Training average positive_sample_loss at step 144600: 0.062092\n",
      "2023-12-02 23:24:48,574 INFO     Training average negative_sample_loss at step 144600: 0.063643\n",
      "2023-12-02 23:24:48,574 INFO     Training average loss at step 144600: 0.062867\n",
      "2023-12-02 23:24:59,775 INFO     Training average positive_sample_loss at step 144700: 0.062486\n",
      "2023-12-02 23:24:59,775 INFO     Training average negative_sample_loss at step 144700: 0.062875\n",
      "2023-12-02 23:24:59,776 INFO     Training average loss at step 144700: 0.062680\n",
      "2023-12-02 23:25:11,836 INFO     Training average positive_sample_loss at step 144800: 0.062827\n",
      "2023-12-02 23:25:11,836 INFO     Training average negative_sample_loss at step 144800: 0.062861\n",
      "2023-12-02 23:25:11,836 INFO     Training average loss at step 144800: 0.062844\n",
      "2023-12-02 23:25:23,821 INFO     Training average positive_sample_loss at step 144900: 0.062803\n",
      "2023-12-02 23:25:23,822 INFO     Training average negative_sample_loss at step 144900: 0.063097\n",
      "2023-12-02 23:25:23,822 INFO     Training average loss at step 144900: 0.062950\n",
      "2023-12-02 23:25:35,809 INFO     Training average positive_sample_loss at step 145000: 0.062951\n",
      "2023-12-02 23:25:35,809 INFO     Training average negative_sample_loss at step 145000: 0.063042\n",
      "2023-12-02 23:25:35,809 INFO     Training average loss at step 145000: 0.062997\n",
      "2023-12-02 23:25:46,991 INFO     Training average positive_sample_loss at step 145100: 0.063125\n",
      "2023-12-02 23:25:46,991 INFO     Training average negative_sample_loss at step 145100: 0.062611\n",
      "2023-12-02 23:25:46,991 INFO     Training average loss at step 145100: 0.062868\n",
      "2023-12-02 23:25:58,906 INFO     Training average positive_sample_loss at step 145200: 0.063380\n",
      "2023-12-02 23:25:58,906 INFO     Training average negative_sample_loss at step 145200: 0.063337\n",
      "2023-12-02 23:25:58,906 INFO     Training average loss at step 145200: 0.063358\n",
      "2023-12-02 23:26:10,831 INFO     Training average positive_sample_loss at step 145300: 0.063419\n",
      "2023-12-02 23:26:10,832 INFO     Training average negative_sample_loss at step 145300: 0.064076\n",
      "2023-12-02 23:26:10,832 INFO     Training average loss at step 145300: 0.063748\n",
      "2023-12-02 23:26:22,803 INFO     Training average positive_sample_loss at step 145400: 0.063083\n",
      "2023-12-02 23:26:22,803 INFO     Training average negative_sample_loss at step 145400: 0.063016\n",
      "2023-12-02 23:26:22,803 INFO     Training average loss at step 145400: 0.063049\n",
      "2023-12-02 23:26:34,691 INFO     Training average positive_sample_loss at step 145500: 0.062021\n",
      "2023-12-02 23:26:34,692 INFO     Training average negative_sample_loss at step 145500: 0.063691\n",
      "2023-12-02 23:26:34,692 INFO     Training average loss at step 145500: 0.062856\n",
      "2023-12-02 23:26:46,641 INFO     Training average positive_sample_loss at step 145600: 0.062071\n",
      "2023-12-02 23:26:46,641 INFO     Training average negative_sample_loss at step 145600: 0.062207\n",
      "2023-12-02 23:26:46,641 INFO     Training average loss at step 145600: 0.062139\n",
      "2023-12-02 23:26:58,697 INFO     Training average positive_sample_loss at step 145700: 0.062449\n",
      "2023-12-02 23:26:58,697 INFO     Training average negative_sample_loss at step 145700: 0.063044\n",
      "2023-12-02 23:26:58,697 INFO     Training average loss at step 145700: 0.062746\n",
      "2023-12-02 23:27:09,872 INFO     Training average positive_sample_loss at step 145800: 0.062530\n",
      "2023-12-02 23:27:09,872 INFO     Training average negative_sample_loss at step 145800: 0.063586\n",
      "2023-12-02 23:27:09,872 INFO     Training average loss at step 145800: 0.063058\n",
      "2023-12-02 23:27:21,680 INFO     Training average positive_sample_loss at step 145900: 0.062851\n",
      "2023-12-02 23:27:21,680 INFO     Training average negative_sample_loss at step 145900: 0.062497\n",
      "2023-12-02 23:27:21,681 INFO     Training average loss at step 145900: 0.062674\n",
      "2023-12-02 23:27:33,500 INFO     Training average positive_sample_loss at step 146000: 0.062880\n",
      "2023-12-02 23:27:33,500 INFO     Training average negative_sample_loss at step 146000: 0.063236\n",
      "2023-12-02 23:27:33,500 INFO     Training average loss at step 146000: 0.063058\n",
      "2023-12-02 23:27:44,668 INFO     Training average positive_sample_loss at step 146100: 0.063438\n",
      "2023-12-02 23:27:44,668 INFO     Training average negative_sample_loss at step 146100: 0.062786\n",
      "2023-12-02 23:27:44,668 INFO     Training average loss at step 146100: 0.063112\n",
      "2023-12-02 23:27:56,603 INFO     Training average positive_sample_loss at step 146200: 0.063022\n",
      "2023-12-02 23:27:56,604 INFO     Training average negative_sample_loss at step 146200: 0.063354\n",
      "2023-12-02 23:27:56,604 INFO     Training average loss at step 146200: 0.063188\n",
      "2023-12-02 23:28:08,550 INFO     Training average positive_sample_loss at step 146300: 0.063367\n",
      "2023-12-02 23:28:08,550 INFO     Training average negative_sample_loss at step 146300: 0.063792\n",
      "2023-12-02 23:28:08,550 INFO     Training average loss at step 146300: 0.063579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 23:28:21,085 INFO     Training average positive_sample_loss at step 146400: 0.062006\n",
      "2023-12-02 23:28:21,085 INFO     Training average negative_sample_loss at step 146400: 0.063257\n",
      "2023-12-02 23:28:21,085 INFO     Training average loss at step 146400: 0.062632\n",
      "2023-12-02 23:28:32,331 INFO     Training average positive_sample_loss at step 146500: 0.062079\n",
      "2023-12-02 23:28:32,332 INFO     Training average negative_sample_loss at step 146500: 0.063026\n",
      "2023-12-02 23:28:32,332 INFO     Training average loss at step 146500: 0.062553\n",
      "2023-12-02 23:28:44,289 INFO     Training average positive_sample_loss at step 146600: 0.062511\n",
      "2023-12-02 23:28:44,290 INFO     Training average negative_sample_loss at step 146600: 0.063415\n",
      "2023-12-02 23:28:44,290 INFO     Training average loss at step 146600: 0.062963\n",
      "2023-12-02 23:28:56,149 INFO     Training average positive_sample_loss at step 146700: 0.062685\n",
      "2023-12-02 23:28:56,149 INFO     Training average negative_sample_loss at step 146700: 0.062934\n",
      "2023-12-02 23:28:56,149 INFO     Training average loss at step 146700: 0.062810\n",
      "2023-12-02 23:29:07,336 INFO     Training average positive_sample_loss at step 146800: 0.062998\n",
      "2023-12-02 23:29:07,336 INFO     Training average negative_sample_loss at step 146800: 0.064196\n",
      "2023-12-02 23:29:07,336 INFO     Training average loss at step 146800: 0.063597\n",
      "2023-12-02 23:29:19,224 INFO     Training average positive_sample_loss at step 146900: 0.063399\n",
      "2023-12-02 23:29:19,224 INFO     Training average negative_sample_loss at step 146900: 0.062761\n",
      "2023-12-02 23:29:19,224 INFO     Training average loss at step 146900: 0.063080\n",
      "2023-12-02 23:29:31,104 INFO     Training average positive_sample_loss at step 147000: 0.063310\n",
      "2023-12-02 23:29:31,105 INFO     Training average negative_sample_loss at step 147000: 0.063704\n",
      "2023-12-02 23:29:31,105 INFO     Training average loss at step 147000: 0.063507\n",
      "2023-12-02 23:29:42,982 INFO     Training average positive_sample_loss at step 147100: 0.063381\n",
      "2023-12-02 23:29:42,982 INFO     Training average negative_sample_loss at step 147100: 0.064025\n",
      "2023-12-02 23:29:42,982 INFO     Training average loss at step 147100: 0.063703\n",
      "2023-12-02 23:29:52,866 INFO     Training average positive_sample_loss at step 147200: 0.063140\n",
      "2023-12-02 23:29:52,867 INFO     Training average negative_sample_loss at step 147200: 0.062766\n",
      "2023-12-02 23:29:52,867 INFO     Training average loss at step 147200: 0.062953\n",
      "2023-12-02 23:30:00,189 INFO     Training average positive_sample_loss at step 147300: 0.062821\n",
      "2023-12-02 23:30:00,190 INFO     Training average negative_sample_loss at step 147300: 0.064535\n",
      "2023-12-02 23:30:00,190 INFO     Training average loss at step 147300: 0.063678\n",
      "2023-12-02 23:30:11,571 INFO     Training average positive_sample_loss at step 147400: 0.062078\n",
      "2023-12-02 23:30:11,572 INFO     Training average negative_sample_loss at step 147400: 0.062387\n",
      "2023-12-02 23:30:11,572 INFO     Training average loss at step 147400: 0.062232\n",
      "2023-12-02 23:30:19,898 INFO     Training average positive_sample_loss at step 147500: 0.062698\n",
      "2023-12-02 23:30:19,898 INFO     Training average negative_sample_loss at step 147500: 0.063057\n",
      "2023-12-02 23:30:19,898 INFO     Training average loss at step 147500: 0.062877\n",
      "2023-12-02 23:30:28,647 INFO     Training average positive_sample_loss at step 147600: 0.062702\n",
      "2023-12-02 23:30:28,648 INFO     Training average negative_sample_loss at step 147600: 0.064039\n",
      "2023-12-02 23:30:28,648 INFO     Training average loss at step 147600: 0.063370\n",
      "2023-12-02 23:30:37,464 INFO     Training average positive_sample_loss at step 147700: 0.062769\n",
      "2023-12-02 23:30:37,465 INFO     Training average negative_sample_loss at step 147700: 0.063203\n",
      "2023-12-02 23:30:37,465 INFO     Training average loss at step 147700: 0.062986\n",
      "2023-12-02 23:30:49,069 INFO     Training average positive_sample_loss at step 147800: 0.063048\n",
      "2023-12-02 23:30:49,069 INFO     Training average negative_sample_loss at step 147800: 0.063126\n",
      "2023-12-02 23:30:49,069 INFO     Training average loss at step 147800: 0.063087\n",
      "2023-12-02 23:31:01,031 INFO     Training average positive_sample_loss at step 147900: 0.063292\n",
      "2023-12-02 23:31:01,032 INFO     Training average negative_sample_loss at step 147900: 0.062882\n",
      "2023-12-02 23:31:01,032 INFO     Training average loss at step 147900: 0.063087\n",
      "2023-12-02 23:31:12,960 INFO     Training average positive_sample_loss at step 148000: 0.063368\n",
      "2023-12-02 23:31:12,960 INFO     Training average negative_sample_loss at step 148000: 0.062809\n",
      "2023-12-02 23:31:12,960 INFO     Training average loss at step 148000: 0.063088\n",
      "2023-12-02 23:31:23,991 INFO     Training average positive_sample_loss at step 148100: 0.063416\n",
      "2023-12-02 23:31:23,991 INFO     Training average negative_sample_loss at step 148100: 0.063833\n",
      "2023-12-02 23:31:23,991 INFO     Training average loss at step 148100: 0.063625\n",
      "2023-12-02 23:31:35,971 INFO     Training average positive_sample_loss at step 148200: 0.063077\n",
      "2023-12-02 23:31:35,971 INFO     Training average negative_sample_loss at step 148200: 0.062992\n",
      "2023-12-02 23:31:35,971 INFO     Training average loss at step 148200: 0.063034\n",
      "2023-12-02 23:31:48,688 INFO     Training average positive_sample_loss at step 148300: 0.061527\n",
      "2023-12-02 23:31:48,689 INFO     Training average negative_sample_loss at step 148300: 0.062973\n",
      "2023-12-02 23:31:48,689 INFO     Training average loss at step 148300: 0.062250\n",
      "2023-12-02 23:31:59,805 INFO     Training average positive_sample_loss at step 148400: 0.062119\n",
      "2023-12-02 23:31:59,806 INFO     Training average negative_sample_loss at step 148400: 0.063376\n",
      "2023-12-02 23:31:59,806 INFO     Training average loss at step 148400: 0.062747\n",
      "2023-12-02 23:32:11,679 INFO     Training average positive_sample_loss at step 148500: 0.062682\n",
      "2023-12-02 23:32:11,679 INFO     Training average negative_sample_loss at step 148500: 0.064108\n",
      "2023-12-02 23:32:11,680 INFO     Training average loss at step 148500: 0.063395\n",
      "2023-12-02 23:32:23,588 INFO     Training average positive_sample_loss at step 148600: 0.062904\n",
      "2023-12-02 23:32:23,588 INFO     Training average negative_sample_loss at step 148600: 0.062287\n",
      "2023-12-02 23:32:23,588 INFO     Training average loss at step 148600: 0.062596\n",
      "2023-12-02 23:32:35,463 INFO     Training average positive_sample_loss at step 148700: 0.062891\n",
      "2023-12-02 23:32:35,463 INFO     Training average negative_sample_loss at step 148700: 0.063466\n",
      "2023-12-02 23:32:35,463 INFO     Training average loss at step 148700: 0.063179\n",
      "2023-12-02 23:32:46,611 INFO     Training average positive_sample_loss at step 148800: 0.062938\n",
      "2023-12-02 23:32:46,611 INFO     Training average negative_sample_loss at step 148800: 0.062695\n",
      "2023-12-02 23:32:46,611 INFO     Training average loss at step 148800: 0.062816\n",
      "2023-12-02 23:32:58,547 INFO     Training average positive_sample_loss at step 148900: 0.063193\n",
      "2023-12-02 23:32:58,547 INFO     Training average negative_sample_loss at step 148900: 0.063005\n",
      "2023-12-02 23:32:58,547 INFO     Training average loss at step 148900: 0.063099\n",
      "2023-12-02 23:33:10,386 INFO     Training average positive_sample_loss at step 149000: 0.063403\n",
      "2023-12-02 23:33:10,386 INFO     Training average negative_sample_loss at step 149000: 0.064390\n",
      "2023-12-02 23:33:10,386 INFO     Training average loss at step 149000: 0.063896\n",
      "2023-12-02 23:33:22,254 INFO     Training average positive_sample_loss at step 149100: 0.063857\n",
      "2023-12-02 23:33:22,254 INFO     Training average negative_sample_loss at step 149100: 0.063221\n",
      "2023-12-02 23:33:22,254 INFO     Training average loss at step 149100: 0.063539\n",
      "2023-12-02 23:33:34,360 INFO     Training average positive_sample_loss at step 149200: 0.062523\n",
      "2023-12-02 23:33:34,361 INFO     Training average negative_sample_loss at step 149200: 0.062429\n",
      "2023-12-02 23:33:34,361 INFO     Training average loss at step 149200: 0.062476\n",
      "2023-12-02 23:33:46,263 INFO     Training average positive_sample_loss at step 149300: 0.061507\n",
      "2023-12-02 23:33:46,264 INFO     Training average negative_sample_loss at step 149300: 0.063253\n",
      "2023-12-02 23:33:46,264 INFO     Training average loss at step 149300: 0.062380\n",
      "2023-12-02 23:33:58,178 INFO     Training average positive_sample_loss at step 149400: 0.061923\n",
      "2023-12-02 23:33:58,179 INFO     Training average negative_sample_loss at step 149400: 0.062689\n",
      "2023-12-02 23:33:58,179 INFO     Training average loss at step 149400: 0.062306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-02 23:34:09,296 INFO     Training average positive_sample_loss at step 149500: 0.062854\n",
      "2023-12-02 23:34:09,296 INFO     Training average negative_sample_loss at step 149500: 0.063721\n",
      "2023-12-02 23:34:09,296 INFO     Training average loss at step 149500: 0.063288\n",
      "2023-12-02 23:34:21,126 INFO     Training average positive_sample_loss at step 149600: 0.062709\n",
      "2023-12-02 23:34:21,126 INFO     Training average negative_sample_loss at step 149600: 0.062700\n",
      "2023-12-02 23:34:21,126 INFO     Training average loss at step 149600: 0.062705\n",
      "2023-12-02 23:34:32,962 INFO     Training average positive_sample_loss at step 149700: 0.062905\n",
      "2023-12-02 23:34:32,963 INFO     Training average negative_sample_loss at step 149700: 0.063010\n",
      "2023-12-02 23:34:32,963 INFO     Training average loss at step 149700: 0.062958\n",
      "2023-12-02 23:34:44,767 INFO     Training average positive_sample_loss at step 149800: 0.063302\n",
      "2023-12-02 23:34:44,768 INFO     Training average negative_sample_loss at step 149800: 0.063957\n",
      "2023-12-02 23:34:44,768 INFO     Training average loss at step 149800: 0.063630\n",
      "2023-12-02 23:34:55,830 INFO     Training average positive_sample_loss at step 149900: 0.063291\n",
      "2023-12-02 23:34:55,830 INFO     Training average negative_sample_loss at step 149900: 0.063274\n",
      "2023-12-02 23:34:55,830 INFO     Training average loss at step 149900: 0.063283\n",
      "2023-12-02 23:35:19,443 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-02 23:35:20,903 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-02 23:36:43,747 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-02 23:38:06,974 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-02 23:39:29,286 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-02 23:40:52,728 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-02 23:42:16,784 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-02 23:43:41,085 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-02 23:44:02,036 INFO     Valid MRR at step 149999: 0.790691\n",
      "2023-12-02 23:44:02,036 INFO     Valid MR at step 149999: 41.025380\n",
      "2023-12-02 23:44:02,036 INFO     Valid HITS@1 at step 149999: 0.738450\n",
      "2023-12-02 23:44:02,036 INFO     Valid HITS@3 at step 149999: 0.823990\n",
      "2023-12-02 23:44:02,036 INFO     Valid HITS@10 at step 149999: 0.880540\n",
      "2023-12-02 23:44:02,036 INFO     Evaluating on Test Dataset...\n",
      "2023-12-02 23:44:02,742 INFO     Evaluating the model... (0/7384)\n",
      "2023-12-02 23:45:25,854 INFO     Evaluating the model... (1000/7384)\n",
      "2023-12-02 23:46:45,222 INFO     Evaluating the model... (2000/7384)\n",
      "2023-12-02 23:47:33,074 INFO     Evaluating the model... (3000/7384)\n",
      "2023-12-02 23:48:57,503 INFO     Evaluating the model... (4000/7384)\n",
      "2023-12-02 23:50:20,838 INFO     Evaluating the model... (5000/7384)\n",
      "2023-12-02 23:51:44,611 INFO     Evaluating the model... (6000/7384)\n",
      "2023-12-02 23:53:07,295 INFO     Evaluating the model... (7000/7384)\n",
      "2023-12-02 23:53:39,166 INFO     Test MRR at step 149999: 0.790539\n",
      "2023-12-02 23:53:39,166 INFO     Test MR at step 149999: 41.827335\n",
      "2023-12-02 23:53:39,166 INFO     Test HITS@1 at step 149999: 0.737536\n",
      "2023-12-02 23:53:39,167 INFO     Test HITS@3 at step 149999: 0.825151\n",
      "2023-12-02 23:53:39,167 INFO     Test HITS@10 at step 149999: 0.880855\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE FB15k 0 0 1024 256 1000 24.0 1.0 0.0001 150000 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione: 425 minuti e 17 secondi\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "minutes, seconds = divmod(execution_time, 60)\n",
    "print(f\"Tempo di esecuzione: {int(minutes)} minuti e {int(seconds)} secondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento del modello RotatE con la Variante NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding_old\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding_variant_NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-09 18:41:28,989 INFO     Model: RotatE\n",
      "2023-12-09 18:41:28,991 INFO     Data Path: data/FB15k\n",
      "2023-12-09 18:41:28,991 INFO     #entity: 14951\n",
      "2023-12-09 18:41:28,991 INFO     #relation: 1345\n",
      "2023-12-09 18:41:29,475 INFO     #train: 483142\n",
      "2023-12-09 18:41:29,563 INFO     #valid: 50000\n",
      "2023-12-09 18:41:29,671 INFO     #test: 59071\n",
      "2023-12-09 18:41:29,849 INFO     Model Parameter Configuration:\n",
      "2023-12-09 18:41:29,850 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-09 18:41:29,850 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-09 18:41:29,850 INFO     Parameter entity_embedding: torch.Size([14951, 2000]), require_grad = True\n",
      "2023-12-09 18:41:29,850 INFO     Parameter relation_embedding: torch.Size([1345, 1000]), require_grad = True\n",
      "2023-12-09 18:41:35,519 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-09 18:41:35,520 INFO     Start Training...\n",
      "2023-12-09 18:41:35,520 INFO     init_step = 0\n",
      "2023-12-09 18:41:35,520 INFO     batch_size = 1024\n",
      "2023-12-09 18:41:35,520 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-09 18:41:35,520 INFO     hidden_dim = 1000\n",
      "2023-12-09 18:41:35,520 INFO     gamma = 24.000000\n",
      "2023-12-09 18:41:35,520 INFO     negative_adversarial_sampling = True\n",
      "2023-12-09 18:41:35,520 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-09 18:41:35,520 INFO     learning_rate = 0\n",
      "2023-12-09 18:42:09,576 INFO     Training average positive_sample_loss at step 0: 3.152054\n",
      "2023-12-09 18:42:09,577 INFO     Training average negative_sample_loss at step 0: 0.053533\n",
      "2023-12-09 18:42:09,577 INFO     Training average loss at step 0: 1.602794\n",
      "2023-12-09 18:42:09,577 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 18:42:10,543 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-09 18:44:56,222 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-09 18:47:42,381 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-09 18:50:19,894 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-09 18:53:05,494 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-09 18:55:47,141 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-09 18:58:30,131 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-09 18:59:15,215 INFO     Valid MRR at step 0: 0.003453\n",
      "2023-12-09 18:59:15,215 INFO     Valid MR at step 0: 7120.328800\n",
      "2023-12-09 18:59:15,215 INFO     Valid HITS@1 at step 0: 0.002460\n",
      "2023-12-09 18:59:15,215 INFO     Valid HITS@3 at step 0: 0.003080\n",
      "2023-12-09 18:59:15,215 INFO     Valid HITS@10 at step 0: 0.003920\n",
      "2023-12-09 19:00:33,515 INFO     Training average positive_sample_loss at step 100: 2.307718\n",
      "2023-12-09 19:00:33,515 INFO     Training average negative_sample_loss at step 100: 0.275458\n",
      "2023-12-09 19:00:33,515 INFO     Training average loss at step 100: 1.291588\n",
      "2023-12-09 19:01:48,841 INFO     Training average positive_sample_loss at step 200: 1.078137\n",
      "2023-12-09 19:01:48,841 INFO     Training average negative_sample_loss at step 200: 0.584352\n",
      "2023-12-09 19:01:48,841 INFO     Training average loss at step 200: 0.831244\n",
      "2023-12-09 19:03:07,022 INFO     Training average positive_sample_loss at step 300: 0.817427\n",
      "2023-12-09 19:03:07,022 INFO     Training average negative_sample_loss at step 300: 0.659135\n",
      "2023-12-09 19:03:07,022 INFO     Training average loss at step 300: 0.738281\n",
      "2023-12-09 19:04:25,385 INFO     Training average positive_sample_loss at step 400: 0.734044\n",
      "2023-12-09 19:04:25,385 INFO     Training average negative_sample_loss at step 400: 0.668941\n",
      "2023-12-09 19:04:25,385 INFO     Training average loss at step 400: 0.701493\n",
      "2023-12-09 19:05:43,366 INFO     Training average positive_sample_loss at step 500: 0.697509\n",
      "2023-12-09 19:05:43,366 INFO     Training average negative_sample_loss at step 500: 0.659490\n",
      "2023-12-09 19:05:43,366 INFO     Training average loss at step 500: 0.678500\n",
      "2023-12-09 19:06:59,906 INFO     Training average positive_sample_loss at step 600: 0.670549\n",
      "2023-12-09 19:06:59,906 INFO     Training average negative_sample_loss at step 600: 0.643500\n",
      "2023-12-09 19:06:59,906 INFO     Training average loss at step 600: 0.657024\n",
      "2023-12-09 19:08:14,412 INFO     Training average positive_sample_loss at step 700: 0.643592\n",
      "2023-12-09 19:08:14,412 INFO     Training average negative_sample_loss at step 700: 0.621875\n",
      "2023-12-09 19:08:14,414 INFO     Training average loss at step 700: 0.632734\n",
      "2023-12-09 19:09:28,844 INFO     Training average positive_sample_loss at step 800: 0.619329\n",
      "2023-12-09 19:09:28,845 INFO     Training average negative_sample_loss at step 800: 0.598120\n",
      "2023-12-09 19:09:28,845 INFO     Training average loss at step 800: 0.608725\n",
      "2023-12-09 19:10:43,782 INFO     Training average positive_sample_loss at step 900: 0.590270\n",
      "2023-12-09 19:10:43,782 INFO     Training average negative_sample_loss at step 900: 0.572318\n",
      "2023-12-09 19:10:43,782 INFO     Training average loss at step 900: 0.581294\n",
      "2023-12-09 19:12:12,828 INFO     Training average positive_sample_loss at step 1000: 0.518412\n",
      "2023-12-09 19:12:12,829 INFO     Training average negative_sample_loss at step 1000: 0.524024\n",
      "2023-12-09 19:12:12,829 INFO     Training average loss at step 1000: 0.521218\n",
      "2023-12-09 19:13:29,997 INFO     Training average positive_sample_loss at step 1100: 0.489894\n",
      "2023-12-09 19:13:29,997 INFO     Training average negative_sample_loss at step 1100: 0.462830\n",
      "2023-12-09 19:13:29,997 INFO     Training average loss at step 1100: 0.476362\n",
      "2023-12-09 19:14:47,180 INFO     Training average positive_sample_loss at step 1200: 0.478395\n",
      "2023-12-09 19:14:47,180 INFO     Training average negative_sample_loss at step 1200: 0.444757\n",
      "2023-12-09 19:14:47,180 INFO     Training average loss at step 1200: 0.461576\n",
      "2023-12-09 19:16:04,474 INFO     Training average positive_sample_loss at step 1300: 0.461346\n",
      "2023-12-09 19:16:04,474 INFO     Training average negative_sample_loss at step 1300: 0.427539\n",
      "2023-12-09 19:16:04,474 INFO     Training average loss at step 1300: 0.444442\n",
      "2023-12-09 19:17:20,060 INFO     Training average positive_sample_loss at step 1400: 0.444139\n",
      "2023-12-09 19:17:20,060 INFO     Training average negative_sample_loss at step 1400: 0.409587\n",
      "2023-12-09 19:17:20,060 INFO     Training average loss at step 1400: 0.426863\n",
      "2023-12-09 19:18:35,021 INFO     Training average positive_sample_loss at step 1500: 0.425788\n",
      "2023-12-09 19:18:35,022 INFO     Training average negative_sample_loss at step 1500: 0.390176\n",
      "2023-12-09 19:18:35,022 INFO     Training average loss at step 1500: 0.407982\n",
      "2023-12-09 19:19:51,490 INFO     Training average positive_sample_loss at step 1600: 0.405325\n",
      "2023-12-09 19:19:51,490 INFO     Training average negative_sample_loss at step 1600: 0.370698\n",
      "2023-12-09 19:19:51,490 INFO     Training average loss at step 1600: 0.388011\n",
      "2023-12-09 19:21:06,297 INFO     Training average positive_sample_loss at step 1700: 0.387145\n",
      "2023-12-09 19:21:06,297 INFO     Training average negative_sample_loss at step 1700: 0.354030\n",
      "2023-12-09 19:21:06,297 INFO     Training average loss at step 1700: 0.370587\n",
      "2023-12-09 19:22:21,603 INFO     Training average positive_sample_loss at step 1800: 0.367226\n",
      "2023-12-09 19:22:21,603 INFO     Training average negative_sample_loss at step 1800: 0.335298\n",
      "2023-12-09 19:22:21,603 INFO     Training average loss at step 1800: 0.351262\n",
      "2023-12-09 19:23:53,813 INFO     Training average positive_sample_loss at step 1900: 0.339232\n",
      "2023-12-09 19:23:53,813 INFO     Training average negative_sample_loss at step 1900: 0.317277\n",
      "2023-12-09 19:23:53,813 INFO     Training average loss at step 1900: 0.328254\n",
      "2023-12-09 19:25:09,957 INFO     Training average positive_sample_loss at step 2000: 0.295117\n",
      "2023-12-09 19:25:09,958 INFO     Training average negative_sample_loss at step 2000: 0.274633\n",
      "2023-12-09 19:25:09,958 INFO     Training average loss at step 2000: 0.284875\n",
      "2023-12-09 19:26:26,267 INFO     Training average positive_sample_loss at step 2100: 0.289297\n",
      "2023-12-09 19:26:26,267 INFO     Training average negative_sample_loss at step 2100: 0.262066\n",
      "2023-12-09 19:26:26,267 INFO     Training average loss at step 2100: 0.275682\n",
      "2023-12-09 19:27:42,868 INFO     Training average positive_sample_loss at step 2200: 0.279010\n",
      "2023-12-09 19:27:42,869 INFO     Training average negative_sample_loss at step 2200: 0.252551\n",
      "2023-12-09 19:27:42,869 INFO     Training average loss at step 2200: 0.265781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:29:00,296 INFO     Training average positive_sample_loss at step 2300: 0.268658\n",
      "2023-12-09 19:29:00,297 INFO     Training average negative_sample_loss at step 2300: 0.243458\n",
      "2023-12-09 19:29:00,297 INFO     Training average loss at step 2300: 0.256058\n",
      "2023-12-09 19:30:17,732 INFO     Training average positive_sample_loss at step 2400: 0.257701\n",
      "2023-12-09 19:30:17,732 INFO     Training average negative_sample_loss at step 2400: 0.235985\n",
      "2023-12-09 19:30:17,732 INFO     Training average loss at step 2400: 0.246843\n",
      "2023-12-09 19:31:33,351 INFO     Training average positive_sample_loss at step 2500: 0.247870\n",
      "2023-12-09 19:31:33,351 INFO     Training average negative_sample_loss at step 2500: 0.227219\n",
      "2023-12-09 19:31:33,351 INFO     Training average loss at step 2500: 0.237545\n",
      "2023-12-09 19:32:48,958 INFO     Training average positive_sample_loss at step 2600: 0.237386\n",
      "2023-12-09 19:32:48,958 INFO     Training average negative_sample_loss at step 2600: 0.219789\n",
      "2023-12-09 19:32:48,958 INFO     Training average loss at step 2600: 0.228588\n",
      "2023-12-09 19:34:05,779 INFO     Training average positive_sample_loss at step 2700: 0.228116\n",
      "2023-12-09 19:34:05,780 INFO     Training average negative_sample_loss at step 2700: 0.213110\n",
      "2023-12-09 19:34:05,780 INFO     Training average loss at step 2700: 0.220613\n",
      "2023-12-09 19:35:20,771 INFO     Training average positive_sample_loss at step 2800: 0.219313\n",
      "2023-12-09 19:35:20,772 INFO     Training average negative_sample_loss at step 2800: 0.206936\n",
      "2023-12-09 19:35:20,772 INFO     Training average loss at step 2800: 0.213124\n",
      "2023-12-09 19:36:47,365 INFO     Training average positive_sample_loss at step 2900: 0.192963\n",
      "2023-12-09 19:36:47,366 INFO     Training average negative_sample_loss at step 2900: 0.192380\n",
      "2023-12-09 19:36:47,366 INFO     Training average loss at step 2900: 0.192671\n",
      "2023-12-09 19:38:05,331 INFO     Training average positive_sample_loss at step 3000: 0.187377\n",
      "2023-12-09 19:38:05,332 INFO     Training average negative_sample_loss at step 3000: 0.178951\n",
      "2023-12-09 19:38:05,332 INFO     Training average loss at step 3000: 0.183164\n",
      "2023-12-09 19:39:20,814 INFO     Training average positive_sample_loss at step 3100: 0.184515\n",
      "2023-12-09 19:39:20,815 INFO     Training average negative_sample_loss at step 3100: 0.177205\n",
      "2023-12-09 19:39:20,815 INFO     Training average loss at step 3100: 0.180860\n",
      "2023-12-09 19:40:37,958 INFO     Training average positive_sample_loss at step 3200: 0.181327\n",
      "2023-12-09 19:40:37,958 INFO     Training average negative_sample_loss at step 3200: 0.174780\n",
      "2023-12-09 19:40:37,958 INFO     Training average loss at step 3200: 0.178053\n",
      "2023-12-09 19:41:53,686 INFO     Training average positive_sample_loss at step 3300: 0.177465\n",
      "2023-12-09 19:41:53,686 INFO     Training average negative_sample_loss at step 3300: 0.171904\n",
      "2023-12-09 19:41:53,686 INFO     Training average loss at step 3300: 0.174685\n",
      "2023-12-09 19:43:09,236 INFO     Training average positive_sample_loss at step 3400: 0.173943\n",
      "2023-12-09 19:43:09,236 INFO     Training average negative_sample_loss at step 3400: 0.170638\n",
      "2023-12-09 19:43:09,236 INFO     Training average loss at step 3400: 0.172290\n",
      "2023-12-09 19:44:26,720 INFO     Training average positive_sample_loss at step 3500: 0.169456\n",
      "2023-12-09 19:44:26,720 INFO     Training average negative_sample_loss at step 3500: 0.167990\n",
      "2023-12-09 19:44:26,720 INFO     Training average loss at step 3500: 0.168723\n",
      "2023-12-09 19:45:43,277 INFO     Training average positive_sample_loss at step 3600: 0.167196\n",
      "2023-12-09 19:45:43,277 INFO     Training average negative_sample_loss at step 3600: 0.166301\n",
      "2023-12-09 19:45:43,277 INFO     Training average loss at step 3600: 0.166749\n",
      "2023-12-09 19:46:57,907 INFO     Training average positive_sample_loss at step 3700: 0.161600\n",
      "2023-12-09 19:46:57,907 INFO     Training average negative_sample_loss at step 3700: 0.162066\n",
      "2023-12-09 19:46:57,907 INFO     Training average loss at step 3700: 0.161833\n",
      "2023-12-09 19:48:26,240 INFO     Training average positive_sample_loss at step 3800: 0.153495\n",
      "2023-12-09 19:48:26,241 INFO     Training average negative_sample_loss at step 3800: 0.159981\n",
      "2023-12-09 19:48:26,241 INFO     Training average loss at step 3800: 0.156738\n",
      "2023-12-09 19:49:42,826 INFO     Training average positive_sample_loss at step 3900: 0.144079\n",
      "2023-12-09 19:49:42,826 INFO     Training average negative_sample_loss at step 3900: 0.147557\n",
      "2023-12-09 19:49:42,826 INFO     Training average loss at step 3900: 0.145818\n",
      "2023-12-09 19:50:59,566 INFO     Training average positive_sample_loss at step 4000: 0.143986\n",
      "2023-12-09 19:50:59,566 INFO     Training average negative_sample_loss at step 4000: 0.145850\n",
      "2023-12-09 19:50:59,566 INFO     Training average loss at step 4000: 0.144918\n",
      "2023-12-09 19:52:14,307 INFO     Training average positive_sample_loss at step 4100: 0.143826\n",
      "2023-12-09 19:52:14,308 INFO     Training average negative_sample_loss at step 4100: 0.146308\n",
      "2023-12-09 19:52:14,308 INFO     Training average loss at step 4100: 0.145067\n",
      "2023-12-09 19:53:31,303 INFO     Training average positive_sample_loss at step 4200: 0.143757\n",
      "2023-12-09 19:53:31,303 INFO     Training average negative_sample_loss at step 4200: 0.145815\n",
      "2023-12-09 19:53:31,303 INFO     Training average loss at step 4200: 0.144786\n",
      "2023-12-09 19:54:47,351 INFO     Training average positive_sample_loss at step 4300: 0.142118\n",
      "2023-12-09 19:54:47,351 INFO     Training average negative_sample_loss at step 4300: 0.146174\n",
      "2023-12-09 19:54:47,351 INFO     Training average loss at step 4300: 0.144146\n",
      "2023-12-09 19:56:05,358 INFO     Training average positive_sample_loss at step 4400: 0.141269\n",
      "2023-12-09 19:56:05,359 INFO     Training average negative_sample_loss at step 4400: 0.146072\n",
      "2023-12-09 19:56:05,359 INFO     Training average loss at step 4400: 0.143671\n",
      "2023-12-09 19:57:19,297 INFO     Training average positive_sample_loss at step 4500: 0.139669\n",
      "2023-12-09 19:57:19,297 INFO     Training average negative_sample_loss at step 4500: 0.144694\n",
      "2023-12-09 19:57:19,297 INFO     Training average loss at step 4500: 0.142181\n",
      "2023-12-09 19:58:34,124 INFO     Training average positive_sample_loss at step 4600: 0.138074\n",
      "2023-12-09 19:58:34,125 INFO     Training average negative_sample_loss at step 4600: 0.143945\n",
      "2023-12-09 19:58:34,125 INFO     Training average loss at step 4600: 0.141009\n",
      "2023-12-09 19:59:48,725 INFO     Training average positive_sample_loss at step 4700: 0.136083\n",
      "2023-12-09 19:59:48,725 INFO     Training average negative_sample_loss at step 4700: 0.142180\n",
      "2023-12-09 19:59:48,725 INFO     Training average loss at step 4700: 0.139131\n",
      "2023-12-09 20:01:13,614 INFO     Training average positive_sample_loss at step 4800: 0.123989\n",
      "2023-12-09 20:01:13,614 INFO     Training average negative_sample_loss at step 4800: 0.135251\n",
      "2023-12-09 20:01:13,615 INFO     Training average loss at step 4800: 0.129620\n",
      "2023-12-09 20:02:31,972 INFO     Training average positive_sample_loss at step 4900: 0.126068\n",
      "2023-12-09 20:02:31,972 INFO     Training average negative_sample_loss at step 4900: 0.131703\n",
      "2023-12-09 20:02:31,972 INFO     Training average loss at step 4900: 0.128886\n",
      "2023-12-09 20:03:50,530 INFO     Training average positive_sample_loss at step 5000: 0.127233\n",
      "2023-12-09 20:03:50,530 INFO     Training average negative_sample_loss at step 5000: 0.132886\n",
      "2023-12-09 20:03:50,530 INFO     Training average loss at step 5000: 0.130060\n",
      "2023-12-09 20:05:07,495 INFO     Training average positive_sample_loss at step 5100: 0.127314\n",
      "2023-12-09 20:05:07,495 INFO     Training average negative_sample_loss at step 5100: 0.132757\n",
      "2023-12-09 20:05:07,495 INFO     Training average loss at step 5100: 0.130035\n",
      "2023-12-09 20:06:22,663 INFO     Training average positive_sample_loss at step 5200: 0.127173\n",
      "2023-12-09 20:06:22,663 INFO     Training average negative_sample_loss at step 5200: 0.132967\n",
      "2023-12-09 20:06:22,663 INFO     Training average loss at step 5200: 0.130070\n",
      "2023-12-09 20:07:37,875 INFO     Training average positive_sample_loss at step 5300: 0.126245\n",
      "2023-12-09 20:07:37,876 INFO     Training average negative_sample_loss at step 5300: 0.133189\n",
      "2023-12-09 20:07:37,876 INFO     Training average loss at step 5300: 0.129717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:08:53,036 INFO     Training average positive_sample_loss at step 5400: 0.125746\n",
      "2023-12-09 20:08:53,036 INFO     Training average negative_sample_loss at step 5400: 0.133024\n",
      "2023-12-09 20:08:53,036 INFO     Training average loss at step 5400: 0.129385\n",
      "2023-12-09 20:10:08,517 INFO     Training average positive_sample_loss at step 5500: 0.125654\n",
      "2023-12-09 20:10:08,517 INFO     Training average negative_sample_loss at step 5500: 0.133208\n",
      "2023-12-09 20:10:08,517 INFO     Training average loss at step 5500: 0.129431\n",
      "2023-12-09 20:11:24,620 INFO     Training average positive_sample_loss at step 5600: 0.124060\n",
      "2023-12-09 20:11:24,620 INFO     Training average negative_sample_loss at step 5600: 0.131807\n",
      "2023-12-09 20:11:24,620 INFO     Training average loss at step 5600: 0.127934\n",
      "2023-12-09 20:12:56,243 INFO     Training average positive_sample_loss at step 5700: 0.118269\n",
      "2023-12-09 20:12:56,243 INFO     Training average negative_sample_loss at step 5700: 0.129637\n",
      "2023-12-09 20:12:56,243 INFO     Training average loss at step 5700: 0.123953\n",
      "2023-12-09 20:14:13,608 INFO     Training average positive_sample_loss at step 5800: 0.114570\n",
      "2023-12-09 20:14:13,608 INFO     Training average negative_sample_loss at step 5800: 0.121623\n",
      "2023-12-09 20:14:13,608 INFO     Training average loss at step 5800: 0.118096\n",
      "2023-12-09 20:15:29,827 INFO     Training average positive_sample_loss at step 5900: 0.116581\n",
      "2023-12-09 20:15:29,827 INFO     Training average negative_sample_loss at step 5900: 0.122228\n",
      "2023-12-09 20:15:29,827 INFO     Training average loss at step 5900: 0.119405\n",
      "2023-12-09 20:16:44,225 INFO     Training average positive_sample_loss at step 6000: 0.117118\n",
      "2023-12-09 20:16:44,225 INFO     Training average negative_sample_loss at step 6000: 0.123311\n",
      "2023-12-09 20:16:44,225 INFO     Training average loss at step 6000: 0.120214\n",
      "2023-12-09 20:18:00,253 INFO     Training average positive_sample_loss at step 6100: 0.117769\n",
      "2023-12-09 20:18:00,253 INFO     Training average negative_sample_loss at step 6100: 0.124969\n",
      "2023-12-09 20:18:00,253 INFO     Training average loss at step 6100: 0.121369\n",
      "2023-12-09 20:19:16,110 INFO     Training average positive_sample_loss at step 6200: 0.118697\n",
      "2023-12-09 20:19:16,110 INFO     Training average negative_sample_loss at step 6200: 0.126262\n",
      "2023-12-09 20:19:16,110 INFO     Training average loss at step 6200: 0.122479\n",
      "2023-12-09 20:20:30,891 INFO     Training average positive_sample_loss at step 6300: 0.118247\n",
      "2023-12-09 20:20:30,891 INFO     Training average negative_sample_loss at step 6300: 0.126211\n",
      "2023-12-09 20:20:30,891 INFO     Training average loss at step 6300: 0.122229\n",
      "2023-12-09 20:21:47,058 INFO     Training average positive_sample_loss at step 6400: 0.118098\n",
      "2023-12-09 20:21:47,058 INFO     Training average negative_sample_loss at step 6400: 0.126464\n",
      "2023-12-09 20:21:47,058 INFO     Training average loss at step 6400: 0.122281\n",
      "2023-12-09 20:23:04,781 INFO     Training average positive_sample_loss at step 6500: 0.117076\n",
      "2023-12-09 20:23:04,781 INFO     Training average negative_sample_loss at step 6500: 0.124144\n",
      "2023-12-09 20:23:04,781 INFO     Training average loss at step 6500: 0.120610\n",
      "2023-12-09 20:24:20,739 INFO     Training average positive_sample_loss at step 6600: 0.115620\n",
      "2023-12-09 20:24:20,740 INFO     Training average negative_sample_loss at step 6600: 0.123697\n",
      "2023-12-09 20:24:20,740 INFO     Training average loss at step 6600: 0.119659\n",
      "2023-12-09 20:25:52,983 INFO     Training average positive_sample_loss at step 6700: 0.106332\n",
      "2023-12-09 20:25:52,983 INFO     Training average negative_sample_loss at step 6700: 0.116518\n",
      "2023-12-09 20:25:52,983 INFO     Training average loss at step 6700: 0.111425\n",
      "2023-12-09 20:27:09,112 INFO     Training average positive_sample_loss at step 6800: 0.109435\n",
      "2023-12-09 20:27:09,112 INFO     Training average negative_sample_loss at step 6800: 0.115538\n",
      "2023-12-09 20:27:09,112 INFO     Training average loss at step 6800: 0.112486\n",
      "2023-12-09 20:28:24,457 INFO     Training average positive_sample_loss at step 6900: 0.110514\n",
      "2023-12-09 20:28:24,457 INFO     Training average negative_sample_loss at step 6900: 0.116964\n",
      "2023-12-09 20:28:24,457 INFO     Training average loss at step 6900: 0.113739\n",
      "2023-12-09 20:29:39,155 INFO     Training average positive_sample_loss at step 7000: 0.111753\n",
      "2023-12-09 20:29:39,155 INFO     Training average negative_sample_loss at step 7000: 0.117629\n",
      "2023-12-09 20:29:39,155 INFO     Training average loss at step 7000: 0.114691\n",
      "2023-12-09 20:30:55,291 INFO     Training average positive_sample_loss at step 7100: 0.111676\n",
      "2023-12-09 20:30:55,291 INFO     Training average negative_sample_loss at step 7100: 0.119551\n",
      "2023-12-09 20:30:55,291 INFO     Training average loss at step 7100: 0.115614\n",
      "2023-12-09 20:32:11,133 INFO     Training average positive_sample_loss at step 7200: 0.112496\n",
      "2023-12-09 20:32:11,133 INFO     Training average negative_sample_loss at step 7200: 0.118388\n",
      "2023-12-09 20:32:11,133 INFO     Training average loss at step 7200: 0.115442\n",
      "2023-12-09 20:33:26,966 INFO     Training average positive_sample_loss at step 7300: 0.112061\n",
      "2023-12-09 20:33:26,966 INFO     Training average negative_sample_loss at step 7300: 0.119880\n",
      "2023-12-09 20:33:26,966 INFO     Training average loss at step 7300: 0.115970\n",
      "2023-12-09 20:34:41,391 INFO     Training average positive_sample_loss at step 7400: 0.111641\n",
      "2023-12-09 20:34:41,391 INFO     Training average negative_sample_loss at step 7400: 0.118272\n",
      "2023-12-09 20:34:41,392 INFO     Training average loss at step 7400: 0.114956\n",
      "2023-12-09 20:35:58,754 INFO     Training average positive_sample_loss at step 7500: 0.111357\n",
      "2023-12-09 20:35:58,754 INFO     Training average negative_sample_loss at step 7500: 0.118404\n",
      "2023-12-09 20:35:58,754 INFO     Training average loss at step 7500: 0.114880\n",
      "2023-12-09 20:37:26,631 INFO     Training average positive_sample_loss at step 7600: 0.105670\n",
      "2023-12-09 20:37:26,631 INFO     Training average negative_sample_loss at step 7600: 0.116158\n",
      "2023-12-09 20:37:26,631 INFO     Training average loss at step 7600: 0.110914\n",
      "2023-12-09 20:38:43,369 INFO     Training average positive_sample_loss at step 7700: 0.104183\n",
      "2023-12-09 20:38:43,369 INFO     Training average negative_sample_loss at step 7700: 0.110290\n",
      "2023-12-09 20:38:43,369 INFO     Training average loss at step 7700: 0.107236\n",
      "2023-12-09 20:40:00,604 INFO     Training average positive_sample_loss at step 7800: 0.105386\n",
      "2023-12-09 20:40:00,604 INFO     Training average negative_sample_loss at step 7800: 0.111029\n",
      "2023-12-09 20:40:00,604 INFO     Training average loss at step 7800: 0.108208\n",
      "2023-12-09 20:41:16,960 INFO     Training average positive_sample_loss at step 7900: 0.106640\n",
      "2023-12-09 20:41:16,960 INFO     Training average negative_sample_loss at step 7900: 0.113351\n",
      "2023-12-09 20:41:16,960 INFO     Training average loss at step 7900: 0.109995\n",
      "2023-12-09 20:42:32,543 INFO     Training average positive_sample_loss at step 8000: 0.107482\n",
      "2023-12-09 20:42:32,543 INFO     Training average negative_sample_loss at step 8000: 0.113033\n",
      "2023-12-09 20:42:32,543 INFO     Training average loss at step 8000: 0.110257\n",
      "2023-12-09 20:43:48,688 INFO     Training average positive_sample_loss at step 8100: 0.107208\n",
      "2023-12-09 20:43:48,688 INFO     Training average negative_sample_loss at step 8100: 0.114418\n",
      "2023-12-09 20:43:48,688 INFO     Training average loss at step 8100: 0.110813\n",
      "2023-12-09 20:45:05,395 INFO     Training average positive_sample_loss at step 8200: 0.108090\n",
      "2023-12-09 20:45:05,395 INFO     Training average negative_sample_loss at step 8200: 0.114167\n",
      "2023-12-09 20:45:05,395 INFO     Training average loss at step 8200: 0.111129\n",
      "2023-12-09 20:46:24,136 INFO     Training average positive_sample_loss at step 8300: 0.107964\n",
      "2023-12-09 20:46:24,136 INFO     Training average negative_sample_loss at step 8300: 0.115071\n",
      "2023-12-09 20:46:24,136 INFO     Training average loss at step 8300: 0.111518\n",
      "2023-12-09 20:47:40,660 INFO     Training average positive_sample_loss at step 8400: 0.108185\n",
      "2023-12-09 20:47:40,660 INFO     Training average negative_sample_loss at step 8400: 0.115610\n",
      "2023-12-09 20:47:40,660 INFO     Training average loss at step 8400: 0.111898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:49:11,261 INFO     Training average positive_sample_loss at step 8500: 0.106625\n",
      "2023-12-09 20:49:11,261 INFO     Training average negative_sample_loss at step 8500: 0.113839\n",
      "2023-12-09 20:49:11,261 INFO     Training average loss at step 8500: 0.110232\n",
      "2023-12-09 20:50:27,547 INFO     Training average positive_sample_loss at step 8600: 0.098893\n",
      "2023-12-09 20:50:27,548 INFO     Training average negative_sample_loss at step 8600: 0.107413\n",
      "2023-12-09 20:50:27,548 INFO     Training average loss at step 8600: 0.103153\n",
      "2023-12-09 20:51:44,325 INFO     Training average positive_sample_loss at step 8700: 0.100945\n",
      "2023-12-09 20:51:44,325 INFO     Training average negative_sample_loss at step 8700: 0.106663\n",
      "2023-12-09 20:51:44,325 INFO     Training average loss at step 8700: 0.103804\n",
      "2023-12-09 20:52:59,308 INFO     Training average positive_sample_loss at step 8800: 0.102424\n",
      "2023-12-09 20:52:59,308 INFO     Training average negative_sample_loss at step 8800: 0.108307\n",
      "2023-12-09 20:52:59,308 INFO     Training average loss at step 8800: 0.105366\n",
      "2023-12-09 20:54:15,225 INFO     Training average positive_sample_loss at step 8900: 0.103859\n",
      "2023-12-09 20:54:15,225 INFO     Training average negative_sample_loss at step 8900: 0.110089\n",
      "2023-12-09 20:54:15,225 INFO     Training average loss at step 8900: 0.106974\n",
      "2023-12-09 20:55:31,367 INFO     Training average positive_sample_loss at step 9000: 0.103757\n",
      "2023-12-09 20:55:31,367 INFO     Training average negative_sample_loss at step 9000: 0.109655\n",
      "2023-12-09 20:55:31,367 INFO     Training average loss at step 9000: 0.106706\n",
      "2023-12-09 20:56:47,212 INFO     Training average positive_sample_loss at step 9100: 0.104266\n",
      "2023-12-09 20:56:47,213 INFO     Training average negative_sample_loss at step 9100: 0.110104\n",
      "2023-12-09 20:56:47,213 INFO     Training average loss at step 9100: 0.107185\n",
      "2023-12-09 20:58:05,197 INFO     Training average positive_sample_loss at step 9200: 0.104242\n",
      "2023-12-09 20:58:05,197 INFO     Training average negative_sample_loss at step 9200: 0.109872\n",
      "2023-12-09 20:58:05,197 INFO     Training average loss at step 9200: 0.107057\n",
      "2023-12-09 20:59:22,397 INFO     Training average positive_sample_loss at step 9300: 0.104444\n",
      "2023-12-09 20:59:22,397 INFO     Training average negative_sample_loss at step 9300: 0.110879\n",
      "2023-12-09 20:59:22,398 INFO     Training average loss at step 9300: 0.107662\n",
      "2023-12-09 21:00:38,406 INFO     Training average positive_sample_loss at step 9400: 0.104718\n",
      "2023-12-09 21:00:38,406 INFO     Training average negative_sample_loss at step 9400: 0.111487\n",
      "2023-12-09 21:00:38,406 INFO     Training average loss at step 9400: 0.108102\n",
      "2023-12-09 21:02:05,250 INFO     Training average positive_sample_loss at step 9500: 0.097504\n",
      "2023-12-09 21:02:05,250 INFO     Training average negative_sample_loss at step 9500: 0.106775\n",
      "2023-12-09 21:02:05,251 INFO     Training average loss at step 9500: 0.102139\n",
      "2023-12-09 21:03:22,038 INFO     Training average positive_sample_loss at step 9600: 0.097827\n",
      "2023-12-09 21:03:22,038 INFO     Training average negative_sample_loss at step 9600: 0.102607\n",
      "2023-12-09 21:03:22,038 INFO     Training average loss at step 9600: 0.100217\n",
      "2023-12-09 21:04:37,353 INFO     Training average positive_sample_loss at step 9700: 0.099850\n",
      "2023-12-09 21:04:37,354 INFO     Training average negative_sample_loss at step 9700: 0.104812\n",
      "2023-12-09 21:04:37,354 INFO     Training average loss at step 9700: 0.102331\n",
      "2023-12-09 21:05:53,557 INFO     Training average positive_sample_loss at step 9800: 0.100069\n",
      "2023-12-09 21:05:53,557 INFO     Training average negative_sample_loss at step 9800: 0.105532\n",
      "2023-12-09 21:05:53,557 INFO     Training average loss at step 9800: 0.102801\n",
      "2023-12-09 21:07:09,651 INFO     Training average positive_sample_loss at step 9900: 0.100770\n",
      "2023-12-09 21:07:09,652 INFO     Training average negative_sample_loss at step 9900: 0.106710\n",
      "2023-12-09 21:07:09,652 INFO     Training average loss at step 9900: 0.103740\n",
      "2023-12-09 21:08:43,248 INFO     Training average positive_sample_loss at step 10000: 0.101774\n",
      "2023-12-09 21:08:43,248 INFO     Training average negative_sample_loss at step 10000: 0.107580\n",
      "2023-12-09 21:08:43,248 INFO     Training average loss at step 10000: 0.104677\n",
      "2023-12-09 21:08:43,248 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 21:08:44,240 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-09 21:11:29,034 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-09 21:13:17,720 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-09 21:15:52,801 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-09 21:18:37,292 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-09 21:21:22,507 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-09 21:22:58,723 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-09 21:23:41,726 INFO     Valid MRR at step 10000: 0.730873\n",
      "2023-12-09 21:23:41,726 INFO     Valid MR at step 10000: 55.581300\n",
      "2023-12-09 21:23:41,726 INFO     Valid HITS@1 at step 10000: 0.658850\n",
      "2023-12-09 21:23:41,726 INFO     Valid HITS@3 at step 10000: 0.779430\n",
      "2023-12-09 21:23:41,726 INFO     Valid HITS@10 at step 10000: 0.852050\n",
      "2023-12-09 21:24:44,785 INFO     Training average positive_sample_loss at step 10100: 0.102111\n",
      "2023-12-09 21:24:44,785 INFO     Training average negative_sample_loss at step 10100: 0.107189\n",
      "2023-12-09 21:24:44,785 INFO     Training average loss at step 10100: 0.104650\n",
      "2023-12-09 21:26:01,366 INFO     Training average positive_sample_loss at step 10200: 0.102522\n",
      "2023-12-09 21:26:01,367 INFO     Training average negative_sample_loss at step 10200: 0.108276\n",
      "2023-12-09 21:26:01,367 INFO     Training average loss at step 10200: 0.105399\n",
      "2023-12-09 21:27:19,746 INFO     Training average positive_sample_loss at step 10300: 0.101473\n",
      "2023-12-09 21:27:19,747 INFO     Training average negative_sample_loss at step 10300: 0.107302\n",
      "2023-12-09 21:27:19,747 INFO     Training average loss at step 10300: 0.104387\n",
      "2023-12-09 21:28:48,349 INFO     Training average positive_sample_loss at step 10400: 0.099646\n",
      "2023-12-09 21:28:48,350 INFO     Training average negative_sample_loss at step 10400: 0.106901\n",
      "2023-12-09 21:28:48,350 INFO     Training average loss at step 10400: 0.103274\n",
      "2023-12-09 21:30:05,082 INFO     Training average positive_sample_loss at step 10500: 0.094524\n",
      "2023-12-09 21:30:05,083 INFO     Training average negative_sample_loss at step 10500: 0.101420\n",
      "2023-12-09 21:30:05,083 INFO     Training average loss at step 10500: 0.097972\n",
      "2023-12-09 21:31:21,355 INFO     Training average positive_sample_loss at step 10600: 0.096595\n",
      "2023-12-09 21:31:21,355 INFO     Training average negative_sample_loss at step 10600: 0.101809\n",
      "2023-12-09 21:31:21,355 INFO     Training average loss at step 10600: 0.099202\n",
      "2023-12-09 21:32:35,924 INFO     Training average positive_sample_loss at step 10700: 0.097907\n",
      "2023-12-09 21:32:35,925 INFO     Training average negative_sample_loss at step 10700: 0.102594\n",
      "2023-12-09 21:32:35,925 INFO     Training average loss at step 10700: 0.100251\n",
      "2023-12-09 21:33:51,696 INFO     Training average positive_sample_loss at step 10800: 0.097922\n",
      "2023-12-09 21:33:51,697 INFO     Training average negative_sample_loss at step 10800: 0.102976\n",
      "2023-12-09 21:33:51,697 INFO     Training average loss at step 10800: 0.100449\n",
      "2023-12-09 21:35:07,454 INFO     Training average positive_sample_loss at step 10900: 0.099713\n",
      "2023-12-09 21:35:07,454 INFO     Training average negative_sample_loss at step 10900: 0.103296\n",
      "2023-12-09 21:35:07,454 INFO     Training average loss at step 10900: 0.101505\n",
      "2023-12-09 21:36:23,936 INFO     Training average positive_sample_loss at step 11000: 0.099700\n",
      "2023-12-09 21:36:23,936 INFO     Training average negative_sample_loss at step 11000: 0.104670\n",
      "2023-12-09 21:36:23,936 INFO     Training average loss at step 11000: 0.102185\n",
      "2023-12-09 21:37:39,726 INFO     Training average positive_sample_loss at step 11100: 0.100027\n",
      "2023-12-09 21:37:39,727 INFO     Training average negative_sample_loss at step 11100: 0.105167\n",
      "2023-12-09 21:37:39,727 INFO     Training average loss at step 11100: 0.102597\n",
      "2023-12-09 21:38:55,246 INFO     Training average positive_sample_loss at step 11200: 0.099677\n",
      "2023-12-09 21:38:55,247 INFO     Training average negative_sample_loss at step 11200: 0.105349\n",
      "2023-12-09 21:38:55,247 INFO     Training average loss at step 11200: 0.102513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:40:10,623 INFO     Training average positive_sample_loss at step 11300: 0.099752\n",
      "2023-12-09 21:40:10,624 INFO     Training average negative_sample_loss at step 11300: 0.105323\n",
      "2023-12-09 21:40:10,624 INFO     Training average loss at step 11300: 0.102537\n",
      "2023-12-09 21:41:42,489 INFO     Training average positive_sample_loss at step 11400: 0.093137\n",
      "2023-12-09 21:41:42,490 INFO     Training average negative_sample_loss at step 11400: 0.100861\n",
      "2023-12-09 21:41:42,490 INFO     Training average loss at step 11400: 0.096999\n",
      "2023-12-09 21:42:57,258 INFO     Training average positive_sample_loss at step 11500: 0.094221\n",
      "2023-12-09 21:42:57,258 INFO     Training average negative_sample_loss at step 11500: 0.098758\n",
      "2023-12-09 21:42:57,258 INFO     Training average loss at step 11500: 0.096490\n",
      "2023-12-09 21:44:11,683 INFO     Training average positive_sample_loss at step 11600: 0.095420\n",
      "2023-12-09 21:44:11,684 INFO     Training average negative_sample_loss at step 11600: 0.100604\n",
      "2023-12-09 21:44:11,684 INFO     Training average loss at step 11600: 0.098012\n",
      "2023-12-09 21:45:28,906 INFO     Training average positive_sample_loss at step 11700: 0.096967\n",
      "2023-12-09 21:45:28,907 INFO     Training average negative_sample_loss at step 11700: 0.100502\n",
      "2023-12-09 21:45:28,907 INFO     Training average loss at step 11700: 0.098735\n",
      "2023-12-09 21:46:43,616 INFO     Training average positive_sample_loss at step 11800: 0.097391\n",
      "2023-12-09 21:46:43,616 INFO     Training average negative_sample_loss at step 11800: 0.101381\n",
      "2023-12-09 21:46:43,616 INFO     Training average loss at step 11800: 0.099386\n",
      "2023-12-09 21:47:57,585 INFO     Training average positive_sample_loss at step 11900: 0.097482\n",
      "2023-12-09 21:47:57,585 INFO     Training average negative_sample_loss at step 11900: 0.102792\n",
      "2023-12-09 21:47:57,585 INFO     Training average loss at step 11900: 0.100137\n",
      "2023-12-09 21:49:13,475 INFO     Training average positive_sample_loss at step 12000: 0.097899\n",
      "2023-12-09 21:49:13,476 INFO     Training average negative_sample_loss at step 12000: 0.103011\n",
      "2023-12-09 21:49:13,476 INFO     Training average loss at step 12000: 0.100455\n",
      "2023-12-09 21:50:29,750 INFO     Training average positive_sample_loss at step 12100: 0.097587\n",
      "2023-12-09 21:50:29,750 INFO     Training average negative_sample_loss at step 12100: 0.100660\n",
      "2023-12-09 21:50:29,750 INFO     Training average loss at step 12100: 0.099123\n",
      "2023-12-09 21:51:44,024 INFO     Training average positive_sample_loss at step 12200: 0.096877\n",
      "2023-12-09 21:51:44,024 INFO     Training average negative_sample_loss at step 12200: 0.101608\n",
      "2023-12-09 21:51:44,024 INFO     Training average loss at step 12200: 0.099242\n",
      "2023-12-09 21:53:13,773 INFO     Training average positive_sample_loss at step 12300: 0.094613\n",
      "2023-12-09 21:53:13,773 INFO     Training average negative_sample_loss at step 12300: 0.102316\n",
      "2023-12-09 21:53:13,773 INFO     Training average loss at step 12300: 0.098465\n",
      "2023-12-09 21:54:31,435 INFO     Training average positive_sample_loss at step 12400: 0.091779\n",
      "2023-12-09 21:54:31,435 INFO     Training average negative_sample_loss at step 12400: 0.097030\n",
      "2023-12-09 21:54:31,435 INFO     Training average loss at step 12400: 0.094404\n",
      "2023-12-09 21:55:48,370 INFO     Training average positive_sample_loss at step 12500: 0.093297\n",
      "2023-12-09 21:55:48,370 INFO     Training average negative_sample_loss at step 12500: 0.097211\n",
      "2023-12-09 21:55:48,370 INFO     Training average loss at step 12500: 0.095254\n",
      "2023-12-09 21:57:04,278 INFO     Training average positive_sample_loss at step 12600: 0.094331\n",
      "2023-12-09 21:57:04,278 INFO     Training average negative_sample_loss at step 12600: 0.098179\n",
      "2023-12-09 21:57:04,278 INFO     Training average loss at step 12600: 0.096255\n",
      "2023-12-09 21:58:19,411 INFO     Training average positive_sample_loss at step 12700: 0.095609\n",
      "2023-12-09 21:58:19,412 INFO     Training average negative_sample_loss at step 12700: 0.100639\n",
      "2023-12-09 21:58:19,412 INFO     Training average loss at step 12700: 0.098124\n",
      "2023-12-09 21:59:34,446 INFO     Training average positive_sample_loss at step 12800: 0.096706\n",
      "2023-12-09 21:59:34,446 INFO     Training average negative_sample_loss at step 12800: 0.100930\n",
      "2023-12-09 21:59:34,446 INFO     Training average loss at step 12800: 0.098818\n",
      "2023-12-09 22:00:50,291 INFO     Training average positive_sample_loss at step 12900: 0.097055\n",
      "2023-12-09 22:00:50,291 INFO     Training average negative_sample_loss at step 12900: 0.100546\n",
      "2023-12-09 22:00:50,291 INFO     Training average loss at step 12900: 0.098800\n",
      "2023-12-09 22:02:06,331 INFO     Training average positive_sample_loss at step 13000: 0.096534\n",
      "2023-12-09 22:02:06,332 INFO     Training average negative_sample_loss at step 13000: 0.101127\n",
      "2023-12-09 22:02:06,332 INFO     Training average loss at step 13000: 0.098830\n",
      "2023-12-09 22:03:22,122 INFO     Training average positive_sample_loss at step 13100: 0.095440\n",
      "2023-12-09 22:03:22,123 INFO     Training average negative_sample_loss at step 13100: 0.100717\n",
      "2023-12-09 22:03:22,123 INFO     Training average loss at step 13100: 0.098079\n",
      "2023-12-09 22:04:38,843 INFO     Training average positive_sample_loss at step 13200: 0.096097\n",
      "2023-12-09 22:04:38,843 INFO     Training average negative_sample_loss at step 13200: 0.099795\n",
      "2023-12-09 22:04:38,843 INFO     Training average loss at step 13200: 0.097946\n",
      "2023-12-09 22:06:04,377 INFO     Training average positive_sample_loss at step 13300: 0.089179\n",
      "2023-12-09 22:06:04,377 INFO     Training average negative_sample_loss at step 13300: 0.097482\n",
      "2023-12-09 22:06:04,377 INFO     Training average loss at step 13300: 0.093331\n",
      "2023-12-09 22:07:20,080 INFO     Training average positive_sample_loss at step 13400: 0.091752\n",
      "2023-12-09 22:07:20,080 INFO     Training average negative_sample_loss at step 13400: 0.095196\n",
      "2023-12-09 22:07:20,080 INFO     Training average loss at step 13400: 0.093474\n",
      "2023-12-09 22:08:36,389 INFO     Training average positive_sample_loss at step 13500: 0.092742\n",
      "2023-12-09 22:08:36,390 INFO     Training average negative_sample_loss at step 13500: 0.096656\n",
      "2023-12-09 22:08:36,390 INFO     Training average loss at step 13500: 0.094699\n",
      "2023-12-09 22:09:53,894 INFO     Training average positive_sample_loss at step 13600: 0.093988\n",
      "2023-12-09 22:09:53,895 INFO     Training average negative_sample_loss at step 13600: 0.098041\n",
      "2023-12-09 22:09:53,895 INFO     Training average loss at step 13600: 0.096015\n",
      "2023-12-09 22:11:11,101 INFO     Training average positive_sample_loss at step 13700: 0.094867\n",
      "2023-12-09 22:11:11,101 INFO     Training average negative_sample_loss at step 13700: 0.098722\n",
      "2023-12-09 22:11:11,101 INFO     Training average loss at step 13700: 0.096795\n",
      "2023-12-09 22:12:31,374 INFO     Training average positive_sample_loss at step 13800: 0.095439\n",
      "2023-12-09 22:12:31,374 INFO     Training average negative_sample_loss at step 13800: 0.099814\n",
      "2023-12-09 22:12:31,374 INFO     Training average loss at step 13800: 0.097627\n",
      "2023-12-09 22:13:49,431 INFO     Training average positive_sample_loss at step 13900: 0.095604\n",
      "2023-12-09 22:13:49,431 INFO     Training average negative_sample_loss at step 13900: 0.099725\n",
      "2023-12-09 22:13:49,431 INFO     Training average loss at step 13900: 0.097665\n",
      "2023-12-09 22:15:04,827 INFO     Training average positive_sample_loss at step 14000: 0.094820\n",
      "2023-12-09 22:15:04,827 INFO     Training average negative_sample_loss at step 14000: 0.099281\n",
      "2023-12-09 22:15:04,827 INFO     Training average loss at step 14000: 0.097051\n",
      "2023-12-09 22:16:23,693 INFO     Training average positive_sample_loss at step 14100: 0.095667\n",
      "2023-12-09 22:16:23,693 INFO     Training average negative_sample_loss at step 14100: 0.101397\n",
      "2023-12-09 22:16:23,694 INFO     Training average loss at step 14100: 0.098532\n",
      "2023-12-09 22:17:48,500 INFO     Training average positive_sample_loss at step 14200: 0.091264\n",
      "2023-12-09 22:17:48,500 INFO     Training average negative_sample_loss at step 14200: 0.098178\n",
      "2023-12-09 22:17:48,500 INFO     Training average loss at step 14200: 0.094721\n",
      "2023-12-09 22:19:07,293 INFO     Training average positive_sample_loss at step 14300: 0.090122\n",
      "2023-12-09 22:19:07,293 INFO     Training average negative_sample_loss at step 14300: 0.094231\n",
      "2023-12-09 22:19:07,293 INFO     Training average loss at step 14300: 0.092177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 22:20:23,754 INFO     Training average positive_sample_loss at step 14400: 0.091599\n",
      "2023-12-09 22:20:23,754 INFO     Training average negative_sample_loss at step 14400: 0.095173\n",
      "2023-12-09 22:20:23,755 INFO     Training average loss at step 14400: 0.093386\n",
      "2023-12-09 22:21:39,785 INFO     Training average positive_sample_loss at step 14500: 0.092338\n",
      "2023-12-09 22:21:39,785 INFO     Training average negative_sample_loss at step 14500: 0.095135\n",
      "2023-12-09 22:21:39,785 INFO     Training average loss at step 14500: 0.093736\n",
      "2023-12-09 22:22:58,840 INFO     Training average positive_sample_loss at step 14600: 0.092380\n",
      "2023-12-09 22:22:58,840 INFO     Training average negative_sample_loss at step 14600: 0.095533\n",
      "2023-12-09 22:22:58,840 INFO     Training average loss at step 14600: 0.093956\n",
      "2023-12-09 22:24:14,815 INFO     Training average positive_sample_loss at step 14700: 0.093541\n",
      "2023-12-09 22:24:14,815 INFO     Training average negative_sample_loss at step 14700: 0.096794\n",
      "2023-12-09 22:24:14,815 INFO     Training average loss at step 14700: 0.095168\n",
      "2023-12-09 22:25:33,167 INFO     Training average positive_sample_loss at step 14800: 0.094117\n",
      "2023-12-09 22:25:33,168 INFO     Training average negative_sample_loss at step 14800: 0.097795\n",
      "2023-12-09 22:25:33,168 INFO     Training average loss at step 14800: 0.095956\n",
      "2023-12-09 22:26:49,299 INFO     Training average positive_sample_loss at step 14900: 0.094213\n",
      "2023-12-09 22:26:49,299 INFO     Training average negative_sample_loss at step 14900: 0.098411\n",
      "2023-12-09 22:26:49,299 INFO     Training average loss at step 14900: 0.096312\n",
      "2023-12-09 22:28:04,403 INFO     Training average positive_sample_loss at step 15000: 0.093789\n",
      "2023-12-09 22:28:04,403 INFO     Training average negative_sample_loss at step 15000: 0.097069\n",
      "2023-12-09 22:28:04,403 INFO     Training average loss at step 15000: 0.095429\n",
      "2023-12-09 22:29:20,041 INFO     Training average positive_sample_loss at step 15100: 0.094099\n",
      "2023-12-09 22:29:20,041 INFO     Training average negative_sample_loss at step 15100: 0.098613\n",
      "2023-12-09 22:29:20,041 INFO     Training average loss at step 15100: 0.096356\n",
      "2023-12-09 22:30:52,285 INFO     Training average positive_sample_loss at step 15200: 0.087075\n",
      "2023-12-09 22:30:52,286 INFO     Training average negative_sample_loss at step 15200: 0.093900\n",
      "2023-12-09 22:30:52,286 INFO     Training average loss at step 15200: 0.090487\n",
      "2023-12-09 22:32:09,990 INFO     Training average positive_sample_loss at step 15300: 0.090182\n",
      "2023-12-09 22:32:09,990 INFO     Training average negative_sample_loss at step 15300: 0.093026\n",
      "2023-12-09 22:32:09,990 INFO     Training average loss at step 15300: 0.091604\n",
      "2023-12-09 22:33:26,810 INFO     Training average positive_sample_loss at step 15400: 0.090918\n",
      "2023-12-09 22:33:26,810 INFO     Training average negative_sample_loss at step 15400: 0.094283\n",
      "2023-12-09 22:33:26,810 INFO     Training average loss at step 15400: 0.092601\n",
      "2023-12-09 22:34:43,711 INFO     Training average positive_sample_loss at step 15500: 0.091724\n",
      "2023-12-09 22:34:43,711 INFO     Training average negative_sample_loss at step 15500: 0.094469\n",
      "2023-12-09 22:34:43,711 INFO     Training average loss at step 15500: 0.093097\n",
      "2023-12-09 22:36:00,443 INFO     Training average positive_sample_loss at step 15600: 0.092500\n",
      "2023-12-09 22:36:00,444 INFO     Training average negative_sample_loss at step 15600: 0.095820\n",
      "2023-12-09 22:36:00,444 INFO     Training average loss at step 15600: 0.094160\n",
      "2023-12-09 22:37:18,255 INFO     Training average positive_sample_loss at step 15700: 0.092808\n",
      "2023-12-09 22:37:18,255 INFO     Training average negative_sample_loss at step 15700: 0.095499\n",
      "2023-12-09 22:37:18,255 INFO     Training average loss at step 15700: 0.094153\n",
      "2023-12-09 22:38:39,293 INFO     Training average positive_sample_loss at step 15800: 0.092148\n",
      "2023-12-09 22:38:39,293 INFO     Training average negative_sample_loss at step 15800: 0.095605\n",
      "2023-12-09 22:38:39,293 INFO     Training average loss at step 15800: 0.093876\n",
      "2023-12-09 22:39:57,538 INFO     Training average positive_sample_loss at step 15900: 0.093594\n",
      "2023-12-09 22:39:57,538 INFO     Training average negative_sample_loss at step 15900: 0.096370\n",
      "2023-12-09 22:39:57,538 INFO     Training average loss at step 15900: 0.094982\n",
      "2023-12-09 22:41:16,344 INFO     Training average positive_sample_loss at step 16000: 0.092847\n",
      "2023-12-09 22:41:16,344 INFO     Training average negative_sample_loss at step 16000: 0.096970\n",
      "2023-12-09 22:41:16,344 INFO     Training average loss at step 16000: 0.094908\n",
      "2023-12-09 22:42:49,221 INFO     Training average positive_sample_loss at step 16100: 0.088757\n",
      "2023-12-09 22:42:49,222 INFO     Training average negative_sample_loss at step 16100: 0.094896\n",
      "2023-12-09 22:42:49,222 INFO     Training average loss at step 16100: 0.091827\n",
      "2023-12-09 22:44:06,086 INFO     Training average positive_sample_loss at step 16200: 0.087790\n",
      "2023-12-09 22:44:06,087 INFO     Training average negative_sample_loss at step 16200: 0.091578\n",
      "2023-12-09 22:44:06,087 INFO     Training average loss at step 16200: 0.089684\n",
      "2023-12-09 22:45:26,310 INFO     Training average positive_sample_loss at step 16300: 0.089618\n",
      "2023-12-09 22:45:26,311 INFO     Training average negative_sample_loss at step 16300: 0.092875\n",
      "2023-12-09 22:45:26,311 INFO     Training average loss at step 16300: 0.091247\n",
      "2023-12-09 22:46:45,274 INFO     Training average positive_sample_loss at step 16400: 0.091124\n",
      "2023-12-09 22:46:45,274 INFO     Training average negative_sample_loss at step 16400: 0.093492\n",
      "2023-12-09 22:46:45,274 INFO     Training average loss at step 16400: 0.092308\n",
      "2023-12-09 22:48:04,128 INFO     Training average positive_sample_loss at step 16500: 0.091031\n",
      "2023-12-09 22:48:04,128 INFO     Training average negative_sample_loss at step 16500: 0.094459\n",
      "2023-12-09 22:48:04,128 INFO     Training average loss at step 16500: 0.092745\n",
      "2023-12-09 22:49:22,270 INFO     Training average positive_sample_loss at step 16600: 0.091681\n",
      "2023-12-09 22:49:22,270 INFO     Training average negative_sample_loss at step 16600: 0.094521\n",
      "2023-12-09 22:49:22,270 INFO     Training average loss at step 16600: 0.093101\n",
      "2023-12-09 22:50:42,334 INFO     Training average positive_sample_loss at step 16700: 0.091945\n",
      "2023-12-09 22:50:42,334 INFO     Training average negative_sample_loss at step 16700: 0.095424\n",
      "2023-12-09 22:50:42,334 INFO     Training average loss at step 16700: 0.093684\n",
      "2023-12-09 22:52:06,590 INFO     Training average positive_sample_loss at step 16800: 0.092712\n",
      "2023-12-09 22:52:06,591 INFO     Training average negative_sample_loss at step 16800: 0.095546\n",
      "2023-12-09 22:52:06,591 INFO     Training average loss at step 16800: 0.094129\n",
      "2023-12-09 22:53:26,956 INFO     Training average positive_sample_loss at step 16900: 0.092401\n",
      "2023-12-09 22:53:26,956 INFO     Training average negative_sample_loss at step 16900: 0.096145\n",
      "2023-12-09 22:53:26,956 INFO     Training average loss at step 16900: 0.094273\n",
      "2023-12-09 22:54:59,105 INFO     Training average positive_sample_loss at step 17000: 0.090948\n",
      "2023-12-09 22:54:59,106 INFO     Training average negative_sample_loss at step 17000: 0.095329\n",
      "2023-12-09 22:54:59,106 INFO     Training average loss at step 17000: 0.093139\n",
      "2023-12-09 22:56:17,840 INFO     Training average positive_sample_loss at step 17100: 0.085529\n",
      "2023-12-09 22:56:17,841 INFO     Training average negative_sample_loss at step 17100: 0.090992\n",
      "2023-12-09 22:56:17,841 INFO     Training average loss at step 17100: 0.088260\n",
      "2023-12-09 22:57:37,245 INFO     Training average positive_sample_loss at step 17200: 0.088495\n",
      "2023-12-09 22:57:37,246 INFO     Training average negative_sample_loss at step 17200: 0.090298\n",
      "2023-12-09 22:57:37,246 INFO     Training average loss at step 17200: 0.089397\n",
      "2023-12-09 22:58:56,759 INFO     Training average positive_sample_loss at step 17300: 0.089207\n",
      "2023-12-09 22:58:56,760 INFO     Training average negative_sample_loss at step 17300: 0.091007\n",
      "2023-12-09 22:58:56,760 INFO     Training average loss at step 17300: 0.090107\n",
      "2023-12-09 23:00:16,472 INFO     Training average positive_sample_loss at step 17400: 0.089685\n",
      "2023-12-09 23:00:16,472 INFO     Training average negative_sample_loss at step 17400: 0.092312\n",
      "2023-12-09 23:00:16,473 INFO     Training average loss at step 17400: 0.090999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 23:01:33,238 INFO     Training average positive_sample_loss at step 17500: 0.090399\n",
      "2023-12-09 23:01:33,239 INFO     Training average negative_sample_loss at step 17500: 0.092932\n",
      "2023-12-09 23:01:33,239 INFO     Training average loss at step 17500: 0.091665\n",
      "2023-12-09 23:02:50,824 INFO     Training average positive_sample_loss at step 17600: 0.091195\n",
      "2023-12-09 23:02:50,824 INFO     Training average negative_sample_loss at step 17600: 0.094517\n",
      "2023-12-09 23:02:50,824 INFO     Training average loss at step 17600: 0.092856\n",
      "2023-12-09 23:04:08,670 INFO     Training average positive_sample_loss at step 17700: 0.091498\n",
      "2023-12-09 23:04:08,670 INFO     Training average negative_sample_loss at step 17700: 0.095080\n",
      "2023-12-09 23:04:08,670 INFO     Training average loss at step 17700: 0.093289\n",
      "2023-12-09 23:05:26,379 INFO     Training average positive_sample_loss at step 17800: 0.092021\n",
      "2023-12-09 23:05:26,379 INFO     Training average negative_sample_loss at step 17800: 0.095416\n",
      "2023-12-09 23:05:26,379 INFO     Training average loss at step 17800: 0.093718\n",
      "2023-12-09 23:06:45,841 INFO     Training average positive_sample_loss at step 17900: 0.091512\n",
      "2023-12-09 23:06:45,841 INFO     Training average negative_sample_loss at step 17900: 0.094297\n",
      "2023-12-09 23:06:45,841 INFO     Training average loss at step 17900: 0.092905\n",
      "2023-12-09 23:08:12,053 INFO     Training average positive_sample_loss at step 18000: 0.086630\n",
      "2023-12-09 23:08:12,053 INFO     Training average negative_sample_loss at step 18000: 0.092130\n",
      "2023-12-09 23:08:12,054 INFO     Training average loss at step 18000: 0.089380\n",
      "2023-12-09 23:09:31,754 INFO     Training average positive_sample_loss at step 18100: 0.086731\n",
      "2023-12-09 23:09:31,755 INFO     Training average negative_sample_loss at step 18100: 0.089701\n",
      "2023-12-09 23:09:31,755 INFO     Training average loss at step 18100: 0.088216\n",
      "2023-12-09 23:10:50,429 INFO     Training average positive_sample_loss at step 18200: 0.088327\n",
      "2023-12-09 23:10:50,430 INFO     Training average negative_sample_loss at step 18200: 0.090982\n",
      "2023-12-09 23:10:50,430 INFO     Training average loss at step 18200: 0.089654\n",
      "2023-12-09 23:12:07,668 INFO     Training average positive_sample_loss at step 18300: 0.089049\n",
      "2023-12-09 23:12:07,668 INFO     Training average negative_sample_loss at step 18300: 0.090258\n",
      "2023-12-09 23:12:07,668 INFO     Training average loss at step 18300: 0.089654\n",
      "2023-12-09 23:13:27,788 INFO     Training average positive_sample_loss at step 18400: 0.090174\n",
      "2023-12-09 23:13:27,788 INFO     Training average negative_sample_loss at step 18400: 0.092287\n",
      "2023-12-09 23:13:27,788 INFO     Training average loss at step 18400: 0.091231\n",
      "2023-12-09 23:14:46,951 INFO     Training average positive_sample_loss at step 18500: 0.090635\n",
      "2023-12-09 23:14:46,952 INFO     Training average negative_sample_loss at step 18500: 0.093512\n",
      "2023-12-09 23:14:46,952 INFO     Training average loss at step 18500: 0.092073\n",
      "2023-12-09 23:16:05,346 INFO     Training average positive_sample_loss at step 18600: 0.090192\n",
      "2023-12-09 23:16:05,346 INFO     Training average negative_sample_loss at step 18600: 0.093550\n",
      "2023-12-09 23:16:05,346 INFO     Training average loss at step 18600: 0.091871\n",
      "2023-12-09 23:17:24,673 INFO     Training average positive_sample_loss at step 18700: 0.090918\n",
      "2023-12-09 23:17:24,673 INFO     Training average negative_sample_loss at step 18700: 0.092505\n",
      "2023-12-09 23:17:24,673 INFO     Training average loss at step 18700: 0.091712\n",
      "2023-12-09 23:18:43,347 INFO     Training average positive_sample_loss at step 18800: 0.090331\n",
      "2023-12-09 23:18:43,347 INFO     Training average negative_sample_loss at step 18800: 0.093651\n",
      "2023-12-09 23:18:43,347 INFO     Training average loss at step 18800: 0.091991\n",
      "2023-12-09 23:20:08,423 INFO     Training average positive_sample_loss at step 18900: 0.088386\n",
      "2023-12-09 23:20:08,423 INFO     Training average negative_sample_loss at step 18900: 0.093220\n",
      "2023-12-09 23:20:08,424 INFO     Training average loss at step 18900: 0.090803\n",
      "2023-12-09 23:21:30,985 INFO     Training average positive_sample_loss at step 19000: 0.085362\n",
      "2023-12-09 23:21:30,986 INFO     Training average negative_sample_loss at step 19000: 0.088667\n",
      "2023-12-09 23:21:30,986 INFO     Training average loss at step 19000: 0.087014\n",
      "2023-12-09 23:22:49,918 INFO     Training average positive_sample_loss at step 19100: 0.086841\n",
      "2023-12-09 23:22:49,919 INFO     Training average negative_sample_loss at step 19100: 0.088512\n",
      "2023-12-09 23:22:49,919 INFO     Training average loss at step 19100: 0.087677\n",
      "2023-12-09 23:24:07,626 INFO     Training average positive_sample_loss at step 19200: 0.088547\n",
      "2023-12-09 23:24:07,627 INFO     Training average negative_sample_loss at step 19200: 0.090008\n",
      "2023-12-09 23:24:07,627 INFO     Training average loss at step 19200: 0.089278\n",
      "2023-12-09 23:25:23,679 INFO     Training average positive_sample_loss at step 19300: 0.088414\n",
      "2023-12-09 23:25:23,679 INFO     Training average negative_sample_loss at step 19300: 0.090374\n",
      "2023-12-09 23:25:23,679 INFO     Training average loss at step 19300: 0.089394\n",
      "2023-12-09 23:26:40,276 INFO     Training average positive_sample_loss at step 19400: 0.089127\n",
      "2023-12-09 23:26:40,276 INFO     Training average negative_sample_loss at step 19400: 0.091361\n",
      "2023-12-09 23:26:40,277 INFO     Training average loss at step 19400: 0.090244\n",
      "2023-12-09 23:27:56,316 INFO     Training average positive_sample_loss at step 19500: 0.089975\n",
      "2023-12-09 23:27:56,317 INFO     Training average negative_sample_loss at step 19500: 0.092577\n",
      "2023-12-09 23:27:56,317 INFO     Training average loss at step 19500: 0.091276\n",
      "2023-12-09 23:29:12,296 INFO     Training average positive_sample_loss at step 19600: 0.090357\n",
      "2023-12-09 23:29:12,296 INFO     Training average negative_sample_loss at step 19600: 0.092865\n",
      "2023-12-09 23:29:12,296 INFO     Training average loss at step 19600: 0.091611\n",
      "2023-12-09 23:30:30,323 INFO     Training average positive_sample_loss at step 19700: 0.090329\n",
      "2023-12-09 23:30:30,323 INFO     Training average negative_sample_loss at step 19700: 0.093084\n",
      "2023-12-09 23:30:30,323 INFO     Training average loss at step 19700: 0.091707\n",
      "2023-12-09 23:31:53,731 INFO     Training average positive_sample_loss at step 19800: 0.089746\n",
      "2023-12-09 23:31:53,731 INFO     Training average negative_sample_loss at step 19800: 0.093102\n",
      "2023-12-09 23:31:53,731 INFO     Training average loss at step 19800: 0.091424\n",
      "2023-12-09 23:33:27,485 INFO     Training average positive_sample_loss at step 19900: 0.084923\n",
      "2023-12-09 23:33:27,486 INFO     Training average negative_sample_loss at step 19900: 0.090640\n",
      "2023-12-09 23:33:27,486 INFO     Training average loss at step 19900: 0.087781\n",
      "2023-12-09 23:35:01,578 INFO     Training average positive_sample_loss at step 20000: 0.085407\n",
      "2023-12-09 23:35:01,578 INFO     Training average negative_sample_loss at step 20000: 0.086952\n",
      "2023-12-09 23:35:01,578 INFO     Training average loss at step 20000: 0.086180\n",
      "2023-12-09 23:35:01,578 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 23:35:02,448 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-09 23:35:29,604 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-09 23:35:57,568 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-09 23:36:25,743 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-09 23:36:54,512 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-09 23:37:22,693 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-09 23:37:52,017 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-09 23:37:58,609 INFO     Valid MRR at step 20000: 0.745114\n",
      "2023-12-09 23:37:58,609 INFO     Valid MR at step 20000: 49.518200\n",
      "2023-12-09 23:37:58,609 INFO     Valid HITS@1 at step 20000: 0.679830\n",
      "2023-12-09 23:37:58,609 INFO     Valid HITS@3 at step 20000: 0.787190\n",
      "2023-12-09 23:37:58,609 INFO     Valid HITS@10 at step 20000: 0.857030\n",
      "2023-12-09 23:39:03,542 INFO     Training average positive_sample_loss at step 20100: 0.087130\n",
      "2023-12-09 23:39:03,542 INFO     Training average negative_sample_loss at step 20100: 0.089562\n",
      "2023-12-09 23:39:03,542 INFO     Training average loss at step 20100: 0.088346\n",
      "2023-12-09 23:40:20,535 INFO     Training average positive_sample_loss at step 20200: 0.087695\n",
      "2023-12-09 23:40:20,535 INFO     Training average negative_sample_loss at step 20200: 0.089453\n",
      "2023-12-09 23:40:20,535 INFO     Training average loss at step 20200: 0.088574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 23:41:37,723 INFO     Training average positive_sample_loss at step 20300: 0.089481\n",
      "2023-12-09 23:41:37,724 INFO     Training average negative_sample_loss at step 20300: 0.092016\n",
      "2023-12-09 23:41:37,724 INFO     Training average loss at step 20300: 0.090749\n",
      "2023-12-09 23:42:55,885 INFO     Training average positive_sample_loss at step 20400: 0.089067\n",
      "2023-12-09 23:42:55,885 INFO     Training average negative_sample_loss at step 20400: 0.089761\n",
      "2023-12-09 23:42:55,886 INFO     Training average loss at step 20400: 0.089414\n",
      "2023-12-09 23:44:14,041 INFO     Training average positive_sample_loss at step 20500: 0.088780\n",
      "2023-12-09 23:44:14,041 INFO     Training average negative_sample_loss at step 20500: 0.091320\n",
      "2023-12-09 23:44:14,041 INFO     Training average loss at step 20500: 0.090050\n",
      "2023-12-09 23:45:34,677 INFO     Training average positive_sample_loss at step 20600: 0.090121\n",
      "2023-12-09 23:45:34,677 INFO     Training average negative_sample_loss at step 20600: 0.092205\n",
      "2023-12-09 23:45:34,677 INFO     Training average loss at step 20600: 0.091163\n",
      "2023-12-09 23:46:56,905 INFO     Training average positive_sample_loss at step 20700: 0.090033\n",
      "2023-12-09 23:46:56,905 INFO     Training average negative_sample_loss at step 20700: 0.092476\n",
      "2023-12-09 23:46:56,905 INFO     Training average loss at step 20700: 0.091255\n",
      "2023-12-09 23:48:30,255 INFO     Training average positive_sample_loss at step 20800: 0.086093\n",
      "2023-12-09 23:48:30,255 INFO     Training average negative_sample_loss at step 20800: 0.090633\n",
      "2023-12-09 23:48:30,255 INFO     Training average loss at step 20800: 0.088363\n",
      "2023-12-09 23:49:46,001 INFO     Training average positive_sample_loss at step 20900: 0.084084\n",
      "2023-12-09 23:49:46,001 INFO     Training average negative_sample_loss at step 20900: 0.086282\n",
      "2023-12-09 23:49:46,001 INFO     Training average loss at step 20900: 0.085183\n",
      "2023-12-09 23:51:02,210 INFO     Training average positive_sample_loss at step 21000: 0.085669\n",
      "2023-12-09 23:51:02,211 INFO     Training average negative_sample_loss at step 21000: 0.088654\n",
      "2023-12-09 23:51:02,211 INFO     Training average loss at step 21000: 0.087161\n",
      "2023-12-09 23:52:22,122 INFO     Training average positive_sample_loss at step 21100: 0.087304\n",
      "2023-12-09 23:52:22,122 INFO     Training average negative_sample_loss at step 21100: 0.088622\n",
      "2023-12-09 23:52:22,122 INFO     Training average loss at step 21100: 0.087963\n",
      "2023-12-09 23:53:39,213 INFO     Training average positive_sample_loss at step 21200: 0.088007\n",
      "2023-12-09 23:53:39,213 INFO     Training average negative_sample_loss at step 21200: 0.089481\n",
      "2023-12-09 23:53:39,213 INFO     Training average loss at step 21200: 0.088744\n",
      "2023-12-09 23:54:56,262 INFO     Training average positive_sample_loss at step 21300: 0.088437\n",
      "2023-12-09 23:54:56,262 INFO     Training average negative_sample_loss at step 21300: 0.091390\n",
      "2023-12-09 23:54:56,263 INFO     Training average loss at step 21300: 0.089913\n",
      "2023-12-09 23:56:15,341 INFO     Training average positive_sample_loss at step 21400: 0.089339\n",
      "2023-12-09 23:56:15,341 INFO     Training average negative_sample_loss at step 21400: 0.091359\n",
      "2023-12-09 23:56:15,341 INFO     Training average loss at step 21400: 0.090349\n",
      "2023-12-09 23:57:31,318 INFO     Training average positive_sample_loss at step 21500: 0.089238\n",
      "2023-12-09 23:57:31,318 INFO     Training average negative_sample_loss at step 21500: 0.090574\n",
      "2023-12-09 23:57:31,318 INFO     Training average loss at step 21500: 0.089906\n",
      "2023-12-09 23:58:50,823 INFO     Training average positive_sample_loss at step 21600: 0.088571\n",
      "2023-12-09 23:58:50,824 INFO     Training average negative_sample_loss at step 21600: 0.091040\n",
      "2023-12-09 23:58:50,824 INFO     Training average loss at step 21600: 0.089805\n",
      "2023-12-10 00:00:08,397 INFO     Training average positive_sample_loss at step 21700: 0.088850\n",
      "2023-12-10 00:00:08,398 INFO     Training average negative_sample_loss at step 21700: 0.091585\n",
      "2023-12-10 00:00:08,398 INFO     Training average loss at step 21700: 0.090218\n",
      "2023-12-10 00:01:40,014 INFO     Training average positive_sample_loss at step 21800: 0.082847\n",
      "2023-12-10 00:01:40,014 INFO     Training average negative_sample_loss at step 21800: 0.086956\n",
      "2023-12-10 00:01:40,014 INFO     Training average loss at step 21800: 0.084902\n",
      "2023-12-10 00:02:58,748 INFO     Training average positive_sample_loss at step 21900: 0.085016\n",
      "2023-12-10 00:02:58,748 INFO     Training average negative_sample_loss at step 21900: 0.087204\n",
      "2023-12-10 00:02:58,748 INFO     Training average loss at step 21900: 0.086110\n",
      "2023-12-10 00:04:16,375 INFO     Training average positive_sample_loss at step 22000: 0.086730\n",
      "2023-12-10 00:04:16,376 INFO     Training average negative_sample_loss at step 22000: 0.088050\n",
      "2023-12-10 00:04:16,376 INFO     Training average loss at step 22000: 0.087390\n",
      "2023-12-10 00:05:35,077 INFO     Training average positive_sample_loss at step 22100: 0.086530\n",
      "2023-12-10 00:05:35,077 INFO     Training average negative_sample_loss at step 22100: 0.087516\n",
      "2023-12-10 00:05:35,077 INFO     Training average loss at step 22100: 0.087023\n",
      "2023-12-10 00:06:55,475 INFO     Training average positive_sample_loss at step 22200: 0.087615\n",
      "2023-12-10 00:06:55,475 INFO     Training average negative_sample_loss at step 22200: 0.088957\n",
      "2023-12-10 00:06:55,475 INFO     Training average loss at step 22200: 0.088286\n",
      "2023-12-10 00:08:12,708 INFO     Training average positive_sample_loss at step 22300: 0.087735\n",
      "2023-12-10 00:08:12,708 INFO     Training average negative_sample_loss at step 22300: 0.089231\n",
      "2023-12-10 00:08:12,708 INFO     Training average loss at step 22300: 0.088483\n",
      "2023-12-10 00:09:31,372 INFO     Training average positive_sample_loss at step 22400: 0.088190\n",
      "2023-12-10 00:09:31,373 INFO     Training average negative_sample_loss at step 22400: 0.090308\n",
      "2023-12-10 00:09:31,373 INFO     Training average loss at step 22400: 0.089249\n",
      "2023-12-10 00:10:49,811 INFO     Training average positive_sample_loss at step 22500: 0.089023\n",
      "2023-12-10 00:10:49,812 INFO     Training average negative_sample_loss at step 22500: 0.091409\n",
      "2023-12-10 00:10:49,812 INFO     Training average loss at step 22500: 0.090216\n",
      "2023-12-10 00:12:06,892 INFO     Training average positive_sample_loss at step 22600: 0.089381\n",
      "2023-12-10 00:12:06,893 INFO     Training average negative_sample_loss at step 22600: 0.091642\n",
      "2023-12-10 00:12:06,893 INFO     Training average loss at step 22600: 0.090511\n",
      "2023-12-10 00:13:42,145 INFO     Training average positive_sample_loss at step 22700: 0.084786\n",
      "2023-12-10 00:13:42,146 INFO     Training average negative_sample_loss at step 22700: 0.088955\n",
      "2023-12-10 00:13:42,146 INFO     Training average loss at step 22700: 0.086871\n",
      "2023-12-10 00:15:00,977 INFO     Training average positive_sample_loss at step 22800: 0.083709\n",
      "2023-12-10 00:15:00,977 INFO     Training average negative_sample_loss at step 22800: 0.085851\n",
      "2023-12-10 00:15:00,977 INFO     Training average loss at step 22800: 0.084780\n",
      "2023-12-10 00:16:15,577 INFO     Training average positive_sample_loss at step 22900: 0.085532\n",
      "2023-12-10 00:16:15,577 INFO     Training average negative_sample_loss at step 22900: 0.086984\n",
      "2023-12-10 00:16:15,577 INFO     Training average loss at step 22900: 0.086258\n",
      "2023-12-10 00:17:33,604 INFO     Training average positive_sample_loss at step 23000: 0.086350\n",
      "2023-12-10 00:17:33,604 INFO     Training average negative_sample_loss at step 23000: 0.086581\n",
      "2023-12-10 00:17:33,604 INFO     Training average loss at step 23000: 0.086466\n",
      "2023-12-10 00:18:49,619 INFO     Training average positive_sample_loss at step 23100: 0.086948\n",
      "2023-12-10 00:18:49,619 INFO     Training average negative_sample_loss at step 23100: 0.089251\n",
      "2023-12-10 00:18:49,619 INFO     Training average loss at step 23100: 0.088099\n",
      "2023-12-10 00:20:05,487 INFO     Training average positive_sample_loss at step 23200: 0.087353\n",
      "2023-12-10 00:20:05,487 INFO     Training average negative_sample_loss at step 23200: 0.089320\n",
      "2023-12-10 00:20:05,487 INFO     Training average loss at step 23200: 0.088337\n",
      "2023-12-10 00:21:22,576 INFO     Training average positive_sample_loss at step 23300: 0.087777\n",
      "2023-12-10 00:21:22,577 INFO     Training average negative_sample_loss at step 23300: 0.089581\n",
      "2023-12-10 00:21:22,577 INFO     Training average loss at step 23300: 0.088679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:22:40,454 INFO     Training average positive_sample_loss at step 23400: 0.088324\n",
      "2023-12-10 00:22:40,454 INFO     Training average negative_sample_loss at step 23400: 0.090003\n",
      "2023-12-10 00:22:40,454 INFO     Training average loss at step 23400: 0.089164\n",
      "2023-12-10 00:23:59,792 INFO     Training average positive_sample_loss at step 23500: 0.088548\n",
      "2023-12-10 00:23:59,792 INFO     Training average negative_sample_loss at step 23500: 0.089887\n",
      "2023-12-10 00:23:59,792 INFO     Training average loss at step 23500: 0.089218\n",
      "2023-12-10 00:25:24,206 INFO     Training average positive_sample_loss at step 23600: 0.088525\n",
      "2023-12-10 00:25:24,206 INFO     Training average negative_sample_loss at step 23600: 0.091191\n",
      "2023-12-10 00:25:24,206 INFO     Training average loss at step 23600: 0.089858\n",
      "2023-12-10 00:26:43,929 INFO     Training average positive_sample_loss at step 23700: 0.081385\n",
      "2023-12-10 00:26:43,929 INFO     Training average negative_sample_loss at step 23700: 0.086098\n",
      "2023-12-10 00:26:43,929 INFO     Training average loss at step 23700: 0.083742\n",
      "2023-12-10 00:28:04,818 INFO     Training average positive_sample_loss at step 23800: 0.084761\n",
      "2023-12-10 00:28:04,818 INFO     Training average negative_sample_loss at step 23800: 0.085367\n",
      "2023-12-10 00:28:04,818 INFO     Training average loss at step 23800: 0.085064\n",
      "2023-12-10 00:29:24,118 INFO     Training average positive_sample_loss at step 23900: 0.085262\n",
      "2023-12-10 00:29:24,118 INFO     Training average negative_sample_loss at step 23900: 0.085129\n",
      "2023-12-10 00:29:24,118 INFO     Training average loss at step 23900: 0.085196\n",
      "2023-12-10 00:30:46,722 INFO     Training average positive_sample_loss at step 24000: 0.086481\n",
      "2023-12-10 00:30:46,723 INFO     Training average negative_sample_loss at step 24000: 0.087798\n",
      "2023-12-10 00:30:46,723 INFO     Training average loss at step 24000: 0.087139\n",
      "2023-12-10 00:32:06,627 INFO     Training average positive_sample_loss at step 24100: 0.086750\n",
      "2023-12-10 00:32:06,627 INFO     Training average negative_sample_loss at step 24100: 0.088772\n",
      "2023-12-10 00:32:06,627 INFO     Training average loss at step 24100: 0.087761\n",
      "2023-12-10 00:33:25,687 INFO     Training average positive_sample_loss at step 24200: 0.087333\n",
      "2023-12-10 00:33:25,688 INFO     Training average negative_sample_loss at step 24200: 0.089399\n",
      "2023-12-10 00:33:25,688 INFO     Training average loss at step 24200: 0.088366\n",
      "2023-12-10 00:34:44,500 INFO     Training average positive_sample_loss at step 24300: 0.087599\n",
      "2023-12-10 00:34:44,500 INFO     Training average negative_sample_loss at step 24300: 0.088968\n",
      "2023-12-10 00:34:44,500 INFO     Training average loss at step 24300: 0.088283\n",
      "2023-12-10 00:36:03,390 INFO     Training average positive_sample_loss at step 24400: 0.087431\n",
      "2023-12-10 00:36:03,390 INFO     Training average negative_sample_loss at step 24400: 0.089007\n",
      "2023-12-10 00:36:03,390 INFO     Training average loss at step 24400: 0.088219\n",
      "2023-12-10 00:37:23,082 INFO     Training average positive_sample_loss at step 24500: 0.087721\n",
      "2023-12-10 00:37:23,083 INFO     Training average negative_sample_loss at step 24500: 0.088939\n",
      "2023-12-10 00:37:23,083 INFO     Training average loss at step 24500: 0.088330\n",
      "2023-12-10 00:38:53,995 INFO     Training average positive_sample_loss at step 24600: 0.083142\n",
      "2023-12-10 00:38:53,996 INFO     Training average negative_sample_loss at step 24600: 0.088722\n",
      "2023-12-10 00:38:53,996 INFO     Training average loss at step 24600: 0.085932\n",
      "2023-12-10 00:40:12,610 INFO     Training average positive_sample_loss at step 24700: 0.083185\n",
      "2023-12-10 00:40:12,611 INFO     Training average negative_sample_loss at step 24700: 0.085020\n",
      "2023-12-10 00:40:12,611 INFO     Training average loss at step 24700: 0.084102\n",
      "2023-12-10 00:41:30,345 INFO     Training average positive_sample_loss at step 24800: 0.085118\n",
      "2023-12-10 00:41:30,345 INFO     Training average negative_sample_loss at step 24800: 0.086068\n",
      "2023-12-10 00:41:30,345 INFO     Training average loss at step 24800: 0.085593\n",
      "2023-12-10 00:42:48,173 INFO     Training average positive_sample_loss at step 24900: 0.085289\n",
      "2023-12-10 00:42:48,174 INFO     Training average negative_sample_loss at step 24900: 0.085365\n",
      "2023-12-10 00:42:48,174 INFO     Training average loss at step 24900: 0.085327\n",
      "2023-12-10 00:44:07,382 INFO     Training average positive_sample_loss at step 25000: 0.086489\n",
      "2023-12-10 00:44:07,383 INFO     Training average negative_sample_loss at step 25000: 0.087449\n",
      "2023-12-10 00:44:07,383 INFO     Training average loss at step 25000: 0.086969\n",
      "2023-12-10 00:45:25,520 INFO     Training average positive_sample_loss at step 25100: 0.086277\n",
      "2023-12-10 00:45:25,520 INFO     Training average negative_sample_loss at step 25100: 0.088054\n",
      "2023-12-10 00:45:25,520 INFO     Training average loss at step 25100: 0.087166\n",
      "2023-12-10 00:46:45,819 INFO     Training average positive_sample_loss at step 25200: 0.087000\n",
      "2023-12-10 00:46:45,819 INFO     Training average negative_sample_loss at step 25200: 0.089327\n",
      "2023-12-10 00:46:45,820 INFO     Training average loss at step 25200: 0.088164\n",
      "2023-12-10 00:48:02,573 INFO     Training average positive_sample_loss at step 25300: 0.088125\n",
      "2023-12-10 00:48:02,573 INFO     Training average negative_sample_loss at step 25300: 0.089995\n",
      "2023-12-10 00:48:02,573 INFO     Training average loss at step 25300: 0.089060\n",
      "2023-12-10 00:49:20,201 INFO     Training average positive_sample_loss at step 25400: 0.087610\n",
      "2023-12-10 00:49:20,201 INFO     Training average negative_sample_loss at step 25400: 0.089320\n",
      "2023-12-10 00:49:20,201 INFO     Training average loss at step 25400: 0.088465\n",
      "2023-12-10 00:50:49,856 INFO     Training average positive_sample_loss at step 25500: 0.086720\n",
      "2023-12-10 00:50:49,857 INFO     Training average negative_sample_loss at step 25500: 0.089941\n",
      "2023-12-10 00:50:49,857 INFO     Training average loss at step 25500: 0.088331\n",
      "2023-12-10 00:52:10,392 INFO     Training average positive_sample_loss at step 25600: 0.081620\n",
      "2023-12-10 00:52:10,393 INFO     Training average negative_sample_loss at step 25600: 0.083487\n",
      "2023-12-10 00:52:10,393 INFO     Training average loss at step 25600: 0.082553\n",
      "2023-12-10 00:53:30,122 INFO     Training average positive_sample_loss at step 25700: 0.084100\n",
      "2023-12-10 00:53:30,123 INFO     Training average negative_sample_loss at step 25700: 0.086723\n",
      "2023-12-10 00:53:30,123 INFO     Training average loss at step 25700: 0.085412\n",
      "2023-12-10 00:54:49,622 INFO     Training average positive_sample_loss at step 25800: 0.085361\n",
      "2023-12-10 00:54:49,622 INFO     Training average negative_sample_loss at step 25800: 0.086068\n",
      "2023-12-10 00:54:49,622 INFO     Training average loss at step 25800: 0.085715\n",
      "2023-12-10 00:56:08,167 INFO     Training average positive_sample_loss at step 25900: 0.086078\n",
      "2023-12-10 00:56:08,168 INFO     Training average negative_sample_loss at step 25900: 0.087857\n",
      "2023-12-10 00:56:08,168 INFO     Training average loss at step 25900: 0.086967\n",
      "2023-12-10 00:57:28,383 INFO     Training average positive_sample_loss at step 26000: 0.086593\n",
      "2023-12-10 00:57:28,383 INFO     Training average negative_sample_loss at step 26000: 0.087363\n",
      "2023-12-10 00:57:28,383 INFO     Training average loss at step 26000: 0.086978\n",
      "2023-12-10 00:58:46,595 INFO     Training average positive_sample_loss at step 26100: 0.087108\n",
      "2023-12-10 00:58:46,596 INFO     Training average negative_sample_loss at step 26100: 0.088812\n",
      "2023-12-10 00:58:46,596 INFO     Training average loss at step 26100: 0.087960\n",
      "2023-12-10 01:00:03,934 INFO     Training average positive_sample_loss at step 26200: 0.086736\n",
      "2023-12-10 01:00:03,934 INFO     Training average negative_sample_loss at step 26200: 0.087089\n",
      "2023-12-10 01:00:03,935 INFO     Training average loss at step 26200: 0.086912\n",
      "2023-12-10 01:01:18,898 INFO     Training average positive_sample_loss at step 26300: 0.087127\n",
      "2023-12-10 01:01:18,898 INFO     Training average negative_sample_loss at step 26300: 0.090258\n",
      "2023-12-10 01:01:18,898 INFO     Training average loss at step 26300: 0.088692\n",
      "2023-12-10 01:02:38,006 INFO     Training average positive_sample_loss at step 26400: 0.087628\n",
      "2023-12-10 01:02:38,006 INFO     Training average negative_sample_loss at step 26400: 0.089602\n",
      "2023-12-10 01:02:38,006 INFO     Training average loss at step 26400: 0.088615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:04:05,646 INFO     Training average positive_sample_loss at step 26500: 0.081502\n",
      "2023-12-10 01:04:05,647 INFO     Training average negative_sample_loss at step 26500: 0.085892\n",
      "2023-12-10 01:04:05,647 INFO     Training average loss at step 26500: 0.083697\n",
      "2023-12-10 01:05:23,886 INFO     Training average positive_sample_loss at step 26600: 0.083447\n",
      "2023-12-10 01:05:23,886 INFO     Training average negative_sample_loss at step 26600: 0.084155\n",
      "2023-12-10 01:05:23,886 INFO     Training average loss at step 26600: 0.083801\n",
      "2023-12-10 01:06:45,297 INFO     Training average positive_sample_loss at step 26700: 0.084185\n",
      "2023-12-10 01:06:45,297 INFO     Training average negative_sample_loss at step 26700: 0.085482\n",
      "2023-12-10 01:06:45,297 INFO     Training average loss at step 26700: 0.084833\n",
      "2023-12-10 01:08:02,848 INFO     Training average positive_sample_loss at step 26800: 0.084823\n",
      "2023-12-10 01:08:02,848 INFO     Training average negative_sample_loss at step 26800: 0.085728\n",
      "2023-12-10 01:08:02,848 INFO     Training average loss at step 26800: 0.085275\n",
      "2023-12-10 01:09:22,495 INFO     Training average positive_sample_loss at step 26900: 0.086053\n",
      "2023-12-10 01:09:22,495 INFO     Training average negative_sample_loss at step 26900: 0.087093\n",
      "2023-12-10 01:09:22,495 INFO     Training average loss at step 26900: 0.086573\n",
      "2023-12-10 01:10:39,530 INFO     Training average positive_sample_loss at step 27000: 0.086492\n",
      "2023-12-10 01:10:39,531 INFO     Training average negative_sample_loss at step 27000: 0.087731\n",
      "2023-12-10 01:10:39,531 INFO     Training average loss at step 27000: 0.087112\n",
      "2023-12-10 01:11:56,501 INFO     Training average positive_sample_loss at step 27100: 0.086512\n",
      "2023-12-10 01:11:56,501 INFO     Training average negative_sample_loss at step 27100: 0.087626\n",
      "2023-12-10 01:11:56,501 INFO     Training average loss at step 27100: 0.087069\n",
      "2023-12-10 01:13:17,732 INFO     Training average positive_sample_loss at step 27200: 0.086470\n",
      "2023-12-10 01:13:17,732 INFO     Training average negative_sample_loss at step 27200: 0.087226\n",
      "2023-12-10 01:13:17,732 INFO     Training average loss at step 27200: 0.086848\n",
      "2023-12-10 01:14:33,184 INFO     Training average positive_sample_loss at step 27300: 0.087037\n",
      "2023-12-10 01:14:33,184 INFO     Training average negative_sample_loss at step 27300: 0.088891\n",
      "2023-12-10 01:14:33,184 INFO     Training average loss at step 27300: 0.087964\n",
      "2023-12-10 01:16:07,394 INFO     Training average positive_sample_loss at step 27400: 0.083950\n",
      "2023-12-10 01:16:07,394 INFO     Training average negative_sample_loss at step 27400: 0.087632\n",
      "2023-12-10 01:16:07,395 INFO     Training average loss at step 27400: 0.085791\n",
      "2023-12-10 01:17:25,706 INFO     Training average positive_sample_loss at step 27500: 0.081311\n",
      "2023-12-10 01:17:25,706 INFO     Training average negative_sample_loss at step 27500: 0.082447\n",
      "2023-12-10 01:17:25,706 INFO     Training average loss at step 27500: 0.081879\n",
      "2023-12-10 01:18:50,117 INFO     Training average positive_sample_loss at step 27600: 0.083079\n",
      "2023-12-10 01:18:50,117 INFO     Training average negative_sample_loss at step 27600: 0.084252\n",
      "2023-12-10 01:18:50,117 INFO     Training average loss at step 27600: 0.083665\n",
      "2023-12-10 01:20:07,950 INFO     Training average positive_sample_loss at step 27700: 0.084729\n",
      "2023-12-10 01:20:07,950 INFO     Training average negative_sample_loss at step 27700: 0.084861\n",
      "2023-12-10 01:20:07,950 INFO     Training average loss at step 27700: 0.084795\n",
      "2023-12-10 01:21:26,989 INFO     Training average positive_sample_loss at step 27800: 0.085156\n",
      "2023-12-10 01:21:26,989 INFO     Training average negative_sample_loss at step 27800: 0.085659\n",
      "2023-12-10 01:21:26,990 INFO     Training average loss at step 27800: 0.085408\n",
      "2023-12-10 01:22:45,632 INFO     Training average positive_sample_loss at step 27900: 0.085225\n",
      "2023-12-10 01:22:45,632 INFO     Training average negative_sample_loss at step 27900: 0.086570\n",
      "2023-12-10 01:22:45,632 INFO     Training average loss at step 27900: 0.085897\n",
      "2023-12-10 01:24:06,085 INFO     Training average positive_sample_loss at step 28000: 0.086238\n",
      "2023-12-10 01:24:06,085 INFO     Training average negative_sample_loss at step 28000: 0.087325\n",
      "2023-12-10 01:24:06,086 INFO     Training average loss at step 28000: 0.086782\n",
      "2023-12-10 01:25:22,924 INFO     Training average positive_sample_loss at step 28100: 0.086751\n",
      "2023-12-10 01:25:22,924 INFO     Training average negative_sample_loss at step 28100: 0.088100\n",
      "2023-12-10 01:25:22,924 INFO     Training average loss at step 28100: 0.087426\n",
      "2023-12-10 01:26:38,965 INFO     Training average positive_sample_loss at step 28200: 0.085772\n",
      "2023-12-10 01:26:38,965 INFO     Training average negative_sample_loss at step 28200: 0.087298\n",
      "2023-12-10 01:26:38,965 INFO     Training average loss at step 28200: 0.086535\n",
      "2023-12-10 01:27:58,411 INFO     Training average positive_sample_loss at step 28300: 0.087002\n",
      "2023-12-10 01:27:58,412 INFO     Training average negative_sample_loss at step 28300: 0.087787\n",
      "2023-12-10 01:27:58,412 INFO     Training average loss at step 28300: 0.087394\n",
      "2023-12-10 01:29:25,796 INFO     Training average positive_sample_loss at step 28400: 0.081087\n",
      "2023-12-10 01:29:25,796 INFO     Training average negative_sample_loss at step 28400: 0.085204\n",
      "2023-12-10 01:29:25,796 INFO     Training average loss at step 28400: 0.083146\n",
      "2023-12-10 01:30:44,491 INFO     Training average positive_sample_loss at step 28500: 0.082375\n",
      "2023-12-10 01:30:44,491 INFO     Training average negative_sample_loss at step 28500: 0.083456\n",
      "2023-12-10 01:30:44,491 INFO     Training average loss at step 28500: 0.082915\n",
      "2023-12-10 01:32:02,788 INFO     Training average positive_sample_loss at step 28600: 0.083940\n",
      "2023-12-10 01:32:02,789 INFO     Training average negative_sample_loss at step 28600: 0.084395\n",
      "2023-12-10 01:32:02,789 INFO     Training average loss at step 28600: 0.084167\n",
      "2023-12-10 01:33:22,595 INFO     Training average positive_sample_loss at step 28700: 0.084441\n",
      "2023-12-10 01:33:22,596 INFO     Training average negative_sample_loss at step 28700: 0.084351\n",
      "2023-12-10 01:33:22,596 INFO     Training average loss at step 28700: 0.084396\n",
      "2023-12-10 01:34:39,161 INFO     Training average positive_sample_loss at step 28800: 0.085272\n",
      "2023-12-10 01:34:39,161 INFO     Training average negative_sample_loss at step 28800: 0.085970\n",
      "2023-12-10 01:34:39,161 INFO     Training average loss at step 28800: 0.085621\n",
      "2023-12-10 01:35:55,734 INFO     Training average positive_sample_loss at step 28900: 0.085759\n",
      "2023-12-10 01:35:55,734 INFO     Training average negative_sample_loss at step 28900: 0.087149\n",
      "2023-12-10 01:35:55,734 INFO     Training average loss at step 28900: 0.086454\n",
      "2023-12-10 01:37:14,817 INFO     Training average positive_sample_loss at step 29000: 0.085594\n",
      "2023-12-10 01:37:14,818 INFO     Training average negative_sample_loss at step 29000: 0.086200\n",
      "2023-12-10 01:37:14,818 INFO     Training average loss at step 29000: 0.085897\n",
      "2023-12-10 01:38:35,540 INFO     Training average positive_sample_loss at step 29100: 0.085914\n",
      "2023-12-10 01:38:35,541 INFO     Training average negative_sample_loss at step 29100: 0.087171\n",
      "2023-12-10 01:38:35,541 INFO     Training average loss at step 29100: 0.086542\n",
      "2023-12-10 01:39:56,951 INFO     Training average positive_sample_loss at step 29200: 0.086483\n",
      "2023-12-10 01:39:56,951 INFO     Training average negative_sample_loss at step 29200: 0.088939\n",
      "2023-12-10 01:39:56,951 INFO     Training average loss at step 29200: 0.087711\n",
      "2023-12-10 01:41:33,287 INFO     Training average positive_sample_loss at step 29300: 0.083392\n",
      "2023-12-10 01:41:33,288 INFO     Training average negative_sample_loss at step 29300: 0.086718\n",
      "2023-12-10 01:41:33,288 INFO     Training average loss at step 29300: 0.085055\n",
      "2023-12-10 01:42:51,287 INFO     Training average positive_sample_loss at step 29400: 0.081895\n",
      "2023-12-10 01:42:51,287 INFO     Training average negative_sample_loss at step 29400: 0.083190\n",
      "2023-12-10 01:42:51,287 INFO     Training average loss at step 29400: 0.082543\n",
      "2023-12-10 01:44:08,787 INFO     Training average positive_sample_loss at step 29500: 0.083093\n",
      "2023-12-10 01:44:08,788 INFO     Training average negative_sample_loss at step 29500: 0.083882\n",
      "2023-12-10 01:44:08,788 INFO     Training average loss at step 29500: 0.083487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:45:24,949 INFO     Training average positive_sample_loss at step 29600: 0.083755\n",
      "2023-12-10 01:45:24,949 INFO     Training average negative_sample_loss at step 29600: 0.084647\n",
      "2023-12-10 01:45:24,949 INFO     Training average loss at step 29600: 0.084201\n",
      "2023-12-10 01:46:45,454 INFO     Training average positive_sample_loss at step 29700: 0.084615\n",
      "2023-12-10 01:46:45,455 INFO     Training average negative_sample_loss at step 29700: 0.084943\n",
      "2023-12-10 01:46:45,455 INFO     Training average loss at step 29700: 0.084779\n",
      "2023-12-10 01:48:02,131 INFO     Training average positive_sample_loss at step 29800: 0.085314\n",
      "2023-12-10 01:48:02,131 INFO     Training average negative_sample_loss at step 29800: 0.085315\n",
      "2023-12-10 01:48:02,131 INFO     Training average loss at step 29800: 0.085314\n",
      "2023-12-10 01:49:18,023 INFO     Training average positive_sample_loss at step 29900: 0.085217\n",
      "2023-12-10 01:49:18,023 INFO     Training average negative_sample_loss at step 29900: 0.085958\n",
      "2023-12-10 01:49:18,024 INFO     Training average loss at step 29900: 0.085587\n",
      "2023-12-10 01:50:46,247 INFO     Training average positive_sample_loss at step 30000: 0.085936\n",
      "2023-12-10 01:50:46,247 INFO     Training average negative_sample_loss at step 30000: 0.086257\n",
      "2023-12-10 01:50:46,248 INFO     Training average loss at step 30000: 0.086096\n",
      "2023-12-10 01:50:46,248 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 01:50:47,081 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 01:51:15,513 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 01:51:44,055 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 01:52:12,635 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 01:52:43,138 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 01:53:11,571 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 01:53:40,796 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 01:53:47,661 INFO     Valid MRR at step 30000: 0.742350\n",
      "2023-12-10 01:53:47,662 INFO     Valid MR at step 30000: 48.307600\n",
      "2023-12-10 01:53:47,662 INFO     Valid HITS@1 at step 30000: 0.677680\n",
      "2023-12-10 01:53:47,662 INFO     Valid HITS@3 at step 30000: 0.783300\n",
      "2023-12-10 01:53:47,662 INFO     Valid HITS@10 at step 30000: 0.856190\n",
      "2023-12-10 01:54:50,529 INFO     Training average positive_sample_loss at step 30100: 0.085436\n",
      "2023-12-10 01:54:50,529 INFO     Training average negative_sample_loss at step 30100: 0.086289\n",
      "2023-12-10 01:54:50,529 INFO     Training average loss at step 30100: 0.085862\n",
      "2023-12-10 01:56:07,987 INFO     Training average positive_sample_loss at step 30200: 0.086258\n",
      "2023-12-10 01:56:07,987 INFO     Training average negative_sample_loss at step 30200: 0.087159\n",
      "2023-12-10 01:56:07,987 INFO     Training average loss at step 30200: 0.086708\n",
      "2023-12-10 01:57:43,198 INFO     Training average positive_sample_loss at step 30300: 0.080244\n",
      "2023-12-10 01:57:43,199 INFO     Training average negative_sample_loss at step 30300: 0.083830\n",
      "2023-12-10 01:57:43,199 INFO     Training average loss at step 30300: 0.082037\n",
      "2023-12-10 01:59:00,440 INFO     Training average positive_sample_loss at step 30400: 0.081984\n",
      "2023-12-10 01:59:00,440 INFO     Training average negative_sample_loss at step 30400: 0.082918\n",
      "2023-12-10 01:59:00,440 INFO     Training average loss at step 30400: 0.082451\n",
      "2023-12-10 02:00:16,729 INFO     Training average positive_sample_loss at step 30500: 0.083465\n",
      "2023-12-10 02:00:16,729 INFO     Training average negative_sample_loss at step 30500: 0.083863\n",
      "2023-12-10 02:00:16,729 INFO     Training average loss at step 30500: 0.083664\n",
      "2023-12-10 02:01:31,674 INFO     Training average positive_sample_loss at step 30600: 0.083842\n",
      "2023-12-10 02:01:31,675 INFO     Training average negative_sample_loss at step 30600: 0.084266\n",
      "2023-12-10 02:01:31,675 INFO     Training average loss at step 30600: 0.084054\n",
      "2023-12-10 02:02:46,876 INFO     Training average positive_sample_loss at step 30700: 0.084966\n",
      "2023-12-10 02:02:46,876 INFO     Training average negative_sample_loss at step 30700: 0.085823\n",
      "2023-12-10 02:02:46,876 INFO     Training average loss at step 30700: 0.085394\n",
      "2023-12-10 02:04:03,508 INFO     Training average positive_sample_loss at step 30800: 0.084870\n",
      "2023-12-10 02:04:03,508 INFO     Training average negative_sample_loss at step 30800: 0.085296\n",
      "2023-12-10 02:04:03,508 INFO     Training average loss at step 30800: 0.085083\n",
      "2023-12-10 02:05:25,267 INFO     Training average positive_sample_loss at step 30900: 0.085754\n",
      "2023-12-10 02:05:25,267 INFO     Training average negative_sample_loss at step 30900: 0.086669\n",
      "2023-12-10 02:05:25,267 INFO     Training average loss at step 30900: 0.086211\n",
      "2023-12-10 02:06:41,174 INFO     Training average positive_sample_loss at step 31000: 0.085447\n",
      "2023-12-10 02:06:41,175 INFO     Training average negative_sample_loss at step 31000: 0.086179\n",
      "2023-12-10 02:06:41,175 INFO     Training average loss at step 31000: 0.085813\n",
      "2023-12-10 02:07:58,603 INFO     Training average positive_sample_loss at step 31100: 0.085873\n",
      "2023-12-10 02:07:58,603 INFO     Training average negative_sample_loss at step 31100: 0.086551\n",
      "2023-12-10 02:07:58,604 INFO     Training average loss at step 31100: 0.086212\n",
      "2023-12-10 02:09:29,466 INFO     Training average positive_sample_loss at step 31200: 0.081572\n",
      "2023-12-10 02:09:29,466 INFO     Training average negative_sample_loss at step 31200: 0.084309\n",
      "2023-12-10 02:09:29,466 INFO     Training average loss at step 31200: 0.082941\n",
      "2023-12-10 02:10:46,001 INFO     Training average positive_sample_loss at step 31300: 0.081582\n",
      "2023-12-10 02:10:46,001 INFO     Training average negative_sample_loss at step 31300: 0.082668\n",
      "2023-12-10 02:10:46,001 INFO     Training average loss at step 31300: 0.082125\n",
      "2023-12-10 02:12:01,947 INFO     Training average positive_sample_loss at step 31400: 0.082465\n",
      "2023-12-10 02:12:01,947 INFO     Training average negative_sample_loss at step 31400: 0.082637\n",
      "2023-12-10 02:12:01,947 INFO     Training average loss at step 31400: 0.082551\n",
      "2023-12-10 02:13:20,649 INFO     Training average positive_sample_loss at step 31500: 0.083883\n",
      "2023-12-10 02:13:20,649 INFO     Training average negative_sample_loss at step 31500: 0.084442\n",
      "2023-12-10 02:13:20,649 INFO     Training average loss at step 31500: 0.084162\n",
      "2023-12-10 02:14:38,046 INFO     Training average positive_sample_loss at step 31600: 0.083637\n",
      "2023-12-10 02:14:38,046 INFO     Training average negative_sample_loss at step 31600: 0.084127\n",
      "2023-12-10 02:14:38,046 INFO     Training average loss at step 31600: 0.083882\n",
      "2023-12-10 02:15:55,679 INFO     Training average positive_sample_loss at step 31700: 0.084202\n",
      "2023-12-10 02:15:55,680 INFO     Training average negative_sample_loss at step 31700: 0.084996\n",
      "2023-12-10 02:15:55,680 INFO     Training average loss at step 31700: 0.084599\n",
      "2023-12-10 02:17:15,279 INFO     Training average positive_sample_loss at step 31800: 0.085529\n",
      "2023-12-10 02:17:15,279 INFO     Training average negative_sample_loss at step 31800: 0.085982\n",
      "2023-12-10 02:17:15,279 INFO     Training average loss at step 31800: 0.085756\n",
      "2023-12-10 02:18:34,887 INFO     Training average positive_sample_loss at step 31900: 0.085588\n",
      "2023-12-10 02:18:34,887 INFO     Training average negative_sample_loss at step 31900: 0.086111\n",
      "2023-12-10 02:18:34,888 INFO     Training average loss at step 31900: 0.085849\n",
      "2023-12-10 02:19:51,971 INFO     Training average positive_sample_loss at step 32000: 0.085151\n",
      "2023-12-10 02:19:51,971 INFO     Training average negative_sample_loss at step 32000: 0.085780\n",
      "2023-12-10 02:19:51,971 INFO     Training average loss at step 32000: 0.085465\n",
      "2023-12-10 02:21:18,750 INFO     Training average positive_sample_loss at step 32100: 0.085046\n",
      "2023-12-10 02:21:18,750 INFO     Training average negative_sample_loss at step 32100: 0.086944\n",
      "2023-12-10 02:21:18,750 INFO     Training average loss at step 32100: 0.085995\n",
      "2023-12-10 02:22:38,965 INFO     Training average positive_sample_loss at step 32200: 0.080080\n",
      "2023-12-10 02:22:38,965 INFO     Training average negative_sample_loss at step 32200: 0.082095\n",
      "2023-12-10 02:22:38,965 INFO     Training average loss at step 32200: 0.081087\n",
      "2023-12-10 02:23:59,082 INFO     Training average positive_sample_loss at step 32300: 0.081641\n",
      "2023-12-10 02:23:59,083 INFO     Training average negative_sample_loss at step 32300: 0.082105\n",
      "2023-12-10 02:23:59,083 INFO     Training average loss at step 32300: 0.081873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 02:25:17,159 INFO     Training average positive_sample_loss at step 32400: 0.082792\n",
      "2023-12-10 02:25:17,159 INFO     Training average negative_sample_loss at step 32400: 0.082237\n",
      "2023-12-10 02:25:17,160 INFO     Training average loss at step 32400: 0.082515\n",
      "2023-12-10 02:26:36,249 INFO     Training average positive_sample_loss at step 32500: 0.083173\n",
      "2023-12-10 02:26:36,249 INFO     Training average negative_sample_loss at step 32500: 0.083602\n",
      "2023-12-10 02:26:36,249 INFO     Training average loss at step 32500: 0.083388\n",
      "2023-12-10 02:27:57,046 INFO     Training average positive_sample_loss at step 32600: 0.084053\n",
      "2023-12-10 02:27:57,046 INFO     Training average negative_sample_loss at step 32600: 0.082860\n",
      "2023-12-10 02:27:57,046 INFO     Training average loss at step 32600: 0.083457\n",
      "2023-12-10 02:29:14,034 INFO     Training average positive_sample_loss at step 32700: 0.083770\n",
      "2023-12-10 02:29:14,035 INFO     Training average negative_sample_loss at step 32700: 0.084083\n",
      "2023-12-10 02:29:14,035 INFO     Training average loss at step 32700: 0.083926\n",
      "2023-12-10 02:30:33,969 INFO     Training average positive_sample_loss at step 32800: 0.084429\n",
      "2023-12-10 02:30:33,969 INFO     Training average negative_sample_loss at step 32800: 0.085888\n",
      "2023-12-10 02:30:33,969 INFO     Training average loss at step 32800: 0.085158\n",
      "2023-12-10 02:31:52,775 INFO     Training average positive_sample_loss at step 32900: 0.085441\n",
      "2023-12-10 02:31:52,776 INFO     Training average negative_sample_loss at step 32900: 0.086061\n",
      "2023-12-10 02:31:52,776 INFO     Training average loss at step 32900: 0.085751\n",
      "2023-12-10 02:33:12,092 INFO     Training average positive_sample_loss at step 33000: 0.085200\n",
      "2023-12-10 02:33:12,093 INFO     Training average negative_sample_loss at step 33000: 0.085665\n",
      "2023-12-10 02:33:12,093 INFO     Training average loss at step 33000: 0.085433\n",
      "2023-12-10 02:34:44,006 INFO     Training average positive_sample_loss at step 33100: 0.080721\n",
      "2023-12-10 02:34:44,006 INFO     Training average negative_sample_loss at step 33100: 0.083829\n",
      "2023-12-10 02:34:44,006 INFO     Training average loss at step 33100: 0.082275\n",
      "2023-12-10 02:36:00,066 INFO     Training average positive_sample_loss at step 33200: 0.081008\n",
      "2023-12-10 02:36:00,067 INFO     Training average negative_sample_loss at step 33200: 0.081057\n",
      "2023-12-10 02:36:00,067 INFO     Training average loss at step 33200: 0.081033\n",
      "2023-12-10 02:37:17,318 INFO     Training average positive_sample_loss at step 33300: 0.082804\n",
      "2023-12-10 02:37:17,319 INFO     Training average negative_sample_loss at step 33300: 0.083629\n",
      "2023-12-10 02:37:17,319 INFO     Training average loss at step 33300: 0.083216\n",
      "2023-12-10 02:38:34,025 INFO     Training average positive_sample_loss at step 33400: 0.083366\n",
      "2023-12-10 02:38:34,025 INFO     Training average negative_sample_loss at step 33400: 0.083246\n",
      "2023-12-10 02:38:34,025 INFO     Training average loss at step 33400: 0.083306\n",
      "2023-12-10 02:39:50,860 INFO     Training average positive_sample_loss at step 33500: 0.083793\n",
      "2023-12-10 02:39:50,860 INFO     Training average negative_sample_loss at step 33500: 0.084527\n",
      "2023-12-10 02:39:50,860 INFO     Training average loss at step 33500: 0.084160\n",
      "2023-12-10 02:41:07,894 INFO     Training average positive_sample_loss at step 33600: 0.084936\n",
      "2023-12-10 02:41:07,894 INFO     Training average negative_sample_loss at step 33600: 0.084790\n",
      "2023-12-10 02:41:07,894 INFO     Training average loss at step 33600: 0.084863\n",
      "2023-12-10 02:42:28,636 INFO     Training average positive_sample_loss at step 33700: 0.084669\n",
      "2023-12-10 02:42:28,636 INFO     Training average negative_sample_loss at step 33700: 0.085389\n",
      "2023-12-10 02:42:28,636 INFO     Training average loss at step 33700: 0.085029\n",
      "2023-12-10 02:43:47,703 INFO     Training average positive_sample_loss at step 33800: 0.084923\n",
      "2023-12-10 02:43:47,703 INFO     Training average negative_sample_loss at step 33800: 0.085529\n",
      "2023-12-10 02:43:47,703 INFO     Training average loss at step 33800: 0.085226\n",
      "2023-12-10 02:45:05,232 INFO     Training average positive_sample_loss at step 33900: 0.085123\n",
      "2023-12-10 02:45:05,232 INFO     Training average negative_sample_loss at step 33900: 0.086533\n",
      "2023-12-10 02:45:05,232 INFO     Training average loss at step 33900: 0.085828\n",
      "2023-12-10 02:46:40,350 INFO     Training average positive_sample_loss at step 34000: 0.083182\n",
      "2023-12-10 02:46:40,350 INFO     Training average negative_sample_loss at step 34000: 0.085675\n",
      "2023-12-10 02:46:40,350 INFO     Training average loss at step 34000: 0.084428\n",
      "2023-12-10 02:47:57,231 INFO     Training average positive_sample_loss at step 34100: 0.080044\n",
      "2023-12-10 02:47:57,232 INFO     Training average negative_sample_loss at step 34100: 0.082250\n",
      "2023-12-10 02:47:57,232 INFO     Training average loss at step 34100: 0.081147\n",
      "2023-12-10 02:49:15,309 INFO     Training average positive_sample_loss at step 34200: 0.082480\n",
      "2023-12-10 02:49:15,310 INFO     Training average negative_sample_loss at step 34200: 0.082159\n",
      "2023-12-10 02:49:15,310 INFO     Training average loss at step 34200: 0.082319\n",
      "2023-12-10 02:50:32,618 INFO     Training average positive_sample_loss at step 34300: 0.082607\n",
      "2023-12-10 02:50:32,618 INFO     Training average negative_sample_loss at step 34300: 0.082722\n",
      "2023-12-10 02:50:32,618 INFO     Training average loss at step 34300: 0.082665\n",
      "2023-12-10 02:51:47,764 INFO     Training average positive_sample_loss at step 34400: 0.083231\n",
      "2023-12-10 02:51:47,764 INFO     Training average negative_sample_loss at step 34400: 0.083773\n",
      "2023-12-10 02:51:47,764 INFO     Training average loss at step 34400: 0.083502\n",
      "2023-12-10 02:53:04,603 INFO     Training average positive_sample_loss at step 34500: 0.084110\n",
      "2023-12-10 02:53:04,604 INFO     Training average negative_sample_loss at step 34500: 0.083584\n",
      "2023-12-10 02:53:04,604 INFO     Training average loss at step 34500: 0.083847\n",
      "2023-12-10 02:54:21,640 INFO     Training average positive_sample_loss at step 34600: 0.084306\n",
      "2023-12-10 02:54:21,641 INFO     Training average negative_sample_loss at step 34600: 0.084705\n",
      "2023-12-10 02:54:21,641 INFO     Training average loss at step 34600: 0.084506\n",
      "2023-12-10 02:55:38,860 INFO     Training average positive_sample_loss at step 34700: 0.084727\n",
      "2023-12-10 02:55:38,861 INFO     Training average negative_sample_loss at step 34700: 0.084407\n",
      "2023-12-10 02:55:38,861 INFO     Training average loss at step 34700: 0.084567\n",
      "2023-12-10 02:56:55,633 INFO     Training average positive_sample_loss at step 34800: 0.084538\n",
      "2023-12-10 02:56:55,634 INFO     Training average negative_sample_loss at step 34800: 0.086234\n",
      "2023-12-10 02:56:55,634 INFO     Training average loss at step 34800: 0.085386\n",
      "2023-12-10 02:58:11,654 INFO     Training average positive_sample_loss at step 34900: 0.085162\n",
      "2023-12-10 02:58:11,655 INFO     Training average negative_sample_loss at step 34900: 0.086001\n",
      "2023-12-10 02:58:11,655 INFO     Training average loss at step 34900: 0.085581\n",
      "2023-12-10 02:59:39,843 INFO     Training average positive_sample_loss at step 35000: 0.079432\n",
      "2023-12-10 02:59:39,844 INFO     Training average negative_sample_loss at step 35000: 0.081655\n",
      "2023-12-10 02:59:39,844 INFO     Training average loss at step 35000: 0.080544\n",
      "2023-12-10 03:01:00,278 INFO     Training average positive_sample_loss at step 35100: 0.080357\n",
      "2023-12-10 03:01:00,279 INFO     Training average negative_sample_loss at step 35100: 0.080555\n",
      "2023-12-10 03:01:00,279 INFO     Training average loss at step 35100: 0.080456\n",
      "2023-12-10 03:02:16,821 INFO     Training average positive_sample_loss at step 35200: 0.081943\n",
      "2023-12-10 03:02:16,822 INFO     Training average negative_sample_loss at step 35200: 0.081991\n",
      "2023-12-10 03:02:16,822 INFO     Training average loss at step 35200: 0.081967\n",
      "2023-12-10 03:03:34,279 INFO     Training average positive_sample_loss at step 35300: 0.082853\n",
      "2023-12-10 03:03:34,279 INFO     Training average negative_sample_loss at step 35300: 0.082921\n",
      "2023-12-10 03:03:34,279 INFO     Training average loss at step 35300: 0.082887\n",
      "2023-12-10 03:04:51,016 INFO     Training average positive_sample_loss at step 35400: 0.084057\n",
      "2023-12-10 03:04:51,016 INFO     Training average negative_sample_loss at step 35400: 0.084622\n",
      "2023-12-10 03:04:51,016 INFO     Training average loss at step 35400: 0.084339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 03:06:07,621 INFO     Training average positive_sample_loss at step 35500: 0.084627\n",
      "2023-12-10 03:06:07,621 INFO     Training average negative_sample_loss at step 35500: 0.084903\n",
      "2023-12-10 03:06:07,621 INFO     Training average loss at step 35500: 0.084765\n",
      "2023-12-10 03:07:28,222 INFO     Training average positive_sample_loss at step 35600: 0.084675\n",
      "2023-12-10 03:07:28,222 INFO     Training average negative_sample_loss at step 35600: 0.084903\n",
      "2023-12-10 03:07:28,222 INFO     Training average loss at step 35600: 0.084789\n",
      "2023-12-10 03:08:47,656 INFO     Training average positive_sample_loss at step 35700: 0.084782\n",
      "2023-12-10 03:08:47,656 INFO     Training average negative_sample_loss at step 35700: 0.085493\n",
      "2023-12-10 03:08:47,656 INFO     Training average loss at step 35700: 0.085137\n",
      "2023-12-10 03:10:06,363 INFO     Training average positive_sample_loss at step 35800: 0.084260\n",
      "2023-12-10 03:10:06,363 INFO     Training average negative_sample_loss at step 35800: 0.085480\n",
      "2023-12-10 03:10:06,363 INFO     Training average loss at step 35800: 0.084870\n",
      "2023-12-10 03:11:40,550 INFO     Training average positive_sample_loss at step 35900: 0.082356\n",
      "2023-12-10 03:11:40,550 INFO     Training average negative_sample_loss at step 35900: 0.084661\n",
      "2023-12-10 03:11:40,550 INFO     Training average loss at step 35900: 0.083509\n",
      "2023-12-10 03:12:58,365 INFO     Training average positive_sample_loss at step 36000: 0.079835\n",
      "2023-12-10 03:12:58,365 INFO     Training average negative_sample_loss at step 36000: 0.080952\n",
      "2023-12-10 03:12:58,365 INFO     Training average loss at step 36000: 0.080393\n",
      "2023-12-10 03:14:20,498 INFO     Training average positive_sample_loss at step 36100: 0.081897\n",
      "2023-12-10 03:14:20,499 INFO     Training average negative_sample_loss at step 36100: 0.083226\n",
      "2023-12-10 03:14:20,499 INFO     Training average loss at step 36100: 0.082562\n",
      "2023-12-10 03:15:40,267 INFO     Training average positive_sample_loss at step 36200: 0.082694\n",
      "2023-12-10 03:15:40,267 INFO     Training average negative_sample_loss at step 36200: 0.083065\n",
      "2023-12-10 03:15:40,267 INFO     Training average loss at step 36200: 0.082879\n",
      "2023-12-10 03:16:55,410 INFO     Training average positive_sample_loss at step 36300: 0.083688\n",
      "2023-12-10 03:16:55,410 INFO     Training average negative_sample_loss at step 36300: 0.083210\n",
      "2023-12-10 03:16:55,410 INFO     Training average loss at step 36300: 0.083449\n",
      "2023-12-10 03:18:12,637 INFO     Training average positive_sample_loss at step 36400: 0.083173\n",
      "2023-12-10 03:18:12,637 INFO     Training average negative_sample_loss at step 36400: 0.083953\n",
      "2023-12-10 03:18:12,637 INFO     Training average loss at step 36400: 0.083563\n",
      "2023-12-10 03:19:28,532 INFO     Training average positive_sample_loss at step 36500: 0.084166\n",
      "2023-12-10 03:19:28,533 INFO     Training average negative_sample_loss at step 36500: 0.083564\n",
      "2023-12-10 03:19:28,533 INFO     Training average loss at step 36500: 0.083865\n",
      "2023-12-10 03:20:45,086 INFO     Training average positive_sample_loss at step 36600: 0.084454\n",
      "2023-12-10 03:20:45,087 INFO     Training average negative_sample_loss at step 36600: 0.085017\n",
      "2023-12-10 03:20:45,087 INFO     Training average loss at step 36600: 0.084736\n",
      "2023-12-10 03:22:02,881 INFO     Training average positive_sample_loss at step 36700: 0.084145\n",
      "2023-12-10 03:22:02,882 INFO     Training average negative_sample_loss at step 36700: 0.085066\n",
      "2023-12-10 03:22:02,882 INFO     Training average loss at step 36700: 0.084605\n",
      "2023-12-10 03:23:21,462 INFO     Training average positive_sample_loss at step 36800: 0.085029\n",
      "2023-12-10 03:23:21,462 INFO     Training average negative_sample_loss at step 36800: 0.085145\n",
      "2023-12-10 03:23:21,462 INFO     Training average loss at step 36800: 0.085087\n",
      "2023-12-10 03:24:53,583 INFO     Training average positive_sample_loss at step 36900: 0.078845\n",
      "2023-12-10 03:24:53,584 INFO     Training average negative_sample_loss at step 36900: 0.081999\n",
      "2023-12-10 03:24:53,584 INFO     Training average loss at step 36900: 0.080422\n",
      "2023-12-10 03:26:11,090 INFO     Training average positive_sample_loss at step 37000: 0.081295\n",
      "2023-12-10 03:26:11,090 INFO     Training average negative_sample_loss at step 37000: 0.080718\n",
      "2023-12-10 03:26:11,090 INFO     Training average loss at step 37000: 0.081006\n",
      "2023-12-10 03:27:26,613 INFO     Training average positive_sample_loss at step 37100: 0.081715\n",
      "2023-12-10 03:27:26,613 INFO     Training average negative_sample_loss at step 37100: 0.082246\n",
      "2023-12-10 03:27:26,613 INFO     Training average loss at step 37100: 0.081980\n",
      "2023-12-10 03:28:46,553 INFO     Training average positive_sample_loss at step 37200: 0.082957\n",
      "2023-12-10 03:28:46,553 INFO     Training average negative_sample_loss at step 37200: 0.082801\n",
      "2023-12-10 03:28:46,553 INFO     Training average loss at step 37200: 0.082879\n",
      "2023-12-10 03:30:03,382 INFO     Training average positive_sample_loss at step 37300: 0.083262\n",
      "2023-12-10 03:30:03,383 INFO     Training average negative_sample_loss at step 37300: 0.082523\n",
      "2023-12-10 03:30:03,383 INFO     Training average loss at step 37300: 0.082893\n",
      "2023-12-10 03:31:23,211 INFO     Training average positive_sample_loss at step 37400: 0.083622\n",
      "2023-12-10 03:31:23,212 INFO     Training average negative_sample_loss at step 37400: 0.083495\n",
      "2023-12-10 03:31:23,212 INFO     Training average loss at step 37400: 0.083558\n",
      "2023-12-10 03:32:44,210 INFO     Training average positive_sample_loss at step 37500: 0.083988\n",
      "2023-12-10 03:32:44,210 INFO     Training average negative_sample_loss at step 37500: 0.084735\n",
      "2023-12-10 03:32:44,210 INFO     Training average loss at step 37500: 0.084361\n",
      "2023-12-10 03:34:04,689 INFO     Training average positive_sample_loss at step 37600: 0.084288\n",
      "2023-12-10 03:34:04,689 INFO     Training average negative_sample_loss at step 37600: 0.084759\n",
      "2023-12-10 03:34:04,690 INFO     Training average loss at step 37600: 0.084524\n",
      "2023-12-10 03:35:24,793 INFO     Training average positive_sample_loss at step 37700: 0.083886\n",
      "2023-12-10 03:35:24,793 INFO     Training average negative_sample_loss at step 37700: 0.083817\n",
      "2023-12-10 03:35:24,793 INFO     Training average loss at step 37700: 0.083851\n",
      "2023-12-10 03:36:50,383 INFO     Training average positive_sample_loss at step 37800: 0.080625\n",
      "2023-12-10 03:36:50,384 INFO     Training average negative_sample_loss at step 37800: 0.083558\n",
      "2023-12-10 03:36:50,384 INFO     Training average loss at step 37800: 0.082092\n",
      "2023-12-10 03:38:09,475 INFO     Training average positive_sample_loss at step 37900: 0.079965\n",
      "2023-12-10 03:38:09,476 INFO     Training average negative_sample_loss at step 37900: 0.079653\n",
      "2023-12-10 03:38:09,476 INFO     Training average loss at step 37900: 0.079809\n",
      "2023-12-10 03:39:27,007 INFO     Training average positive_sample_loss at step 38000: 0.081101\n",
      "2023-12-10 03:39:27,007 INFO     Training average negative_sample_loss at step 38000: 0.081633\n",
      "2023-12-10 03:39:27,007 INFO     Training average loss at step 38000: 0.081367\n",
      "2023-12-10 03:40:44,862 INFO     Training average positive_sample_loss at step 38100: 0.082333\n",
      "2023-12-10 03:40:44,862 INFO     Training average negative_sample_loss at step 38100: 0.082304\n",
      "2023-12-10 03:40:44,862 INFO     Training average loss at step 38100: 0.082319\n",
      "2023-12-10 03:42:02,496 INFO     Training average positive_sample_loss at step 38200: 0.082470\n",
      "2023-12-10 03:42:02,496 INFO     Training average negative_sample_loss at step 38200: 0.082591\n",
      "2023-12-10 03:42:02,496 INFO     Training average loss at step 38200: 0.082530\n",
      "2023-12-10 03:43:21,056 INFO     Training average positive_sample_loss at step 38300: 0.083343\n",
      "2023-12-10 03:43:21,056 INFO     Training average negative_sample_loss at step 38300: 0.084065\n",
      "2023-12-10 03:43:21,056 INFO     Training average loss at step 38300: 0.083704\n",
      "2023-12-10 03:44:40,106 INFO     Training average positive_sample_loss at step 38400: 0.084404\n",
      "2023-12-10 03:44:40,107 INFO     Training average negative_sample_loss at step 38400: 0.084552\n",
      "2023-12-10 03:44:40,107 INFO     Training average loss at step 38400: 0.084478\n",
      "2023-12-10 03:45:55,597 INFO     Training average positive_sample_loss at step 38500: 0.084218\n",
      "2023-12-10 03:45:55,597 INFO     Training average negative_sample_loss at step 38500: 0.084317\n",
      "2023-12-10 03:45:55,597 INFO     Training average loss at step 38500: 0.084268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 03:47:13,357 INFO     Training average positive_sample_loss at step 38600: 0.084437\n",
      "2023-12-10 03:47:13,358 INFO     Training average negative_sample_loss at step 38600: 0.084456\n",
      "2023-12-10 03:47:13,358 INFO     Training average loss at step 38600: 0.084447\n",
      "2023-12-10 03:48:30,747 INFO     Training average positive_sample_loss at step 38700: 0.084199\n",
      "2023-12-10 03:48:30,748 INFO     Training average negative_sample_loss at step 38700: 0.083785\n",
      "2023-12-10 03:48:30,748 INFO     Training average loss at step 38700: 0.083992\n",
      "2023-12-10 03:50:00,186 INFO     Training average positive_sample_loss at step 38800: 0.077948\n",
      "2023-12-10 03:50:00,186 INFO     Training average negative_sample_loss at step 38800: 0.080670\n",
      "2023-12-10 03:50:00,186 INFO     Training average loss at step 38800: 0.079309\n",
      "2023-12-10 03:51:19,051 INFO     Training average positive_sample_loss at step 38900: 0.080577\n",
      "2023-12-10 03:51:19,051 INFO     Training average negative_sample_loss at step 38900: 0.080650\n",
      "2023-12-10 03:51:19,051 INFO     Training average loss at step 38900: 0.080614\n",
      "2023-12-10 03:52:36,279 INFO     Training average positive_sample_loss at step 39000: 0.081316\n",
      "2023-12-10 03:52:36,280 INFO     Training average negative_sample_loss at step 39000: 0.080936\n",
      "2023-12-10 03:52:36,280 INFO     Training average loss at step 39000: 0.081126\n",
      "2023-12-10 03:53:56,537 INFO     Training average positive_sample_loss at step 39100: 0.081689\n",
      "2023-12-10 03:53:56,537 INFO     Training average negative_sample_loss at step 39100: 0.081828\n",
      "2023-12-10 03:53:56,537 INFO     Training average loss at step 39100: 0.081758\n",
      "2023-12-10 03:55:15,476 INFO     Training average positive_sample_loss at step 39200: 0.083231\n",
      "2023-12-10 03:55:15,477 INFO     Training average negative_sample_loss at step 39200: 0.082505\n",
      "2023-12-10 03:55:15,477 INFO     Training average loss at step 39200: 0.082868\n",
      "2023-12-10 03:56:35,761 INFO     Training average positive_sample_loss at step 39300: 0.083627\n",
      "2023-12-10 03:56:35,761 INFO     Training average negative_sample_loss at step 39300: 0.083192\n",
      "2023-12-10 03:56:35,761 INFO     Training average loss at step 39300: 0.083410\n",
      "2023-12-10 03:57:56,269 INFO     Training average positive_sample_loss at step 39400: 0.083195\n",
      "2023-12-10 03:57:56,269 INFO     Training average negative_sample_loss at step 39400: 0.083261\n",
      "2023-12-10 03:57:56,269 INFO     Training average loss at step 39400: 0.083228\n",
      "2023-12-10 03:59:14,082 INFO     Training average positive_sample_loss at step 39500: 0.083996\n",
      "2023-12-10 03:59:14,083 INFO     Training average negative_sample_loss at step 39500: 0.085201\n",
      "2023-12-10 03:59:14,083 INFO     Training average loss at step 39500: 0.084598\n",
      "2023-12-10 04:00:33,970 INFO     Training average positive_sample_loss at step 39600: 0.084693\n",
      "2023-12-10 04:00:33,970 INFO     Training average negative_sample_loss at step 39600: 0.084755\n",
      "2023-12-10 04:00:33,970 INFO     Training average loss at step 39600: 0.084724\n",
      "2023-12-10 04:02:01,153 INFO     Training average positive_sample_loss at step 39700: 0.080566\n",
      "2023-12-10 04:02:01,153 INFO     Training average negative_sample_loss at step 39700: 0.082906\n",
      "2023-12-10 04:02:01,153 INFO     Training average loss at step 39700: 0.081736\n",
      "2023-12-10 04:03:19,400 INFO     Training average positive_sample_loss at step 39800: 0.079742\n",
      "2023-12-10 04:03:19,400 INFO     Training average negative_sample_loss at step 39800: 0.079113\n",
      "2023-12-10 04:03:19,400 INFO     Training average loss at step 39800: 0.079427\n",
      "2023-12-10 04:04:35,516 INFO     Training average positive_sample_loss at step 39900: 0.081406\n",
      "2023-12-10 04:04:35,517 INFO     Training average negative_sample_loss at step 39900: 0.081314\n",
      "2023-12-10 04:04:35,517 INFO     Training average loss at step 39900: 0.081360\n",
      "2023-12-10 04:06:01,271 INFO     Training average positive_sample_loss at step 40000: 0.081777\n",
      "2023-12-10 04:06:01,272 INFO     Training average negative_sample_loss at step 40000: 0.081934\n",
      "2023-12-10 04:06:01,272 INFO     Training average loss at step 40000: 0.081855\n",
      "2023-12-10 04:06:01,272 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 04:06:02,134 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 04:06:34,741 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 04:07:04,288 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 04:07:32,959 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 04:07:59,916 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 04:08:28,422 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 04:08:56,093 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 04:09:03,635 INFO     Valid MRR at step 40000: 0.740977\n",
      "2023-12-10 04:09:03,635 INFO     Valid MR at step 40000: 46.872710\n",
      "2023-12-10 04:09:03,635 INFO     Valid HITS@1 at step 40000: 0.677230\n",
      "2023-12-10 04:09:03,635 INFO     Valid HITS@3 at step 40000: 0.779870\n",
      "2023-12-10 04:09:03,635 INFO     Valid HITS@10 at step 40000: 0.854350\n",
      "2023-12-10 04:10:07,817 INFO     Training average positive_sample_loss at step 40100: 0.082785\n",
      "2023-12-10 04:10:07,818 INFO     Training average negative_sample_loss at step 40100: 0.082804\n",
      "2023-12-10 04:10:07,818 INFO     Training average loss at step 40100: 0.082795\n",
      "2023-12-10 04:11:26,630 INFO     Training average positive_sample_loss at step 40200: 0.082948\n",
      "2023-12-10 04:11:26,630 INFO     Training average negative_sample_loss at step 40200: 0.082402\n",
      "2023-12-10 04:11:26,630 INFO     Training average loss at step 40200: 0.082675\n",
      "2023-12-10 04:12:46,160 INFO     Training average positive_sample_loss at step 40300: 0.083371\n",
      "2023-12-10 04:12:46,160 INFO     Training average negative_sample_loss at step 40300: 0.083700\n",
      "2023-12-10 04:12:46,160 INFO     Training average loss at step 40300: 0.083536\n",
      "2023-12-10 04:14:04,842 INFO     Training average positive_sample_loss at step 40400: 0.083998\n",
      "2023-12-10 04:14:04,842 INFO     Training average negative_sample_loss at step 40400: 0.084174\n",
      "2023-12-10 04:14:04,842 INFO     Training average loss at step 40400: 0.084086\n",
      "2023-12-10 04:15:25,927 INFO     Training average positive_sample_loss at step 40500: 0.083399\n",
      "2023-12-10 04:15:25,927 INFO     Training average negative_sample_loss at step 40500: 0.083564\n",
      "2023-12-10 04:15:25,927 INFO     Training average loss at step 40500: 0.083482\n",
      "2023-12-10 04:16:51,625 INFO     Training average positive_sample_loss at step 40600: 0.083592\n",
      "2023-12-10 04:16:51,626 INFO     Training average negative_sample_loss at step 40600: 0.084923\n",
      "2023-12-10 04:16:51,626 INFO     Training average loss at step 40600: 0.084258\n",
      "2023-12-10 04:18:08,536 INFO     Training average positive_sample_loss at step 40700: 0.078621\n",
      "2023-12-10 04:18:08,536 INFO     Training average negative_sample_loss at step 40700: 0.079362\n",
      "2023-12-10 04:18:08,537 INFO     Training average loss at step 40700: 0.078991\n",
      "2023-12-10 04:19:25,647 INFO     Training average positive_sample_loss at step 40800: 0.079909\n",
      "2023-12-10 04:19:25,648 INFO     Training average negative_sample_loss at step 40800: 0.080243\n",
      "2023-12-10 04:19:25,648 INFO     Training average loss at step 40800: 0.080076\n",
      "2023-12-10 04:20:42,942 INFO     Training average positive_sample_loss at step 40900: 0.081756\n",
      "2023-12-10 04:20:42,943 INFO     Training average negative_sample_loss at step 40900: 0.080632\n",
      "2023-12-10 04:20:42,943 INFO     Training average loss at step 40900: 0.081194\n",
      "2023-12-10 04:21:59,491 INFO     Training average positive_sample_loss at step 41000: 0.082266\n",
      "2023-12-10 04:21:59,492 INFO     Training average negative_sample_loss at step 41000: 0.082470\n",
      "2023-12-10 04:21:59,492 INFO     Training average loss at step 41000: 0.082368\n",
      "2023-12-10 04:23:17,314 INFO     Training average positive_sample_loss at step 41100: 0.083180\n",
      "2023-12-10 04:23:17,315 INFO     Training average negative_sample_loss at step 41100: 0.083515\n",
      "2023-12-10 04:23:17,315 INFO     Training average loss at step 41100: 0.083348\n",
      "2023-12-10 04:24:34,044 INFO     Training average positive_sample_loss at step 41200: 0.083520\n",
      "2023-12-10 04:24:34,044 INFO     Training average negative_sample_loss at step 41200: 0.082713\n",
      "2023-12-10 04:24:34,044 INFO     Training average loss at step 41200: 0.083116\n",
      "2023-12-10 04:25:50,150 INFO     Training average positive_sample_loss at step 41300: 0.083523\n",
      "2023-12-10 04:25:50,151 INFO     Training average negative_sample_loss at step 41300: 0.083228\n",
      "2023-12-10 04:25:50,151 INFO     Training average loss at step 41300: 0.083376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 04:27:07,288 INFO     Training average positive_sample_loss at step 41400: 0.083994\n",
      "2023-12-10 04:27:07,289 INFO     Training average negative_sample_loss at step 41400: 0.083736\n",
      "2023-12-10 04:27:07,289 INFO     Training average loss at step 41400: 0.083865\n",
      "2023-12-10 04:28:23,772 INFO     Training average positive_sample_loss at step 41500: 0.083646\n",
      "2023-12-10 04:28:23,772 INFO     Training average negative_sample_loss at step 41500: 0.084077\n",
      "2023-12-10 04:28:23,772 INFO     Training average loss at step 41500: 0.083861\n",
      "2023-12-10 04:29:56,137 INFO     Training average positive_sample_loss at step 41600: 0.078808\n",
      "2023-12-10 04:29:56,137 INFO     Training average negative_sample_loss at step 41600: 0.082008\n",
      "2023-12-10 04:29:56,137 INFO     Training average loss at step 41600: 0.080408\n",
      "2023-12-10 04:31:16,777 INFO     Training average positive_sample_loss at step 41700: 0.079613\n",
      "2023-12-10 04:31:16,778 INFO     Training average negative_sample_loss at step 41700: 0.079118\n",
      "2023-12-10 04:31:16,778 INFO     Training average loss at step 41700: 0.079365\n",
      "2023-12-10 04:32:36,188 INFO     Training average positive_sample_loss at step 41800: 0.081349\n",
      "2023-12-10 04:32:36,189 INFO     Training average negative_sample_loss at step 41800: 0.080853\n",
      "2023-12-10 04:32:36,189 INFO     Training average loss at step 41800: 0.081101\n",
      "2023-12-10 04:33:52,023 INFO     Training average positive_sample_loss at step 41900: 0.081732\n",
      "2023-12-10 04:33:52,024 INFO     Training average negative_sample_loss at step 41900: 0.081882\n",
      "2023-12-10 04:33:52,024 INFO     Training average loss at step 41900: 0.081807\n",
      "2023-12-10 04:35:09,592 INFO     Training average positive_sample_loss at step 42000: 0.082553\n",
      "2023-12-10 04:35:09,592 INFO     Training average negative_sample_loss at step 42000: 0.081412\n",
      "2023-12-10 04:35:09,592 INFO     Training average loss at step 42000: 0.081982\n",
      "2023-12-10 04:36:31,056 INFO     Training average positive_sample_loss at step 42100: 0.083362\n",
      "2023-12-10 04:36:31,056 INFO     Training average negative_sample_loss at step 42100: 0.082860\n",
      "2023-12-10 04:36:31,056 INFO     Training average loss at step 42100: 0.083111\n",
      "2023-12-10 04:37:47,862 INFO     Training average positive_sample_loss at step 42200: 0.083204\n",
      "2023-12-10 04:37:47,863 INFO     Training average negative_sample_loss at step 42200: 0.083642\n",
      "2023-12-10 04:37:47,863 INFO     Training average loss at step 42200: 0.083423\n",
      "2023-12-10 04:39:05,796 INFO     Training average positive_sample_loss at step 42300: 0.083487\n",
      "2023-12-10 04:39:05,796 INFO     Training average negative_sample_loss at step 42300: 0.083537\n",
      "2023-12-10 04:39:05,797 INFO     Training average loss at step 42300: 0.083512\n",
      "2023-12-10 04:40:22,973 INFO     Training average positive_sample_loss at step 42400: 0.082977\n",
      "2023-12-10 04:40:22,973 INFO     Training average negative_sample_loss at step 42400: 0.083454\n",
      "2023-12-10 04:40:22,973 INFO     Training average loss at step 42400: 0.083215\n",
      "2023-12-10 04:41:48,582 INFO     Training average positive_sample_loss at step 42500: 0.081356\n",
      "2023-12-10 04:41:48,583 INFO     Training average negative_sample_loss at step 42500: 0.083448\n",
      "2023-12-10 04:41:48,583 INFO     Training average loss at step 42500: 0.082402\n",
      "2023-12-10 04:43:07,990 INFO     Training average positive_sample_loss at step 42600: 0.078530\n",
      "2023-12-10 04:43:07,990 INFO     Training average negative_sample_loss at step 42600: 0.079040\n",
      "2023-12-10 04:43:07,990 INFO     Training average loss at step 42600: 0.078785\n",
      "2023-12-10 04:44:26,434 INFO     Training average positive_sample_loss at step 42700: 0.080581\n",
      "2023-12-10 04:44:26,434 INFO     Training average negative_sample_loss at step 42700: 0.080295\n",
      "2023-12-10 04:44:26,434 INFO     Training average loss at step 42700: 0.080438\n",
      "2023-12-10 04:45:47,671 INFO     Training average positive_sample_loss at step 42800: 0.081183\n",
      "2023-12-10 04:45:47,672 INFO     Training average negative_sample_loss at step 42800: 0.080213\n",
      "2023-12-10 04:45:47,672 INFO     Training average loss at step 42800: 0.080698\n",
      "2023-12-10 04:47:06,824 INFO     Training average positive_sample_loss at step 42900: 0.081897\n",
      "2023-12-10 04:47:06,825 INFO     Training average negative_sample_loss at step 42900: 0.081278\n",
      "2023-12-10 04:47:06,825 INFO     Training average loss at step 42900: 0.081587\n",
      "2023-12-10 04:48:26,975 INFO     Training average positive_sample_loss at step 43000: 0.082431\n",
      "2023-12-10 04:48:26,976 INFO     Training average negative_sample_loss at step 43000: 0.082527\n",
      "2023-12-10 04:48:26,976 INFO     Training average loss at step 43000: 0.082479\n",
      "2023-12-10 04:49:43,630 INFO     Training average positive_sample_loss at step 43100: 0.083102\n",
      "2023-12-10 04:49:43,631 INFO     Training average negative_sample_loss at step 43100: 0.082599\n",
      "2023-12-10 04:49:43,631 INFO     Training average loss at step 43100: 0.082850\n",
      "2023-12-10 04:51:02,114 INFO     Training average positive_sample_loss at step 43200: 0.083234\n",
      "2023-12-10 04:51:02,114 INFO     Training average negative_sample_loss at step 43200: 0.083509\n",
      "2023-12-10 04:51:02,114 INFO     Training average loss at step 43200: 0.083371\n",
      "2023-12-10 04:52:19,579 INFO     Training average positive_sample_loss at step 43300: 0.083986\n",
      "2023-12-10 04:52:19,579 INFO     Training average negative_sample_loss at step 43300: 0.085266\n",
      "2023-12-10 04:52:19,579 INFO     Training average loss at step 43300: 0.084626\n",
      "2023-12-10 04:53:34,807 INFO     Training average positive_sample_loss at step 43400: 0.083433\n",
      "2023-12-10 04:53:34,808 INFO     Training average negative_sample_loss at step 43400: 0.083312\n",
      "2023-12-10 04:53:34,808 INFO     Training average loss at step 43400: 0.083373\n",
      "2023-12-10 04:55:07,651 INFO     Training average positive_sample_loss at step 43500: 0.078900\n",
      "2023-12-10 04:55:07,651 INFO     Training average negative_sample_loss at step 43500: 0.081372\n",
      "2023-12-10 04:55:07,651 INFO     Training average loss at step 43500: 0.080136\n",
      "2023-12-10 04:56:27,063 INFO     Training average positive_sample_loss at step 43600: 0.080065\n",
      "2023-12-10 04:56:27,063 INFO     Training average negative_sample_loss at step 43600: 0.080093\n",
      "2023-12-10 04:56:27,063 INFO     Training average loss at step 43600: 0.080079\n",
      "2023-12-10 04:57:45,390 INFO     Training average positive_sample_loss at step 43700: 0.081273\n",
      "2023-12-10 04:57:45,390 INFO     Training average negative_sample_loss at step 43700: 0.079373\n",
      "2023-12-10 04:57:45,390 INFO     Training average loss at step 43700: 0.080323\n",
      "2023-12-10 04:59:04,772 INFO     Training average positive_sample_loss at step 43800: 0.081727\n",
      "2023-12-10 04:59:04,772 INFO     Training average negative_sample_loss at step 43800: 0.081376\n",
      "2023-12-10 04:59:04,772 INFO     Training average loss at step 43800: 0.081552\n",
      "2023-12-10 05:00:23,984 INFO     Training average positive_sample_loss at step 43900: 0.082175\n",
      "2023-12-10 05:00:23,984 INFO     Training average negative_sample_loss at step 43900: 0.081481\n",
      "2023-12-10 05:00:23,984 INFO     Training average loss at step 43900: 0.081828\n",
      "2023-12-10 05:01:43,104 INFO     Training average positive_sample_loss at step 44000: 0.082948\n",
      "2023-12-10 05:01:43,105 INFO     Training average negative_sample_loss at step 44000: 0.082589\n",
      "2023-12-10 05:01:43,105 INFO     Training average loss at step 44000: 0.082769\n",
      "2023-12-10 05:03:03,529 INFO     Training average positive_sample_loss at step 44100: 0.082289\n",
      "2023-12-10 05:03:03,529 INFO     Training average negative_sample_loss at step 44100: 0.083033\n",
      "2023-12-10 05:03:03,529 INFO     Training average loss at step 44100: 0.082661\n",
      "2023-12-10 05:04:21,534 INFO     Training average positive_sample_loss at step 44200: 0.083537\n",
      "2023-12-10 05:04:21,534 INFO     Training average negative_sample_loss at step 44200: 0.082831\n",
      "2023-12-10 05:04:21,534 INFO     Training average loss at step 44200: 0.083184\n",
      "2023-12-10 05:05:39,934 INFO     Training average positive_sample_loss at step 44300: 0.083618\n",
      "2023-12-10 05:05:39,934 INFO     Training average negative_sample_loss at step 44300: 0.083153\n",
      "2023-12-10 05:05:39,934 INFO     Training average loss at step 44300: 0.083386\n",
      "2023-12-10 05:07:13,429 INFO     Training average positive_sample_loss at step 44400: 0.080612\n",
      "2023-12-10 05:07:13,430 INFO     Training average negative_sample_loss at step 44400: 0.082531\n",
      "2023-12-10 05:07:13,430 INFO     Training average loss at step 44400: 0.081572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 05:08:29,433 INFO     Training average positive_sample_loss at step 44500: 0.078472\n",
      "2023-12-10 05:08:29,433 INFO     Training average negative_sample_loss at step 44500: 0.078525\n",
      "2023-12-10 05:08:29,433 INFO     Training average loss at step 44500: 0.078499\n",
      "2023-12-10 05:09:48,141 INFO     Training average positive_sample_loss at step 44600: 0.080432\n",
      "2023-12-10 05:09:48,141 INFO     Training average negative_sample_loss at step 44600: 0.079714\n",
      "2023-12-10 05:09:48,141 INFO     Training average loss at step 44600: 0.080073\n",
      "2023-12-10 05:11:09,966 INFO     Training average positive_sample_loss at step 44700: 0.081118\n",
      "2023-12-10 05:11:09,966 INFO     Training average negative_sample_loss at step 44700: 0.080623\n",
      "2023-12-10 05:11:09,966 INFO     Training average loss at step 44700: 0.080871\n",
      "2023-12-10 05:12:28,936 INFO     Training average positive_sample_loss at step 44800: 0.081595\n",
      "2023-12-10 05:12:28,936 INFO     Training average negative_sample_loss at step 44800: 0.081384\n",
      "2023-12-10 05:12:28,936 INFO     Training average loss at step 44800: 0.081489\n",
      "2023-12-10 05:13:47,569 INFO     Training average positive_sample_loss at step 44900: 0.081851\n",
      "2023-12-10 05:13:47,570 INFO     Training average negative_sample_loss at step 44900: 0.081650\n",
      "2023-12-10 05:13:47,570 INFO     Training average loss at step 44900: 0.081750\n",
      "2023-12-10 05:15:04,332 INFO     Training average positive_sample_loss at step 45000: 0.082762\n",
      "2023-12-10 05:15:04,333 INFO     Training average negative_sample_loss at step 45000: 0.081880\n",
      "2023-12-10 05:15:04,333 INFO     Training average loss at step 45000: 0.082321\n",
      "2023-12-10 05:16:21,428 INFO     Training average positive_sample_loss at step 45100: 0.082384\n",
      "2023-12-10 05:16:21,429 INFO     Training average negative_sample_loss at step 45100: 0.082144\n",
      "2023-12-10 05:16:21,429 INFO     Training average loss at step 45100: 0.082264\n",
      "2023-12-10 05:17:37,760 INFO     Training average positive_sample_loss at step 45200: 0.082660\n",
      "2023-12-10 05:17:37,760 INFO     Training average negative_sample_loss at step 45200: 0.083132\n",
      "2023-12-10 05:17:37,760 INFO     Training average loss at step 45200: 0.082896\n",
      "2023-12-10 05:18:53,644 INFO     Training average positive_sample_loss at step 45300: 0.083944\n",
      "2023-12-10 05:18:53,645 INFO     Training average negative_sample_loss at step 45300: 0.083643\n",
      "2023-12-10 05:18:53,645 INFO     Training average loss at step 45300: 0.083793\n",
      "2023-12-10 05:20:19,039 INFO     Training average positive_sample_loss at step 45400: 0.076986\n",
      "2023-12-10 05:20:19,040 INFO     Training average negative_sample_loss at step 45400: 0.078986\n",
      "2023-12-10 05:20:19,040 INFO     Training average loss at step 45400: 0.077986\n",
      "2023-12-10 05:21:35,471 INFO     Training average positive_sample_loss at step 45500: 0.079622\n",
      "2023-12-10 05:21:35,472 INFO     Training average negative_sample_loss at step 45500: 0.080438\n",
      "2023-12-10 05:21:35,472 INFO     Training average loss at step 45500: 0.080030\n",
      "2023-12-10 05:22:53,261 INFO     Training average positive_sample_loss at step 45600: 0.080936\n",
      "2023-12-10 05:22:53,261 INFO     Training average negative_sample_loss at step 45600: 0.080000\n",
      "2023-12-10 05:22:53,262 INFO     Training average loss at step 45600: 0.080468\n",
      "2023-12-10 05:24:10,979 INFO     Training average positive_sample_loss at step 45700: 0.081680\n",
      "2023-12-10 05:24:10,980 INFO     Training average negative_sample_loss at step 45700: 0.081512\n",
      "2023-12-10 05:24:10,980 INFO     Training average loss at step 45700: 0.081596\n",
      "2023-12-10 05:25:30,812 INFO     Training average positive_sample_loss at step 45800: 0.082529\n",
      "2023-12-10 05:25:30,812 INFO     Training average negative_sample_loss at step 45800: 0.081553\n",
      "2023-12-10 05:25:30,812 INFO     Training average loss at step 45800: 0.082041\n",
      "2023-12-10 05:26:45,456 INFO     Training average positive_sample_loss at step 45900: 0.082964\n",
      "2023-12-10 05:26:45,457 INFO     Training average negative_sample_loss at step 45900: 0.081692\n",
      "2023-12-10 05:26:45,457 INFO     Training average loss at step 45900: 0.082328\n",
      "2023-12-10 05:28:01,928 INFO     Training average positive_sample_loss at step 46000: 0.081971\n",
      "2023-12-10 05:28:01,928 INFO     Training average negative_sample_loss at step 46000: 0.081965\n",
      "2023-12-10 05:28:01,928 INFO     Training average loss at step 46000: 0.081968\n",
      "2023-12-10 05:29:19,248 INFO     Training average positive_sample_loss at step 46100: 0.083458\n",
      "2023-12-10 05:29:19,248 INFO     Training average negative_sample_loss at step 46100: 0.083307\n",
      "2023-12-10 05:29:19,248 INFO     Training average loss at step 46100: 0.083383\n",
      "2023-12-10 05:30:36,747 INFO     Training average positive_sample_loss at step 46200: 0.082676\n",
      "2023-12-10 05:30:36,748 INFO     Training average negative_sample_loss at step 46200: 0.081806\n",
      "2023-12-10 05:30:36,748 INFO     Training average loss at step 46200: 0.082241\n",
      "2023-12-10 05:32:05,753 INFO     Training average positive_sample_loss at step 46300: 0.079143\n",
      "2023-12-10 05:32:05,753 INFO     Training average negative_sample_loss at step 46300: 0.082298\n",
      "2023-12-10 05:32:05,753 INFO     Training average loss at step 46300: 0.080720\n",
      "2023-12-10 05:33:22,207 INFO     Training average positive_sample_loss at step 46400: 0.078528\n",
      "2023-12-10 05:33:22,207 INFO     Training average negative_sample_loss at step 46400: 0.078901\n",
      "2023-12-10 05:33:22,207 INFO     Training average loss at step 46400: 0.078714\n",
      "2023-12-10 05:34:39,803 INFO     Training average positive_sample_loss at step 46500: 0.080710\n",
      "2023-12-10 05:34:39,804 INFO     Training average negative_sample_loss at step 46500: 0.079449\n",
      "2023-12-10 05:34:39,804 INFO     Training average loss at step 46500: 0.080080\n",
      "2023-12-10 05:35:58,292 INFO     Training average positive_sample_loss at step 46600: 0.080747\n",
      "2023-12-10 05:35:58,292 INFO     Training average negative_sample_loss at step 46600: 0.080521\n",
      "2023-12-10 05:35:58,292 INFO     Training average loss at step 46600: 0.080634\n",
      "2023-12-10 05:37:17,972 INFO     Training average positive_sample_loss at step 46700: 0.081736\n",
      "2023-12-10 05:37:17,973 INFO     Training average negative_sample_loss at step 46700: 0.080799\n",
      "2023-12-10 05:37:17,973 INFO     Training average loss at step 46700: 0.081267\n",
      "2023-12-10 05:38:37,493 INFO     Training average positive_sample_loss at step 46800: 0.082064\n",
      "2023-12-10 05:38:37,493 INFO     Training average negative_sample_loss at step 46800: 0.081627\n",
      "2023-12-10 05:38:37,493 INFO     Training average loss at step 46800: 0.081846\n",
      "2023-12-10 05:39:55,998 INFO     Training average positive_sample_loss at step 46900: 0.082553\n",
      "2023-12-10 05:39:55,998 INFO     Training average negative_sample_loss at step 46900: 0.082611\n",
      "2023-12-10 05:39:55,998 INFO     Training average loss at step 46900: 0.082582\n",
      "2023-12-10 05:41:13,694 INFO     Training average positive_sample_loss at step 47000: 0.083247\n",
      "2023-12-10 05:41:13,694 INFO     Training average negative_sample_loss at step 47000: 0.081940\n",
      "2023-12-10 05:41:13,695 INFO     Training average loss at step 47000: 0.082594\n",
      "2023-12-10 05:42:33,004 INFO     Training average positive_sample_loss at step 47100: 0.082693\n",
      "2023-12-10 05:42:33,004 INFO     Training average negative_sample_loss at step 47100: 0.082329\n",
      "2023-12-10 05:42:33,004 INFO     Training average loss at step 47100: 0.082511\n",
      "2023-12-10 05:43:58,933 INFO     Training average positive_sample_loss at step 47200: 0.082864\n",
      "2023-12-10 05:43:58,934 INFO     Training average negative_sample_loss at step 47200: 0.082651\n",
      "2023-12-10 05:43:58,934 INFO     Training average loss at step 47200: 0.082758\n",
      "2023-12-10 05:45:19,284 INFO     Training average positive_sample_loss at step 47300: 0.076640\n",
      "2023-12-10 05:45:19,284 INFO     Training average negative_sample_loss at step 47300: 0.078894\n",
      "2023-12-10 05:45:19,284 INFO     Training average loss at step 47300: 0.077767\n",
      "2023-12-10 05:46:37,260 INFO     Training average positive_sample_loss at step 47400: 0.079417\n",
      "2023-12-10 05:46:37,260 INFO     Training average negative_sample_loss at step 47400: 0.078689\n",
      "2023-12-10 05:46:37,260 INFO     Training average loss at step 47400: 0.079053\n",
      "2023-12-10 05:47:54,563 INFO     Training average positive_sample_loss at step 47500: 0.080947\n",
      "2023-12-10 05:47:54,564 INFO     Training average negative_sample_loss at step 47500: 0.079732\n",
      "2023-12-10 05:47:54,564 INFO     Training average loss at step 47500: 0.080340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 05:49:11,863 INFO     Training average positive_sample_loss at step 47600: 0.081295\n",
      "2023-12-10 05:49:11,863 INFO     Training average negative_sample_loss at step 47600: 0.081044\n",
      "2023-12-10 05:49:11,863 INFO     Training average loss at step 47600: 0.081170\n",
      "2023-12-10 05:50:31,283 INFO     Training average positive_sample_loss at step 47700: 0.081926\n",
      "2023-12-10 05:50:31,283 INFO     Training average negative_sample_loss at step 47700: 0.080686\n",
      "2023-12-10 05:50:31,284 INFO     Training average loss at step 47700: 0.081306\n",
      "2023-12-10 05:51:48,309 INFO     Training average positive_sample_loss at step 47800: 0.082000\n",
      "2023-12-10 05:51:48,309 INFO     Training average negative_sample_loss at step 47800: 0.081805\n",
      "2023-12-10 05:51:48,309 INFO     Training average loss at step 47800: 0.081902\n",
      "2023-12-10 05:53:05,726 INFO     Training average positive_sample_loss at step 47900: 0.082239\n",
      "2023-12-10 05:53:05,726 INFO     Training average negative_sample_loss at step 47900: 0.081948\n",
      "2023-12-10 05:53:05,726 INFO     Training average loss at step 47900: 0.082094\n",
      "2023-12-10 05:54:21,907 INFO     Training average positive_sample_loss at step 48000: 0.082712\n",
      "2023-12-10 05:54:21,908 INFO     Training average negative_sample_loss at step 48000: 0.082554\n",
      "2023-12-10 05:54:21,908 INFO     Training average loss at step 48000: 0.082633\n",
      "2023-12-10 05:55:38,206 INFO     Training average positive_sample_loss at step 48100: 0.083173\n",
      "2023-12-10 05:55:38,206 INFO     Training average negative_sample_loss at step 48100: 0.082326\n",
      "2023-12-10 05:55:38,206 INFO     Training average loss at step 48100: 0.082750\n",
      "2023-12-10 05:57:14,309 INFO     Training average positive_sample_loss at step 48200: 0.078921\n",
      "2023-12-10 05:57:14,309 INFO     Training average negative_sample_loss at step 48200: 0.081942\n",
      "2023-12-10 05:57:14,309 INFO     Training average loss at step 48200: 0.080432\n",
      "2023-12-10 05:58:31,560 INFO     Training average positive_sample_loss at step 48300: 0.078707\n",
      "2023-12-10 05:58:31,560 INFO     Training average negative_sample_loss at step 48300: 0.077778\n",
      "2023-12-10 05:58:31,560 INFO     Training average loss at step 48300: 0.078242\n",
      "2023-12-10 05:59:50,325 INFO     Training average positive_sample_loss at step 48400: 0.080026\n",
      "2023-12-10 05:59:50,326 INFO     Training average negative_sample_loss at step 48400: 0.079743\n",
      "2023-12-10 05:59:50,326 INFO     Training average loss at step 48400: 0.079885\n",
      "2023-12-10 06:01:11,239 INFO     Training average positive_sample_loss at step 48500: 0.081715\n",
      "2023-12-10 06:01:11,240 INFO     Training average negative_sample_loss at step 48500: 0.080067\n",
      "2023-12-10 06:01:11,240 INFO     Training average loss at step 48500: 0.080891\n",
      "2023-12-10 06:02:31,871 INFO     Training average positive_sample_loss at step 48600: 0.081477\n",
      "2023-12-10 06:02:31,872 INFO     Training average negative_sample_loss at step 48600: 0.081074\n",
      "2023-12-10 06:02:31,872 INFO     Training average loss at step 48600: 0.081275\n",
      "2023-12-10 06:03:51,999 INFO     Training average positive_sample_loss at step 48700: 0.081799\n",
      "2023-12-10 06:03:51,999 INFO     Training average negative_sample_loss at step 48700: 0.080879\n",
      "2023-12-10 06:03:51,999 INFO     Training average loss at step 48700: 0.081339\n",
      "2023-12-10 06:05:09,999 INFO     Training average positive_sample_loss at step 48800: 0.082591\n",
      "2023-12-10 06:05:10,000 INFO     Training average negative_sample_loss at step 48800: 0.082653\n",
      "2023-12-10 06:05:10,000 INFO     Training average loss at step 48800: 0.082622\n",
      "2023-12-10 06:06:27,710 INFO     Training average positive_sample_loss at step 48900: 0.083221\n",
      "2023-12-10 06:06:27,711 INFO     Training average negative_sample_loss at step 48900: 0.083394\n",
      "2023-12-10 06:06:27,711 INFO     Training average loss at step 48900: 0.083307\n",
      "2023-12-10 06:07:46,390 INFO     Training average positive_sample_loss at step 49000: 0.082852\n",
      "2023-12-10 06:07:46,390 INFO     Training average negative_sample_loss at step 49000: 0.081935\n",
      "2023-12-10 06:07:46,390 INFO     Training average loss at step 49000: 0.082394\n",
      "2023-12-10 06:09:19,807 INFO     Training average positive_sample_loss at step 49100: 0.080924\n",
      "2023-12-10 06:09:19,807 INFO     Training average negative_sample_loss at step 49100: 0.082166\n",
      "2023-12-10 06:09:19,807 INFO     Training average loss at step 49100: 0.081545\n",
      "2023-12-10 06:10:37,742 INFO     Training average positive_sample_loss at step 49200: 0.076973\n",
      "2023-12-10 06:10:37,742 INFO     Training average negative_sample_loss at step 49200: 0.077561\n",
      "2023-12-10 06:10:37,742 INFO     Training average loss at step 49200: 0.077267\n",
      "2023-12-10 06:11:57,233 INFO     Training average positive_sample_loss at step 49300: 0.079170\n",
      "2023-12-10 06:11:57,234 INFO     Training average negative_sample_loss at step 49300: 0.078395\n",
      "2023-12-10 06:11:57,234 INFO     Training average loss at step 49300: 0.078782\n",
      "2023-12-10 06:13:15,537 INFO     Training average positive_sample_loss at step 49400: 0.080663\n",
      "2023-12-10 06:13:15,538 INFO     Training average negative_sample_loss at step 49400: 0.079936\n",
      "2023-12-10 06:13:15,538 INFO     Training average loss at step 49400: 0.080300\n",
      "2023-12-10 06:14:34,230 INFO     Training average positive_sample_loss at step 49500: 0.081478\n",
      "2023-12-10 06:14:34,231 INFO     Training average negative_sample_loss at step 49500: 0.080677\n",
      "2023-12-10 06:14:34,231 INFO     Training average loss at step 49500: 0.081078\n",
      "2023-12-10 06:15:51,855 INFO     Training average positive_sample_loss at step 49600: 0.081786\n",
      "2023-12-10 06:15:51,855 INFO     Training average negative_sample_loss at step 49600: 0.081452\n",
      "2023-12-10 06:15:51,855 INFO     Training average loss at step 49600: 0.081619\n",
      "2023-12-10 06:17:08,951 INFO     Training average positive_sample_loss at step 49700: 0.081969\n",
      "2023-12-10 06:17:08,951 INFO     Training average negative_sample_loss at step 49700: 0.080788\n",
      "2023-12-10 06:17:08,951 INFO     Training average loss at step 49700: 0.081378\n",
      "2023-12-10 06:18:26,280 INFO     Training average positive_sample_loss at step 49800: 0.082213\n",
      "2023-12-10 06:18:26,280 INFO     Training average negative_sample_loss at step 49800: 0.083079\n",
      "2023-12-10 06:18:26,280 INFO     Training average loss at step 49800: 0.082646\n",
      "2023-12-10 06:19:41,838 INFO     Training average positive_sample_loss at step 49900: 0.083225\n",
      "2023-12-10 06:19:41,838 INFO     Training average negative_sample_loss at step 49900: 0.081945\n",
      "2023-12-10 06:19:41,838 INFO     Training average loss at step 49900: 0.082585\n",
      "2023-12-10 06:21:16,392 INFO     Training average positive_sample_loss at step 50000: 0.082461\n",
      "2023-12-10 06:21:16,392 INFO     Training average negative_sample_loss at step 50000: 0.082108\n",
      "2023-12-10 06:21:16,392 INFO     Training average loss at step 50000: 0.082285\n",
      "2023-12-10 06:21:16,392 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 06:21:17,392 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 06:21:45,851 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 06:22:12,266 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 06:22:41,227 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 06:23:09,685 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 06:23:37,260 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 06:24:05,511 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 06:24:12,874 INFO     Valid MRR at step 50000: 0.742559\n",
      "2023-12-10 06:24:12,874 INFO     Valid MR at step 50000: 45.566580\n",
      "2023-12-10 06:24:12,875 INFO     Valid HITS@1 at step 50000: 0.677440\n",
      "2023-12-10 06:24:12,875 INFO     Valid HITS@3 at step 50000: 0.783330\n",
      "2023-12-10 06:24:12,875 INFO     Valid HITS@10 at step 50000: 0.857410\n",
      "2023-12-10 06:25:29,167 INFO     Training average positive_sample_loss at step 50100: 0.077927\n",
      "2023-12-10 06:25:29,168 INFO     Training average negative_sample_loss at step 50100: 0.080090\n",
      "2023-12-10 06:25:29,168 INFO     Training average loss at step 50100: 0.079009\n",
      "2023-12-10 06:26:48,240 INFO     Training average positive_sample_loss at step 50200: 0.079183\n",
      "2023-12-10 06:26:48,241 INFO     Training average negative_sample_loss at step 50200: 0.078815\n",
      "2023-12-10 06:26:48,241 INFO     Training average loss at step 50200: 0.078999\n",
      "2023-12-10 06:28:08,424 INFO     Training average positive_sample_loss at step 50300: 0.080186\n",
      "2023-12-10 06:28:08,424 INFO     Training average negative_sample_loss at step 50300: 0.079070\n",
      "2023-12-10 06:28:08,424 INFO     Training average loss at step 50300: 0.079628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 06:29:26,314 INFO     Training average positive_sample_loss at step 50400: 0.081051\n",
      "2023-12-10 06:29:26,314 INFO     Training average negative_sample_loss at step 50400: 0.080274\n",
      "2023-12-10 06:29:26,314 INFO     Training average loss at step 50400: 0.080662\n",
      "2023-12-10 06:30:44,206 INFO     Training average positive_sample_loss at step 50500: 0.081354\n",
      "2023-12-10 06:30:44,206 INFO     Training average negative_sample_loss at step 50500: 0.080070\n",
      "2023-12-10 06:30:44,206 INFO     Training average loss at step 50500: 0.080712\n",
      "2023-12-10 06:32:01,848 INFO     Training average positive_sample_loss at step 50600: 0.082080\n",
      "2023-12-10 06:32:01,849 INFO     Training average negative_sample_loss at step 50600: 0.081552\n",
      "2023-12-10 06:32:01,849 INFO     Training average loss at step 50600: 0.081816\n",
      "2023-12-10 06:33:18,060 INFO     Training average positive_sample_loss at step 50700: 0.081945\n",
      "2023-12-10 06:33:18,060 INFO     Training average negative_sample_loss at step 50700: 0.080665\n",
      "2023-12-10 06:33:18,060 INFO     Training average loss at step 50700: 0.081305\n",
      "2023-12-10 06:34:35,382 INFO     Training average positive_sample_loss at step 50800: 0.081944\n",
      "2023-12-10 06:34:35,382 INFO     Training average negative_sample_loss at step 50800: 0.081357\n",
      "2023-12-10 06:34:35,382 INFO     Training average loss at step 50800: 0.081651\n",
      "2023-12-10 06:35:54,216 INFO     Training average positive_sample_loss at step 50900: 0.082425\n",
      "2023-12-10 06:35:54,216 INFO     Training average negative_sample_loss at step 50900: 0.082087\n",
      "2023-12-10 06:35:54,216 INFO     Training average loss at step 50900: 0.082256\n",
      "2023-12-10 06:37:23,968 INFO     Training average positive_sample_loss at step 51000: 0.079950\n",
      "2023-12-10 06:37:23,969 INFO     Training average negative_sample_loss at step 51000: 0.081520\n",
      "2023-12-10 06:37:23,969 INFO     Training average loss at step 51000: 0.080735\n",
      "2023-12-10 06:38:41,836 INFO     Training average positive_sample_loss at step 51100: 0.077429\n",
      "2023-12-10 06:38:41,836 INFO     Training average negative_sample_loss at step 51100: 0.078079\n",
      "2023-12-10 06:38:41,836 INFO     Training average loss at step 51100: 0.077754\n",
      "2023-12-10 06:39:59,529 INFO     Training average positive_sample_loss at step 51200: 0.079165\n",
      "2023-12-10 06:39:59,529 INFO     Training average negative_sample_loss at step 51200: 0.078415\n",
      "2023-12-10 06:39:59,529 INFO     Training average loss at step 51200: 0.078790\n",
      "2023-12-10 06:41:16,354 INFO     Training average positive_sample_loss at step 51300: 0.080694\n",
      "2023-12-10 06:41:16,355 INFO     Training average negative_sample_loss at step 51300: 0.079336\n",
      "2023-12-10 06:41:16,355 INFO     Training average loss at step 51300: 0.080015\n",
      "2023-12-10 06:42:32,856 INFO     Training average positive_sample_loss at step 51400: 0.081287\n",
      "2023-12-10 06:42:32,856 INFO     Training average negative_sample_loss at step 51400: 0.080588\n",
      "2023-12-10 06:42:32,856 INFO     Training average loss at step 51400: 0.080937\n",
      "2023-12-10 06:43:51,106 INFO     Training average positive_sample_loss at step 51500: 0.081529\n",
      "2023-12-10 06:43:51,106 INFO     Training average negative_sample_loss at step 51500: 0.080251\n",
      "2023-12-10 06:43:51,106 INFO     Training average loss at step 51500: 0.080890\n",
      "2023-12-10 06:45:07,138 INFO     Training average positive_sample_loss at step 51600: 0.081884\n",
      "2023-12-10 06:45:07,138 INFO     Training average negative_sample_loss at step 51600: 0.082058\n",
      "2023-12-10 06:45:07,138 INFO     Training average loss at step 51600: 0.081971\n",
      "2023-12-10 06:46:26,117 INFO     Training average positive_sample_loss at step 51700: 0.082511\n",
      "2023-12-10 06:46:26,117 INFO     Training average negative_sample_loss at step 51700: 0.082093\n",
      "2023-12-10 06:46:26,117 INFO     Training average loss at step 51700: 0.082302\n",
      "2023-12-10 06:47:44,847 INFO     Training average positive_sample_loss at step 51800: 0.083168\n",
      "2023-12-10 06:47:44,847 INFO     Training average negative_sample_loss at step 51800: 0.082631\n",
      "2023-12-10 06:47:44,847 INFO     Training average loss at step 51800: 0.082899\n",
      "2023-12-10 06:49:02,556 INFO     Training average positive_sample_loss at step 51900: 0.082262\n",
      "2023-12-10 06:49:02,556 INFO     Training average negative_sample_loss at step 51900: 0.082127\n",
      "2023-12-10 06:49:02,556 INFO     Training average loss at step 51900: 0.082194\n",
      "2023-12-10 06:50:29,446 INFO     Training average positive_sample_loss at step 52000: 0.077284\n",
      "2023-12-10 06:50:29,446 INFO     Training average negative_sample_loss at step 52000: 0.079646\n",
      "2023-12-10 06:50:29,446 INFO     Training average loss at step 52000: 0.078465\n",
      "2023-12-10 06:51:48,048 INFO     Training average positive_sample_loss at step 52100: 0.078590\n",
      "2023-12-10 06:51:48,048 INFO     Training average negative_sample_loss at step 52100: 0.077173\n",
      "2023-12-10 06:51:48,048 INFO     Training average loss at step 52100: 0.077881\n",
      "2023-12-10 06:53:07,848 INFO     Training average positive_sample_loss at step 52200: 0.079543\n",
      "2023-12-10 06:53:07,848 INFO     Training average negative_sample_loss at step 52200: 0.079002\n",
      "2023-12-10 06:53:07,848 INFO     Training average loss at step 52200: 0.079272\n",
      "2023-12-10 06:54:27,780 INFO     Training average positive_sample_loss at step 52300: 0.080661\n",
      "2023-12-10 06:54:27,780 INFO     Training average negative_sample_loss at step 52300: 0.080223\n",
      "2023-12-10 06:54:27,780 INFO     Training average loss at step 52300: 0.080442\n",
      "2023-12-10 06:55:45,917 INFO     Training average positive_sample_loss at step 52400: 0.081273\n",
      "2023-12-10 06:55:45,918 INFO     Training average negative_sample_loss at step 52400: 0.080082\n",
      "2023-12-10 06:55:45,918 INFO     Training average loss at step 52400: 0.080677\n",
      "2023-12-10 06:57:03,062 INFO     Training average positive_sample_loss at step 52500: 0.081697\n",
      "2023-12-10 06:57:03,062 INFO     Training average negative_sample_loss at step 52500: 0.079891\n",
      "2023-12-10 06:57:03,062 INFO     Training average loss at step 52500: 0.080794\n",
      "2023-12-10 06:58:21,699 INFO     Training average positive_sample_loss at step 52600: 0.082008\n",
      "2023-12-10 06:58:21,699 INFO     Training average negative_sample_loss at step 52600: 0.081589\n",
      "2023-12-10 06:58:21,699 INFO     Training average loss at step 52600: 0.081798\n",
      "2023-12-10 06:59:41,285 INFO     Training average positive_sample_loss at step 52700: 0.082415\n",
      "2023-12-10 06:59:41,286 INFO     Training average negative_sample_loss at step 52700: 0.082196\n",
      "2023-12-10 06:59:41,286 INFO     Training average loss at step 52700: 0.082306\n",
      "2023-12-10 07:01:02,754 INFO     Training average positive_sample_loss at step 52800: 0.082303\n",
      "2023-12-10 07:01:02,755 INFO     Training average negative_sample_loss at step 52800: 0.081873\n",
      "2023-12-10 07:01:02,755 INFO     Training average loss at step 52800: 0.082088\n",
      "2023-12-10 07:02:37,252 INFO     Training average positive_sample_loss at step 52900: 0.080386\n",
      "2023-12-10 07:02:37,253 INFO     Training average negative_sample_loss at step 52900: 0.081364\n",
      "2023-12-10 07:02:37,253 INFO     Training average loss at step 52900: 0.080875\n",
      "2023-12-10 07:03:57,995 INFO     Training average positive_sample_loss at step 53000: 0.077470\n",
      "2023-12-10 07:03:57,995 INFO     Training average negative_sample_loss at step 53000: 0.077691\n",
      "2023-12-10 07:03:57,996 INFO     Training average loss at step 53000: 0.077580\n",
      "2023-12-10 07:05:13,089 INFO     Training average positive_sample_loss at step 53100: 0.079051\n",
      "2023-12-10 07:05:13,090 INFO     Training average negative_sample_loss at step 53100: 0.078072\n",
      "2023-12-10 07:05:13,090 INFO     Training average loss at step 53100: 0.078561\n",
      "2023-12-10 07:06:35,034 INFO     Training average positive_sample_loss at step 53200: 0.080233\n",
      "2023-12-10 07:06:35,034 INFO     Training average negative_sample_loss at step 53200: 0.079524\n",
      "2023-12-10 07:06:35,034 INFO     Training average loss at step 53200: 0.079878\n",
      "2023-12-10 07:07:49,620 INFO     Training average positive_sample_loss at step 53300: 0.081072\n",
      "2023-12-10 07:07:49,620 INFO     Training average negative_sample_loss at step 53300: 0.080259\n",
      "2023-12-10 07:07:49,620 INFO     Training average loss at step 53300: 0.080666\n",
      "2023-12-10 07:09:07,108 INFO     Training average positive_sample_loss at step 53400: 0.081822\n",
      "2023-12-10 07:09:07,109 INFO     Training average negative_sample_loss at step 53400: 0.080678\n",
      "2023-12-10 07:09:07,109 INFO     Training average loss at step 53400: 0.081250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 07:10:27,133 INFO     Training average positive_sample_loss at step 53500: 0.081990\n",
      "2023-12-10 07:10:27,133 INFO     Training average negative_sample_loss at step 53500: 0.081806\n",
      "2023-12-10 07:10:27,133 INFO     Training average loss at step 53500: 0.081898\n",
      "2023-12-10 07:11:44,619 INFO     Training average positive_sample_loss at step 53600: 0.082080\n",
      "2023-12-10 07:11:44,619 INFO     Training average negative_sample_loss at step 53600: 0.081356\n",
      "2023-12-10 07:11:44,619 INFO     Training average loss at step 53600: 0.081718\n",
      "2023-12-10 07:12:58,770 INFO     Training average positive_sample_loss at step 53700: 0.082485\n",
      "2023-12-10 07:12:58,771 INFO     Training average negative_sample_loss at step 53700: 0.082129\n",
      "2023-12-10 07:12:58,771 INFO     Training average loss at step 53700: 0.082307\n",
      "2023-12-10 07:14:16,033 INFO     Training average positive_sample_loss at step 53800: 0.082231\n",
      "2023-12-10 07:14:16,034 INFO     Training average negative_sample_loss at step 53800: 0.081645\n",
      "2023-12-10 07:14:16,034 INFO     Training average loss at step 53800: 0.081938\n",
      "2023-12-10 07:15:48,847 INFO     Training average positive_sample_loss at step 53900: 0.076290\n",
      "2023-12-10 07:15:48,847 INFO     Training average negative_sample_loss at step 53900: 0.078152\n",
      "2023-12-10 07:15:48,848 INFO     Training average loss at step 53900: 0.077221\n",
      "2023-12-10 07:17:05,226 INFO     Training average positive_sample_loss at step 54000: 0.078529\n",
      "2023-12-10 07:17:05,226 INFO     Training average negative_sample_loss at step 54000: 0.076691\n",
      "2023-12-10 07:17:05,226 INFO     Training average loss at step 54000: 0.077610\n",
      "2023-12-10 07:18:22,949 INFO     Training average positive_sample_loss at step 54100: 0.079501\n",
      "2023-12-10 07:18:22,949 INFO     Training average negative_sample_loss at step 54100: 0.078968\n",
      "2023-12-10 07:18:22,950 INFO     Training average loss at step 54100: 0.079234\n",
      "2023-12-10 07:19:41,637 INFO     Training average positive_sample_loss at step 54200: 0.080919\n",
      "2023-12-10 07:19:41,637 INFO     Training average negative_sample_loss at step 54200: 0.079335\n",
      "2023-12-10 07:19:41,637 INFO     Training average loss at step 54200: 0.080127\n",
      "2023-12-10 07:20:59,655 INFO     Training average positive_sample_loss at step 54300: 0.081190\n",
      "2023-12-10 07:20:59,655 INFO     Training average negative_sample_loss at step 54300: 0.080364\n",
      "2023-12-10 07:20:59,655 INFO     Training average loss at step 54300: 0.080777\n",
      "2023-12-10 07:22:17,860 INFO     Training average positive_sample_loss at step 54400: 0.081326\n",
      "2023-12-10 07:22:17,860 INFO     Training average negative_sample_loss at step 54400: 0.080313\n",
      "2023-12-10 07:22:17,860 INFO     Training average loss at step 54400: 0.080819\n",
      "2023-12-10 07:23:37,317 INFO     Training average positive_sample_loss at step 54500: 0.082259\n",
      "2023-12-10 07:23:37,317 INFO     Training average negative_sample_loss at step 54500: 0.081994\n",
      "2023-12-10 07:23:37,317 INFO     Training average loss at step 54500: 0.082127\n",
      "2023-12-10 07:24:56,823 INFO     Training average positive_sample_loss at step 54600: 0.081799\n",
      "2023-12-10 07:24:56,823 INFO     Training average negative_sample_loss at step 54600: 0.081171\n",
      "2023-12-10 07:24:56,823 INFO     Training average loss at step 54600: 0.081485\n",
      "2023-12-10 07:26:15,056 INFO     Training average positive_sample_loss at step 54700: 0.082458\n",
      "2023-12-10 07:26:15,056 INFO     Training average negative_sample_loss at step 54700: 0.081195\n",
      "2023-12-10 07:26:15,056 INFO     Training average loss at step 54700: 0.081827\n",
      "2023-12-10 07:27:41,682 INFO     Training average positive_sample_loss at step 54800: 0.078395\n",
      "2023-12-10 07:27:41,683 INFO     Training average negative_sample_loss at step 54800: 0.080164\n",
      "2023-12-10 07:27:41,683 INFO     Training average loss at step 54800: 0.079280\n",
      "2023-12-10 07:28:59,283 INFO     Training average positive_sample_loss at step 54900: 0.077583\n",
      "2023-12-10 07:28:59,283 INFO     Training average negative_sample_loss at step 54900: 0.076801\n",
      "2023-12-10 07:28:59,283 INFO     Training average loss at step 54900: 0.077192\n",
      "2023-12-10 07:30:16,865 INFO     Training average positive_sample_loss at step 55000: 0.078986\n",
      "2023-12-10 07:30:16,865 INFO     Training average negative_sample_loss at step 55000: 0.078009\n",
      "2023-12-10 07:30:16,865 INFO     Training average loss at step 55000: 0.078498\n",
      "2023-12-10 07:31:35,162 INFO     Training average positive_sample_loss at step 55100: 0.080333\n",
      "2023-12-10 07:31:35,162 INFO     Training average negative_sample_loss at step 55100: 0.078853\n",
      "2023-12-10 07:31:35,162 INFO     Training average loss at step 55100: 0.079593\n",
      "2023-12-10 07:32:52,915 INFO     Training average positive_sample_loss at step 55200: 0.081009\n",
      "2023-12-10 07:32:52,915 INFO     Training average negative_sample_loss at step 55200: 0.079366\n",
      "2023-12-10 07:32:52,915 INFO     Training average loss at step 55200: 0.080188\n",
      "2023-12-10 07:34:08,973 INFO     Training average positive_sample_loss at step 55300: 0.080998\n",
      "2023-12-10 07:34:08,973 INFO     Training average negative_sample_loss at step 55300: 0.080581\n",
      "2023-12-10 07:34:08,973 INFO     Training average loss at step 55300: 0.080789\n",
      "2023-12-10 07:35:25,820 INFO     Training average positive_sample_loss at step 55400: 0.081024\n",
      "2023-12-10 07:35:25,821 INFO     Training average negative_sample_loss at step 55400: 0.080109\n",
      "2023-12-10 07:35:25,821 INFO     Training average loss at step 55400: 0.080566\n",
      "2023-12-10 07:36:43,155 INFO     Training average positive_sample_loss at step 55500: 0.082113\n",
      "2023-12-10 07:36:43,155 INFO     Training average negative_sample_loss at step 55500: 0.082275\n",
      "2023-12-10 07:36:43,156 INFO     Training average loss at step 55500: 0.082194\n",
      "2023-12-10 07:38:00,362 INFO     Training average positive_sample_loss at step 55600: 0.082507\n",
      "2023-12-10 07:38:00,362 INFO     Training average negative_sample_loss at step 55600: 0.082720\n",
      "2023-12-10 07:38:00,362 INFO     Training average loss at step 55600: 0.082613\n",
      "2023-12-10 07:39:26,949 INFO     Training average positive_sample_loss at step 55700: 0.082177\n",
      "2023-12-10 07:39:26,950 INFO     Training average negative_sample_loss at step 55700: 0.081749\n",
      "2023-12-10 07:39:26,950 INFO     Training average loss at step 55700: 0.081963\n",
      "2023-12-10 07:40:43,876 INFO     Training average positive_sample_loss at step 55800: 0.076437\n",
      "2023-12-10 07:40:43,876 INFO     Training average negative_sample_loss at step 55800: 0.077760\n",
      "2023-12-10 07:40:43,876 INFO     Training average loss at step 55800: 0.077098\n",
      "2023-12-10 07:42:01,084 INFO     Training average positive_sample_loss at step 55900: 0.078857\n",
      "2023-12-10 07:42:01,084 INFO     Training average negative_sample_loss at step 55900: 0.077746\n",
      "2023-12-10 07:42:01,084 INFO     Training average loss at step 55900: 0.078301\n",
      "2023-12-10 07:43:18,881 INFO     Training average positive_sample_loss at step 56000: 0.079785\n",
      "2023-12-10 07:43:18,881 INFO     Training average negative_sample_loss at step 56000: 0.078667\n",
      "2023-12-10 07:43:18,881 INFO     Training average loss at step 56000: 0.079226\n",
      "2023-12-10 07:44:38,774 INFO     Training average positive_sample_loss at step 56100: 0.080526\n",
      "2023-12-10 07:44:38,774 INFO     Training average negative_sample_loss at step 56100: 0.079054\n",
      "2023-12-10 07:44:38,775 INFO     Training average loss at step 56100: 0.079790\n",
      "2023-12-10 07:45:58,022 INFO     Training average positive_sample_loss at step 56200: 0.080682\n",
      "2023-12-10 07:45:58,022 INFO     Training average negative_sample_loss at step 56200: 0.080381\n",
      "2023-12-10 07:45:58,022 INFO     Training average loss at step 56200: 0.080532\n",
      "2023-12-10 07:47:17,333 INFO     Training average positive_sample_loss at step 56300: 0.081656\n",
      "2023-12-10 07:47:17,333 INFO     Training average negative_sample_loss at step 56300: 0.080860\n",
      "2023-12-10 07:47:17,333 INFO     Training average loss at step 56300: 0.081258\n",
      "2023-12-10 07:48:36,144 INFO     Training average positive_sample_loss at step 56400: 0.081470\n",
      "2023-12-10 07:48:36,145 INFO     Training average negative_sample_loss at step 56400: 0.080823\n",
      "2023-12-10 07:48:36,145 INFO     Training average loss at step 56400: 0.081146\n",
      "2023-12-10 07:49:53,949 INFO     Training average positive_sample_loss at step 56500: 0.081967\n",
      "2023-12-10 07:49:53,950 INFO     Training average negative_sample_loss at step 56500: 0.080718\n",
      "2023-12-10 07:49:53,950 INFO     Training average loss at step 56500: 0.081343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 07:51:13,011 INFO     Training average positive_sample_loss at step 56600: 0.082669\n",
      "2023-12-10 07:51:13,011 INFO     Training average negative_sample_loss at step 56600: 0.082619\n",
      "2023-12-10 07:51:13,011 INFO     Training average loss at step 56600: 0.082644\n",
      "2023-12-10 07:52:37,283 INFO     Training average positive_sample_loss at step 56700: 0.077635\n",
      "2023-12-10 07:52:37,283 INFO     Training average negative_sample_loss at step 56700: 0.079265\n",
      "2023-12-10 07:52:37,283 INFO     Training average loss at step 56700: 0.078450\n",
      "2023-12-10 07:53:54,755 INFO     Training average positive_sample_loss at step 56800: 0.077743\n",
      "2023-12-10 07:53:54,756 INFO     Training average negative_sample_loss at step 56800: 0.076401\n",
      "2023-12-10 07:53:54,756 INFO     Training average loss at step 56800: 0.077072\n",
      "2023-12-10 07:55:11,979 INFO     Training average positive_sample_loss at step 56900: 0.078907\n",
      "2023-12-10 07:55:11,979 INFO     Training average negative_sample_loss at step 56900: 0.077220\n",
      "2023-12-10 07:55:11,979 INFO     Training average loss at step 56900: 0.078063\n",
      "2023-12-10 07:56:31,437 INFO     Training average positive_sample_loss at step 57000: 0.079590\n",
      "2023-12-10 07:56:31,437 INFO     Training average negative_sample_loss at step 57000: 0.078207\n",
      "2023-12-10 07:56:31,437 INFO     Training average loss at step 57000: 0.078899\n",
      "2023-12-10 07:57:49,267 INFO     Training average positive_sample_loss at step 57100: 0.080377\n",
      "2023-12-10 07:57:49,267 INFO     Training average negative_sample_loss at step 57100: 0.079482\n",
      "2023-12-10 07:57:49,267 INFO     Training average loss at step 57100: 0.079929\n",
      "2023-12-10 07:59:07,771 INFO     Training average positive_sample_loss at step 57200: 0.081490\n",
      "2023-12-10 07:59:07,771 INFO     Training average negative_sample_loss at step 57200: 0.080666\n",
      "2023-12-10 07:59:07,771 INFO     Training average loss at step 57200: 0.081078\n",
      "2023-12-10 08:00:25,820 INFO     Training average positive_sample_loss at step 57300: 0.081881\n",
      "2023-12-10 08:00:25,821 INFO     Training average negative_sample_loss at step 57300: 0.081169\n",
      "2023-12-10 08:00:25,821 INFO     Training average loss at step 57300: 0.081525\n",
      "2023-12-10 08:01:44,348 INFO     Training average positive_sample_loss at step 57400: 0.082402\n",
      "2023-12-10 08:01:44,348 INFO     Training average negative_sample_loss at step 57400: 0.081948\n",
      "2023-12-10 08:01:44,348 INFO     Training average loss at step 57400: 0.082175\n",
      "2023-12-10 08:03:03,175 INFO     Training average positive_sample_loss at step 57500: 0.081628\n",
      "2023-12-10 08:03:03,175 INFO     Training average negative_sample_loss at step 57500: 0.081780\n",
      "2023-12-10 08:03:03,175 INFO     Training average loss at step 57500: 0.081704\n",
      "2023-12-10 08:04:34,942 INFO     Training average positive_sample_loss at step 57600: 0.080304\n",
      "2023-12-10 08:04:34,943 INFO     Training average negative_sample_loss at step 57600: 0.081838\n",
      "2023-12-10 08:04:34,943 INFO     Training average loss at step 57600: 0.081071\n",
      "2023-12-10 08:05:54,754 INFO     Training average positive_sample_loss at step 57700: 0.077190\n",
      "2023-12-10 08:05:54,754 INFO     Training average negative_sample_loss at step 57700: 0.076971\n",
      "2023-12-10 08:05:54,754 INFO     Training average loss at step 57700: 0.077080\n",
      "2023-12-10 08:07:10,716 INFO     Training average positive_sample_loss at step 57800: 0.078877\n",
      "2023-12-10 08:07:10,716 INFO     Training average negative_sample_loss at step 57800: 0.077625\n",
      "2023-12-10 08:07:10,716 INFO     Training average loss at step 57800: 0.078251\n",
      "2023-12-10 08:08:28,666 INFO     Training average positive_sample_loss at step 57900: 0.079989\n",
      "2023-12-10 08:08:28,667 INFO     Training average negative_sample_loss at step 57900: 0.079474\n",
      "2023-12-10 08:08:28,667 INFO     Training average loss at step 57900: 0.079731\n",
      "2023-12-10 08:09:45,862 INFO     Training average positive_sample_loss at step 58000: 0.080311\n",
      "2023-12-10 08:09:45,862 INFO     Training average negative_sample_loss at step 58000: 0.078712\n",
      "2023-12-10 08:09:45,862 INFO     Training average loss at step 58000: 0.079512\n",
      "2023-12-10 08:11:04,087 INFO     Training average positive_sample_loss at step 58100: 0.080882\n",
      "2023-12-10 08:11:04,087 INFO     Training average negative_sample_loss at step 58100: 0.080021\n",
      "2023-12-10 08:11:04,087 INFO     Training average loss at step 58100: 0.080452\n",
      "2023-12-10 08:12:20,843 INFO     Training average positive_sample_loss at step 58200: 0.081910\n",
      "2023-12-10 08:12:20,843 INFO     Training average negative_sample_loss at step 58200: 0.081873\n",
      "2023-12-10 08:12:20,843 INFO     Training average loss at step 58200: 0.081892\n",
      "2023-12-10 08:13:38,575 INFO     Training average positive_sample_loss at step 58300: 0.081633\n",
      "2023-12-10 08:13:38,575 INFO     Training average negative_sample_loss at step 58300: 0.080537\n",
      "2023-12-10 08:13:38,575 INFO     Training average loss at step 58300: 0.081085\n",
      "2023-12-10 08:14:56,309 INFO     Training average positive_sample_loss at step 58400: 0.081449\n",
      "2023-12-10 08:14:56,309 INFO     Training average negative_sample_loss at step 58400: 0.079959\n",
      "2023-12-10 08:14:56,309 INFO     Training average loss at step 58400: 0.080704\n",
      "2023-12-10 08:16:13,971 INFO     Training average positive_sample_loss at step 58500: 0.082100\n",
      "2023-12-10 08:16:13,971 INFO     Training average negative_sample_loss at step 58500: 0.082286\n",
      "2023-12-10 08:16:13,971 INFO     Training average loss at step 58500: 0.082193\n",
      "2023-12-10 08:17:45,794 INFO     Training average positive_sample_loss at step 58600: 0.077044\n",
      "2023-12-10 08:17:45,795 INFO     Training average negative_sample_loss at step 58600: 0.078408\n",
      "2023-12-10 08:17:45,795 INFO     Training average loss at step 58600: 0.077726\n",
      "2023-12-10 08:19:04,912 INFO     Training average positive_sample_loss at step 58700: 0.077630\n",
      "2023-12-10 08:19:04,913 INFO     Training average negative_sample_loss at step 58700: 0.077091\n",
      "2023-12-10 08:19:04,913 INFO     Training average loss at step 58700: 0.077360\n",
      "2023-12-10 08:20:20,016 INFO     Training average positive_sample_loss at step 58800: 0.079631\n",
      "2023-12-10 08:20:20,017 INFO     Training average negative_sample_loss at step 58800: 0.078344\n",
      "2023-12-10 08:20:20,017 INFO     Training average loss at step 58800: 0.078988\n",
      "2023-12-10 08:21:37,582 INFO     Training average positive_sample_loss at step 58900: 0.080274\n",
      "2023-12-10 08:21:37,582 INFO     Training average negative_sample_loss at step 58900: 0.078777\n",
      "2023-12-10 08:21:37,582 INFO     Training average loss at step 58900: 0.079526\n",
      "2023-12-10 08:22:55,032 INFO     Training average positive_sample_loss at step 59000: 0.080812\n",
      "2023-12-10 08:22:55,032 INFO     Training average negative_sample_loss at step 59000: 0.079913\n",
      "2023-12-10 08:22:55,032 INFO     Training average loss at step 59000: 0.080362\n",
      "2023-12-10 08:24:11,789 INFO     Training average positive_sample_loss at step 59100: 0.081390\n",
      "2023-12-10 08:24:11,790 INFO     Training average negative_sample_loss at step 59100: 0.080697\n",
      "2023-12-10 08:24:11,790 INFO     Training average loss at step 59100: 0.081043\n",
      "2023-12-10 08:25:28,377 INFO     Training average positive_sample_loss at step 59200: 0.081466\n",
      "2023-12-10 08:25:28,377 INFO     Training average negative_sample_loss at step 59200: 0.079912\n",
      "2023-12-10 08:25:28,377 INFO     Training average loss at step 59200: 0.080689\n",
      "2023-12-10 08:26:44,516 INFO     Training average positive_sample_loss at step 59300: 0.081950\n",
      "2023-12-10 08:26:44,516 INFO     Training average negative_sample_loss at step 59300: 0.081357\n",
      "2023-12-10 08:26:44,516 INFO     Training average loss at step 59300: 0.081654\n",
      "2023-12-10 08:27:59,035 INFO     Training average positive_sample_loss at step 59400: 0.081198\n",
      "2023-12-10 08:27:59,035 INFO     Training average negative_sample_loss at step 59400: 0.080819\n",
      "2023-12-10 08:27:59,035 INFO     Training average loss at step 59400: 0.081008\n",
      "2023-12-10 08:29:27,912 INFO     Training average positive_sample_loss at step 59500: 0.079500\n",
      "2023-12-10 08:29:27,912 INFO     Training average negative_sample_loss at step 59500: 0.081139\n",
      "2023-12-10 08:29:27,913 INFO     Training average loss at step 59500: 0.080320\n",
      "2023-12-10 08:30:45,559 INFO     Training average positive_sample_loss at step 59600: 0.077106\n",
      "2023-12-10 08:30:45,560 INFO     Training average negative_sample_loss at step 59600: 0.075936\n",
      "2023-12-10 08:30:45,560 INFO     Training average loss at step 59600: 0.076521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 08:32:03,578 INFO     Training average positive_sample_loss at step 59700: 0.079014\n",
      "2023-12-10 08:32:03,578 INFO     Training average negative_sample_loss at step 59700: 0.077625\n",
      "2023-12-10 08:32:03,578 INFO     Training average loss at step 59700: 0.078320\n",
      "2023-12-10 08:33:22,907 INFO     Training average positive_sample_loss at step 59800: 0.079265\n",
      "2023-12-10 08:33:22,907 INFO     Training average negative_sample_loss at step 59800: 0.078468\n",
      "2023-12-10 08:33:22,907 INFO     Training average loss at step 59800: 0.078866\n",
      "2023-12-10 08:34:41,114 INFO     Training average positive_sample_loss at step 59900: 0.079998\n",
      "2023-12-10 08:34:41,114 INFO     Training average negative_sample_loss at step 59900: 0.078383\n",
      "2023-12-10 08:34:41,114 INFO     Training average loss at step 59900: 0.079191\n",
      "2023-12-10 08:36:12,588 INFO     Training average positive_sample_loss at step 60000: 0.081147\n",
      "2023-12-10 08:36:12,588 INFO     Training average negative_sample_loss at step 60000: 0.079818\n",
      "2023-12-10 08:36:12,588 INFO     Training average loss at step 60000: 0.080482\n",
      "2023-12-10 08:36:12,588 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 08:36:13,887 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 08:36:46,384 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 08:37:14,299 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 08:37:40,734 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 08:38:27,244 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 08:39:19,387 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 08:40:03,584 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 08:40:12,928 INFO     Valid MRR at step 60000: 0.738510\n",
      "2023-12-10 08:40:12,928 INFO     Valid MR at step 60000: 45.506070\n",
      "2023-12-10 08:40:12,929 INFO     Valid HITS@1 at step 60000: 0.673110\n",
      "2023-12-10 08:40:12,929 INFO     Valid HITS@3 at step 60000: 0.778240\n",
      "2023-12-10 08:40:12,929 INFO     Valid HITS@10 at step 60000: 0.854240\n",
      "2023-12-10 08:41:15,198 INFO     Training average positive_sample_loss at step 60100: 0.081627\n",
      "2023-12-10 08:41:15,199 INFO     Training average negative_sample_loss at step 60100: 0.081032\n",
      "2023-12-10 08:41:15,199 INFO     Training average loss at step 60100: 0.081329\n",
      "2023-12-10 08:42:33,487 INFO     Training average positive_sample_loss at step 60200: 0.081311\n",
      "2023-12-10 08:42:33,488 INFO     Training average negative_sample_loss at step 60200: 0.080648\n",
      "2023-12-10 08:42:33,488 INFO     Training average loss at step 60200: 0.080980\n",
      "2023-12-10 08:43:48,591 INFO     Training average positive_sample_loss at step 60300: 0.081804\n",
      "2023-12-10 08:43:48,592 INFO     Training average negative_sample_loss at step 60300: 0.080599\n",
      "2023-12-10 08:43:48,592 INFO     Training average loss at step 60300: 0.081202\n",
      "2023-12-10 08:45:03,391 INFO     Training average positive_sample_loss at step 60400: 0.081547\n",
      "2023-12-10 08:45:03,391 INFO     Training average negative_sample_loss at step 60400: 0.081022\n",
      "2023-12-10 08:45:03,391 INFO     Training average loss at step 60400: 0.081284\n",
      "2023-12-10 08:46:36,329 INFO     Training average positive_sample_loss at step 60500: 0.076434\n",
      "2023-12-10 08:46:36,329 INFO     Training average negative_sample_loss at step 60500: 0.077855\n",
      "2023-12-10 08:46:36,330 INFO     Training average loss at step 60500: 0.077145\n",
      "2023-12-10 08:47:53,061 INFO     Training average positive_sample_loss at step 60600: 0.078093\n",
      "2023-12-10 08:47:53,062 INFO     Training average negative_sample_loss at step 60600: 0.076474\n",
      "2023-12-10 08:47:53,062 INFO     Training average loss at step 60600: 0.077283\n",
      "2023-12-10 08:49:07,307 INFO     Training average positive_sample_loss at step 60700: 0.079398\n",
      "2023-12-10 08:49:07,307 INFO     Training average negative_sample_loss at step 60700: 0.077743\n",
      "2023-12-10 08:49:07,308 INFO     Training average loss at step 60700: 0.078570\n",
      "2023-12-10 08:50:22,103 INFO     Training average positive_sample_loss at step 60800: 0.080236\n",
      "2023-12-10 08:50:22,103 INFO     Training average negative_sample_loss at step 60800: 0.079515\n",
      "2023-12-10 08:50:22,103 INFO     Training average loss at step 60800: 0.079875\n",
      "2023-12-10 08:51:36,339 INFO     Training average positive_sample_loss at step 60900: 0.080425\n",
      "2023-12-10 08:51:36,339 INFO     Training average negative_sample_loss at step 60900: 0.079500\n",
      "2023-12-10 08:51:36,339 INFO     Training average loss at step 60900: 0.079962\n",
      "2023-12-10 08:52:52,716 INFO     Training average positive_sample_loss at step 61000: 0.080582\n",
      "2023-12-10 08:52:52,716 INFO     Training average negative_sample_loss at step 61000: 0.079356\n",
      "2023-12-10 08:52:52,716 INFO     Training average loss at step 61000: 0.079969\n",
      "2023-12-10 08:54:07,687 INFO     Training average positive_sample_loss at step 61100: 0.081676\n",
      "2023-12-10 08:54:07,688 INFO     Training average negative_sample_loss at step 61100: 0.081560\n",
      "2023-12-10 08:54:07,688 INFO     Training average loss at step 61100: 0.081618\n",
      "2023-12-10 08:55:22,189 INFO     Training average positive_sample_loss at step 61200: 0.081985\n",
      "2023-12-10 08:55:22,189 INFO     Training average negative_sample_loss at step 61200: 0.081293\n",
      "2023-12-10 08:55:22,189 INFO     Training average loss at step 61200: 0.081639\n",
      "2023-12-10 08:56:37,285 INFO     Training average positive_sample_loss at step 61300: 0.081846\n",
      "2023-12-10 08:56:37,285 INFO     Training average negative_sample_loss at step 61300: 0.081480\n",
      "2023-12-10 08:56:37,285 INFO     Training average loss at step 61300: 0.081663\n",
      "2023-12-10 08:58:03,459 INFO     Training average positive_sample_loss at step 61400: 0.078738\n",
      "2023-12-10 08:58:03,459 INFO     Training average negative_sample_loss at step 61400: 0.079437\n",
      "2023-12-10 08:58:03,459 INFO     Training average loss at step 61400: 0.079087\n",
      "2023-12-10 08:59:20,832 INFO     Training average positive_sample_loss at step 61500: 0.076583\n",
      "2023-12-10 08:59:20,832 INFO     Training average negative_sample_loss at step 61500: 0.075973\n",
      "2023-12-10 08:59:20,832 INFO     Training average loss at step 61500: 0.076278\n",
      "2023-12-10 09:00:37,612 INFO     Training average positive_sample_loss at step 61600: 0.079319\n",
      "2023-12-10 09:00:37,612 INFO     Training average negative_sample_loss at step 61600: 0.078215\n",
      "2023-12-10 09:00:37,612 INFO     Training average loss at step 61600: 0.078767\n",
      "2023-12-10 09:01:52,202 INFO     Training average positive_sample_loss at step 61700: 0.079783\n",
      "2023-12-10 09:01:52,203 INFO     Training average negative_sample_loss at step 61700: 0.078772\n",
      "2023-12-10 09:01:52,203 INFO     Training average loss at step 61700: 0.079278\n",
      "2023-12-10 09:03:06,902 INFO     Training average positive_sample_loss at step 61800: 0.080395\n",
      "2023-12-10 09:03:06,903 INFO     Training average negative_sample_loss at step 61800: 0.078556\n",
      "2023-12-10 09:03:06,903 INFO     Training average loss at step 61800: 0.079475\n",
      "2023-12-10 09:04:21,168 INFO     Training average positive_sample_loss at step 61900: 0.081154\n",
      "2023-12-10 09:04:21,168 INFO     Training average negative_sample_loss at step 61900: 0.080096\n",
      "2023-12-10 09:04:21,168 INFO     Training average loss at step 61900: 0.080625\n",
      "2023-12-10 09:05:38,037 INFO     Training average positive_sample_loss at step 62000: 0.081381\n",
      "2023-12-10 09:05:38,037 INFO     Training average negative_sample_loss at step 62000: 0.080440\n",
      "2023-12-10 09:05:38,038 INFO     Training average loss at step 62000: 0.080911\n",
      "2023-12-10 09:06:55,257 INFO     Training average positive_sample_loss at step 62100: 0.081506\n",
      "2023-12-10 09:06:55,257 INFO     Training average negative_sample_loss at step 62100: 0.080770\n",
      "2023-12-10 09:06:55,257 INFO     Training average loss at step 62100: 0.081138\n",
      "2023-12-10 09:08:08,821 INFO     Training average positive_sample_loss at step 62200: 0.081858\n",
      "2023-12-10 09:08:08,821 INFO     Training average negative_sample_loss at step 62200: 0.080954\n",
      "2023-12-10 09:08:08,821 INFO     Training average loss at step 62200: 0.081406\n",
      "2023-12-10 09:09:24,795 INFO     Training average positive_sample_loss at step 62300: 0.081471\n",
      "2023-12-10 09:09:24,795 INFO     Training average negative_sample_loss at step 62300: 0.081178\n",
      "2023-12-10 09:09:24,795 INFO     Training average loss at step 62300: 0.081325\n",
      "2023-12-10 09:10:52,141 INFO     Training average positive_sample_loss at step 62400: 0.075937\n",
      "2023-12-10 09:10:52,141 INFO     Training average negative_sample_loss at step 62400: 0.077005\n",
      "2023-12-10 09:10:52,141 INFO     Training average loss at step 62400: 0.076471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 09:12:10,150 INFO     Training average positive_sample_loss at step 62500: 0.078335\n",
      "2023-12-10 09:12:10,150 INFO     Training average negative_sample_loss at step 62500: 0.076861\n",
      "2023-12-10 09:12:10,150 INFO     Training average loss at step 62500: 0.077598\n",
      "2023-12-10 09:13:27,183 INFO     Training average positive_sample_loss at step 62600: 0.078584\n",
      "2023-12-10 09:13:27,183 INFO     Training average negative_sample_loss at step 62600: 0.077695\n",
      "2023-12-10 09:13:27,183 INFO     Training average loss at step 62600: 0.078140\n",
      "2023-12-10 09:14:45,011 INFO     Training average positive_sample_loss at step 62700: 0.080568\n",
      "2023-12-10 09:14:45,011 INFO     Training average negative_sample_loss at step 62700: 0.079501\n",
      "2023-12-10 09:14:45,011 INFO     Training average loss at step 62700: 0.080034\n",
      "2023-12-10 09:16:02,193 INFO     Training average positive_sample_loss at step 62800: 0.080971\n",
      "2023-12-10 09:16:02,193 INFO     Training average negative_sample_loss at step 62800: 0.079426\n",
      "2023-12-10 09:16:02,193 INFO     Training average loss at step 62800: 0.080198\n",
      "2023-12-10 09:17:19,476 INFO     Training average positive_sample_loss at step 62900: 0.080353\n",
      "2023-12-10 09:17:19,476 INFO     Training average negative_sample_loss at step 62900: 0.079343\n",
      "2023-12-10 09:17:19,476 INFO     Training average loss at step 62900: 0.079848\n",
      "2023-12-10 09:18:35,914 INFO     Training average positive_sample_loss at step 63000: 0.081315\n",
      "2023-12-10 09:18:35,914 INFO     Training average negative_sample_loss at step 63000: 0.080942\n",
      "2023-12-10 09:18:35,914 INFO     Training average loss at step 63000: 0.081129\n",
      "2023-12-10 09:19:52,536 INFO     Training average positive_sample_loss at step 63100: 0.082228\n",
      "2023-12-10 09:19:52,537 INFO     Training average negative_sample_loss at step 63100: 0.081298\n",
      "2023-12-10 09:19:52,537 INFO     Training average loss at step 63100: 0.081763\n",
      "2023-12-10 09:21:05,954 INFO     Training average positive_sample_loss at step 63200: 0.080956\n",
      "2023-12-10 09:21:05,954 INFO     Training average negative_sample_loss at step 63200: 0.079623\n",
      "2023-12-10 09:21:05,954 INFO     Training average loss at step 63200: 0.080290\n",
      "2023-12-10 09:22:35,219 INFO     Training average positive_sample_loss at step 63300: 0.077931\n",
      "2023-12-10 09:22:35,219 INFO     Training average negative_sample_loss at step 63300: 0.079738\n",
      "2023-12-10 09:22:35,219 INFO     Training average loss at step 63300: 0.078834\n",
      "2023-12-10 09:23:49,121 INFO     Training average positive_sample_loss at step 63400: 0.077296\n",
      "2023-12-10 09:23:49,121 INFO     Training average negative_sample_loss at step 63400: 0.075984\n",
      "2023-12-10 09:23:49,122 INFO     Training average loss at step 63400: 0.076640\n",
      "2023-12-10 09:25:04,690 INFO     Training average positive_sample_loss at step 63500: 0.079157\n",
      "2023-12-10 09:25:04,690 INFO     Training average negative_sample_loss at step 63500: 0.077458\n",
      "2023-12-10 09:25:04,690 INFO     Training average loss at step 63500: 0.078308\n",
      "2023-12-10 09:26:19,402 INFO     Training average positive_sample_loss at step 63600: 0.079723\n",
      "2023-12-10 09:26:19,402 INFO     Training average negative_sample_loss at step 63600: 0.078330\n",
      "2023-12-10 09:26:19,403 INFO     Training average loss at step 63600: 0.079026\n",
      "2023-12-10 09:27:39,503 INFO     Training average positive_sample_loss at step 63700: 0.080607\n",
      "2023-12-10 09:27:39,503 INFO     Training average negative_sample_loss at step 63700: 0.079790\n",
      "2023-12-10 09:27:39,503 INFO     Training average loss at step 63700: 0.080199\n",
      "2023-12-10 09:28:52,779 INFO     Training average positive_sample_loss at step 63800: 0.080990\n",
      "2023-12-10 09:28:52,780 INFO     Training average negative_sample_loss at step 63800: 0.080343\n",
      "2023-12-10 09:28:52,780 INFO     Training average loss at step 63800: 0.080666\n",
      "2023-12-10 09:30:07,969 INFO     Training average positive_sample_loss at step 63900: 0.081335\n",
      "2023-12-10 09:30:07,969 INFO     Training average negative_sample_loss at step 63900: 0.080528\n",
      "2023-12-10 09:30:07,969 INFO     Training average loss at step 63900: 0.080931\n",
      "2023-12-10 09:31:23,350 INFO     Training average positive_sample_loss at step 64000: 0.081362\n",
      "2023-12-10 09:31:23,350 INFO     Training average negative_sample_loss at step 64000: 0.080357\n",
      "2023-12-10 09:31:23,350 INFO     Training average loss at step 64000: 0.080859\n",
      "2023-12-10 09:32:38,880 INFO     Training average positive_sample_loss at step 64100: 0.080816\n",
      "2023-12-10 09:32:38,881 INFO     Training average negative_sample_loss at step 64100: 0.080263\n",
      "2023-12-10 09:32:38,881 INFO     Training average loss at step 64100: 0.080540\n",
      "2023-12-10 09:34:02,937 INFO     Training average positive_sample_loss at step 64200: 0.080611\n",
      "2023-12-10 09:34:02,937 INFO     Training average negative_sample_loss at step 64200: 0.080630\n",
      "2023-12-10 09:34:02,937 INFO     Training average loss at step 64200: 0.080621\n",
      "2023-12-10 09:35:19,747 INFO     Training average positive_sample_loss at step 64300: 0.076322\n",
      "2023-12-10 09:35:19,747 INFO     Training average negative_sample_loss at step 64300: 0.076927\n",
      "2023-12-10 09:35:19,747 INFO     Training average loss at step 64300: 0.076625\n",
      "2023-12-10 09:36:35,441 INFO     Training average positive_sample_loss at step 64400: 0.078535\n",
      "2023-12-10 09:36:35,441 INFO     Training average negative_sample_loss at step 64400: 0.077140\n",
      "2023-12-10 09:36:35,442 INFO     Training average loss at step 64400: 0.077838\n",
      "2023-12-10 09:37:50,473 INFO     Training average positive_sample_loss at step 64500: 0.079667\n",
      "2023-12-10 09:37:50,473 INFO     Training average negative_sample_loss at step 64500: 0.078815\n",
      "2023-12-10 09:37:50,473 INFO     Training average loss at step 64500: 0.079241\n",
      "2023-12-10 09:39:05,436 INFO     Training average positive_sample_loss at step 64600: 0.079697\n",
      "2023-12-10 09:39:05,437 INFO     Training average negative_sample_loss at step 64600: 0.078437\n",
      "2023-12-10 09:39:05,437 INFO     Training average loss at step 64600: 0.079067\n",
      "2023-12-10 09:40:21,390 INFO     Training average positive_sample_loss at step 64700: 0.080213\n",
      "2023-12-10 09:40:21,390 INFO     Training average negative_sample_loss at step 64700: 0.078458\n",
      "2023-12-10 09:40:21,390 INFO     Training average loss at step 64700: 0.079336\n",
      "2023-12-10 09:41:36,143 INFO     Training average positive_sample_loss at step 64800: 0.081420\n",
      "2023-12-10 09:41:36,144 INFO     Training average negative_sample_loss at step 64800: 0.080861\n",
      "2023-12-10 09:41:36,144 INFO     Training average loss at step 64800: 0.081140\n",
      "2023-12-10 09:42:51,423 INFO     Training average positive_sample_loss at step 64900: 0.080872\n",
      "2023-12-10 09:42:51,423 INFO     Training average negative_sample_loss at step 64900: 0.080074\n",
      "2023-12-10 09:42:51,423 INFO     Training average loss at step 64900: 0.080473\n",
      "2023-12-10 09:44:05,500 INFO     Training average positive_sample_loss at step 65000: 0.081109\n",
      "2023-12-10 09:44:05,500 INFO     Training average negative_sample_loss at step 65000: 0.079436\n",
      "2023-12-10 09:44:05,500 INFO     Training average loss at step 65000: 0.080273\n",
      "2023-12-10 09:45:21,699 INFO     Training average positive_sample_loss at step 65100: 0.081672\n",
      "2023-12-10 09:45:21,700 INFO     Training average negative_sample_loss at step 65100: 0.081134\n",
      "2023-12-10 09:45:21,700 INFO     Training average loss at step 65100: 0.081403\n",
      "2023-12-10 09:46:48,831 INFO     Training average positive_sample_loss at step 65200: 0.076611\n",
      "2023-12-10 09:46:48,831 INFO     Training average negative_sample_loss at step 65200: 0.077863\n",
      "2023-12-10 09:46:48,831 INFO     Training average loss at step 65200: 0.077237\n",
      "2023-12-10 09:48:03,695 INFO     Training average positive_sample_loss at step 65300: 0.077069\n",
      "2023-12-10 09:48:03,696 INFO     Training average negative_sample_loss at step 65300: 0.076776\n",
      "2023-12-10 09:48:03,696 INFO     Training average loss at step 65300: 0.076923\n",
      "2023-12-10 09:49:18,137 INFO     Training average positive_sample_loss at step 65400: 0.078458\n",
      "2023-12-10 09:49:18,138 INFO     Training average negative_sample_loss at step 65400: 0.076762\n",
      "2023-12-10 09:49:18,138 INFO     Training average loss at step 65400: 0.077610\n",
      "2023-12-10 09:50:32,876 INFO     Training average positive_sample_loss at step 65500: 0.079934\n",
      "2023-12-10 09:50:32,876 INFO     Training average negative_sample_loss at step 65500: 0.078682\n",
      "2023-12-10 09:50:32,876 INFO     Training average loss at step 65500: 0.079308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 09:51:47,965 INFO     Training average positive_sample_loss at step 65600: 0.079612\n",
      "2023-12-10 09:51:47,965 INFO     Training average negative_sample_loss at step 65600: 0.078326\n",
      "2023-12-10 09:51:47,966 INFO     Training average loss at step 65600: 0.078969\n",
      "2023-12-10 09:53:03,801 INFO     Training average positive_sample_loss at step 65700: 0.080761\n",
      "2023-12-10 09:53:03,801 INFO     Training average negative_sample_loss at step 65700: 0.079068\n",
      "2023-12-10 09:53:03,801 INFO     Training average loss at step 65700: 0.079915\n",
      "2023-12-10 09:54:21,258 INFO     Training average positive_sample_loss at step 65800: 0.081016\n",
      "2023-12-10 09:54:21,258 INFO     Training average negative_sample_loss at step 65800: 0.080105\n",
      "2023-12-10 09:54:21,258 INFO     Training average loss at step 65800: 0.080561\n",
      "2023-12-10 09:55:39,988 INFO     Training average positive_sample_loss at step 65900: 0.081063\n",
      "2023-12-10 09:55:39,988 INFO     Training average negative_sample_loss at step 65900: 0.081022\n",
      "2023-12-10 09:55:39,988 INFO     Training average loss at step 65900: 0.081042\n",
      "2023-12-10 09:56:55,572 INFO     Training average positive_sample_loss at step 66000: 0.081948\n",
      "2023-12-10 09:56:55,572 INFO     Training average negative_sample_loss at step 66000: 0.081149\n",
      "2023-12-10 09:56:55,572 INFO     Training average loss at step 66000: 0.081548\n",
      "2023-12-10 09:58:19,181 INFO     Training average positive_sample_loss at step 66100: 0.079455\n",
      "2023-12-10 09:58:19,181 INFO     Training average negative_sample_loss at step 66100: 0.080158\n",
      "2023-12-10 09:58:19,181 INFO     Training average loss at step 66100: 0.079806\n",
      "2023-12-10 09:59:35,723 INFO     Training average positive_sample_loss at step 66200: 0.076779\n",
      "2023-12-10 09:59:35,723 INFO     Training average negative_sample_loss at step 66200: 0.076425\n",
      "2023-12-10 09:59:35,723 INFO     Training average loss at step 66200: 0.076602\n",
      "2023-12-10 10:00:51,249 INFO     Training average positive_sample_loss at step 66300: 0.078135\n",
      "2023-12-10 10:00:51,249 INFO     Training average negative_sample_loss at step 66300: 0.076341\n",
      "2023-12-10 10:00:51,249 INFO     Training average loss at step 66300: 0.077238\n",
      "2023-12-10 10:02:07,276 INFO     Training average positive_sample_loss at step 66400: 0.079190\n",
      "2023-12-10 10:02:07,277 INFO     Training average negative_sample_loss at step 66400: 0.078050\n",
      "2023-12-10 10:02:07,277 INFO     Training average loss at step 66400: 0.078620\n",
      "2023-12-10 10:03:24,885 INFO     Training average positive_sample_loss at step 66500: 0.080036\n",
      "2023-12-10 10:03:24,885 INFO     Training average negative_sample_loss at step 66500: 0.079030\n",
      "2023-12-10 10:03:24,885 INFO     Training average loss at step 66500: 0.079533\n",
      "2023-12-10 10:04:40,690 INFO     Training average positive_sample_loss at step 66600: 0.080892\n",
      "2023-12-10 10:04:40,691 INFO     Training average negative_sample_loss at step 66600: 0.079777\n",
      "2023-12-10 10:04:40,691 INFO     Training average loss at step 66600: 0.080335\n",
      "2023-12-10 10:05:56,064 INFO     Training average positive_sample_loss at step 66700: 0.080641\n",
      "2023-12-10 10:05:56,065 INFO     Training average negative_sample_loss at step 66700: 0.078999\n",
      "2023-12-10 10:05:56,065 INFO     Training average loss at step 66700: 0.079820\n",
      "2023-12-10 10:07:10,026 INFO     Training average positive_sample_loss at step 66800: 0.080930\n",
      "2023-12-10 10:07:10,026 INFO     Training average negative_sample_loss at step 66800: 0.080432\n",
      "2023-12-10 10:07:10,026 INFO     Training average loss at step 66800: 0.080681\n",
      "2023-12-10 10:08:25,198 INFO     Training average positive_sample_loss at step 66900: 0.081844\n",
      "2023-12-10 10:08:25,198 INFO     Training average negative_sample_loss at step 66900: 0.080240\n",
      "2023-12-10 10:08:25,198 INFO     Training average loss at step 66900: 0.081042\n",
      "2023-12-10 10:09:41,458 INFO     Training average positive_sample_loss at step 67000: 0.081195\n",
      "2023-12-10 10:09:41,459 INFO     Training average negative_sample_loss at step 67000: 0.080095\n",
      "2023-12-10 10:09:41,459 INFO     Training average loss at step 67000: 0.080645\n",
      "2023-12-10 10:11:12,691 INFO     Training average positive_sample_loss at step 67100: 0.075836\n",
      "2023-12-10 10:11:12,692 INFO     Training average negative_sample_loss at step 67100: 0.076931\n",
      "2023-12-10 10:11:12,692 INFO     Training average loss at step 67100: 0.076384\n",
      "2023-12-10 10:12:30,899 INFO     Training average positive_sample_loss at step 67200: 0.077392\n",
      "2023-12-10 10:12:30,899 INFO     Training average negative_sample_loss at step 67200: 0.076487\n",
      "2023-12-10 10:12:30,899 INFO     Training average loss at step 67200: 0.076940\n",
      "2023-12-10 10:13:46,323 INFO     Training average positive_sample_loss at step 67300: 0.078531\n",
      "2023-12-10 10:13:46,324 INFO     Training average negative_sample_loss at step 67300: 0.077612\n",
      "2023-12-10 10:13:46,324 INFO     Training average loss at step 67300: 0.078072\n",
      "2023-12-10 10:15:01,073 INFO     Training average positive_sample_loss at step 67400: 0.079482\n",
      "2023-12-10 10:15:01,073 INFO     Training average negative_sample_loss at step 67400: 0.078060\n",
      "2023-12-10 10:15:01,073 INFO     Training average loss at step 67400: 0.078771\n",
      "2023-12-10 10:16:16,924 INFO     Training average positive_sample_loss at step 67500: 0.080916\n",
      "2023-12-10 10:16:16,924 INFO     Training average negative_sample_loss at step 67500: 0.079646\n",
      "2023-12-10 10:16:16,924 INFO     Training average loss at step 67500: 0.080281\n",
      "2023-12-10 10:17:31,472 INFO     Training average positive_sample_loss at step 67600: 0.081213\n",
      "2023-12-10 10:17:31,472 INFO     Training average negative_sample_loss at step 67600: 0.080326\n",
      "2023-12-10 10:17:31,472 INFO     Training average loss at step 67600: 0.080769\n",
      "2023-12-10 10:18:46,631 INFO     Training average positive_sample_loss at step 67700: 0.081168\n",
      "2023-12-10 10:18:46,631 INFO     Training average negative_sample_loss at step 67700: 0.080041\n",
      "2023-12-10 10:18:46,631 INFO     Training average loss at step 67700: 0.080604\n",
      "2023-12-10 10:20:01,501 INFO     Training average positive_sample_loss at step 67800: 0.080791\n",
      "2023-12-10 10:20:01,501 INFO     Training average negative_sample_loss at step 67800: 0.079391\n",
      "2023-12-10 10:20:01,501 INFO     Training average loss at step 67800: 0.080091\n",
      "2023-12-10 10:21:17,965 INFO     Training average positive_sample_loss at step 67900: 0.081025\n",
      "2023-12-10 10:21:17,965 INFO     Training average negative_sample_loss at step 67900: 0.080431\n",
      "2023-12-10 10:21:17,965 INFO     Training average loss at step 67900: 0.080728\n",
      "2023-12-10 10:22:44,407 INFO     Training average positive_sample_loss at step 68000: 0.078917\n",
      "2023-12-10 10:22:44,407 INFO     Training average negative_sample_loss at step 68000: 0.080210\n",
      "2023-12-10 10:22:44,407 INFO     Training average loss at step 68000: 0.079564\n",
      "2023-12-10 10:24:00,570 INFO     Training average positive_sample_loss at step 68100: 0.077064\n",
      "2023-12-10 10:24:00,571 INFO     Training average negative_sample_loss at step 68100: 0.075816\n",
      "2023-12-10 10:24:00,571 INFO     Training average loss at step 68100: 0.076440\n",
      "2023-12-10 10:25:15,140 INFO     Training average positive_sample_loss at step 68200: 0.077957\n",
      "2023-12-10 10:25:15,140 INFO     Training average negative_sample_loss at step 68200: 0.075921\n",
      "2023-12-10 10:25:15,140 INFO     Training average loss at step 68200: 0.076939\n",
      "2023-12-10 10:26:29,115 INFO     Training average positive_sample_loss at step 68300: 0.079542\n",
      "2023-12-10 10:26:29,115 INFO     Training average negative_sample_loss at step 68300: 0.078088\n",
      "2023-12-10 10:26:29,115 INFO     Training average loss at step 68300: 0.078815\n",
      "2023-12-10 10:27:42,943 INFO     Training average positive_sample_loss at step 68400: 0.079852\n",
      "2023-12-10 10:27:42,943 INFO     Training average negative_sample_loss at step 68400: 0.078574\n",
      "2023-12-10 10:27:42,943 INFO     Training average loss at step 68400: 0.079213\n",
      "2023-12-10 10:28:58,092 INFO     Training average positive_sample_loss at step 68500: 0.080392\n",
      "2023-12-10 10:28:58,093 INFO     Training average negative_sample_loss at step 68500: 0.079124\n",
      "2023-12-10 10:28:58,093 INFO     Training average loss at step 68500: 0.079758\n",
      "2023-12-10 10:30:13,378 INFO     Training average positive_sample_loss at step 68600: 0.080680\n",
      "2023-12-10 10:30:13,379 INFO     Training average negative_sample_loss at step 68600: 0.079461\n",
      "2023-12-10 10:30:13,379 INFO     Training average loss at step 68600: 0.080070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 10:31:30,194 INFO     Training average positive_sample_loss at step 68700: 0.080718\n",
      "2023-12-10 10:31:30,194 INFO     Training average negative_sample_loss at step 68700: 0.079814\n",
      "2023-12-10 10:31:30,195 INFO     Training average loss at step 68700: 0.080266\n",
      "2023-12-10 10:32:45,425 INFO     Training average positive_sample_loss at step 68800: 0.081255\n",
      "2023-12-10 10:32:45,425 INFO     Training average negative_sample_loss at step 68800: 0.080721\n",
      "2023-12-10 10:32:45,425 INFO     Training average loss at step 68800: 0.080988\n",
      "2023-12-10 10:34:02,265 INFO     Training average positive_sample_loss at step 68900: 0.081256\n",
      "2023-12-10 10:34:02,265 INFO     Training average negative_sample_loss at step 68900: 0.080247\n",
      "2023-12-10 10:34:02,265 INFO     Training average loss at step 68900: 0.080752\n",
      "2023-12-10 10:35:27,389 INFO     Training average positive_sample_loss at step 69000: 0.076154\n",
      "2023-12-10 10:35:27,389 INFO     Training average negative_sample_loss at step 69000: 0.077462\n",
      "2023-12-10 10:35:27,389 INFO     Training average loss at step 69000: 0.076808\n",
      "2023-12-10 10:36:42,864 INFO     Training average positive_sample_loss at step 69100: 0.077215\n",
      "2023-12-10 10:36:42,865 INFO     Training average negative_sample_loss at step 69100: 0.076034\n",
      "2023-12-10 10:36:42,865 INFO     Training average loss at step 69100: 0.076624\n",
      "2023-12-10 10:37:58,986 INFO     Training average positive_sample_loss at step 69200: 0.078765\n",
      "2023-12-10 10:37:58,987 INFO     Training average negative_sample_loss at step 69200: 0.076661\n",
      "2023-12-10 10:37:58,987 INFO     Training average loss at step 69200: 0.077713\n",
      "2023-12-10 10:39:17,589 INFO     Training average positive_sample_loss at step 69300: 0.079231\n",
      "2023-12-10 10:39:17,589 INFO     Training average negative_sample_loss at step 69300: 0.078035\n",
      "2023-12-10 10:39:17,589 INFO     Training average loss at step 69300: 0.078633\n",
      "2023-12-10 10:40:34,184 INFO     Training average positive_sample_loss at step 69400: 0.080152\n",
      "2023-12-10 10:40:34,184 INFO     Training average negative_sample_loss at step 69400: 0.078775\n",
      "2023-12-10 10:40:34,185 INFO     Training average loss at step 69400: 0.079464\n",
      "2023-12-10 10:41:49,516 INFO     Training average positive_sample_loss at step 69500: 0.080023\n",
      "2023-12-10 10:41:49,516 INFO     Training average negative_sample_loss at step 69500: 0.078932\n",
      "2023-12-10 10:41:49,516 INFO     Training average loss at step 69500: 0.079478\n",
      "2023-12-10 10:43:04,790 INFO     Training average positive_sample_loss at step 69600: 0.081174\n",
      "2023-12-10 10:43:04,790 INFO     Training average negative_sample_loss at step 69600: 0.080583\n",
      "2023-12-10 10:43:04,790 INFO     Training average loss at step 69600: 0.080879\n",
      "2023-12-10 10:44:20,831 INFO     Training average positive_sample_loss at step 69700: 0.081132\n",
      "2023-12-10 10:44:20,831 INFO     Training average negative_sample_loss at step 69700: 0.080116\n",
      "2023-12-10 10:44:20,831 INFO     Training average loss at step 69700: 0.080624\n",
      "2023-12-10 10:45:37,884 INFO     Training average positive_sample_loss at step 69800: 0.081699\n",
      "2023-12-10 10:45:37,884 INFO     Training average negative_sample_loss at step 69800: 0.079736\n",
      "2023-12-10 10:45:37,884 INFO     Training average loss at step 69800: 0.080717\n",
      "2023-12-10 10:47:08,196 INFO     Training average positive_sample_loss at step 69900: 0.077846\n",
      "2023-12-10 10:47:08,197 INFO     Training average negative_sample_loss at step 69900: 0.079670\n",
      "2023-12-10 10:47:08,197 INFO     Training average loss at step 69900: 0.078758\n",
      "2023-12-10 10:48:38,752 INFO     Training average positive_sample_loss at step 70000: 0.076539\n",
      "2023-12-10 10:48:38,752 INFO     Training average negative_sample_loss at step 70000: 0.074939\n",
      "2023-12-10 10:48:38,752 INFO     Training average loss at step 70000: 0.075739\n",
      "2023-12-10 10:48:38,752 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 10:48:39,599 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 10:49:12,687 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 10:49:45,541 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 10:50:18,954 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 10:50:52,388 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 10:51:24,709 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 10:51:56,445 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 10:52:04,306 INFO     Valid MRR at step 70000: 0.740893\n",
      "2023-12-10 10:52:04,306 INFO     Valid MR at step 70000: 45.691810\n",
      "2023-12-10 10:52:04,306 INFO     Valid HITS@1 at step 70000: 0.676700\n",
      "2023-12-10 10:52:04,306 INFO     Valid HITS@3 at step 70000: 0.780360\n",
      "2023-12-10 10:52:04,306 INFO     Valid HITS@10 at step 70000: 0.854860\n",
      "2023-12-10 10:53:05,748 INFO     Training average positive_sample_loss at step 70100: 0.078198\n",
      "2023-12-10 10:53:05,748 INFO     Training average negative_sample_loss at step 70100: 0.076982\n",
      "2023-12-10 10:53:05,748 INFO     Training average loss at step 70100: 0.077590\n",
      "2023-12-10 10:54:21,982 INFO     Training average positive_sample_loss at step 70200: 0.078620\n",
      "2023-12-10 10:54:21,983 INFO     Training average negative_sample_loss at step 70200: 0.076754\n",
      "2023-12-10 10:54:21,983 INFO     Training average loss at step 70200: 0.077687\n",
      "2023-12-10 10:55:39,691 INFO     Training average positive_sample_loss at step 70300: 0.080131\n",
      "2023-12-10 10:55:39,691 INFO     Training average negative_sample_loss at step 70300: 0.078861\n",
      "2023-12-10 10:55:39,691 INFO     Training average loss at step 70300: 0.079496\n",
      "2023-12-10 10:56:55,111 INFO     Training average positive_sample_loss at step 70400: 0.080237\n",
      "2023-12-10 10:56:55,112 INFO     Training average negative_sample_loss at step 70400: 0.079182\n",
      "2023-12-10 10:56:55,112 INFO     Training average loss at step 70400: 0.079710\n",
      "2023-12-10 10:58:16,303 INFO     Training average positive_sample_loss at step 70500: 0.081133\n",
      "2023-12-10 10:58:16,304 INFO     Training average negative_sample_loss at step 70500: 0.079487\n",
      "2023-12-10 10:58:16,304 INFO     Training average loss at step 70500: 0.080310\n",
      "2023-12-10 10:59:31,504 INFO     Training average positive_sample_loss at step 70600: 0.081139\n",
      "2023-12-10 10:59:31,504 INFO     Training average negative_sample_loss at step 70600: 0.080058\n",
      "2023-12-10 10:59:31,504 INFO     Training average loss at step 70600: 0.080598\n",
      "2023-12-10 11:00:47,278 INFO     Training average positive_sample_loss at step 70700: 0.081208\n",
      "2023-12-10 11:00:47,278 INFO     Training average negative_sample_loss at step 70700: 0.080100\n",
      "2023-12-10 11:00:47,278 INFO     Training average loss at step 70700: 0.080654\n",
      "2023-12-10 11:02:11,844 INFO     Training average positive_sample_loss at step 70800: 0.081195\n",
      "2023-12-10 11:02:11,845 INFO     Training average negative_sample_loss at step 70800: 0.080625\n",
      "2023-12-10 11:02:11,845 INFO     Training average loss at step 70800: 0.080910\n",
      "2023-12-10 11:03:30,266 INFO     Training average positive_sample_loss at step 70900: 0.074984\n",
      "2023-12-10 11:03:30,267 INFO     Training average negative_sample_loss at step 70900: 0.075528\n",
      "2023-12-10 11:03:30,267 INFO     Training average loss at step 70900: 0.075256\n",
      "2023-12-10 11:04:45,657 INFO     Training average positive_sample_loss at step 71000: 0.077939\n",
      "2023-12-10 11:04:45,657 INFO     Training average negative_sample_loss at step 71000: 0.077107\n",
      "2023-12-10 11:04:45,657 INFO     Training average loss at step 71000: 0.077523\n",
      "2023-12-10 11:06:03,262 INFO     Training average positive_sample_loss at step 71100: 0.078681\n",
      "2023-12-10 11:06:03,262 INFO     Training average negative_sample_loss at step 71100: 0.077247\n",
      "2023-12-10 11:06:03,262 INFO     Training average loss at step 71100: 0.077964\n",
      "2023-12-10 11:07:19,649 INFO     Training average positive_sample_loss at step 71200: 0.079447\n",
      "2023-12-10 11:07:19,650 INFO     Training average negative_sample_loss at step 71200: 0.077293\n",
      "2023-12-10 11:07:19,650 INFO     Training average loss at step 71200: 0.078370\n",
      "2023-12-10 11:08:33,674 INFO     Training average positive_sample_loss at step 71300: 0.080165\n",
      "2023-12-10 11:08:33,674 INFO     Training average negative_sample_loss at step 71300: 0.079729\n",
      "2023-12-10 11:08:33,674 INFO     Training average loss at step 71300: 0.079947\n",
      "2023-12-10 11:09:48,402 INFO     Training average positive_sample_loss at step 71400: 0.080632\n",
      "2023-12-10 11:09:48,402 INFO     Training average negative_sample_loss at step 71400: 0.078834\n",
      "2023-12-10 11:09:48,403 INFO     Training average loss at step 71400: 0.079733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 11:11:05,944 INFO     Training average positive_sample_loss at step 71500: 0.080283\n",
      "2023-12-10 11:11:05,944 INFO     Training average negative_sample_loss at step 71500: 0.078597\n",
      "2023-12-10 11:11:05,944 INFO     Training average loss at step 71500: 0.079440\n",
      "2023-12-10 11:12:23,287 INFO     Training average positive_sample_loss at step 71600: 0.080722\n",
      "2023-12-10 11:12:23,288 INFO     Training average negative_sample_loss at step 71600: 0.079873\n",
      "2023-12-10 11:12:23,288 INFO     Training average loss at step 71600: 0.080298\n",
      "2023-12-10 11:13:39,111 INFO     Training average positive_sample_loss at step 71700: 0.080860\n",
      "2023-12-10 11:13:39,111 INFO     Training average negative_sample_loss at step 71700: 0.079398\n",
      "2023-12-10 11:13:39,111 INFO     Training average loss at step 71700: 0.080129\n",
      "2023-12-10 11:15:12,160 INFO     Training average positive_sample_loss at step 71800: 0.076772\n",
      "2023-12-10 11:15:12,160 INFO     Training average negative_sample_loss at step 71800: 0.078690\n",
      "2023-12-10 11:15:12,160 INFO     Training average loss at step 71800: 0.077731\n",
      "2023-12-10 11:16:27,649 INFO     Training average positive_sample_loss at step 71900: 0.076858\n",
      "2023-12-10 11:16:27,650 INFO     Training average negative_sample_loss at step 71900: 0.075467\n",
      "2023-12-10 11:16:27,650 INFO     Training average loss at step 71900: 0.076162\n",
      "2023-12-10 11:17:43,506 INFO     Training average positive_sample_loss at step 72000: 0.078686\n",
      "2023-12-10 11:17:43,506 INFO     Training average negative_sample_loss at step 72000: 0.077719\n",
      "2023-12-10 11:17:43,506 INFO     Training average loss at step 72000: 0.078202\n",
      "2023-12-10 11:19:01,775 INFO     Training average positive_sample_loss at step 72100: 0.079128\n",
      "2023-12-10 11:19:01,776 INFO     Training average negative_sample_loss at step 72100: 0.077054\n",
      "2023-12-10 11:19:01,776 INFO     Training average loss at step 72100: 0.078091\n",
      "2023-12-10 11:20:16,610 INFO     Training average positive_sample_loss at step 72200: 0.079800\n",
      "2023-12-10 11:20:16,611 INFO     Training average negative_sample_loss at step 72200: 0.079483\n",
      "2023-12-10 11:20:16,611 INFO     Training average loss at step 72200: 0.079641\n",
      "2023-12-10 11:21:31,553 INFO     Training average positive_sample_loss at step 72300: 0.081066\n",
      "2023-12-10 11:21:31,553 INFO     Training average negative_sample_loss at step 72300: 0.080007\n",
      "2023-12-10 11:21:31,553 INFO     Training average loss at step 72300: 0.080537\n",
      "2023-12-10 11:22:47,547 INFO     Training average positive_sample_loss at step 72400: 0.081364\n",
      "2023-12-10 11:22:47,547 INFO     Training average negative_sample_loss at step 72400: 0.079370\n",
      "2023-12-10 11:22:47,548 INFO     Training average loss at step 72400: 0.080367\n",
      "2023-12-10 11:24:02,357 INFO     Training average positive_sample_loss at step 72500: 0.080498\n",
      "2023-12-10 11:24:02,358 INFO     Training average negative_sample_loss at step 72500: 0.079699\n",
      "2023-12-10 11:24:02,358 INFO     Training average loss at step 72500: 0.080098\n",
      "2023-12-10 11:25:19,031 INFO     Training average positive_sample_loss at step 72600: 0.080922\n",
      "2023-12-10 11:25:19,031 INFO     Training average negative_sample_loss at step 72600: 0.080381\n",
      "2023-12-10 11:25:19,031 INFO     Training average loss at step 72600: 0.080651\n",
      "2023-12-10 11:26:52,084 INFO     Training average positive_sample_loss at step 72700: 0.079983\n",
      "2023-12-10 11:26:52,085 INFO     Training average negative_sample_loss at step 72700: 0.078677\n",
      "2023-12-10 11:26:52,085 INFO     Training average loss at step 72700: 0.079330\n",
      "2023-12-10 11:28:07,458 INFO     Training average positive_sample_loss at step 72800: 0.075254\n",
      "2023-12-10 11:28:07,473 INFO     Training average negative_sample_loss at step 72800: 0.076107\n",
      "2023-12-10 11:28:07,474 INFO     Training average loss at step 72800: 0.075681\n",
      "2023-12-10 11:29:23,427 INFO     Training average positive_sample_loss at step 72900: 0.078140\n",
      "2023-12-10 11:29:23,427 INFO     Training average negative_sample_loss at step 72900: 0.075572\n",
      "2023-12-10 11:29:23,427 INFO     Training average loss at step 72900: 0.076856\n",
      "2023-12-10 11:30:37,514 INFO     Training average positive_sample_loss at step 73000: 0.078388\n",
      "2023-12-10 11:30:37,514 INFO     Training average negative_sample_loss at step 73000: 0.077349\n",
      "2023-12-10 11:30:37,514 INFO     Training average loss at step 73000: 0.077869\n",
      "2023-12-10 11:31:51,696 INFO     Training average positive_sample_loss at step 73100: 0.079750\n",
      "2023-12-10 11:31:51,696 INFO     Training average negative_sample_loss at step 73100: 0.077994\n",
      "2023-12-10 11:31:51,696 INFO     Training average loss at step 73100: 0.078872\n",
      "2023-12-10 11:33:07,501 INFO     Training average positive_sample_loss at step 73200: 0.080391\n",
      "2023-12-10 11:33:07,502 INFO     Training average negative_sample_loss at step 73200: 0.078906\n",
      "2023-12-10 11:33:07,502 INFO     Training average loss at step 73200: 0.079648\n",
      "2023-12-10 11:34:23,501 INFO     Training average positive_sample_loss at step 73300: 0.080457\n",
      "2023-12-10 11:34:23,502 INFO     Training average negative_sample_loss at step 73300: 0.079655\n",
      "2023-12-10 11:34:23,502 INFO     Training average loss at step 73300: 0.080056\n",
      "2023-12-10 11:35:37,891 INFO     Training average positive_sample_loss at step 73400: 0.081047\n",
      "2023-12-10 11:35:37,891 INFO     Training average negative_sample_loss at step 73400: 0.079708\n",
      "2023-12-10 11:35:37,891 INFO     Training average loss at step 73400: 0.080378\n",
      "2023-12-10 11:36:53,725 INFO     Training average positive_sample_loss at step 73500: 0.080579\n",
      "2023-12-10 11:36:53,726 INFO     Training average negative_sample_loss at step 73500: 0.079614\n",
      "2023-12-10 11:36:53,726 INFO     Training average loss at step 73500: 0.080097\n",
      "2023-12-10 11:38:09,051 INFO     Training average positive_sample_loss at step 73600: 0.080770\n",
      "2023-12-10 11:38:09,052 INFO     Training average negative_sample_loss at step 73600: 0.079449\n",
      "2023-12-10 11:38:09,052 INFO     Training average loss at step 73600: 0.080109\n",
      "2023-12-10 11:39:41,128 INFO     Training average positive_sample_loss at step 73700: 0.075684\n",
      "2023-12-10 11:39:41,128 INFO     Training average negative_sample_loss at step 73700: 0.076612\n",
      "2023-12-10 11:39:41,128 INFO     Training average loss at step 73700: 0.076148\n",
      "2023-12-10 11:40:56,740 INFO     Training average positive_sample_loss at step 73800: 0.077654\n",
      "2023-12-10 11:40:56,740 INFO     Training average negative_sample_loss at step 73800: 0.076413\n",
      "2023-12-10 11:40:56,740 INFO     Training average loss at step 73800: 0.077034\n",
      "2023-12-10 11:42:12,034 INFO     Training average positive_sample_loss at step 73900: 0.078240\n",
      "2023-12-10 11:42:12,034 INFO     Training average negative_sample_loss at step 73900: 0.077202\n",
      "2023-12-10 11:42:12,034 INFO     Training average loss at step 73900: 0.077721\n",
      "2023-12-10 11:43:27,704 INFO     Training average positive_sample_loss at step 74000: 0.078956\n",
      "2023-12-10 11:43:27,704 INFO     Training average negative_sample_loss at step 74000: 0.077969\n",
      "2023-12-10 11:43:27,704 INFO     Training average loss at step 74000: 0.078462\n",
      "2023-12-10 11:44:43,502 INFO     Training average positive_sample_loss at step 74100: 0.079930\n",
      "2023-12-10 11:44:43,502 INFO     Training average negative_sample_loss at step 74100: 0.077698\n",
      "2023-12-10 11:44:43,502 INFO     Training average loss at step 74100: 0.078814\n",
      "2023-12-10 11:46:00,590 INFO     Training average positive_sample_loss at step 74200: 0.080669\n",
      "2023-12-10 11:46:00,591 INFO     Training average negative_sample_loss at step 74200: 0.079712\n",
      "2023-12-10 11:46:00,591 INFO     Training average loss at step 74200: 0.080191\n",
      "2023-12-10 11:47:15,614 INFO     Training average positive_sample_loss at step 74300: 0.080132\n",
      "2023-12-10 11:47:15,614 INFO     Training average negative_sample_loss at step 74300: 0.078927\n",
      "2023-12-10 11:47:15,614 INFO     Training average loss at step 74300: 0.079530\n",
      "2023-12-10 11:48:30,951 INFO     Training average positive_sample_loss at step 74400: 0.080359\n",
      "2023-12-10 11:48:30,951 INFO     Training average negative_sample_loss at step 74400: 0.078682\n",
      "2023-12-10 11:48:30,951 INFO     Training average loss at step 74400: 0.079521\n",
      "2023-12-10 11:49:46,165 INFO     Training average positive_sample_loss at step 74500: 0.081561\n",
      "2023-12-10 11:49:46,165 INFO     Training average negative_sample_loss at step 74500: 0.080530\n",
      "2023-12-10 11:49:46,165 INFO     Training average loss at step 74500: 0.081045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 11:51:18,210 INFO     Training average positive_sample_loss at step 74600: 0.078635\n",
      "2023-12-10 11:51:18,211 INFO     Training average negative_sample_loss at step 74600: 0.078756\n",
      "2023-12-10 11:51:18,211 INFO     Training average loss at step 74600: 0.078696\n",
      "2023-12-10 11:52:35,230 INFO     Training average positive_sample_loss at step 74700: 0.076481\n",
      "2023-12-10 11:52:35,231 INFO     Training average negative_sample_loss at step 74700: 0.075525\n",
      "2023-12-10 11:52:35,231 INFO     Training average loss at step 74700: 0.076003\n",
      "2023-12-10 11:53:52,207 INFO     Training average positive_sample_loss at step 74800: 0.077929\n",
      "2023-12-10 11:53:52,207 INFO     Training average negative_sample_loss at step 74800: 0.076815\n",
      "2023-12-10 11:53:52,207 INFO     Training average loss at step 74800: 0.077372\n",
      "2023-12-10 11:55:07,208 INFO     Training average positive_sample_loss at step 74900: 0.078210\n",
      "2023-12-10 11:55:07,208 INFO     Training average negative_sample_loss at step 74900: 0.076372\n",
      "2023-12-10 11:55:07,208 INFO     Training average loss at step 74900: 0.077291\n",
      "2023-12-10 11:56:22,089 INFO     Change learning_rate to 0.000010 at step 75000\n",
      "2023-12-10 11:56:22,090 INFO     Training average positive_sample_loss at step 75000: 0.079345\n",
      "2023-12-10 11:56:22,091 INFO     Training average negative_sample_loss at step 75000: 0.077774\n",
      "2023-12-10 11:56:22,091 INFO     Training average loss at step 75000: 0.078560\n",
      "2023-12-10 11:57:36,920 INFO     Training average positive_sample_loss at step 75100: 0.079941\n",
      "2023-12-10 11:57:36,920 INFO     Training average negative_sample_loss at step 75100: 0.077357\n",
      "2023-12-10 11:57:36,920 INFO     Training average loss at step 75100: 0.078649\n",
      "2023-12-10 11:58:51,436 INFO     Training average positive_sample_loss at step 75200: 0.077218\n",
      "2023-12-10 11:58:51,436 INFO     Training average negative_sample_loss at step 75200: 0.076348\n",
      "2023-12-10 11:58:51,436 INFO     Training average loss at step 75200: 0.076783\n",
      "2023-12-10 12:00:05,535 INFO     Training average positive_sample_loss at step 75300: 0.076680\n",
      "2023-12-10 12:00:05,535 INFO     Training average negative_sample_loss at step 75300: 0.075539\n",
      "2023-12-10 12:00:05,535 INFO     Training average loss at step 75300: 0.076110\n",
      "2023-12-10 12:01:20,967 INFO     Training average positive_sample_loss at step 75400: 0.075765\n",
      "2023-12-10 12:01:20,968 INFO     Training average negative_sample_loss at step 75400: 0.077298\n",
      "2023-12-10 12:01:20,968 INFO     Training average loss at step 75400: 0.076532\n",
      "2023-12-10 12:02:35,773 INFO     Training average positive_sample_loss at step 75500: 0.075061\n",
      "2023-12-10 12:02:35,773 INFO     Training average negative_sample_loss at step 75500: 0.076496\n",
      "2023-12-10 12:02:35,773 INFO     Training average loss at step 75500: 0.075778\n",
      "2023-12-10 12:04:01,857 INFO     Training average positive_sample_loss at step 75600: 0.069435\n",
      "2023-12-10 12:04:01,858 INFO     Training average negative_sample_loss at step 75600: 0.074933\n",
      "2023-12-10 12:04:01,858 INFO     Training average loss at step 75600: 0.072184\n",
      "2023-12-10 12:05:18,264 INFO     Training average positive_sample_loss at step 75700: 0.068662\n",
      "2023-12-10 12:05:18,264 INFO     Training average negative_sample_loss at step 75700: 0.073548\n",
      "2023-12-10 12:05:18,264 INFO     Training average loss at step 75700: 0.071105\n",
      "2023-12-10 12:06:35,960 INFO     Training average positive_sample_loss at step 75800: 0.069473\n",
      "2023-12-10 12:06:35,961 INFO     Training average negative_sample_loss at step 75800: 0.073087\n",
      "2023-12-10 12:06:35,961 INFO     Training average loss at step 75800: 0.071280\n",
      "2023-12-10 12:07:51,209 INFO     Training average positive_sample_loss at step 75900: 0.069914\n",
      "2023-12-10 12:07:51,210 INFO     Training average negative_sample_loss at step 75900: 0.072566\n",
      "2023-12-10 12:07:51,210 INFO     Training average loss at step 75900: 0.071240\n",
      "2023-12-10 12:09:06,281 INFO     Training average positive_sample_loss at step 76000: 0.070283\n",
      "2023-12-10 12:09:06,282 INFO     Training average negative_sample_loss at step 76000: 0.072600\n",
      "2023-12-10 12:09:06,282 INFO     Training average loss at step 76000: 0.071441\n",
      "2023-12-10 12:10:22,558 INFO     Training average positive_sample_loss at step 76100: 0.070139\n",
      "2023-12-10 12:10:22,558 INFO     Training average negative_sample_loss at step 76100: 0.071971\n",
      "2023-12-10 12:10:22,558 INFO     Training average loss at step 76100: 0.071055\n",
      "2023-12-10 12:11:37,205 INFO     Training average positive_sample_loss at step 76200: 0.070652\n",
      "2023-12-10 12:11:37,205 INFO     Training average negative_sample_loss at step 76200: 0.071607\n",
      "2023-12-10 12:11:37,205 INFO     Training average loss at step 76200: 0.071129\n",
      "2023-12-10 12:12:52,731 INFO     Training average positive_sample_loss at step 76300: 0.070464\n",
      "2023-12-10 12:12:52,731 INFO     Training average negative_sample_loss at step 76300: 0.071732\n",
      "2023-12-10 12:12:52,731 INFO     Training average loss at step 76300: 0.071098\n",
      "2023-12-10 12:14:08,448 INFO     Training average positive_sample_loss at step 76400: 0.070354\n",
      "2023-12-10 12:14:08,448 INFO     Training average negative_sample_loss at step 76400: 0.071317\n",
      "2023-12-10 12:14:08,449 INFO     Training average loss at step 76400: 0.070836\n",
      "2023-12-10 12:15:39,135 INFO     Training average positive_sample_loss at step 76500: 0.069403\n",
      "2023-12-10 12:15:39,135 INFO     Training average negative_sample_loss at step 76500: 0.071570\n",
      "2023-12-10 12:15:39,135 INFO     Training average loss at step 76500: 0.070486\n",
      "2023-12-10 12:16:57,457 INFO     Training average positive_sample_loss at step 76600: 0.068589\n",
      "2023-12-10 12:16:57,457 INFO     Training average negative_sample_loss at step 76600: 0.070252\n",
      "2023-12-10 12:16:57,458 INFO     Training average loss at step 76600: 0.069420\n",
      "2023-12-10 12:18:15,810 INFO     Training average positive_sample_loss at step 76700: 0.069026\n",
      "2023-12-10 12:18:15,810 INFO     Training average negative_sample_loss at step 76700: 0.070926\n",
      "2023-12-10 12:18:15,810 INFO     Training average loss at step 76700: 0.069976\n",
      "2023-12-10 12:19:31,569 INFO     Training average positive_sample_loss at step 76800: 0.069999\n",
      "2023-12-10 12:19:31,569 INFO     Training average negative_sample_loss at step 76800: 0.070483\n",
      "2023-12-10 12:19:31,569 INFO     Training average loss at step 76800: 0.070241\n",
      "2023-12-10 12:20:47,180 INFO     Training average positive_sample_loss at step 76900: 0.069704\n",
      "2023-12-10 12:20:47,180 INFO     Training average negative_sample_loss at step 76900: 0.070197\n",
      "2023-12-10 12:20:47,180 INFO     Training average loss at step 76900: 0.069950\n",
      "2023-12-10 12:22:02,889 INFO     Training average positive_sample_loss at step 77000: 0.069449\n",
      "2023-12-10 12:22:02,889 INFO     Training average negative_sample_loss at step 77000: 0.069593\n",
      "2023-12-10 12:22:02,889 INFO     Training average loss at step 77000: 0.069521\n",
      "2023-12-10 12:23:18,431 INFO     Training average positive_sample_loss at step 77100: 0.069585\n",
      "2023-12-10 12:23:18,431 INFO     Training average negative_sample_loss at step 77100: 0.070682\n",
      "2023-12-10 12:23:18,431 INFO     Training average loss at step 77100: 0.070133\n",
      "2023-12-10 12:24:32,043 INFO     Training average positive_sample_loss at step 77200: 0.069849\n",
      "2023-12-10 12:24:32,043 INFO     Training average negative_sample_loss at step 77200: 0.071018\n",
      "2023-12-10 12:24:32,043 INFO     Training average loss at step 77200: 0.070433\n",
      "2023-12-10 12:25:45,814 INFO     Training average positive_sample_loss at step 77300: 0.069990\n",
      "2023-12-10 12:25:45,814 INFO     Training average negative_sample_loss at step 77300: 0.069840\n",
      "2023-12-10 12:25:45,815 INFO     Training average loss at step 77300: 0.069915\n",
      "2023-12-10 12:27:03,972 INFO     Training average positive_sample_loss at step 77400: 0.069826\n",
      "2023-12-10 12:27:03,972 INFO     Training average negative_sample_loss at step 77400: 0.071029\n",
      "2023-12-10 12:27:03,972 INFO     Training average loss at step 77400: 0.070428\n",
      "2023-12-10 12:28:36,574 INFO     Training average positive_sample_loss at step 77500: 0.068131\n",
      "2023-12-10 12:28:36,574 INFO     Training average negative_sample_loss at step 77500: 0.069356\n",
      "2023-12-10 12:28:36,575 INFO     Training average loss at step 77500: 0.068744\n",
      "2023-12-10 12:29:51,988 INFO     Training average positive_sample_loss at step 77600: 0.068749\n",
      "2023-12-10 12:29:51,988 INFO     Training average negative_sample_loss at step 77600: 0.069896\n",
      "2023-12-10 12:29:51,988 INFO     Training average loss at step 77600: 0.069322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 12:31:08,988 INFO     Training average positive_sample_loss at step 77700: 0.068890\n",
      "2023-12-10 12:31:08,988 INFO     Training average negative_sample_loss at step 77700: 0.069973\n",
      "2023-12-10 12:31:08,988 INFO     Training average loss at step 77700: 0.069432\n",
      "2023-12-10 12:32:25,760 INFO     Training average positive_sample_loss at step 77800: 0.069217\n",
      "2023-12-10 12:32:25,760 INFO     Training average negative_sample_loss at step 77800: 0.068612\n",
      "2023-12-10 12:32:25,760 INFO     Training average loss at step 77800: 0.068915\n",
      "2023-12-10 12:33:44,106 INFO     Training average positive_sample_loss at step 77900: 0.069620\n",
      "2023-12-10 12:33:44,106 INFO     Training average negative_sample_loss at step 77900: 0.069671\n",
      "2023-12-10 12:33:44,106 INFO     Training average loss at step 77900: 0.069645\n",
      "2023-12-10 12:35:00,606 INFO     Training average positive_sample_loss at step 78000: 0.069035\n",
      "2023-12-10 12:35:00,606 INFO     Training average negative_sample_loss at step 78000: 0.070090\n",
      "2023-12-10 12:35:00,606 INFO     Training average loss at step 78000: 0.069562\n",
      "2023-12-10 12:36:14,118 INFO     Training average positive_sample_loss at step 78100: 0.069584\n",
      "2023-12-10 12:36:14,119 INFO     Training average negative_sample_loss at step 78100: 0.069224\n",
      "2023-12-10 12:36:14,119 INFO     Training average loss at step 78100: 0.069404\n",
      "2023-12-10 12:37:29,172 INFO     Training average positive_sample_loss at step 78200: 0.070036\n",
      "2023-12-10 12:37:29,172 INFO     Training average negative_sample_loss at step 78200: 0.070502\n",
      "2023-12-10 12:37:29,172 INFO     Training average loss at step 78200: 0.070269\n",
      "2023-12-10 12:38:43,399 INFO     Training average positive_sample_loss at step 78300: 0.069634\n",
      "2023-12-10 12:38:43,399 INFO     Training average negative_sample_loss at step 78300: 0.069949\n",
      "2023-12-10 12:38:43,399 INFO     Training average loss at step 78300: 0.069792\n",
      "2023-12-10 12:40:07,229 INFO     Training average positive_sample_loss at step 78400: 0.068960\n",
      "2023-12-10 12:40:07,229 INFO     Training average negative_sample_loss at step 78400: 0.070236\n",
      "2023-12-10 12:40:07,229 INFO     Training average loss at step 78400: 0.069598\n",
      "2023-12-10 12:41:25,949 INFO     Training average positive_sample_loss at step 78500: 0.068381\n",
      "2023-12-10 12:41:25,949 INFO     Training average negative_sample_loss at step 78500: 0.069544\n",
      "2023-12-10 12:41:25,950 INFO     Training average loss at step 78500: 0.068963\n",
      "2023-12-10 12:42:42,630 INFO     Training average positive_sample_loss at step 78600: 0.068775\n",
      "2023-12-10 12:42:42,631 INFO     Training average negative_sample_loss at step 78600: 0.068639\n",
      "2023-12-10 12:42:42,631 INFO     Training average loss at step 78600: 0.068707\n",
      "2023-12-10 12:43:57,124 INFO     Training average positive_sample_loss at step 78700: 0.068888\n",
      "2023-12-10 12:43:57,125 INFO     Training average negative_sample_loss at step 78700: 0.069576\n",
      "2023-12-10 12:43:57,125 INFO     Training average loss at step 78700: 0.069232\n",
      "2023-12-10 12:45:12,084 INFO     Training average positive_sample_loss at step 78800: 0.068836\n",
      "2023-12-10 12:45:12,084 INFO     Training average negative_sample_loss at step 78800: 0.068645\n",
      "2023-12-10 12:45:12,084 INFO     Training average loss at step 78800: 0.068741\n",
      "2023-12-10 12:46:28,034 INFO     Training average positive_sample_loss at step 78900: 0.069211\n",
      "2023-12-10 12:46:28,035 INFO     Training average negative_sample_loss at step 78900: 0.069524\n",
      "2023-12-10 12:46:28,035 INFO     Training average loss at step 78900: 0.069368\n",
      "2023-12-10 12:47:42,532 INFO     Training average positive_sample_loss at step 79000: 0.069302\n",
      "2023-12-10 12:47:42,532 INFO     Training average negative_sample_loss at step 79000: 0.068306\n",
      "2023-12-10 12:47:42,532 INFO     Training average loss at step 79000: 0.068804\n",
      "2023-12-10 12:49:01,104 INFO     Training average positive_sample_loss at step 79100: 0.069193\n",
      "2023-12-10 12:49:01,104 INFO     Training average negative_sample_loss at step 79100: 0.069589\n",
      "2023-12-10 12:49:01,104 INFO     Training average loss at step 79100: 0.069391\n",
      "2023-12-10 12:50:18,294 INFO     Training average positive_sample_loss at step 79200: 0.069707\n",
      "2023-12-10 12:50:18,294 INFO     Training average negative_sample_loss at step 79200: 0.068722\n",
      "2023-12-10 12:50:18,294 INFO     Training average loss at step 79200: 0.069215\n",
      "2023-12-10 12:51:50,891 INFO     Training average positive_sample_loss at step 79300: 0.069738\n",
      "2023-12-10 12:51:50,891 INFO     Training average negative_sample_loss at step 79300: 0.069324\n",
      "2023-12-10 12:51:50,891 INFO     Training average loss at step 79300: 0.069531\n",
      "2023-12-10 12:53:07,548 INFO     Training average positive_sample_loss at step 79400: 0.067684\n",
      "2023-12-10 12:53:07,548 INFO     Training average negative_sample_loss at step 79400: 0.069589\n",
      "2023-12-10 12:53:07,549 INFO     Training average loss at step 79400: 0.068636\n",
      "2023-12-10 12:54:23,916 INFO     Training average positive_sample_loss at step 79500: 0.068092\n",
      "2023-12-10 12:54:23,917 INFO     Training average negative_sample_loss at step 79500: 0.068592\n",
      "2023-12-10 12:54:23,917 INFO     Training average loss at step 79500: 0.068342\n",
      "2023-12-10 12:55:40,054 INFO     Training average positive_sample_loss at step 79600: 0.068653\n",
      "2023-12-10 12:55:40,054 INFO     Training average negative_sample_loss at step 79600: 0.069311\n",
      "2023-12-10 12:55:40,054 INFO     Training average loss at step 79600: 0.068982\n",
      "2023-12-10 12:56:55,475 INFO     Training average positive_sample_loss at step 79700: 0.068818\n",
      "2023-12-10 12:56:55,476 INFO     Training average negative_sample_loss at step 79700: 0.068344\n",
      "2023-12-10 12:56:55,476 INFO     Training average loss at step 79700: 0.068581\n",
      "2023-12-10 12:58:10,765 INFO     Training average positive_sample_loss at step 79800: 0.068907\n",
      "2023-12-10 12:58:10,766 INFO     Training average negative_sample_loss at step 79800: 0.067674\n",
      "2023-12-10 12:58:10,766 INFO     Training average loss at step 79800: 0.068290\n",
      "2023-12-10 12:59:26,476 INFO     Training average positive_sample_loss at step 79900: 0.069076\n",
      "2023-12-10 12:59:26,476 INFO     Training average negative_sample_loss at step 79900: 0.068609\n",
      "2023-12-10 12:59:26,477 INFO     Training average loss at step 79900: 0.068843\n",
      "2023-12-10 13:00:58,854 INFO     Training average positive_sample_loss at step 80000: 0.069171\n",
      "2023-12-10 13:00:58,855 INFO     Training average negative_sample_loss at step 80000: 0.068657\n",
      "2023-12-10 13:00:58,855 INFO     Training average loss at step 80000: 0.068914\n",
      "2023-12-10 13:00:58,855 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 13:00:59,883 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 13:01:42,796 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 13:02:25,836 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 13:03:07,556 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 13:03:49,878 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 13:04:33,056 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 13:05:14,877 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 13:05:26,303 INFO     Valid MRR at step 80000: 0.789920\n",
      "2023-12-10 13:05:26,304 INFO     Valid MR at step 80000: 39.551460\n",
      "2023-12-10 13:05:26,304 INFO     Valid HITS@1 at step 80000: 0.737530\n",
      "2023-12-10 13:05:26,304 INFO     Valid HITS@3 at step 80000: 0.823130\n",
      "2023-12-10 13:05:26,304 INFO     Valid HITS@10 at step 80000: 0.881400\n",
      "2023-12-10 13:06:28,743 INFO     Training average positive_sample_loss at step 80100: 0.069323\n",
      "2023-12-10 13:06:28,744 INFO     Training average negative_sample_loss at step 80100: 0.068548\n",
      "2023-12-10 13:06:28,744 INFO     Training average loss at step 80100: 0.068935\n",
      "2023-12-10 13:07:45,207 INFO     Training average positive_sample_loss at step 80200: 0.069326\n",
      "2023-12-10 13:07:45,208 INFO     Training average negative_sample_loss at step 80200: 0.068394\n",
      "2023-12-10 13:07:45,208 INFO     Training average loss at step 80200: 0.068860\n",
      "2023-12-10 13:09:11,407 INFO     Training average positive_sample_loss at step 80300: 0.068280\n",
      "2023-12-10 13:09:11,407 INFO     Training average negative_sample_loss at step 80300: 0.068511\n",
      "2023-12-10 13:09:11,407 INFO     Training average loss at step 80300: 0.068395\n",
      "2023-12-10 13:10:27,001 INFO     Training average positive_sample_loss at step 80400: 0.068285\n",
      "2023-12-10 13:10:27,001 INFO     Training average negative_sample_loss at step 80400: 0.069534\n",
      "2023-12-10 13:10:27,001 INFO     Training average loss at step 80400: 0.068910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 13:11:42,722 INFO     Training average positive_sample_loss at step 80500: 0.068667\n",
      "2023-12-10 13:11:42,723 INFO     Training average negative_sample_loss at step 80500: 0.067762\n",
      "2023-12-10 13:11:42,723 INFO     Training average loss at step 80500: 0.068215\n",
      "2023-12-10 13:13:00,708 INFO     Training average positive_sample_loss at step 80600: 0.068188\n",
      "2023-12-10 13:13:00,708 INFO     Training average negative_sample_loss at step 80600: 0.067745\n",
      "2023-12-10 13:13:00,708 INFO     Training average loss at step 80600: 0.067967\n",
      "2023-12-10 13:14:17,115 INFO     Training average positive_sample_loss at step 80700: 0.068710\n",
      "2023-12-10 13:14:17,115 INFO     Training average negative_sample_loss at step 80700: 0.068638\n",
      "2023-12-10 13:14:17,115 INFO     Training average loss at step 80700: 0.068674\n",
      "2023-12-10 13:15:33,761 INFO     Training average positive_sample_loss at step 80800: 0.068899\n",
      "2023-12-10 13:15:33,761 INFO     Training average negative_sample_loss at step 80800: 0.069129\n",
      "2023-12-10 13:15:33,761 INFO     Training average loss at step 80800: 0.069014\n",
      "2023-12-10 13:16:50,154 INFO     Training average positive_sample_loss at step 80900: 0.069187\n",
      "2023-12-10 13:16:50,154 INFO     Training average negative_sample_loss at step 80900: 0.067927\n",
      "2023-12-10 13:16:50,155 INFO     Training average loss at step 80900: 0.068557\n",
      "2023-12-10 13:18:08,708 INFO     Training average positive_sample_loss at step 81000: 0.068921\n",
      "2023-12-10 13:18:08,709 INFO     Training average negative_sample_loss at step 81000: 0.068218\n",
      "2023-12-10 13:18:08,709 INFO     Training average loss at step 81000: 0.068569\n",
      "2023-12-10 13:19:26,054 INFO     Training average positive_sample_loss at step 81100: 0.069165\n",
      "2023-12-10 13:19:26,054 INFO     Training average negative_sample_loss at step 81100: 0.068824\n",
      "2023-12-10 13:19:26,054 INFO     Training average loss at step 81100: 0.068995\n",
      "2023-12-10 13:20:53,836 INFO     Training average positive_sample_loss at step 81200: 0.068865\n",
      "2023-12-10 13:20:53,836 INFO     Training average negative_sample_loss at step 81200: 0.068290\n",
      "2023-12-10 13:20:53,837 INFO     Training average loss at step 81200: 0.068578\n",
      "2023-12-10 13:22:08,945 INFO     Training average positive_sample_loss at step 81300: 0.067231\n",
      "2023-12-10 13:22:08,946 INFO     Training average negative_sample_loss at step 81300: 0.068246\n",
      "2023-12-10 13:22:08,946 INFO     Training average loss at step 81300: 0.067739\n",
      "2023-12-10 13:23:24,911 INFO     Training average positive_sample_loss at step 81400: 0.067936\n",
      "2023-12-10 13:23:24,912 INFO     Training average negative_sample_loss at step 81400: 0.068317\n",
      "2023-12-10 13:23:24,912 INFO     Training average loss at step 81400: 0.068126\n",
      "2023-12-10 13:24:39,041 INFO     Training average positive_sample_loss at step 81500: 0.068507\n",
      "2023-12-10 13:24:39,042 INFO     Training average negative_sample_loss at step 81500: 0.068255\n",
      "2023-12-10 13:24:39,042 INFO     Training average loss at step 81500: 0.068381\n",
      "2023-12-10 13:25:56,482 INFO     Training average positive_sample_loss at step 81600: 0.068824\n",
      "2023-12-10 13:25:56,482 INFO     Training average negative_sample_loss at step 81600: 0.068749\n",
      "2023-12-10 13:25:56,482 INFO     Training average loss at step 81600: 0.068787\n",
      "2023-12-10 13:27:13,527 INFO     Training average positive_sample_loss at step 81700: 0.068708\n",
      "2023-12-10 13:27:13,528 INFO     Training average negative_sample_loss at step 81700: 0.067691\n",
      "2023-12-10 13:27:13,528 INFO     Training average loss at step 81700: 0.068200\n",
      "2023-12-10 13:28:31,839 INFO     Training average positive_sample_loss at step 81800: 0.068546\n",
      "2023-12-10 13:28:31,839 INFO     Training average negative_sample_loss at step 81800: 0.067223\n",
      "2023-12-10 13:28:31,839 INFO     Training average loss at step 81800: 0.067885\n",
      "2023-12-10 13:29:46,318 INFO     Training average positive_sample_loss at step 81900: 0.069509\n",
      "2023-12-10 13:29:46,318 INFO     Training average negative_sample_loss at step 81900: 0.069094\n",
      "2023-12-10 13:29:46,318 INFO     Training average loss at step 81900: 0.069302\n",
      "2023-12-10 13:31:01,477 INFO     Training average positive_sample_loss at step 82000: 0.069482\n",
      "2023-12-10 13:31:01,478 INFO     Training average negative_sample_loss at step 82000: 0.070107\n",
      "2023-12-10 13:31:01,478 INFO     Training average loss at step 82000: 0.069795\n",
      "2023-12-10 13:32:16,988 INFO     Training average positive_sample_loss at step 82100: 0.069366\n",
      "2023-12-10 13:32:16,988 INFO     Training average negative_sample_loss at step 82100: 0.068494\n",
      "2023-12-10 13:32:16,988 INFO     Training average loss at step 82100: 0.068930\n",
      "2023-12-10 13:33:48,171 INFO     Training average positive_sample_loss at step 82200: 0.068277\n",
      "2023-12-10 13:33:48,172 INFO     Training average negative_sample_loss at step 82200: 0.067509\n",
      "2023-12-10 13:33:48,172 INFO     Training average loss at step 82200: 0.067893\n",
      "2023-12-10 13:35:02,581 INFO     Training average positive_sample_loss at step 82300: 0.067885\n",
      "2023-12-10 13:35:02,582 INFO     Training average negative_sample_loss at step 82300: 0.069612\n",
      "2023-12-10 13:35:02,582 INFO     Training average loss at step 82300: 0.068748\n",
      "2023-12-10 13:36:19,105 INFO     Training average positive_sample_loss at step 82400: 0.068316\n",
      "2023-12-10 13:36:19,105 INFO     Training average negative_sample_loss at step 82400: 0.067828\n",
      "2023-12-10 13:36:19,105 INFO     Training average loss at step 82400: 0.068072\n",
      "2023-12-10 13:37:37,557 INFO     Training average positive_sample_loss at step 82500: 0.068227\n",
      "2023-12-10 13:37:37,558 INFO     Training average negative_sample_loss at step 82500: 0.068346\n",
      "2023-12-10 13:37:37,558 INFO     Training average loss at step 82500: 0.068287\n",
      "2023-12-10 13:38:54,166 INFO     Training average positive_sample_loss at step 82600: 0.068796\n",
      "2023-12-10 13:38:54,166 INFO     Training average negative_sample_loss at step 82600: 0.068490\n",
      "2023-12-10 13:38:54,167 INFO     Training average loss at step 82600: 0.068643\n",
      "2023-12-10 13:40:10,249 INFO     Training average positive_sample_loss at step 82700: 0.068429\n",
      "2023-12-10 13:40:10,250 INFO     Training average negative_sample_loss at step 82700: 0.067424\n",
      "2023-12-10 13:40:10,250 INFO     Training average loss at step 82700: 0.067927\n",
      "2023-12-10 13:41:25,132 INFO     Training average positive_sample_loss at step 82800: 0.068984\n",
      "2023-12-10 13:41:25,133 INFO     Training average negative_sample_loss at step 82800: 0.067367\n",
      "2023-12-10 13:41:25,133 INFO     Training average loss at step 82800: 0.068175\n",
      "2023-12-10 13:42:43,201 INFO     Training average positive_sample_loss at step 82900: 0.068991\n",
      "2023-12-10 13:42:43,201 INFO     Training average negative_sample_loss at step 82900: 0.067847\n",
      "2023-12-10 13:42:43,202 INFO     Training average loss at step 82900: 0.068419\n",
      "2023-12-10 13:43:59,774 INFO     Training average positive_sample_loss at step 83000: 0.068837\n",
      "2023-12-10 13:43:59,774 INFO     Training average negative_sample_loss at step 83000: 0.067907\n",
      "2023-12-10 13:43:59,774 INFO     Training average loss at step 83000: 0.068372\n",
      "2023-12-10 13:45:25,078 INFO     Training average positive_sample_loss at step 83100: 0.068665\n",
      "2023-12-10 13:45:25,078 INFO     Training average negative_sample_loss at step 83100: 0.068900\n",
      "2023-12-10 13:45:25,078 INFO     Training average loss at step 83100: 0.068782\n",
      "2023-12-10 13:46:40,707 INFO     Training average positive_sample_loss at step 83200: 0.067522\n",
      "2023-12-10 13:46:40,707 INFO     Training average negative_sample_loss at step 83200: 0.068032\n",
      "2023-12-10 13:46:40,707 INFO     Training average loss at step 83200: 0.067777\n",
      "2023-12-10 13:47:55,491 INFO     Training average positive_sample_loss at step 83300: 0.068301\n",
      "2023-12-10 13:47:55,492 INFO     Training average negative_sample_loss at step 83300: 0.067450\n",
      "2023-12-10 13:47:55,492 INFO     Training average loss at step 83300: 0.067876\n",
      "2023-12-10 13:49:10,694 INFO     Training average positive_sample_loss at step 83400: 0.068373\n",
      "2023-12-10 13:49:10,694 INFO     Training average negative_sample_loss at step 83400: 0.068129\n",
      "2023-12-10 13:49:10,694 INFO     Training average loss at step 83400: 0.068251\n",
      "2023-12-10 13:50:26,336 INFO     Training average positive_sample_loss at step 83500: 0.068534\n",
      "2023-12-10 13:50:26,336 INFO     Training average negative_sample_loss at step 83500: 0.068400\n",
      "2023-12-10 13:50:26,336 INFO     Training average loss at step 83500: 0.068467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 13:51:40,982 INFO     Training average positive_sample_loss at step 83600: 0.068828\n",
      "2023-12-10 13:51:40,982 INFO     Training average negative_sample_loss at step 83600: 0.066796\n",
      "2023-12-10 13:51:40,982 INFO     Training average loss at step 83600: 0.067812\n",
      "2023-12-10 13:52:54,997 INFO     Training average positive_sample_loss at step 83700: 0.068725\n",
      "2023-12-10 13:52:54,997 INFO     Training average negative_sample_loss at step 83700: 0.067644\n",
      "2023-12-10 13:52:54,997 INFO     Training average loss at step 83700: 0.068184\n",
      "2023-12-10 13:54:10,691 INFO     Training average positive_sample_loss at step 83800: 0.068680\n",
      "2023-12-10 13:54:10,691 INFO     Training average negative_sample_loss at step 83800: 0.068080\n",
      "2023-12-10 13:54:10,691 INFO     Training average loss at step 83800: 0.068380\n",
      "2023-12-10 13:55:25,576 INFO     Training average positive_sample_loss at step 83900: 0.069036\n",
      "2023-12-10 13:55:25,576 INFO     Training average negative_sample_loss at step 83900: 0.067453\n",
      "2023-12-10 13:55:25,576 INFO     Training average loss at step 83900: 0.068245\n",
      "2023-12-10 13:56:42,420 INFO     Training average positive_sample_loss at step 84000: 0.068834\n",
      "2023-12-10 13:56:42,420 INFO     Training average negative_sample_loss at step 84000: 0.068140\n",
      "2023-12-10 13:56:42,420 INFO     Training average loss at step 84000: 0.068487\n",
      "2023-12-10 13:58:14,156 INFO     Training average positive_sample_loss at step 84100: 0.067445\n",
      "2023-12-10 13:58:14,156 INFO     Training average negative_sample_loss at step 84100: 0.067834\n",
      "2023-12-10 13:58:14,156 INFO     Training average loss at step 84100: 0.067640\n",
      "2023-12-10 13:59:29,446 INFO     Training average positive_sample_loss at step 84200: 0.068193\n",
      "2023-12-10 13:59:29,446 INFO     Training average negative_sample_loss at step 84200: 0.068669\n",
      "2023-12-10 13:59:29,446 INFO     Training average loss at step 84200: 0.068431\n",
      "2023-12-10 14:00:44,445 INFO     Training average positive_sample_loss at step 84300: 0.068129\n",
      "2023-12-10 14:00:44,446 INFO     Training average negative_sample_loss at step 84300: 0.066974\n",
      "2023-12-10 14:00:44,446 INFO     Training average loss at step 84300: 0.067551\n",
      "2023-12-10 14:01:59,229 INFO     Training average positive_sample_loss at step 84400: 0.068564\n",
      "2023-12-10 14:01:59,230 INFO     Training average negative_sample_loss at step 84400: 0.067247\n",
      "2023-12-10 14:01:59,230 INFO     Training average loss at step 84400: 0.067906\n",
      "2023-12-10 14:03:13,648 INFO     Training average positive_sample_loss at step 84500: 0.068521\n",
      "2023-12-10 14:03:13,648 INFO     Training average negative_sample_loss at step 84500: 0.068681\n",
      "2023-12-10 14:03:13,649 INFO     Training average loss at step 84500: 0.068601\n",
      "2023-12-10 14:04:28,601 INFO     Training average positive_sample_loss at step 84600: 0.068638\n",
      "2023-12-10 14:04:28,601 INFO     Training average negative_sample_loss at step 84600: 0.067976\n",
      "2023-12-10 14:04:28,601 INFO     Training average loss at step 84600: 0.068307\n",
      "2023-12-10 14:05:43,765 INFO     Training average positive_sample_loss at step 84700: 0.068922\n",
      "2023-12-10 14:05:43,765 INFO     Training average negative_sample_loss at step 84700: 0.068098\n",
      "2023-12-10 14:05:43,765 INFO     Training average loss at step 84700: 0.068510\n",
      "2023-12-10 14:06:58,360 INFO     Training average positive_sample_loss at step 84800: 0.068830\n",
      "2023-12-10 14:06:58,361 INFO     Training average negative_sample_loss at step 84800: 0.067775\n",
      "2023-12-10 14:06:58,361 INFO     Training average loss at step 84800: 0.068303\n",
      "2023-12-10 14:08:14,820 INFO     Training average positive_sample_loss at step 84900: 0.068981\n",
      "2023-12-10 14:08:14,821 INFO     Training average negative_sample_loss at step 84900: 0.068487\n",
      "2023-12-10 14:08:14,821 INFO     Training average loss at step 84900: 0.068734\n",
      "2023-12-10 14:09:41,594 INFO     Training average positive_sample_loss at step 85000: 0.068038\n",
      "2023-12-10 14:09:41,595 INFO     Training average negative_sample_loss at step 85000: 0.067895\n",
      "2023-12-10 14:09:41,595 INFO     Training average loss at step 85000: 0.067966\n",
      "2023-12-10 14:10:59,198 INFO     Training average positive_sample_loss at step 85100: 0.067600\n",
      "2023-12-10 14:10:59,199 INFO     Training average negative_sample_loss at step 85100: 0.067669\n",
      "2023-12-10 14:10:59,199 INFO     Training average loss at step 85100: 0.067634\n",
      "2023-12-10 14:12:13,908 INFO     Training average positive_sample_loss at step 85200: 0.068093\n",
      "2023-12-10 14:12:13,908 INFO     Training average negative_sample_loss at step 85200: 0.067292\n",
      "2023-12-10 14:12:13,908 INFO     Training average loss at step 85200: 0.067693\n",
      "2023-12-10 14:13:28,668 INFO     Training average positive_sample_loss at step 85300: 0.068666\n",
      "2023-12-10 14:13:28,668 INFO     Training average negative_sample_loss at step 85300: 0.068130\n",
      "2023-12-10 14:13:28,668 INFO     Training average loss at step 85300: 0.068398\n",
      "2023-12-10 14:14:43,479 INFO     Training average positive_sample_loss at step 85400: 0.068385\n",
      "2023-12-10 14:14:43,480 INFO     Training average negative_sample_loss at step 85400: 0.067319\n",
      "2023-12-10 14:14:43,480 INFO     Training average loss at step 85400: 0.067852\n",
      "2023-12-10 14:16:00,150 INFO     Training average positive_sample_loss at step 85500: 0.068476\n",
      "2023-12-10 14:16:00,150 INFO     Training average negative_sample_loss at step 85500: 0.067498\n",
      "2023-12-10 14:16:00,150 INFO     Training average loss at step 85500: 0.067987\n",
      "2023-12-10 14:17:15,957 INFO     Training average positive_sample_loss at step 85600: 0.068959\n",
      "2023-12-10 14:17:15,957 INFO     Training average negative_sample_loss at step 85600: 0.067430\n",
      "2023-12-10 14:17:15,957 INFO     Training average loss at step 85600: 0.068195\n",
      "2023-12-10 14:18:32,634 INFO     Training average positive_sample_loss at step 85700: 0.068742\n",
      "2023-12-10 14:18:32,634 INFO     Training average negative_sample_loss at step 85700: 0.068024\n",
      "2023-12-10 14:18:32,634 INFO     Training average loss at step 85700: 0.068383\n",
      "2023-12-10 14:19:47,090 INFO     Training average positive_sample_loss at step 85800: 0.068584\n",
      "2023-12-10 14:19:47,090 INFO     Training average negative_sample_loss at step 85800: 0.068504\n",
      "2023-12-10 14:19:47,090 INFO     Training average loss at step 85800: 0.068544\n",
      "2023-12-10 14:21:04,331 INFO     Training average positive_sample_loss at step 85900: 0.069221\n",
      "2023-12-10 14:21:04,332 INFO     Training average negative_sample_loss at step 85900: 0.068379\n",
      "2023-12-10 14:21:04,332 INFO     Training average loss at step 85900: 0.068800\n",
      "2023-12-10 14:22:36,595 INFO     Training average positive_sample_loss at step 86000: 0.067226\n",
      "2023-12-10 14:22:36,596 INFO     Training average negative_sample_loss at step 86000: 0.067617\n",
      "2023-12-10 14:22:36,596 INFO     Training average loss at step 86000: 0.067421\n",
      "2023-12-10 14:23:52,386 INFO     Training average positive_sample_loss at step 86100: 0.068049\n",
      "2023-12-10 14:23:52,386 INFO     Training average negative_sample_loss at step 86100: 0.068014\n",
      "2023-12-10 14:23:52,386 INFO     Training average loss at step 86100: 0.068032\n",
      "2023-12-10 14:25:06,761 INFO     Training average positive_sample_loss at step 86200: 0.068192\n",
      "2023-12-10 14:25:06,761 INFO     Training average negative_sample_loss at step 86200: 0.067588\n",
      "2023-12-10 14:25:06,762 INFO     Training average loss at step 86200: 0.067890\n",
      "2023-12-10 14:26:22,727 INFO     Training average positive_sample_loss at step 86300: 0.068162\n",
      "2023-12-10 14:26:22,727 INFO     Training average negative_sample_loss at step 86300: 0.067387\n",
      "2023-12-10 14:26:22,727 INFO     Training average loss at step 86300: 0.067775\n",
      "2023-12-10 14:27:37,844 INFO     Training average positive_sample_loss at step 86400: 0.068803\n",
      "2023-12-10 14:27:37,844 INFO     Training average negative_sample_loss at step 86400: 0.068041\n",
      "2023-12-10 14:27:37,844 INFO     Training average loss at step 86400: 0.068422\n",
      "2023-12-10 14:28:51,161 INFO     Training average positive_sample_loss at step 86500: 0.068726\n",
      "2023-12-10 14:28:51,161 INFO     Training average negative_sample_loss at step 86500: 0.068445\n",
      "2023-12-10 14:28:51,161 INFO     Training average loss at step 86500: 0.068586\n",
      "2023-12-10 14:30:06,126 INFO     Training average positive_sample_loss at step 86600: 0.069025\n",
      "2023-12-10 14:30:06,126 INFO     Training average negative_sample_loss at step 86600: 0.068126\n",
      "2023-12-10 14:30:06,127 INFO     Training average loss at step 86600: 0.068575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 14:31:20,738 INFO     Training average positive_sample_loss at step 86700: 0.068769\n",
      "2023-12-10 14:31:20,738 INFO     Training average negative_sample_loss at step 86700: 0.067578\n",
      "2023-12-10 14:31:20,738 INFO     Training average loss at step 86700: 0.068173\n",
      "2023-12-10 14:32:35,963 INFO     Training average positive_sample_loss at step 86800: 0.069109\n",
      "2023-12-10 14:32:35,963 INFO     Training average negative_sample_loss at step 86800: 0.067582\n",
      "2023-12-10 14:32:35,963 INFO     Training average loss at step 86800: 0.068345\n",
      "2023-12-10 14:34:00,181 INFO     Training average positive_sample_loss at step 86900: 0.068049\n",
      "2023-12-10 14:34:00,181 INFO     Training average negative_sample_loss at step 86900: 0.067359\n",
      "2023-12-10 14:34:00,181 INFO     Training average loss at step 86900: 0.067704\n",
      "2023-12-10 14:35:14,687 INFO     Training average positive_sample_loss at step 87000: 0.067574\n",
      "2023-12-10 14:35:14,687 INFO     Training average negative_sample_loss at step 87000: 0.067686\n",
      "2023-12-10 14:35:14,687 INFO     Training average loss at step 87000: 0.067630\n",
      "2023-12-10 14:36:32,410 INFO     Training average positive_sample_loss at step 87100: 0.067944\n",
      "2023-12-10 14:36:32,410 INFO     Training average negative_sample_loss at step 87100: 0.067425\n",
      "2023-12-10 14:36:32,410 INFO     Training average loss at step 87100: 0.067685\n",
      "2023-12-10 14:37:50,593 INFO     Training average positive_sample_loss at step 87200: 0.068262\n",
      "2023-12-10 14:37:50,594 INFO     Training average negative_sample_loss at step 87200: 0.066621\n",
      "2023-12-10 14:37:50,594 INFO     Training average loss at step 87200: 0.067441\n",
      "2023-12-10 14:39:08,302 INFO     Training average positive_sample_loss at step 87300: 0.068662\n",
      "2023-12-10 14:39:08,302 INFO     Training average negative_sample_loss at step 87300: 0.068164\n",
      "2023-12-10 14:39:08,302 INFO     Training average loss at step 87300: 0.068413\n",
      "2023-12-10 14:40:23,133 INFO     Training average positive_sample_loss at step 87400: 0.068428\n",
      "2023-12-10 14:40:23,133 INFO     Training average negative_sample_loss at step 87400: 0.067216\n",
      "2023-12-10 14:40:23,133 INFO     Training average loss at step 87400: 0.067822\n",
      "2023-12-10 14:41:38,599 INFO     Training average positive_sample_loss at step 87500: 0.068506\n",
      "2023-12-10 14:41:38,599 INFO     Training average negative_sample_loss at step 87500: 0.067223\n",
      "2023-12-10 14:41:38,599 INFO     Training average loss at step 87500: 0.067864\n",
      "2023-12-10 14:42:54,339 INFO     Training average positive_sample_loss at step 87600: 0.068744\n",
      "2023-12-10 14:42:54,339 INFO     Training average negative_sample_loss at step 87600: 0.067687\n",
      "2023-12-10 14:42:54,339 INFO     Training average loss at step 87600: 0.068216\n",
      "2023-12-10 14:44:10,112 INFO     Training average positive_sample_loss at step 87700: 0.068852\n",
      "2023-12-10 14:44:10,112 INFO     Training average negative_sample_loss at step 87700: 0.067179\n",
      "2023-12-10 14:44:10,112 INFO     Training average loss at step 87700: 0.068015\n",
      "2023-12-10 14:45:35,628 INFO     Training average positive_sample_loss at step 87800: 0.068718\n",
      "2023-12-10 14:45:35,629 INFO     Training average negative_sample_loss at step 87800: 0.067067\n",
      "2023-12-10 14:45:35,629 INFO     Training average loss at step 87800: 0.067892\n",
      "2023-12-10 14:46:50,697 INFO     Training average positive_sample_loss at step 87900: 0.067222\n",
      "2023-12-10 14:46:50,697 INFO     Training average negative_sample_loss at step 87900: 0.067762\n",
      "2023-12-10 14:46:50,697 INFO     Training average loss at step 87900: 0.067492\n",
      "2023-12-10 14:48:06,507 INFO     Training average positive_sample_loss at step 88000: 0.067726\n",
      "2023-12-10 14:48:06,507 INFO     Training average negative_sample_loss at step 88000: 0.066866\n",
      "2023-12-10 14:48:06,507 INFO     Training average loss at step 88000: 0.067296\n",
      "2023-12-10 14:49:22,054 INFO     Training average positive_sample_loss at step 88100: 0.067593\n",
      "2023-12-10 14:49:22,054 INFO     Training average negative_sample_loss at step 88100: 0.067563\n",
      "2023-12-10 14:49:22,054 INFO     Training average loss at step 88100: 0.067578\n",
      "2023-12-10 14:50:37,938 INFO     Training average positive_sample_loss at step 88200: 0.068426\n",
      "2023-12-10 14:50:37,939 INFO     Training average negative_sample_loss at step 88200: 0.066852\n",
      "2023-12-10 14:50:37,939 INFO     Training average loss at step 88200: 0.067639\n",
      "2023-12-10 14:51:53,696 INFO     Training average positive_sample_loss at step 88300: 0.068418\n",
      "2023-12-10 14:51:53,696 INFO     Training average negative_sample_loss at step 88300: 0.067491\n",
      "2023-12-10 14:51:53,696 INFO     Training average loss at step 88300: 0.067955\n",
      "2023-12-10 14:53:08,938 INFO     Training average positive_sample_loss at step 88400: 0.068685\n",
      "2023-12-10 14:53:08,939 INFO     Training average negative_sample_loss at step 88400: 0.067779\n",
      "2023-12-10 14:53:08,939 INFO     Training average loss at step 88400: 0.068232\n",
      "2023-12-10 14:54:24,278 INFO     Training average positive_sample_loss at step 88500: 0.068791\n",
      "2023-12-10 14:54:24,279 INFO     Training average negative_sample_loss at step 88500: 0.067391\n",
      "2023-12-10 14:54:24,279 INFO     Training average loss at step 88500: 0.068091\n",
      "2023-12-10 14:55:39,176 INFO     Training average positive_sample_loss at step 88600: 0.068625\n",
      "2023-12-10 14:55:39,176 INFO     Training average negative_sample_loss at step 88600: 0.067924\n",
      "2023-12-10 14:55:39,176 INFO     Training average loss at step 88600: 0.068275\n",
      "2023-12-10 14:56:55,067 INFO     Training average positive_sample_loss at step 88700: 0.069203\n",
      "2023-12-10 14:56:55,067 INFO     Training average negative_sample_loss at step 88700: 0.067359\n",
      "2023-12-10 14:56:55,067 INFO     Training average loss at step 88700: 0.068281\n",
      "2023-12-10 14:58:21,672 INFO     Training average positive_sample_loss at step 88800: 0.067424\n",
      "2023-12-10 14:58:21,672 INFO     Training average negative_sample_loss at step 88800: 0.068053\n",
      "2023-12-10 14:58:21,672 INFO     Training average loss at step 88800: 0.067739\n",
      "2023-12-10 14:59:38,115 INFO     Training average positive_sample_loss at step 88900: 0.067186\n",
      "2023-12-10 14:59:38,115 INFO     Training average negative_sample_loss at step 88900: 0.066864\n",
      "2023-12-10 14:59:38,115 INFO     Training average loss at step 88900: 0.067025\n",
      "2023-12-10 15:00:53,389 INFO     Training average positive_sample_loss at step 89000: 0.067719\n",
      "2023-12-10 15:00:53,390 INFO     Training average negative_sample_loss at step 89000: 0.067962\n",
      "2023-12-10 15:00:53,390 INFO     Training average loss at step 89000: 0.067840\n",
      "2023-12-10 15:02:07,008 INFO     Training average positive_sample_loss at step 89100: 0.068763\n",
      "2023-12-10 15:02:07,008 INFO     Training average negative_sample_loss at step 89100: 0.067130\n",
      "2023-12-10 15:02:07,008 INFO     Training average loss at step 89100: 0.067946\n",
      "2023-12-10 15:03:21,943 INFO     Training average positive_sample_loss at step 89200: 0.068556\n",
      "2023-12-10 15:03:21,944 INFO     Training average negative_sample_loss at step 89200: 0.068128\n",
      "2023-12-10 15:03:21,944 INFO     Training average loss at step 89200: 0.068342\n",
      "2023-12-10 15:04:38,622 INFO     Training average positive_sample_loss at step 89300: 0.068405\n",
      "2023-12-10 15:04:38,622 INFO     Training average negative_sample_loss at step 89300: 0.067005\n",
      "2023-12-10 15:04:38,622 INFO     Training average loss at step 89300: 0.067705\n",
      "2023-12-10 15:05:54,739 INFO     Training average positive_sample_loss at step 89400: 0.068661\n",
      "2023-12-10 15:05:54,740 INFO     Training average negative_sample_loss at step 89400: 0.069063\n",
      "2023-12-10 15:05:54,740 INFO     Training average loss at step 89400: 0.068862\n",
      "2023-12-10 15:07:10,728 INFO     Training average positive_sample_loss at step 89500: 0.068936\n",
      "2023-12-10 15:07:10,728 INFO     Training average negative_sample_loss at step 89500: 0.067590\n",
      "2023-12-10 15:07:10,728 INFO     Training average loss at step 89500: 0.068263\n",
      "2023-12-10 15:08:26,210 INFO     Training average positive_sample_loss at step 89600: 0.068672\n",
      "2023-12-10 15:08:26,210 INFO     Training average negative_sample_loss at step 89600: 0.067794\n",
      "2023-12-10 15:08:26,210 INFO     Training average loss at step 89600: 0.068233\n",
      "2023-12-10 15:09:51,664 INFO     Training average positive_sample_loss at step 89700: 0.068857\n",
      "2023-12-10 15:09:51,665 INFO     Training average negative_sample_loss at step 89700: 0.068722\n",
      "2023-12-10 15:09:51,665 INFO     Training average loss at step 89700: 0.068789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 15:11:09,089 INFO     Training average positive_sample_loss at step 89800: 0.067077\n",
      "2023-12-10 15:11:09,089 INFO     Training average negative_sample_loss at step 89800: 0.066629\n",
      "2023-12-10 15:11:09,089 INFO     Training average loss at step 89800: 0.066853\n",
      "2023-12-10 15:12:24,295 INFO     Training average positive_sample_loss at step 89900: 0.067701\n",
      "2023-12-10 15:12:24,295 INFO     Training average negative_sample_loss at step 89900: 0.066760\n",
      "2023-12-10 15:12:24,295 INFO     Training average loss at step 89900: 0.067231\n",
      "2023-12-10 15:13:58,962 INFO     Training average positive_sample_loss at step 90000: 0.068043\n",
      "2023-12-10 15:13:58,962 INFO     Training average negative_sample_loss at step 90000: 0.068122\n",
      "2023-12-10 15:13:58,962 INFO     Training average loss at step 90000: 0.068082\n",
      "2023-12-10 15:13:58,962 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 15:13:59,808 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 15:14:41,177 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 15:15:23,602 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 15:16:07,907 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 15:16:50,248 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 15:17:34,016 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 15:18:17,515 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 15:18:28,262 INFO     Valid MRR at step 90000: 0.794603\n",
      "2023-12-10 15:18:28,262 INFO     Valid MR at step 90000: 39.574990\n",
      "2023-12-10 15:18:28,262 INFO     Valid HITS@1 at step 90000: 0.744450\n",
      "2023-12-10 15:18:28,262 INFO     Valid HITS@3 at step 90000: 0.825770\n",
      "2023-12-10 15:18:28,262 INFO     Valid HITS@10 at step 90000: 0.881670\n",
      "2023-12-10 15:19:30,566 INFO     Training average positive_sample_loss at step 90100: 0.068648\n",
      "2023-12-10 15:19:30,566 INFO     Training average negative_sample_loss at step 90100: 0.066776\n",
      "2023-12-10 15:19:30,566 INFO     Training average loss at step 90100: 0.067712\n",
      "2023-12-10 15:20:48,202 INFO     Training average positive_sample_loss at step 90200: 0.068437\n",
      "2023-12-10 15:20:48,202 INFO     Training average negative_sample_loss at step 90200: 0.067403\n",
      "2023-12-10 15:20:48,202 INFO     Training average loss at step 90200: 0.067920\n",
      "2023-12-10 15:22:05,822 INFO     Training average positive_sample_loss at step 90300: 0.069018\n",
      "2023-12-10 15:22:05,823 INFO     Training average negative_sample_loss at step 90300: 0.068074\n",
      "2023-12-10 15:22:05,823 INFO     Training average loss at step 90300: 0.068546\n",
      "2023-12-10 15:23:22,061 INFO     Training average positive_sample_loss at step 90400: 0.068744\n",
      "2023-12-10 15:23:22,062 INFO     Training average negative_sample_loss at step 90400: 0.067486\n",
      "2023-12-10 15:23:22,062 INFO     Training average loss at step 90400: 0.068115\n",
      "2023-12-10 15:24:37,827 INFO     Training average positive_sample_loss at step 90500: 0.068462\n",
      "2023-12-10 15:24:37,827 INFO     Training average negative_sample_loss at step 90500: 0.067109\n",
      "2023-12-10 15:24:37,827 INFO     Training average loss at step 90500: 0.067786\n",
      "2023-12-10 15:25:51,505 INFO     Training average positive_sample_loss at step 90600: 0.068676\n",
      "2023-12-10 15:25:51,505 INFO     Training average negative_sample_loss at step 90600: 0.067381\n",
      "2023-12-10 15:25:51,505 INFO     Training average loss at step 90600: 0.068029\n",
      "2023-12-10 15:27:22,560 INFO     Training average positive_sample_loss at step 90700: 0.067906\n",
      "2023-12-10 15:27:22,560 INFO     Training average negative_sample_loss at step 90700: 0.067512\n",
      "2023-12-10 15:27:22,561 INFO     Training average loss at step 90700: 0.067709\n",
      "2023-12-10 15:28:38,978 INFO     Training average positive_sample_loss at step 90800: 0.067194\n",
      "2023-12-10 15:28:38,978 INFO     Training average negative_sample_loss at step 90800: 0.067028\n",
      "2023-12-10 15:28:38,978 INFO     Training average loss at step 90800: 0.067111\n",
      "2023-12-10 15:29:53,494 INFO     Training average positive_sample_loss at step 90900: 0.068137\n",
      "2023-12-10 15:29:53,494 INFO     Training average negative_sample_loss at step 90900: 0.067438\n",
      "2023-12-10 15:29:53,494 INFO     Training average loss at step 90900: 0.067787\n",
      "2023-12-10 15:31:09,114 INFO     Training average positive_sample_loss at step 91000: 0.067862\n",
      "2023-12-10 15:31:09,114 INFO     Training average negative_sample_loss at step 91000: 0.067160\n",
      "2023-12-10 15:31:09,114 INFO     Training average loss at step 91000: 0.067511\n",
      "2023-12-10 15:32:25,215 INFO     Training average positive_sample_loss at step 91100: 0.068379\n",
      "2023-12-10 15:32:25,215 INFO     Training average negative_sample_loss at step 91100: 0.068078\n",
      "2023-12-10 15:32:25,215 INFO     Training average loss at step 91100: 0.068229\n",
      "2023-12-10 15:33:40,693 INFO     Training average positive_sample_loss at step 91200: 0.068236\n",
      "2023-12-10 15:33:40,693 INFO     Training average negative_sample_loss at step 91200: 0.067010\n",
      "2023-12-10 15:33:40,694 INFO     Training average loss at step 91200: 0.067623\n",
      "2023-12-10 15:34:59,881 INFO     Training average positive_sample_loss at step 91300: 0.068534\n",
      "2023-12-10 15:34:59,882 INFO     Training average negative_sample_loss at step 91300: 0.066648\n",
      "2023-12-10 15:34:59,882 INFO     Training average loss at step 91300: 0.067591\n",
      "2023-12-10 15:36:18,262 INFO     Training average positive_sample_loss at step 91400: 0.069189\n",
      "2023-12-10 15:36:18,262 INFO     Training average negative_sample_loss at step 91400: 0.067510\n",
      "2023-12-10 15:36:18,262 INFO     Training average loss at step 91400: 0.068349\n",
      "2023-12-10 15:37:36,748 INFO     Training average positive_sample_loss at step 91500: 0.068716\n",
      "2023-12-10 15:37:36,748 INFO     Training average negative_sample_loss at step 91500: 0.067595\n",
      "2023-12-10 15:37:36,748 INFO     Training average loss at step 91500: 0.068156\n",
      "2023-12-10 15:39:09,489 INFO     Training average positive_sample_loss at step 91600: 0.067928\n",
      "2023-12-10 15:39:09,490 INFO     Training average negative_sample_loss at step 91600: 0.068083\n",
      "2023-12-10 15:39:09,490 INFO     Training average loss at step 91600: 0.068005\n",
      "2023-12-10 15:40:25,005 INFO     Training average positive_sample_loss at step 91700: 0.067486\n",
      "2023-12-10 15:40:25,005 INFO     Training average negative_sample_loss at step 91700: 0.067013\n",
      "2023-12-10 15:40:25,005 INFO     Training average loss at step 91700: 0.067249\n",
      "2023-12-10 15:41:40,100 INFO     Training average positive_sample_loss at step 91800: 0.067963\n",
      "2023-12-10 15:41:40,100 INFO     Training average negative_sample_loss at step 91800: 0.067360\n",
      "2023-12-10 15:41:40,100 INFO     Training average loss at step 91800: 0.067662\n",
      "2023-12-10 15:42:55,711 INFO     Training average positive_sample_loss at step 91900: 0.067922\n",
      "2023-12-10 15:42:55,712 INFO     Training average negative_sample_loss at step 91900: 0.067590\n",
      "2023-12-10 15:42:55,712 INFO     Training average loss at step 91900: 0.067756\n",
      "2023-12-10 15:44:11,526 INFO     Training average positive_sample_loss at step 92000: 0.068267\n",
      "2023-12-10 15:44:11,526 INFO     Training average negative_sample_loss at step 92000: 0.066492\n",
      "2023-12-10 15:44:11,526 INFO     Training average loss at step 92000: 0.067379\n",
      "2023-12-10 15:45:25,470 INFO     Training average positive_sample_loss at step 92100: 0.068444\n",
      "2023-12-10 15:45:25,470 INFO     Training average negative_sample_loss at step 92100: 0.066723\n",
      "2023-12-10 15:45:25,470 INFO     Training average loss at step 92100: 0.067584\n",
      "2023-12-10 15:46:40,653 INFO     Training average positive_sample_loss at step 92200: 0.068558\n",
      "2023-12-10 15:46:40,653 INFO     Training average negative_sample_loss at step 92200: 0.067601\n",
      "2023-12-10 15:46:40,654 INFO     Training average loss at step 92200: 0.068079\n",
      "2023-12-10 15:47:55,773 INFO     Training average positive_sample_loss at step 92300: 0.068575\n",
      "2023-12-10 15:47:55,773 INFO     Training average negative_sample_loss at step 92300: 0.067391\n",
      "2023-12-10 15:47:55,773 INFO     Training average loss at step 92300: 0.067983\n",
      "2023-12-10 15:49:13,058 INFO     Training average positive_sample_loss at step 92400: 0.068597\n",
      "2023-12-10 15:49:13,058 INFO     Training average negative_sample_loss at step 92400: 0.067288\n",
      "2023-12-10 15:49:13,058 INFO     Training average loss at step 92400: 0.067943\n",
      "2023-12-10 15:50:29,386 INFO     Training average positive_sample_loss at step 92500: 0.069038\n",
      "2023-12-10 15:50:29,386 INFO     Training average negative_sample_loss at step 92500: 0.067739\n",
      "2023-12-10 15:50:29,386 INFO     Training average loss at step 92500: 0.068388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 15:52:01,122 INFO     Training average positive_sample_loss at step 92600: 0.066971\n",
      "2023-12-10 15:52:01,122 INFO     Training average negative_sample_loss at step 92600: 0.066633\n",
      "2023-12-10 15:52:01,123 INFO     Training average loss at step 92600: 0.066802\n",
      "2023-12-10 15:53:18,404 INFO     Training average positive_sample_loss at step 92700: 0.067716\n",
      "2023-12-10 15:53:18,404 INFO     Training average negative_sample_loss at step 92700: 0.067027\n",
      "2023-12-10 15:53:18,404 INFO     Training average loss at step 92700: 0.067372\n",
      "2023-12-10 15:54:33,207 INFO     Training average positive_sample_loss at step 92800: 0.067782\n",
      "2023-12-10 15:54:33,207 INFO     Training average negative_sample_loss at step 92800: 0.066719\n",
      "2023-12-10 15:54:33,207 INFO     Training average loss at step 92800: 0.067251\n",
      "2023-12-10 15:55:48,686 INFO     Training average positive_sample_loss at step 92900: 0.067872\n",
      "2023-12-10 15:55:48,687 INFO     Training average negative_sample_loss at step 92900: 0.066879\n",
      "2023-12-10 15:55:48,687 INFO     Training average loss at step 92900: 0.067376\n",
      "2023-12-10 15:57:02,742 INFO     Training average positive_sample_loss at step 93000: 0.068237\n",
      "2023-12-10 15:57:02,742 INFO     Training average negative_sample_loss at step 93000: 0.066792\n",
      "2023-12-10 15:57:02,742 INFO     Training average loss at step 93000: 0.067515\n",
      "2023-12-10 15:58:17,368 INFO     Training average positive_sample_loss at step 93100: 0.068609\n",
      "2023-12-10 15:58:17,368 INFO     Training average negative_sample_loss at step 93100: 0.067130\n",
      "2023-12-10 15:58:17,368 INFO     Training average loss at step 93100: 0.067869\n",
      "2023-12-10 15:59:34,345 INFO     Training average positive_sample_loss at step 93200: 0.068596\n",
      "2023-12-10 15:59:34,345 INFO     Training average negative_sample_loss at step 93200: 0.067501\n",
      "2023-12-10 15:59:34,345 INFO     Training average loss at step 93200: 0.068049\n",
      "2023-12-10 16:00:51,080 INFO     Training average positive_sample_loss at step 93300: 0.068849\n",
      "2023-12-10 16:00:51,080 INFO     Training average negative_sample_loss at step 93300: 0.067011\n",
      "2023-12-10 16:00:51,081 INFO     Training average loss at step 93300: 0.067930\n",
      "2023-12-10 16:02:08,727 INFO     Training average positive_sample_loss at step 93400: 0.068528\n",
      "2023-12-10 16:02:08,727 INFO     Training average negative_sample_loss at step 93400: 0.067308\n",
      "2023-12-10 16:02:08,727 INFO     Training average loss at step 93400: 0.067918\n",
      "2023-12-10 16:03:42,039 INFO     Training average positive_sample_loss at step 93500: 0.067863\n",
      "2023-12-10 16:03:42,039 INFO     Training average negative_sample_loss at step 93500: 0.067725\n",
      "2023-12-10 16:03:42,039 INFO     Training average loss at step 93500: 0.067794\n",
      "2023-12-10 16:04:58,703 INFO     Training average positive_sample_loss at step 93600: 0.067898\n",
      "2023-12-10 16:04:58,704 INFO     Training average negative_sample_loss at step 93600: 0.067532\n",
      "2023-12-10 16:04:58,704 INFO     Training average loss at step 93600: 0.067715\n",
      "2023-12-10 16:06:16,586 INFO     Training average positive_sample_loss at step 93700: 0.067366\n",
      "2023-12-10 16:06:16,586 INFO     Training average negative_sample_loss at step 93700: 0.066544\n",
      "2023-12-10 16:06:16,586 INFO     Training average loss at step 93700: 0.066955\n",
      "2023-12-10 16:07:34,069 INFO     Training average positive_sample_loss at step 93800: 0.067871\n",
      "2023-12-10 16:07:34,069 INFO     Training average negative_sample_loss at step 93800: 0.066324\n",
      "2023-12-10 16:07:34,069 INFO     Training average loss at step 93800: 0.067098\n",
      "2023-12-10 16:08:49,526 INFO     Training average positive_sample_loss at step 93900: 0.067945\n",
      "2023-12-10 16:08:49,526 INFO     Training average negative_sample_loss at step 93900: 0.067180\n",
      "2023-12-10 16:08:49,526 INFO     Training average loss at step 93900: 0.067563\n",
      "2023-12-10 16:10:04,234 INFO     Training average positive_sample_loss at step 94000: 0.067935\n",
      "2023-12-10 16:10:04,234 INFO     Training average negative_sample_loss at step 94000: 0.066982\n",
      "2023-12-10 16:10:04,235 INFO     Training average loss at step 94000: 0.067459\n",
      "2023-12-10 16:11:20,676 INFO     Training average positive_sample_loss at step 94100: 0.068426\n",
      "2023-12-10 16:11:20,676 INFO     Training average negative_sample_loss at step 94100: 0.067769\n",
      "2023-12-10 16:11:20,676 INFO     Training average loss at step 94100: 0.068097\n",
      "2023-12-10 16:12:36,745 INFO     Training average positive_sample_loss at step 94200: 0.068723\n",
      "2023-12-10 16:12:36,746 INFO     Training average negative_sample_loss at step 94200: 0.066423\n",
      "2023-12-10 16:12:36,746 INFO     Training average loss at step 94200: 0.067573\n",
      "2023-12-10 16:13:51,320 INFO     Training average positive_sample_loss at step 94300: 0.069223\n",
      "2023-12-10 16:13:51,321 INFO     Training average negative_sample_loss at step 94300: 0.068236\n",
      "2023-12-10 16:13:51,321 INFO     Training average loss at step 94300: 0.068730\n",
      "2023-12-10 16:15:12,726 INFO     Training average positive_sample_loss at step 94400: 0.068984\n",
      "2023-12-10 16:15:12,727 INFO     Training average negative_sample_loss at step 94400: 0.067046\n",
      "2023-12-10 16:15:12,727 INFO     Training average loss at step 94400: 0.068015\n",
      "2023-12-10 16:16:32,795 INFO     Training average positive_sample_loss at step 94500: 0.066695\n",
      "2023-12-10 16:16:32,795 INFO     Training average negative_sample_loss at step 94500: 0.067551\n",
      "2023-12-10 16:16:32,795 INFO     Training average loss at step 94500: 0.067123\n",
      "2023-12-10 16:17:49,820 INFO     Training average positive_sample_loss at step 94600: 0.067836\n",
      "2023-12-10 16:17:49,820 INFO     Training average negative_sample_loss at step 94600: 0.067049\n",
      "2023-12-10 16:17:49,820 INFO     Training average loss at step 94600: 0.067443\n",
      "2023-12-10 16:19:05,322 INFO     Training average positive_sample_loss at step 94700: 0.067748\n",
      "2023-12-10 16:19:05,323 INFO     Training average negative_sample_loss at step 94700: 0.067843\n",
      "2023-12-10 16:19:05,323 INFO     Training average loss at step 94700: 0.067796\n",
      "2023-12-10 16:20:21,321 INFO     Training average positive_sample_loss at step 94800: 0.068069\n",
      "2023-12-10 16:20:21,321 INFO     Training average negative_sample_loss at step 94800: 0.066418\n",
      "2023-12-10 16:20:21,321 INFO     Training average loss at step 94800: 0.067244\n",
      "2023-12-10 16:21:36,986 INFO     Training average positive_sample_loss at step 94900: 0.068111\n",
      "2023-12-10 16:21:36,986 INFO     Training average negative_sample_loss at step 94900: 0.066833\n",
      "2023-12-10 16:21:36,986 INFO     Training average loss at step 94900: 0.067472\n",
      "2023-12-10 16:22:52,155 INFO     Training average positive_sample_loss at step 95000: 0.068421\n",
      "2023-12-10 16:22:52,155 INFO     Training average negative_sample_loss at step 95000: 0.066941\n",
      "2023-12-10 16:22:52,155 INFO     Training average loss at step 95000: 0.067681\n",
      "2023-12-10 16:24:07,416 INFO     Training average positive_sample_loss at step 95100: 0.068645\n",
      "2023-12-10 16:24:07,416 INFO     Training average negative_sample_loss at step 95100: 0.067430\n",
      "2023-12-10 16:24:07,416 INFO     Training average loss at step 95100: 0.068037\n",
      "2023-12-10 16:25:25,905 INFO     Training average positive_sample_loss at step 95200: 0.068875\n",
      "2023-12-10 16:25:25,906 INFO     Training average negative_sample_loss at step 95200: 0.067701\n",
      "2023-12-10 16:25:25,906 INFO     Training average loss at step 95200: 0.068288\n",
      "2023-12-10 16:26:42,793 INFO     Training average positive_sample_loss at step 95300: 0.068855\n",
      "2023-12-10 16:26:42,794 INFO     Training average negative_sample_loss at step 95300: 0.067070\n",
      "2023-12-10 16:26:42,794 INFO     Training average loss at step 95300: 0.067963\n",
      "2023-12-10 16:28:10,015 INFO     Training average positive_sample_loss at step 95400: 0.067587\n",
      "2023-12-10 16:28:10,015 INFO     Training average negative_sample_loss at step 95400: 0.066699\n",
      "2023-12-10 16:28:10,015 INFO     Training average loss at step 95400: 0.067143\n",
      "2023-12-10 16:29:27,759 INFO     Training average positive_sample_loss at step 95500: 0.067565\n",
      "2023-12-10 16:29:27,760 INFO     Training average negative_sample_loss at step 95500: 0.067374\n",
      "2023-12-10 16:29:27,760 INFO     Training average loss at step 95500: 0.067469\n",
      "2023-12-10 16:30:42,873 INFO     Training average positive_sample_loss at step 95600: 0.068008\n",
      "2023-12-10 16:30:42,874 INFO     Training average negative_sample_loss at step 95600: 0.066849\n",
      "2023-12-10 16:30:42,874 INFO     Training average loss at step 95600: 0.067428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 16:31:57,914 INFO     Training average positive_sample_loss at step 95700: 0.068180\n",
      "2023-12-10 16:31:57,914 INFO     Training average negative_sample_loss at step 95700: 0.067664\n",
      "2023-12-10 16:31:57,914 INFO     Training average loss at step 95700: 0.067922\n",
      "2023-12-10 16:33:16,600 INFO     Training average positive_sample_loss at step 95800: 0.068109\n",
      "2023-12-10 16:33:16,600 INFO     Training average negative_sample_loss at step 95800: 0.067318\n",
      "2023-12-10 16:33:16,600 INFO     Training average loss at step 95800: 0.067713\n",
      "2023-12-10 16:34:35,040 INFO     Training average positive_sample_loss at step 95900: 0.068654\n",
      "2023-12-10 16:34:35,040 INFO     Training average negative_sample_loss at step 95900: 0.067704\n",
      "2023-12-10 16:34:35,040 INFO     Training average loss at step 95900: 0.068179\n",
      "2023-12-10 16:35:49,430 INFO     Training average positive_sample_loss at step 96000: 0.068391\n",
      "2023-12-10 16:35:49,430 INFO     Training average negative_sample_loss at step 96000: 0.066816\n",
      "2023-12-10 16:35:49,430 INFO     Training average loss at step 96000: 0.067603\n",
      "2023-12-10 16:37:03,376 INFO     Training average positive_sample_loss at step 96100: 0.068635\n",
      "2023-12-10 16:37:03,376 INFO     Training average negative_sample_loss at step 96100: 0.067174\n",
      "2023-12-10 16:37:03,376 INFO     Training average loss at step 96100: 0.067905\n",
      "2023-12-10 16:38:18,398 INFO     Training average positive_sample_loss at step 96200: 0.068380\n",
      "2023-12-10 16:38:18,398 INFO     Training average negative_sample_loss at step 96200: 0.066746\n",
      "2023-12-10 16:38:18,398 INFO     Training average loss at step 96200: 0.067563\n",
      "2023-12-10 16:39:48,493 INFO     Training average positive_sample_loss at step 96300: 0.068599\n",
      "2023-12-10 16:39:48,494 INFO     Training average negative_sample_loss at step 96300: 0.068290\n",
      "2023-12-10 16:39:48,494 INFO     Training average loss at step 96300: 0.068444\n",
      "2023-12-10 16:41:03,876 INFO     Training average positive_sample_loss at step 96400: 0.067018\n",
      "2023-12-10 16:41:03,877 INFO     Training average negative_sample_loss at step 96400: 0.066573\n",
      "2023-12-10 16:41:03,877 INFO     Training average loss at step 96400: 0.066796\n",
      "2023-12-10 16:42:21,384 INFO     Training average positive_sample_loss at step 96500: 0.067776\n",
      "2023-12-10 16:42:21,384 INFO     Training average negative_sample_loss at step 96500: 0.066476\n",
      "2023-12-10 16:42:21,384 INFO     Training average loss at step 96500: 0.067126\n",
      "2023-12-10 16:43:37,243 INFO     Training average positive_sample_loss at step 96600: 0.068180\n",
      "2023-12-10 16:43:37,243 INFO     Training average negative_sample_loss at step 96600: 0.067363\n",
      "2023-12-10 16:43:37,243 INFO     Training average loss at step 96600: 0.067771\n",
      "2023-12-10 16:44:53,126 INFO     Training average positive_sample_loss at step 96700: 0.068057\n",
      "2023-12-10 16:44:53,127 INFO     Training average negative_sample_loss at step 96700: 0.067097\n",
      "2023-12-10 16:44:53,127 INFO     Training average loss at step 96700: 0.067577\n",
      "2023-12-10 16:46:08,911 INFO     Training average positive_sample_loss at step 96800: 0.068590\n",
      "2023-12-10 16:46:08,911 INFO     Training average negative_sample_loss at step 96800: 0.066631\n",
      "2023-12-10 16:46:08,911 INFO     Training average loss at step 96800: 0.067611\n",
      "2023-12-10 16:47:24,096 INFO     Training average positive_sample_loss at step 96900: 0.068513\n",
      "2023-12-10 16:47:24,096 INFO     Training average negative_sample_loss at step 96900: 0.067517\n",
      "2023-12-10 16:47:24,096 INFO     Training average loss at step 96900: 0.068015\n",
      "2023-12-10 16:48:41,299 INFO     Training average positive_sample_loss at step 97000: 0.068484\n",
      "2023-12-10 16:48:41,300 INFO     Training average negative_sample_loss at step 97000: 0.066835\n",
      "2023-12-10 16:48:41,300 INFO     Training average loss at step 97000: 0.067659\n",
      "2023-12-10 16:49:56,332 INFO     Training average positive_sample_loss at step 97100: 0.068419\n",
      "2023-12-10 16:49:56,332 INFO     Training average negative_sample_loss at step 97100: 0.066839\n",
      "2023-12-10 16:49:56,332 INFO     Training average loss at step 97100: 0.067629\n",
      "2023-12-10 16:51:10,852 INFO     Training average positive_sample_loss at step 97200: 0.068462\n",
      "2023-12-10 16:51:10,852 INFO     Training average negative_sample_loss at step 97200: 0.067250\n",
      "2023-12-10 16:51:10,852 INFO     Training average loss at step 97200: 0.067856\n",
      "2023-12-10 16:52:35,287 INFO     Training average positive_sample_loss at step 97300: 0.067174\n",
      "2023-12-10 16:52:35,288 INFO     Training average negative_sample_loss at step 97300: 0.067197\n",
      "2023-12-10 16:52:35,288 INFO     Training average loss at step 97300: 0.067186\n",
      "2023-12-10 16:53:50,570 INFO     Training average positive_sample_loss at step 97400: 0.067274\n",
      "2023-12-10 16:53:50,570 INFO     Training average negative_sample_loss at step 97400: 0.067462\n",
      "2023-12-10 16:53:50,570 INFO     Training average loss at step 97400: 0.067368\n",
      "2023-12-10 16:55:07,031 INFO     Training average positive_sample_loss at step 97500: 0.067603\n",
      "2023-12-10 16:55:07,031 INFO     Training average negative_sample_loss at step 97500: 0.065666\n",
      "2023-12-10 16:55:07,031 INFO     Training average loss at step 97500: 0.066634\n",
      "2023-12-10 16:56:21,194 INFO     Training average positive_sample_loss at step 97600: 0.068084\n",
      "2023-12-10 16:56:21,194 INFO     Training average negative_sample_loss at step 97600: 0.067108\n",
      "2023-12-10 16:56:21,194 INFO     Training average loss at step 97600: 0.067596\n",
      "2023-12-10 16:57:35,338 INFO     Training average positive_sample_loss at step 97700: 0.068018\n",
      "2023-12-10 16:57:35,338 INFO     Training average negative_sample_loss at step 97700: 0.067294\n",
      "2023-12-10 16:57:35,338 INFO     Training average loss at step 97700: 0.067656\n",
      "2023-12-10 16:58:52,440 INFO     Training average positive_sample_loss at step 97800: 0.068670\n",
      "2023-12-10 16:58:52,440 INFO     Training average negative_sample_loss at step 97800: 0.067660\n",
      "2023-12-10 16:58:52,440 INFO     Training average loss at step 97800: 0.068165\n",
      "2023-12-10 17:00:11,773 INFO     Training average positive_sample_loss at step 97900: 0.068290\n",
      "2023-12-10 17:00:11,773 INFO     Training average negative_sample_loss at step 97900: 0.066931\n",
      "2023-12-10 17:00:11,773 INFO     Training average loss at step 97900: 0.067611\n",
      "2023-12-10 17:01:29,514 INFO     Training average positive_sample_loss at step 98000: 0.068813\n",
      "2023-12-10 17:01:29,515 INFO     Training average negative_sample_loss at step 98000: 0.067680\n",
      "2023-12-10 17:01:29,515 INFO     Training average loss at step 98000: 0.068247\n",
      "2023-12-10 17:02:46,136 INFO     Training average positive_sample_loss at step 98100: 0.069199\n",
      "2023-12-10 17:02:46,136 INFO     Training average negative_sample_loss at step 98100: 0.067903\n",
      "2023-12-10 17:02:46,136 INFO     Training average loss at step 98100: 0.068551\n",
      "2023-12-10 17:04:18,534 INFO     Training average positive_sample_loss at step 98200: 0.068460\n",
      "2023-12-10 17:04:18,535 INFO     Training average negative_sample_loss at step 98200: 0.067159\n",
      "2023-12-10 17:04:18,535 INFO     Training average loss at step 98200: 0.067810\n",
      "2023-12-10 17:05:32,934 INFO     Training average positive_sample_loss at step 98300: 0.067480\n",
      "2023-12-10 17:05:32,935 INFO     Training average negative_sample_loss at step 98300: 0.067694\n",
      "2023-12-10 17:05:32,935 INFO     Training average loss at step 98300: 0.067587\n",
      "2023-12-10 17:06:47,306 INFO     Training average positive_sample_loss at step 98400: 0.067691\n",
      "2023-12-10 17:06:47,306 INFO     Training average negative_sample_loss at step 98400: 0.066285\n",
      "2023-12-10 17:06:47,306 INFO     Training average loss at step 98400: 0.066988\n",
      "2023-12-10 17:08:02,544 INFO     Training average positive_sample_loss at step 98500: 0.067706\n",
      "2023-12-10 17:08:02,545 INFO     Training average negative_sample_loss at step 98500: 0.067665\n",
      "2023-12-10 17:08:02,545 INFO     Training average loss at step 98500: 0.067685\n",
      "2023-12-10 17:09:19,753 INFO     Training average positive_sample_loss at step 98600: 0.068131\n",
      "2023-12-10 17:09:19,754 INFO     Training average negative_sample_loss at step 98600: 0.066984\n",
      "2023-12-10 17:09:19,754 INFO     Training average loss at step 98600: 0.067558\n",
      "2023-12-10 17:10:37,902 INFO     Training average positive_sample_loss at step 98700: 0.068747\n",
      "2023-12-10 17:10:37,902 INFO     Training average negative_sample_loss at step 98700: 0.067409\n",
      "2023-12-10 17:10:37,902 INFO     Training average loss at step 98700: 0.068078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 17:11:53,819 INFO     Training average positive_sample_loss at step 98800: 0.068411\n",
      "2023-12-10 17:11:53,819 INFO     Training average negative_sample_loss at step 98800: 0.066458\n",
      "2023-12-10 17:11:53,819 INFO     Training average loss at step 98800: 0.067434\n",
      "2023-12-10 17:13:08,635 INFO     Training average positive_sample_loss at step 98900: 0.068432\n",
      "2023-12-10 17:13:08,635 INFO     Training average negative_sample_loss at step 98900: 0.067410\n",
      "2023-12-10 17:13:08,635 INFO     Training average loss at step 98900: 0.067921\n",
      "2023-12-10 17:14:22,574 INFO     Training average positive_sample_loss at step 99000: 0.068635\n",
      "2023-12-10 17:14:22,574 INFO     Training average negative_sample_loss at step 99000: 0.066999\n",
      "2023-12-10 17:14:22,574 INFO     Training average loss at step 99000: 0.067817\n",
      "2023-12-10 17:15:38,179 INFO     Training average positive_sample_loss at step 99100: 0.068646\n",
      "2023-12-10 17:15:38,180 INFO     Training average negative_sample_loss at step 99100: 0.067375\n",
      "2023-12-10 17:15:38,180 INFO     Training average loss at step 99100: 0.068010\n",
      "2023-12-10 17:17:02,664 INFO     Training average positive_sample_loss at step 99200: 0.067072\n",
      "2023-12-10 17:17:02,664 INFO     Training average negative_sample_loss at step 99200: 0.066780\n",
      "2023-12-10 17:17:02,664 INFO     Training average loss at step 99200: 0.066926\n",
      "2023-12-10 17:18:20,059 INFO     Training average positive_sample_loss at step 99300: 0.067517\n",
      "2023-12-10 17:18:20,059 INFO     Training average negative_sample_loss at step 99300: 0.066779\n",
      "2023-12-10 17:18:20,059 INFO     Training average loss at step 99300: 0.067148\n",
      "2023-12-10 17:19:37,107 INFO     Training average positive_sample_loss at step 99400: 0.067947\n",
      "2023-12-10 17:19:37,108 INFO     Training average negative_sample_loss at step 99400: 0.067078\n",
      "2023-12-10 17:19:37,108 INFO     Training average loss at step 99400: 0.067512\n",
      "2023-12-10 17:20:56,000 INFO     Training average positive_sample_loss at step 99500: 0.068145\n",
      "2023-12-10 17:20:56,000 INFO     Training average negative_sample_loss at step 99500: 0.067346\n",
      "2023-12-10 17:20:56,000 INFO     Training average loss at step 99500: 0.067745\n",
      "2023-12-10 17:22:14,699 INFO     Training average positive_sample_loss at step 99600: 0.068230\n",
      "2023-12-10 17:22:14,699 INFO     Training average negative_sample_loss at step 99600: 0.066447\n",
      "2023-12-10 17:22:14,699 INFO     Training average loss at step 99600: 0.067339\n",
      "2023-12-10 17:23:32,483 INFO     Training average positive_sample_loss at step 99700: 0.068609\n",
      "2023-12-10 17:23:32,483 INFO     Training average negative_sample_loss at step 99700: 0.067466\n",
      "2023-12-10 17:23:32,483 INFO     Training average loss at step 99700: 0.068038\n",
      "2023-12-10 17:24:48,185 INFO     Training average positive_sample_loss at step 99800: 0.068167\n",
      "2023-12-10 17:24:48,185 INFO     Training average negative_sample_loss at step 99800: 0.067808\n",
      "2023-12-10 17:24:48,186 INFO     Training average loss at step 99800: 0.067987\n",
      "2023-12-10 17:26:05,824 INFO     Training average positive_sample_loss at step 99900: 0.068946\n",
      "2023-12-10 17:26:05,824 INFO     Training average negative_sample_loss at step 99900: 0.067141\n",
      "2023-12-10 17:26:05,824 INFO     Training average loss at step 99900: 0.068043\n",
      "2023-12-10 17:27:37,211 INFO     Training average positive_sample_loss at step 100000: 0.068651\n",
      "2023-12-10 17:27:37,211 INFO     Training average negative_sample_loss at step 100000: 0.067385\n",
      "2023-12-10 17:27:37,211 INFO     Training average loss at step 100000: 0.068018\n",
      "2023-12-10 17:27:37,211 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 17:27:38,236 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 17:28:22,903 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 17:29:07,023 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 17:29:49,503 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 17:30:31,907 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 17:31:13,797 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 17:31:54,728 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 17:32:04,888 INFO     Valid MRR at step 100000: 0.796437\n",
      "2023-12-10 17:32:04,888 INFO     Valid MR at step 100000: 39.656480\n",
      "2023-12-10 17:32:04,888 INFO     Valid HITS@1 at step 100000: 0.746690\n",
      "2023-12-10 17:32:04,888 INFO     Valid HITS@3 at step 100000: 0.826850\n",
      "2023-12-10 17:32:04,888 INFO     Valid HITS@10 at step 100000: 0.883040\n",
      "2023-12-10 17:33:25,268 INFO     Training average positive_sample_loss at step 100100: 0.068181\n",
      "2023-12-10 17:33:25,268 INFO     Training average negative_sample_loss at step 100100: 0.067434\n",
      "2023-12-10 17:33:25,268 INFO     Training average loss at step 100100: 0.067807\n",
      "2023-12-10 17:34:40,085 INFO     Training average positive_sample_loss at step 100200: 0.066881\n",
      "2023-12-10 17:34:40,086 INFO     Training average negative_sample_loss at step 100200: 0.065857\n",
      "2023-12-10 17:34:40,086 INFO     Training average loss at step 100200: 0.066369\n",
      "2023-12-10 17:35:56,389 INFO     Training average positive_sample_loss at step 100300: 0.067517\n",
      "2023-12-10 17:35:56,390 INFO     Training average negative_sample_loss at step 100300: 0.066750\n",
      "2023-12-10 17:35:56,390 INFO     Training average loss at step 100300: 0.067133\n",
      "2023-12-10 17:37:13,191 INFO     Training average positive_sample_loss at step 100400: 0.068232\n",
      "2023-12-10 17:37:13,191 INFO     Training average negative_sample_loss at step 100400: 0.067324\n",
      "2023-12-10 17:37:13,192 INFO     Training average loss at step 100400: 0.067778\n",
      "2023-12-10 17:38:28,412 INFO     Training average positive_sample_loss at step 100500: 0.068011\n",
      "2023-12-10 17:38:28,412 INFO     Training average negative_sample_loss at step 100500: 0.065623\n",
      "2023-12-10 17:38:28,412 INFO     Training average loss at step 100500: 0.066817\n",
      "2023-12-10 17:39:43,148 INFO     Training average positive_sample_loss at step 100600: 0.068428\n",
      "2023-12-10 17:39:43,148 INFO     Training average negative_sample_loss at step 100600: 0.066995\n",
      "2023-12-10 17:39:43,148 INFO     Training average loss at step 100600: 0.067711\n",
      "2023-12-10 17:40:58,594 INFO     Training average positive_sample_loss at step 100700: 0.068492\n",
      "2023-12-10 17:40:58,594 INFO     Training average negative_sample_loss at step 100700: 0.068339\n",
      "2023-12-10 17:40:58,594 INFO     Training average loss at step 100700: 0.068416\n",
      "2023-12-10 17:42:14,164 INFO     Training average positive_sample_loss at step 100800: 0.068795\n",
      "2023-12-10 17:42:14,165 INFO     Training average negative_sample_loss at step 100800: 0.067342\n",
      "2023-12-10 17:42:14,165 INFO     Training average loss at step 100800: 0.068068\n",
      "2023-12-10 17:43:29,884 INFO     Training average positive_sample_loss at step 100900: 0.068542\n",
      "2023-12-10 17:43:29,884 INFO     Training average negative_sample_loss at step 100900: 0.067339\n",
      "2023-12-10 17:43:29,884 INFO     Training average loss at step 100900: 0.067940\n",
      "2023-12-10 17:44:46,088 INFO     Training average positive_sample_loss at step 101000: 0.068789\n",
      "2023-12-10 17:44:46,088 INFO     Training average negative_sample_loss at step 101000: 0.067468\n",
      "2023-12-10 17:44:46,088 INFO     Training average loss at step 101000: 0.068129\n",
      "2023-12-10 17:46:11,660 INFO     Training average positive_sample_loss at step 101100: 0.067001\n",
      "2023-12-10 17:46:11,660 INFO     Training average negative_sample_loss at step 101100: 0.066919\n",
      "2023-12-10 17:46:11,660 INFO     Training average loss at step 101100: 0.066960\n",
      "2023-12-10 17:47:27,435 INFO     Training average positive_sample_loss at step 101200: 0.067631\n",
      "2023-12-10 17:47:27,435 INFO     Training average negative_sample_loss at step 101200: 0.067414\n",
      "2023-12-10 17:47:27,435 INFO     Training average loss at step 101200: 0.067522\n",
      "2023-12-10 17:48:43,366 INFO     Training average positive_sample_loss at step 101300: 0.067852\n",
      "2023-12-10 17:48:43,366 INFO     Training average negative_sample_loss at step 101300: 0.067281\n",
      "2023-12-10 17:48:43,366 INFO     Training average loss at step 101300: 0.067567\n",
      "2023-12-10 17:50:00,493 INFO     Training average positive_sample_loss at step 101400: 0.068207\n",
      "2023-12-10 17:50:00,493 INFO     Training average negative_sample_loss at step 101400: 0.066862\n",
      "2023-12-10 17:50:00,493 INFO     Training average loss at step 101400: 0.067534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 17:51:17,247 INFO     Training average positive_sample_loss at step 101500: 0.068348\n",
      "2023-12-10 17:51:17,247 INFO     Training average negative_sample_loss at step 101500: 0.067159\n",
      "2023-12-10 17:51:17,247 INFO     Training average loss at step 101500: 0.067754\n",
      "2023-12-10 17:52:31,388 INFO     Training average positive_sample_loss at step 101600: 0.068307\n",
      "2023-12-10 17:52:31,389 INFO     Training average negative_sample_loss at step 101600: 0.067110\n",
      "2023-12-10 17:52:31,389 INFO     Training average loss at step 101600: 0.067709\n",
      "2023-12-10 17:53:45,791 INFO     Training average positive_sample_loss at step 101700: 0.068545\n",
      "2023-12-10 17:53:45,792 INFO     Training average negative_sample_loss at step 101700: 0.066192\n",
      "2023-12-10 17:53:45,792 INFO     Training average loss at step 101700: 0.067369\n",
      "2023-12-10 17:55:00,958 INFO     Training average positive_sample_loss at step 101800: 0.068792\n",
      "2023-12-10 17:55:00,958 INFO     Training average negative_sample_loss at step 101800: 0.067143\n",
      "2023-12-10 17:55:00,958 INFO     Training average loss at step 101800: 0.067967\n",
      "2023-12-10 17:56:15,132 INFO     Training average positive_sample_loss at step 101900: 0.068620\n",
      "2023-12-10 17:56:15,132 INFO     Training average negative_sample_loss at step 101900: 0.067414\n",
      "2023-12-10 17:56:15,132 INFO     Training average loss at step 101900: 0.068017\n",
      "2023-12-10 17:57:40,997 INFO     Training average positive_sample_loss at step 102000: 0.067927\n",
      "2023-12-10 17:57:40,997 INFO     Training average negative_sample_loss at step 102000: 0.067669\n",
      "2023-12-10 17:57:40,997 INFO     Training average loss at step 102000: 0.067798\n",
      "2023-12-10 17:58:58,260 INFO     Training average positive_sample_loss at step 102100: 0.067349\n",
      "2023-12-10 17:58:58,260 INFO     Training average negative_sample_loss at step 102100: 0.067158\n",
      "2023-12-10 17:58:58,261 INFO     Training average loss at step 102100: 0.067254\n",
      "2023-12-10 18:00:12,881 INFO     Training average positive_sample_loss at step 102200: 0.067818\n",
      "2023-12-10 18:00:12,882 INFO     Training average negative_sample_loss at step 102200: 0.066618\n",
      "2023-12-10 18:00:12,882 INFO     Training average loss at step 102200: 0.067218\n",
      "2023-12-10 18:01:28,313 INFO     Training average positive_sample_loss at step 102300: 0.067605\n",
      "2023-12-10 18:01:28,313 INFO     Training average negative_sample_loss at step 102300: 0.066589\n",
      "2023-12-10 18:01:28,313 INFO     Training average loss at step 102300: 0.067097\n",
      "2023-12-10 18:02:45,451 INFO     Training average positive_sample_loss at step 102400: 0.068318\n",
      "2023-12-10 18:02:45,452 INFO     Training average negative_sample_loss at step 102400: 0.066913\n",
      "2023-12-10 18:02:45,452 INFO     Training average loss at step 102400: 0.067615\n",
      "2023-12-10 18:04:00,641 INFO     Training average positive_sample_loss at step 102500: 0.068562\n",
      "2023-12-10 18:04:00,641 INFO     Training average negative_sample_loss at step 102500: 0.066501\n",
      "2023-12-10 18:04:00,641 INFO     Training average loss at step 102500: 0.067532\n",
      "2023-12-10 18:05:16,296 INFO     Training average positive_sample_loss at step 102600: 0.068720\n",
      "2023-12-10 18:05:16,296 INFO     Training average negative_sample_loss at step 102600: 0.067837\n",
      "2023-12-10 18:05:16,296 INFO     Training average loss at step 102600: 0.068279\n",
      "2023-12-10 18:06:30,910 INFO     Training average positive_sample_loss at step 102700: 0.068511\n",
      "2023-12-10 18:06:30,910 INFO     Training average negative_sample_loss at step 102700: 0.066075\n",
      "2023-12-10 18:06:30,910 INFO     Training average loss at step 102700: 0.067293\n",
      "2023-12-10 18:07:47,248 INFO     Training average positive_sample_loss at step 102800: 0.068398\n",
      "2023-12-10 18:07:47,248 INFO     Training average negative_sample_loss at step 102800: 0.066811\n",
      "2023-12-10 18:07:47,248 INFO     Training average loss at step 102800: 0.067605\n",
      "2023-12-10 18:09:14,889 INFO     Training average positive_sample_loss at step 102900: 0.068574\n",
      "2023-12-10 18:09:14,889 INFO     Training average negative_sample_loss at step 102900: 0.067639\n",
      "2023-12-10 18:09:14,889 INFO     Training average loss at step 102900: 0.068107\n",
      "2023-12-10 18:10:32,881 INFO     Training average positive_sample_loss at step 103000: 0.066614\n",
      "2023-12-10 18:10:32,881 INFO     Training average negative_sample_loss at step 103000: 0.066711\n",
      "2023-12-10 18:10:32,881 INFO     Training average loss at step 103000: 0.066663\n",
      "2023-12-10 18:11:49,192 INFO     Training average positive_sample_loss at step 103100: 0.067542\n",
      "2023-12-10 18:11:49,192 INFO     Training average negative_sample_loss at step 103100: 0.065698\n",
      "2023-12-10 18:11:49,192 INFO     Training average loss at step 103100: 0.066620\n",
      "2023-12-10 18:13:04,322 INFO     Training average positive_sample_loss at step 103200: 0.067857\n",
      "2023-12-10 18:13:04,323 INFO     Training average negative_sample_loss at step 103200: 0.066894\n",
      "2023-12-10 18:13:04,323 INFO     Training average loss at step 103200: 0.067375\n",
      "2023-12-10 18:14:21,821 INFO     Training average positive_sample_loss at step 103300: 0.067759\n",
      "2023-12-10 18:14:21,821 INFO     Training average negative_sample_loss at step 103300: 0.065867\n",
      "2023-12-10 18:14:21,821 INFO     Training average loss at step 103300: 0.066813\n",
      "2023-12-10 18:15:38,450 INFO     Training average positive_sample_loss at step 103400: 0.068120\n",
      "2023-12-10 18:15:38,450 INFO     Training average negative_sample_loss at step 103400: 0.066666\n",
      "2023-12-10 18:15:38,450 INFO     Training average loss at step 103400: 0.067393\n",
      "2023-12-10 18:16:53,702 INFO     Training average positive_sample_loss at step 103500: 0.068483\n",
      "2023-12-10 18:16:53,702 INFO     Training average negative_sample_loss at step 103500: 0.067605\n",
      "2023-12-10 18:16:53,702 INFO     Training average loss at step 103500: 0.068044\n",
      "2023-12-10 18:18:08,942 INFO     Training average positive_sample_loss at step 103600: 0.068219\n",
      "2023-12-10 18:18:08,942 INFO     Training average negative_sample_loss at step 103600: 0.066759\n",
      "2023-12-10 18:18:08,942 INFO     Training average loss at step 103600: 0.067489\n",
      "2023-12-10 18:19:24,605 INFO     Training average positive_sample_loss at step 103700: 0.068605\n",
      "2023-12-10 18:19:24,605 INFO     Training average negative_sample_loss at step 103700: 0.066515\n",
      "2023-12-10 18:19:24,606 INFO     Training average loss at step 103700: 0.067560\n",
      "2023-12-10 18:20:39,496 INFO     Training average positive_sample_loss at step 103800: 0.068813\n",
      "2023-12-10 18:20:39,497 INFO     Training average negative_sample_loss at step 103800: 0.067750\n",
      "2023-12-10 18:20:39,497 INFO     Training average loss at step 103800: 0.068281\n",
      "2023-12-10 18:22:03,804 INFO     Training average positive_sample_loss at step 103900: 0.067558\n",
      "2023-12-10 18:22:03,804 INFO     Training average negative_sample_loss at step 103900: 0.067063\n",
      "2023-12-10 18:22:03,804 INFO     Training average loss at step 103900: 0.067311\n",
      "2023-12-10 18:23:21,367 INFO     Training average positive_sample_loss at step 104000: 0.067363\n",
      "2023-12-10 18:23:21,367 INFO     Training average negative_sample_loss at step 104000: 0.066266\n",
      "2023-12-10 18:23:21,367 INFO     Training average loss at step 104000: 0.066815\n",
      "2023-12-10 18:24:37,461 INFO     Training average positive_sample_loss at step 104100: 0.067360\n",
      "2023-12-10 18:24:37,462 INFO     Training average negative_sample_loss at step 104100: 0.066861\n",
      "2023-12-10 18:24:37,462 INFO     Training average loss at step 104100: 0.067110\n",
      "2023-12-10 18:25:53,756 INFO     Training average positive_sample_loss at step 104200: 0.067649\n",
      "2023-12-10 18:25:53,756 INFO     Training average negative_sample_loss at step 104200: 0.066232\n",
      "2023-12-10 18:25:53,756 INFO     Training average loss at step 104200: 0.066940\n",
      "2023-12-10 18:27:09,882 INFO     Training average positive_sample_loss at step 104300: 0.067885\n",
      "2023-12-10 18:27:09,882 INFO     Training average negative_sample_loss at step 104300: 0.066658\n",
      "2023-12-10 18:27:09,882 INFO     Training average loss at step 104300: 0.067271\n",
      "2023-12-10 18:28:26,443 INFO     Training average positive_sample_loss at step 104400: 0.068256\n",
      "2023-12-10 18:28:26,443 INFO     Training average negative_sample_loss at step 104400: 0.067785\n",
      "2023-12-10 18:28:26,443 INFO     Training average loss at step 104400: 0.068020\n",
      "2023-12-10 18:29:43,271 INFO     Training average positive_sample_loss at step 104500: 0.068625\n",
      "2023-12-10 18:29:43,271 INFO     Training average negative_sample_loss at step 104500: 0.067214\n",
      "2023-12-10 18:29:43,271 INFO     Training average loss at step 104500: 0.067920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 18:30:58,392 INFO     Training average positive_sample_loss at step 104600: 0.068792\n",
      "2023-12-10 18:30:58,392 INFO     Training average negative_sample_loss at step 104600: 0.067058\n",
      "2023-12-10 18:30:58,392 INFO     Training average loss at step 104600: 0.067925\n",
      "2023-12-10 18:32:12,726 INFO     Training average positive_sample_loss at step 104700: 0.068543\n",
      "2023-12-10 18:32:12,726 INFO     Training average negative_sample_loss at step 104700: 0.066537\n",
      "2023-12-10 18:32:12,726 INFO     Training average loss at step 104700: 0.067540\n",
      "2023-12-10 18:33:45,687 INFO     Training average positive_sample_loss at step 104800: 0.068364\n",
      "2023-12-10 18:33:45,688 INFO     Training average negative_sample_loss at step 104800: 0.067354\n",
      "2023-12-10 18:33:45,688 INFO     Training average loss at step 104800: 0.067859\n",
      "2023-12-10 18:35:01,530 INFO     Training average positive_sample_loss at step 104900: 0.066831\n",
      "2023-12-10 18:35:01,530 INFO     Training average negative_sample_loss at step 104900: 0.066207\n",
      "2023-12-10 18:35:01,530 INFO     Training average loss at step 104900: 0.066519\n",
      "2023-12-10 18:36:17,722 INFO     Training average positive_sample_loss at step 105000: 0.067799\n",
      "2023-12-10 18:36:17,723 INFO     Training average negative_sample_loss at step 105000: 0.067233\n",
      "2023-12-10 18:36:17,723 INFO     Training average loss at step 105000: 0.067516\n",
      "2023-12-10 18:37:35,845 INFO     Training average positive_sample_loss at step 105100: 0.067646\n",
      "2023-12-10 18:37:35,846 INFO     Training average negative_sample_loss at step 105100: 0.067093\n",
      "2023-12-10 18:37:35,846 INFO     Training average loss at step 105100: 0.067370\n",
      "2023-12-10 18:38:55,090 INFO     Training average positive_sample_loss at step 105200: 0.068200\n",
      "2023-12-10 18:38:55,091 INFO     Training average negative_sample_loss at step 105200: 0.065485\n",
      "2023-12-10 18:38:55,091 INFO     Training average loss at step 105200: 0.066843\n",
      "2023-12-10 18:40:12,781 INFO     Training average positive_sample_loss at step 105300: 0.067863\n",
      "2023-12-10 18:40:12,781 INFO     Training average negative_sample_loss at step 105300: 0.067278\n",
      "2023-12-10 18:40:12,781 INFO     Training average loss at step 105300: 0.067570\n",
      "2023-12-10 18:41:30,738 INFO     Training average positive_sample_loss at step 105400: 0.068521\n",
      "2023-12-10 18:41:30,739 INFO     Training average negative_sample_loss at step 105400: 0.066743\n",
      "2023-12-10 18:41:30,739 INFO     Training average loss at step 105400: 0.067632\n",
      "2023-12-10 18:42:48,903 INFO     Training average positive_sample_loss at step 105500: 0.068881\n",
      "2023-12-10 18:42:48,903 INFO     Training average negative_sample_loss at step 105500: 0.067199\n",
      "2023-12-10 18:42:48,903 INFO     Training average loss at step 105500: 0.068040\n",
      "2023-12-10 18:44:04,703 INFO     Training average positive_sample_loss at step 105600: 0.068548\n",
      "2023-12-10 18:44:04,704 INFO     Training average negative_sample_loss at step 105600: 0.066221\n",
      "2023-12-10 18:44:04,704 INFO     Training average loss at step 105600: 0.067385\n",
      "2023-12-10 18:45:21,900 INFO     Training average positive_sample_loss at step 105700: 0.068516\n",
      "2023-12-10 18:45:21,900 INFO     Training average negative_sample_loss at step 105700: 0.067806\n",
      "2023-12-10 18:45:21,900 INFO     Training average loss at step 105700: 0.068161\n",
      "2023-12-10 18:46:53,439 INFO     Training average positive_sample_loss at step 105800: 0.067484\n",
      "2023-12-10 18:46:53,440 INFO     Training average negative_sample_loss at step 105800: 0.067243\n",
      "2023-12-10 18:46:53,440 INFO     Training average loss at step 105800: 0.067363\n",
      "2023-12-10 18:48:10,411 INFO     Training average positive_sample_loss at step 105900: 0.067185\n",
      "2023-12-10 18:48:10,412 INFO     Training average negative_sample_loss at step 105900: 0.066020\n",
      "2023-12-10 18:48:10,412 INFO     Training average loss at step 105900: 0.066602\n",
      "2023-12-10 18:49:26,614 INFO     Training average positive_sample_loss at step 106000: 0.067660\n",
      "2023-12-10 18:49:26,614 INFO     Training average negative_sample_loss at step 106000: 0.067545\n",
      "2023-12-10 18:49:26,614 INFO     Training average loss at step 106000: 0.067602\n",
      "2023-12-10 18:50:40,016 INFO     Training average positive_sample_loss at step 106100: 0.068153\n",
      "2023-12-10 18:50:40,016 INFO     Training average negative_sample_loss at step 106100: 0.067261\n",
      "2023-12-10 18:50:40,016 INFO     Training average loss at step 106100: 0.067707\n",
      "2023-12-10 18:51:55,168 INFO     Training average positive_sample_loss at step 106200: 0.067816\n",
      "2023-12-10 18:51:55,169 INFO     Training average negative_sample_loss at step 106200: 0.067001\n",
      "2023-12-10 18:51:55,169 INFO     Training average loss at step 106200: 0.067409\n",
      "2023-12-10 18:53:09,651 INFO     Training average positive_sample_loss at step 106300: 0.068109\n",
      "2023-12-10 18:53:09,651 INFO     Training average negative_sample_loss at step 106300: 0.066641\n",
      "2023-12-10 18:53:09,651 INFO     Training average loss at step 106300: 0.067375\n",
      "2023-12-10 18:54:24,725 INFO     Training average positive_sample_loss at step 106400: 0.068587\n",
      "2023-12-10 18:54:24,725 INFO     Training average negative_sample_loss at step 106400: 0.066801\n",
      "2023-12-10 18:54:24,725 INFO     Training average loss at step 106400: 0.067694\n",
      "2023-12-10 18:55:43,756 INFO     Training average positive_sample_loss at step 106500: 0.068606\n",
      "2023-12-10 18:55:43,756 INFO     Training average negative_sample_loss at step 106500: 0.067562\n",
      "2023-12-10 18:55:43,756 INFO     Training average loss at step 106500: 0.068084\n",
      "2023-12-10 18:57:03,330 INFO     Training average positive_sample_loss at step 106600: 0.068233\n",
      "2023-12-10 18:57:03,330 INFO     Training average negative_sample_loss at step 106600: 0.066791\n",
      "2023-12-10 18:57:03,330 INFO     Training average loss at step 106600: 0.067512\n",
      "2023-12-10 18:58:33,318 INFO     Training average positive_sample_loss at step 106700: 0.068218\n",
      "2023-12-10 18:58:33,318 INFO     Training average negative_sample_loss at step 106700: 0.066889\n",
      "2023-12-10 18:58:33,318 INFO     Training average loss at step 106700: 0.067554\n",
      "2023-12-10 18:59:52,458 INFO     Training average positive_sample_loss at step 106800: 0.067251\n",
      "2023-12-10 18:59:52,459 INFO     Training average negative_sample_loss at step 106800: 0.066528\n",
      "2023-12-10 18:59:52,459 INFO     Training average loss at step 106800: 0.066890\n",
      "2023-12-10 19:01:09,800 INFO     Training average positive_sample_loss at step 106900: 0.067774\n",
      "2023-12-10 19:01:09,801 INFO     Training average negative_sample_loss at step 106900: 0.065934\n",
      "2023-12-10 19:01:09,801 INFO     Training average loss at step 106900: 0.066854\n",
      "2023-12-10 19:02:24,477 INFO     Training average positive_sample_loss at step 107000: 0.067497\n",
      "2023-12-10 19:02:24,477 INFO     Training average negative_sample_loss at step 107000: 0.066300\n",
      "2023-12-10 19:02:24,477 INFO     Training average loss at step 107000: 0.066898\n",
      "2023-12-10 19:03:41,259 INFO     Training average positive_sample_loss at step 107100: 0.067759\n",
      "2023-12-10 19:03:41,259 INFO     Training average negative_sample_loss at step 107100: 0.066480\n",
      "2023-12-10 19:03:41,259 INFO     Training average loss at step 107100: 0.067119\n",
      "2023-12-10 19:04:56,460 INFO     Training average positive_sample_loss at step 107200: 0.068214\n",
      "2023-12-10 19:04:56,460 INFO     Training average negative_sample_loss at step 107200: 0.066135\n",
      "2023-12-10 19:04:56,460 INFO     Training average loss at step 107200: 0.067175\n",
      "2023-12-10 19:06:11,313 INFO     Training average positive_sample_loss at step 107300: 0.068149\n",
      "2023-12-10 19:06:11,313 INFO     Training average negative_sample_loss at step 107300: 0.067682\n",
      "2023-12-10 19:06:11,313 INFO     Training average loss at step 107300: 0.067915\n",
      "2023-12-10 19:07:26,342 INFO     Training average positive_sample_loss at step 107400: 0.068557\n",
      "2023-12-10 19:07:26,342 INFO     Training average negative_sample_loss at step 107400: 0.066576\n",
      "2023-12-10 19:07:26,343 INFO     Training average loss at step 107400: 0.067566\n",
      "2023-12-10 19:08:41,117 INFO     Training average positive_sample_loss at step 107500: 0.068819\n",
      "2023-12-10 19:08:41,117 INFO     Training average negative_sample_loss at step 107500: 0.067814\n",
      "2023-12-10 19:08:41,117 INFO     Training average loss at step 107500: 0.068317\n",
      "2023-12-10 19:10:01,776 INFO     Training average positive_sample_loss at step 107600: 0.068713\n",
      "2023-12-10 19:10:01,776 INFO     Training average negative_sample_loss at step 107600: 0.066450\n",
      "2023-12-10 19:10:01,776 INFO     Training average loss at step 107600: 0.067582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 19:11:32,257 INFO     Training average positive_sample_loss at step 107700: 0.067056\n",
      "2023-12-10 19:11:32,258 INFO     Training average negative_sample_loss at step 107700: 0.066917\n",
      "2023-12-10 19:11:32,258 INFO     Training average loss at step 107700: 0.066987\n",
      "2023-12-10 19:12:47,936 INFO     Training average positive_sample_loss at step 107800: 0.067389\n",
      "2023-12-10 19:12:47,937 INFO     Training average negative_sample_loss at step 107800: 0.065946\n",
      "2023-12-10 19:12:47,937 INFO     Training average loss at step 107800: 0.066668\n",
      "2023-12-10 19:14:04,500 INFO     Training average positive_sample_loss at step 107900: 0.067901\n",
      "2023-12-10 19:14:04,500 INFO     Training average negative_sample_loss at step 107900: 0.067229\n",
      "2023-12-10 19:14:04,500 INFO     Training average loss at step 107900: 0.067565\n",
      "2023-12-10 19:15:19,619 INFO     Training average positive_sample_loss at step 108000: 0.067871\n",
      "2023-12-10 19:15:19,619 INFO     Training average negative_sample_loss at step 108000: 0.066830\n",
      "2023-12-10 19:15:19,619 INFO     Training average loss at step 108000: 0.067351\n",
      "2023-12-10 19:16:34,887 INFO     Training average positive_sample_loss at step 108100: 0.067978\n",
      "2023-12-10 19:16:34,887 INFO     Training average negative_sample_loss at step 108100: 0.066138\n",
      "2023-12-10 19:16:34,887 INFO     Training average loss at step 108100: 0.067058\n",
      "2023-12-10 19:17:50,167 INFO     Training average positive_sample_loss at step 108200: 0.068242\n",
      "2023-12-10 19:17:50,167 INFO     Training average negative_sample_loss at step 108200: 0.066668\n",
      "2023-12-10 19:17:50,167 INFO     Training average loss at step 108200: 0.067455\n",
      "2023-12-10 19:19:05,178 INFO     Training average positive_sample_loss at step 108300: 0.068093\n",
      "2023-12-10 19:19:05,178 INFO     Training average negative_sample_loss at step 108300: 0.067545\n",
      "2023-12-10 19:19:05,178 INFO     Training average loss at step 108300: 0.067819\n",
      "2023-12-10 19:20:20,325 INFO     Training average positive_sample_loss at step 108400: 0.068648\n",
      "2023-12-10 19:20:20,325 INFO     Training average negative_sample_loss at step 108400: 0.067123\n",
      "2023-12-10 19:20:20,325 INFO     Training average loss at step 108400: 0.067885\n",
      "2023-12-10 19:21:35,407 INFO     Training average positive_sample_loss at step 108500: 0.068593\n",
      "2023-12-10 19:21:35,408 INFO     Training average negative_sample_loss at step 108500: 0.066270\n",
      "2023-12-10 19:21:35,408 INFO     Training average loss at step 108500: 0.067432\n",
      "2023-12-10 19:23:01,383 INFO     Training average positive_sample_loss at step 108600: 0.067827\n",
      "2023-12-10 19:23:01,383 INFO     Training average negative_sample_loss at step 108600: 0.067621\n",
      "2023-12-10 19:23:01,383 INFO     Training average loss at step 108600: 0.067724\n",
      "2023-12-10 19:24:16,966 INFO     Training average positive_sample_loss at step 108700: 0.066865\n",
      "2023-12-10 19:24:16,966 INFO     Training average negative_sample_loss at step 108700: 0.066001\n",
      "2023-12-10 19:24:16,966 INFO     Training average loss at step 108700: 0.066433\n",
      "2023-12-10 19:25:32,611 INFO     Training average positive_sample_loss at step 108800: 0.067768\n",
      "2023-12-10 19:25:32,611 INFO     Training average negative_sample_loss at step 108800: 0.066684\n",
      "2023-12-10 19:25:32,611 INFO     Training average loss at step 108800: 0.067226\n",
      "2023-12-10 19:26:48,818 INFO     Training average positive_sample_loss at step 108900: 0.067740\n",
      "2023-12-10 19:26:48,819 INFO     Training average negative_sample_loss at step 108900: 0.067399\n",
      "2023-12-10 19:26:48,819 INFO     Training average loss at step 108900: 0.067569\n",
      "2023-12-10 19:28:06,937 INFO     Training average positive_sample_loss at step 109000: 0.068178\n",
      "2023-12-10 19:28:06,937 INFO     Training average negative_sample_loss at step 109000: 0.067162\n",
      "2023-12-10 19:28:06,937 INFO     Training average loss at step 109000: 0.067670\n",
      "2023-12-10 19:29:23,871 INFO     Training average positive_sample_loss at step 109100: 0.068200\n",
      "2023-12-10 19:29:23,871 INFO     Training average negative_sample_loss at step 109100: 0.066145\n",
      "2023-12-10 19:29:23,871 INFO     Training average loss at step 109100: 0.067172\n",
      "2023-12-10 19:30:38,836 INFO     Training average positive_sample_loss at step 109200: 0.068789\n",
      "2023-12-10 19:30:38,836 INFO     Training average negative_sample_loss at step 109200: 0.066475\n",
      "2023-12-10 19:30:38,836 INFO     Training average loss at step 109200: 0.067632\n",
      "2023-12-10 19:31:53,817 INFO     Training average positive_sample_loss at step 109300: 0.068404\n",
      "2023-12-10 19:31:53,818 INFO     Training average negative_sample_loss at step 109300: 0.067062\n",
      "2023-12-10 19:31:53,818 INFO     Training average loss at step 109300: 0.067733\n",
      "2023-12-10 19:33:08,911 INFO     Training average positive_sample_loss at step 109400: 0.068420\n",
      "2023-12-10 19:33:08,912 INFO     Training average negative_sample_loss at step 109400: 0.066961\n",
      "2023-12-10 19:33:08,912 INFO     Training average loss at step 109400: 0.067691\n",
      "2023-12-10 19:34:24,078 INFO     Training average positive_sample_loss at step 109500: 0.068411\n",
      "2023-12-10 19:34:24,078 INFO     Training average negative_sample_loss at step 109500: 0.066755\n",
      "2023-12-10 19:34:24,078 INFO     Training average loss at step 109500: 0.067583\n",
      "2023-12-10 19:35:57,775 INFO     Training average positive_sample_loss at step 109600: 0.066897\n",
      "2023-12-10 19:35:57,775 INFO     Training average negative_sample_loss at step 109600: 0.066826\n",
      "2023-12-10 19:35:57,775 INFO     Training average loss at step 109600: 0.066861\n",
      "2023-12-10 19:37:13,810 INFO     Training average positive_sample_loss at step 109700: 0.067233\n",
      "2023-12-10 19:37:13,810 INFO     Training average negative_sample_loss at step 109700: 0.066591\n",
      "2023-12-10 19:37:13,810 INFO     Training average loss at step 109700: 0.066912\n",
      "2023-12-10 19:38:28,665 INFO     Training average positive_sample_loss at step 109800: 0.067841\n",
      "2023-12-10 19:38:28,666 INFO     Training average negative_sample_loss at step 109800: 0.066578\n",
      "2023-12-10 19:38:28,666 INFO     Training average loss at step 109800: 0.067209\n",
      "2023-12-10 19:39:43,580 INFO     Training average positive_sample_loss at step 109900: 0.067991\n",
      "2023-12-10 19:39:43,580 INFO     Training average negative_sample_loss at step 109900: 0.066011\n",
      "2023-12-10 19:39:43,580 INFO     Training average loss at step 109900: 0.067001\n",
      "2023-12-10 19:41:14,960 INFO     Training average positive_sample_loss at step 110000: 0.068321\n",
      "2023-12-10 19:41:14,960 INFO     Training average negative_sample_loss at step 110000: 0.066058\n",
      "2023-12-10 19:41:14,960 INFO     Training average loss at step 110000: 0.067190\n",
      "2023-12-10 19:41:14,960 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 19:41:15,761 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 19:41:50,729 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 19:42:24,931 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 19:42:59,359 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 19:43:32,595 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 19:44:06,451 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 19:44:40,486 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 19:44:47,909 INFO     Valid MRR at step 110000: 0.798940\n",
      "2023-12-10 19:44:47,909 INFO     Valid MR at step 110000: 39.628330\n",
      "2023-12-10 19:44:47,910 INFO     Valid HITS@1 at step 110000: 0.750840\n",
      "2023-12-10 19:44:47,910 INFO     Valid HITS@3 at step 110000: 0.828070\n",
      "2023-12-10 19:44:47,910 INFO     Valid HITS@10 at step 110000: 0.883270\n",
      "2023-12-10 19:45:49,734 INFO     Training average positive_sample_loss at step 110100: 0.068445\n",
      "2023-12-10 19:45:49,734 INFO     Training average negative_sample_loss at step 110100: 0.066892\n",
      "2023-12-10 19:45:49,734 INFO     Training average loss at step 110100: 0.067669\n",
      "2023-12-10 19:47:07,839 INFO     Training average positive_sample_loss at step 110200: 0.067802\n",
      "2023-12-10 19:47:07,839 INFO     Training average negative_sample_loss at step 110200: 0.066362\n",
      "2023-12-10 19:47:07,839 INFO     Training average loss at step 110200: 0.067082\n",
      "2023-12-10 19:48:22,047 INFO     Training average positive_sample_loss at step 110300: 0.068721\n",
      "2023-12-10 19:48:22,047 INFO     Training average negative_sample_loss at step 110300: 0.066989\n",
      "2023-12-10 19:48:22,047 INFO     Training average loss at step 110300: 0.067855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 19:49:40,976 INFO     Training average positive_sample_loss at step 110400: 0.068553\n",
      "2023-12-10 19:49:40,976 INFO     Training average negative_sample_loss at step 110400: 0.067268\n",
      "2023-12-10 19:49:40,976 INFO     Training average loss at step 110400: 0.067911\n",
      "2023-12-10 19:51:15,354 INFO     Training average positive_sample_loss at step 110500: 0.067327\n",
      "2023-12-10 19:51:15,354 INFO     Training average negative_sample_loss at step 110500: 0.066430\n",
      "2023-12-10 19:51:15,354 INFO     Training average loss at step 110500: 0.066879\n",
      "2023-12-10 19:52:30,874 INFO     Training average positive_sample_loss at step 110600: 0.067542\n",
      "2023-12-10 19:52:30,874 INFO     Training average negative_sample_loss at step 110600: 0.067615\n",
      "2023-12-10 19:52:30,874 INFO     Training average loss at step 110600: 0.067579\n",
      "2023-12-10 19:53:49,262 INFO     Training average positive_sample_loss at step 110700: 0.067618\n",
      "2023-12-10 19:53:49,262 INFO     Training average negative_sample_loss at step 110700: 0.066918\n",
      "2023-12-10 19:53:49,263 INFO     Training average loss at step 110700: 0.067268\n",
      "2023-12-10 19:55:08,392 INFO     Training average positive_sample_loss at step 110800: 0.067829\n",
      "2023-12-10 19:55:08,392 INFO     Training average negative_sample_loss at step 110800: 0.066448\n",
      "2023-12-10 19:55:08,392 INFO     Training average loss at step 110800: 0.067138\n",
      "2023-12-10 19:56:25,311 INFO     Training average positive_sample_loss at step 110900: 0.067884\n",
      "2023-12-10 19:56:25,311 INFO     Training average negative_sample_loss at step 110900: 0.066707\n",
      "2023-12-10 19:56:25,311 INFO     Training average loss at step 110900: 0.067296\n",
      "2023-12-10 19:57:40,120 INFO     Training average positive_sample_loss at step 111000: 0.068502\n",
      "2023-12-10 19:57:40,121 INFO     Training average negative_sample_loss at step 111000: 0.066824\n",
      "2023-12-10 19:57:40,121 INFO     Training average loss at step 111000: 0.067663\n",
      "2023-12-10 19:58:55,761 INFO     Training average positive_sample_loss at step 111100: 0.068408\n",
      "2023-12-10 19:58:55,761 INFO     Training average negative_sample_loss at step 111100: 0.067109\n",
      "2023-12-10 19:58:55,762 INFO     Training average loss at step 111100: 0.067759\n",
      "2023-12-10 20:00:11,497 INFO     Training average positive_sample_loss at step 111200: 0.068376\n",
      "2023-12-10 20:00:11,497 INFO     Training average negative_sample_loss at step 111200: 0.066818\n",
      "2023-12-10 20:00:11,497 INFO     Training average loss at step 111200: 0.067597\n",
      "2023-12-10 20:01:27,193 INFO     Training average positive_sample_loss at step 111300: 0.068529\n",
      "2023-12-10 20:01:27,193 INFO     Training average negative_sample_loss at step 111300: 0.066613\n",
      "2023-12-10 20:01:27,193 INFO     Training average loss at step 111300: 0.067571\n",
      "2023-12-10 20:02:52,152 INFO     Training average positive_sample_loss at step 111400: 0.068771\n",
      "2023-12-10 20:02:52,152 INFO     Training average negative_sample_loss at step 111400: 0.067936\n",
      "2023-12-10 20:02:52,152 INFO     Training average loss at step 111400: 0.068354\n",
      "2023-12-10 20:04:09,600 INFO     Training average positive_sample_loss at step 111500: 0.067205\n",
      "2023-12-10 20:04:09,600 INFO     Training average negative_sample_loss at step 111500: 0.067364\n",
      "2023-12-10 20:04:09,600 INFO     Training average loss at step 111500: 0.067285\n",
      "2023-12-10 20:05:24,782 INFO     Training average positive_sample_loss at step 111600: 0.067023\n",
      "2023-12-10 20:05:24,783 INFO     Training average negative_sample_loss at step 111600: 0.065968\n",
      "2023-12-10 20:05:24,783 INFO     Training average loss at step 111600: 0.066496\n",
      "2023-12-10 20:06:43,061 INFO     Training average positive_sample_loss at step 111700: 0.067607\n",
      "2023-12-10 20:06:43,061 INFO     Training average negative_sample_loss at step 111700: 0.066066\n",
      "2023-12-10 20:06:43,061 INFO     Training average loss at step 111700: 0.066837\n",
      "2023-12-10 20:07:58,099 INFO     Training average positive_sample_loss at step 111800: 0.067918\n",
      "2023-12-10 20:07:58,099 INFO     Training average negative_sample_loss at step 111800: 0.066823\n",
      "2023-12-10 20:07:58,099 INFO     Training average loss at step 111800: 0.067370\n",
      "2023-12-10 20:09:12,910 INFO     Training average positive_sample_loss at step 111900: 0.068426\n",
      "2023-12-10 20:09:12,910 INFO     Training average negative_sample_loss at step 111900: 0.067358\n",
      "2023-12-10 20:09:12,910 INFO     Training average loss at step 111900: 0.067892\n",
      "2023-12-10 20:10:28,812 INFO     Training average positive_sample_loss at step 112000: 0.068518\n",
      "2023-12-10 20:10:28,812 INFO     Training average negative_sample_loss at step 112000: 0.066619\n",
      "2023-12-10 20:10:28,812 INFO     Training average loss at step 112000: 0.067569\n",
      "2023-12-10 20:11:44,263 INFO     Training average positive_sample_loss at step 112100: 0.068136\n",
      "2023-12-10 20:11:44,263 INFO     Training average negative_sample_loss at step 112100: 0.066695\n",
      "2023-12-10 20:11:44,263 INFO     Training average loss at step 112100: 0.067416\n",
      "2023-12-10 20:13:00,069 INFO     Training average positive_sample_loss at step 112200: 0.068433\n",
      "2023-12-10 20:13:00,069 INFO     Training average negative_sample_loss at step 112200: 0.067000\n",
      "2023-12-10 20:13:00,069 INFO     Training average loss at step 112200: 0.067716\n",
      "2023-12-10 20:14:14,317 INFO     Training average positive_sample_loss at step 112300: 0.068497\n",
      "2023-12-10 20:14:14,317 INFO     Training average negative_sample_loss at step 112300: 0.067664\n",
      "2023-12-10 20:14:14,317 INFO     Training average loss at step 112300: 0.068080\n",
      "2023-12-10 20:15:44,937 INFO     Training average positive_sample_loss at step 112400: 0.067291\n",
      "2023-12-10 20:15:44,938 INFO     Training average negative_sample_loss at step 112400: 0.066289\n",
      "2023-12-10 20:15:44,938 INFO     Training average loss at step 112400: 0.066790\n",
      "2023-12-10 20:16:59,982 INFO     Training average positive_sample_loss at step 112500: 0.067359\n",
      "2023-12-10 20:16:59,982 INFO     Training average negative_sample_loss at step 112500: 0.067336\n",
      "2023-12-10 20:16:59,982 INFO     Training average loss at step 112500: 0.067347\n",
      "2023-12-10 20:18:16,546 INFO     Training average positive_sample_loss at step 112600: 0.067566\n",
      "2023-12-10 20:18:16,547 INFO     Training average negative_sample_loss at step 112600: 0.066395\n",
      "2023-12-10 20:18:16,547 INFO     Training average loss at step 112600: 0.066981\n",
      "2023-12-10 20:19:34,496 INFO     Training average positive_sample_loss at step 112700: 0.067773\n",
      "2023-12-10 20:19:34,497 INFO     Training average negative_sample_loss at step 112700: 0.066841\n",
      "2023-12-10 20:19:34,497 INFO     Training average loss at step 112700: 0.067307\n",
      "2023-12-10 20:20:48,966 INFO     Training average positive_sample_loss at step 112800: 0.068109\n",
      "2023-12-10 20:20:48,966 INFO     Training average negative_sample_loss at step 112800: 0.066716\n",
      "2023-12-10 20:20:48,966 INFO     Training average loss at step 112800: 0.067412\n",
      "2023-12-10 20:22:04,272 INFO     Training average positive_sample_loss at step 112900: 0.068128\n",
      "2023-12-10 20:22:04,272 INFO     Training average negative_sample_loss at step 112900: 0.067027\n",
      "2023-12-10 20:22:04,272 INFO     Training average loss at step 112900: 0.067578\n",
      "2023-12-10 20:23:21,353 INFO     Training average positive_sample_loss at step 113000: 0.068376\n",
      "2023-12-10 20:23:21,354 INFO     Training average negative_sample_loss at step 113000: 0.067005\n",
      "2023-12-10 20:23:21,354 INFO     Training average loss at step 113000: 0.067690\n",
      "2023-12-10 20:24:36,378 INFO     Training average positive_sample_loss at step 113100: 0.068574\n",
      "2023-12-10 20:24:36,378 INFO     Training average negative_sample_loss at step 113100: 0.067184\n",
      "2023-12-10 20:24:36,378 INFO     Training average loss at step 113100: 0.067879\n",
      "2023-12-10 20:25:50,540 INFO     Training average positive_sample_loss at step 113200: 0.069144\n",
      "2023-12-10 20:25:50,541 INFO     Training average negative_sample_loss at step 113200: 0.067199\n",
      "2023-12-10 20:25:50,541 INFO     Training average loss at step 113200: 0.068171\n",
      "2023-12-10 20:27:15,085 INFO     Training average positive_sample_loss at step 113300: 0.068350\n",
      "2023-12-10 20:27:15,085 INFO     Training average negative_sample_loss at step 113300: 0.067135\n",
      "2023-12-10 20:27:15,085 INFO     Training average loss at step 113300: 0.067743\n",
      "2023-12-10 20:28:31,151 INFO     Training average positive_sample_loss at step 113400: 0.067008\n",
      "2023-12-10 20:28:31,151 INFO     Training average negative_sample_loss at step 113400: 0.066462\n",
      "2023-12-10 20:28:31,151 INFO     Training average loss at step 113400: 0.066735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 20:29:47,542 INFO     Training average positive_sample_loss at step 113500: 0.067349\n",
      "2023-12-10 20:29:47,542 INFO     Training average negative_sample_loss at step 113500: 0.067514\n",
      "2023-12-10 20:29:47,542 INFO     Training average loss at step 113500: 0.067432\n",
      "2023-12-10 20:31:03,662 INFO     Training average positive_sample_loss at step 113600: 0.068233\n",
      "2023-12-10 20:31:03,662 INFO     Training average negative_sample_loss at step 113600: 0.066825\n",
      "2023-12-10 20:31:03,662 INFO     Training average loss at step 113600: 0.067529\n",
      "2023-12-10 20:32:19,758 INFO     Training average positive_sample_loss at step 113700: 0.068170\n",
      "2023-12-10 20:32:19,759 INFO     Training average negative_sample_loss at step 113700: 0.066511\n",
      "2023-12-10 20:32:19,759 INFO     Training average loss at step 113700: 0.067340\n",
      "2023-12-10 20:33:35,522 INFO     Training average positive_sample_loss at step 113800: 0.067920\n",
      "2023-12-10 20:33:35,523 INFO     Training average negative_sample_loss at step 113800: 0.066451\n",
      "2023-12-10 20:33:35,523 INFO     Training average loss at step 113800: 0.067185\n",
      "2023-12-10 20:34:50,246 INFO     Training average positive_sample_loss at step 113900: 0.068238\n",
      "2023-12-10 20:34:50,246 INFO     Training average negative_sample_loss at step 113900: 0.066485\n",
      "2023-12-10 20:34:50,246 INFO     Training average loss at step 113900: 0.067361\n",
      "2023-12-10 20:36:07,465 INFO     Training average positive_sample_loss at step 114000: 0.068505\n",
      "2023-12-10 20:36:07,466 INFO     Training average negative_sample_loss at step 114000: 0.067463\n",
      "2023-12-10 20:36:07,466 INFO     Training average loss at step 114000: 0.067984\n",
      "2023-12-10 20:37:24,635 INFO     Training average positive_sample_loss at step 114100: 0.068517\n",
      "2023-12-10 20:37:24,635 INFO     Training average negative_sample_loss at step 114100: 0.066025\n",
      "2023-12-10 20:37:24,635 INFO     Training average loss at step 114100: 0.067271\n",
      "2023-12-10 20:38:39,694 INFO     Training average positive_sample_loss at step 114200: 0.068469\n",
      "2023-12-10 20:38:39,694 INFO     Training average negative_sample_loss at step 114200: 0.066040\n",
      "2023-12-10 20:38:39,694 INFO     Training average loss at step 114200: 0.067255\n",
      "2023-12-10 20:40:05,971 INFO     Training average positive_sample_loss at step 114300: 0.067028\n",
      "2023-12-10 20:40:05,971 INFO     Training average negative_sample_loss at step 114300: 0.066835\n",
      "2023-12-10 20:40:05,971 INFO     Training average loss at step 114300: 0.066931\n",
      "2023-12-10 20:41:22,671 INFO     Training average positive_sample_loss at step 114400: 0.067098\n",
      "2023-12-10 20:41:22,672 INFO     Training average negative_sample_loss at step 114400: 0.066607\n",
      "2023-12-10 20:41:22,672 INFO     Training average loss at step 114400: 0.066853\n",
      "2023-12-10 20:42:40,612 INFO     Training average positive_sample_loss at step 114500: 0.067664\n",
      "2023-12-10 20:42:40,612 INFO     Training average negative_sample_loss at step 114500: 0.066502\n",
      "2023-12-10 20:42:40,612 INFO     Training average loss at step 114500: 0.067083\n",
      "2023-12-10 20:43:57,375 INFO     Training average positive_sample_loss at step 114600: 0.067987\n",
      "2023-12-10 20:43:57,375 INFO     Training average negative_sample_loss at step 114600: 0.066975\n",
      "2023-12-10 20:43:57,375 INFO     Training average loss at step 114600: 0.067481\n",
      "2023-12-10 20:45:13,646 INFO     Training average positive_sample_loss at step 114700: 0.068135\n",
      "2023-12-10 20:45:13,646 INFO     Training average negative_sample_loss at step 114700: 0.066392\n",
      "2023-12-10 20:45:13,647 INFO     Training average loss at step 114700: 0.067264\n",
      "2023-12-10 20:46:28,634 INFO     Training average positive_sample_loss at step 114800: 0.068511\n",
      "2023-12-10 20:46:28,634 INFO     Training average negative_sample_loss at step 114800: 0.066994\n",
      "2023-12-10 20:46:28,634 INFO     Training average loss at step 114800: 0.067753\n",
      "2023-12-10 20:47:43,510 INFO     Training average positive_sample_loss at step 114900: 0.068512\n",
      "2023-12-10 20:47:43,510 INFO     Training average negative_sample_loss at step 114900: 0.066767\n",
      "2023-12-10 20:47:43,510 INFO     Training average loss at step 114900: 0.067640\n",
      "2023-12-10 20:48:57,969 INFO     Training average positive_sample_loss at step 115000: 0.068231\n",
      "2023-12-10 20:48:57,970 INFO     Training average negative_sample_loss at step 115000: 0.067422\n",
      "2023-12-10 20:48:57,970 INFO     Training average loss at step 115000: 0.067826\n",
      "2023-12-10 20:50:12,645 INFO     Training average positive_sample_loss at step 115100: 0.068441\n",
      "2023-12-10 20:50:12,645 INFO     Training average negative_sample_loss at step 115100: 0.066635\n",
      "2023-12-10 20:50:12,645 INFO     Training average loss at step 115100: 0.067538\n",
      "2023-12-10 20:51:42,958 INFO     Training average positive_sample_loss at step 115200: 0.067895\n",
      "2023-12-10 20:51:42,958 INFO     Training average negative_sample_loss at step 115200: 0.066714\n",
      "2023-12-10 20:51:42,958 INFO     Training average loss at step 115200: 0.067305\n",
      "2023-12-10 20:52:58,485 INFO     Training average positive_sample_loss at step 115300: 0.067049\n",
      "2023-12-10 20:52:58,485 INFO     Training average negative_sample_loss at step 115300: 0.067170\n",
      "2023-12-10 20:52:58,485 INFO     Training average loss at step 115300: 0.067109\n",
      "2023-12-10 20:54:12,962 INFO     Training average positive_sample_loss at step 115400: 0.067458\n",
      "2023-12-10 20:54:12,963 INFO     Training average negative_sample_loss at step 115400: 0.066804\n",
      "2023-12-10 20:54:12,963 INFO     Training average loss at step 115400: 0.067131\n",
      "2023-12-10 20:55:28,164 INFO     Training average positive_sample_loss at step 115500: 0.068031\n",
      "2023-12-10 20:55:28,164 INFO     Training average negative_sample_loss at step 115500: 0.066584\n",
      "2023-12-10 20:55:28,164 INFO     Training average loss at step 115500: 0.067308\n",
      "2023-12-10 20:56:43,177 INFO     Training average positive_sample_loss at step 115600: 0.068211\n",
      "2023-12-10 20:56:43,177 INFO     Training average negative_sample_loss at step 115600: 0.066143\n",
      "2023-12-10 20:56:43,177 INFO     Training average loss at step 115600: 0.067177\n",
      "2023-12-10 20:57:59,957 INFO     Training average positive_sample_loss at step 115700: 0.067977\n",
      "2023-12-10 20:57:59,957 INFO     Training average negative_sample_loss at step 115700: 0.065807\n",
      "2023-12-10 20:57:59,957 INFO     Training average loss at step 115700: 0.066892\n",
      "2023-12-10 20:59:14,027 INFO     Training average positive_sample_loss at step 115800: 0.067865\n",
      "2023-12-10 20:59:14,027 INFO     Training average negative_sample_loss at step 115800: 0.066434\n",
      "2023-12-10 20:59:14,027 INFO     Training average loss at step 115800: 0.067149\n",
      "2023-12-10 21:00:29,376 INFO     Training average positive_sample_loss at step 115900: 0.068678\n",
      "2023-12-10 21:00:29,376 INFO     Training average negative_sample_loss at step 115900: 0.066823\n",
      "2023-12-10 21:00:29,376 INFO     Training average loss at step 115900: 0.067751\n",
      "2023-12-10 21:01:43,938 INFO     Training average positive_sample_loss at step 116000: 0.068425\n",
      "2023-12-10 21:01:43,938 INFO     Training average negative_sample_loss at step 116000: 0.066651\n",
      "2023-12-10 21:01:43,938 INFO     Training average loss at step 116000: 0.067538\n",
      "2023-12-10 21:02:59,414 INFO     Training average positive_sample_loss at step 116100: 0.068485\n",
      "2023-12-10 21:02:59,415 INFO     Training average negative_sample_loss at step 116100: 0.067685\n",
      "2023-12-10 21:02:59,415 INFO     Training average loss at step 116100: 0.068085\n",
      "2023-12-10 21:04:24,976 INFO     Training average positive_sample_loss at step 116200: 0.067117\n",
      "2023-12-10 21:04:24,976 INFO     Training average negative_sample_loss at step 116200: 0.066970\n",
      "2023-12-10 21:04:24,976 INFO     Training average loss at step 116200: 0.067044\n",
      "2023-12-10 21:05:42,939 INFO     Training average positive_sample_loss at step 116300: 0.067102\n",
      "2023-12-10 21:05:42,939 INFO     Training average negative_sample_loss at step 116300: 0.066619\n",
      "2023-12-10 21:05:42,940 INFO     Training average loss at step 116300: 0.066861\n",
      "2023-12-10 21:06:58,634 INFO     Training average positive_sample_loss at step 116400: 0.067671\n",
      "2023-12-10 21:06:58,634 INFO     Training average negative_sample_loss at step 116400: 0.066635\n",
      "2023-12-10 21:06:58,634 INFO     Training average loss at step 116400: 0.067153\n",
      "2023-12-10 21:08:13,673 INFO     Training average positive_sample_loss at step 116500: 0.067836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 21:08:13,673 INFO     Training average negative_sample_loss at step 116500: 0.066558\n",
      "2023-12-10 21:08:13,673 INFO     Training average loss at step 116500: 0.067197\n",
      "2023-12-10 21:09:30,432 INFO     Training average positive_sample_loss at step 116600: 0.068378\n",
      "2023-12-10 21:09:30,433 INFO     Training average negative_sample_loss at step 116600: 0.066710\n",
      "2023-12-10 21:09:30,433 INFO     Training average loss at step 116600: 0.067544\n",
      "2023-12-10 21:10:45,001 INFO     Training average positive_sample_loss at step 116700: 0.068182\n",
      "2023-12-10 21:10:45,001 INFO     Training average negative_sample_loss at step 116700: 0.066314\n",
      "2023-12-10 21:10:45,001 INFO     Training average loss at step 116700: 0.067248\n",
      "2023-12-10 21:11:58,850 INFO     Training average positive_sample_loss at step 116800: 0.068538\n",
      "2023-12-10 21:11:58,851 INFO     Training average negative_sample_loss at step 116800: 0.066100\n",
      "2023-12-10 21:11:58,851 INFO     Training average loss at step 116800: 0.067319\n",
      "2023-12-10 21:13:14,182 INFO     Training average positive_sample_loss at step 116900: 0.068333\n",
      "2023-12-10 21:13:14,182 INFO     Training average negative_sample_loss at step 116900: 0.066521\n",
      "2023-12-10 21:13:14,182 INFO     Training average loss at step 116900: 0.067427\n",
      "2023-12-10 21:14:31,300 INFO     Training average positive_sample_loss at step 117000: 0.068544\n",
      "2023-12-10 21:14:31,300 INFO     Training average negative_sample_loss at step 117000: 0.066453\n",
      "2023-12-10 21:14:31,300 INFO     Training average loss at step 117000: 0.067498\n",
      "2023-12-10 21:15:55,739 INFO     Training average positive_sample_loss at step 117100: 0.067581\n",
      "2023-12-10 21:15:55,739 INFO     Training average negative_sample_loss at step 117100: 0.066611\n",
      "2023-12-10 21:15:55,739 INFO     Training average loss at step 117100: 0.067096\n",
      "2023-12-10 21:17:11,712 INFO     Training average positive_sample_loss at step 117200: 0.067123\n",
      "2023-12-10 21:17:11,713 INFO     Training average negative_sample_loss at step 117200: 0.066036\n",
      "2023-12-10 21:17:11,713 INFO     Training average loss at step 117200: 0.066579\n",
      "2023-12-10 21:18:28,865 INFO     Training average positive_sample_loss at step 117300: 0.067112\n",
      "2023-12-10 21:18:28,865 INFO     Training average negative_sample_loss at step 117300: 0.066366\n",
      "2023-12-10 21:18:28,865 INFO     Training average loss at step 117300: 0.066739\n",
      "2023-12-10 21:19:44,341 INFO     Training average positive_sample_loss at step 117400: 0.067642\n",
      "2023-12-10 21:19:44,342 INFO     Training average negative_sample_loss at step 117400: 0.066785\n",
      "2023-12-10 21:19:44,342 INFO     Training average loss at step 117400: 0.067214\n",
      "2023-12-10 21:20:59,590 INFO     Training average positive_sample_loss at step 117500: 0.068289\n",
      "2023-12-10 21:20:59,591 INFO     Training average negative_sample_loss at step 117500: 0.067502\n",
      "2023-12-10 21:20:59,591 INFO     Training average loss at step 117500: 0.067895\n",
      "2023-12-10 21:22:17,530 INFO     Training average positive_sample_loss at step 117600: 0.068209\n",
      "2023-12-10 21:22:17,530 INFO     Training average negative_sample_loss at step 117600: 0.067106\n",
      "2023-12-10 21:22:17,530 INFO     Training average loss at step 117600: 0.067658\n",
      "2023-12-10 21:23:36,443 INFO     Training average positive_sample_loss at step 117700: 0.068338\n",
      "2023-12-10 21:23:36,444 INFO     Training average negative_sample_loss at step 117700: 0.066926\n",
      "2023-12-10 21:23:36,444 INFO     Training average loss at step 117700: 0.067632\n",
      "2023-12-10 21:24:54,012 INFO     Training average positive_sample_loss at step 117800: 0.068468\n",
      "2023-12-10 21:24:54,013 INFO     Training average negative_sample_loss at step 117800: 0.066690\n",
      "2023-12-10 21:24:54,013 INFO     Training average loss at step 117800: 0.067579\n",
      "2023-12-10 21:26:14,277 INFO     Training average positive_sample_loss at step 117900: 0.068743\n",
      "2023-12-10 21:26:14,278 INFO     Training average negative_sample_loss at step 117900: 0.068196\n",
      "2023-12-10 21:26:14,278 INFO     Training average loss at step 117900: 0.068470\n",
      "2023-12-10 21:27:39,476 INFO     Training average positive_sample_loss at step 118000: 0.068468\n",
      "2023-12-10 21:27:39,477 INFO     Training average negative_sample_loss at step 118000: 0.067199\n",
      "2023-12-10 21:27:39,477 INFO     Training average loss at step 118000: 0.067834\n",
      "2023-12-10 21:28:58,879 INFO     Training average positive_sample_loss at step 118100: 0.066475\n",
      "2023-12-10 21:28:58,879 INFO     Training average negative_sample_loss at step 118100: 0.065709\n",
      "2023-12-10 21:28:58,879 INFO     Training average loss at step 118100: 0.066092\n",
      "2023-12-10 21:30:17,582 INFO     Training average positive_sample_loss at step 118200: 0.067390\n",
      "2023-12-10 21:30:17,583 INFO     Training average negative_sample_loss at step 118200: 0.066436\n",
      "2023-12-10 21:30:17,583 INFO     Training average loss at step 118200: 0.066913\n",
      "2023-12-10 21:31:35,124 INFO     Training average positive_sample_loss at step 118300: 0.067951\n",
      "2023-12-10 21:31:35,125 INFO     Training average negative_sample_loss at step 118300: 0.066018\n",
      "2023-12-10 21:31:35,125 INFO     Training average loss at step 118300: 0.066984\n",
      "2023-12-10 21:32:54,746 INFO     Training average positive_sample_loss at step 118400: 0.068189\n",
      "2023-12-10 21:32:54,746 INFO     Training average negative_sample_loss at step 118400: 0.066498\n",
      "2023-12-10 21:32:54,746 INFO     Training average loss at step 118400: 0.067343\n",
      "2023-12-10 21:34:12,344 INFO     Training average positive_sample_loss at step 118500: 0.067868\n",
      "2023-12-10 21:34:12,344 INFO     Training average negative_sample_loss at step 118500: 0.066063\n",
      "2023-12-10 21:34:12,344 INFO     Training average loss at step 118500: 0.066965\n",
      "2023-12-10 21:35:30,327 INFO     Training average positive_sample_loss at step 118600: 0.068489\n",
      "2023-12-10 21:35:30,327 INFO     Training average negative_sample_loss at step 118600: 0.067460\n",
      "2023-12-10 21:35:30,327 INFO     Training average loss at step 118600: 0.067975\n",
      "2023-12-10 21:36:48,036 INFO     Training average positive_sample_loss at step 118700: 0.067990\n",
      "2023-12-10 21:36:48,036 INFO     Training average negative_sample_loss at step 118700: 0.066970\n",
      "2023-12-10 21:36:48,036 INFO     Training average loss at step 118700: 0.067480\n",
      "2023-12-10 21:38:06,339 INFO     Training average positive_sample_loss at step 118800: 0.068435\n",
      "2023-12-10 21:38:06,339 INFO     Training average negative_sample_loss at step 118800: 0.066586\n",
      "2023-12-10 21:38:06,339 INFO     Training average loss at step 118800: 0.067510\n",
      "2023-12-10 21:39:23,944 INFO     Training average positive_sample_loss at step 118900: 0.068586\n",
      "2023-12-10 21:39:23,944 INFO     Training average negative_sample_loss at step 118900: 0.066578\n",
      "2023-12-10 21:39:23,944 INFO     Training average loss at step 118900: 0.067582\n",
      "2023-12-10 21:40:51,760 INFO     Training average positive_sample_loss at step 119000: 0.067126\n",
      "2023-12-10 21:40:51,760 INFO     Training average negative_sample_loss at step 119000: 0.066980\n",
      "2023-12-10 21:40:51,760 INFO     Training average loss at step 119000: 0.067053\n",
      "2023-12-10 21:42:10,800 INFO     Training average positive_sample_loss at step 119100: 0.067262\n",
      "2023-12-10 21:42:10,800 INFO     Training average negative_sample_loss at step 119100: 0.066421\n",
      "2023-12-10 21:42:10,800 INFO     Training average loss at step 119100: 0.066842\n",
      "2023-12-10 21:43:28,037 INFO     Training average positive_sample_loss at step 119200: 0.067913\n",
      "2023-12-10 21:43:28,037 INFO     Training average negative_sample_loss at step 119200: 0.067146\n",
      "2023-12-10 21:43:28,037 INFO     Training average loss at step 119200: 0.067529\n",
      "2023-12-10 21:44:46,325 INFO     Training average positive_sample_loss at step 119300: 0.067899\n",
      "2023-12-10 21:44:46,325 INFO     Training average negative_sample_loss at step 119300: 0.065795\n",
      "2023-12-10 21:44:46,325 INFO     Training average loss at step 119300: 0.066847\n",
      "2023-12-10 21:46:05,228 INFO     Training average positive_sample_loss at step 119400: 0.067999\n",
      "2023-12-10 21:46:05,228 INFO     Training average negative_sample_loss at step 119400: 0.067316\n",
      "2023-12-10 21:46:05,228 INFO     Training average loss at step 119400: 0.067658\n",
      "2023-12-10 21:47:25,718 INFO     Training average positive_sample_loss at step 119500: 0.067952\n",
      "2023-12-10 21:47:25,719 INFO     Training average negative_sample_loss at step 119500: 0.066501\n",
      "2023-12-10 21:47:25,719 INFO     Training average loss at step 119500: 0.067226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 21:48:43,812 INFO     Training average positive_sample_loss at step 119600: 0.068282\n",
      "2023-12-10 21:48:43,813 INFO     Training average negative_sample_loss at step 119600: 0.066558\n",
      "2023-12-10 21:48:43,813 INFO     Training average loss at step 119600: 0.067420\n",
      "2023-12-10 21:50:02,477 INFO     Training average positive_sample_loss at step 119700: 0.068952\n",
      "2023-12-10 21:50:02,477 INFO     Training average negative_sample_loss at step 119700: 0.066487\n",
      "2023-12-10 21:50:02,477 INFO     Training average loss at step 119700: 0.067720\n",
      "2023-12-10 21:51:18,971 INFO     Training average positive_sample_loss at step 119800: 0.068401\n",
      "2023-12-10 21:51:18,972 INFO     Training average negative_sample_loss at step 119800: 0.067230\n",
      "2023-12-10 21:51:18,972 INFO     Training average loss at step 119800: 0.067816\n",
      "2023-12-10 21:52:52,291 INFO     Training average positive_sample_loss at step 119900: 0.068296\n",
      "2023-12-10 21:52:52,292 INFO     Training average negative_sample_loss at step 119900: 0.067220\n",
      "2023-12-10 21:52:52,292 INFO     Training average loss at step 119900: 0.067758\n",
      "2023-12-10 21:54:23,910 INFO     Training average positive_sample_loss at step 120000: 0.066860\n",
      "2023-12-10 21:54:23,910 INFO     Training average negative_sample_loss at step 120000: 0.066728\n",
      "2023-12-10 21:54:23,911 INFO     Training average loss at step 120000: 0.066794\n",
      "2023-12-10 21:54:23,911 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-10 21:54:24,716 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-10 21:54:52,198 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-10 21:55:21,661 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-10 21:55:49,582 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-10 21:56:16,677 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-10 21:56:46,076 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-10 21:57:16,679 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-10 21:57:23,983 INFO     Valid MRR at step 120000: 0.798190\n",
      "2023-12-10 21:57:23,983 INFO     Valid MR at step 120000: 39.658790\n",
      "2023-12-10 21:57:23,983 INFO     Valid HITS@1 at step 120000: 0.749540\n",
      "2023-12-10 21:57:23,983 INFO     Valid HITS@3 at step 120000: 0.827710\n",
      "2023-12-10 21:57:23,983 INFO     Valid HITS@10 at step 120000: 0.883130\n",
      "2023-12-10 21:58:29,749 INFO     Training average positive_sample_loss at step 120100: 0.067628\n",
      "2023-12-10 21:58:29,749 INFO     Training average negative_sample_loss at step 120100: 0.067625\n",
      "2023-12-10 21:58:29,750 INFO     Training average loss at step 120100: 0.067627\n",
      "2023-12-10 21:59:50,389 INFO     Training average positive_sample_loss at step 120200: 0.067526\n",
      "2023-12-10 21:59:50,390 INFO     Training average negative_sample_loss at step 120200: 0.065669\n",
      "2023-12-10 21:59:50,390 INFO     Training average loss at step 120200: 0.066597\n",
      "2023-12-10 22:01:10,278 INFO     Training average positive_sample_loss at step 120300: 0.068118\n",
      "2023-12-10 22:01:10,278 INFO     Training average negative_sample_loss at step 120300: 0.066429\n",
      "2023-12-10 22:01:10,278 INFO     Training average loss at step 120300: 0.067273\n",
      "2023-12-10 22:02:27,381 INFO     Training average positive_sample_loss at step 120400: 0.068091\n",
      "2023-12-10 22:02:27,381 INFO     Training average negative_sample_loss at step 120400: 0.066217\n",
      "2023-12-10 22:02:27,381 INFO     Training average loss at step 120400: 0.067154\n",
      "2023-12-10 22:03:45,367 INFO     Training average positive_sample_loss at step 120500: 0.068400\n",
      "2023-12-10 22:03:45,367 INFO     Training average negative_sample_loss at step 120500: 0.066938\n",
      "2023-12-10 22:03:45,367 INFO     Training average loss at step 120500: 0.067669\n",
      "2023-12-10 22:05:02,139 INFO     Training average positive_sample_loss at step 120600: 0.068056\n",
      "2023-12-10 22:05:02,139 INFO     Training average negative_sample_loss at step 120600: 0.066755\n",
      "2023-12-10 22:05:02,139 INFO     Training average loss at step 120600: 0.067405\n",
      "2023-12-10 22:06:18,319 INFO     Training average positive_sample_loss at step 120700: 0.068378\n",
      "2023-12-10 22:06:18,320 INFO     Training average negative_sample_loss at step 120700: 0.067394\n",
      "2023-12-10 22:06:18,320 INFO     Training average loss at step 120700: 0.067886\n",
      "2023-12-10 22:07:34,601 INFO     Training average positive_sample_loss at step 120800: 0.068589\n",
      "2023-12-10 22:07:34,601 INFO     Training average negative_sample_loss at step 120800: 0.066666\n",
      "2023-12-10 22:07:34,602 INFO     Training average loss at step 120800: 0.067628\n",
      "2023-12-10 22:09:01,182 INFO     Training average positive_sample_loss at step 120900: 0.067470\n",
      "2023-12-10 22:09:01,182 INFO     Training average negative_sample_loss at step 120900: 0.067089\n",
      "2023-12-10 22:09:01,182 INFO     Training average loss at step 120900: 0.067279\n",
      "2023-12-10 22:10:18,692 INFO     Training average positive_sample_loss at step 121000: 0.067343\n",
      "2023-12-10 22:10:18,692 INFO     Training average negative_sample_loss at step 121000: 0.066505\n",
      "2023-12-10 22:10:18,692 INFO     Training average loss at step 121000: 0.066924\n",
      "2023-12-10 22:11:37,030 INFO     Training average positive_sample_loss at step 121100: 0.067503\n",
      "2023-12-10 22:11:37,030 INFO     Training average negative_sample_loss at step 121100: 0.066941\n",
      "2023-12-10 22:11:37,030 INFO     Training average loss at step 121100: 0.067222\n",
      "2023-12-10 22:12:54,465 INFO     Training average positive_sample_loss at step 121200: 0.067733\n",
      "2023-12-10 22:12:54,465 INFO     Training average negative_sample_loss at step 121200: 0.066462\n",
      "2023-12-10 22:12:54,465 INFO     Training average loss at step 121200: 0.067097\n",
      "2023-12-10 22:14:11,666 INFO     Training average positive_sample_loss at step 121300: 0.068327\n",
      "2023-12-10 22:14:11,666 INFO     Training average negative_sample_loss at step 121300: 0.066349\n",
      "2023-12-10 22:14:11,666 INFO     Training average loss at step 121300: 0.067338\n",
      "2023-12-10 22:15:29,432 INFO     Training average positive_sample_loss at step 121400: 0.067666\n",
      "2023-12-10 22:15:29,432 INFO     Training average negative_sample_loss at step 121400: 0.066470\n",
      "2023-12-10 22:15:29,432 INFO     Training average loss at step 121400: 0.067068\n",
      "2023-12-10 22:16:50,015 INFO     Training average positive_sample_loss at step 121500: 0.068426\n",
      "2023-12-10 22:16:50,015 INFO     Training average negative_sample_loss at step 121500: 0.065867\n",
      "2023-12-10 22:16:50,015 INFO     Training average loss at step 121500: 0.067147\n",
      "2023-12-10 22:18:07,676 INFO     Training average positive_sample_loss at step 121600: 0.068309\n",
      "2023-12-10 22:18:07,677 INFO     Training average negative_sample_loss at step 121600: 0.067092\n",
      "2023-12-10 22:18:07,677 INFO     Training average loss at step 121600: 0.067701\n",
      "2023-12-10 22:19:26,179 INFO     Training average positive_sample_loss at step 121700: 0.068452\n",
      "2023-12-10 22:19:26,180 INFO     Training average negative_sample_loss at step 121700: 0.067249\n",
      "2023-12-10 22:19:26,180 INFO     Training average loss at step 121700: 0.067851\n",
      "2023-12-10 22:20:58,288 INFO     Training average positive_sample_loss at step 121800: 0.067941\n",
      "2023-12-10 22:20:58,288 INFO     Training average negative_sample_loss at step 121800: 0.066978\n",
      "2023-12-10 22:20:58,288 INFO     Training average loss at step 121800: 0.067459\n",
      "2023-12-10 22:22:16,654 INFO     Training average positive_sample_loss at step 121900: 0.067275\n",
      "2023-12-10 22:22:16,654 INFO     Training average negative_sample_loss at step 121900: 0.067273\n",
      "2023-12-10 22:22:16,654 INFO     Training average loss at step 121900: 0.067274\n",
      "2023-12-10 22:23:35,675 INFO     Training average positive_sample_loss at step 122000: 0.067413\n",
      "2023-12-10 22:23:35,676 INFO     Training average negative_sample_loss at step 122000: 0.065995\n",
      "2023-12-10 22:23:35,676 INFO     Training average loss at step 122000: 0.066704\n",
      "2023-12-10 22:24:58,198 INFO     Training average positive_sample_loss at step 122100: 0.067938\n",
      "2023-12-10 22:24:58,199 INFO     Training average negative_sample_loss at step 122100: 0.066883\n",
      "2023-12-10 22:24:58,199 INFO     Training average loss at step 122100: 0.067411\n",
      "2023-12-10 22:26:16,743 INFO     Training average positive_sample_loss at step 122200: 0.067708\n",
      "2023-12-10 22:26:16,743 INFO     Training average negative_sample_loss at step 122200: 0.066598\n",
      "2023-12-10 22:26:16,743 INFO     Training average loss at step 122200: 0.067153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 22:27:35,696 INFO     Training average positive_sample_loss at step 122300: 0.068025\n",
      "2023-12-10 22:27:35,697 INFO     Training average negative_sample_loss at step 122300: 0.067496\n",
      "2023-12-10 22:27:35,697 INFO     Training average loss at step 122300: 0.067760\n",
      "2023-12-10 22:28:55,743 INFO     Training average positive_sample_loss at step 122400: 0.067990\n",
      "2023-12-10 22:28:55,744 INFO     Training average negative_sample_loss at step 122400: 0.067276\n",
      "2023-12-10 22:28:55,744 INFO     Training average loss at step 122400: 0.067633\n",
      "2023-12-10 22:30:14,930 INFO     Training average positive_sample_loss at step 122500: 0.068513\n",
      "2023-12-10 22:30:14,930 INFO     Training average negative_sample_loss at step 122500: 0.065884\n",
      "2023-12-10 22:30:14,930 INFO     Training average loss at step 122500: 0.067199\n",
      "2023-12-10 22:31:34,640 INFO     Training average positive_sample_loss at step 122600: 0.068440\n",
      "2023-12-10 22:31:34,641 INFO     Training average negative_sample_loss at step 122600: 0.066509\n",
      "2023-12-10 22:31:34,641 INFO     Training average loss at step 122600: 0.067474\n",
      "2023-12-10 22:32:53,518 INFO     Training average positive_sample_loss at step 122700: 0.068757\n",
      "2023-12-10 22:32:53,519 INFO     Training average negative_sample_loss at step 122700: 0.067165\n",
      "2023-12-10 22:32:53,519 INFO     Training average loss at step 122700: 0.067961\n",
      "2023-12-10 22:34:19,844 INFO     Training average positive_sample_loss at step 122800: 0.066996\n",
      "2023-12-10 22:34:19,844 INFO     Training average negative_sample_loss at step 122800: 0.066912\n",
      "2023-12-10 22:34:19,844 INFO     Training average loss at step 122800: 0.066954\n",
      "2023-12-10 22:35:37,003 INFO     Training average positive_sample_loss at step 122900: 0.067169\n",
      "2023-12-10 22:35:37,003 INFO     Training average negative_sample_loss at step 122900: 0.065944\n",
      "2023-12-10 22:35:37,003 INFO     Training average loss at step 122900: 0.066556\n",
      "2023-12-10 22:36:54,784 INFO     Training average positive_sample_loss at step 123000: 0.067438\n",
      "2023-12-10 22:36:54,785 INFO     Training average negative_sample_loss at step 123000: 0.066790\n",
      "2023-12-10 22:36:54,785 INFO     Training average loss at step 123000: 0.067114\n",
      "2023-12-10 22:38:12,048 INFO     Training average positive_sample_loss at step 123100: 0.068084\n",
      "2023-12-10 22:38:12,049 INFO     Training average negative_sample_loss at step 123100: 0.066695\n",
      "2023-12-10 22:38:12,049 INFO     Training average loss at step 123100: 0.067389\n",
      "2023-12-10 22:39:29,081 INFO     Training average positive_sample_loss at step 123200: 0.068046\n",
      "2023-12-10 22:39:29,081 INFO     Training average negative_sample_loss at step 123200: 0.066568\n",
      "2023-12-10 22:39:29,081 INFO     Training average loss at step 123200: 0.067307\n",
      "2023-12-10 22:40:46,714 INFO     Training average positive_sample_loss at step 123300: 0.068238\n",
      "2023-12-10 22:40:46,714 INFO     Training average negative_sample_loss at step 123300: 0.066360\n",
      "2023-12-10 22:40:46,714 INFO     Training average loss at step 123300: 0.067299\n",
      "2023-12-10 22:42:04,950 INFO     Training average positive_sample_loss at step 123400: 0.068631\n",
      "2023-12-10 22:42:04,950 INFO     Training average negative_sample_loss at step 123400: 0.067175\n",
      "2023-12-10 22:42:04,950 INFO     Training average loss at step 123400: 0.067903\n",
      "2023-12-10 22:43:23,525 INFO     Training average positive_sample_loss at step 123500: 0.068479\n",
      "2023-12-10 22:43:23,525 INFO     Training average negative_sample_loss at step 123500: 0.066038\n",
      "2023-12-10 22:43:23,525 INFO     Training average loss at step 123500: 0.067258\n",
      "2023-12-10 22:44:43,859 INFO     Training average positive_sample_loss at step 123600: 0.068486\n",
      "2023-12-10 22:44:43,860 INFO     Training average negative_sample_loss at step 123600: 0.066284\n",
      "2023-12-10 22:44:43,860 INFO     Training average loss at step 123600: 0.067385\n",
      "2023-12-10 22:46:12,284 INFO     Training average positive_sample_loss at step 123700: 0.067751\n",
      "2023-12-10 22:46:12,284 INFO     Training average negative_sample_loss at step 123700: 0.067194\n",
      "2023-12-10 22:46:12,284 INFO     Training average loss at step 123700: 0.067473\n",
      "2023-12-10 22:47:31,624 INFO     Training average positive_sample_loss at step 123800: 0.066979\n",
      "2023-12-10 22:47:31,624 INFO     Training average negative_sample_loss at step 123800: 0.065727\n",
      "2023-12-10 22:47:31,624 INFO     Training average loss at step 123800: 0.066353\n",
      "2023-12-10 22:48:48,468 INFO     Training average positive_sample_loss at step 123900: 0.067341\n",
      "2023-12-10 22:48:48,469 INFO     Training average negative_sample_loss at step 123900: 0.065966\n",
      "2023-12-10 22:48:48,469 INFO     Training average loss at step 123900: 0.066654\n",
      "2023-12-10 22:50:06,448 INFO     Training average positive_sample_loss at step 124000: 0.067544\n",
      "2023-12-10 22:50:06,448 INFO     Training average negative_sample_loss at step 124000: 0.067350\n",
      "2023-12-10 22:50:06,448 INFO     Training average loss at step 124000: 0.067447\n",
      "2023-12-10 22:51:27,149 INFO     Training average positive_sample_loss at step 124100: 0.067901\n",
      "2023-12-10 22:51:27,149 INFO     Training average negative_sample_loss at step 124100: 0.065772\n",
      "2023-12-10 22:51:27,149 INFO     Training average loss at step 124100: 0.066837\n",
      "2023-12-10 22:52:44,940 INFO     Training average positive_sample_loss at step 124200: 0.067988\n",
      "2023-12-10 22:52:44,940 INFO     Training average negative_sample_loss at step 124200: 0.066589\n",
      "2023-12-10 22:52:44,940 INFO     Training average loss at step 124200: 0.067288\n",
      "2023-12-10 22:54:06,258 INFO     Training average positive_sample_loss at step 124300: 0.067680\n",
      "2023-12-10 22:54:06,258 INFO     Training average negative_sample_loss at step 124300: 0.065372\n",
      "2023-12-10 22:54:06,258 INFO     Training average loss at step 124300: 0.066526\n",
      "2023-12-10 22:55:25,908 INFO     Training average positive_sample_loss at step 124400: 0.068031\n",
      "2023-12-10 22:55:25,909 INFO     Training average negative_sample_loss at step 124400: 0.066627\n",
      "2023-12-10 22:55:25,909 INFO     Training average loss at step 124400: 0.067329\n",
      "2023-12-10 22:56:41,498 INFO     Training average positive_sample_loss at step 124500: 0.068398\n",
      "2023-12-10 22:56:41,498 INFO     Training average negative_sample_loss at step 124500: 0.067249\n",
      "2023-12-10 22:56:41,498 INFO     Training average loss at step 124500: 0.067823\n",
      "2023-12-10 22:57:59,952 INFO     Training average positive_sample_loss at step 124600: 0.068753\n",
      "2023-12-10 22:57:59,952 INFO     Training average negative_sample_loss at step 124600: 0.066943\n",
      "2023-12-10 22:57:59,952 INFO     Training average loss at step 124600: 0.067848\n",
      "2023-12-10 22:59:31,705 INFO     Training average positive_sample_loss at step 124700: 0.066920\n",
      "2023-12-10 22:59:31,706 INFO     Training average negative_sample_loss at step 124700: 0.066782\n",
      "2023-12-10 22:59:31,706 INFO     Training average loss at step 124700: 0.066851\n",
      "2023-12-10 23:00:46,648 INFO     Training average positive_sample_loss at step 124800: 0.067072\n",
      "2023-12-10 23:00:46,648 INFO     Training average negative_sample_loss at step 124800: 0.066197\n",
      "2023-12-10 23:00:46,648 INFO     Training average loss at step 124800: 0.066634\n",
      "2023-12-10 23:02:05,225 INFO     Training average positive_sample_loss at step 124900: 0.067699\n",
      "2023-12-10 23:02:05,226 INFO     Training average negative_sample_loss at step 124900: 0.065672\n",
      "2023-12-10 23:02:05,226 INFO     Training average loss at step 124900: 0.066685\n",
      "2023-12-10 23:03:21,905 INFO     Training average positive_sample_loss at step 125000: 0.067866\n",
      "2023-12-10 23:03:21,906 INFO     Training average negative_sample_loss at step 125000: 0.066170\n",
      "2023-12-10 23:03:21,906 INFO     Training average loss at step 125000: 0.067018\n",
      "2023-12-10 23:04:41,425 INFO     Training average positive_sample_loss at step 125100: 0.068017\n",
      "2023-12-10 23:04:41,425 INFO     Training average negative_sample_loss at step 125100: 0.067656\n",
      "2023-12-10 23:04:41,425 INFO     Training average loss at step 125100: 0.067836\n",
      "2023-12-10 23:06:00,068 INFO     Training average positive_sample_loss at step 125200: 0.067886\n",
      "2023-12-10 23:06:00,069 INFO     Training average negative_sample_loss at step 125200: 0.066554\n",
      "2023-12-10 23:06:00,069 INFO     Training average loss at step 125200: 0.067220\n",
      "2023-12-10 23:07:22,227 INFO     Training average positive_sample_loss at step 125300: 0.068423\n",
      "2023-12-10 23:07:22,228 INFO     Training average negative_sample_loss at step 125300: 0.067015\n",
      "2023-12-10 23:07:22,228 INFO     Training average loss at step 125300: 0.067719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 23:08:41,842 INFO     Training average positive_sample_loss at step 125400: 0.068418\n",
      "2023-12-10 23:08:41,842 INFO     Training average negative_sample_loss at step 125400: 0.066643\n",
      "2023-12-10 23:08:41,842 INFO     Training average loss at step 125400: 0.067530\n",
      "2023-12-10 23:10:00,141 INFO     Training average positive_sample_loss at step 125500: 0.068511\n",
      "2023-12-10 23:10:00,142 INFO     Training average negative_sample_loss at step 125500: 0.067120\n",
      "2023-12-10 23:10:00,142 INFO     Training average loss at step 125500: 0.067815\n",
      "2023-12-10 23:11:33,333 INFO     Training average positive_sample_loss at step 125600: 0.067630\n",
      "2023-12-10 23:11:33,334 INFO     Training average negative_sample_loss at step 125600: 0.066435\n",
      "2023-12-10 23:11:33,334 INFO     Training average loss at step 125600: 0.067032\n",
      "2023-12-10 23:12:52,401 INFO     Training average positive_sample_loss at step 125700: 0.067220\n",
      "2023-12-10 23:12:52,401 INFO     Training average negative_sample_loss at step 125700: 0.066318\n",
      "2023-12-10 23:12:52,401 INFO     Training average loss at step 125700: 0.066769\n",
      "2023-12-10 23:14:10,824 INFO     Training average positive_sample_loss at step 125800: 0.067643\n",
      "2023-12-10 23:14:10,825 INFO     Training average negative_sample_loss at step 125800: 0.066652\n",
      "2023-12-10 23:14:10,825 INFO     Training average loss at step 125800: 0.067148\n",
      "2023-12-10 23:15:29,847 INFO     Training average positive_sample_loss at step 125900: 0.067849\n",
      "2023-12-10 23:15:29,847 INFO     Training average negative_sample_loss at step 125900: 0.066048\n",
      "2023-12-10 23:15:29,847 INFO     Training average loss at step 125900: 0.066949\n",
      "2023-12-10 23:16:48,888 INFO     Training average positive_sample_loss at step 126000: 0.067911\n",
      "2023-12-10 23:16:48,888 INFO     Training average negative_sample_loss at step 126000: 0.066613\n",
      "2023-12-10 23:16:48,888 INFO     Training average loss at step 126000: 0.067262\n",
      "2023-12-10 23:18:05,930 INFO     Training average positive_sample_loss at step 126100: 0.067990\n",
      "2023-12-10 23:18:05,930 INFO     Training average negative_sample_loss at step 126100: 0.066409\n",
      "2023-12-10 23:18:05,930 INFO     Training average loss at step 126100: 0.067200\n",
      "2023-12-10 23:19:25,531 INFO     Training average positive_sample_loss at step 126200: 0.068737\n",
      "2023-12-10 23:19:25,532 INFO     Training average negative_sample_loss at step 126200: 0.067045\n",
      "2023-12-10 23:19:25,532 INFO     Training average loss at step 126200: 0.067891\n",
      "2023-12-10 23:20:44,516 INFO     Training average positive_sample_loss at step 126300: 0.068374\n",
      "2023-12-10 23:20:44,516 INFO     Training average negative_sample_loss at step 126300: 0.067136\n",
      "2023-12-10 23:20:44,516 INFO     Training average loss at step 126300: 0.067755\n",
      "2023-12-10 23:22:02,389 INFO     Training average positive_sample_loss at step 126400: 0.068152\n",
      "2023-12-10 23:22:02,389 INFO     Training average negative_sample_loss at step 126400: 0.066687\n",
      "2023-12-10 23:22:02,389 INFO     Training average loss at step 126400: 0.067420\n",
      "2023-12-10 23:23:35,961 INFO     Training average positive_sample_loss at step 126500: 0.068323\n",
      "2023-12-10 23:23:35,962 INFO     Training average negative_sample_loss at step 126500: 0.066740\n",
      "2023-12-10 23:23:35,962 INFO     Training average loss at step 126500: 0.067532\n",
      "2023-12-10 23:24:52,805 INFO     Training average positive_sample_loss at step 126600: 0.066641\n",
      "2023-12-10 23:24:52,806 INFO     Training average negative_sample_loss at step 126600: 0.066692\n",
      "2023-12-10 23:24:52,806 INFO     Training average loss at step 126600: 0.066666\n",
      "2023-12-10 23:26:08,987 INFO     Training average positive_sample_loss at step 126700: 0.067553\n",
      "2023-12-10 23:26:08,988 INFO     Training average negative_sample_loss at step 126700: 0.066626\n",
      "2023-12-10 23:26:08,988 INFO     Training average loss at step 126700: 0.067090\n",
      "2023-12-10 23:27:25,369 INFO     Training average positive_sample_loss at step 126800: 0.067567\n",
      "2023-12-10 23:27:25,370 INFO     Training average negative_sample_loss at step 126800: 0.066304\n",
      "2023-12-10 23:27:25,370 INFO     Training average loss at step 126800: 0.066935\n",
      "2023-12-10 23:28:42,439 INFO     Training average positive_sample_loss at step 126900: 0.068016\n",
      "2023-12-10 23:28:42,440 INFO     Training average negative_sample_loss at step 126900: 0.065958\n",
      "2023-12-10 23:28:42,440 INFO     Training average loss at step 126900: 0.066987\n",
      "2023-12-10 23:30:00,541 INFO     Training average positive_sample_loss at step 127000: 0.067949\n",
      "2023-12-10 23:30:00,541 INFO     Training average negative_sample_loss at step 127000: 0.066204\n",
      "2023-12-10 23:30:00,541 INFO     Training average loss at step 127000: 0.067077\n",
      "2023-12-10 23:31:17,170 INFO     Training average positive_sample_loss at step 127100: 0.068353\n",
      "2023-12-10 23:31:17,170 INFO     Training average negative_sample_loss at step 127100: 0.066073\n",
      "2023-12-10 23:31:17,171 INFO     Training average loss at step 127100: 0.067213\n",
      "2023-12-10 23:32:37,612 INFO     Training average positive_sample_loss at step 127200: 0.068092\n",
      "2023-12-10 23:32:37,612 INFO     Training average negative_sample_loss at step 127200: 0.066715\n",
      "2023-12-10 23:32:37,612 INFO     Training average loss at step 127200: 0.067404\n",
      "2023-12-10 23:33:57,349 INFO     Training average positive_sample_loss at step 127300: 0.068443\n",
      "2023-12-10 23:33:57,350 INFO     Training average negative_sample_loss at step 127300: 0.068265\n",
      "2023-12-10 23:33:57,350 INFO     Training average loss at step 127300: 0.068354\n",
      "2023-12-10 23:35:17,016 INFO     Training average positive_sample_loss at step 127400: 0.068796\n",
      "2023-12-10 23:35:17,017 INFO     Training average negative_sample_loss at step 127400: 0.066563\n",
      "2023-12-10 23:35:17,017 INFO     Training average loss at step 127400: 0.067680\n",
      "2023-12-10 23:36:42,603 INFO     Training average positive_sample_loss at step 127500: 0.067431\n",
      "2023-12-10 23:36:42,603 INFO     Training average negative_sample_loss at step 127500: 0.067349\n",
      "2023-12-10 23:36:42,603 INFO     Training average loss at step 127500: 0.067390\n",
      "2023-12-10 23:37:58,805 INFO     Training average positive_sample_loss at step 127600: 0.067339\n",
      "2023-12-10 23:37:58,805 INFO     Training average negative_sample_loss at step 127600: 0.066898\n",
      "2023-12-10 23:37:58,805 INFO     Training average loss at step 127600: 0.067118\n",
      "2023-12-10 23:39:16,192 INFO     Training average positive_sample_loss at step 127700: 0.067433\n",
      "2023-12-10 23:39:16,193 INFO     Training average negative_sample_loss at step 127700: 0.065659\n",
      "2023-12-10 23:39:16,193 INFO     Training average loss at step 127700: 0.066546\n",
      "2023-12-10 23:40:34,017 INFO     Training average positive_sample_loss at step 127800: 0.067746\n",
      "2023-12-10 23:40:34,018 INFO     Training average negative_sample_loss at step 127800: 0.066475\n",
      "2023-12-10 23:40:34,018 INFO     Training average loss at step 127800: 0.067111\n",
      "2023-12-10 23:41:52,228 INFO     Training average positive_sample_loss at step 127900: 0.067980\n",
      "2023-12-10 23:41:52,228 INFO     Training average negative_sample_loss at step 127900: 0.066659\n",
      "2023-12-10 23:41:52,228 INFO     Training average loss at step 127900: 0.067320\n",
      "2023-12-10 23:43:11,084 INFO     Training average positive_sample_loss at step 128000: 0.068258\n",
      "2023-12-10 23:43:11,085 INFO     Training average negative_sample_loss at step 128000: 0.066320\n",
      "2023-12-10 23:43:11,085 INFO     Training average loss at step 128000: 0.067289\n",
      "2023-12-10 23:44:28,404 INFO     Training average positive_sample_loss at step 128100: 0.068113\n",
      "2023-12-10 23:44:28,405 INFO     Training average negative_sample_loss at step 128100: 0.065794\n",
      "2023-12-10 23:44:28,405 INFO     Training average loss at step 128100: 0.066953\n",
      "2023-12-10 23:45:47,087 INFO     Training average positive_sample_loss at step 128200: 0.067911\n",
      "2023-12-10 23:45:47,088 INFO     Training average negative_sample_loss at step 128200: 0.067095\n",
      "2023-12-10 23:45:47,088 INFO     Training average loss at step 128200: 0.067503\n",
      "2023-12-10 23:47:05,286 INFO     Training average positive_sample_loss at step 128300: 0.068724\n",
      "2023-12-10 23:47:05,286 INFO     Training average negative_sample_loss at step 128300: 0.066529\n",
      "2023-12-10 23:47:05,287 INFO     Training average loss at step 128300: 0.067626\n",
      "2023-12-10 23:48:38,919 INFO     Training average positive_sample_loss at step 128400: 0.068227\n",
      "2023-12-10 23:48:38,919 INFO     Training average negative_sample_loss at step 128400: 0.066644\n",
      "2023-12-10 23:48:38,919 INFO     Training average loss at step 128400: 0.067435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10 23:49:57,108 INFO     Training average positive_sample_loss at step 128500: 0.066745\n",
      "2023-12-10 23:49:57,109 INFO     Training average negative_sample_loss at step 128500: 0.067027\n",
      "2023-12-10 23:49:57,109 INFO     Training average loss at step 128500: 0.066886\n",
      "2023-12-10 23:51:17,697 INFO     Training average positive_sample_loss at step 128600: 0.067369\n",
      "2023-12-10 23:51:17,697 INFO     Training average negative_sample_loss at step 128600: 0.066021\n",
      "2023-12-10 23:51:17,697 INFO     Training average loss at step 128600: 0.066695\n",
      "2023-12-10 23:52:37,673 INFO     Training average positive_sample_loss at step 128700: 0.067784\n",
      "2023-12-10 23:52:37,673 INFO     Training average negative_sample_loss at step 128700: 0.066915\n",
      "2023-12-10 23:52:37,673 INFO     Training average loss at step 128700: 0.067350\n",
      "2023-12-10 23:53:54,436 INFO     Training average positive_sample_loss at step 128800: 0.067668\n",
      "2023-12-10 23:53:54,436 INFO     Training average negative_sample_loss at step 128800: 0.066702\n",
      "2023-12-10 23:53:54,436 INFO     Training average loss at step 128800: 0.067185\n",
      "2023-12-10 23:55:10,607 INFO     Training average positive_sample_loss at step 128900: 0.068302\n",
      "2023-12-10 23:55:10,607 INFO     Training average negative_sample_loss at step 128900: 0.066710\n",
      "2023-12-10 23:55:10,607 INFO     Training average loss at step 128900: 0.067506\n",
      "2023-12-10 23:56:27,622 INFO     Training average positive_sample_loss at step 129000: 0.068232\n",
      "2023-12-10 23:56:27,622 INFO     Training average negative_sample_loss at step 129000: 0.065982\n",
      "2023-12-10 23:56:27,623 INFO     Training average loss at step 129000: 0.067107\n",
      "2023-12-10 23:57:48,145 INFO     Training average positive_sample_loss at step 129100: 0.068477\n",
      "2023-12-10 23:57:48,146 INFO     Training average negative_sample_loss at step 129100: 0.067137\n",
      "2023-12-10 23:57:48,146 INFO     Training average loss at step 129100: 0.067807\n",
      "2023-12-10 23:59:05,174 INFO     Training average positive_sample_loss at step 129200: 0.068321\n",
      "2023-12-10 23:59:05,174 INFO     Training average negative_sample_loss at step 129200: 0.066915\n",
      "2023-12-10 23:59:05,174 INFO     Training average loss at step 129200: 0.067618\n",
      "2023-12-11 00:00:27,292 INFO     Training average positive_sample_loss at step 129300: 0.068038\n",
      "2023-12-11 00:00:27,292 INFO     Training average negative_sample_loss at step 129300: 0.066964\n",
      "2023-12-11 00:00:27,292 INFO     Training average loss at step 129300: 0.067501\n",
      "2023-12-11 00:02:00,862 INFO     Training average positive_sample_loss at step 129400: 0.067295\n",
      "2023-12-11 00:02:00,863 INFO     Training average negative_sample_loss at step 129400: 0.066535\n",
      "2023-12-11 00:02:00,863 INFO     Training average loss at step 129400: 0.066915\n",
      "2023-12-11 00:03:20,374 INFO     Training average positive_sample_loss at step 129500: 0.067093\n",
      "2023-12-11 00:03:20,374 INFO     Training average negative_sample_loss at step 129500: 0.066074\n",
      "2023-12-11 00:03:20,374 INFO     Training average loss at step 129500: 0.066584\n",
      "2023-12-11 00:04:38,299 INFO     Training average positive_sample_loss at step 129600: 0.067421\n",
      "2023-12-11 00:04:38,300 INFO     Training average negative_sample_loss at step 129600: 0.066445\n",
      "2023-12-11 00:04:38,300 INFO     Training average loss at step 129600: 0.066933\n",
      "2023-12-11 00:05:56,117 INFO     Training average positive_sample_loss at step 129700: 0.067709\n",
      "2023-12-11 00:05:56,117 INFO     Training average negative_sample_loss at step 129700: 0.066483\n",
      "2023-12-11 00:05:56,117 INFO     Training average loss at step 129700: 0.067096\n",
      "2023-12-11 00:07:14,458 INFO     Training average positive_sample_loss at step 129800: 0.067918\n",
      "2023-12-11 00:07:14,459 INFO     Training average negative_sample_loss at step 129800: 0.066429\n",
      "2023-12-11 00:07:14,459 INFO     Training average loss at step 129800: 0.067173\n",
      "2023-12-11 00:08:31,953 INFO     Training average positive_sample_loss at step 129900: 0.068193\n",
      "2023-12-11 00:08:31,953 INFO     Training average negative_sample_loss at step 129900: 0.067158\n",
      "2023-12-11 00:08:31,953 INFO     Training average loss at step 129900: 0.067676\n",
      "2023-12-11 00:09:53,865 INFO     Training average positive_sample_loss at step 130000: 0.068252\n",
      "2023-12-11 00:09:53,865 INFO     Training average negative_sample_loss at step 130000: 0.065277\n",
      "2023-12-11 00:09:53,865 INFO     Training average loss at step 130000: 0.066765\n",
      "2023-12-11 00:09:53,865 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-11 00:09:54,764 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-11 00:10:24,724 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-11 00:10:52,376 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-11 00:11:21,102 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-11 00:11:50,283 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-11 00:12:19,760 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-11 00:12:49,760 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-11 00:12:56,584 INFO     Valid MRR at step 130000: 0.798202\n",
      "2023-12-11 00:12:56,585 INFO     Valid MR at step 130000: 39.539830\n",
      "2023-12-11 00:12:56,585 INFO     Valid HITS@1 at step 130000: 0.749650\n",
      "2023-12-11 00:12:56,585 INFO     Valid HITS@3 at step 130000: 0.827590\n",
      "2023-12-11 00:12:56,585 INFO     Valid HITS@10 at step 130000: 0.882820\n",
      "2023-12-11 00:13:59,739 INFO     Training average positive_sample_loss at step 130100: 0.068480\n",
      "2023-12-11 00:13:59,739 INFO     Training average negative_sample_loss at step 130100: 0.067518\n",
      "2023-12-11 00:13:59,739 INFO     Training average loss at step 130100: 0.067999\n",
      "2023-12-11 00:15:20,853 INFO     Training average positive_sample_loss at step 130200: 0.068632\n",
      "2023-12-11 00:15:20,853 INFO     Training average negative_sample_loss at step 130200: 0.066330\n",
      "2023-12-11 00:15:20,853 INFO     Training average loss at step 130200: 0.067481\n",
      "2023-12-11 00:16:48,507 INFO     Training average positive_sample_loss at step 130300: 0.067959\n",
      "2023-12-11 00:16:48,508 INFO     Training average negative_sample_loss at step 130300: 0.066311\n",
      "2023-12-11 00:16:48,508 INFO     Training average loss at step 130300: 0.067135\n",
      "2023-12-11 00:18:07,062 INFO     Training average positive_sample_loss at step 130400: 0.066969\n",
      "2023-12-11 00:18:07,063 INFO     Training average negative_sample_loss at step 130400: 0.066533\n",
      "2023-12-11 00:18:07,063 INFO     Training average loss at step 130400: 0.066751\n",
      "2023-12-11 00:19:24,932 INFO     Training average positive_sample_loss at step 130500: 0.067745\n",
      "2023-12-11 00:19:24,932 INFO     Training average negative_sample_loss at step 130500: 0.065936\n",
      "2023-12-11 00:19:24,932 INFO     Training average loss at step 130500: 0.066840\n",
      "2023-12-11 00:20:44,333 INFO     Training average positive_sample_loss at step 130600: 0.067360\n",
      "2023-12-11 00:20:44,333 INFO     Training average negative_sample_loss at step 130600: 0.065845\n",
      "2023-12-11 00:20:44,333 INFO     Training average loss at step 130600: 0.066602\n",
      "2023-12-11 00:22:02,773 INFO     Training average positive_sample_loss at step 130700: 0.067553\n",
      "2023-12-11 00:22:02,773 INFO     Training average negative_sample_loss at step 130700: 0.066488\n",
      "2023-12-11 00:22:02,773 INFO     Training average loss at step 130700: 0.067021\n",
      "2023-12-11 00:23:22,876 INFO     Training average positive_sample_loss at step 130800: 0.067791\n",
      "2023-12-11 00:23:22,876 INFO     Training average negative_sample_loss at step 130800: 0.065393\n",
      "2023-12-11 00:23:22,876 INFO     Training average loss at step 130800: 0.066592\n",
      "2023-12-11 00:24:42,052 INFO     Training average positive_sample_loss at step 130900: 0.068109\n",
      "2023-12-11 00:24:42,052 INFO     Training average negative_sample_loss at step 130900: 0.067368\n",
      "2023-12-11 00:24:42,052 INFO     Training average loss at step 130900: 0.067738\n",
      "2023-12-11 00:26:01,127 INFO     Training average positive_sample_loss at step 131000: 0.068292\n",
      "2023-12-11 00:26:01,127 INFO     Training average negative_sample_loss at step 131000: 0.066402\n",
      "2023-12-11 00:26:01,127 INFO     Training average loss at step 131000: 0.067347\n",
      "2023-12-11 00:27:19,541 INFO     Training average positive_sample_loss at step 131100: 0.068839\n",
      "2023-12-11 00:27:19,542 INFO     Training average negative_sample_loss at step 131100: 0.066905\n",
      "2023-12-11 00:27:19,542 INFO     Training average loss at step 131100: 0.067872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-11 00:28:37,291 INFO     Training average positive_sample_loss at step 131200: 0.068405\n",
      "2023-12-11 00:28:37,292 INFO     Training average negative_sample_loss at step 131200: 0.067076\n",
      "2023-12-11 00:28:37,292 INFO     Training average loss at step 131200: 0.067741\n",
      "2023-12-11 00:30:08,230 INFO     Training average positive_sample_loss at step 131300: 0.067051\n",
      "2023-12-11 00:30:08,230 INFO     Training average negative_sample_loss at step 131300: 0.066142\n",
      "2023-12-11 00:30:08,230 INFO     Training average loss at step 131300: 0.066596\n",
      "2023-12-11 00:31:27,010 INFO     Training average positive_sample_loss at step 131400: 0.066967\n",
      "2023-12-11 00:31:27,010 INFO     Training average negative_sample_loss at step 131400: 0.066091\n",
      "2023-12-11 00:31:27,010 INFO     Training average loss at step 131400: 0.066529\n",
      "2023-12-11 00:32:46,525 INFO     Training average positive_sample_loss at step 131500: 0.067445\n",
      "2023-12-11 00:32:46,526 INFO     Training average negative_sample_loss at step 131500: 0.066487\n",
      "2023-12-11 00:32:46,526 INFO     Training average loss at step 131500: 0.066966\n",
      "2023-12-11 00:34:05,321 INFO     Training average positive_sample_loss at step 131600: 0.067975\n",
      "2023-12-11 00:34:05,322 INFO     Training average negative_sample_loss at step 131600: 0.066479\n",
      "2023-12-11 00:34:05,322 INFO     Training average loss at step 131600: 0.067227\n",
      "2023-12-11 00:35:21,306 INFO     Training average positive_sample_loss at step 131700: 0.067764\n",
      "2023-12-11 00:35:21,306 INFO     Training average negative_sample_loss at step 131700: 0.067467\n",
      "2023-12-11 00:35:21,307 INFO     Training average loss at step 131700: 0.067615\n",
      "2023-12-11 00:36:38,462 INFO     Training average positive_sample_loss at step 131800: 0.068315\n",
      "2023-12-11 00:36:38,462 INFO     Training average negative_sample_loss at step 131800: 0.065740\n",
      "2023-12-11 00:36:38,462 INFO     Training average loss at step 131800: 0.067027\n",
      "2023-12-11 00:37:57,103 INFO     Training average positive_sample_loss at step 131900: 0.068135\n",
      "2023-12-11 00:37:57,104 INFO     Training average negative_sample_loss at step 131900: 0.066720\n",
      "2023-12-11 00:37:57,104 INFO     Training average loss at step 131900: 0.067428\n",
      "2023-12-11 00:39:14,366 INFO     Training average positive_sample_loss at step 132000: 0.068127\n",
      "2023-12-11 00:39:14,366 INFO     Training average negative_sample_loss at step 132000: 0.066807\n",
      "2023-12-11 00:39:14,366 INFO     Training average loss at step 132000: 0.067467\n",
      "2023-12-11 00:40:32,119 INFO     Training average positive_sample_loss at step 132100: 0.068572\n",
      "2023-12-11 00:40:32,119 INFO     Training average negative_sample_loss at step 132100: 0.065682\n",
      "2023-12-11 00:40:32,119 INFO     Training average loss at step 132100: 0.067127\n",
      "2023-12-11 00:41:59,074 INFO     Training average positive_sample_loss at step 132200: 0.067802\n",
      "2023-12-11 00:41:59,075 INFO     Training average negative_sample_loss at step 132200: 0.066364\n",
      "2023-12-11 00:41:59,075 INFO     Training average loss at step 132200: 0.067083\n",
      "2023-12-11 00:43:17,353 INFO     Training average positive_sample_loss at step 132300: 0.066818\n",
      "2023-12-11 00:43:17,353 INFO     Training average negative_sample_loss at step 132300: 0.066284\n",
      "2023-12-11 00:43:17,354 INFO     Training average loss at step 132300: 0.066551\n",
      "2023-12-11 00:44:35,876 INFO     Training average positive_sample_loss at step 132400: 0.067871\n",
      "2023-12-11 00:44:35,876 INFO     Training average negative_sample_loss at step 132400: 0.066565\n",
      "2023-12-11 00:44:35,876 INFO     Training average loss at step 132400: 0.067218\n",
      "2023-12-11 00:45:54,092 INFO     Training average positive_sample_loss at step 132500: 0.067286\n",
      "2023-12-11 00:45:54,092 INFO     Training average negative_sample_loss at step 132500: 0.066418\n",
      "2023-12-11 00:45:54,092 INFO     Training average loss at step 132500: 0.066852\n",
      "2023-12-11 00:47:12,557 INFO     Training average positive_sample_loss at step 132600: 0.067840\n",
      "2023-12-11 00:47:12,558 INFO     Training average negative_sample_loss at step 132600: 0.066911\n",
      "2023-12-11 00:47:12,558 INFO     Training average loss at step 132600: 0.067376\n",
      "2023-12-11 00:48:29,424 INFO     Training average positive_sample_loss at step 132700: 0.068289\n",
      "2023-12-11 00:48:29,424 INFO     Training average negative_sample_loss at step 132700: 0.067189\n",
      "2023-12-11 00:48:29,424 INFO     Training average loss at step 132700: 0.067739\n",
      "2023-12-11 00:49:44,794 INFO     Training average positive_sample_loss at step 132800: 0.068229\n",
      "2023-12-11 00:49:44,794 INFO     Training average negative_sample_loss at step 132800: 0.067121\n",
      "2023-12-11 00:49:44,794 INFO     Training average loss at step 132800: 0.067675\n",
      "2023-12-11 00:51:05,094 INFO     Training average positive_sample_loss at step 132900: 0.068443\n",
      "2023-12-11 00:51:05,095 INFO     Training average negative_sample_loss at step 132900: 0.066215\n",
      "2023-12-11 00:51:05,095 INFO     Training average loss at step 132900: 0.067329\n",
      "2023-12-11 00:52:22,407 INFO     Training average positive_sample_loss at step 133000: 0.068548\n",
      "2023-12-11 00:52:22,407 INFO     Training average negative_sample_loss at step 133000: 0.066544\n",
      "2023-12-11 00:52:22,407 INFO     Training average loss at step 133000: 0.067546\n",
      "2023-12-11 00:53:41,209 INFO     Training average positive_sample_loss at step 133100: 0.068417\n",
      "2023-12-11 00:53:41,209 INFO     Training average negative_sample_loss at step 133100: 0.067287\n",
      "2023-12-11 00:53:41,209 INFO     Training average loss at step 133100: 0.067852\n",
      "2023-12-11 00:55:11,482 INFO     Training average positive_sample_loss at step 133200: 0.066683\n",
      "2023-12-11 00:55:11,482 INFO     Training average negative_sample_loss at step 133200: 0.066863\n",
      "2023-12-11 00:55:11,482 INFO     Training average loss at step 133200: 0.066773\n",
      "2023-12-11 00:56:30,408 INFO     Training average positive_sample_loss at step 133300: 0.067361\n",
      "2023-12-11 00:56:30,409 INFO     Training average negative_sample_loss at step 133300: 0.066077\n",
      "2023-12-11 00:56:30,409 INFO     Training average loss at step 133300: 0.066719\n",
      "2023-12-11 00:57:47,893 INFO     Training average positive_sample_loss at step 133400: 0.067526\n",
      "2023-12-11 00:57:47,893 INFO     Training average negative_sample_loss at step 133400: 0.066102\n",
      "2023-12-11 00:57:47,893 INFO     Training average loss at step 133400: 0.066814\n",
      "2023-12-11 00:59:08,120 INFO     Training average positive_sample_loss at step 133500: 0.068022\n",
      "2023-12-11 00:59:08,121 INFO     Training average negative_sample_loss at step 133500: 0.066682\n",
      "2023-12-11 00:59:08,121 INFO     Training average loss at step 133500: 0.067352\n",
      "2023-12-11 01:00:25,695 INFO     Training average positive_sample_loss at step 133600: 0.068013\n",
      "2023-12-11 01:00:25,695 INFO     Training average negative_sample_loss at step 133600: 0.066679\n",
      "2023-12-11 01:00:25,695 INFO     Training average loss at step 133600: 0.067346\n",
      "2023-12-11 01:01:46,153 INFO     Training average positive_sample_loss at step 133700: 0.068288\n",
      "2023-12-11 01:01:46,154 INFO     Training average negative_sample_loss at step 133700: 0.067190\n",
      "2023-12-11 01:01:46,154 INFO     Training average loss at step 133700: 0.067739\n",
      "2023-12-11 01:03:04,937 INFO     Training average positive_sample_loss at step 133800: 0.068151\n",
      "2023-12-11 01:03:04,937 INFO     Training average negative_sample_loss at step 133800: 0.066988\n",
      "2023-12-11 01:03:04,937 INFO     Training average loss at step 133800: 0.067570\n",
      "2023-12-11 01:04:21,545 INFO     Training average positive_sample_loss at step 133900: 0.068474\n",
      "2023-12-11 01:04:21,545 INFO     Training average negative_sample_loss at step 133900: 0.066600\n",
      "2023-12-11 01:04:21,545 INFO     Training average loss at step 133900: 0.067537\n",
      "2023-12-11 01:05:40,197 INFO     Training average positive_sample_loss at step 134000: 0.068474\n",
      "2023-12-11 01:05:40,197 INFO     Training average negative_sample_loss at step 134000: 0.065982\n",
      "2023-12-11 01:05:40,197 INFO     Training average loss at step 134000: 0.067228\n",
      "2023-12-11 01:07:07,620 INFO     Training average positive_sample_loss at step 134100: 0.067885\n",
      "2023-12-11 01:07:07,621 INFO     Training average negative_sample_loss at step 134100: 0.066536\n",
      "2023-12-11 01:07:07,621 INFO     Training average loss at step 134100: 0.067211\n",
      "2023-12-11 01:08:25,807 INFO     Training average positive_sample_loss at step 134200: 0.067169\n",
      "2023-12-11 01:08:25,808 INFO     Training average negative_sample_loss at step 134200: 0.066925\n",
      "2023-12-11 01:08:25,808 INFO     Training average loss at step 134200: 0.067047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-11 01:09:46,397 INFO     Training average positive_sample_loss at step 134300: 0.067797\n",
      "2023-12-11 01:09:46,397 INFO     Training average negative_sample_loss at step 134300: 0.066344\n",
      "2023-12-11 01:09:46,398 INFO     Training average loss at step 134300: 0.067070\n",
      "2023-12-11 01:11:03,862 INFO     Training average positive_sample_loss at step 134400: 0.067913\n",
      "2023-12-11 01:11:03,862 INFO     Training average negative_sample_loss at step 134400: 0.066638\n",
      "2023-12-11 01:11:03,862 INFO     Training average loss at step 134400: 0.067276\n",
      "2023-12-11 01:12:20,497 INFO     Training average positive_sample_loss at step 134500: 0.068042\n",
      "2023-12-11 01:12:20,497 INFO     Training average negative_sample_loss at step 134500: 0.066103\n",
      "2023-12-11 01:12:20,498 INFO     Training average loss at step 134500: 0.067073\n",
      "2023-12-11 01:13:38,579 INFO     Training average positive_sample_loss at step 134600: 0.067994\n",
      "2023-12-11 01:13:38,580 INFO     Training average negative_sample_loss at step 134600: 0.067324\n",
      "2023-12-11 01:13:38,580 INFO     Training average loss at step 134600: 0.067659\n",
      "2023-12-11 01:14:55,401 INFO     Training average positive_sample_loss at step 134700: 0.068123\n",
      "2023-12-11 01:14:55,402 INFO     Training average negative_sample_loss at step 134700: 0.066559\n",
      "2023-12-11 01:14:55,402 INFO     Training average loss at step 134700: 0.067341\n",
      "2023-12-11 01:16:14,243 INFO     Training average positive_sample_loss at step 134800: 0.068365\n",
      "2023-12-11 01:16:14,243 INFO     Training average negative_sample_loss at step 134800: 0.066166\n",
      "2023-12-11 01:16:14,243 INFO     Training average loss at step 134800: 0.067265\n",
      "2023-12-11 01:17:34,290 INFO     Training average positive_sample_loss at step 134900: 0.068315\n",
      "2023-12-11 01:17:34,290 INFO     Training average negative_sample_loss at step 134900: 0.066679\n",
      "2023-12-11 01:17:34,290 INFO     Training average loss at step 134900: 0.067497\n",
      "2023-12-11 01:19:00,949 INFO     Training average positive_sample_loss at step 135000: 0.067941\n",
      "2023-12-11 01:19:00,949 INFO     Training average negative_sample_loss at step 135000: 0.067222\n",
      "2023-12-11 01:19:00,949 INFO     Training average loss at step 135000: 0.067581\n",
      "2023-12-11 01:20:18,539 INFO     Training average positive_sample_loss at step 135100: 0.066903\n",
      "2023-12-11 01:20:18,540 INFO     Training average negative_sample_loss at step 135100: 0.066462\n",
      "2023-12-11 01:20:18,540 INFO     Training average loss at step 135100: 0.066682\n",
      "2023-12-11 01:21:36,455 INFO     Training average positive_sample_loss at step 135200: 0.067031\n",
      "2023-12-11 01:21:36,455 INFO     Training average negative_sample_loss at step 135200: 0.066831\n",
      "2023-12-11 01:21:36,455 INFO     Training average loss at step 135200: 0.066931\n",
      "2023-12-11 01:22:54,505 INFO     Training average positive_sample_loss at step 135300: 0.067510\n",
      "2023-12-11 01:22:54,505 INFO     Training average negative_sample_loss at step 135300: 0.065641\n",
      "2023-12-11 01:22:54,505 INFO     Training average loss at step 135300: 0.066576\n",
      "2023-12-11 01:24:11,975 INFO     Training average positive_sample_loss at step 135400: 0.067665\n",
      "2023-12-11 01:24:11,975 INFO     Training average negative_sample_loss at step 135400: 0.066695\n",
      "2023-12-11 01:24:11,975 INFO     Training average loss at step 135400: 0.067180\n",
      "2023-12-11 01:25:28,860 INFO     Training average positive_sample_loss at step 135500: 0.068228\n",
      "2023-12-11 01:25:28,860 INFO     Training average negative_sample_loss at step 135500: 0.066701\n",
      "2023-12-11 01:25:28,861 INFO     Training average loss at step 135500: 0.067464\n",
      "2023-12-11 01:26:49,355 INFO     Training average positive_sample_loss at step 135600: 0.068173\n",
      "2023-12-11 01:26:49,356 INFO     Training average negative_sample_loss at step 135600: 0.066851\n",
      "2023-12-11 01:26:49,356 INFO     Training average loss at step 135600: 0.067512\n",
      "2023-12-11 01:28:11,244 INFO     Training average positive_sample_loss at step 135700: 0.068479\n",
      "2023-12-11 01:28:11,245 INFO     Training average negative_sample_loss at step 135700: 0.067365\n",
      "2023-12-11 01:28:11,245 INFO     Training average loss at step 135700: 0.067922\n",
      "2023-12-11 01:29:32,228 INFO     Training average positive_sample_loss at step 135800: 0.068351\n",
      "2023-12-11 01:29:32,228 INFO     Training average negative_sample_loss at step 135800: 0.066450\n",
      "2023-12-11 01:29:32,228 INFO     Training average loss at step 135800: 0.067400\n",
      "2023-12-11 01:30:49,737 INFO     Training average positive_sample_loss at step 135900: 0.068651\n",
      "2023-12-11 01:30:49,737 INFO     Training average negative_sample_loss at step 135900: 0.066123\n",
      "2023-12-11 01:30:49,737 INFO     Training average loss at step 135900: 0.067387\n",
      "2023-12-11 01:32:22,600 INFO     Training average positive_sample_loss at step 136000: 0.067238\n",
      "2023-12-11 01:32:22,600 INFO     Training average negative_sample_loss at step 136000: 0.066818\n",
      "2023-12-11 01:32:22,600 INFO     Training average loss at step 136000: 0.067028\n",
      "2023-12-11 01:33:40,483 INFO     Training average positive_sample_loss at step 136100: 0.067204\n",
      "2023-12-11 01:33:40,483 INFO     Training average negative_sample_loss at step 136100: 0.066596\n",
      "2023-12-11 01:33:40,483 INFO     Training average loss at step 136100: 0.066900\n",
      "2023-12-11 01:34:57,449 INFO     Training average positive_sample_loss at step 136200: 0.067468\n",
      "2023-12-11 01:34:57,450 INFO     Training average negative_sample_loss at step 136200: 0.065781\n",
      "2023-12-11 01:34:57,450 INFO     Training average loss at step 136200: 0.066624\n",
      "2023-12-11 01:36:13,857 INFO     Training average positive_sample_loss at step 136300: 0.067631\n",
      "2023-12-11 01:36:13,857 INFO     Training average negative_sample_loss at step 136300: 0.066175\n",
      "2023-12-11 01:36:13,857 INFO     Training average loss at step 136300: 0.066903\n",
      "2023-12-11 01:37:33,140 INFO     Training average positive_sample_loss at step 136400: 0.067985\n",
      "2023-12-11 01:37:33,140 INFO     Training average negative_sample_loss at step 136400: 0.066533\n",
      "2023-12-11 01:37:33,140 INFO     Training average loss at step 136400: 0.067259\n",
      "2023-12-11 01:38:50,107 INFO     Training average positive_sample_loss at step 136500: 0.068061\n",
      "2023-12-11 01:38:50,107 INFO     Training average negative_sample_loss at step 136500: 0.067013\n",
      "2023-12-11 01:38:50,107 INFO     Training average loss at step 136500: 0.067537\n",
      "2023-12-11 01:40:06,001 INFO     Training average positive_sample_loss at step 136600: 0.068016\n",
      "2023-12-11 01:40:06,001 INFO     Training average negative_sample_loss at step 136600: 0.066688\n",
      "2023-12-11 01:40:06,001 INFO     Training average loss at step 136600: 0.067352\n",
      "2023-12-11 01:41:21,333 INFO     Training average positive_sample_loss at step 136700: 0.068270\n",
      "2023-12-11 01:41:21,333 INFO     Training average negative_sample_loss at step 136700: 0.065796\n",
      "2023-12-11 01:41:21,333 INFO     Training average loss at step 136700: 0.067033\n",
      "2023-12-11 01:42:36,200 INFO     Training average positive_sample_loss at step 136800: 0.068528\n",
      "2023-12-11 01:42:36,200 INFO     Training average negative_sample_loss at step 136800: 0.067439\n",
      "2023-12-11 01:42:36,200 INFO     Training average loss at step 136800: 0.067983\n",
      "2023-12-11 01:44:00,681 INFO     Training average positive_sample_loss at step 136900: 0.068117\n",
      "2023-12-11 01:44:00,681 INFO     Training average negative_sample_loss at step 136900: 0.066231\n",
      "2023-12-11 01:44:00,681 INFO     Training average loss at step 136900: 0.067174\n",
      "2023-12-11 01:45:20,187 INFO     Training average positive_sample_loss at step 137000: 0.066719\n",
      "2023-12-11 01:45:20,188 INFO     Training average negative_sample_loss at step 137000: 0.066649\n",
      "2023-12-11 01:45:20,188 INFO     Training average loss at step 137000: 0.066684\n",
      "2023-12-11 01:46:37,118 INFO     Training average positive_sample_loss at step 137100: 0.067379\n",
      "2023-12-11 01:46:37,118 INFO     Training average negative_sample_loss at step 137100: 0.065881\n",
      "2023-12-11 01:46:37,118 INFO     Training average loss at step 137100: 0.066630\n",
      "2023-12-11 01:47:54,369 INFO     Training average positive_sample_loss at step 137200: 0.067313\n",
      "2023-12-11 01:47:54,369 INFO     Training average negative_sample_loss at step 137200: 0.066714\n",
      "2023-12-11 01:47:54,369 INFO     Training average loss at step 137200: 0.067013\n",
      "2023-12-11 01:49:13,559 INFO     Training average positive_sample_loss at step 137300: 0.068120\n",
      "2023-12-11 01:49:13,560 INFO     Training average negative_sample_loss at step 137300: 0.066311\n",
      "2023-12-11 01:49:13,560 INFO     Training average loss at step 137300: 0.067216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-11 01:50:33,736 INFO     Training average positive_sample_loss at step 137400: 0.068083\n",
      "2023-12-11 01:50:33,736 INFO     Training average negative_sample_loss at step 137400: 0.066377\n",
      "2023-12-11 01:50:33,736 INFO     Training average loss at step 137400: 0.067230\n",
      "2023-12-11 01:51:51,895 INFO     Training average positive_sample_loss at step 137500: 0.067909\n",
      "2023-12-11 01:51:51,895 INFO     Training average negative_sample_loss at step 137500: 0.066289\n",
      "2023-12-11 01:51:51,895 INFO     Training average loss at step 137500: 0.067099\n",
      "2023-12-11 01:53:10,167 INFO     Training average positive_sample_loss at step 137600: 0.068519\n",
      "2023-12-11 01:53:10,168 INFO     Training average negative_sample_loss at step 137600: 0.066197\n",
      "2023-12-11 01:53:10,168 INFO     Training average loss at step 137600: 0.067358\n",
      "2023-12-11 01:54:31,232 INFO     Training average positive_sample_loss at step 137700: 0.068119\n",
      "2023-12-11 01:54:31,232 INFO     Training average negative_sample_loss at step 137700: 0.066659\n",
      "2023-12-11 01:54:31,232 INFO     Training average loss at step 137700: 0.067389\n",
      "2023-12-11 01:55:49,320 INFO     Training average positive_sample_loss at step 137800: 0.068706\n",
      "2023-12-11 01:55:49,321 INFO     Training average negative_sample_loss at step 137800: 0.067250\n",
      "2023-12-11 01:55:49,321 INFO     Training average loss at step 137800: 0.067978\n",
      "2023-12-11 01:57:17,918 INFO     Training average positive_sample_loss at step 137900: 0.067242\n",
      "2023-12-11 01:57:17,919 INFO     Training average negative_sample_loss at step 137900: 0.066567\n",
      "2023-12-11 01:57:17,919 INFO     Training average loss at step 137900: 0.066905\n",
      "2023-12-11 01:58:38,392 INFO     Training average positive_sample_loss at step 138000: 0.067092\n",
      "2023-12-11 01:58:38,392 INFO     Training average negative_sample_loss at step 138000: 0.066304\n",
      "2023-12-11 01:58:38,392 INFO     Training average loss at step 138000: 0.066698\n",
      "2023-12-11 01:59:58,395 INFO     Training average positive_sample_loss at step 138100: 0.067389\n",
      "2023-12-11 01:59:58,396 INFO     Training average negative_sample_loss at step 138100: 0.067411\n",
      "2023-12-11 01:59:58,396 INFO     Training average loss at step 138100: 0.067400\n",
      "2023-12-11 02:01:17,755 INFO     Training average positive_sample_loss at step 138200: 0.067864\n",
      "2023-12-11 02:01:17,756 INFO     Training average negative_sample_loss at step 138200: 0.066020\n",
      "2023-12-11 02:01:17,756 INFO     Training average loss at step 138200: 0.066942\n",
      "2023-12-11 02:02:35,295 INFO     Training average positive_sample_loss at step 138300: 0.068049\n",
      "2023-12-11 02:02:35,295 INFO     Training average negative_sample_loss at step 138300: 0.066140\n",
      "2023-12-11 02:02:35,295 INFO     Training average loss at step 138300: 0.067094\n",
      "2023-12-11 02:03:51,887 INFO     Training average positive_sample_loss at step 138400: 0.068226\n",
      "2023-12-11 02:03:51,887 INFO     Training average negative_sample_loss at step 138400: 0.065827\n",
      "2023-12-11 02:03:51,887 INFO     Training average loss at step 138400: 0.067026\n",
      "2023-12-11 02:05:09,986 INFO     Training average positive_sample_loss at step 138500: 0.068223\n",
      "2023-12-11 02:05:09,987 INFO     Training average negative_sample_loss at step 138500: 0.066337\n",
      "2023-12-11 02:05:09,987 INFO     Training average loss at step 138500: 0.067280\n",
      "2023-12-11 02:06:27,807 INFO     Training average positive_sample_loss at step 138600: 0.068070\n",
      "2023-12-11 02:06:27,808 INFO     Training average negative_sample_loss at step 138600: 0.066738\n",
      "2023-12-11 02:06:27,808 INFO     Training average loss at step 138600: 0.067404\n",
      "2023-12-11 02:07:49,739 INFO     Training average positive_sample_loss at step 138700: 0.068631\n",
      "2023-12-11 02:07:49,739 INFO     Training average negative_sample_loss at step 138700: 0.066196\n",
      "2023-12-11 02:07:49,739 INFO     Training average loss at step 138700: 0.067414\n",
      "2023-12-11 02:09:24,153 INFO     Training average positive_sample_loss at step 138800: 0.067579\n",
      "2023-12-11 02:09:24,153 INFO     Training average negative_sample_loss at step 138800: 0.066131\n",
      "2023-12-11 02:09:24,153 INFO     Training average loss at step 138800: 0.066855\n",
      "2023-12-11 02:10:40,784 INFO     Training average positive_sample_loss at step 138900: 0.066720\n",
      "2023-12-11 02:10:40,784 INFO     Training average negative_sample_loss at step 138900: 0.066485\n",
      "2023-12-11 02:10:40,784 INFO     Training average loss at step 138900: 0.066602\n",
      "2023-12-11 02:11:57,700 INFO     Training average positive_sample_loss at step 139000: 0.067127\n",
      "2023-12-11 02:11:57,700 INFO     Training average negative_sample_loss at step 139000: 0.066258\n",
      "2023-12-11 02:11:57,700 INFO     Training average loss at step 139000: 0.066692\n",
      "2023-12-11 02:13:16,213 INFO     Training average positive_sample_loss at step 139100: 0.067271\n",
      "2023-12-11 02:13:16,213 INFO     Training average negative_sample_loss at step 139100: 0.065898\n",
      "2023-12-11 02:13:16,213 INFO     Training average loss at step 139100: 0.066585\n",
      "2023-12-11 02:14:33,430 INFO     Training average positive_sample_loss at step 139200: 0.068011\n",
      "2023-12-11 02:14:33,430 INFO     Training average negative_sample_loss at step 139200: 0.066692\n",
      "2023-12-11 02:14:33,430 INFO     Training average loss at step 139200: 0.067352\n",
      "2023-12-11 02:15:53,718 INFO     Training average positive_sample_loss at step 139300: 0.068394\n",
      "2023-12-11 02:15:53,718 INFO     Training average negative_sample_loss at step 139300: 0.066855\n",
      "2023-12-11 02:15:53,718 INFO     Training average loss at step 139300: 0.067625\n",
      "2023-12-11 02:17:12,246 INFO     Training average positive_sample_loss at step 139400: 0.067955\n",
      "2023-12-11 02:17:12,246 INFO     Training average negative_sample_loss at step 139400: 0.066037\n",
      "2023-12-11 02:17:12,246 INFO     Training average loss at step 139400: 0.066996\n",
      "2023-12-11 02:18:31,159 INFO     Training average positive_sample_loss at step 139500: 0.068510\n",
      "2023-12-11 02:18:31,159 INFO     Training average negative_sample_loss at step 139500: 0.066997\n",
      "2023-12-11 02:18:31,159 INFO     Training average loss at step 139500: 0.067754\n",
      "2023-12-11 02:19:47,298 INFO     Training average positive_sample_loss at step 139600: 0.068575\n",
      "2023-12-11 02:19:47,298 INFO     Training average negative_sample_loss at step 139600: 0.066551\n",
      "2023-12-11 02:19:47,299 INFO     Training average loss at step 139600: 0.067563\n",
      "2023-12-11 02:21:07,219 INFO     Training average positive_sample_loss at step 139700: 0.068760\n",
      "2023-12-11 02:21:07,219 INFO     Training average negative_sample_loss at step 139700: 0.066240\n",
      "2023-12-11 02:21:07,219 INFO     Training average loss at step 139700: 0.067500\n",
      "2023-12-11 02:22:33,391 INFO     Training average positive_sample_loss at step 139800: 0.066679\n",
      "2023-12-11 02:22:33,392 INFO     Training average negative_sample_loss at step 139800: 0.067786\n",
      "2023-12-11 02:22:33,392 INFO     Training average loss at step 139800: 0.067233\n",
      "2023-12-11 02:23:51,552 INFO     Training average positive_sample_loss at step 139900: 0.067296\n",
      "2023-12-11 02:23:51,552 INFO     Training average negative_sample_loss at step 139900: 0.066816\n",
      "2023-12-11 02:23:51,552 INFO     Training average loss at step 139900: 0.067056\n",
      "2023-12-11 02:25:22,026 INFO     Training average positive_sample_loss at step 140000: 0.067345\n",
      "2023-12-11 02:25:22,026 INFO     Training average negative_sample_loss at step 140000: 0.065820\n",
      "2023-12-11 02:25:22,026 INFO     Training average loss at step 140000: 0.066583\n",
      "2023-12-11 02:25:22,026 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-11 02:25:23,302 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-11 02:25:51,574 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-11 02:26:22,557 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-11 02:26:52,185 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-11 02:27:19,483 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-11 02:27:47,541 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-11 02:28:15,718 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-11 02:28:23,364 INFO     Valid MRR at step 140000: 0.797344\n",
      "2023-12-11 02:28:23,364 INFO     Valid MR at step 140000: 39.604120\n",
      "2023-12-11 02:28:23,364 INFO     Valid HITS@1 at step 140000: 0.748210\n",
      "2023-12-11 02:28:23,364 INFO     Valid HITS@3 at step 140000: 0.828360\n",
      "2023-12-11 02:28:23,365 INFO     Valid HITS@10 at step 140000: 0.882070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-11 02:29:28,342 INFO     Training average positive_sample_loss at step 140100: 0.068116\n",
      "2023-12-11 02:29:28,343 INFO     Training average negative_sample_loss at step 140100: 0.067071\n",
      "2023-12-11 02:29:28,343 INFO     Training average loss at step 140100: 0.067594\n",
      "2023-12-11 02:30:44,647 INFO     Training average positive_sample_loss at step 140200: 0.067994\n",
      "2023-12-11 02:30:44,647 INFO     Training average negative_sample_loss at step 140200: 0.065857\n",
      "2023-12-11 02:30:44,647 INFO     Training average loss at step 140200: 0.066925\n",
      "2023-12-11 02:32:02,228 INFO     Training average positive_sample_loss at step 140300: 0.068070\n",
      "2023-12-11 02:32:02,228 INFO     Training average negative_sample_loss at step 140300: 0.066384\n",
      "2023-12-11 02:32:02,229 INFO     Training average loss at step 140300: 0.067227\n",
      "2023-12-11 02:33:20,375 INFO     Training average positive_sample_loss at step 140400: 0.068141\n",
      "2023-12-11 02:33:20,375 INFO     Training average negative_sample_loss at step 140400: 0.065467\n",
      "2023-12-11 02:33:20,375 INFO     Training average loss at step 140400: 0.066804\n",
      "2023-12-11 02:34:37,438 INFO     Training average positive_sample_loss at step 140500: 0.068428\n",
      "2023-12-11 02:34:37,438 INFO     Training average negative_sample_loss at step 140500: 0.067497\n",
      "2023-12-11 02:34:37,438 INFO     Training average loss at step 140500: 0.067963\n",
      "2023-12-11 02:35:54,319 INFO     Training average positive_sample_loss at step 140600: 0.068456\n",
      "2023-12-11 02:35:54,319 INFO     Training average negative_sample_loss at step 140600: 0.066488\n",
      "2023-12-11 02:35:54,319 INFO     Training average loss at step 140600: 0.067472\n",
      "2023-12-11 02:37:25,113 INFO     Training average positive_sample_loss at step 140700: 0.067543\n",
      "2023-12-11 02:37:25,113 INFO     Training average negative_sample_loss at step 140700: 0.066078\n",
      "2023-12-11 02:37:25,113 INFO     Training average loss at step 140700: 0.066811\n",
      "2023-12-11 02:38:46,748 INFO     Training average positive_sample_loss at step 140800: 0.066674\n",
      "2023-12-11 02:38:46,748 INFO     Training average negative_sample_loss at step 140800: 0.066349\n",
      "2023-12-11 02:38:46,748 INFO     Training average loss at step 140800: 0.066511\n",
      "2023-12-11 02:40:03,860 INFO     Training average positive_sample_loss at step 140900: 0.067568\n",
      "2023-12-11 02:40:03,860 INFO     Training average negative_sample_loss at step 140900: 0.066512\n",
      "2023-12-11 02:40:03,860 INFO     Training average loss at step 140900: 0.067040\n",
      "2023-12-11 02:41:22,019 INFO     Training average positive_sample_loss at step 141000: 0.067961\n",
      "2023-12-11 02:41:22,020 INFO     Training average negative_sample_loss at step 141000: 0.067029\n",
      "2023-12-11 02:41:22,020 INFO     Training average loss at step 141000: 0.067495\n",
      "2023-12-11 02:42:42,646 INFO     Training average positive_sample_loss at step 141100: 0.068174\n",
      "2023-12-11 02:42:42,647 INFO     Training average negative_sample_loss at step 141100: 0.066273\n",
      "2023-12-11 02:42:42,647 INFO     Training average loss at step 141100: 0.067224\n",
      "2023-12-11 02:44:04,036 INFO     Training average positive_sample_loss at step 141200: 0.067629\n",
      "2023-12-11 02:44:04,037 INFO     Training average negative_sample_loss at step 141200: 0.066236\n",
      "2023-12-11 02:44:04,037 INFO     Training average loss at step 141200: 0.066933\n",
      "2023-12-11 02:45:24,917 INFO     Training average positive_sample_loss at step 141300: 0.068071\n",
      "2023-12-11 02:45:24,918 INFO     Training average negative_sample_loss at step 141300: 0.066407\n",
      "2023-12-11 02:45:24,918 INFO     Training average loss at step 141300: 0.067239\n",
      "2023-12-11 02:46:46,336 INFO     Training average positive_sample_loss at step 141400: 0.068310\n",
      "2023-12-11 02:46:46,337 INFO     Training average negative_sample_loss at step 141400: 0.065657\n",
      "2023-12-11 02:46:46,337 INFO     Training average loss at step 141400: 0.066984\n",
      "2023-12-11 02:48:05,588 INFO     Training average positive_sample_loss at step 141500: 0.068143\n",
      "2023-12-11 02:48:05,588 INFO     Training average negative_sample_loss at step 141500: 0.066670\n",
      "2023-12-11 02:48:05,588 INFO     Training average loss at step 141500: 0.067407\n",
      "2023-12-11 02:49:30,888 INFO     Training average positive_sample_loss at step 141600: 0.068459\n",
      "2023-12-11 02:49:30,889 INFO     Training average negative_sample_loss at step 141600: 0.066407\n",
      "2023-12-11 02:49:30,889 INFO     Training average loss at step 141600: 0.067433\n",
      "2023-12-11 02:50:51,420 INFO     Training average positive_sample_loss at step 141700: 0.066773\n",
      "2023-12-11 02:50:51,421 INFO     Training average negative_sample_loss at step 141700: 0.066486\n",
      "2023-12-11 02:50:51,421 INFO     Training average loss at step 141700: 0.066629\n",
      "2023-12-11 02:52:08,584 INFO     Training average positive_sample_loss at step 141800: 0.067341\n",
      "2023-12-11 02:52:08,584 INFO     Training average negative_sample_loss at step 141800: 0.066917\n",
      "2023-12-11 02:52:08,584 INFO     Training average loss at step 141800: 0.067129\n",
      "2023-12-11 02:53:28,012 INFO     Training average positive_sample_loss at step 141900: 0.067545\n",
      "2023-12-11 02:53:28,012 INFO     Training average negative_sample_loss at step 141900: 0.065343\n",
      "2023-12-11 02:53:28,012 INFO     Training average loss at step 141900: 0.066444\n",
      "2023-12-11 02:54:46,942 INFO     Training average positive_sample_loss at step 142000: 0.067906\n",
      "2023-12-11 02:54:46,943 INFO     Training average negative_sample_loss at step 142000: 0.066168\n",
      "2023-12-11 02:54:46,943 INFO     Training average loss at step 142000: 0.067037\n",
      "2023-12-11 02:56:05,628 INFO     Training average positive_sample_loss at step 142100: 0.067596\n",
      "2023-12-11 02:56:05,629 INFO     Training average negative_sample_loss at step 142100: 0.065895\n",
      "2023-12-11 02:56:05,629 INFO     Training average loss at step 142100: 0.066745\n",
      "2023-12-11 02:57:23,317 INFO     Training average positive_sample_loss at step 142200: 0.068348\n",
      "2023-12-11 02:57:23,317 INFO     Training average negative_sample_loss at step 142200: 0.065688\n",
      "2023-12-11 02:57:23,318 INFO     Training average loss at step 142200: 0.067018\n",
      "2023-12-11 02:58:41,610 INFO     Training average positive_sample_loss at step 142300: 0.068077\n",
      "2023-12-11 02:58:41,610 INFO     Training average negative_sample_loss at step 142300: 0.066274\n",
      "2023-12-11 02:58:41,610 INFO     Training average loss at step 142300: 0.067175\n",
      "2023-12-11 03:00:00,249 INFO     Training average positive_sample_loss at step 142400: 0.068108\n",
      "2023-12-11 03:00:00,249 INFO     Training average negative_sample_loss at step 142400: 0.066512\n",
      "2023-12-11 03:00:00,249 INFO     Training average loss at step 142400: 0.067310\n",
      "2023-12-11 03:01:18,498 INFO     Training average positive_sample_loss at step 142500: 0.068078\n",
      "2023-12-11 03:01:18,498 INFO     Training average negative_sample_loss at step 142500: 0.066407\n",
      "2023-12-11 03:01:18,498 INFO     Training average loss at step 142500: 0.067242\n",
      "2023-12-11 03:02:46,378 INFO     Training average positive_sample_loss at step 142600: 0.067265\n",
      "2023-12-11 03:02:46,379 INFO     Training average negative_sample_loss at step 142600: 0.066545\n",
      "2023-12-11 03:02:46,379 INFO     Training average loss at step 142600: 0.066905\n",
      "2023-12-11 03:04:02,578 INFO     Training average positive_sample_loss at step 142700: 0.066939\n",
      "2023-12-11 03:04:02,578 INFO     Training average negative_sample_loss at step 142700: 0.066331\n",
      "2023-12-11 03:04:02,578 INFO     Training average loss at step 142700: 0.066635\n",
      "2023-12-11 03:05:18,134 INFO     Training average positive_sample_loss at step 142800: 0.067307\n",
      "2023-12-11 03:05:18,134 INFO     Training average negative_sample_loss at step 142800: 0.066164\n",
      "2023-12-11 03:05:18,134 INFO     Training average loss at step 142800: 0.066736\n",
      "2023-12-11 03:06:34,170 INFO     Training average positive_sample_loss at step 142900: 0.067767\n",
      "2023-12-11 03:06:34,170 INFO     Training average negative_sample_loss at step 142900: 0.065954\n",
      "2023-12-11 03:06:34,170 INFO     Training average loss at step 142900: 0.066860\n",
      "2023-12-11 03:07:50,424 INFO     Training average positive_sample_loss at step 143000: 0.067978\n",
      "2023-12-11 03:07:50,425 INFO     Training average negative_sample_loss at step 143000: 0.066513\n",
      "2023-12-11 03:07:50,425 INFO     Training average loss at step 143000: 0.067245\n",
      "2023-12-11 03:09:10,450 INFO     Training average positive_sample_loss at step 143100: 0.068048\n",
      "2023-12-11 03:09:10,450 INFO     Training average negative_sample_loss at step 143100: 0.066078\n",
      "2023-12-11 03:09:10,451 INFO     Training average loss at step 143100: 0.067063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-11 03:10:28,034 INFO     Training average positive_sample_loss at step 143200: 0.068031\n",
      "2023-12-11 03:10:28,034 INFO     Training average negative_sample_loss at step 143200: 0.066197\n",
      "2023-12-11 03:10:28,034 INFO     Training average loss at step 143200: 0.067114\n",
      "2023-12-11 03:11:46,563 INFO     Training average positive_sample_loss at step 143300: 0.068606\n",
      "2023-12-11 03:11:46,563 INFO     Training average negative_sample_loss at step 143300: 0.067086\n",
      "2023-12-11 03:11:46,563 INFO     Training average loss at step 143300: 0.067846\n",
      "2023-12-11 03:13:03,162 INFO     Training average positive_sample_loss at step 143400: 0.068561\n",
      "2023-12-11 03:13:03,162 INFO     Training average negative_sample_loss at step 143400: 0.066421\n",
      "2023-12-11 03:13:03,162 INFO     Training average loss at step 143400: 0.067491\n",
      "2023-12-11 03:14:34,354 INFO     Training average positive_sample_loss at step 143500: 0.067875\n",
      "2023-12-11 03:14:34,354 INFO     Training average negative_sample_loss at step 143500: 0.066680\n",
      "2023-12-11 03:14:34,354 INFO     Training average loss at step 143500: 0.067278\n",
      "2023-12-11 03:15:51,516 INFO     Training average positive_sample_loss at step 143600: 0.067008\n",
      "2023-12-11 03:15:51,516 INFO     Training average negative_sample_loss at step 143600: 0.067532\n",
      "2023-12-11 03:15:51,516 INFO     Training average loss at step 143600: 0.067270\n",
      "2023-12-11 03:17:10,435 INFO     Training average positive_sample_loss at step 143700: 0.067214\n",
      "2023-12-11 03:17:10,436 INFO     Training average negative_sample_loss at step 143700: 0.066061\n",
      "2023-12-11 03:17:10,436 INFO     Training average loss at step 143700: 0.066637\n",
      "2023-12-11 03:18:31,411 INFO     Training average positive_sample_loss at step 143800: 0.067371\n",
      "2023-12-11 03:18:31,411 INFO     Training average negative_sample_loss at step 143800: 0.066513\n",
      "2023-12-11 03:18:31,411 INFO     Training average loss at step 143800: 0.066942\n",
      "2023-12-11 03:19:51,887 INFO     Training average positive_sample_loss at step 143900: 0.067858\n",
      "2023-12-11 03:19:51,887 INFO     Training average negative_sample_loss at step 143900: 0.065999\n",
      "2023-12-11 03:19:51,887 INFO     Training average loss at step 143900: 0.066928\n",
      "2023-12-11 03:21:08,486 INFO     Training average positive_sample_loss at step 144000: 0.068224\n",
      "2023-12-11 03:21:08,487 INFO     Training average negative_sample_loss at step 144000: 0.065968\n",
      "2023-12-11 03:21:08,487 INFO     Training average loss at step 144000: 0.067096\n",
      "2023-12-11 03:22:25,422 INFO     Training average positive_sample_loss at step 144100: 0.068366\n",
      "2023-12-11 03:22:25,422 INFO     Training average negative_sample_loss at step 144100: 0.066294\n",
      "2023-12-11 03:22:25,422 INFO     Training average loss at step 144100: 0.067330\n",
      "2023-12-11 03:23:39,394 INFO     Training average positive_sample_loss at step 144200: 0.068269\n",
      "2023-12-11 03:23:39,394 INFO     Training average negative_sample_loss at step 144200: 0.066220\n",
      "2023-12-11 03:23:39,395 INFO     Training average loss at step 144200: 0.067244\n",
      "2023-12-11 03:24:54,208 INFO     Training average positive_sample_loss at step 144300: 0.068223\n",
      "2023-12-11 03:24:54,208 INFO     Training average negative_sample_loss at step 144300: 0.066119\n",
      "2023-12-11 03:24:54,208 INFO     Training average loss at step 144300: 0.067171\n",
      "2023-12-11 03:26:09,046 INFO     Training average positive_sample_loss at step 144400: 0.068212\n",
      "2023-12-11 03:26:09,046 INFO     Training average negative_sample_loss at step 144400: 0.066258\n",
      "2023-12-11 03:26:09,046 INFO     Training average loss at step 144400: 0.067235\n",
      "2023-12-11 03:27:39,484 INFO     Training average positive_sample_loss at step 144500: 0.067146\n",
      "2023-12-11 03:27:39,484 INFO     Training average negative_sample_loss at step 144500: 0.065165\n",
      "2023-12-11 03:27:39,484 INFO     Training average loss at step 144500: 0.066155\n",
      "2023-12-11 03:28:59,246 INFO     Training average positive_sample_loss at step 144600: 0.066930\n",
      "2023-12-11 03:28:59,247 INFO     Training average negative_sample_loss at step 144600: 0.066367\n",
      "2023-12-11 03:28:59,247 INFO     Training average loss at step 144600: 0.066649\n",
      "2023-12-11 03:30:14,556 INFO     Training average positive_sample_loss at step 144700: 0.067660\n",
      "2023-12-11 03:30:14,556 INFO     Training average negative_sample_loss at step 144700: 0.066902\n",
      "2023-12-11 03:30:14,556 INFO     Training average loss at step 144700: 0.067281\n",
      "2023-12-11 03:31:31,434 INFO     Training average positive_sample_loss at step 144800: 0.067426\n",
      "2023-12-11 03:31:31,435 INFO     Training average negative_sample_loss at step 144800: 0.066007\n",
      "2023-12-11 03:31:31,435 INFO     Training average loss at step 144800: 0.066717\n",
      "2023-12-11 03:32:47,697 INFO     Training average positive_sample_loss at step 144900: 0.067841\n",
      "2023-12-11 03:32:47,697 INFO     Training average negative_sample_loss at step 144900: 0.065532\n",
      "2023-12-11 03:32:47,697 INFO     Training average loss at step 144900: 0.066687\n",
      "2023-12-11 03:34:05,241 INFO     Training average positive_sample_loss at step 145000: 0.068197\n",
      "2023-12-11 03:34:05,241 INFO     Training average negative_sample_loss at step 145000: 0.066970\n",
      "2023-12-11 03:34:05,241 INFO     Training average loss at step 145000: 0.067584\n",
      "2023-12-11 03:35:22,224 INFO     Training average positive_sample_loss at step 145100: 0.068073\n",
      "2023-12-11 03:35:22,224 INFO     Training average negative_sample_loss at step 145100: 0.066174\n",
      "2023-12-11 03:35:22,224 INFO     Training average loss at step 145100: 0.067123\n",
      "2023-12-11 03:36:43,634 INFO     Training average positive_sample_loss at step 145200: 0.068608\n",
      "2023-12-11 03:36:43,634 INFO     Training average negative_sample_loss at step 145200: 0.066801\n",
      "2023-12-11 03:36:43,634 INFO     Training average loss at step 145200: 0.067705\n",
      "2023-12-11 03:38:01,726 INFO     Training average positive_sample_loss at step 145300: 0.068125\n",
      "2023-12-11 03:38:01,726 INFO     Training average negative_sample_loss at step 145300: 0.066629\n",
      "2023-12-11 03:38:01,726 INFO     Training average loss at step 145300: 0.067377\n",
      "2023-12-11 03:39:34,958 INFO     Training average positive_sample_loss at step 145400: 0.067834\n",
      "2023-12-11 03:39:34,958 INFO     Training average negative_sample_loss at step 145400: 0.066698\n",
      "2023-12-11 03:39:34,958 INFO     Training average loss at step 145400: 0.067266\n",
      "2023-12-11 03:40:53,247 INFO     Training average positive_sample_loss at step 145500: 0.066689\n",
      "2023-12-11 03:40:53,248 INFO     Training average negative_sample_loss at step 145500: 0.066262\n",
      "2023-12-11 03:40:53,248 INFO     Training average loss at step 145500: 0.066476\n",
      "2023-12-11 03:42:10,129 INFO     Training average positive_sample_loss at step 145600: 0.067372\n",
      "2023-12-11 03:42:10,129 INFO     Training average negative_sample_loss at step 145600: 0.066118\n",
      "2023-12-11 03:42:10,130 INFO     Training average loss at step 145600: 0.066745\n",
      "2023-12-11 03:43:27,327 INFO     Training average positive_sample_loss at step 145700: 0.067303\n",
      "2023-12-11 03:43:27,327 INFO     Training average negative_sample_loss at step 145700: 0.065767\n",
      "2023-12-11 03:43:27,327 INFO     Training average loss at step 145700: 0.066535\n",
      "2023-12-11 03:44:47,503 INFO     Training average positive_sample_loss at step 145800: 0.068015\n",
      "2023-12-11 03:44:47,503 INFO     Training average negative_sample_loss at step 145800: 0.066306\n",
      "2023-12-11 03:44:47,503 INFO     Training average loss at step 145800: 0.067160\n",
      "2023-12-11 03:46:07,115 INFO     Training average positive_sample_loss at step 145900: 0.068003\n",
      "2023-12-11 03:46:07,115 INFO     Training average negative_sample_loss at step 145900: 0.066285\n",
      "2023-12-11 03:46:07,115 INFO     Training average loss at step 145900: 0.067144\n",
      "2023-12-11 03:47:26,307 INFO     Training average positive_sample_loss at step 146000: 0.068088\n",
      "2023-12-11 03:47:26,308 INFO     Training average negative_sample_loss at step 146000: 0.066054\n",
      "2023-12-11 03:47:26,308 INFO     Training average loss at step 146000: 0.067071\n",
      "2023-12-11 03:48:46,664 INFO     Training average positive_sample_loss at step 146100: 0.068461\n",
      "2023-12-11 03:48:46,664 INFO     Training average negative_sample_loss at step 146100: 0.066713\n",
      "2023-12-11 03:48:46,664 INFO     Training average loss at step 146100: 0.067587\n",
      "2023-12-11 03:50:05,151 INFO     Training average positive_sample_loss at step 146200: 0.068238\n",
      "2023-12-11 03:50:05,152 INFO     Training average negative_sample_loss at step 146200: 0.066886\n",
      "2023-12-11 03:50:05,152 INFO     Training average loss at step 146200: 0.067562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-11 03:51:21,514 INFO     Training average positive_sample_loss at step 146300: 0.068543\n",
      "2023-12-11 03:51:21,514 INFO     Training average negative_sample_loss at step 146300: 0.066518\n",
      "2023-12-11 03:51:21,514 INFO     Training average loss at step 146300: 0.067530\n",
      "2023-12-11 03:52:46,098 INFO     Training average positive_sample_loss at step 146400: 0.066867\n",
      "2023-12-11 03:52:46,099 INFO     Training average negative_sample_loss at step 146400: 0.066319\n",
      "2023-12-11 03:52:46,099 INFO     Training average loss at step 146400: 0.066593\n",
      "2023-12-11 03:54:04,048 INFO     Training average positive_sample_loss at step 146500: 0.067170\n",
      "2023-12-11 03:54:04,048 INFO     Training average negative_sample_loss at step 146500: 0.065879\n",
      "2023-12-11 03:54:04,048 INFO     Training average loss at step 146500: 0.066525\n",
      "2023-12-11 03:55:21,740 INFO     Training average positive_sample_loss at step 146600: 0.067095\n",
      "2023-12-11 03:55:21,740 INFO     Training average negative_sample_loss at step 146600: 0.066476\n",
      "2023-12-11 03:55:21,740 INFO     Training average loss at step 146600: 0.066785\n",
      "2023-12-11 03:56:40,180 INFO     Training average positive_sample_loss at step 146700: 0.067651\n",
      "2023-12-11 03:56:40,181 INFO     Training average negative_sample_loss at step 146700: 0.066112\n",
      "2023-12-11 03:56:40,181 INFO     Training average loss at step 146700: 0.066881\n",
      "2023-12-11 03:57:59,097 INFO     Training average positive_sample_loss at step 146800: 0.067711\n",
      "2023-12-11 03:57:59,097 INFO     Training average negative_sample_loss at step 146800: 0.066772\n",
      "2023-12-11 03:57:59,097 INFO     Training average loss at step 146800: 0.067241\n",
      "2023-12-11 03:59:16,724 INFO     Training average positive_sample_loss at step 146900: 0.067901\n",
      "2023-12-11 03:59:16,725 INFO     Training average negative_sample_loss at step 146900: 0.066241\n",
      "2023-12-11 03:59:16,725 INFO     Training average loss at step 146900: 0.067071\n",
      "2023-12-11 04:00:33,548 INFO     Training average positive_sample_loss at step 147000: 0.068170\n",
      "2023-12-11 04:00:33,548 INFO     Training average negative_sample_loss at step 147000: 0.066129\n",
      "2023-12-11 04:00:33,549 INFO     Training average loss at step 147000: 0.067149\n",
      "2023-12-11 04:01:50,522 INFO     Training average positive_sample_loss at step 147100: 0.068221\n",
      "2023-12-11 04:01:50,523 INFO     Training average negative_sample_loss at step 147100: 0.066411\n",
      "2023-12-11 04:01:50,523 INFO     Training average loss at step 147100: 0.067316\n",
      "2023-12-11 04:03:08,167 INFO     Training average positive_sample_loss at step 147200: 0.068872\n",
      "2023-12-11 04:03:08,167 INFO     Training average negative_sample_loss at step 147200: 0.067038\n",
      "2023-12-11 04:03:08,167 INFO     Training average loss at step 147200: 0.067955\n",
      "2023-12-11 04:04:39,195 INFO     Training average positive_sample_loss at step 147300: 0.067692\n",
      "2023-12-11 04:04:39,195 INFO     Training average negative_sample_loss at step 147300: 0.066589\n",
      "2023-12-11 04:04:39,195 INFO     Training average loss at step 147300: 0.067141\n",
      "2023-12-11 04:05:56,864 INFO     Training average positive_sample_loss at step 147400: 0.066775\n",
      "2023-12-11 04:05:56,864 INFO     Training average negative_sample_loss at step 147400: 0.065440\n",
      "2023-12-11 04:05:56,864 INFO     Training average loss at step 147400: 0.066107\n",
      "2023-12-11 04:07:13,010 INFO     Training average positive_sample_loss at step 147500: 0.067350\n",
      "2023-12-11 04:07:13,010 INFO     Training average negative_sample_loss at step 147500: 0.066178\n",
      "2023-12-11 04:07:13,011 INFO     Training average loss at step 147500: 0.066764\n",
      "2023-12-11 04:08:30,281 INFO     Training average positive_sample_loss at step 147600: 0.067387\n",
      "2023-12-11 04:08:30,281 INFO     Training average negative_sample_loss at step 147600: 0.065653\n",
      "2023-12-11 04:08:30,281 INFO     Training average loss at step 147600: 0.066520\n",
      "2023-12-11 04:09:47,653 INFO     Training average positive_sample_loss at step 147700: 0.067776\n",
      "2023-12-11 04:09:47,654 INFO     Training average negative_sample_loss at step 147700: 0.066331\n",
      "2023-12-11 04:09:47,654 INFO     Training average loss at step 147700: 0.067053\n",
      "2023-12-11 04:11:07,523 INFO     Training average positive_sample_loss at step 147800: 0.067821\n",
      "2023-12-11 04:11:07,523 INFO     Training average negative_sample_loss at step 147800: 0.066497\n",
      "2023-12-11 04:11:07,523 INFO     Training average loss at step 147800: 0.067159\n",
      "2023-12-11 04:12:26,119 INFO     Training average positive_sample_loss at step 147900: 0.068181\n",
      "2023-12-11 04:12:26,119 INFO     Training average negative_sample_loss at step 147900: 0.066423\n",
      "2023-12-11 04:12:26,119 INFO     Training average loss at step 147900: 0.067302\n",
      "2023-12-11 04:13:41,681 INFO     Training average positive_sample_loss at step 148000: 0.068475\n",
      "2023-12-11 04:13:41,681 INFO     Training average negative_sample_loss at step 148000: 0.066376\n",
      "2023-12-11 04:13:41,681 INFO     Training average loss at step 148000: 0.067425\n",
      "2023-12-11 04:15:00,557 INFO     Training average positive_sample_loss at step 148100: 0.068301\n",
      "2023-12-11 04:15:00,558 INFO     Training average negative_sample_loss at step 148100: 0.067520\n",
      "2023-12-11 04:15:00,558 INFO     Training average loss at step 148100: 0.067911\n",
      "2023-12-11 04:16:20,353 INFO     Training average positive_sample_loss at step 148200: 0.068475\n",
      "2023-12-11 04:16:20,353 INFO     Training average negative_sample_loss at step 148200: 0.066211\n",
      "2023-12-11 04:16:20,353 INFO     Training average loss at step 148200: 0.067343\n",
      "2023-12-11 04:17:52,330 INFO     Training average positive_sample_loss at step 148300: 0.066330\n",
      "2023-12-11 04:17:52,330 INFO     Training average negative_sample_loss at step 148300: 0.065563\n",
      "2023-12-11 04:17:52,330 INFO     Training average loss at step 148300: 0.065946\n",
      "2023-12-11 04:19:09,005 INFO     Training average positive_sample_loss at step 148400: 0.067095\n",
      "2023-12-11 04:19:09,005 INFO     Training average negative_sample_loss at step 148400: 0.066051\n",
      "2023-12-11 04:19:09,005 INFO     Training average loss at step 148400: 0.066573\n",
      "2023-12-11 04:20:27,137 INFO     Training average positive_sample_loss at step 148500: 0.067611\n",
      "2023-12-11 04:20:27,137 INFO     Training average negative_sample_loss at step 148500: 0.066220\n",
      "2023-12-11 04:20:27,137 INFO     Training average loss at step 148500: 0.066915\n",
      "2023-12-11 04:21:45,542 INFO     Training average positive_sample_loss at step 148600: 0.067616\n",
      "2023-12-11 04:21:45,542 INFO     Training average negative_sample_loss at step 148600: 0.066026\n",
      "2023-12-11 04:21:45,542 INFO     Training average loss at step 148600: 0.066821\n",
      "2023-12-11 04:23:04,164 INFO     Training average positive_sample_loss at step 148700: 0.068139\n",
      "2023-12-11 04:23:04,165 INFO     Training average negative_sample_loss at step 148700: 0.067171\n",
      "2023-12-11 04:23:04,165 INFO     Training average loss at step 148700: 0.067655\n",
      "2023-12-11 04:24:20,655 INFO     Training average positive_sample_loss at step 148800: 0.068071\n",
      "2023-12-11 04:24:20,655 INFO     Training average negative_sample_loss at step 148800: 0.066168\n",
      "2023-12-11 04:24:20,655 INFO     Training average loss at step 148800: 0.067119\n",
      "2023-12-11 04:25:39,056 INFO     Training average positive_sample_loss at step 148900: 0.068370\n",
      "2023-12-11 04:25:39,056 INFO     Training average negative_sample_loss at step 148900: 0.067259\n",
      "2023-12-11 04:25:39,056 INFO     Training average loss at step 148900: 0.067814\n",
      "2023-12-11 04:26:58,309 INFO     Training average positive_sample_loss at step 149000: 0.067994\n",
      "2023-12-11 04:26:58,309 INFO     Training average negative_sample_loss at step 149000: 0.066486\n",
      "2023-12-11 04:26:58,309 INFO     Training average loss at step 149000: 0.067240\n",
      "2023-12-11 04:28:16,445 INFO     Training average positive_sample_loss at step 149100: 0.068511\n",
      "2023-12-11 04:28:16,446 INFO     Training average negative_sample_loss at step 149100: 0.066229\n",
      "2023-12-11 04:28:16,446 INFO     Training average loss at step 149100: 0.067370\n",
      "2023-12-11 04:29:42,367 INFO     Training average positive_sample_loss at step 149200: 0.067339\n",
      "2023-12-11 04:29:42,367 INFO     Training average negative_sample_loss at step 149200: 0.066140\n",
      "2023-12-11 04:29:42,368 INFO     Training average loss at step 149200: 0.066739\n",
      "2023-12-11 04:31:03,222 INFO     Training average positive_sample_loss at step 149300: 0.066860\n",
      "2023-12-11 04:31:03,223 INFO     Training average negative_sample_loss at step 149300: 0.065732\n",
      "2023-12-11 04:31:03,223 INFO     Training average loss at step 149300: 0.066296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-11 04:32:21,949 INFO     Training average positive_sample_loss at step 149400: 0.067143\n",
      "2023-12-11 04:32:21,949 INFO     Training average negative_sample_loss at step 149400: 0.065626\n",
      "2023-12-11 04:32:21,949 INFO     Training average loss at step 149400: 0.066384\n",
      "2023-12-11 04:33:41,281 INFO     Training average positive_sample_loss at step 149500: 0.067413\n",
      "2023-12-11 04:33:41,281 INFO     Training average negative_sample_loss at step 149500: 0.066494\n",
      "2023-12-11 04:33:41,281 INFO     Training average loss at step 149500: 0.066953\n",
      "2023-12-11 04:35:00,683 INFO     Training average positive_sample_loss at step 149600: 0.067837\n",
      "2023-12-11 04:35:00,683 INFO     Training average negative_sample_loss at step 149600: 0.066737\n",
      "2023-12-11 04:35:00,683 INFO     Training average loss at step 149600: 0.067287\n",
      "2023-12-11 04:36:19,553 INFO     Training average positive_sample_loss at step 149700: 0.068051\n",
      "2023-12-11 04:36:19,553 INFO     Training average negative_sample_loss at step 149700: 0.066698\n",
      "2023-12-11 04:36:19,553 INFO     Training average loss at step 149700: 0.067374\n",
      "2023-12-11 04:37:39,075 INFO     Training average positive_sample_loss at step 149800: 0.067835\n",
      "2023-12-11 04:37:39,075 INFO     Training average negative_sample_loss at step 149800: 0.065436\n",
      "2023-12-11 04:37:39,075 INFO     Training average loss at step 149800: 0.066635\n",
      "2023-12-11 04:38:56,142 INFO     Training average positive_sample_loss at step 149900: 0.068352\n",
      "2023-12-11 04:38:56,143 INFO     Training average negative_sample_loss at step 149900: 0.067180\n",
      "2023-12-11 04:38:56,143 INFO     Training average loss at step 149900: 0.067766\n",
      "2023-12-11 04:40:26,497 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-11 04:40:27,472 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-11 04:40:55,884 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-11 04:41:25,688 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-11 04:41:55,312 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-11 04:42:25,542 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-11 04:42:53,413 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-11 04:43:21,517 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-11 04:43:29,979 INFO     Valid MRR at step 149999: 0.799452\n",
      "2023-12-11 04:43:29,980 INFO     Valid MR at step 149999: 39.530380\n",
      "2023-12-11 04:43:29,980 INFO     Valid HITS@1 at step 149999: 0.751210\n",
      "2023-12-11 04:43:29,980 INFO     Valid HITS@3 at step 149999: 0.829420\n",
      "2023-12-11 04:43:29,980 INFO     Valid HITS@10 at step 149999: 0.883620\n",
      "2023-12-11 04:43:29,980 INFO     Evaluating on Test Dataset...\n",
      "2023-12-11 04:43:30,683 INFO     Evaluating the model... (0/7384)\n",
      "2023-12-11 04:44:00,082 INFO     Evaluating the model... (1000/7384)\n",
      "2023-12-11 04:44:28,852 INFO     Evaluating the model... (2000/7384)\n",
      "2023-12-11 04:44:57,231 INFO     Evaluating the model... (3000/7384)\n",
      "2023-12-11 04:45:27,837 INFO     Evaluating the model... (4000/7384)\n",
      "2023-12-11 04:45:56,169 INFO     Evaluating the model... (5000/7384)\n",
      "2023-12-11 04:46:23,314 INFO     Evaluating the model... (6000/7384)\n",
      "2023-12-11 04:46:52,056 INFO     Evaluating the model... (7000/7384)\n",
      "2023-12-11 04:47:03,094 INFO     Test MRR at step 149999: 0.799674\n",
      "2023-12-11 04:47:03,095 INFO     Test MR at step 149999: 39.794459\n",
      "2023-12-11 04:47:03,095 INFO     Test HITS@1 at step 149999: 0.750563\n",
      "2023-12-11 04:47:03,095 INFO     Test HITS@3 at step 149999: 0.830568\n",
      "2023-12-11 04:47:03,095 INFO     Test HITS@10 at step 149999: 0.884554\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE FB15k 0 0 1024 256 1000 24.0 1.0 0.0001 150000 16 -de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con il metodo NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'vsegreto1/KnowledgeGraphEmbedding_NTU'\n",
      "/Users/valeriosegreto/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd vsegreto1/KnowledgeGraphEmbedding_NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-14 08:08:56,050 INFO     Model: RotatE\n",
      "2023-12-14 08:08:56,051 INFO     Data Path: data/FB15k\n",
      "2023-12-14 08:08:56,051 INFO     #entity: 14951\n",
      "2023-12-14 08:08:56,051 INFO     #relation: 1345\n",
      "2023-12-14 08:08:57,098 INFO     #train: 483142\n",
      "2023-12-14 08:08:57,238 INFO     #valid: 50000\n",
      "2023-12-14 08:08:57,402 INFO     #test: 59071\n",
      "2023-12-14 08:08:57,584 INFO     Model Parameter Configuration:\n",
      "2023-12-14 08:08:57,584 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-14 08:08:57,585 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-14 08:08:57,585 INFO     Parameter entity_embedding: torch.Size([14951, 2000]), require_grad = True\n",
      "2023-12-14 08:08:57,585 INFO     Parameter relation_embedding: torch.Size([1345, 1000]), require_grad = True\n",
      "2023-12-14 08:09:09,155 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-14 08:09:09,155 INFO     Start Training...\n",
      "2023-12-14 08:09:09,155 INFO     init_step = 0\n",
      "2023-12-14 08:09:09,155 INFO     batch_size = 1024\n",
      "2023-12-14 08:09:09,155 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-14 08:09:09,155 INFO     hidden_dim = 1000\n",
      "2023-12-14 08:09:09,156 INFO     gamma = 24.000000\n",
      "2023-12-14 08:09:09,156 INFO     negative_adversarial_sampling = True\n",
      "2023-12-14 08:09:09,156 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-14 08:09:09,156 INFO     learning_rate = 0\n",
      "2023-12-14 08:09:36,970 INFO     Training average positive_sample_loss at step 0: 3.149714\n",
      "2023-12-14 08:09:36,971 INFO     Training average negative_sample_loss at step 0: 0.053577\n",
      "2023-12-14 08:09:36,971 INFO     Training average loss at step 0: 1.601646\n",
      "2023-12-14 08:09:36,971 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-14 08:09:38,026 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-14 08:10:10,942 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-14 08:10:41,588 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-14 08:11:12,575 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-14 08:11:45,031 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-14 08:12:16,050 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-14 08:12:46,666 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-14 08:12:54,216 INFO     Valid MRR at step 0: 0.004690\n",
      "2023-12-14 08:12:54,217 INFO     Valid MR at step 0: 7081.827780\n",
      "2023-12-14 08:12:54,217 INFO     Valid HITS@1 at step 0: 0.003770\n",
      "2023-12-14 08:12:54,217 INFO     Valid HITS@3 at step 0: 0.004350\n",
      "2023-12-14 08:12:54,217 INFO     Valid HITS@10 at step 0: 0.005190\n",
      "2023-12-14 08:14:46,891 INFO     Training average positive_sample_loss at step 100: 2.249717\n",
      "2023-12-14 08:14:46,891 INFO     Training average negative_sample_loss at step 100: 0.261167\n",
      "2023-12-14 08:14:46,891 INFO     Training average loss at step 100: 1.255442\n",
      "2023-12-14 08:16:44,284 INFO     Training average positive_sample_loss at step 200: 1.038301\n",
      "2023-12-14 08:16:44,284 INFO     Training average negative_sample_loss at step 200: 0.595097\n",
      "2023-12-14 08:16:44,284 INFO     Training average loss at step 200: 0.816699\n",
      "2023-12-14 08:18:47,222 INFO     Training average positive_sample_loss at step 300: 0.805118\n",
      "2023-12-14 08:18:47,222 INFO     Training average negative_sample_loss at step 300: 0.651619\n",
      "2023-12-14 08:18:47,222 INFO     Training average loss at step 300: 0.728368\n",
      "2023-12-14 08:20:51,846 INFO     Training average positive_sample_loss at step 400: 0.723570\n",
      "2023-12-14 08:20:51,847 INFO     Training average negative_sample_loss at step 400: 0.655866\n",
      "2023-12-14 08:20:51,847 INFO     Training average loss at step 400: 0.689718\n",
      "2023-12-14 08:22:41,258 INFO     Training average positive_sample_loss at step 500: 0.680856\n",
      "2023-12-14 08:22:41,258 INFO     Training average negative_sample_loss at step 500: 0.645633\n",
      "2023-12-14 08:22:41,258 INFO     Training average loss at step 500: 0.663245\n",
      "2023-12-14 08:24:39,140 INFO     Training average positive_sample_loss at step 600: 0.652015\n",
      "2023-12-14 08:24:39,140 INFO     Training average negative_sample_loss at step 600: 0.626588\n",
      "2023-12-14 08:24:39,140 INFO     Training average loss at step 600: 0.639302\n",
      "2023-12-14 08:26:33,133 INFO     Training average positive_sample_loss at step 700: 0.623681\n",
      "2023-12-14 08:26:33,133 INFO     Training average negative_sample_loss at step 700: 0.606388\n",
      "2023-12-14 08:26:33,134 INFO     Training average loss at step 700: 0.615034\n",
      "2023-12-14 08:28:44,014 INFO     Training average positive_sample_loss at step 800: 0.596779\n",
      "2023-12-14 08:28:44,014 INFO     Training average negative_sample_loss at step 800: 0.582618\n",
      "2023-12-14 08:28:44,014 INFO     Training average loss at step 800: 0.589698\n",
      "2023-12-14 08:31:03,979 INFO     Training average positive_sample_loss at step 900: 0.569477\n",
      "2023-12-14 08:31:03,979 INFO     Training average negative_sample_loss at step 900: 0.557936\n",
      "2023-12-14 08:31:03,979 INFO     Training average loss at step 900: 0.563706\n",
      "2023-12-14 08:33:13,876 INFO     Training average positive_sample_loss at step 1000: 0.494585\n",
      "2023-12-14 08:33:13,876 INFO     Training average negative_sample_loss at step 1000: 0.512597\n",
      "2023-12-14 08:33:13,876 INFO     Training average loss at step 1000: 0.503591\n",
      "2023-12-14 08:34:59,583 INFO     Training average positive_sample_loss at step 1100: 0.467073\n",
      "2023-12-14 08:34:59,583 INFO     Training average negative_sample_loss at step 1100: 0.454303\n",
      "2023-12-14 08:34:59,583 INFO     Training average loss at step 1100: 0.460688\n",
      "2023-12-14 08:36:55,563 INFO     Training average positive_sample_loss at step 1200: 0.459837\n",
      "2023-12-14 08:36:55,564 INFO     Training average negative_sample_loss at step 1200: 0.440699\n",
      "2023-12-14 08:36:55,564 INFO     Training average loss at step 1200: 0.450268\n",
      "2023-12-14 08:38:55,467 INFO     Training average positive_sample_loss at step 1300: 0.447422\n",
      "2023-12-14 08:38:55,467 INFO     Training average negative_sample_loss at step 1300: 0.427527\n",
      "2023-12-14 08:38:55,467 INFO     Training average loss at step 1300: 0.437474\n",
      "2023-12-14 08:40:32,723 INFO     Training average positive_sample_loss at step 1400: 0.435370\n",
      "2023-12-14 08:40:32,723 INFO     Training average negative_sample_loss at step 1400: 0.413548\n",
      "2023-12-14 08:40:32,723 INFO     Training average loss at step 1400: 0.424459\n",
      "2023-12-14 08:42:31,008 INFO     Training average positive_sample_loss at step 1500: 0.422007\n",
      "2023-12-14 08:42:31,008 INFO     Training average negative_sample_loss at step 1500: 0.399751\n",
      "2023-12-14 08:42:31,009 INFO     Training average loss at step 1500: 0.410879\n",
      "2023-12-14 08:44:48,032 INFO     Training average positive_sample_loss at step 1600: 0.408362\n",
      "2023-12-14 08:44:48,032 INFO     Training average negative_sample_loss at step 1600: 0.385952\n",
      "2023-12-14 08:44:48,032 INFO     Training average loss at step 1600: 0.397157\n",
      "2023-12-14 08:47:04,535 INFO     Training average positive_sample_loss at step 1700: 0.395562\n",
      "2023-12-14 08:47:04,536 INFO     Training average negative_sample_loss at step 1700: 0.372871\n",
      "2023-12-14 08:47:04,536 INFO     Training average loss at step 1700: 0.384217\n",
      "2023-12-14 08:48:58,623 INFO     Training average positive_sample_loss at step 1800: 0.382374\n",
      "2023-12-14 08:48:58,623 INFO     Training average negative_sample_loss at step 1800: 0.359853\n",
      "2023-12-14 08:48:58,623 INFO     Training average loss at step 1800: 0.371114\n",
      "2023-12-14 08:50:59,790 INFO     Training average positive_sample_loss at step 1900: 0.358477\n",
      "2023-12-14 08:50:59,790 INFO     Training average negative_sample_loss at step 1900: 0.345439\n",
      "2023-12-14 08:50:59,790 INFO     Training average loss at step 1900: 0.351958\n",
      "2023-12-14 08:53:03,930 INFO     Training average positive_sample_loss at step 2000: 0.317094\n",
      "2023-12-14 08:53:03,930 INFO     Training average negative_sample_loss at step 2000: 0.303735\n",
      "2023-12-14 08:53:03,930 INFO     Training average loss at step 2000: 0.310415\n",
      "2023-12-14 08:54:36,018 INFO     Training average positive_sample_loss at step 2100: 0.318469\n",
      "2023-12-14 08:54:36,019 INFO     Training average negative_sample_loss at step 2100: 0.295954\n",
      "2023-12-14 08:54:36,019 INFO     Training average loss at step 2100: 0.307212\n",
      "2023-12-14 08:56:03,675 INFO     Training average positive_sample_loss at step 2200: 0.314134\n",
      "2023-12-14 08:56:03,676 INFO     Training average negative_sample_loss at step 2200: 0.290186\n",
      "2023-12-14 08:56:03,676 INFO     Training average loss at step 2200: 0.302160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-14 08:57:30,875 INFO     Training average positive_sample_loss at step 2300: 0.307869\n",
      "2023-12-14 08:57:30,875 INFO     Training average negative_sample_loss at step 2300: 0.284551\n",
      "2023-12-14 08:57:30,875 INFO     Training average loss at step 2300: 0.296210\n",
      "2023-12-14 08:58:58,893 INFO     Training average positive_sample_loss at step 2400: 0.303096\n",
      "2023-12-14 08:58:58,893 INFO     Training average negative_sample_loss at step 2400: 0.279600\n",
      "2023-12-14 08:58:58,893 INFO     Training average loss at step 2400: 0.291348\n",
      "2023-12-14 09:00:43,527 INFO     Training average positive_sample_loss at step 2500: 0.296352\n",
      "2023-12-14 09:00:43,527 INFO     Training average negative_sample_loss at step 2500: 0.273232\n",
      "2023-12-14 09:00:43,527 INFO     Training average loss at step 2500: 0.284792\n",
      "2023-12-14 09:02:35,452 INFO     Training average positive_sample_loss at step 2600: 0.289729\n",
      "2023-12-14 09:02:35,453 INFO     Training average negative_sample_loss at step 2600: 0.267333\n",
      "2023-12-14 09:02:35,453 INFO     Training average loss at step 2600: 0.278531\n",
      "2023-12-14 09:04:13,591 INFO     Training average positive_sample_loss at step 2700: 0.282420\n",
      "2023-12-14 09:04:13,591 INFO     Training average negative_sample_loss at step 2700: 0.261402\n",
      "2023-12-14 09:04:13,591 INFO     Training average loss at step 2700: 0.271911\n",
      "2023-12-14 09:05:50,761 INFO     Training average positive_sample_loss at step 2800: 0.276111\n",
      "2023-12-14 09:05:50,761 INFO     Training average negative_sample_loss at step 2800: 0.255987\n",
      "2023-12-14 09:05:50,761 INFO     Training average loss at step 2800: 0.266049\n",
      "2023-12-14 09:08:00,932 INFO     Training average positive_sample_loss at step 2900: 0.247084\n",
      "2023-12-14 09:08:00,933 INFO     Training average negative_sample_loss at step 2900: 0.237536\n",
      "2023-12-14 09:08:00,933 INFO     Training average loss at step 2900: 0.242310\n",
      "2023-12-14 09:09:36,504 INFO     Training average positive_sample_loss at step 3000: 0.242596\n",
      "2023-12-14 09:09:36,505 INFO     Training average negative_sample_loss at step 3000: 0.223811\n",
      "2023-12-14 09:09:36,505 INFO     Training average loss at step 3000: 0.233203\n",
      "2023-12-14 09:11:16,710 INFO     Training average positive_sample_loss at step 3100: 0.242440\n",
      "2023-12-14 09:11:16,710 INFO     Training average negative_sample_loss at step 3100: 0.222855\n",
      "2023-12-14 09:11:16,710 INFO     Training average loss at step 3100: 0.232647\n",
      "2023-12-14 09:13:02,206 INFO     Training average positive_sample_loss at step 3200: 0.240365\n",
      "2023-12-14 09:13:02,206 INFO     Training average negative_sample_loss at step 3200: 0.220733\n",
      "2023-12-14 09:13:02,206 INFO     Training average loss at step 3200: 0.230549\n",
      "2023-12-14 09:15:14,601 INFO     Training average positive_sample_loss at step 3300: 0.238497\n",
      "2023-12-14 09:15:14,602 INFO     Training average negative_sample_loss at step 3300: 0.219986\n",
      "2023-12-14 09:15:14,602 INFO     Training average loss at step 3300: 0.229241\n",
      "2023-12-14 09:17:11,742 INFO     Training average positive_sample_loss at step 3400: 0.236116\n",
      "2023-12-14 09:17:11,742 INFO     Training average negative_sample_loss at step 3400: 0.217253\n",
      "2023-12-14 09:17:11,742 INFO     Training average loss at step 3400: 0.226685\n",
      "2023-12-14 09:19:03,531 INFO     Training average positive_sample_loss at step 3500: 0.231877\n",
      "2023-12-14 09:19:03,531 INFO     Training average negative_sample_loss at step 3500: 0.214159\n",
      "2023-12-14 09:19:03,531 INFO     Training average loss at step 3500: 0.223018\n",
      "2023-12-14 09:20:59,791 INFO     Training average positive_sample_loss at step 3600: 0.229352\n",
      "2023-12-14 09:20:59,792 INFO     Training average negative_sample_loss at step 3600: 0.212609\n",
      "2023-12-14 09:20:59,792 INFO     Training average loss at step 3600: 0.220980\n",
      "2023-12-14 09:22:57,125 INFO     Training average positive_sample_loss at step 3700: 0.225350\n",
      "2023-12-14 09:22:57,125 INFO     Training average negative_sample_loss at step 3700: 0.208790\n",
      "2023-12-14 09:22:57,126 INFO     Training average loss at step 3700: 0.217070\n",
      "2023-12-14 09:25:04,961 INFO     Training average positive_sample_loss at step 3800: 0.214372\n",
      "2023-12-14 09:25:04,962 INFO     Training average negative_sample_loss at step 3800: 0.204619\n",
      "2023-12-14 09:25:04,962 INFO     Training average loss at step 3800: 0.209496\n",
      "2023-12-14 09:26:58,081 INFO     Training average positive_sample_loss at step 3900: 0.200173\n",
      "2023-12-14 09:26:58,082 INFO     Training average negative_sample_loss at step 3900: 0.186969\n",
      "2023-12-14 09:26:58,082 INFO     Training average loss at step 3900: 0.193571\n",
      "2023-12-14 09:28:58,984 INFO     Training average positive_sample_loss at step 4000: 0.202009\n",
      "2023-12-14 09:28:58,984 INFO     Training average negative_sample_loss at step 4000: 0.187289\n",
      "2023-12-14 09:28:58,984 INFO     Training average loss at step 4000: 0.194649\n",
      "2023-12-14 09:30:53,900 INFO     Training average positive_sample_loss at step 4100: 0.202265\n",
      "2023-12-14 09:30:53,900 INFO     Training average negative_sample_loss at step 4100: 0.186390\n",
      "2023-12-14 09:30:53,900 INFO     Training average loss at step 4100: 0.194328\n",
      "2023-12-14 09:32:36,551 INFO     Training average positive_sample_loss at step 4200: 0.202049\n",
      "2023-12-14 09:32:36,551 INFO     Training average negative_sample_loss at step 4200: 0.186821\n",
      "2023-12-14 09:32:36,551 INFO     Training average loss at step 4200: 0.194435\n",
      "2023-12-14 09:34:31,959 INFO     Training average positive_sample_loss at step 4300: 0.201143\n",
      "2023-12-14 09:34:31,959 INFO     Training average negative_sample_loss at step 4300: 0.186178\n",
      "2023-12-14 09:34:31,959 INFO     Training average loss at step 4300: 0.193661\n",
      "2023-12-14 09:36:30,621 INFO     Training average positive_sample_loss at step 4400: 0.199352\n",
      "2023-12-14 09:36:30,622 INFO     Training average negative_sample_loss at step 4400: 0.184853\n",
      "2023-12-14 09:36:30,622 INFO     Training average loss at step 4400: 0.192102\n",
      "2023-12-14 09:38:20,697 INFO     Training average positive_sample_loss at step 4500: 0.198003\n",
      "2023-12-14 09:38:20,697 INFO     Training average negative_sample_loss at step 4500: 0.183690\n",
      "2023-12-14 09:38:20,697 INFO     Training average loss at step 4500: 0.190847\n",
      "2023-12-14 09:40:17,632 INFO     Training average positive_sample_loss at step 4600: 0.195865\n",
      "2023-12-14 09:40:17,633 INFO     Training average negative_sample_loss at step 4600: 0.182186\n",
      "2023-12-14 09:40:17,633 INFO     Training average loss at step 4600: 0.189026\n",
      "2023-12-14 09:41:53,815 INFO     Training average positive_sample_loss at step 4700: 0.194119\n",
      "2023-12-14 09:41:53,815 INFO     Training average negative_sample_loss at step 4700: 0.181134\n",
      "2023-12-14 09:41:53,815 INFO     Training average loss at step 4700: 0.187627\n",
      "2023-12-14 09:43:57,687 INFO     Training average positive_sample_loss at step 4800: 0.175237\n",
      "2023-12-14 09:43:57,687 INFO     Training average negative_sample_loss at step 4800: 0.169173\n",
      "2023-12-14 09:43:57,687 INFO     Training average loss at step 4800: 0.172205\n",
      "2023-12-14 09:45:50,058 INFO     Training average positive_sample_loss at step 4900: 0.178030\n",
      "2023-12-14 09:45:50,058 INFO     Training average negative_sample_loss at step 4900: 0.164968\n",
      "2023-12-14 09:45:50,058 INFO     Training average loss at step 4900: 0.171499\n",
      "2023-12-14 09:47:50,663 INFO     Training average positive_sample_loss at step 5000: 0.179070\n",
      "2023-12-14 09:47:50,663 INFO     Training average negative_sample_loss at step 5000: 0.166004\n",
      "2023-12-14 09:47:50,663 INFO     Training average loss at step 5000: 0.172537\n",
      "2023-12-14 09:49:34,656 INFO     Training average positive_sample_loss at step 5100: 0.178983\n",
      "2023-12-14 09:49:34,657 INFO     Training average negative_sample_loss at step 5100: 0.166200\n",
      "2023-12-14 09:49:34,657 INFO     Training average loss at step 5100: 0.172591\n",
      "2023-12-14 09:51:30,542 INFO     Training average positive_sample_loss at step 5200: 0.179816\n",
      "2023-12-14 09:51:30,543 INFO     Training average negative_sample_loss at step 5200: 0.166631\n",
      "2023-12-14 09:51:30,543 INFO     Training average loss at step 5200: 0.173223\n",
      "2023-12-14 09:53:32,928 INFO     Training average positive_sample_loss at step 5300: 0.178617\n",
      "2023-12-14 09:53:32,929 INFO     Training average negative_sample_loss at step 5300: 0.165991\n",
      "2023-12-14 09:53:32,929 INFO     Training average loss at step 5300: 0.172304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-14 09:55:32,877 INFO     Training average positive_sample_loss at step 5400: 0.178166\n",
      "2023-12-14 09:55:32,877 INFO     Training average negative_sample_loss at step 5400: 0.165957\n",
      "2023-12-14 09:55:32,877 INFO     Training average loss at step 5400: 0.172061\n",
      "2023-12-14 09:57:15,855 INFO     Training average positive_sample_loss at step 5500: 0.177156\n",
      "2023-12-14 09:57:15,855 INFO     Training average negative_sample_loss at step 5500: 0.165236\n",
      "2023-12-14 09:57:15,855 INFO     Training average loss at step 5500: 0.171196\n",
      "2023-12-14 09:59:07,477 INFO     Training average positive_sample_loss at step 5600: 0.174932\n",
      "2023-12-14 09:59:07,477 INFO     Training average negative_sample_loss at step 5600: 0.163624\n",
      "2023-12-14 09:59:07,477 INFO     Training average loss at step 5600: 0.169278\n",
      "2023-12-14 10:01:00,656 INFO     Training average positive_sample_loss at step 5700: 0.166981\n",
      "2023-12-14 10:01:00,656 INFO     Training average negative_sample_loss at step 5700: 0.160219\n",
      "2023-12-14 10:01:00,656 INFO     Training average loss at step 5700: 0.163600\n",
      "2023-12-14 10:02:40,811 INFO     Training average positive_sample_loss at step 5800: 0.160085\n",
      "2023-12-14 10:02:40,811 INFO     Training average negative_sample_loss at step 5800: 0.149152\n",
      "2023-12-14 10:02:40,811 INFO     Training average loss at step 5800: 0.154619\n",
      "2023-12-14 10:04:32,015 INFO     Training average positive_sample_loss at step 5900: 0.162692\n",
      "2023-12-14 10:04:32,015 INFO     Training average negative_sample_loss at step 5900: 0.150720\n",
      "2023-12-14 10:04:32,015 INFO     Training average loss at step 5900: 0.156706\n",
      "2023-12-14 10:06:09,678 INFO     Training average positive_sample_loss at step 6000: 0.164124\n",
      "2023-12-14 10:06:09,678 INFO     Training average negative_sample_loss at step 6000: 0.152068\n",
      "2023-12-14 10:06:09,678 INFO     Training average loss at step 6000: 0.158096\n",
      "2023-12-14 10:08:08,825 INFO     Training average positive_sample_loss at step 6100: 0.164668\n",
      "2023-12-14 10:08:08,825 INFO     Training average negative_sample_loss at step 6100: 0.152477\n",
      "2023-12-14 10:08:08,825 INFO     Training average loss at step 6100: 0.158572\n",
      "2023-12-14 10:09:48,613 INFO     Training average positive_sample_loss at step 6200: 0.164969\n",
      "2023-12-14 10:09:48,614 INFO     Training average negative_sample_loss at step 6200: 0.153606\n",
      "2023-12-14 10:09:48,614 INFO     Training average loss at step 6200: 0.159287\n",
      "2023-12-14 10:11:48,718 INFO     Training average positive_sample_loss at step 6300: 0.163944\n",
      "2023-12-14 10:11:48,718 INFO     Training average negative_sample_loss at step 6300: 0.152163\n",
      "2023-12-14 10:11:48,718 INFO     Training average loss at step 6300: 0.158053\n",
      "2023-12-14 10:13:46,275 INFO     Training average positive_sample_loss at step 6400: 0.163722\n",
      "2023-12-14 10:13:46,275 INFO     Training average negative_sample_loss at step 6400: 0.152766\n",
      "2023-12-14 10:13:46,275 INFO     Training average loss at step 6400: 0.158244\n",
      "2023-12-14 10:15:36,808 INFO     Training average positive_sample_loss at step 6500: 0.164272\n",
      "2023-12-14 10:15:36,808 INFO     Training average negative_sample_loss at step 6500: 0.153040\n",
      "2023-12-14 10:15:36,808 INFO     Training average loss at step 6500: 0.158656\n",
      "2023-12-14 10:17:28,629 INFO     Training average positive_sample_loss at step 6600: 0.161921\n",
      "2023-12-14 10:17:28,629 INFO     Training average negative_sample_loss at step 6600: 0.151310\n",
      "2023-12-14 10:17:28,629 INFO     Training average loss at step 6600: 0.156615\n",
      "2023-12-14 10:19:33,471 INFO     Training average positive_sample_loss at step 6700: 0.146871\n",
      "2023-12-14 10:19:33,471 INFO     Training average negative_sample_loss at step 6700: 0.140847\n",
      "2023-12-14 10:19:33,471 INFO     Training average loss at step 6700: 0.143859\n",
      "2023-12-14 10:21:31,599 INFO     Training average positive_sample_loss at step 6800: 0.150615\n",
      "2023-12-14 10:21:31,599 INFO     Training average negative_sample_loss at step 6800: 0.139494\n",
      "2023-12-14 10:21:31,599 INFO     Training average loss at step 6800: 0.145054\n",
      "2023-12-14 10:23:14,243 INFO     Training average positive_sample_loss at step 6900: 0.152515\n",
      "2023-12-14 10:23:14,243 INFO     Training average negative_sample_loss at step 6900: 0.141157\n",
      "2023-12-14 10:23:14,243 INFO     Training average loss at step 6900: 0.146836\n",
      "2023-12-14 10:25:00,416 INFO     Training average positive_sample_loss at step 7000: 0.153992\n",
      "2023-12-14 10:25:00,416 INFO     Training average negative_sample_loss at step 7000: 0.142096\n",
      "2023-12-14 10:25:00,416 INFO     Training average loss at step 7000: 0.148044\n",
      "2023-12-14 10:26:37,861 INFO     Training average positive_sample_loss at step 7100: 0.154454\n",
      "2023-12-14 10:26:37,861 INFO     Training average negative_sample_loss at step 7100: 0.143580\n",
      "2023-12-14 10:26:37,861 INFO     Training average loss at step 7100: 0.149017\n",
      "2023-12-14 10:28:28,474 INFO     Training average positive_sample_loss at step 7200: 0.154942\n",
      "2023-12-14 10:28:28,474 INFO     Training average negative_sample_loss at step 7200: 0.143469\n",
      "2023-12-14 10:28:28,474 INFO     Training average loss at step 7200: 0.149206\n",
      "2023-12-14 10:30:11,437 INFO     Training average positive_sample_loss at step 7300: 0.154604\n",
      "2023-12-14 10:30:11,437 INFO     Training average negative_sample_loss at step 7300: 0.143526\n",
      "2023-12-14 10:30:11,437 INFO     Training average loss at step 7300: 0.149065\n",
      "2023-12-14 10:31:40,943 INFO     Training average positive_sample_loss at step 7400: 0.154394\n",
      "2023-12-14 10:31:40,944 INFO     Training average negative_sample_loss at step 7400: 0.143429\n",
      "2023-12-14 10:31:40,944 INFO     Training average loss at step 7400: 0.148911\n",
      "2023-12-14 10:33:29,696 INFO     Training average positive_sample_loss at step 7500: 0.153028\n",
      "2023-12-14 10:33:29,696 INFO     Training average negative_sample_loss at step 7500: 0.142324\n",
      "2023-12-14 10:33:29,696 INFO     Training average loss at step 7500: 0.147676\n",
      "2023-12-14 10:35:31,531 INFO     Training average positive_sample_loss at step 7600: 0.144130\n",
      "2023-12-14 10:35:31,532 INFO     Training average negative_sample_loss at step 7600: 0.137905\n",
      "2023-12-14 10:35:31,532 INFO     Training average loss at step 7600: 0.141017\n",
      "2023-12-14 10:37:19,898 INFO     Training average positive_sample_loss at step 7700: 0.141391\n",
      "2023-12-14 10:37:19,898 INFO     Training average negative_sample_loss at step 7700: 0.130297\n",
      "2023-12-14 10:37:19,898 INFO     Training average loss at step 7700: 0.135844\n",
      "2023-12-14 10:39:19,306 INFO     Training average positive_sample_loss at step 7800: 0.143585\n",
      "2023-12-14 10:39:19,307 INFO     Training average negative_sample_loss at step 7800: 0.132402\n",
      "2023-12-14 10:39:19,307 INFO     Training average loss at step 7800: 0.137994\n",
      "2023-12-14 10:41:01,932 INFO     Training average positive_sample_loss at step 7900: 0.145355\n",
      "2023-12-14 10:41:01,932 INFO     Training average negative_sample_loss at step 7900: 0.134196\n",
      "2023-12-14 10:41:01,932 INFO     Training average loss at step 7900: 0.139775\n",
      "2023-12-14 10:43:01,255 INFO     Training average positive_sample_loss at step 8000: 0.146456\n",
      "2023-12-14 10:43:01,256 INFO     Training average negative_sample_loss at step 8000: 0.135060\n",
      "2023-12-14 10:43:01,256 INFO     Training average loss at step 8000: 0.140758\n",
      "2023-12-14 10:44:49,383 INFO     Training average positive_sample_loss at step 8100: 0.146731\n",
      "2023-12-14 10:44:49,383 INFO     Training average negative_sample_loss at step 8100: 0.135690\n",
      "2023-12-14 10:44:49,383 INFO     Training average loss at step 8100: 0.141210\n",
      "2023-12-14 10:46:34,039 INFO     Training average positive_sample_loss at step 8200: 0.147401\n",
      "2023-12-14 10:46:34,039 INFO     Training average negative_sample_loss at step 8200: 0.136388\n",
      "2023-12-14 10:46:34,040 INFO     Training average loss at step 8200: 0.141894\n",
      "2023-12-14 10:48:21,623 INFO     Training average positive_sample_loss at step 8300: 0.147427\n",
      "2023-12-14 10:48:21,624 INFO     Training average negative_sample_loss at step 8300: 0.135902\n",
      "2023-12-14 10:48:21,624 INFO     Training average loss at step 8300: 0.141664\n",
      "2023-12-14 10:50:22,978 INFO     Training average positive_sample_loss at step 8400: 0.145769\n",
      "2023-12-14 10:50:22,979 INFO     Training average negative_sample_loss at step 8400: 0.135263\n",
      "2023-12-14 10:50:22,979 INFO     Training average loss at step 8400: 0.140516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-14 10:52:26,528 INFO     Training average positive_sample_loss at step 8500: 0.144800\n",
      "2023-12-14 10:52:26,529 INFO     Training average negative_sample_loss at step 8500: 0.134871\n",
      "2023-12-14 10:52:26,529 INFO     Training average loss at step 8500: 0.139835\n",
      "2023-12-14 10:54:13,637 INFO     Training average positive_sample_loss at step 8600: 0.132542\n",
      "2023-12-14 10:54:13,637 INFO     Training average negative_sample_loss at step 8600: 0.124843\n",
      "2023-12-14 10:54:13,637 INFO     Training average loss at step 8600: 0.128693\n",
      "2023-12-14 10:56:07,119 INFO     Training average positive_sample_loss at step 8700: 0.136833\n",
      "2023-12-14 10:56:07,120 INFO     Training average negative_sample_loss at step 8700: 0.125575\n",
      "2023-12-14 10:56:07,120 INFO     Training average loss at step 8700: 0.131204\n",
      "2023-12-14 10:57:49,398 INFO     Training average positive_sample_loss at step 8800: 0.137971\n",
      "2023-12-14 10:57:49,398 INFO     Training average negative_sample_loss at step 8800: 0.126802\n",
      "2023-12-14 10:57:49,398 INFO     Training average loss at step 8800: 0.132387\n",
      "2023-12-14 10:59:46,475 INFO     Training average positive_sample_loss at step 8900: 0.139797\n",
      "2023-12-14 10:59:46,476 INFO     Training average negative_sample_loss at step 8900: 0.128571\n",
      "2023-12-14 10:59:46,476 INFO     Training average loss at step 8900: 0.134184\n",
      "2023-12-14 11:01:57,128 INFO     Training average positive_sample_loss at step 9000: 0.140923\n",
      "2023-12-14 11:01:57,128 INFO     Training average negative_sample_loss at step 9000: 0.129253\n",
      "2023-12-14 11:01:57,128 INFO     Training average loss at step 9000: 0.135088\n",
      "2023-12-14 11:03:56,262 INFO     Training average positive_sample_loss at step 9100: 0.140721\n",
      "2023-12-14 11:03:56,263 INFO     Training average negative_sample_loss at step 9100: 0.129657\n",
      "2023-12-14 11:03:56,263 INFO     Training average loss at step 9100: 0.135189\n",
      "2023-12-14 11:06:09,115 INFO     Training average positive_sample_loss at step 9200: 0.141902\n",
      "2023-12-14 11:06:09,115 INFO     Training average negative_sample_loss at step 9200: 0.131075\n",
      "2023-12-14 11:06:09,115 INFO     Training average loss at step 9200: 0.136489\n",
      "2023-12-14 11:08:23,042 INFO     Training average positive_sample_loss at step 9300: 0.140938\n",
      "2023-12-14 11:08:23,043 INFO     Training average negative_sample_loss at step 9300: 0.130211\n",
      "2023-12-14 11:08:23,043 INFO     Training average loss at step 9300: 0.135574\n",
      "2023-12-14 11:10:13,379 INFO     Training average positive_sample_loss at step 9400: 0.140320\n",
      "2023-12-14 11:10:13,379 INFO     Training average negative_sample_loss at step 9400: 0.129269\n",
      "2023-12-14 11:10:13,379 INFO     Training average loss at step 9400: 0.134795\n",
      "2023-12-14 11:12:08,580 INFO     Training average positive_sample_loss at step 9500: 0.131655\n",
      "2023-12-14 11:12:08,580 INFO     Training average negative_sample_loss at step 9500: 0.124924\n",
      "2023-12-14 11:12:08,580 INFO     Training average loss at step 9500: 0.128290\n",
      "2023-12-14 11:13:48,280 INFO     Training average positive_sample_loss at step 9600: 0.131256\n",
      "2023-12-14 11:13:48,281 INFO     Training average negative_sample_loss at step 9600: 0.120212\n",
      "2023-12-14 11:13:48,281 INFO     Training average loss at step 9600: 0.125734\n",
      "2023-12-14 11:15:39,437 INFO     Training average positive_sample_loss at step 9700: 0.132827\n",
      "2023-12-14 11:15:39,438 INFO     Training average negative_sample_loss at step 9700: 0.121144\n",
      "2023-12-14 11:15:39,438 INFO     Training average loss at step 9700: 0.126985\n",
      "2023-12-14 11:17:23,476 INFO     Training average positive_sample_loss at step 9800: 0.134186\n",
      "2023-12-14 11:17:23,477 INFO     Training average negative_sample_loss at step 9800: 0.122832\n",
      "2023-12-14 11:17:23,477 INFO     Training average loss at step 9800: 0.128509\n",
      "2023-12-14 11:19:04,374 INFO     Training average positive_sample_loss at step 9900: 0.135526\n",
      "2023-12-14 11:19:04,374 INFO     Training average negative_sample_loss at step 9900: 0.124072\n",
      "2023-12-14 11:19:04,374 INFO     Training average loss at step 9900: 0.129799\n",
      "2023-12-14 11:21:08,234 INFO     Training average positive_sample_loss at step 10000: 0.136358\n",
      "2023-12-14 11:21:08,235 INFO     Training average negative_sample_loss at step 10000: 0.124756\n",
      "2023-12-14 11:21:08,235 INFO     Training average loss at step 10000: 0.130557\n",
      "2023-12-14 11:21:08,235 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-14 11:21:09,161 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-14 11:21:40,571 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-14 11:22:11,502 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-14 11:22:43,049 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-14 11:23:14,995 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-14 11:23:45,818 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-14 11:24:52,193 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-14 11:25:17,534 INFO     Valid MRR at step 10000: 0.345440\n",
      "2023-12-14 11:25:17,534 INFO     Valid MR at step 10000: 580.141470\n",
      "2023-12-14 11:25:17,534 INFO     Valid HITS@1 at step 10000: 0.274660\n",
      "2023-12-14 11:25:17,534 INFO     Valid HITS@3 at step 10000: 0.356360\n",
      "2023-12-14 11:25:17,534 INFO     Valid HITS@10 at step 10000: 0.507850\n",
      "2023-12-14 11:26:50,543 INFO     Training average positive_sample_loss at step 10100: 0.136026\n",
      "2023-12-14 11:26:50,543 INFO     Training average negative_sample_loss at step 10100: 0.124887\n",
      "2023-12-14 11:26:50,544 INFO     Training average loss at step 10100: 0.130457\n",
      "2023-12-14 11:28:32,580 INFO     Training average positive_sample_loss at step 10200: 0.136305\n",
      "2023-12-14 11:28:32,581 INFO     Training average negative_sample_loss at step 10200: 0.125819\n",
      "2023-12-14 11:28:32,581 INFO     Training average loss at step 10200: 0.131062\n",
      "2023-12-14 11:30:25,817 INFO     Training average positive_sample_loss at step 10300: 0.135580\n",
      "2023-12-14 11:30:25,817 INFO     Training average negative_sample_loss at step 10300: 0.124479\n",
      "2023-12-14 11:30:25,817 INFO     Training average loss at step 10300: 0.130030\n",
      "2023-12-14 11:32:27,091 INFO     Training average positive_sample_loss at step 10400: 0.133209\n",
      "2023-12-14 11:32:27,092 INFO     Training average negative_sample_loss at step 10400: 0.124619\n",
      "2023-12-14 11:32:27,092 INFO     Training average loss at step 10400: 0.128914\n",
      "2023-12-14 11:34:09,796 INFO     Training average positive_sample_loss at step 10500: 0.124221\n",
      "2023-12-14 11:34:09,796 INFO     Training average negative_sample_loss at step 10500: 0.115064\n",
      "2023-12-14 11:34:09,796 INFO     Training average loss at step 10500: 0.119642\n",
      "2023-12-14 11:36:04,965 INFO     Training average positive_sample_loss at step 10600: 0.129087\n",
      "2023-12-14 11:36:04,965 INFO     Training average negative_sample_loss at step 10600: 0.117517\n",
      "2023-12-14 11:36:04,965 INFO     Training average loss at step 10600: 0.123302\n",
      "2023-12-14 11:37:42,506 INFO     Training average positive_sample_loss at step 10700: 0.130408\n",
      "2023-12-14 11:37:42,506 INFO     Training average negative_sample_loss at step 10700: 0.118789\n",
      "2023-12-14 11:37:42,507 INFO     Training average loss at step 10700: 0.124598\n",
      "2023-12-14 11:39:32,887 INFO     Training average positive_sample_loss at step 10800: 0.130568\n",
      "2023-12-14 11:39:32,887 INFO     Training average negative_sample_loss at step 10800: 0.119282\n",
      "2023-12-14 11:39:32,888 INFO     Training average loss at step 10800: 0.124925\n",
      "2023-12-14 11:41:08,416 INFO     Training average positive_sample_loss at step 10900: 0.132380\n",
      "2023-12-14 11:41:08,417 INFO     Training average negative_sample_loss at step 10900: 0.120800\n",
      "2023-12-14 11:41:08,417 INFO     Training average loss at step 10900: 0.126590\n",
      "2023-12-14 11:42:53,957 INFO     Training average positive_sample_loss at step 11000: 0.131492\n",
      "2023-12-14 11:42:53,958 INFO     Training average negative_sample_loss at step 11000: 0.120143\n",
      "2023-12-14 11:42:53,958 INFO     Training average loss at step 11000: 0.125817\n",
      "2023-12-14 11:44:51,053 INFO     Training average positive_sample_loss at step 11100: 0.132751\n",
      "2023-12-14 11:44:51,053 INFO     Training average negative_sample_loss at step 11100: 0.120989\n",
      "2023-12-14 11:44:51,053 INFO     Training average loss at step 11100: 0.126870\n",
      "2023-12-14 11:46:42,624 INFO     Training average positive_sample_loss at step 11200: 0.133041\n",
      "2023-12-14 11:46:42,624 INFO     Training average negative_sample_loss at step 11200: 0.122400\n",
      "2023-12-14 11:46:42,624 INFO     Training average loss at step 11200: 0.127720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-14 11:48:25,144 INFO     Training average positive_sample_loss at step 11300: 0.132167\n",
      "2023-12-14 11:48:25,144 INFO     Training average negative_sample_loss at step 11300: 0.121029\n",
      "2023-12-14 11:48:25,144 INFO     Training average loss at step 11300: 0.126598\n",
      "2023-12-14 11:50:27,635 INFO     Training average positive_sample_loss at step 11400: 0.122837\n",
      "2023-12-14 11:50:27,635 INFO     Training average negative_sample_loss at step 11400: 0.115234\n",
      "2023-12-14 11:50:27,635 INFO     Training average loss at step 11400: 0.119035\n",
      "2023-12-14 11:52:04,449 INFO     Training average positive_sample_loss at step 11500: 0.123801\n",
      "2023-12-14 11:52:04,450 INFO     Training average negative_sample_loss at step 11500: 0.112970\n",
      "2023-12-14 11:52:04,450 INFO     Training average loss at step 11500: 0.118386\n",
      "2023-12-14 11:53:53,586 INFO     Training average positive_sample_loss at step 11600: 0.125647\n",
      "2023-12-14 11:53:53,586 INFO     Training average negative_sample_loss at step 11600: 0.113901\n",
      "2023-12-14 11:53:53,586 INFO     Training average loss at step 11600: 0.119774\n",
      "2023-12-14 11:55:39,286 INFO     Training average positive_sample_loss at step 11700: 0.127152\n",
      "2023-12-14 11:55:39,286 INFO     Training average negative_sample_loss at step 11700: 0.115618\n",
      "2023-12-14 11:55:39,286 INFO     Training average loss at step 11700: 0.121385\n",
      "2023-12-14 11:57:06,500 INFO     Training average positive_sample_loss at step 11800: 0.128923\n",
      "2023-12-14 11:57:06,500 INFO     Training average negative_sample_loss at step 11800: 0.117172\n",
      "2023-12-14 11:57:06,500 INFO     Training average loss at step 11800: 0.123048\n",
      "2023-12-14 11:58:43,862 INFO     Training average positive_sample_loss at step 11900: 0.129267\n",
      "2023-12-14 11:58:43,862 INFO     Training average negative_sample_loss at step 11900: 0.118062\n",
      "2023-12-14 11:58:43,862 INFO     Training average loss at step 11900: 0.123664\n",
      "2023-12-14 12:00:22,824 INFO     Training average positive_sample_loss at step 12000: 0.129387\n",
      "2023-12-14 12:00:22,825 INFO     Training average negative_sample_loss at step 12000: 0.118094\n",
      "2023-12-14 12:00:22,825 INFO     Training average loss at step 12000: 0.123740\n",
      "2023-12-14 12:02:35,905 INFO     Training average positive_sample_loss at step 12100: 0.129822\n",
      "2023-12-14 12:02:35,905 INFO     Training average negative_sample_loss at step 12100: 0.118611\n",
      "2023-12-14 12:02:35,905 INFO     Training average loss at step 12100: 0.124216\n",
      "2023-12-14 12:04:25,966 INFO     Training average positive_sample_loss at step 12200: 0.129656\n",
      "2023-12-14 12:04:25,966 INFO     Training average negative_sample_loss at step 12200: 0.118293\n",
      "2023-12-14 12:04:25,966 INFO     Training average loss at step 12200: 0.123974\n",
      "2023-12-14 12:06:25,502 INFO     Training average positive_sample_loss at step 12300: 0.124220\n",
      "2023-12-14 12:06:25,502 INFO     Training average negative_sample_loss at step 12300: 0.116366\n",
      "2023-12-14 12:06:25,503 INFO     Training average loss at step 12300: 0.120293\n",
      "2023-12-14 12:08:15,585 INFO     Training average positive_sample_loss at step 12400: 0.119942\n",
      "2023-12-14 12:08:15,585 INFO     Training average negative_sample_loss at step 12400: 0.108805\n",
      "2023-12-14 12:08:15,585 INFO     Training average loss at step 12400: 0.114373\n",
      "2023-12-14 12:09:51,288 INFO     Training average positive_sample_loss at step 12500: 0.122363\n",
      "2023-12-14 12:09:51,288 INFO     Training average negative_sample_loss at step 12500: 0.111129\n",
      "2023-12-14 12:09:51,288 INFO     Training average loss at step 12500: 0.116746\n",
      "2023-12-14 12:11:27,919 INFO     Training average positive_sample_loss at step 12600: 0.123888\n",
      "2023-12-14 12:11:27,919 INFO     Training average negative_sample_loss at step 12600: 0.112282\n",
      "2023-12-14 12:11:27,919 INFO     Training average loss at step 12600: 0.118085\n",
      "2023-12-14 12:13:25,374 INFO     Training average positive_sample_loss at step 12700: 0.125042\n",
      "2023-12-14 12:13:25,375 INFO     Training average negative_sample_loss at step 12700: 0.113151\n",
      "2023-12-14 12:13:25,375 INFO     Training average loss at step 12700: 0.119096\n",
      "2023-12-14 12:15:09,369 INFO     Training average positive_sample_loss at step 12800: 0.126448\n",
      "2023-12-14 12:15:09,369 INFO     Training average negative_sample_loss at step 12800: 0.114817\n",
      "2023-12-14 12:15:09,369 INFO     Training average loss at step 12800: 0.120632\n",
      "2023-12-14 12:16:50,531 INFO     Training average positive_sample_loss at step 12900: 0.126630\n",
      "2023-12-14 12:16:50,532 INFO     Training average negative_sample_loss at step 12900: 0.115214\n",
      "2023-12-14 12:16:50,532 INFO     Training average loss at step 12900: 0.120922\n",
      "2023-12-14 12:18:48,278 INFO     Training average positive_sample_loss at step 13000: 0.127520\n",
      "2023-12-14 12:18:48,278 INFO     Training average negative_sample_loss at step 13000: 0.115842\n",
      "2023-12-14 12:18:48,278 INFO     Training average loss at step 13000: 0.121681\n",
      "2023-12-14 12:20:52,532 INFO     Training average positive_sample_loss at step 13100: 0.126425\n",
      "2023-12-14 12:20:52,532 INFO     Training average negative_sample_loss at step 13100: 0.115677\n",
      "2023-12-14 12:20:52,532 INFO     Training average loss at step 13100: 0.121051\n",
      "2023-12-14 12:22:52,116 INFO     Training average positive_sample_loss at step 13200: 0.126649\n",
      "2023-12-14 12:22:52,117 INFO     Training average negative_sample_loss at step 13200: 0.115149\n",
      "2023-12-14 12:22:52,117 INFO     Training average loss at step 13200: 0.120899\n",
      "2023-12-14 12:25:03,632 INFO     Training average positive_sample_loss at step 13300: 0.116336\n",
      "2023-12-14 12:25:03,632 INFO     Training average negative_sample_loss at step 13300: 0.108648\n",
      "2023-12-14 12:25:03,632 INFO     Training average loss at step 13300: 0.112492\n",
      "2023-12-14 12:26:53,112 INFO     Training average positive_sample_loss at step 13400: 0.119041\n",
      "2023-12-14 12:26:53,113 INFO     Training average negative_sample_loss at step 13400: 0.107612\n",
      "2023-12-14 12:26:53,113 INFO     Training average loss at step 13400: 0.113326\n",
      "2023-12-14 12:28:45,196 INFO     Training average positive_sample_loss at step 13500: 0.121369\n",
      "2023-12-14 12:28:45,196 INFO     Training average negative_sample_loss at step 13500: 0.109846\n",
      "2023-12-14 12:28:45,196 INFO     Training average loss at step 13500: 0.115607\n",
      "2023-12-14 12:30:33,697 INFO     Training average positive_sample_loss at step 13600: 0.122038\n",
      "2023-12-14 12:30:33,698 INFO     Training average negative_sample_loss at step 13600: 0.110689\n",
      "2023-12-14 12:30:33,698 INFO     Training average loss at step 13600: 0.116364\n",
      "2023-12-14 12:32:23,521 INFO     Training average positive_sample_loss at step 13700: 0.123649\n",
      "2023-12-14 12:32:23,522 INFO     Training average negative_sample_loss at step 13700: 0.111676\n",
      "2023-12-14 12:32:23,522 INFO     Training average loss at step 13700: 0.117662\n",
      "2023-12-14 12:34:01,937 INFO     Training average positive_sample_loss at step 13800: 0.124192\n",
      "2023-12-14 12:34:01,937 INFO     Training average negative_sample_loss at step 13800: 0.112416\n",
      "2023-12-14 12:34:01,937 INFO     Training average loss at step 13800: 0.118304\n",
      "2023-12-14 12:35:44,999 INFO     Training average positive_sample_loss at step 13900: 0.124516\n",
      "2023-12-14 12:35:45,000 INFO     Training average negative_sample_loss at step 13900: 0.112960\n",
      "2023-12-14 12:35:45,000 INFO     Training average loss at step 13900: 0.118738\n",
      "2023-12-14 12:37:38,768 INFO     Training average positive_sample_loss at step 14000: 0.124286\n",
      "2023-12-14 12:37:38,769 INFO     Training average negative_sample_loss at step 14000: 0.112828\n",
      "2023-12-14 12:37:38,769 INFO     Training average loss at step 14000: 0.118557\n",
      "2023-12-14 12:39:41,628 INFO     Training average positive_sample_loss at step 14100: 0.124873\n",
      "2023-12-14 12:39:41,628 INFO     Training average negative_sample_loss at step 14100: 0.113536\n",
      "2023-12-14 12:39:41,628 INFO     Training average loss at step 14100: 0.119205\n",
      "2023-12-14 12:41:53,246 INFO     Training average positive_sample_loss at step 14200: 0.118995\n",
      "2023-12-14 12:41:53,247 INFO     Training average negative_sample_loss at step 14200: 0.110899\n",
      "2023-12-14 12:41:53,247 INFO     Training average loss at step 14200: 0.114947\n",
      "2023-12-14 12:43:30,553 INFO     Training average positive_sample_loss at step 14300: 0.116262\n",
      "2023-12-14 12:43:30,553 INFO     Training average negative_sample_loss at step 14300: 0.104950\n",
      "2023-12-14 12:43:30,553 INFO     Training average loss at step 14300: 0.110606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-14 12:45:21,429 INFO     Training average positive_sample_loss at step 14400: 0.117713\n",
      "2023-12-14 12:45:21,429 INFO     Training average negative_sample_loss at step 14400: 0.106075\n",
      "2023-12-14 12:45:21,429 INFO     Training average loss at step 14400: 0.111894\n",
      "2023-12-14 12:47:15,579 INFO     Training average positive_sample_loss at step 14500: 0.120382\n",
      "2023-12-14 12:47:15,580 INFO     Training average negative_sample_loss at step 14500: 0.108582\n",
      "2023-12-14 12:47:15,580 INFO     Training average loss at step 14500: 0.114482\n",
      "2023-12-14 12:49:02,926 INFO     Training average positive_sample_loss at step 14600: 0.120371\n",
      "2023-12-14 12:49:02,926 INFO     Training average negative_sample_loss at step 14600: 0.108544\n",
      "2023-12-14 12:49:02,926 INFO     Training average loss at step 14600: 0.114458\n",
      "2023-12-14 12:50:54,697 INFO     Training average positive_sample_loss at step 14700: 0.122185\n",
      "2023-12-14 12:50:54,698 INFO     Training average negative_sample_loss at step 14700: 0.110538\n",
      "2023-12-14 12:50:54,698 INFO     Training average loss at step 14700: 0.116362\n",
      "2023-12-14 12:52:47,225 INFO     Training average positive_sample_loss at step 14800: 0.122491\n",
      "2023-12-14 12:52:47,225 INFO     Training average negative_sample_loss at step 14800: 0.111046\n",
      "2023-12-14 12:52:47,225 INFO     Training average loss at step 14800: 0.116768\n",
      "2023-12-14 12:54:38,355 INFO     Training average positive_sample_loss at step 14900: 0.122426\n",
      "2023-12-14 12:54:38,355 INFO     Training average negative_sample_loss at step 14900: 0.111204\n",
      "2023-12-14 12:54:38,355 INFO     Training average loss at step 14900: 0.116815\n",
      "2023-12-14 12:56:32,621 INFO     Training average positive_sample_loss at step 15000: 0.123091\n",
      "2023-12-14 12:56:32,621 INFO     Training average negative_sample_loss at step 15000: 0.111017\n",
      "2023-12-14 12:56:32,621 INFO     Training average loss at step 15000: 0.117054\n",
      "2023-12-14 12:58:27,967 INFO     Training average positive_sample_loss at step 15100: 0.121967\n",
      "2023-12-14 12:58:27,967 INFO     Training average negative_sample_loss at step 15100: 0.110540\n",
      "2023-12-14 12:58:27,967 INFO     Training average loss at step 15100: 0.116253\n",
      "2023-12-14 13:00:30,951 INFO     Training average positive_sample_loss at step 15200: 0.112387\n",
      "2023-12-14 13:00:30,951 INFO     Training average negative_sample_loss at step 15200: 0.103923\n",
      "2023-12-14 13:00:30,951 INFO     Training average loss at step 15200: 0.108155\n",
      "2023-12-14 13:02:14,073 INFO     Training average positive_sample_loss at step 15300: 0.116134\n",
      "2023-12-14 13:02:14,073 INFO     Training average negative_sample_loss at step 15300: 0.104877\n",
      "2023-12-14 13:02:14,073 INFO     Training average loss at step 15300: 0.110505\n",
      "2023-12-14 13:03:55,624 INFO     Training average positive_sample_loss at step 15400: 0.117579\n",
      "2023-12-14 13:03:55,624 INFO     Training average negative_sample_loss at step 15400: 0.105812\n",
      "2023-12-14 13:03:55,625 INFO     Training average loss at step 15400: 0.111695\n",
      "2023-12-14 13:05:56,026 INFO     Training average positive_sample_loss at step 15500: 0.119124\n",
      "2023-12-14 13:05:56,026 INFO     Training average negative_sample_loss at step 15500: 0.106704\n",
      "2023-12-14 13:05:56,026 INFO     Training average loss at step 15500: 0.112914\n",
      "2023-12-14 13:07:56,252 INFO     Training average positive_sample_loss at step 15600: 0.119742\n",
      "2023-12-14 13:07:56,253 INFO     Training average negative_sample_loss at step 15600: 0.107764\n",
      "2023-12-14 13:07:56,253 INFO     Training average loss at step 15600: 0.113753\n",
      "2023-12-14 13:09:49,599 INFO     Training average positive_sample_loss at step 15700: 0.119896\n",
      "2023-12-14 13:09:49,599 INFO     Training average negative_sample_loss at step 15700: 0.108515\n",
      "2023-12-14 13:09:49,599 INFO     Training average loss at step 15700: 0.114206\n",
      "2023-12-14 13:11:37,804 INFO     Training average positive_sample_loss at step 15800: 0.120398\n",
      "2023-12-14 13:11:37,804 INFO     Training average negative_sample_loss at step 15800: 0.108329\n",
      "2023-12-14 13:11:37,804 INFO     Training average loss at step 15800: 0.114364\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE FB15k 0 0 1024 256 1000 24.0 1.0 0.0001 150000 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu118\n",
      "Start Training......\n",
      "2023-12-18 19:23:10,618 INFO     Model: RotatE\n",
      "2023-12-18 19:23:10,618 INFO     Data Path: data/FB15k\n",
      "2023-12-18 19:23:10,618 INFO     #entity: 14951\n",
      "2023-12-18 19:23:10,618 INFO     #relation: 1345\n",
      "2023-12-18 19:23:11,191 INFO     #train: 483142\n",
      "2023-12-18 19:23:11,281 INFO     #valid: 50000\n",
      "2023-12-18 19:23:11,400 INFO     #test: 59071\n",
      "2023-12-18 19:23:11,608 INFO     Model Parameter Configuration:\n",
      "2023-12-18 19:23:11,609 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-18 19:23:11,609 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-18 19:23:11,609 INFO     Parameter entity_embedding: torch.Size([14951, 2000]), require_grad = True\n",
      "2023-12-18 19:23:11,609 INFO     Parameter relation_embedding: torch.Size([1345, 1000]), require_grad = True\n",
      "2023-12-18 19:23:19,893 INFO     Loading checkpoint ../KnowledgeGraphEmbedding_patt/models/RotatE_FB15k_0/...\n",
      "2023-12-18 19:23:20,550 INFO     Start Training...\n",
      "2023-12-18 19:23:20,550 INFO     init_step = 90000\n",
      "2023-12-18 19:23:20,550 INFO     batch_size = 1024\n",
      "2023-12-18 19:23:20,550 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-18 19:23:20,550 INFO     hidden_dim = 1000\n",
      "2023-12-18 19:23:20,550 INFO     gamma = 24.000000\n",
      "2023-12-18 19:23:20,550 INFO     negative_adversarial_sampling = True\n",
      "2023-12-18 19:23:20,551 INFO     adversarial_temperature = 1.000000\n",
      "2023-12-18 19:23:20,551 INFO     learning_rate = 0\n",
      "2023-12-18 19:23:36,190 INFO     Training average positive_sample_loss at step 90000: 0.086938\n",
      "2023-12-18 19:23:36,190 INFO     Training average negative_sample_loss at step 90000: 0.071840\n",
      "2023-12-18 19:23:36,190 INFO     Training average loss at step 90000: 0.079389\n",
      "2023-12-18 19:23:36,190 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-18 19:23:36,840 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-18 19:24:01,560 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-18 19:24:25,881 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-18 19:24:50,108 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-18 19:25:12,553 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-18 19:25:36,066 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-18 19:25:59,222 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-18 19:26:05,163 INFO     Valid MRR at step 90000: 0.444697\n",
      "2023-12-18 19:26:05,164 INFO     Valid MR at step 90000: 222.609980\n",
      "2023-12-18 19:26:05,164 INFO     Valid HITS@1 at step 90000: 0.348450\n",
      "2023-12-18 19:26:05,164 INFO     Valid HITS@3 at step 90000: 0.479380\n",
      "2023-12-18 19:26:05,164 INFO     Valid HITS@10 at step 90000: 0.653040\n",
      "2023-12-18 19:27:37,397 INFO     Training average positive_sample_loss at step 90100: 0.084848\n",
      "2023-12-18 19:27:37,397 INFO     Training average negative_sample_loss at step 90100: 0.074590\n",
      "2023-12-18 19:27:37,397 INFO     Training average loss at step 90100: 0.079719\n",
      "2023-12-18 19:29:18,055 INFO     Training average positive_sample_loss at step 90200: 0.085179\n",
      "2023-12-18 19:29:18,055 INFO     Training average negative_sample_loss at step 90200: 0.074332\n",
      "2023-12-18 19:29:18,055 INFO     Training average loss at step 90200: 0.079755\n",
      "2023-12-18 19:30:48,670 INFO     Training average positive_sample_loss at step 90300: 0.085685\n",
      "2023-12-18 19:30:48,670 INFO     Training average negative_sample_loss at step 90300: 0.074695\n",
      "2023-12-18 19:30:48,670 INFO     Training average loss at step 90300: 0.080190\n",
      "2023-12-18 19:32:24,535 INFO     Training average positive_sample_loss at step 90400: 0.085898\n",
      "2023-12-18 19:32:24,536 INFO     Training average negative_sample_loss at step 90400: 0.074776\n",
      "2023-12-18 19:32:24,536 INFO     Training average loss at step 90400: 0.080337\n",
      "2023-12-18 19:33:57,191 INFO     Training average positive_sample_loss at step 90500: 0.086604\n",
      "2023-12-18 19:33:57,191 INFO     Training average negative_sample_loss at step 90500: 0.075131\n",
      "2023-12-18 19:33:57,191 INFO     Training average loss at step 90500: 0.080867\n",
      "2023-12-18 19:35:29,792 INFO     Training average positive_sample_loss at step 90600: 0.086271\n",
      "2023-12-18 19:35:29,792 INFO     Training average negative_sample_loss at step 90600: 0.075114\n",
      "2023-12-18 19:35:29,792 INFO     Training average loss at step 90600: 0.080692\n",
      "2023-12-18 19:37:03,074 INFO     Training average positive_sample_loss at step 90700: 0.086202\n",
      "2023-12-18 19:37:03,074 INFO     Training average negative_sample_loss at step 90700: 0.075134\n",
      "2023-12-18 19:37:03,074 INFO     Training average loss at step 90700: 0.080668\n",
      "2023-12-18 19:38:35,650 INFO     Training average positive_sample_loss at step 90800: 0.086796\n",
      "2023-12-18 19:38:35,651 INFO     Training average negative_sample_loss at step 90800: 0.075268\n",
      "2023-12-18 19:38:35,651 INFO     Training average loss at step 90800: 0.081032\n",
      "2023-12-18 19:40:19,692 INFO     Training average positive_sample_loss at step 90900: 0.086392\n",
      "2023-12-18 19:40:19,692 INFO     Training average negative_sample_loss at step 90900: 0.075682\n",
      "2023-12-18 19:40:19,692 INFO     Training average loss at step 90900: 0.081037\n",
      "2023-12-18 19:42:19,763 INFO     Training average positive_sample_loss at step 91000: 0.085337\n",
      "2023-12-18 19:42:19,764 INFO     Training average negative_sample_loss at step 91000: 0.075502\n",
      "2023-12-18 19:42:19,764 INFO     Training average loss at step 91000: 0.080420\n",
      "2023-12-18 19:44:01,858 INFO     Training average positive_sample_loss at step 91100: 0.084898\n",
      "2023-12-18 19:44:01,858 INFO     Training average negative_sample_loss at step 91100: 0.074941\n",
      "2023-12-18 19:44:01,858 INFO     Training average loss at step 91100: 0.079920\n",
      "2023-12-18 19:46:15,376 INFO     Training average positive_sample_loss at step 91200: 0.085026\n",
      "2023-12-18 19:46:15,377 INFO     Training average negative_sample_loss at step 91200: 0.074525\n",
      "2023-12-18 19:46:15,377 INFO     Training average loss at step 91200: 0.079776\n",
      "2023-12-18 19:47:52,353 INFO     Training average positive_sample_loss at step 91300: 0.085166\n",
      "2023-12-18 19:47:52,353 INFO     Training average negative_sample_loss at step 91300: 0.074549\n",
      "2023-12-18 19:47:52,353 INFO     Training average loss at step 91300: 0.079858\n",
      "2023-12-18 19:49:43,618 INFO     Training average positive_sample_loss at step 91400: 0.085638\n",
      "2023-12-18 19:49:43,618 INFO     Training average negative_sample_loss at step 91400: 0.074541\n",
      "2023-12-18 19:49:43,618 INFO     Training average loss at step 91400: 0.080090\n",
      "2023-12-18 19:51:20,735 INFO     Training average positive_sample_loss at step 91500: 0.086407\n",
      "2023-12-18 19:51:20,735 INFO     Training average negative_sample_loss at step 91500: 0.074951\n",
      "2023-12-18 19:51:20,735 INFO     Training average loss at step 91500: 0.080679\n",
      "2023-12-18 19:53:00,580 INFO     Training average positive_sample_loss at step 91600: 0.086615\n",
      "2023-12-18 19:53:00,580 INFO     Training average negative_sample_loss at step 91600: 0.075490\n",
      "2023-12-18 19:53:00,580 INFO     Training average loss at step 91600: 0.081052\n",
      "2023-12-18 19:54:48,660 INFO     Training average positive_sample_loss at step 91700: 0.086429\n",
      "2023-12-18 19:54:48,660 INFO     Training average negative_sample_loss at step 91700: 0.075529\n",
      "2023-12-18 19:54:48,660 INFO     Training average loss at step 91700: 0.080979\n",
      "2023-12-18 19:56:34,911 INFO     Training average positive_sample_loss at step 91800: 0.086684\n",
      "2023-12-18 19:56:34,911 INFO     Training average negative_sample_loss at step 91800: 0.075440\n",
      "2023-12-18 19:56:34,911 INFO     Training average loss at step 91800: 0.081062\n",
      "2023-12-18 19:59:02,262 INFO     Training average positive_sample_loss at step 91900: 0.086288\n",
      "2023-12-18 19:59:02,263 INFO     Training average negative_sample_loss at step 91900: 0.075665\n",
      "2023-12-18 19:59:02,263 INFO     Training average loss at step 91900: 0.080977\n",
      "2023-12-18 20:00:43,330 INFO     Training average positive_sample_loss at step 92000: 0.084632\n",
      "2023-12-18 20:00:43,330 INFO     Training average negative_sample_loss at step 92000: 0.075086\n",
      "2023-12-18 20:00:43,330 INFO     Training average loss at step 92000: 0.079859\n",
      "2023-12-18 20:02:52,458 INFO     Training average positive_sample_loss at step 92100: 0.084989\n",
      "2023-12-18 20:02:52,458 INFO     Training average negative_sample_loss at step 92100: 0.074885\n",
      "2023-12-18 20:02:52,458 INFO     Training average loss at step 92100: 0.079937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-18 20:05:03,196 INFO     Training average positive_sample_loss at step 92200: 0.085962\n",
      "2023-12-18 20:05:03,196 INFO     Training average negative_sample_loss at step 92200: 0.075158\n",
      "2023-12-18 20:05:03,196 INFO     Training average loss at step 92200: 0.080560\n",
      "2023-12-18 20:07:03,878 INFO     Training average positive_sample_loss at step 92300: 0.085183\n",
      "2023-12-18 20:07:03,878 INFO     Training average negative_sample_loss at step 92300: 0.074495\n",
      "2023-12-18 20:07:03,878 INFO     Training average loss at step 92300: 0.079839\n",
      "2023-12-18 20:09:05,986 INFO     Training average positive_sample_loss at step 92400: 0.086317\n",
      "2023-12-18 20:09:05,986 INFO     Training average negative_sample_loss at step 92400: 0.074826\n",
      "2023-12-18 20:09:05,986 INFO     Training average loss at step 92400: 0.080572\n",
      "2023-12-18 20:11:10,944 INFO     Training average positive_sample_loss at step 92500: 0.086068\n",
      "2023-12-18 20:11:10,944 INFO     Training average negative_sample_loss at step 92500: 0.075042\n",
      "2023-12-18 20:11:10,944 INFO     Training average loss at step 92500: 0.080555\n",
      "2023-12-18 20:13:02,602 INFO     Training average positive_sample_loss at step 92600: 0.086679\n",
      "2023-12-18 20:13:02,602 INFO     Training average negative_sample_loss at step 92600: 0.075229\n",
      "2023-12-18 20:13:02,602 INFO     Training average loss at step 92600: 0.080954\n",
      "2023-12-18 20:14:37,795 INFO     Training average positive_sample_loss at step 92700: 0.086044\n",
      "2023-12-18 20:14:37,796 INFO     Training average negative_sample_loss at step 92700: 0.075106\n",
      "2023-12-18 20:14:37,796 INFO     Training average loss at step 92700: 0.080575\n",
      "2023-12-18 20:16:14,674 INFO     Training average positive_sample_loss at step 92800: 0.086306\n",
      "2023-12-18 20:16:14,674 INFO     Training average negative_sample_loss at step 92800: 0.075171\n",
      "2023-12-18 20:16:14,674 INFO     Training average loss at step 92800: 0.080739\n",
      "2023-12-18 20:18:01,048 INFO     Training average positive_sample_loss at step 92900: 0.084713\n",
      "2023-12-18 20:18:01,049 INFO     Training average negative_sample_loss at step 92900: 0.074946\n",
      "2023-12-18 20:18:01,049 INFO     Training average loss at step 92900: 0.079829\n",
      "2023-12-18 20:19:35,621 INFO     Training average positive_sample_loss at step 93000: 0.084489\n",
      "2023-12-18 20:19:35,621 INFO     Training average negative_sample_loss at step 93000: 0.074685\n",
      "2023-12-18 20:19:35,621 INFO     Training average loss at step 93000: 0.079587\n",
      "2023-12-18 20:20:59,641 INFO     Training average positive_sample_loss at step 93100: 0.085243\n",
      "2023-12-18 20:20:59,641 INFO     Training average negative_sample_loss at step 93100: 0.074407\n",
      "2023-12-18 20:20:59,641 INFO     Training average loss at step 93100: 0.079825\n",
      "2023-12-18 20:22:24,742 INFO     Training average positive_sample_loss at step 93200: 0.085408\n",
      "2023-12-18 20:22:24,743 INFO     Training average negative_sample_loss at step 93200: 0.074157\n",
      "2023-12-18 20:22:24,743 INFO     Training average loss at step 93200: 0.079783\n",
      "2023-12-18 20:23:54,423 INFO     Training average positive_sample_loss at step 93300: 0.085995\n",
      "2023-12-18 20:23:54,424 INFO     Training average negative_sample_loss at step 93300: 0.074949\n",
      "2023-12-18 20:23:54,424 INFO     Training average loss at step 93300: 0.080472\n",
      "2023-12-18 20:25:21,714 INFO     Training average positive_sample_loss at step 93400: 0.086211\n",
      "2023-12-18 20:25:21,715 INFO     Training average negative_sample_loss at step 93400: 0.075314\n",
      "2023-12-18 20:25:21,715 INFO     Training average loss at step 93400: 0.080763\n",
      "2023-12-18 20:26:57,255 INFO     Training average positive_sample_loss at step 93500: 0.085997\n",
      "2023-12-18 20:26:57,256 INFO     Training average negative_sample_loss at step 93500: 0.075435\n",
      "2023-12-18 20:26:57,256 INFO     Training average loss at step 93500: 0.080716\n",
      "2023-12-18 20:28:49,247 INFO     Training average positive_sample_loss at step 93600: 0.086429\n",
      "2023-12-18 20:28:49,247 INFO     Training average negative_sample_loss at step 93600: 0.075083\n",
      "2023-12-18 20:28:49,247 INFO     Training average loss at step 93600: 0.080756\n",
      "2023-12-18 20:30:22,951 INFO     Training average positive_sample_loss at step 93700: 0.086910\n",
      "2023-12-18 20:30:22,951 INFO     Training average negative_sample_loss at step 93700: 0.075880\n",
      "2023-12-18 20:30:22,952 INFO     Training average loss at step 93700: 0.081395\n",
      "2023-12-18 20:32:05,102 INFO     Training average positive_sample_loss at step 93800: 0.086310\n",
      "2023-12-18 20:32:05,102 INFO     Training average negative_sample_loss at step 93800: 0.075469\n",
      "2023-12-18 20:32:05,102 INFO     Training average loss at step 93800: 0.080890\n",
      "2023-12-18 20:33:36,354 INFO     Training average positive_sample_loss at step 93900: 0.083740\n",
      "2023-12-18 20:33:36,354 INFO     Training average negative_sample_loss at step 93900: 0.074205\n",
      "2023-12-18 20:33:36,354 INFO     Training average loss at step 93900: 0.078973\n",
      "2023-12-18 20:35:25,466 INFO     Training average positive_sample_loss at step 94000: 0.085050\n",
      "2023-12-18 20:35:25,467 INFO     Training average negative_sample_loss at step 94000: 0.074556\n",
      "2023-12-18 20:35:25,467 INFO     Training average loss at step 94000: 0.079803\n",
      "2023-12-18 20:37:05,033 INFO     Training average positive_sample_loss at step 94100: 0.085218\n",
      "2023-12-18 20:37:05,033 INFO     Training average negative_sample_loss at step 94100: 0.074428\n",
      "2023-12-18 20:37:05,033 INFO     Training average loss at step 94100: 0.079823\n",
      "2023-12-18 20:38:55,933 INFO     Training average positive_sample_loss at step 94200: 0.086360\n",
      "2023-12-18 20:38:55,933 INFO     Training average negative_sample_loss at step 94200: 0.075268\n",
      "2023-12-18 20:38:55,933 INFO     Training average loss at step 94200: 0.080814\n",
      "2023-12-18 20:40:48,970 INFO     Training average positive_sample_loss at step 94300: 0.086063\n",
      "2023-12-18 20:40:48,970 INFO     Training average negative_sample_loss at step 94300: 0.074969\n",
      "2023-12-18 20:40:48,970 INFO     Training average loss at step 94300: 0.080516\n",
      "2023-12-18 20:42:43,747 INFO     Training average positive_sample_loss at step 94400: 0.085834\n",
      "2023-12-18 20:42:43,747 INFO     Training average negative_sample_loss at step 94400: 0.074768\n",
      "2023-12-18 20:42:43,747 INFO     Training average loss at step 94400: 0.080301\n",
      "2023-12-18 20:44:25,884 INFO     Training average positive_sample_loss at step 94500: 0.086174\n",
      "2023-12-18 20:44:25,884 INFO     Training average negative_sample_loss at step 94500: 0.075063\n",
      "2023-12-18 20:44:25,884 INFO     Training average loss at step 94500: 0.080618\n",
      "2023-12-18 20:46:05,962 INFO     Training average positive_sample_loss at step 94600: 0.086495\n",
      "2023-12-18 20:46:05,962 INFO     Training average negative_sample_loss at step 94600: 0.075363\n",
      "2023-12-18 20:46:05,962 INFO     Training average loss at step 94600: 0.080929\n",
      "2023-12-18 20:47:31,947 INFO     Training average positive_sample_loss at step 94700: 0.086786\n",
      "2023-12-18 20:47:31,948 INFO     Training average negative_sample_loss at step 94700: 0.075646\n",
      "2023-12-18 20:47:31,948 INFO     Training average loss at step 94700: 0.081216\n",
      "2023-12-18 20:49:33,195 INFO     Training average positive_sample_loss at step 94800: 0.084177\n",
      "2023-12-18 20:49:33,196 INFO     Training average negative_sample_loss at step 94800: 0.075139\n",
      "2023-12-18 20:49:33,196 INFO     Training average loss at step 94800: 0.079658\n",
      "2023-12-18 20:51:11,807 INFO     Training average positive_sample_loss at step 94900: 0.084643\n",
      "2023-12-18 20:51:11,807 INFO     Training average negative_sample_loss at step 94900: 0.074546\n",
      "2023-12-18 20:51:11,807 INFO     Training average loss at step 94900: 0.079594\n",
      "2023-12-18 20:52:37,516 INFO     Training average positive_sample_loss at step 95000: 0.085217\n",
      "2023-12-18 20:52:37,516 INFO     Training average negative_sample_loss at step 95000: 0.074386\n",
      "2023-12-18 20:52:37,516 INFO     Training average loss at step 95000: 0.079802\n",
      "2023-12-18 20:54:06,065 INFO     Training average positive_sample_loss at step 95100: 0.085964\n",
      "2023-12-18 20:54:06,066 INFO     Training average negative_sample_loss at step 95100: 0.074850\n",
      "2023-12-18 20:54:06,066 INFO     Training average loss at step 95100: 0.080407\n",
      "2023-12-18 20:55:37,291 INFO     Training average positive_sample_loss at step 95200: 0.085728\n",
      "2023-12-18 20:55:37,292 INFO     Training average negative_sample_loss at step 95200: 0.074872\n",
      "2023-12-18 20:55:37,292 INFO     Training average loss at step 95200: 0.080300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-18 20:57:04,288 INFO     Training average positive_sample_loss at step 95300: 0.086452\n",
      "2023-12-18 20:57:04,289 INFO     Training average negative_sample_loss at step 95300: 0.075121\n",
      "2023-12-18 20:57:04,289 INFO     Training average loss at step 95300: 0.080787\n",
      "2023-12-18 20:58:36,421 INFO     Training average positive_sample_loss at step 95400: 0.086308\n",
      "2023-12-18 20:58:36,421 INFO     Training average negative_sample_loss at step 95400: 0.075323\n",
      "2023-12-18 20:58:36,421 INFO     Training average loss at step 95400: 0.080815\n",
      "2023-12-18 21:00:12,346 INFO     Training average positive_sample_loss at step 95500: 0.086571\n",
      "2023-12-18 21:00:12,346 INFO     Training average negative_sample_loss at step 95500: 0.075266\n",
      "2023-12-18 21:00:12,346 INFO     Training average loss at step 95500: 0.080918\n",
      "2023-12-18 21:01:47,416 INFO     Training average positive_sample_loss at step 95600: 0.086477\n",
      "2023-12-18 21:01:47,417 INFO     Training average negative_sample_loss at step 95600: 0.075329\n",
      "2023-12-18 21:01:47,417 INFO     Training average loss at step 95600: 0.080903\n",
      "2023-12-18 21:03:51,240 INFO     Training average positive_sample_loss at step 95700: 0.085254\n",
      "2023-12-18 21:03:51,241 INFO     Training average negative_sample_loss at step 95700: 0.075079\n",
      "2023-12-18 21:03:51,241 INFO     Training average loss at step 95700: 0.080166\n",
      "2023-12-18 21:05:40,743 INFO     Training average positive_sample_loss at step 95800: 0.084438\n",
      "2023-12-18 21:05:40,744 INFO     Training average negative_sample_loss at step 95800: 0.074567\n",
      "2023-12-18 21:05:40,744 INFO     Training average loss at step 95800: 0.079503\n",
      "2023-12-18 21:07:16,155 INFO     Training average positive_sample_loss at step 95900: 0.084706\n",
      "2023-12-18 21:07:16,155 INFO     Training average negative_sample_loss at step 95900: 0.074570\n",
      "2023-12-18 21:07:16,155 INFO     Training average loss at step 95900: 0.079638\n",
      "2023-12-18 21:09:16,199 INFO     Training average positive_sample_loss at step 96000: 0.085869\n",
      "2023-12-18 21:09:16,200 INFO     Training average negative_sample_loss at step 96000: 0.074686\n",
      "2023-12-18 21:09:16,200 INFO     Training average loss at step 96000: 0.080278\n",
      "2023-12-18 21:11:11,502 INFO     Training average positive_sample_loss at step 96100: 0.085772\n",
      "2023-12-18 21:11:11,502 INFO     Training average negative_sample_loss at step 96100: 0.075154\n",
      "2023-12-18 21:11:11,503 INFO     Training average loss at step 96100: 0.080463\n",
      "2023-12-18 21:13:05,702 INFO     Training average positive_sample_loss at step 96200: 0.085986\n",
      "2023-12-18 21:13:05,703 INFO     Training average negative_sample_loss at step 96200: 0.074741\n",
      "2023-12-18 21:13:05,703 INFO     Training average loss at step 96200: 0.080364\n",
      "2023-12-18 21:14:45,012 INFO     Training average positive_sample_loss at step 96300: 0.086480\n",
      "2023-12-18 21:14:45,013 INFO     Training average negative_sample_loss at step 96300: 0.075048\n",
      "2023-12-18 21:14:45,013 INFO     Training average loss at step 96300: 0.080764\n",
      "2023-12-18 21:16:28,144 INFO     Training average positive_sample_loss at step 96400: 0.086249\n",
      "2023-12-18 21:16:28,144 INFO     Training average negative_sample_loss at step 96400: 0.075135\n",
      "2023-12-18 21:16:28,145 INFO     Training average loss at step 96400: 0.080692\n",
      "2023-12-18 21:18:30,367 INFO     Training average positive_sample_loss at step 96500: 0.086507\n",
      "2023-12-18 21:18:30,367 INFO     Training average negative_sample_loss at step 96500: 0.075166\n",
      "2023-12-18 21:18:30,367 INFO     Training average loss at step 96500: 0.080837\n",
      "2023-12-18 21:20:04,965 INFO     Training average positive_sample_loss at step 96600: 0.086551\n",
      "2023-12-18 21:20:04,965 INFO     Training average negative_sample_loss at step 96600: 0.075436\n",
      "2023-12-18 21:20:04,965 INFO     Training average loss at step 96600: 0.080993\n",
      "2023-12-18 21:21:53,233 INFO     Training average positive_sample_loss at step 96700: 0.084084\n",
      "2023-12-18 21:21:53,233 INFO     Training average negative_sample_loss at step 96700: 0.075001\n",
      "2023-12-18 21:21:53,234 INFO     Training average loss at step 96700: 0.079542\n",
      "2023-12-18 21:23:34,717 INFO     Training average positive_sample_loss at step 96800: 0.084691\n",
      "2023-12-18 21:23:34,718 INFO     Training average negative_sample_loss at step 96800: 0.074890\n",
      "2023-12-18 21:23:34,718 INFO     Training average loss at step 96800: 0.079790\n",
      "2023-12-18 21:25:27,546 INFO     Training average positive_sample_loss at step 96900: 0.085104\n",
      "2023-12-18 21:25:27,546 INFO     Training average negative_sample_loss at step 96900: 0.074176\n",
      "2023-12-18 21:25:27,547 INFO     Training average loss at step 96900: 0.079640\n",
      "2023-12-18 21:27:00,328 INFO     Training average positive_sample_loss at step 97000: 0.086304\n",
      "2023-12-18 21:27:00,328 INFO     Training average negative_sample_loss at step 97000: 0.074910\n",
      "2023-12-18 21:27:00,328 INFO     Training average loss at step 97000: 0.080607\n",
      "2023-12-18 21:28:47,106 INFO     Training average positive_sample_loss at step 97100: 0.085921\n",
      "2023-12-18 21:28:47,107 INFO     Training average negative_sample_loss at step 97100: 0.074622\n",
      "2023-12-18 21:28:47,107 INFO     Training average loss at step 97100: 0.080272\n",
      "2023-12-18 21:30:40,857 INFO     Training average positive_sample_loss at step 97200: 0.085788\n",
      "2023-12-18 21:30:40,857 INFO     Training average negative_sample_loss at step 97200: 0.075058\n",
      "2023-12-18 21:30:40,857 INFO     Training average loss at step 97200: 0.080423\n",
      "2023-12-18 21:32:33,297 INFO     Training average positive_sample_loss at step 97300: 0.086169\n",
      "2023-12-18 21:32:33,297 INFO     Training average negative_sample_loss at step 97300: 0.074820\n",
      "2023-12-18 21:32:33,297 INFO     Training average loss at step 97300: 0.080495\n",
      "2023-12-18 21:34:39,214 INFO     Training average positive_sample_loss at step 97400: 0.086136\n",
      "2023-12-18 21:34:39,215 INFO     Training average negative_sample_loss at step 97400: 0.074913\n",
      "2023-12-18 21:34:39,215 INFO     Training average loss at step 97400: 0.080524\n",
      "2023-12-18 21:36:40,309 INFO     Training average positive_sample_loss at step 97500: 0.086729\n",
      "2023-12-18 21:36:40,310 INFO     Training average negative_sample_loss at step 97500: 0.075656\n",
      "2023-12-18 21:36:40,310 INFO     Training average loss at step 97500: 0.081192\n",
      "2023-12-18 21:38:36,056 INFO     Training average positive_sample_loss at step 97600: 0.085473\n",
      "2023-12-18 21:38:36,056 INFO     Training average negative_sample_loss at step 97600: 0.075154\n",
      "2023-12-18 21:38:36,056 INFO     Training average loss at step 97600: 0.080314\n",
      "2023-12-18 21:40:16,396 INFO     Training average positive_sample_loss at step 97700: 0.084164\n",
      "2023-12-18 21:40:16,397 INFO     Training average negative_sample_loss at step 97700: 0.074840\n",
      "2023-12-18 21:40:16,397 INFO     Training average loss at step 97700: 0.079502\n",
      "2023-12-18 21:41:58,755 INFO     Training average positive_sample_loss at step 97800: 0.084817\n",
      "2023-12-18 21:41:58,755 INFO     Training average negative_sample_loss at step 97800: 0.074390\n",
      "2023-12-18 21:41:58,755 INFO     Training average loss at step 97800: 0.079604\n",
      "2023-12-18 21:43:35,642 INFO     Training average positive_sample_loss at step 97900: 0.085593\n",
      "2023-12-18 21:43:35,642 INFO     Training average negative_sample_loss at step 97900: 0.074838\n",
      "2023-12-18 21:43:35,642 INFO     Training average loss at step 97900: 0.080216\n",
      "2023-12-18 21:45:00,370 INFO     Training average positive_sample_loss at step 98000: 0.086002\n",
      "2023-12-18 21:45:00,370 INFO     Training average negative_sample_loss at step 98000: 0.074697\n",
      "2023-12-18 21:45:00,370 INFO     Training average loss at step 98000: 0.080349\n",
      "2023-12-18 21:46:35,825 INFO     Training average positive_sample_loss at step 98100: 0.086095\n",
      "2023-12-18 21:46:35,826 INFO     Training average negative_sample_loss at step 98100: 0.074988\n",
      "2023-12-18 21:46:35,826 INFO     Training average loss at step 98100: 0.080542\n",
      "2023-12-18 21:48:07,402 INFO     Training average positive_sample_loss at step 98200: 0.086113\n",
      "2023-12-18 21:48:07,403 INFO     Training average negative_sample_loss at step 98200: 0.074873\n",
      "2023-12-18 21:48:07,403 INFO     Training average loss at step 98200: 0.080493\n",
      "2023-12-18 21:49:47,167 INFO     Training average positive_sample_loss at step 98300: 0.086081\n",
      "2023-12-18 21:49:47,168 INFO     Training average negative_sample_loss at step 98300: 0.074705\n",
      "2023-12-18 21:49:47,168 INFO     Training average loss at step 98300: 0.080393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-18 21:51:27,921 INFO     Training average positive_sample_loss at step 98400: 0.086197\n",
      "2023-12-18 21:51:27,922 INFO     Training average negative_sample_loss at step 98400: 0.075107\n",
      "2023-12-18 21:51:27,922 INFO     Training average loss at step 98400: 0.080652\n",
      "2023-12-18 21:53:26,491 INFO     Training average positive_sample_loss at step 98500: 0.086784\n",
      "2023-12-18 21:53:26,492 INFO     Training average negative_sample_loss at step 98500: 0.075331\n",
      "2023-12-18 21:53:26,492 INFO     Training average loss at step 98500: 0.081057\n",
      "2023-12-18 21:55:05,570 INFO     Training average positive_sample_loss at step 98600: 0.083782\n",
      "2023-12-18 21:55:05,570 INFO     Training average negative_sample_loss at step 98600: 0.075054\n",
      "2023-12-18 21:55:05,570 INFO     Training average loss at step 98600: 0.079418\n",
      "2023-12-18 21:56:43,620 INFO     Training average positive_sample_loss at step 98700: 0.084552\n",
      "2023-12-18 21:56:43,620 INFO     Training average negative_sample_loss at step 98700: 0.073992\n",
      "2023-12-18 21:56:43,620 INFO     Training average loss at step 98700: 0.079272\n",
      "2023-12-18 21:58:20,701 INFO     Training average positive_sample_loss at step 98800: 0.085021\n",
      "2023-12-18 21:58:20,701 INFO     Training average negative_sample_loss at step 98800: 0.074589\n",
      "2023-12-18 21:58:20,701 INFO     Training average loss at step 98800: 0.079805\n",
      "2023-12-18 21:59:54,427 INFO     Training average positive_sample_loss at step 98900: 0.085985\n",
      "2023-12-18 21:59:54,427 INFO     Training average negative_sample_loss at step 98900: 0.074727\n",
      "2023-12-18 21:59:54,427 INFO     Training average loss at step 98900: 0.080356\n",
      "2023-12-18 22:01:30,727 INFO     Training average positive_sample_loss at step 99000: 0.085816\n",
      "2023-12-18 22:01:30,727 INFO     Training average negative_sample_loss at step 99000: 0.074814\n",
      "2023-12-18 22:01:30,727 INFO     Training average loss at step 99000: 0.080315\n",
      "2023-12-18 22:02:56,270 INFO     Training average positive_sample_loss at step 99100: 0.086114\n",
      "2023-12-18 22:02:56,270 INFO     Training average negative_sample_loss at step 99100: 0.074974\n",
      "2023-12-18 22:02:56,270 INFO     Training average loss at step 99100: 0.080544\n",
      "2023-12-18 22:04:29,587 INFO     Training average positive_sample_loss at step 99200: 0.086653\n",
      "2023-12-18 22:04:29,587 INFO     Training average negative_sample_loss at step 99200: 0.075134\n",
      "2023-12-18 22:04:29,587 INFO     Training average loss at step 99200: 0.080893\n",
      "2023-12-18 22:05:56,738 INFO     Training average positive_sample_loss at step 99300: 0.085961\n",
      "2023-12-18 22:05:56,739 INFO     Training average negative_sample_loss at step 99300: 0.075240\n",
      "2023-12-18 22:05:56,739 INFO     Training average loss at step 99300: 0.080601\n",
      "2023-12-18 22:07:33,748 INFO     Training average positive_sample_loss at step 99400: 0.086602\n",
      "2023-12-18 22:07:33,749 INFO     Training average negative_sample_loss at step 99400: 0.075384\n",
      "2023-12-18 22:07:33,749 INFO     Training average loss at step 99400: 0.080993\n",
      "2023-12-18 22:09:19,804 INFO     Training average positive_sample_loss at step 99500: 0.084833\n",
      "2023-12-18 22:09:19,804 INFO     Training average negative_sample_loss at step 99500: 0.075431\n",
      "2023-12-18 22:09:19,805 INFO     Training average loss at step 99500: 0.080132\n",
      "2023-12-18 22:10:56,937 INFO     Training average positive_sample_loss at step 99600: 0.084629\n",
      "2023-12-18 22:10:56,938 INFO     Training average negative_sample_loss at step 99600: 0.074489\n",
      "2023-12-18 22:10:56,938 INFO     Training average loss at step 99600: 0.079559\n",
      "2023-12-18 22:12:39,977 INFO     Training average positive_sample_loss at step 99700: 0.085163\n",
      "2023-12-18 22:12:39,978 INFO     Training average negative_sample_loss at step 99700: 0.074382\n",
      "2023-12-18 22:12:39,978 INFO     Training average loss at step 99700: 0.079772\n",
      "2023-12-18 22:14:32,965 INFO     Training average positive_sample_loss at step 99800: 0.085909\n",
      "2023-12-18 22:14:32,965 INFO     Training average negative_sample_loss at step 99800: 0.074595\n",
      "2023-12-18 22:14:32,965 INFO     Training average loss at step 99800: 0.080252\n",
      "2023-12-18 22:16:22,477 INFO     Training average positive_sample_loss at step 99900: 0.085552\n",
      "2023-12-18 22:16:22,477 INFO     Training average negative_sample_loss at step 99900: 0.074587\n",
      "2023-12-18 22:16:22,477 INFO     Training average loss at step 99900: 0.080069\n",
      "2023-12-18 22:18:28,679 INFO     Training average positive_sample_loss at step 100000: 0.085982\n",
      "2023-12-18 22:18:28,679 INFO     Training average negative_sample_loss at step 100000: 0.074767\n",
      "2023-12-18 22:18:28,679 INFO     Training average loss at step 100000: 0.080375\n",
      "2023-12-18 22:18:28,679 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-18 22:18:29,566 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-18 22:18:53,929 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-18 22:19:19,442 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-18 22:19:45,526 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-18 22:20:10,370 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-18 22:20:33,897 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-18 22:20:57,120 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-18 22:21:03,155 INFO     Valid MRR at step 100000: 0.449340\n",
      "2023-12-18 22:21:03,156 INFO     Valid MR at step 100000: 219.928710\n",
      "2023-12-18 22:21:03,156 INFO     Valid HITS@1 at step 100000: 0.353960\n",
      "2023-12-18 22:21:03,156 INFO     Valid HITS@3 at step 100000: 0.483970\n",
      "2023-12-18 22:21:03,156 INFO     Valid HITS@10 at step 100000: 0.654880\n",
      "2023-12-18 22:22:31,792 INFO     Training average positive_sample_loss at step 100100: 0.085796\n",
      "2023-12-18 22:22:31,792 INFO     Training average negative_sample_loss at step 100100: 0.075084\n",
      "2023-12-18 22:22:31,792 INFO     Training average loss at step 100100: 0.080440\n",
      "2023-12-18 22:24:20,645 INFO     Training average positive_sample_loss at step 100200: 0.086314\n",
      "2023-12-18 22:24:20,646 INFO     Training average negative_sample_loss at step 100200: 0.075174\n",
      "2023-12-18 22:24:20,646 INFO     Training average loss at step 100200: 0.080744\n",
      "2023-12-18 22:26:04,588 INFO     Training average positive_sample_loss at step 100300: 0.086460\n",
      "2023-12-18 22:26:04,589 INFO     Training average negative_sample_loss at step 100300: 0.075034\n",
      "2023-12-18 22:26:04,589 INFO     Training average loss at step 100300: 0.080747\n",
      "2023-12-18 22:28:05,088 INFO     Training average positive_sample_loss at step 100400: 0.085848\n",
      "2023-12-18 22:28:05,088 INFO     Training average negative_sample_loss at step 100400: 0.075338\n",
      "2023-12-18 22:28:05,088 INFO     Training average loss at step 100400: 0.080593\n",
      "2023-12-18 22:29:43,123 INFO     Training average positive_sample_loss at step 100500: 0.084129\n",
      "2023-12-18 22:29:43,124 INFO     Training average negative_sample_loss at step 100500: 0.074724\n",
      "2023-12-18 22:29:43,124 INFO     Training average loss at step 100500: 0.079426\n",
      "2023-12-18 22:31:21,356 INFO     Training average positive_sample_loss at step 100600: 0.084727\n",
      "2023-12-18 22:31:21,356 INFO     Training average negative_sample_loss at step 100600: 0.074227\n",
      "2023-12-18 22:31:21,356 INFO     Training average loss at step 100600: 0.079477\n",
      "2023-12-18 22:32:55,678 INFO     Training average positive_sample_loss at step 100700: 0.085635\n",
      "2023-12-18 22:32:55,678 INFO     Training average negative_sample_loss at step 100700: 0.074796\n",
      "2023-12-18 22:32:55,678 INFO     Training average loss at step 100700: 0.080215\n",
      "2023-12-18 22:34:30,865 INFO     Training average positive_sample_loss at step 100800: 0.085493\n",
      "2023-12-18 22:34:30,865 INFO     Training average negative_sample_loss at step 100800: 0.074508\n",
      "2023-12-18 22:34:30,865 INFO     Training average loss at step 100800: 0.080001\n",
      "2023-12-18 22:36:09,609 INFO     Training average positive_sample_loss at step 100900: 0.086268\n",
      "2023-12-18 22:36:09,609 INFO     Training average negative_sample_loss at step 100900: 0.074782\n",
      "2023-12-18 22:36:09,609 INFO     Training average loss at step 100900: 0.080525\n",
      "2023-12-18 22:37:45,602 INFO     Training average positive_sample_loss at step 101000: 0.085947\n",
      "2023-12-18 22:37:45,602 INFO     Training average negative_sample_loss at step 101000: 0.074642\n",
      "2023-12-18 22:37:45,602 INFO     Training average loss at step 101000: 0.080295\n",
      "2023-12-18 22:39:19,098 INFO     Training average positive_sample_loss at step 101100: 0.085919\n",
      "2023-12-18 22:39:19,098 INFO     Training average negative_sample_loss at step 101100: 0.074713\n",
      "2023-12-18 22:39:19,098 INFO     Training average loss at step 101100: 0.080316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-18 22:40:56,653 INFO     Training average positive_sample_loss at step 101200: 0.086216\n",
      "2023-12-18 22:40:56,653 INFO     Training average negative_sample_loss at step 101200: 0.075229\n",
      "2023-12-18 22:40:56,654 INFO     Training average loss at step 101200: 0.080722\n",
      "2023-12-18 22:42:40,459 INFO     Training average positive_sample_loss at step 101300: 0.086355\n",
      "2023-12-18 22:42:40,459 INFO     Training average negative_sample_loss at step 101300: 0.075347\n",
      "2023-12-18 22:42:40,459 INFO     Training average loss at step 101300: 0.080851\n",
      "2023-12-18 22:44:44,784 INFO     Training average positive_sample_loss at step 101400: 0.084572\n",
      "2023-12-18 22:44:44,784 INFO     Training average negative_sample_loss at step 101400: 0.075136\n",
      "2023-12-18 22:44:44,784 INFO     Training average loss at step 101400: 0.079854\n",
      "2023-12-18 22:46:18,529 INFO     Training average positive_sample_loss at step 101500: 0.084992\n",
      "2023-12-18 22:46:18,530 INFO     Training average negative_sample_loss at step 101500: 0.075039\n",
      "2023-12-18 22:46:18,530 INFO     Training average loss at step 101500: 0.080016\n",
      "2023-12-18 22:47:49,166 INFO     Training average positive_sample_loss at step 101600: 0.085382\n",
      "2023-12-18 22:47:49,167 INFO     Training average negative_sample_loss at step 101600: 0.074541\n",
      "2023-12-18 22:47:49,167 INFO     Training average loss at step 101600: 0.079962\n",
      "2023-12-18 22:49:18,676 INFO     Training average positive_sample_loss at step 101700: 0.085328\n",
      "2023-12-18 22:49:18,677 INFO     Training average negative_sample_loss at step 101700: 0.074703\n",
      "2023-12-18 22:49:18,677 INFO     Training average loss at step 101700: 0.080015\n",
      "2023-12-18 22:51:00,578 INFO     Training average positive_sample_loss at step 101800: 0.085871\n",
      "2023-12-18 22:51:00,579 INFO     Training average negative_sample_loss at step 101800: 0.074807\n",
      "2023-12-18 22:51:00,579 INFO     Training average loss at step 101800: 0.080339\n",
      "2023-12-18 22:52:53,665 INFO     Training average positive_sample_loss at step 101900: 0.086000\n",
      "2023-12-18 22:52:53,665 INFO     Training average negative_sample_loss at step 101900: 0.074771\n",
      "2023-12-18 22:52:53,665 INFO     Training average loss at step 101900: 0.080385\n",
      "2023-12-18 22:54:45,813 INFO     Training average positive_sample_loss at step 102000: 0.086311\n",
      "2023-12-18 22:54:45,813 INFO     Training average negative_sample_loss at step 102000: 0.074958\n",
      "2023-12-18 22:54:45,813 INFO     Training average loss at step 102000: 0.080635\n",
      "2023-12-18 22:56:35,553 INFO     Training average positive_sample_loss at step 102100: 0.086102\n",
      "2023-12-18 22:56:35,554 INFO     Training average negative_sample_loss at step 102100: 0.075213\n",
      "2023-12-18 22:56:35,554 INFO     Training average loss at step 102100: 0.080658\n",
      "2023-12-18 22:58:48,657 INFO     Training average positive_sample_loss at step 102200: 0.086435\n",
      "2023-12-18 22:58:48,657 INFO     Training average negative_sample_loss at step 102200: 0.075464\n",
      "2023-12-18 22:58:48,657 INFO     Training average loss at step 102200: 0.080949\n",
      "2023-12-18 23:00:58,552 INFO     Training average positive_sample_loss at step 102300: 0.085316\n",
      "2023-12-18 23:00:58,552 INFO     Training average negative_sample_loss at step 102300: 0.075013\n",
      "2023-12-18 23:00:58,552 INFO     Training average loss at step 102300: 0.080164\n",
      "2023-12-18 23:02:39,806 INFO     Training average positive_sample_loss at step 102400: 0.084393\n",
      "2023-12-18 23:02:39,806 INFO     Training average negative_sample_loss at step 102400: 0.074531\n",
      "2023-12-18 23:02:39,806 INFO     Training average loss at step 102400: 0.079462\n",
      "2023-12-18 23:04:43,233 INFO     Training average positive_sample_loss at step 102500: 0.084590\n",
      "2023-12-18 23:04:43,233 INFO     Training average negative_sample_loss at step 102500: 0.074399\n",
      "2023-12-18 23:04:43,233 INFO     Training average loss at step 102500: 0.079495\n",
      "2023-12-18 23:06:58,070 INFO     Training average positive_sample_loss at step 102600: 0.085516\n",
      "2023-12-18 23:06:58,070 INFO     Training average negative_sample_loss at step 102600: 0.074647\n",
      "2023-12-18 23:06:58,070 INFO     Training average loss at step 102600: 0.080081\n",
      "2023-12-18 23:08:28,540 INFO     Training average positive_sample_loss at step 102700: 0.085483\n",
      "2023-12-18 23:08:28,541 INFO     Training average negative_sample_loss at step 102700: 0.074375\n",
      "2023-12-18 23:08:28,541 INFO     Training average loss at step 102700: 0.079929\n",
      "2023-12-18 23:09:56,788 INFO     Training average positive_sample_loss at step 102800: 0.085847\n",
      "2023-12-18 23:09:56,788 INFO     Training average negative_sample_loss at step 102800: 0.074928\n",
      "2023-12-18 23:09:56,788 INFO     Training average loss at step 102800: 0.080387\n",
      "2023-12-18 23:11:30,178 INFO     Training average positive_sample_loss at step 102900: 0.086165\n",
      "2023-12-18 23:11:30,179 INFO     Training average negative_sample_loss at step 102900: 0.074779\n",
      "2023-12-18 23:11:30,179 INFO     Training average loss at step 102900: 0.080472\n",
      "2023-12-18 23:13:14,412 INFO     Training average positive_sample_loss at step 103000: 0.086104\n",
      "2023-12-18 23:13:14,412 INFO     Training average negative_sample_loss at step 103000: 0.074991\n",
      "2023-12-18 23:13:14,412 INFO     Training average loss at step 103000: 0.080547\n",
      "2023-12-18 23:15:21,236 INFO     Training average positive_sample_loss at step 103100: 0.086438\n",
      "2023-12-18 23:15:21,237 INFO     Training average negative_sample_loss at step 103100: 0.075349\n",
      "2023-12-18 23:15:21,237 INFO     Training average loss at step 103100: 0.080894\n",
      "2023-12-18 23:17:15,612 INFO     Training average positive_sample_loss at step 103200: 0.086627\n",
      "2023-12-18 23:17:15,612 INFO     Training average negative_sample_loss at step 103200: 0.075238\n",
      "2023-12-18 23:17:15,612 INFO     Training average loss at step 103200: 0.080932\n",
      "2023-12-18 23:19:17,411 INFO     Training average positive_sample_loss at step 103300: 0.084222\n",
      "2023-12-18 23:19:17,412 INFO     Training average negative_sample_loss at step 103300: 0.074977\n",
      "2023-12-18 23:19:17,412 INFO     Training average loss at step 103300: 0.079599\n",
      "2023-12-18 23:21:02,897 INFO     Training average positive_sample_loss at step 103400: 0.084397\n",
      "2023-12-18 23:21:02,898 INFO     Training average negative_sample_loss at step 103400: 0.074221\n",
      "2023-12-18 23:21:02,898 INFO     Training average loss at step 103400: 0.079309\n",
      "2023-12-18 23:22:52,169 INFO     Training average positive_sample_loss at step 103500: 0.085484\n",
      "2023-12-18 23:22:52,170 INFO     Training average negative_sample_loss at step 103500: 0.074681\n",
      "2023-12-18 23:22:52,170 INFO     Training average loss at step 103500: 0.080082\n",
      "2023-12-18 23:24:31,970 INFO     Training average positive_sample_loss at step 103600: 0.085136\n",
      "2023-12-18 23:24:31,971 INFO     Training average negative_sample_loss at step 103600: 0.074487\n",
      "2023-12-18 23:24:31,971 INFO     Training average loss at step 103600: 0.079812\n",
      "2023-12-18 23:26:12,837 INFO     Training average positive_sample_loss at step 103700: 0.085737\n",
      "2023-12-18 23:26:12,838 INFO     Training average negative_sample_loss at step 103700: 0.074400\n",
      "2023-12-18 23:26:12,838 INFO     Training average loss at step 103700: 0.080068\n",
      "2023-12-18 23:28:03,243 INFO     Training average positive_sample_loss at step 103800: 0.086196\n",
      "2023-12-18 23:28:03,244 INFO     Training average negative_sample_loss at step 103800: 0.074934\n",
      "2023-12-18 23:28:03,244 INFO     Training average loss at step 103800: 0.080565\n",
      "2023-12-18 23:29:58,708 INFO     Training average positive_sample_loss at step 103900: 0.086248\n",
      "2023-12-18 23:29:58,708 INFO     Training average negative_sample_loss at step 103900: 0.075011\n",
      "2023-12-18 23:29:58,709 INFO     Training average loss at step 103900: 0.080629\n",
      "2023-12-18 23:31:46,819 INFO     Training average positive_sample_loss at step 104000: 0.085973\n",
      "2023-12-18 23:31:46,820 INFO     Training average negative_sample_loss at step 104000: 0.075180\n",
      "2023-12-18 23:31:46,820 INFO     Training average loss at step 104000: 0.080576\n",
      "2023-12-18 23:33:27,856 INFO     Training average positive_sample_loss at step 104100: 0.086601\n",
      "2023-12-18 23:33:27,856 INFO     Training average negative_sample_loss at step 104100: 0.075266\n",
      "2023-12-18 23:33:27,856 INFO     Training average loss at step 104100: 0.080934\n",
      "2023-12-18 23:35:19,729 INFO     Training average positive_sample_loss at step 104200: 0.085291\n",
      "2023-12-18 23:35:19,730 INFO     Training average negative_sample_loss at step 104200: 0.075136\n",
      "2023-12-18 23:35:19,730 INFO     Training average loss at step 104200: 0.080213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-18 23:36:49,439 INFO     Training average positive_sample_loss at step 104300: 0.084445\n",
      "2023-12-18 23:36:49,439 INFO     Training average negative_sample_loss at step 104300: 0.074777\n",
      "2023-12-18 23:36:49,439 INFO     Training average loss at step 104300: 0.079611\n",
      "2023-12-18 23:38:20,267 INFO     Training average positive_sample_loss at step 104400: 0.084889\n",
      "2023-12-18 23:38:20,268 INFO     Training average negative_sample_loss at step 104400: 0.074468\n",
      "2023-12-18 23:38:20,268 INFO     Training average loss at step 104400: 0.079679\n",
      "2023-12-18 23:40:02,747 INFO     Training average positive_sample_loss at step 104500: 0.084994\n",
      "2023-12-18 23:40:02,747 INFO     Training average negative_sample_loss at step 104500: 0.074405\n",
      "2023-12-18 23:40:02,747 INFO     Training average loss at step 104500: 0.079699\n",
      "2023-12-18 23:41:33,151 INFO     Training average positive_sample_loss at step 104600: 0.085783\n",
      "2023-12-18 23:41:33,151 INFO     Training average negative_sample_loss at step 104600: 0.074832\n",
      "2023-12-18 23:41:33,152 INFO     Training average loss at step 104600: 0.080308\n",
      "2023-12-18 23:43:07,161 INFO     Training average positive_sample_loss at step 104700: 0.085684\n",
      "2023-12-18 23:43:07,162 INFO     Training average negative_sample_loss at step 104700: 0.074444\n",
      "2023-12-18 23:43:07,162 INFO     Training average loss at step 104700: 0.080064\n",
      "2023-12-18 23:44:55,077 INFO     Training average positive_sample_loss at step 104800: 0.086498\n",
      "2023-12-18 23:44:55,077 INFO     Training average negative_sample_loss at step 104800: 0.075143\n",
      "2023-12-18 23:44:55,077 INFO     Training average loss at step 104800: 0.080821\n",
      "2023-12-18 23:46:40,143 INFO     Training average positive_sample_loss at step 104900: 0.086118\n",
      "2023-12-18 23:46:40,144 INFO     Training average negative_sample_loss at step 104900: 0.075057\n",
      "2023-12-18 23:46:40,144 INFO     Training average loss at step 104900: 0.080587\n",
      "2023-12-18 23:48:24,013 INFO     Training average positive_sample_loss at step 105000: 0.086427\n",
      "2023-12-18 23:48:24,014 INFO     Training average negative_sample_loss at step 105000: 0.075154\n",
      "2023-12-18 23:48:24,014 INFO     Training average loss at step 105000: 0.080790\n",
      "2023-12-18 23:49:54,304 INFO     Training average positive_sample_loss at step 105100: 0.086246\n",
      "2023-12-18 23:49:54,304 INFO     Training average negative_sample_loss at step 105100: 0.075181\n",
      "2023-12-18 23:49:54,304 INFO     Training average loss at step 105100: 0.080713\n",
      "2023-12-18 23:51:55,528 INFO     Training average positive_sample_loss at step 105200: 0.083506\n",
      "2023-12-18 23:51:55,529 INFO     Training average negative_sample_loss at step 105200: 0.074580\n",
      "2023-12-18 23:51:55,529 INFO     Training average loss at step 105200: 0.079043\n",
      "2023-12-18 23:53:46,711 INFO     Training average positive_sample_loss at step 105300: 0.084719\n",
      "2023-12-18 23:53:46,711 INFO     Training average negative_sample_loss at step 105300: 0.074400\n",
      "2023-12-18 23:53:46,711 INFO     Training average loss at step 105300: 0.079560\n",
      "2023-12-18 23:55:26,140 INFO     Training average positive_sample_loss at step 105400: 0.085302\n",
      "2023-12-18 23:55:26,140 INFO     Training average negative_sample_loss at step 105400: 0.074590\n",
      "2023-12-18 23:55:26,140 INFO     Training average loss at step 105400: 0.079946\n",
      "2023-12-18 23:56:53,171 INFO     Training average positive_sample_loss at step 105500: 0.085466\n",
      "2023-12-18 23:56:53,172 INFO     Training average negative_sample_loss at step 105500: 0.074866\n",
      "2023-12-18 23:56:53,172 INFO     Training average loss at step 105500: 0.080166\n",
      "2023-12-18 23:58:52,062 INFO     Training average positive_sample_loss at step 105600: 0.086125\n",
      "2023-12-18 23:58:52,062 INFO     Training average negative_sample_loss at step 105600: 0.074645\n",
      "2023-12-18 23:58:52,063 INFO     Training average loss at step 105600: 0.080385\n",
      "2023-12-19 00:00:41,452 INFO     Training average positive_sample_loss at step 105700: 0.086126\n",
      "2023-12-19 00:00:41,453 INFO     Training average negative_sample_loss at step 105700: 0.074755\n",
      "2023-12-19 00:00:41,453 INFO     Training average loss at step 105700: 0.080441\n",
      "2023-12-19 00:02:16,717 INFO     Training average positive_sample_loss at step 105800: 0.086063\n",
      "2023-12-19 00:02:16,717 INFO     Training average negative_sample_loss at step 105800: 0.074729\n",
      "2023-12-19 00:02:16,718 INFO     Training average loss at step 105800: 0.080396\n",
      "2023-12-19 00:03:51,211 INFO     Training average positive_sample_loss at step 105900: 0.086137\n",
      "2023-12-19 00:03:51,211 INFO     Training average negative_sample_loss at step 105900: 0.075321\n",
      "2023-12-19 00:03:51,211 INFO     Training average loss at step 105900: 0.080729\n",
      "2023-12-19 00:05:26,528 INFO     Training average positive_sample_loss at step 106000: 0.086697\n",
      "2023-12-19 00:05:26,528 INFO     Training average negative_sample_loss at step 106000: 0.075601\n",
      "2023-12-19 00:05:26,528 INFO     Training average loss at step 106000: 0.081149\n",
      "2023-12-19 00:07:16,801 INFO     Training average positive_sample_loss at step 106100: 0.084785\n",
      "2023-12-19 00:07:16,801 INFO     Training average negative_sample_loss at step 106100: 0.074650\n",
      "2023-12-19 00:07:16,801 INFO     Training average loss at step 106100: 0.079717\n",
      "2023-12-19 00:08:59,785 INFO     Training average positive_sample_loss at step 106200: 0.084312\n",
      "2023-12-19 00:08:59,786 INFO     Training average negative_sample_loss at step 106200: 0.074642\n",
      "2023-12-19 00:08:59,786 INFO     Training average loss at step 106200: 0.079477\n",
      "2023-12-19 00:10:39,284 INFO     Training average positive_sample_loss at step 106300: 0.084909\n",
      "2023-12-19 00:10:39,284 INFO     Training average negative_sample_loss at step 106300: 0.074347\n",
      "2023-12-19 00:10:39,284 INFO     Training average loss at step 106300: 0.079628\n",
      "2023-12-19 00:12:11,305 INFO     Training average positive_sample_loss at step 106400: 0.085701\n",
      "2023-12-19 00:12:11,306 INFO     Training average negative_sample_loss at step 106400: 0.074307\n",
      "2023-12-19 00:12:11,306 INFO     Training average loss at step 106400: 0.080004\n",
      "2023-12-19 00:13:46,127 INFO     Training average positive_sample_loss at step 106500: 0.085415\n",
      "2023-12-19 00:13:46,127 INFO     Training average negative_sample_loss at step 106500: 0.074861\n",
      "2023-12-19 00:13:46,127 INFO     Training average loss at step 106500: 0.080138\n",
      "2023-12-19 00:15:26,442 INFO     Training average positive_sample_loss at step 106600: 0.085953\n",
      "2023-12-19 00:15:26,442 INFO     Training average negative_sample_loss at step 106600: 0.074865\n",
      "2023-12-19 00:15:26,442 INFO     Training average loss at step 106600: 0.080409\n",
      "2023-12-19 00:17:01,572 INFO     Training average positive_sample_loss at step 106700: 0.086244\n",
      "2023-12-19 00:17:01,572 INFO     Training average negative_sample_loss at step 106700: 0.074850\n",
      "2023-12-19 00:17:01,572 INFO     Training average loss at step 106700: 0.080547\n",
      "2023-12-19 00:18:56,821 INFO     Training average positive_sample_loss at step 106800: 0.086091\n",
      "2023-12-19 00:18:56,821 INFO     Training average negative_sample_loss at step 106800: 0.074955\n",
      "2023-12-19 00:18:56,821 INFO     Training average loss at step 106800: 0.080523\n",
      "2023-12-19 00:20:23,899 INFO     Training average positive_sample_loss at step 106900: 0.086244\n",
      "2023-12-19 00:20:23,899 INFO     Training average negative_sample_loss at step 106900: 0.074812\n",
      "2023-12-19 00:20:23,899 INFO     Training average loss at step 106900: 0.080528\n",
      "2023-12-19 00:22:24,313 INFO     Training average positive_sample_loss at step 107000: 0.086247\n",
      "2023-12-19 00:22:24,313 INFO     Training average negative_sample_loss at step 107000: 0.075377\n",
      "2023-12-19 00:22:24,313 INFO     Training average loss at step 107000: 0.080812\n",
      "2023-12-19 00:23:56,882 INFO     Training average positive_sample_loss at step 107100: 0.083712\n",
      "2023-12-19 00:23:56,883 INFO     Training average negative_sample_loss at step 107100: 0.074768\n",
      "2023-12-19 00:23:56,883 INFO     Training average loss at step 107100: 0.079240\n",
      "2023-12-19 00:25:33,529 INFO     Training average positive_sample_loss at step 107200: 0.085091\n",
      "2023-12-19 00:25:33,530 INFO     Training average negative_sample_loss at step 107200: 0.074603\n",
      "2023-12-19 00:25:33,530 INFO     Training average loss at step 107200: 0.079847\n",
      "2023-12-19 00:27:27,453 INFO     Training average positive_sample_loss at step 107300: 0.085190\n",
      "2023-12-19 00:27:27,454 INFO     Training average negative_sample_loss at step 107300: 0.074330\n",
      "2023-12-19 00:27:27,454 INFO     Training average loss at step 107300: 0.079760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 00:29:17,766 INFO     Training average positive_sample_loss at step 107400: 0.085559\n",
      "2023-12-19 00:29:17,766 INFO     Training average negative_sample_loss at step 107400: 0.074662\n",
      "2023-12-19 00:29:17,766 INFO     Training average loss at step 107400: 0.080111\n",
      "2023-12-19 00:31:08,798 INFO     Training average positive_sample_loss at step 107500: 0.085817\n",
      "2023-12-19 00:31:08,799 INFO     Training average negative_sample_loss at step 107500: 0.074897\n",
      "2023-12-19 00:31:08,799 INFO     Training average loss at step 107500: 0.080357\n",
      "2023-12-19 00:32:44,286 INFO     Training average positive_sample_loss at step 107600: 0.085980\n",
      "2023-12-19 00:32:44,287 INFO     Training average negative_sample_loss at step 107600: 0.074921\n",
      "2023-12-19 00:32:44,287 INFO     Training average loss at step 107600: 0.080450\n",
      "2023-12-19 00:34:16,858 INFO     Training average positive_sample_loss at step 107700: 0.086328\n",
      "2023-12-19 00:34:16,858 INFO     Training average negative_sample_loss at step 107700: 0.074804\n",
      "2023-12-19 00:34:16,858 INFO     Training average loss at step 107700: 0.080566\n",
      "2023-12-19 00:35:58,297 INFO     Training average positive_sample_loss at step 107800: 0.085963\n",
      "2023-12-19 00:35:58,297 INFO     Training average negative_sample_loss at step 107800: 0.074733\n",
      "2023-12-19 00:35:58,297 INFO     Training average loss at step 107800: 0.080348\n",
      "2023-12-19 00:37:47,991 INFO     Training average positive_sample_loss at step 107900: 0.086154\n",
      "2023-12-19 00:37:47,991 INFO     Training average negative_sample_loss at step 107900: 0.075042\n",
      "2023-12-19 00:37:47,992 INFO     Training average loss at step 107900: 0.080598\n",
      "2023-12-19 00:39:39,785 INFO     Training average positive_sample_loss at step 108000: 0.084589\n",
      "2023-12-19 00:39:39,785 INFO     Training average negative_sample_loss at step 108000: 0.075051\n",
      "2023-12-19 00:39:39,785 INFO     Training average loss at step 108000: 0.079820\n",
      "2023-12-19 00:41:28,276 INFO     Training average positive_sample_loss at step 108100: 0.084062\n",
      "2023-12-19 00:41:28,277 INFO     Training average negative_sample_loss at step 108100: 0.074205\n",
      "2023-12-19 00:41:28,277 INFO     Training average loss at step 108100: 0.079134\n",
      "2023-12-19 00:43:17,729 INFO     Training average positive_sample_loss at step 108200: 0.085079\n",
      "2023-12-19 00:43:17,730 INFO     Training average negative_sample_loss at step 108200: 0.074184\n",
      "2023-12-19 00:43:17,730 INFO     Training average loss at step 108200: 0.079631\n",
      "2023-12-19 00:45:27,346 INFO     Training average positive_sample_loss at step 108300: 0.085362\n",
      "2023-12-19 00:45:27,346 INFO     Training average negative_sample_loss at step 108300: 0.074714\n",
      "2023-12-19 00:45:27,346 INFO     Training average loss at step 108300: 0.080038\n",
      "2023-12-19 00:47:39,890 INFO     Training average positive_sample_loss at step 108400: 0.085817\n",
      "2023-12-19 00:47:39,890 INFO     Training average negative_sample_loss at step 108400: 0.074564\n",
      "2023-12-19 00:47:39,890 INFO     Training average loss at step 108400: 0.080191\n",
      "2023-12-19 00:49:56,966 INFO     Training average positive_sample_loss at step 108500: 0.086178\n",
      "2023-12-19 00:49:56,966 INFO     Training average negative_sample_loss at step 108500: 0.074886\n",
      "2023-12-19 00:49:56,966 INFO     Training average loss at step 108500: 0.080532\n",
      "2023-12-19 00:51:53,105 INFO     Training average positive_sample_loss at step 108600: 0.086100\n",
      "2023-12-19 00:51:53,106 INFO     Training average negative_sample_loss at step 108600: 0.074988\n",
      "2023-12-19 00:51:53,106 INFO     Training average loss at step 108600: 0.080544\n",
      "2023-12-19 00:54:01,053 INFO     Training average positive_sample_loss at step 108700: 0.085962\n",
      "2023-12-19 00:54:01,054 INFO     Training average negative_sample_loss at step 108700: 0.074987\n",
      "2023-12-19 00:54:01,054 INFO     Training average loss at step 108700: 0.080475\n",
      "2023-12-19 00:55:50,911 INFO     Training average positive_sample_loss at step 108800: 0.086666\n",
      "2023-12-19 00:55:50,911 INFO     Training average negative_sample_loss at step 108800: 0.075419\n",
      "2023-12-19 00:55:50,911 INFO     Training average loss at step 108800: 0.081043\n",
      "2023-12-19 00:57:51,425 INFO     Training average positive_sample_loss at step 108900: 0.085934\n",
      "2023-12-19 00:57:51,426 INFO     Training average negative_sample_loss at step 108900: 0.075277\n",
      "2023-12-19 00:57:51,426 INFO     Training average loss at step 108900: 0.080605\n",
      "2023-12-19 00:59:19,324 INFO     Training average positive_sample_loss at step 109000: 0.084387\n",
      "2023-12-19 00:59:19,325 INFO     Training average negative_sample_loss at step 109000: 0.074762\n",
      "2023-12-19 00:59:19,325 INFO     Training average loss at step 109000: 0.079574\n",
      "2023-12-19 01:00:57,610 INFO     Training average positive_sample_loss at step 109100: 0.084745\n",
      "2023-12-19 01:00:57,610 INFO     Training average negative_sample_loss at step 109100: 0.074152\n",
      "2023-12-19 01:00:57,610 INFO     Training average loss at step 109100: 0.079449\n",
      "2023-12-19 01:02:32,760 INFO     Training average positive_sample_loss at step 109200: 0.085327\n",
      "2023-12-19 01:02:32,760 INFO     Training average negative_sample_loss at step 109200: 0.074800\n",
      "2023-12-19 01:02:32,760 INFO     Training average loss at step 109200: 0.080064\n",
      "2023-12-19 01:04:10,044 INFO     Training average positive_sample_loss at step 109300: 0.085466\n",
      "2023-12-19 01:04:10,045 INFO     Training average negative_sample_loss at step 109300: 0.074608\n",
      "2023-12-19 01:04:10,045 INFO     Training average loss at step 109300: 0.080037\n",
      "2023-12-19 01:05:55,813 INFO     Training average positive_sample_loss at step 109400: 0.085842\n",
      "2023-12-19 01:05:55,813 INFO     Training average negative_sample_loss at step 109400: 0.074522\n",
      "2023-12-19 01:05:55,813 INFO     Training average loss at step 109400: 0.080182\n",
      "2023-12-19 01:07:46,181 INFO     Training average positive_sample_loss at step 109500: 0.085934\n",
      "2023-12-19 01:07:46,181 INFO     Training average negative_sample_loss at step 109500: 0.075088\n",
      "2023-12-19 01:07:46,181 INFO     Training average loss at step 109500: 0.080511\n",
      "2023-12-19 01:09:17,803 INFO     Training average positive_sample_loss at step 109600: 0.085574\n",
      "2023-12-19 01:09:17,803 INFO     Training average negative_sample_loss at step 109600: 0.074239\n",
      "2023-12-19 01:09:17,803 INFO     Training average loss at step 109600: 0.079906\n",
      "2023-12-19 01:10:50,333 INFO     Training average positive_sample_loss at step 109700: 0.086336\n",
      "2023-12-19 01:10:50,333 INFO     Training average negative_sample_loss at step 109700: 0.075037\n",
      "2023-12-19 01:10:50,333 INFO     Training average loss at step 109700: 0.080687\n",
      "2023-12-19 01:12:30,256 INFO     Training average positive_sample_loss at step 109800: 0.086180\n",
      "2023-12-19 01:12:30,256 INFO     Training average negative_sample_loss at step 109800: 0.074921\n",
      "2023-12-19 01:12:30,257 INFO     Training average loss at step 109800: 0.080551\n",
      "2023-12-19 01:14:36,840 INFO     Training average positive_sample_loss at step 109900: 0.084661\n",
      "2023-12-19 01:14:36,840 INFO     Training average negative_sample_loss at step 109900: 0.075004\n",
      "2023-12-19 01:14:36,840 INFO     Training average loss at step 109900: 0.079833\n",
      "2023-12-19 01:16:15,288 INFO     Training average positive_sample_loss at step 110000: 0.084233\n",
      "2023-12-19 01:16:15,288 INFO     Training average negative_sample_loss at step 110000: 0.074411\n",
      "2023-12-19 01:16:15,289 INFO     Training average loss at step 110000: 0.079322\n",
      "2023-12-19 01:16:15,289 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-19 01:16:16,009 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-19 01:16:42,775 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-19 01:17:08,380 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-19 01:17:34,288 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-19 01:17:58,200 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-19 01:18:21,755 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-19 01:18:45,680 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-19 01:18:51,738 INFO     Valid MRR at step 110000: 0.449913\n",
      "2023-12-19 01:18:51,739 INFO     Valid MR at step 110000: 218.620650\n",
      "2023-12-19 01:18:51,739 INFO     Valid HITS@1 at step 110000: 0.353020\n",
      "2023-12-19 01:18:51,739 INFO     Valid HITS@3 at step 110000: 0.485080\n",
      "2023-12-19 01:18:51,739 INFO     Valid HITS@10 at step 110000: 0.657920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 01:20:19,266 INFO     Training average positive_sample_loss at step 110100: 0.085108\n",
      "2023-12-19 01:20:19,267 INFO     Training average negative_sample_loss at step 110100: 0.074301\n",
      "2023-12-19 01:20:19,267 INFO     Training average loss at step 110100: 0.079705\n",
      "2023-12-19 01:22:17,127 INFO     Training average positive_sample_loss at step 110200: 0.085608\n",
      "2023-12-19 01:22:17,128 INFO     Training average negative_sample_loss at step 110200: 0.074683\n",
      "2023-12-19 01:22:17,128 INFO     Training average loss at step 110200: 0.080145\n",
      "2023-12-19 01:24:05,259 INFO     Training average positive_sample_loss at step 110300: 0.085751\n",
      "2023-12-19 01:24:05,260 INFO     Training average negative_sample_loss at step 110300: 0.074585\n",
      "2023-12-19 01:24:05,260 INFO     Training average loss at step 110300: 0.080168\n",
      "2023-12-19 01:25:42,939 INFO     Training average positive_sample_loss at step 110400: 0.085910\n",
      "2023-12-19 01:25:42,940 INFO     Training average negative_sample_loss at step 110400: 0.074719\n",
      "2023-12-19 01:25:42,940 INFO     Training average loss at step 110400: 0.080315\n",
      "2023-12-19 01:27:16,711 INFO     Training average positive_sample_loss at step 110500: 0.085937\n",
      "2023-12-19 01:27:16,712 INFO     Training average negative_sample_loss at step 110500: 0.074923\n",
      "2023-12-19 01:27:16,712 INFO     Training average loss at step 110500: 0.080430\n",
      "2023-12-19 01:28:53,602 INFO     Training average positive_sample_loss at step 110600: 0.085791\n",
      "2023-12-19 01:28:53,603 INFO     Training average negative_sample_loss at step 110600: 0.074744\n",
      "2023-12-19 01:28:53,603 INFO     Training average loss at step 110600: 0.080267\n",
      "2023-12-19 01:30:28,753 INFO     Training average positive_sample_loss at step 110700: 0.086274\n",
      "2023-12-19 01:30:28,753 INFO     Training average negative_sample_loss at step 110700: 0.075166\n",
      "2023-12-19 01:30:28,753 INFO     Training average loss at step 110700: 0.080720\n",
      "2023-12-19 01:32:24,667 INFO     Training average positive_sample_loss at step 110800: 0.085434\n",
      "2023-12-19 01:32:24,667 INFO     Training average negative_sample_loss at step 110800: 0.075265\n",
      "2023-12-19 01:32:24,667 INFO     Training average loss at step 110800: 0.080349\n",
      "2023-12-19 01:34:18,712 INFO     Training average positive_sample_loss at step 110900: 0.083654\n",
      "2023-12-19 01:34:18,713 INFO     Training average negative_sample_loss at step 110900: 0.074120\n",
      "2023-12-19 01:34:18,713 INFO     Training average loss at step 110900: 0.078887\n",
      "2023-12-19 01:36:04,699 INFO     Training average positive_sample_loss at step 111000: 0.084928\n",
      "2023-12-19 01:36:04,699 INFO     Training average negative_sample_loss at step 111000: 0.074421\n",
      "2023-12-19 01:36:04,699 INFO     Training average loss at step 111000: 0.079674\n",
      "2023-12-19 01:37:54,210 INFO     Training average positive_sample_loss at step 111100: 0.085527\n",
      "2023-12-19 01:37:54,210 INFO     Training average negative_sample_loss at step 111100: 0.074559\n",
      "2023-12-19 01:37:54,210 INFO     Training average loss at step 111100: 0.080043\n",
      "2023-12-19 01:40:12,943 INFO     Training average positive_sample_loss at step 111200: 0.085615\n",
      "2023-12-19 01:40:12,943 INFO     Training average negative_sample_loss at step 111200: 0.074719\n",
      "2023-12-19 01:40:12,944 INFO     Training average loss at step 111200: 0.080167\n",
      "2023-12-19 01:42:36,093 INFO     Training average positive_sample_loss at step 111300: 0.086111\n",
      "2023-12-19 01:42:36,094 INFO     Training average negative_sample_loss at step 111300: 0.074428\n",
      "2023-12-19 01:42:36,094 INFO     Training average loss at step 111300: 0.080270\n",
      "2023-12-19 01:44:39,103 INFO     Training average positive_sample_loss at step 111400: 0.085743\n",
      "2023-12-19 01:44:39,104 INFO     Training average negative_sample_loss at step 111400: 0.074856\n",
      "2023-12-19 01:44:39,104 INFO     Training average loss at step 111400: 0.080299\n",
      "2023-12-19 01:46:55,983 INFO     Training average positive_sample_loss at step 111500: 0.085952\n",
      "2023-12-19 01:46:55,983 INFO     Training average negative_sample_loss at step 111500: 0.075106\n",
      "2023-12-19 01:46:55,983 INFO     Training average loss at step 111500: 0.080529\n",
      "2023-12-19 01:49:10,753 INFO     Training average positive_sample_loss at step 111600: 0.086483\n",
      "2023-12-19 01:49:10,753 INFO     Training average negative_sample_loss at step 111600: 0.075389\n",
      "2023-12-19 01:49:10,753 INFO     Training average loss at step 111600: 0.080936\n",
      "2023-12-19 01:51:25,716 INFO     Training average positive_sample_loss at step 111700: 0.086602\n",
      "2023-12-19 01:51:25,717 INFO     Training average negative_sample_loss at step 111700: 0.075340\n",
      "2023-12-19 01:51:25,717 INFO     Training average loss at step 111700: 0.080971\n",
      "2023-12-19 01:53:20,579 INFO     Training average positive_sample_loss at step 111800: 0.083785\n",
      "2023-12-19 01:53:20,580 INFO     Training average negative_sample_loss at step 111800: 0.074758\n",
      "2023-12-19 01:53:20,580 INFO     Training average loss at step 111800: 0.079272\n",
      "2023-12-19 01:55:06,269 INFO     Training average positive_sample_loss at step 111900: 0.084697\n",
      "2023-12-19 01:55:06,269 INFO     Training average negative_sample_loss at step 111900: 0.074552\n",
      "2023-12-19 01:55:06,269 INFO     Training average loss at step 111900: 0.079625\n",
      "2023-12-19 01:57:05,929 INFO     Training average positive_sample_loss at step 112000: 0.085093\n",
      "2023-12-19 01:57:05,930 INFO     Training average negative_sample_loss at step 112000: 0.074230\n",
      "2023-12-19 01:57:05,930 INFO     Training average loss at step 112000: 0.079661\n",
      "2023-12-19 01:58:49,354 INFO     Training average positive_sample_loss at step 112100: 0.085655\n",
      "2023-12-19 01:58:49,355 INFO     Training average negative_sample_loss at step 112100: 0.074434\n",
      "2023-12-19 01:58:49,355 INFO     Training average loss at step 112100: 0.080044\n",
      "2023-12-19 02:00:22,822 INFO     Training average positive_sample_loss at step 112200: 0.085840\n",
      "2023-12-19 02:00:22,822 INFO     Training average negative_sample_loss at step 112200: 0.074949\n",
      "2023-12-19 02:00:22,822 INFO     Training average loss at step 112200: 0.080395\n",
      "2023-12-19 02:01:50,488 INFO     Training average positive_sample_loss at step 112300: 0.085671\n",
      "2023-12-19 02:01:50,488 INFO     Training average negative_sample_loss at step 112300: 0.074344\n",
      "2023-12-19 02:01:50,488 INFO     Training average loss at step 112300: 0.080007\n",
      "2023-12-19 02:03:15,407 INFO     Training average positive_sample_loss at step 112400: 0.085774\n",
      "2023-12-19 02:03:15,407 INFO     Training average negative_sample_loss at step 112400: 0.074976\n",
      "2023-12-19 02:03:15,408 INFO     Training average loss at step 112400: 0.080375\n",
      "2023-12-19 02:04:46,784 INFO     Training average positive_sample_loss at step 112500: 0.086312\n",
      "2023-12-19 02:04:46,784 INFO     Training average negative_sample_loss at step 112500: 0.075142\n",
      "2023-12-19 02:04:46,784 INFO     Training average loss at step 112500: 0.080727\n",
      "2023-12-19 02:06:27,275 INFO     Training average positive_sample_loss at step 112600: 0.086222\n",
      "2023-12-19 02:06:27,275 INFO     Training average negative_sample_loss at step 112600: 0.074723\n",
      "2023-12-19 02:06:27,276 INFO     Training average loss at step 112600: 0.080472\n",
      "2023-12-19 02:08:15,615 INFO     Training average positive_sample_loss at step 112700: 0.085204\n",
      "2023-12-19 02:08:15,616 INFO     Training average negative_sample_loss at step 112700: 0.075176\n",
      "2023-12-19 02:08:15,616 INFO     Training average loss at step 112700: 0.080190\n",
      "2023-12-19 02:09:49,566 INFO     Training average positive_sample_loss at step 112800: 0.084216\n",
      "2023-12-19 02:09:49,566 INFO     Training average negative_sample_loss at step 112800: 0.074680\n",
      "2023-12-19 02:09:49,567 INFO     Training average loss at step 112800: 0.079448\n",
      "2023-12-19 02:11:15,482 INFO     Training average positive_sample_loss at step 112900: 0.084837\n",
      "2023-12-19 02:11:15,482 INFO     Training average negative_sample_loss at step 112900: 0.074261\n",
      "2023-12-19 02:11:15,482 INFO     Training average loss at step 112900: 0.079549\n",
      "2023-12-19 02:12:39,854 INFO     Training average positive_sample_loss at step 113000: 0.085389\n",
      "2023-12-19 02:12:39,855 INFO     Training average negative_sample_loss at step 113000: 0.074660\n",
      "2023-12-19 02:12:39,855 INFO     Training average loss at step 113000: 0.080025\n",
      "2023-12-19 02:14:08,048 INFO     Training average positive_sample_loss at step 113100: 0.085582\n",
      "2023-12-19 02:14:08,048 INFO     Training average negative_sample_loss at step 113100: 0.074653\n",
      "2023-12-19 02:14:08,048 INFO     Training average loss at step 113100: 0.080117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 02:15:35,931 INFO     Training average positive_sample_loss at step 113200: 0.085787\n",
      "2023-12-19 02:15:35,932 INFO     Training average negative_sample_loss at step 113200: 0.074227\n",
      "2023-12-19 02:15:35,932 INFO     Training average loss at step 113200: 0.080007\n",
      "2023-12-19 02:17:27,405 INFO     Training average positive_sample_loss at step 113300: 0.085849\n",
      "2023-12-19 02:17:27,405 INFO     Training average negative_sample_loss at step 113300: 0.074676\n",
      "2023-12-19 02:17:27,406 INFO     Training average loss at step 113300: 0.080263\n",
      "2023-12-19 02:19:05,492 INFO     Training average positive_sample_loss at step 113400: 0.086447\n",
      "2023-12-19 02:19:05,492 INFO     Training average negative_sample_loss at step 113400: 0.075601\n",
      "2023-12-19 02:19:05,492 INFO     Training average loss at step 113400: 0.081024\n",
      "2023-12-19 02:20:37,596 INFO     Training average positive_sample_loss at step 113500: 0.086150\n",
      "2023-12-19 02:20:37,596 INFO     Training average negative_sample_loss at step 113500: 0.075144\n",
      "2023-12-19 02:20:37,596 INFO     Training average loss at step 113500: 0.080647\n",
      "2023-12-19 02:22:21,824 INFO     Training average positive_sample_loss at step 113600: 0.085871\n",
      "2023-12-19 02:22:21,825 INFO     Training average negative_sample_loss at step 113600: 0.074577\n",
      "2023-12-19 02:22:21,825 INFO     Training average loss at step 113600: 0.080224\n",
      "2023-12-19 02:23:59,915 INFO     Training average positive_sample_loss at step 113700: 0.084170\n",
      "2023-12-19 02:23:59,915 INFO     Training average negative_sample_loss at step 113700: 0.074733\n",
      "2023-12-19 02:23:59,916 INFO     Training average loss at step 113700: 0.079452\n",
      "2023-12-19 02:25:40,544 INFO     Training average positive_sample_loss at step 113800: 0.084689\n",
      "2023-12-19 02:25:40,544 INFO     Training average negative_sample_loss at step 113800: 0.074459\n",
      "2023-12-19 02:25:40,544 INFO     Training average loss at step 113800: 0.079574\n",
      "2023-12-19 02:27:08,278 INFO     Training average positive_sample_loss at step 113900: 0.085099\n",
      "2023-12-19 02:27:08,279 INFO     Training average negative_sample_loss at step 113900: 0.074554\n",
      "2023-12-19 02:27:08,279 INFO     Training average loss at step 113900: 0.079827\n",
      "2023-12-19 02:28:45,159 INFO     Training average positive_sample_loss at step 114000: 0.085613\n",
      "2023-12-19 02:28:45,159 INFO     Training average negative_sample_loss at step 114000: 0.074859\n",
      "2023-12-19 02:28:45,160 INFO     Training average loss at step 114000: 0.080236\n",
      "2023-12-19 02:30:22,211 INFO     Training average positive_sample_loss at step 114100: 0.085627\n",
      "2023-12-19 02:30:22,211 INFO     Training average negative_sample_loss at step 114100: 0.074529\n",
      "2023-12-19 02:30:22,211 INFO     Training average loss at step 114100: 0.080078\n",
      "2023-12-19 02:32:04,085 INFO     Training average positive_sample_loss at step 114200: 0.085610\n",
      "2023-12-19 02:32:04,085 INFO     Training average negative_sample_loss at step 114200: 0.074590\n",
      "2023-12-19 02:32:04,085 INFO     Training average loss at step 114200: 0.080100\n",
      "2023-12-19 02:33:37,218 INFO     Training average positive_sample_loss at step 114300: 0.086302\n",
      "2023-12-19 02:33:37,219 INFO     Training average negative_sample_loss at step 114300: 0.074870\n",
      "2023-12-19 02:33:37,219 INFO     Training average loss at step 114300: 0.080586\n",
      "2023-12-19 02:35:10,575 INFO     Training average positive_sample_loss at step 114400: 0.086279\n",
      "2023-12-19 02:35:10,575 INFO     Training average negative_sample_loss at step 114400: 0.075314\n",
      "2023-12-19 02:35:10,575 INFO     Training average loss at step 114400: 0.080797\n",
      "2023-12-19 02:36:43,424 INFO     Training average positive_sample_loss at step 114500: 0.085954\n",
      "2023-12-19 02:36:43,424 INFO     Training average negative_sample_loss at step 114500: 0.074544\n",
      "2023-12-19 02:36:43,424 INFO     Training average loss at step 114500: 0.080249\n",
      "2023-12-19 02:38:31,874 INFO     Training average positive_sample_loss at step 114600: 0.084858\n",
      "2023-12-19 02:38:31,874 INFO     Training average negative_sample_loss at step 114600: 0.075182\n",
      "2023-12-19 02:38:31,874 INFO     Training average loss at step 114600: 0.080020\n",
      "2023-12-19 02:40:18,325 INFO     Training average positive_sample_loss at step 114700: 0.083972\n",
      "2023-12-19 02:40:18,326 INFO     Training average negative_sample_loss at step 114700: 0.073925\n",
      "2023-12-19 02:40:18,326 INFO     Training average loss at step 114700: 0.078948\n",
      "2023-12-19 02:41:57,173 INFO     Training average positive_sample_loss at step 114800: 0.085239\n",
      "2023-12-19 02:41:57,173 INFO     Training average negative_sample_loss at step 114800: 0.074864\n",
      "2023-12-19 02:41:57,173 INFO     Training average loss at step 114800: 0.080051\n",
      "2023-12-19 02:43:49,962 INFO     Training average positive_sample_loss at step 114900: 0.085113\n",
      "2023-12-19 02:43:49,963 INFO     Training average negative_sample_loss at step 114900: 0.074457\n",
      "2023-12-19 02:43:49,963 INFO     Training average loss at step 114900: 0.079785\n",
      "2023-12-19 02:45:18,571 INFO     Training average positive_sample_loss at step 115000: 0.086142\n",
      "2023-12-19 02:45:18,571 INFO     Training average negative_sample_loss at step 115000: 0.074753\n",
      "2023-12-19 02:45:18,572 INFO     Training average loss at step 115000: 0.080447\n",
      "2023-12-19 02:46:46,553 INFO     Training average positive_sample_loss at step 115100: 0.085775\n",
      "2023-12-19 02:46:46,553 INFO     Training average negative_sample_loss at step 115100: 0.074582\n",
      "2023-12-19 02:46:46,553 INFO     Training average loss at step 115100: 0.080178\n",
      "2023-12-19 02:48:12,412 INFO     Training average positive_sample_loss at step 115200: 0.085674\n",
      "2023-12-19 02:48:12,413 INFO     Training average negative_sample_loss at step 115200: 0.074281\n",
      "2023-12-19 02:48:12,413 INFO     Training average loss at step 115200: 0.079977\n",
      "2023-12-19 02:49:42,071 INFO     Training average positive_sample_loss at step 115300: 0.085917\n",
      "2023-12-19 02:49:42,072 INFO     Training average negative_sample_loss at step 115300: 0.074687\n",
      "2023-12-19 02:49:42,072 INFO     Training average loss at step 115300: 0.080302\n",
      "2023-12-19 02:51:15,760 INFO     Training average positive_sample_loss at step 115400: 0.086639\n",
      "2023-12-19 02:51:15,760 INFO     Training average negative_sample_loss at step 115400: 0.075317\n",
      "2023-12-19 02:51:15,760 INFO     Training average loss at step 115400: 0.080978\n",
      "2023-12-19 02:53:01,362 INFO     Training average positive_sample_loss at step 115500: 0.085774\n",
      "2023-12-19 02:53:01,362 INFO     Training average negative_sample_loss at step 115500: 0.074974\n",
      "2023-12-19 02:53:01,362 INFO     Training average loss at step 115500: 0.080374\n",
      "2023-12-19 02:54:44,966 INFO     Training average positive_sample_loss at step 115600: 0.083391\n",
      "2023-12-19 02:54:44,967 INFO     Training average negative_sample_loss at step 115600: 0.074522\n",
      "2023-12-19 02:54:44,967 INFO     Training average loss at step 115600: 0.078956\n",
      "2023-12-19 02:56:36,418 INFO     Training average positive_sample_loss at step 115700: 0.084963\n",
      "2023-12-19 02:56:36,419 INFO     Training average negative_sample_loss at step 115700: 0.074482\n",
      "2023-12-19 02:56:36,419 INFO     Training average loss at step 115700: 0.079722\n",
      "2023-12-19 02:58:15,735 INFO     Training average positive_sample_loss at step 115800: 0.085345\n",
      "2023-12-19 02:58:15,735 INFO     Training average negative_sample_loss at step 115800: 0.074719\n",
      "2023-12-19 02:58:15,735 INFO     Training average loss at step 115800: 0.080032\n",
      "2023-12-19 02:59:48,137 INFO     Training average positive_sample_loss at step 115900: 0.085500\n",
      "2023-12-19 02:59:48,138 INFO     Training average negative_sample_loss at step 115900: 0.074364\n",
      "2023-12-19 02:59:48,138 INFO     Training average loss at step 115900: 0.079932\n",
      "2023-12-19 03:01:11,374 INFO     Training average positive_sample_loss at step 116000: 0.085755\n",
      "2023-12-19 03:01:11,374 INFO     Training average negative_sample_loss at step 116000: 0.074693\n",
      "2023-12-19 03:01:11,374 INFO     Training average loss at step 116000: 0.080224\n",
      "2023-12-19 03:02:46,813 INFO     Training average positive_sample_loss at step 116100: 0.086095\n",
      "2023-12-19 03:02:46,814 INFO     Training average negative_sample_loss at step 116100: 0.074473\n",
      "2023-12-19 03:02:46,814 INFO     Training average loss at step 116100: 0.080284\n",
      "2023-12-19 03:04:17,976 INFO     Training average positive_sample_loss at step 116200: 0.086024\n",
      "2023-12-19 03:04:17,976 INFO     Training average negative_sample_loss at step 116200: 0.075138\n",
      "2023-12-19 03:04:17,977 INFO     Training average loss at step 116200: 0.080581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 03:05:46,608 INFO     Training average positive_sample_loss at step 116300: 0.086009\n",
      "2023-12-19 03:05:46,609 INFO     Training average negative_sample_loss at step 116300: 0.075114\n",
      "2023-12-19 03:05:46,609 INFO     Training average loss at step 116300: 0.080562\n",
      "2023-12-19 03:07:27,028 INFO     Training average positive_sample_loss at step 116400: 0.085969\n",
      "2023-12-19 03:07:27,029 INFO     Training average negative_sample_loss at step 116400: 0.074710\n",
      "2023-12-19 03:07:27,029 INFO     Training average loss at step 116400: 0.080340\n",
      "2023-12-19 03:09:17,095 INFO     Training average positive_sample_loss at step 116500: 0.083985\n",
      "2023-12-19 03:09:17,095 INFO     Training average negative_sample_loss at step 116500: 0.074623\n",
      "2023-12-19 03:09:17,095 INFO     Training average loss at step 116500: 0.079304\n",
      "2023-12-19 03:11:12,574 INFO     Training average positive_sample_loss at step 116600: 0.084933\n",
      "2023-12-19 03:11:12,575 INFO     Training average negative_sample_loss at step 116600: 0.074582\n",
      "2023-12-19 03:11:12,575 INFO     Training average loss at step 116600: 0.079757\n",
      "2023-12-19 03:12:46,214 INFO     Training average positive_sample_loss at step 116700: 0.085089\n",
      "2023-12-19 03:12:46,214 INFO     Training average negative_sample_loss at step 116700: 0.074322\n",
      "2023-12-19 03:12:46,214 INFO     Training average loss at step 116700: 0.079706\n",
      "2023-12-19 03:14:13,322 INFO     Training average positive_sample_loss at step 116800: 0.084986\n",
      "2023-12-19 03:14:13,323 INFO     Training average negative_sample_loss at step 116800: 0.074040\n",
      "2023-12-19 03:14:13,323 INFO     Training average loss at step 116800: 0.079513\n",
      "2023-12-19 03:15:39,054 INFO     Training average positive_sample_loss at step 116900: 0.085388\n",
      "2023-12-19 03:15:39,055 INFO     Training average negative_sample_loss at step 116900: 0.074709\n",
      "2023-12-19 03:15:39,055 INFO     Training average loss at step 116900: 0.080048\n",
      "2023-12-19 03:17:04,704 INFO     Training average positive_sample_loss at step 117000: 0.086189\n",
      "2023-12-19 03:17:04,704 INFO     Training average negative_sample_loss at step 117000: 0.074934\n",
      "2023-12-19 03:17:04,704 INFO     Training average loss at step 117000: 0.080561\n",
      "2023-12-19 03:18:28,595 INFO     Training average positive_sample_loss at step 117100: 0.085731\n",
      "2023-12-19 03:18:28,595 INFO     Training average negative_sample_loss at step 117100: 0.074759\n",
      "2023-12-19 03:18:28,595 INFO     Training average loss at step 117100: 0.080245\n",
      "2023-12-19 03:20:03,590 INFO     Training average positive_sample_loss at step 117200: 0.086106\n",
      "2023-12-19 03:20:03,590 INFO     Training average negative_sample_loss at step 117200: 0.074855\n",
      "2023-12-19 03:20:03,590 INFO     Training average loss at step 117200: 0.080480\n",
      "2023-12-19 03:21:32,842 INFO     Training average positive_sample_loss at step 117300: 0.086231\n",
      "2023-12-19 03:21:32,843 INFO     Training average negative_sample_loss at step 117300: 0.075252\n",
      "2023-12-19 03:21:32,843 INFO     Training average loss at step 117300: 0.080741\n",
      "2023-12-19 03:23:20,284 INFO     Training average positive_sample_loss at step 117400: 0.085499\n",
      "2023-12-19 03:23:20,284 INFO     Training average negative_sample_loss at step 117400: 0.074951\n",
      "2023-12-19 03:23:20,284 INFO     Training average loss at step 117400: 0.080225\n",
      "2023-12-19 03:25:19,148 INFO     Training average positive_sample_loss at step 117500: 0.083939\n",
      "2023-12-19 03:25:19,148 INFO     Training average negative_sample_loss at step 117500: 0.074124\n",
      "2023-12-19 03:25:19,148 INFO     Training average loss at step 117500: 0.079032\n",
      "2023-12-19 03:27:12,221 INFO     Training average positive_sample_loss at step 117600: 0.085308\n",
      "2023-12-19 03:27:12,221 INFO     Training average negative_sample_loss at step 117600: 0.074653\n",
      "2023-12-19 03:27:12,221 INFO     Training average loss at step 117600: 0.079980\n",
      "2023-12-19 03:28:39,065 INFO     Training average positive_sample_loss at step 117700: 0.085255\n",
      "2023-12-19 03:28:39,065 INFO     Training average negative_sample_loss at step 117700: 0.074395\n",
      "2023-12-19 03:28:39,065 INFO     Training average loss at step 117700: 0.079825\n",
      "2023-12-19 03:30:16,950 INFO     Training average positive_sample_loss at step 117800: 0.085452\n",
      "2023-12-19 03:30:16,950 INFO     Training average negative_sample_loss at step 117800: 0.074210\n",
      "2023-12-19 03:30:16,950 INFO     Training average loss at step 117800: 0.079831\n",
      "2023-12-19 03:31:58,777 INFO     Training average positive_sample_loss at step 117900: 0.085722\n",
      "2023-12-19 03:31:58,777 INFO     Training average negative_sample_loss at step 117900: 0.074827\n",
      "2023-12-19 03:31:58,777 INFO     Training average loss at step 117900: 0.080275\n",
      "2023-12-19 03:33:46,826 INFO     Training average positive_sample_loss at step 118000: 0.085739\n",
      "2023-12-19 03:33:46,826 INFO     Training average negative_sample_loss at step 118000: 0.074827\n",
      "2023-12-19 03:33:46,826 INFO     Training average loss at step 118000: 0.080283\n",
      "2023-12-19 03:35:15,773 INFO     Training average positive_sample_loss at step 118100: 0.085799\n",
      "2023-12-19 03:35:15,774 INFO     Training average negative_sample_loss at step 118100: 0.074918\n",
      "2023-12-19 03:35:15,774 INFO     Training average loss at step 118100: 0.080358\n",
      "2023-12-19 03:36:39,727 INFO     Training average positive_sample_loss at step 118200: 0.086004\n",
      "2023-12-19 03:36:39,727 INFO     Training average negative_sample_loss at step 118200: 0.074849\n",
      "2023-12-19 03:36:39,727 INFO     Training average loss at step 118200: 0.080427\n",
      "2023-12-19 03:38:09,856 INFO     Training average positive_sample_loss at step 118300: 0.086516\n",
      "2023-12-19 03:38:09,856 INFO     Training average negative_sample_loss at step 118300: 0.075268\n",
      "2023-12-19 03:38:09,857 INFO     Training average loss at step 118300: 0.080892\n",
      "2023-12-19 03:40:15,073 INFO     Training average positive_sample_loss at step 118400: 0.084152\n",
      "2023-12-19 03:40:15,074 INFO     Training average negative_sample_loss at step 118400: 0.074778\n",
      "2023-12-19 03:40:15,074 INFO     Training average loss at step 118400: 0.079465\n",
      "2023-12-19 03:41:56,791 INFO     Training average positive_sample_loss at step 118500: 0.084115\n",
      "2023-12-19 03:41:56,791 INFO     Training average negative_sample_loss at step 118500: 0.074372\n",
      "2023-12-19 03:41:56,791 INFO     Training average loss at step 118500: 0.079243\n",
      "2023-12-19 03:43:31,041 INFO     Training average positive_sample_loss at step 118600: 0.085209\n",
      "2023-12-19 03:43:31,042 INFO     Training average negative_sample_loss at step 118600: 0.074175\n",
      "2023-12-19 03:43:31,042 INFO     Training average loss at step 118600: 0.079692\n",
      "2023-12-19 03:44:56,892 INFO     Training average positive_sample_loss at step 118700: 0.085392\n",
      "2023-12-19 03:44:56,892 INFO     Training average negative_sample_loss at step 118700: 0.074557\n",
      "2023-12-19 03:44:56,892 INFO     Training average loss at step 118700: 0.079974\n",
      "2023-12-19 03:46:34,012 INFO     Training average positive_sample_loss at step 118800: 0.085326\n",
      "2023-12-19 03:46:34,012 INFO     Training average negative_sample_loss at step 118800: 0.074338\n",
      "2023-12-19 03:46:34,012 INFO     Training average loss at step 118800: 0.079832\n",
      "2023-12-19 03:48:01,782 INFO     Training average positive_sample_loss at step 118900: 0.085988\n",
      "2023-12-19 03:48:01,783 INFO     Training average negative_sample_loss at step 118900: 0.074559\n",
      "2023-12-19 03:48:01,783 INFO     Training average loss at step 118900: 0.080274\n",
      "2023-12-19 03:49:30,849 INFO     Training average positive_sample_loss at step 119000: 0.085903\n",
      "2023-12-19 03:49:30,850 INFO     Training average negative_sample_loss at step 119000: 0.074971\n",
      "2023-12-19 03:49:30,850 INFO     Training average loss at step 119000: 0.080437\n",
      "2023-12-19 03:51:05,677 INFO     Training average positive_sample_loss at step 119100: 0.085859\n",
      "2023-12-19 03:51:05,677 INFO     Training average negative_sample_loss at step 119100: 0.074870\n",
      "2023-12-19 03:51:05,678 INFO     Training average loss at step 119100: 0.080364\n",
      "2023-12-19 03:52:38,297 INFO     Training average positive_sample_loss at step 119200: 0.086427\n",
      "2023-12-19 03:52:38,298 INFO     Training average negative_sample_loss at step 119200: 0.075148\n",
      "2023-12-19 03:52:38,298 INFO     Training average loss at step 119200: 0.080788\n",
      "2023-12-19 03:54:29,311 INFO     Training average positive_sample_loss at step 119300: 0.085355\n",
      "2023-12-19 03:54:29,312 INFO     Training average negative_sample_loss at step 119300: 0.075141\n",
      "2023-12-19 03:54:29,312 INFO     Training average loss at step 119300: 0.080248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 03:56:04,251 INFO     Training average positive_sample_loss at step 119400: 0.084516\n",
      "2023-12-19 03:56:04,251 INFO     Training average negative_sample_loss at step 119400: 0.074640\n",
      "2023-12-19 03:56:04,251 INFO     Training average loss at step 119400: 0.079578\n",
      "2023-12-19 03:57:49,400 INFO     Training average positive_sample_loss at step 119500: 0.084595\n",
      "2023-12-19 03:57:49,401 INFO     Training average negative_sample_loss at step 119500: 0.074187\n",
      "2023-12-19 03:57:49,401 INFO     Training average loss at step 119500: 0.079391\n",
      "2023-12-19 03:59:59,381 INFO     Training average positive_sample_loss at step 119600: 0.085170\n",
      "2023-12-19 03:59:59,381 INFO     Training average negative_sample_loss at step 119600: 0.074178\n",
      "2023-12-19 03:59:59,381 INFO     Training average loss at step 119600: 0.079674\n",
      "2023-12-19 04:01:42,396 INFO     Training average positive_sample_loss at step 119700: 0.085539\n",
      "2023-12-19 04:01:42,396 INFO     Training average negative_sample_loss at step 119700: 0.074528\n",
      "2023-12-19 04:01:42,396 INFO     Training average loss at step 119700: 0.080033\n",
      "2023-12-19 04:03:17,351 INFO     Training average positive_sample_loss at step 119800: 0.085854\n",
      "2023-12-19 04:03:17,352 INFO     Training average negative_sample_loss at step 119800: 0.074624\n",
      "2023-12-19 04:03:17,352 INFO     Training average loss at step 119800: 0.080239\n",
      "2023-12-19 04:04:41,580 INFO     Training average positive_sample_loss at step 119900: 0.085875\n",
      "2023-12-19 04:04:41,580 INFO     Training average negative_sample_loss at step 119900: 0.074611\n",
      "2023-12-19 04:04:41,580 INFO     Training average loss at step 119900: 0.080243\n",
      "2023-12-19 04:06:07,733 INFO     Training average positive_sample_loss at step 120000: 0.085873\n",
      "2023-12-19 04:06:07,733 INFO     Training average negative_sample_loss at step 120000: 0.074927\n",
      "2023-12-19 04:06:07,733 INFO     Training average loss at step 120000: 0.080400\n",
      "2023-12-19 04:06:07,733 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-19 04:06:08,745 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-19 04:06:35,063 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-19 04:07:00,338 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-19 04:07:26,436 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-19 04:07:51,356 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-19 04:08:15,438 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-19 04:08:40,198 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-19 04:08:46,356 INFO     Valid MRR at step 120000: 0.449893\n",
      "2023-12-19 04:08:46,356 INFO     Valid MR at step 120000: 216.970500\n",
      "2023-12-19 04:08:46,356 INFO     Valid HITS@1 at step 120000: 0.353290\n",
      "2023-12-19 04:08:46,356 INFO     Valid HITS@3 at step 120000: 0.484360\n",
      "2023-12-19 04:08:46,356 INFO     Valid HITS@10 at step 120000: 0.658740\n",
      "2023-12-19 04:10:21,600 INFO     Training average positive_sample_loss at step 120100: 0.086139\n",
      "2023-12-19 04:10:21,600 INFO     Training average negative_sample_loss at step 120100: 0.074998\n",
      "2023-12-19 04:10:21,600 INFO     Training average loss at step 120100: 0.080569\n",
      "2023-12-19 04:11:50,355 INFO     Training average positive_sample_loss at step 120200: 0.086157\n",
      "2023-12-19 04:11:50,356 INFO     Training average negative_sample_loss at step 120200: 0.074990\n",
      "2023-12-19 04:11:50,356 INFO     Training average loss at step 120200: 0.080574\n",
      "2023-12-19 04:13:41,210 INFO     Training average positive_sample_loss at step 120300: 0.083921\n",
      "2023-12-19 04:13:41,211 INFO     Training average negative_sample_loss at step 120300: 0.074741\n",
      "2023-12-19 04:13:41,211 INFO     Training average loss at step 120300: 0.079331\n",
      "2023-12-19 04:15:17,241 INFO     Training average positive_sample_loss at step 120400: 0.084211\n",
      "2023-12-19 04:15:17,241 INFO     Training average negative_sample_loss at step 120400: 0.074078\n",
      "2023-12-19 04:15:17,241 INFO     Training average loss at step 120400: 0.079144\n",
      "2023-12-19 04:16:49,623 INFO     Training average positive_sample_loss at step 120500: 0.085100\n",
      "2023-12-19 04:16:49,624 INFO     Training average negative_sample_loss at step 120500: 0.074381\n",
      "2023-12-19 04:16:49,624 INFO     Training average loss at step 120500: 0.079741\n",
      "2023-12-19 04:18:16,197 INFO     Training average positive_sample_loss at step 120600: 0.085201\n",
      "2023-12-19 04:18:16,197 INFO     Training average negative_sample_loss at step 120600: 0.074330\n",
      "2023-12-19 04:18:16,197 INFO     Training average loss at step 120600: 0.079766\n",
      "2023-12-19 04:19:56,262 INFO     Training average positive_sample_loss at step 120700: 0.085619\n",
      "2023-12-19 04:19:56,262 INFO     Training average negative_sample_loss at step 120700: 0.074308\n",
      "2023-12-19 04:19:56,262 INFO     Training average loss at step 120700: 0.079964\n",
      "2023-12-19 04:21:32,563 INFO     Training average positive_sample_loss at step 120800: 0.085695\n",
      "2023-12-19 04:21:32,563 INFO     Training average negative_sample_loss at step 120800: 0.074708\n",
      "2023-12-19 04:21:32,563 INFO     Training average loss at step 120800: 0.080201\n",
      "2023-12-19 04:23:10,740 INFO     Training average positive_sample_loss at step 120900: 0.086031\n",
      "2023-12-19 04:23:10,740 INFO     Training average negative_sample_loss at step 120900: 0.074693\n",
      "2023-12-19 04:23:10,740 INFO     Training average loss at step 120900: 0.080362\n",
      "2023-12-19 04:24:46,287 INFO     Training average positive_sample_loss at step 121000: 0.086205\n",
      "2023-12-19 04:24:46,287 INFO     Training average negative_sample_loss at step 121000: 0.074986\n",
      "2023-12-19 04:24:46,288 INFO     Training average loss at step 121000: 0.080595\n",
      "2023-12-19 04:26:19,823 INFO     Training average positive_sample_loss at step 121100: 0.086358\n",
      "2023-12-19 04:26:19,824 INFO     Training average negative_sample_loss at step 121100: 0.075056\n",
      "2023-12-19 04:26:19,824 INFO     Training average loss at step 121100: 0.080707\n",
      "2023-12-19 04:28:14,529 INFO     Training average positive_sample_loss at step 121200: 0.084627\n",
      "2023-12-19 04:28:14,529 INFO     Training average negative_sample_loss at step 121200: 0.074813\n",
      "2023-12-19 04:28:14,529 INFO     Training average loss at step 121200: 0.079720\n",
      "2023-12-19 04:30:02,964 INFO     Training average positive_sample_loss at step 121300: 0.083921\n",
      "2023-12-19 04:30:02,964 INFO     Training average negative_sample_loss at step 121300: 0.074185\n",
      "2023-12-19 04:30:02,964 INFO     Training average loss at step 121300: 0.079053\n",
      "2023-12-19 04:31:46,451 INFO     Training average positive_sample_loss at step 121400: 0.085095\n",
      "2023-12-19 04:31:46,451 INFO     Training average negative_sample_loss at step 121400: 0.074442\n",
      "2023-12-19 04:31:46,451 INFO     Training average loss at step 121400: 0.079769\n",
      "2023-12-19 04:33:22,484 INFO     Training average positive_sample_loss at step 121500: 0.085389\n",
      "2023-12-19 04:33:22,484 INFO     Training average negative_sample_loss at step 121500: 0.074633\n",
      "2023-12-19 04:33:22,484 INFO     Training average loss at step 121500: 0.080011\n",
      "2023-12-19 04:34:53,748 INFO     Training average positive_sample_loss at step 121600: 0.085579\n",
      "2023-12-19 04:34:53,748 INFO     Training average negative_sample_loss at step 121600: 0.074584\n",
      "2023-12-19 04:34:53,748 INFO     Training average loss at step 121600: 0.080081\n",
      "2023-12-19 04:36:29,400 INFO     Training average positive_sample_loss at step 121700: 0.086318\n",
      "2023-12-19 04:36:29,400 INFO     Training average negative_sample_loss at step 121700: 0.074898\n",
      "2023-12-19 04:36:29,400 INFO     Training average loss at step 121700: 0.080608\n",
      "2023-12-19 04:37:56,598 INFO     Training average positive_sample_loss at step 121800: 0.085672\n",
      "2023-12-19 04:37:56,598 INFO     Training average negative_sample_loss at step 121800: 0.074688\n",
      "2023-12-19 04:37:56,598 INFO     Training average loss at step 121800: 0.080180\n",
      "2023-12-19 04:39:23,205 INFO     Training average positive_sample_loss at step 121900: 0.086010\n",
      "2023-12-19 04:39:23,205 INFO     Training average negative_sample_loss at step 121900: 0.074688\n",
      "2023-12-19 04:39:23,206 INFO     Training average loss at step 121900: 0.080349\n",
      "2023-12-19 04:40:49,400 INFO     Training average positive_sample_loss at step 122000: 0.085547\n",
      "2023-12-19 04:40:49,400 INFO     Training average negative_sample_loss at step 122000: 0.074508\n",
      "2023-12-19 04:40:49,400 INFO     Training average loss at step 122000: 0.080028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 04:42:47,274 INFO     Training average positive_sample_loss at step 122100: 0.086180\n",
      "2023-12-19 04:42:47,274 INFO     Training average negative_sample_loss at step 122100: 0.075067\n",
      "2023-12-19 04:42:47,274 INFO     Training average loss at step 122100: 0.080623\n",
      "2023-12-19 04:44:35,464 INFO     Training average positive_sample_loss at step 122200: 0.083858\n",
      "2023-12-19 04:44:35,464 INFO     Training average negative_sample_loss at step 122200: 0.074712\n",
      "2023-12-19 04:44:35,464 INFO     Training average loss at step 122200: 0.079285\n",
      "2023-12-19 04:46:24,750 INFO     Training average positive_sample_loss at step 122300: 0.084359\n",
      "2023-12-19 04:46:24,751 INFO     Training average negative_sample_loss at step 122300: 0.073990\n",
      "2023-12-19 04:46:24,751 INFO     Training average loss at step 122300: 0.079174\n",
      "2023-12-19 04:48:20,845 INFO     Training average positive_sample_loss at step 122400: 0.084997\n",
      "2023-12-19 04:48:20,845 INFO     Training average negative_sample_loss at step 122400: 0.074467\n",
      "2023-12-19 04:48:20,846 INFO     Training average loss at step 122400: 0.079732\n",
      "2023-12-19 04:50:11,560 INFO     Training average positive_sample_loss at step 122500: 0.085012\n",
      "2023-12-19 04:50:11,561 INFO     Training average negative_sample_loss at step 122500: 0.074259\n",
      "2023-12-19 04:50:11,561 INFO     Training average loss at step 122500: 0.079635\n",
      "2023-12-19 04:52:07,365 INFO     Training average positive_sample_loss at step 122600: 0.085993\n",
      "2023-12-19 04:52:07,366 INFO     Training average negative_sample_loss at step 122600: 0.074537\n",
      "2023-12-19 04:52:07,366 INFO     Training average loss at step 122600: 0.080265\n",
      "2023-12-19 04:53:44,610 INFO     Training average positive_sample_loss at step 122700: 0.085651\n",
      "2023-12-19 04:53:44,610 INFO     Training average negative_sample_loss at step 122700: 0.074507\n",
      "2023-12-19 04:53:44,610 INFO     Training average loss at step 122700: 0.080079\n",
      "2023-12-19 04:55:58,787 INFO     Training average positive_sample_loss at step 122800: 0.086120\n",
      "2023-12-19 04:55:58,787 INFO     Training average negative_sample_loss at step 122800: 0.075002\n",
      "2023-12-19 04:55:58,787 INFO     Training average loss at step 122800: 0.080561\n",
      "2023-12-19 04:58:16,195 INFO     Training average positive_sample_loss at step 122900: 0.086173\n",
      "2023-12-19 04:58:16,195 INFO     Training average negative_sample_loss at step 122900: 0.075217\n",
      "2023-12-19 04:58:16,195 INFO     Training average loss at step 122900: 0.080695\n",
      "2023-12-19 05:00:16,736 INFO     Training average positive_sample_loss at step 123000: 0.086125\n",
      "2023-12-19 05:00:16,736 INFO     Training average negative_sample_loss at step 123000: 0.074903\n",
      "2023-12-19 05:00:16,736 INFO     Training average loss at step 123000: 0.080514\n",
      "2023-12-19 05:02:24,527 INFO     Training average positive_sample_loss at step 123100: 0.084590\n",
      "2023-12-19 05:02:24,527 INFO     Training average negative_sample_loss at step 123100: 0.074791\n",
      "2023-12-19 05:02:24,527 INFO     Training average loss at step 123100: 0.079691\n",
      "2023-12-19 05:04:22,595 INFO     Training average positive_sample_loss at step 123200: 0.084519\n",
      "2023-12-19 05:04:22,595 INFO     Training average negative_sample_loss at step 123200: 0.074494\n",
      "2023-12-19 05:04:22,595 INFO     Training average loss at step 123200: 0.079507\n",
      "2023-12-19 05:06:12,496 INFO     Training average positive_sample_loss at step 123300: 0.084828\n",
      "2023-12-19 05:06:12,497 INFO     Training average negative_sample_loss at step 123300: 0.074287\n",
      "2023-12-19 05:06:12,497 INFO     Training average loss at step 123300: 0.079558\n",
      "2023-12-19 05:07:56,813 INFO     Training average positive_sample_loss at step 123400: 0.084944\n",
      "2023-12-19 05:07:56,813 INFO     Training average negative_sample_loss at step 123400: 0.074241\n",
      "2023-12-19 05:07:56,813 INFO     Training average loss at step 123400: 0.079592\n",
      "2023-12-19 05:09:53,118 INFO     Training average positive_sample_loss at step 123500: 0.085554\n",
      "2023-12-19 05:09:53,118 INFO     Training average negative_sample_loss at step 123500: 0.074417\n",
      "2023-12-19 05:09:53,118 INFO     Training average loss at step 123500: 0.079985\n",
      "2023-12-19 05:11:45,850 INFO     Training average positive_sample_loss at step 123600: 0.085899\n",
      "2023-12-19 05:11:45,850 INFO     Training average negative_sample_loss at step 123600: 0.074702\n",
      "2023-12-19 05:11:45,850 INFO     Training average loss at step 123600: 0.080300\n",
      "2023-12-19 05:13:52,549 INFO     Training average positive_sample_loss at step 123700: 0.085756\n",
      "2023-12-19 05:13:52,550 INFO     Training average negative_sample_loss at step 123700: 0.074432\n",
      "2023-12-19 05:13:52,550 INFO     Training average loss at step 123700: 0.080094\n",
      "2023-12-19 05:15:44,840 INFO     Training average positive_sample_loss at step 123800: 0.085933\n",
      "2023-12-19 05:15:44,840 INFO     Training average negative_sample_loss at step 123800: 0.074856\n",
      "2023-12-19 05:15:44,840 INFO     Training average loss at step 123800: 0.080394\n",
      "2023-12-19 05:17:32,857 INFO     Training average positive_sample_loss at step 123900: 0.086360\n",
      "2023-12-19 05:17:32,857 INFO     Training average negative_sample_loss at step 123900: 0.075231\n",
      "2023-12-19 05:17:32,857 INFO     Training average loss at step 123900: 0.080795\n",
      "2023-12-19 05:19:31,836 INFO     Training average positive_sample_loss at step 124000: 0.085823\n",
      "2023-12-19 05:19:31,836 INFO     Training average negative_sample_loss at step 124000: 0.075277\n",
      "2023-12-19 05:19:31,836 INFO     Training average loss at step 124000: 0.080550\n",
      "2023-12-19 05:21:11,820 INFO     Training average positive_sample_loss at step 124100: 0.083685\n",
      "2023-12-19 05:21:11,820 INFO     Training average negative_sample_loss at step 124100: 0.074214\n",
      "2023-12-19 05:21:11,820 INFO     Training average loss at step 124100: 0.078949\n",
      "2023-12-19 05:22:42,422 INFO     Training average positive_sample_loss at step 124200: 0.084627\n",
      "2023-12-19 05:22:42,423 INFO     Training average negative_sample_loss at step 124200: 0.074317\n",
      "2023-12-19 05:22:42,423 INFO     Training average loss at step 124200: 0.079472\n",
      "2023-12-19 05:24:10,167 INFO     Training average positive_sample_loss at step 124300: 0.085302\n",
      "2023-12-19 05:24:10,167 INFO     Training average negative_sample_loss at step 124300: 0.074505\n",
      "2023-12-19 05:24:10,167 INFO     Training average loss at step 124300: 0.079904\n",
      "2023-12-19 05:26:04,979 INFO     Training average positive_sample_loss at step 124400: 0.085547\n",
      "2023-12-19 05:26:04,980 INFO     Training average negative_sample_loss at step 124400: 0.074681\n",
      "2023-12-19 05:26:04,980 INFO     Training average loss at step 124400: 0.080114\n",
      "2023-12-19 05:27:57,043 INFO     Training average positive_sample_loss at step 124500: 0.085422\n",
      "2023-12-19 05:27:57,044 INFO     Training average negative_sample_loss at step 124500: 0.074402\n",
      "2023-12-19 05:27:57,044 INFO     Training average loss at step 124500: 0.079912\n",
      "2023-12-19 05:29:39,944 INFO     Training average positive_sample_loss at step 124600: 0.086039\n",
      "2023-12-19 05:29:39,944 INFO     Training average negative_sample_loss at step 124600: 0.074641\n",
      "2023-12-19 05:29:39,944 INFO     Training average loss at step 124600: 0.080340\n",
      "2023-12-19 05:31:12,773 INFO     Training average positive_sample_loss at step 124700: 0.085678\n",
      "2023-12-19 05:31:12,773 INFO     Training average negative_sample_loss at step 124700: 0.074791\n",
      "2023-12-19 05:31:12,773 INFO     Training average loss at step 124700: 0.080234\n",
      "2023-12-19 05:32:41,247 INFO     Training average positive_sample_loss at step 124800: 0.085956\n",
      "2023-12-19 05:32:41,247 INFO     Training average negative_sample_loss at step 124800: 0.074667\n",
      "2023-12-19 05:32:41,247 INFO     Training average loss at step 124800: 0.080311\n",
      "2023-12-19 05:34:18,879 INFO     Training average positive_sample_loss at step 124900: 0.086610\n",
      "2023-12-19 05:34:18,880 INFO     Training average negative_sample_loss at step 124900: 0.075333\n",
      "2023-12-19 05:34:18,881 INFO     Training average loss at step 124900: 0.080972\n",
      "2023-12-19 05:36:14,127 INFO     Training average positive_sample_loss at step 125000: 0.084332\n",
      "2023-12-19 05:36:14,128 INFO     Training average negative_sample_loss at step 125000: 0.074788\n",
      "2023-12-19 05:36:14,128 INFO     Training average loss at step 125000: 0.079560\n",
      "2023-12-19 05:37:52,879 INFO     Training average positive_sample_loss at step 125100: 0.084055\n",
      "2023-12-19 05:37:52,879 INFO     Training average negative_sample_loss at step 125100: 0.073995\n",
      "2023-12-19 05:37:52,879 INFO     Training average loss at step 125100: 0.079025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 05:39:26,989 INFO     Training average positive_sample_loss at step 125200: 0.084948\n",
      "2023-12-19 05:39:26,989 INFO     Training average negative_sample_loss at step 125200: 0.074238\n",
      "2023-12-19 05:39:26,989 INFO     Training average loss at step 125200: 0.079593\n",
      "2023-12-19 05:41:01,317 INFO     Training average positive_sample_loss at step 125300: 0.085414\n",
      "2023-12-19 05:41:01,317 INFO     Training average negative_sample_loss at step 125300: 0.074495\n",
      "2023-12-19 05:41:01,317 INFO     Training average loss at step 125300: 0.079955\n",
      "2023-12-19 05:42:38,493 INFO     Training average positive_sample_loss at step 125400: 0.085372\n",
      "2023-12-19 05:42:38,494 INFO     Training average negative_sample_loss at step 125400: 0.074623\n",
      "2023-12-19 05:42:38,494 INFO     Training average loss at step 125400: 0.079997\n",
      "2023-12-19 05:44:12,599 INFO     Training average positive_sample_loss at step 125500: 0.085906\n",
      "2023-12-19 05:44:12,600 INFO     Training average negative_sample_loss at step 125500: 0.074774\n",
      "2023-12-19 05:44:12,600 INFO     Training average loss at step 125500: 0.080340\n",
      "2023-12-19 05:45:48,884 INFO     Training average positive_sample_loss at step 125600: 0.085743\n",
      "2023-12-19 05:45:48,885 INFO     Training average negative_sample_loss at step 125600: 0.074620\n",
      "2023-12-19 05:45:48,885 INFO     Training average loss at step 125600: 0.080181\n",
      "2023-12-19 05:47:28,648 INFO     Training average positive_sample_loss at step 125700: 0.086342\n",
      "2023-12-19 05:47:28,648 INFO     Training average negative_sample_loss at step 125700: 0.075221\n",
      "2023-12-19 05:47:28,649 INFO     Training average loss at step 125700: 0.080781\n",
      "2023-12-19 05:49:05,579 INFO     Training average positive_sample_loss at step 125800: 0.086211\n",
      "2023-12-19 05:49:05,579 INFO     Training average negative_sample_loss at step 125800: 0.074878\n",
      "2023-12-19 05:49:05,579 INFO     Training average loss at step 125800: 0.080544\n",
      "2023-12-19 05:50:59,568 INFO     Training average positive_sample_loss at step 125900: 0.085219\n",
      "2023-12-19 05:50:59,568 INFO     Training average negative_sample_loss at step 125900: 0.074840\n",
      "2023-12-19 05:50:59,568 INFO     Training average loss at step 125900: 0.080029\n",
      "2023-12-19 05:52:40,757 INFO     Training average positive_sample_loss at step 126000: 0.083452\n",
      "2023-12-19 05:52:40,758 INFO     Training average negative_sample_loss at step 126000: 0.074299\n",
      "2023-12-19 05:52:40,758 INFO     Training average loss at step 126000: 0.078875\n",
      "2023-12-19 05:54:18,299 INFO     Training average positive_sample_loss at step 126100: 0.085139\n",
      "2023-12-19 05:54:18,300 INFO     Training average negative_sample_loss at step 126100: 0.074337\n",
      "2023-12-19 05:54:18,300 INFO     Training average loss at step 126100: 0.079738\n",
      "2023-12-19 05:55:51,830 INFO     Training average positive_sample_loss at step 126200: 0.085517\n",
      "2023-12-19 05:55:51,830 INFO     Training average negative_sample_loss at step 126200: 0.074400\n",
      "2023-12-19 05:55:51,830 INFO     Training average loss at step 126200: 0.079959\n",
      "2023-12-19 05:57:29,619 INFO     Training average positive_sample_loss at step 126300: 0.085359\n",
      "2023-12-19 05:57:29,620 INFO     Training average negative_sample_loss at step 126300: 0.074445\n",
      "2023-12-19 05:57:29,620 INFO     Training average loss at step 126300: 0.079902\n",
      "2023-12-19 05:59:09,822 INFO     Training average positive_sample_loss at step 126400: 0.085235\n",
      "2023-12-19 05:59:09,823 INFO     Training average negative_sample_loss at step 126400: 0.074459\n",
      "2023-12-19 05:59:09,823 INFO     Training average loss at step 126400: 0.079847\n",
      "2023-12-19 06:00:45,946 INFO     Training average positive_sample_loss at step 126500: 0.086099\n",
      "2023-12-19 06:00:45,946 INFO     Training average negative_sample_loss at step 126500: 0.074575\n",
      "2023-12-19 06:00:45,946 INFO     Training average loss at step 126500: 0.080337\n",
      "2023-12-19 06:02:20,027 INFO     Training average positive_sample_loss at step 126600: 0.086005\n",
      "2023-12-19 06:02:20,028 INFO     Training average negative_sample_loss at step 126600: 0.075115\n",
      "2023-12-19 06:02:20,028 INFO     Training average loss at step 126600: 0.080560\n",
      "2023-12-19 06:03:54,883 INFO     Training average positive_sample_loss at step 126700: 0.085939\n",
      "2023-12-19 06:03:54,883 INFO     Training average negative_sample_loss at step 126700: 0.074793\n",
      "2023-12-19 06:03:54,883 INFO     Training average loss at step 126700: 0.080366\n",
      "2023-12-19 06:05:26,846 INFO     Training average positive_sample_loss at step 126800: 0.086317\n",
      "2023-12-19 06:05:26,846 INFO     Training average negative_sample_loss at step 126800: 0.075319\n",
      "2023-12-19 06:05:26,846 INFO     Training average loss at step 126800: 0.080818\n",
      "2023-12-19 06:07:25,596 INFO     Training average positive_sample_loss at step 126900: 0.084068\n",
      "2023-12-19 06:07:25,596 INFO     Training average negative_sample_loss at step 126900: 0.074742\n",
      "2023-12-19 06:07:25,596 INFO     Training average loss at step 126900: 0.079405\n",
      "2023-12-19 06:09:16,198 INFO     Training average positive_sample_loss at step 127000: 0.084605\n",
      "2023-12-19 06:09:16,198 INFO     Training average negative_sample_loss at step 127000: 0.074329\n",
      "2023-12-19 06:09:16,198 INFO     Training average loss at step 127000: 0.079467\n",
      "2023-12-19 06:10:52,830 INFO     Training average positive_sample_loss at step 127100: 0.084926\n",
      "2023-12-19 06:10:52,831 INFO     Training average negative_sample_loss at step 127100: 0.074068\n",
      "2023-12-19 06:10:52,831 INFO     Training average loss at step 127100: 0.079497\n",
      "2023-12-19 06:12:41,643 INFO     Training average positive_sample_loss at step 127200: 0.085713\n",
      "2023-12-19 06:12:41,643 INFO     Training average negative_sample_loss at step 127200: 0.074699\n",
      "2023-12-19 06:12:41,643 INFO     Training average loss at step 127200: 0.080206\n",
      "2023-12-19 06:14:57,317 INFO     Training average positive_sample_loss at step 127300: 0.085194\n",
      "2023-12-19 06:14:57,317 INFO     Training average negative_sample_loss at step 127300: 0.074204\n",
      "2023-12-19 06:14:57,317 INFO     Training average loss at step 127300: 0.079699\n",
      "2023-12-19 06:17:04,532 INFO     Training average positive_sample_loss at step 127400: 0.085825\n",
      "2023-12-19 06:17:04,533 INFO     Training average negative_sample_loss at step 127400: 0.074848\n",
      "2023-12-19 06:17:04,533 INFO     Training average loss at step 127400: 0.080337\n",
      "2023-12-19 06:19:08,310 INFO     Training average positive_sample_loss at step 127500: 0.085918\n",
      "2023-12-19 06:19:08,311 INFO     Training average negative_sample_loss at step 127500: 0.074531\n",
      "2023-12-19 06:19:08,311 INFO     Training average loss at step 127500: 0.080224\n",
      "2023-12-19 06:21:15,465 INFO     Training average positive_sample_loss at step 127600: 0.085787\n",
      "2023-12-19 06:21:15,465 INFO     Training average negative_sample_loss at step 127600: 0.075040\n",
      "2023-12-19 06:21:15,465 INFO     Training average loss at step 127600: 0.080413\n",
      "2023-12-19 06:23:13,212 INFO     Training average positive_sample_loss at step 127700: 0.086054\n",
      "2023-12-19 06:23:13,212 INFO     Training average negative_sample_loss at step 127700: 0.075034\n",
      "2023-12-19 06:23:13,212 INFO     Training average loss at step 127700: 0.080544\n",
      "2023-12-19 06:25:24,203 INFO     Training average positive_sample_loss at step 127800: 0.085236\n",
      "2023-12-19 06:25:24,203 INFO     Training average negative_sample_loss at step 127800: 0.074782\n",
      "2023-12-19 06:25:24,203 INFO     Training average loss at step 127800: 0.080009\n",
      "2023-12-19 06:26:56,801 INFO     Training average positive_sample_loss at step 127900: 0.084245\n",
      "2023-12-19 06:26:56,802 INFO     Training average negative_sample_loss at step 127900: 0.074470\n",
      "2023-12-19 06:26:56,802 INFO     Training average loss at step 127900: 0.079357\n",
      "2023-12-19 06:28:27,511 INFO     Training average positive_sample_loss at step 128000: 0.084801\n",
      "2023-12-19 06:28:27,511 INFO     Training average negative_sample_loss at step 128000: 0.074232\n",
      "2023-12-19 06:28:27,511 INFO     Training average loss at step 128000: 0.079517\n",
      "2023-12-19 06:30:06,543 INFO     Training average positive_sample_loss at step 128100: 0.084870\n",
      "2023-12-19 06:30:06,544 INFO     Training average negative_sample_loss at step 128100: 0.073780\n",
      "2023-12-19 06:30:06,544 INFO     Training average loss at step 128100: 0.079325\n",
      "2023-12-19 06:31:43,969 INFO     Training average positive_sample_loss at step 128200: 0.085144\n",
      "2023-12-19 06:31:43,969 INFO     Training average negative_sample_loss at step 128200: 0.074539\n",
      "2023-12-19 06:31:43,969 INFO     Training average loss at step 128200: 0.079842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 06:33:20,464 INFO     Training average positive_sample_loss at step 128300: 0.085762\n",
      "2023-12-19 06:33:20,464 INFO     Training average negative_sample_loss at step 128300: 0.074513\n",
      "2023-12-19 06:33:20,464 INFO     Training average loss at step 128300: 0.080138\n",
      "2023-12-19 06:34:55,813 INFO     Training average positive_sample_loss at step 128400: 0.085751\n",
      "2023-12-19 06:34:55,813 INFO     Training average negative_sample_loss at step 128400: 0.074611\n",
      "2023-12-19 06:34:55,813 INFO     Training average loss at step 128400: 0.080181\n",
      "2023-12-19 06:36:30,229 INFO     Training average positive_sample_loss at step 128500: 0.086548\n",
      "2023-12-19 06:36:30,230 INFO     Training average negative_sample_loss at step 128500: 0.075240\n",
      "2023-12-19 06:36:30,230 INFO     Training average loss at step 128500: 0.080894\n",
      "2023-12-19 06:38:01,415 INFO     Training average positive_sample_loss at step 128600: 0.085737\n",
      "2023-12-19 06:38:01,415 INFO     Training average negative_sample_loss at step 128600: 0.074607\n",
      "2023-12-19 06:38:01,415 INFO     Training average loss at step 128600: 0.080172\n",
      "2023-12-19 06:39:32,743 INFO     Training average positive_sample_loss at step 128700: 0.086235\n",
      "2023-12-19 06:39:32,744 INFO     Training average negative_sample_loss at step 128700: 0.075110\n",
      "2023-12-19 06:39:32,744 INFO     Training average loss at step 128700: 0.080672\n",
      "2023-12-19 06:41:30,414 INFO     Training average positive_sample_loss at step 128800: 0.083568\n",
      "2023-12-19 06:41:30,415 INFO     Training average negative_sample_loss at step 128800: 0.074530\n",
      "2023-12-19 06:41:30,415 INFO     Training average loss at step 128800: 0.079049\n",
      "2023-12-19 06:43:32,081 INFO     Training average positive_sample_loss at step 128900: 0.085306\n",
      "2023-12-19 06:43:32,081 INFO     Training average negative_sample_loss at step 128900: 0.074833\n",
      "2023-12-19 06:43:32,081 INFO     Training average loss at step 128900: 0.080070\n",
      "2023-12-19 06:45:16,304 INFO     Training average positive_sample_loss at step 129000: 0.084656\n",
      "2023-12-19 06:45:16,304 INFO     Training average negative_sample_loss at step 129000: 0.074116\n",
      "2023-12-19 06:45:16,304 INFO     Training average loss at step 129000: 0.079386\n",
      "2023-12-19 06:46:49,575 INFO     Training average positive_sample_loss at step 129100: 0.085304\n",
      "2023-12-19 06:46:49,575 INFO     Training average negative_sample_loss at step 129100: 0.074146\n",
      "2023-12-19 06:46:49,575 INFO     Training average loss at step 129100: 0.079725\n",
      "2023-12-19 06:48:26,922 INFO     Training average positive_sample_loss at step 129200: 0.085272\n",
      "2023-12-19 06:48:26,923 INFO     Training average negative_sample_loss at step 129200: 0.074184\n",
      "2023-12-19 06:48:26,923 INFO     Training average loss at step 129200: 0.079728\n",
      "2023-12-19 06:50:04,578 INFO     Training average positive_sample_loss at step 129300: 0.085570\n",
      "2023-12-19 06:50:04,578 INFO     Training average negative_sample_loss at step 129300: 0.074529\n",
      "2023-12-19 06:50:04,578 INFO     Training average loss at step 129300: 0.080050\n",
      "2023-12-19 06:51:37,942 INFO     Training average positive_sample_loss at step 129400: 0.085890\n",
      "2023-12-19 06:51:37,942 INFO     Training average negative_sample_loss at step 129400: 0.074482\n",
      "2023-12-19 06:51:37,943 INFO     Training average loss at step 129400: 0.080186\n",
      "2023-12-19 06:53:11,389 INFO     Training average positive_sample_loss at step 129500: 0.086161\n",
      "2023-12-19 06:53:11,389 INFO     Training average negative_sample_loss at step 129500: 0.075256\n",
      "2023-12-19 06:53:11,389 INFO     Training average loss at step 129500: 0.080708\n",
      "2023-12-19 06:54:50,437 INFO     Training average positive_sample_loss at step 129600: 0.086145\n",
      "2023-12-19 06:54:50,438 INFO     Training average negative_sample_loss at step 129600: 0.075069\n",
      "2023-12-19 06:54:50,438 INFO     Training average loss at step 129600: 0.080607\n",
      "2023-12-19 06:56:59,742 INFO     Training average positive_sample_loss at step 129700: 0.084561\n",
      "2023-12-19 06:56:59,742 INFO     Training average negative_sample_loss at step 129700: 0.074820\n",
      "2023-12-19 06:56:59,742 INFO     Training average loss at step 129700: 0.079690\n",
      "2023-12-19 06:58:40,419 INFO     Training average positive_sample_loss at step 129800: 0.083984\n",
      "2023-12-19 06:58:40,419 INFO     Training average negative_sample_loss at step 129800: 0.074043\n",
      "2023-12-19 06:58:40,419 INFO     Training average loss at step 129800: 0.079014\n",
      "2023-12-19 07:00:33,235 INFO     Training average positive_sample_loss at step 129900: 0.084841\n",
      "2023-12-19 07:00:33,235 INFO     Training average negative_sample_loss at step 129900: 0.073896\n",
      "2023-12-19 07:00:33,235 INFO     Training average loss at step 129900: 0.079368\n",
      "2023-12-19 07:02:25,412 INFO     Training average positive_sample_loss at step 130000: 0.085079\n",
      "2023-12-19 07:02:25,412 INFO     Training average negative_sample_loss at step 130000: 0.074061\n",
      "2023-12-19 07:02:25,412 INFO     Training average loss at step 130000: 0.079570\n",
      "2023-12-19 07:02:25,412 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-19 07:02:26,179 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-19 07:02:52,626 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-19 07:03:18,067 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-19 07:03:44,063 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-19 07:04:08,934 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-19 07:04:33,117 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-19 07:04:56,413 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-19 07:05:02,441 INFO     Valid MRR at step 130000: 0.449986\n",
      "2023-12-19 07:05:02,442 INFO     Valid MR at step 130000: 216.388480\n",
      "2023-12-19 07:05:02,442 INFO     Valid HITS@1 at step 130000: 0.353990\n",
      "2023-12-19 07:05:02,442 INFO     Valid HITS@3 at step 130000: 0.483210\n",
      "2023-12-19 07:05:02,442 INFO     Valid HITS@10 at step 130000: 0.659360\n",
      "2023-12-19 07:06:48,204 INFO     Training average positive_sample_loss at step 130100: 0.085335\n",
      "2023-12-19 07:06:48,204 INFO     Training average negative_sample_loss at step 130100: 0.074341\n",
      "2023-12-19 07:06:48,204 INFO     Training average loss at step 130100: 0.079838\n",
      "2023-12-19 07:08:36,489 INFO     Training average positive_sample_loss at step 130200: 0.085672\n",
      "2023-12-19 07:08:36,489 INFO     Training average negative_sample_loss at step 130200: 0.074682\n",
      "2023-12-19 07:08:36,489 INFO     Training average loss at step 130200: 0.080177\n",
      "2023-12-19 07:10:25,417 INFO     Training average positive_sample_loss at step 130300: 0.085862\n",
      "2023-12-19 07:10:25,417 INFO     Training average negative_sample_loss at step 130300: 0.074831\n",
      "2023-12-19 07:10:25,417 INFO     Training average loss at step 130300: 0.080346\n",
      "2023-12-19 07:12:20,749 INFO     Training average positive_sample_loss at step 130400: 0.085943\n",
      "2023-12-19 07:12:20,749 INFO     Training average negative_sample_loss at step 130400: 0.074848\n",
      "2023-12-19 07:12:20,749 INFO     Training average loss at step 130400: 0.080396\n",
      "2023-12-19 07:14:07,121 INFO     Training average positive_sample_loss at step 130500: 0.086356\n",
      "2023-12-19 07:14:07,121 INFO     Training average negative_sample_loss at step 130500: 0.074859\n",
      "2023-12-19 07:14:07,121 INFO     Training average loss at step 130500: 0.080607\n",
      "2023-12-19 07:16:24,911 INFO     Training average positive_sample_loss at step 130600: 0.086298\n",
      "2023-12-19 07:16:24,911 INFO     Training average negative_sample_loss at step 130600: 0.075180\n",
      "2023-12-19 07:16:24,911 INFO     Training average loss at step 130600: 0.080739\n",
      "2023-12-19 07:17:56,988 INFO     Training average positive_sample_loss at step 130700: 0.084161\n",
      "2023-12-19 07:17:56,989 INFO     Training average negative_sample_loss at step 130700: 0.074885\n",
      "2023-12-19 07:17:56,989 INFO     Training average loss at step 130700: 0.079523\n",
      "2023-12-19 07:19:37,049 INFO     Training average positive_sample_loss at step 130800: 0.084522\n",
      "2023-12-19 07:19:37,049 INFO     Training average negative_sample_loss at step 130800: 0.074345\n",
      "2023-12-19 07:19:37,049 INFO     Training average loss at step 130800: 0.079434\n",
      "2023-12-19 07:21:19,392 INFO     Training average positive_sample_loss at step 130900: 0.085036\n",
      "2023-12-19 07:21:19,393 INFO     Training average negative_sample_loss at step 130900: 0.074037\n",
      "2023-12-19 07:21:19,393 INFO     Training average loss at step 130900: 0.079536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 07:22:52,167 INFO     Training average positive_sample_loss at step 131000: 0.085160\n",
      "2023-12-19 07:22:52,167 INFO     Training average negative_sample_loss at step 131000: 0.074309\n",
      "2023-12-19 07:22:52,167 INFO     Training average loss at step 131000: 0.079734\n",
      "2023-12-19 07:24:27,085 INFO     Training average positive_sample_loss at step 131100: 0.085461\n",
      "2023-12-19 07:24:27,085 INFO     Training average negative_sample_loss at step 131100: 0.074464\n",
      "2023-12-19 07:24:27,085 INFO     Training average loss at step 131100: 0.079962\n",
      "2023-12-19 07:26:00,223 INFO     Training average positive_sample_loss at step 131200: 0.085347\n",
      "2023-12-19 07:26:00,223 INFO     Training average negative_sample_loss at step 131200: 0.074252\n",
      "2023-12-19 07:26:00,223 INFO     Training average loss at step 131200: 0.079800\n",
      "2023-12-19 07:27:27,910 INFO     Training average positive_sample_loss at step 131300: 0.085795\n",
      "2023-12-19 07:27:27,910 INFO     Training average negative_sample_loss at step 131300: 0.074575\n",
      "2023-12-19 07:27:27,910 INFO     Training average loss at step 131300: 0.080185\n",
      "2023-12-19 07:28:51,975 INFO     Training average positive_sample_loss at step 131400: 0.085881\n",
      "2023-12-19 07:28:51,976 INFO     Training average negative_sample_loss at step 131400: 0.074655\n",
      "2023-12-19 07:28:51,976 INFO     Training average loss at step 131400: 0.080268\n",
      "2023-12-19 07:30:16,469 INFO     Training average positive_sample_loss at step 131500: 0.086031\n",
      "2023-12-19 07:30:16,469 INFO     Training average negative_sample_loss at step 131500: 0.075091\n",
      "2023-12-19 07:30:16,469 INFO     Training average loss at step 131500: 0.080561\n",
      "2023-12-19 07:32:16,818 INFO     Training average positive_sample_loss at step 131600: 0.084522\n",
      "2023-12-19 07:32:16,819 INFO     Training average negative_sample_loss at step 131600: 0.074851\n",
      "2023-12-19 07:32:16,819 INFO     Training average loss at step 131600: 0.079687\n",
      "2023-12-19 07:34:04,944 INFO     Training average positive_sample_loss at step 131700: 0.084152\n",
      "2023-12-19 07:34:04,944 INFO     Training average negative_sample_loss at step 131700: 0.074181\n",
      "2023-12-19 07:34:04,944 INFO     Training average loss at step 131700: 0.079166\n",
      "2023-12-19 07:35:43,688 INFO     Training average positive_sample_loss at step 131800: 0.084411\n",
      "2023-12-19 07:35:43,689 INFO     Training average negative_sample_loss at step 131800: 0.073797\n",
      "2023-12-19 07:35:43,689 INFO     Training average loss at step 131800: 0.079104\n",
      "2023-12-19 07:37:15,149 INFO     Training average positive_sample_loss at step 131900: 0.085694\n",
      "2023-12-19 07:37:15,150 INFO     Training average negative_sample_loss at step 131900: 0.074583\n",
      "2023-12-19 07:37:15,150 INFO     Training average loss at step 131900: 0.080138\n",
      "2023-12-19 07:38:52,274 INFO     Training average positive_sample_loss at step 132000: 0.085666\n",
      "2023-12-19 07:38:52,275 INFO     Training average negative_sample_loss at step 132000: 0.074835\n",
      "2023-12-19 07:38:52,275 INFO     Training average loss at step 132000: 0.080250\n",
      "2023-12-19 07:40:24,215 INFO     Training average positive_sample_loss at step 132100: 0.085195\n",
      "2023-12-19 07:40:24,215 INFO     Training average negative_sample_loss at step 132100: 0.074063\n",
      "2023-12-19 07:40:24,215 INFO     Training average loss at step 132100: 0.079629\n",
      "2023-12-19 07:41:48,535 INFO     Training average positive_sample_loss at step 132200: 0.085435\n",
      "2023-12-19 07:41:48,535 INFO     Training average negative_sample_loss at step 132200: 0.074392\n",
      "2023-12-19 07:41:48,535 INFO     Training average loss at step 132200: 0.079913\n",
      "2023-12-19 07:43:19,060 INFO     Training average positive_sample_loss at step 132300: 0.086069\n",
      "2023-12-19 07:43:19,060 INFO     Training average negative_sample_loss at step 132300: 0.074670\n",
      "2023-12-19 07:43:19,060 INFO     Training average loss at step 132300: 0.080370\n",
      "2023-12-19 07:44:50,771 INFO     Training average positive_sample_loss at step 132400: 0.086529\n",
      "2023-12-19 07:44:50,771 INFO     Training average negative_sample_loss at step 132400: 0.075189\n",
      "2023-12-19 07:44:50,771 INFO     Training average loss at step 132400: 0.080859\n",
      "2023-12-19 07:46:35,961 INFO     Training average positive_sample_loss at step 132500: 0.085484\n",
      "2023-12-19 07:46:35,962 INFO     Training average negative_sample_loss at step 132500: 0.075233\n",
      "2023-12-19 07:46:35,962 INFO     Training average loss at step 132500: 0.080358\n",
      "2023-12-19 07:48:14,889 INFO     Training average positive_sample_loss at step 132600: 0.084117\n",
      "2023-12-19 07:48:14,889 INFO     Training average negative_sample_loss at step 132600: 0.074413\n",
      "2023-12-19 07:48:14,890 INFO     Training average loss at step 132600: 0.079265\n",
      "2023-12-19 07:49:49,586 INFO     Training average positive_sample_loss at step 132700: 0.084217\n",
      "2023-12-19 07:49:49,586 INFO     Training average negative_sample_loss at step 132700: 0.073843\n",
      "2023-12-19 07:49:49,587 INFO     Training average loss at step 132700: 0.079030\n",
      "2023-12-19 07:51:47,720 INFO     Training average positive_sample_loss at step 132800: 0.085448\n",
      "2023-12-19 07:51:47,720 INFO     Training average negative_sample_loss at step 132800: 0.074283\n",
      "2023-12-19 07:51:47,720 INFO     Training average loss at step 132800: 0.079866\n",
      "2023-12-19 07:53:50,388 INFO     Training average positive_sample_loss at step 132900: 0.085244\n",
      "2023-12-19 07:53:50,388 INFO     Training average negative_sample_loss at step 132900: 0.074413\n",
      "2023-12-19 07:53:50,388 INFO     Training average loss at step 132900: 0.079828\n",
      "2023-12-19 07:55:48,958 INFO     Training average positive_sample_loss at step 133000: 0.085115\n",
      "2023-12-19 07:55:48,958 INFO     Training average negative_sample_loss at step 133000: 0.074106\n",
      "2023-12-19 07:55:48,958 INFO     Training average loss at step 133000: 0.079611\n",
      "2023-12-19 07:57:38,585 INFO     Training average positive_sample_loss at step 133100: 0.085822\n",
      "2023-12-19 07:57:38,585 INFO     Training average negative_sample_loss at step 133100: 0.074426\n",
      "2023-12-19 07:57:38,585 INFO     Training average loss at step 133100: 0.080124\n",
      "2023-12-19 07:59:43,047 INFO     Training average positive_sample_loss at step 133200: 0.085473\n",
      "2023-12-19 07:59:43,047 INFO     Training average negative_sample_loss at step 133200: 0.074954\n",
      "2023-12-19 07:59:43,047 INFO     Training average loss at step 133200: 0.080213\n",
      "2023-12-19 08:01:41,547 INFO     Training average positive_sample_loss at step 133300: 0.086271\n",
      "2023-12-19 08:01:41,548 INFO     Training average negative_sample_loss at step 133300: 0.075040\n",
      "2023-12-19 08:01:41,548 INFO     Training average loss at step 133300: 0.080655\n",
      "2023-12-19 08:03:26,627 INFO     Training average positive_sample_loss at step 133400: 0.086283\n",
      "2023-12-19 08:03:26,627 INFO     Training average negative_sample_loss at step 133400: 0.074863\n",
      "2023-12-19 08:03:26,627 INFO     Training average loss at step 133400: 0.080573\n",
      "2023-12-19 08:05:19,544 INFO     Training average positive_sample_loss at step 133500: 0.084078\n",
      "2023-12-19 08:05:19,545 INFO     Training average negative_sample_loss at step 133500: 0.074753\n",
      "2023-12-19 08:05:19,545 INFO     Training average loss at step 133500: 0.079415\n",
      "2023-12-19 08:06:47,061 INFO     Training average positive_sample_loss at step 133600: 0.084629\n",
      "2023-12-19 08:06:47,061 INFO     Training average negative_sample_loss at step 133600: 0.074325\n",
      "2023-12-19 08:06:47,061 INFO     Training average loss at step 133600: 0.079477\n",
      "2023-12-19 08:08:22,408 INFO     Training average positive_sample_loss at step 133700: 0.084619\n",
      "2023-12-19 08:08:22,409 INFO     Training average negative_sample_loss at step 133700: 0.074119\n",
      "2023-12-19 08:08:22,409 INFO     Training average loss at step 133700: 0.079369\n",
      "2023-12-19 08:09:46,934 INFO     Training average positive_sample_loss at step 133800: 0.084870\n",
      "2023-12-19 08:09:46,934 INFO     Training average negative_sample_loss at step 133800: 0.074274\n",
      "2023-12-19 08:09:46,934 INFO     Training average loss at step 133800: 0.079572\n",
      "2023-12-19 08:11:38,723 INFO     Training average positive_sample_loss at step 133900: 0.085244\n",
      "2023-12-19 08:11:38,723 INFO     Training average negative_sample_loss at step 133900: 0.074471\n",
      "2023-12-19 08:11:38,723 INFO     Training average loss at step 133900: 0.079857\n",
      "2023-12-19 08:13:16,983 INFO     Training average positive_sample_loss at step 134000: 0.085907\n",
      "2023-12-19 08:13:16,984 INFO     Training average negative_sample_loss at step 134000: 0.074822\n",
      "2023-12-19 08:13:16,984 INFO     Training average loss at step 134000: 0.080364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 08:14:53,397 INFO     Training average positive_sample_loss at step 134100: 0.086102\n",
      "2023-12-19 08:14:53,397 INFO     Training average negative_sample_loss at step 134100: 0.074859\n",
      "2023-12-19 08:14:53,397 INFO     Training average loss at step 134100: 0.080481\n",
      "2023-12-19 08:16:28,990 INFO     Training average positive_sample_loss at step 134200: 0.086190\n",
      "2023-12-19 08:16:28,990 INFO     Training average negative_sample_loss at step 134200: 0.075114\n",
      "2023-12-19 08:16:28,990 INFO     Training average loss at step 134200: 0.080652\n",
      "2023-12-19 08:18:08,285 INFO     Training average positive_sample_loss at step 134300: 0.086107\n",
      "2023-12-19 08:18:08,285 INFO     Training average negative_sample_loss at step 134300: 0.074630\n",
      "2023-12-19 08:18:08,285 INFO     Training average loss at step 134300: 0.080369\n",
      "2023-12-19 08:19:57,113 INFO     Training average positive_sample_loss at step 134400: 0.084889\n",
      "2023-12-19 08:19:57,113 INFO     Training average negative_sample_loss at step 134400: 0.074527\n",
      "2023-12-19 08:19:57,113 INFO     Training average loss at step 134400: 0.079708\n",
      "2023-12-19 08:21:34,644 INFO     Training average positive_sample_loss at step 134500: 0.084255\n",
      "2023-12-19 08:21:34,644 INFO     Training average negative_sample_loss at step 134500: 0.074748\n",
      "2023-12-19 08:21:34,645 INFO     Training average loss at step 134500: 0.079502\n",
      "2023-12-19 08:23:17,688 INFO     Training average positive_sample_loss at step 134600: 0.084184\n",
      "2023-12-19 08:23:17,688 INFO     Training average negative_sample_loss at step 134600: 0.074004\n",
      "2023-12-19 08:23:17,689 INFO     Training average loss at step 134600: 0.079094\n",
      "2023-12-19 08:24:53,229 INFO     Training average positive_sample_loss at step 134700: 0.085177\n",
      "2023-12-19 08:24:53,229 INFO     Training average negative_sample_loss at step 134700: 0.074052\n",
      "2023-12-19 08:24:53,229 INFO     Training average loss at step 134700: 0.079614\n",
      "2023-12-19 08:26:19,855 INFO     Training average positive_sample_loss at step 134800: 0.085658\n",
      "2023-12-19 08:26:19,855 INFO     Training average negative_sample_loss at step 134800: 0.074361\n",
      "2023-12-19 08:26:19,855 INFO     Training average loss at step 134800: 0.080010\n",
      "2023-12-19 08:27:49,418 INFO     Training average positive_sample_loss at step 134900: 0.085170\n",
      "2023-12-19 08:27:49,419 INFO     Training average negative_sample_loss at step 134900: 0.074483\n",
      "2023-12-19 08:27:49,419 INFO     Training average loss at step 134900: 0.079827\n",
      "2023-12-19 08:29:23,039 INFO     Training average positive_sample_loss at step 135000: 0.085899\n",
      "2023-12-19 08:29:23,040 INFO     Training average negative_sample_loss at step 135000: 0.074443\n",
      "2023-12-19 08:29:23,040 INFO     Training average loss at step 135000: 0.080171\n",
      "2023-12-19 08:30:47,383 INFO     Training average positive_sample_loss at step 135100: 0.086186\n",
      "2023-12-19 08:30:47,383 INFO     Training average negative_sample_loss at step 135100: 0.074761\n",
      "2023-12-19 08:30:47,383 INFO     Training average loss at step 135100: 0.080473\n",
      "2023-12-19 08:32:11,660 INFO     Training average positive_sample_loss at step 135200: 0.085871\n",
      "2023-12-19 08:32:11,660 INFO     Training average negative_sample_loss at step 135200: 0.074914\n",
      "2023-12-19 08:32:11,660 INFO     Training average loss at step 135200: 0.080392\n",
      "2023-12-19 08:33:36,071 INFO     Training average positive_sample_loss at step 135300: 0.086008\n",
      "2023-12-19 08:33:36,071 INFO     Training average negative_sample_loss at step 135300: 0.075010\n",
      "2023-12-19 08:33:36,071 INFO     Training average loss at step 135300: 0.080509\n",
      "2023-12-19 08:35:37,217 INFO     Training average positive_sample_loss at step 135400: 0.084088\n",
      "2023-12-19 08:35:37,218 INFO     Training average negative_sample_loss at step 135400: 0.074754\n",
      "2023-12-19 08:35:37,218 INFO     Training average loss at step 135400: 0.079421\n",
      "2023-12-19 08:37:36,588 INFO     Training average positive_sample_loss at step 135500: 0.084453\n",
      "2023-12-19 08:37:36,588 INFO     Training average negative_sample_loss at step 135500: 0.074254\n",
      "2023-12-19 08:37:36,588 INFO     Training average loss at step 135500: 0.079353\n",
      "2023-12-19 08:39:31,346 INFO     Training average positive_sample_loss at step 135600: 0.084606\n",
      "2023-12-19 08:39:31,346 INFO     Training average negative_sample_loss at step 135600: 0.073991\n",
      "2023-12-19 08:39:31,346 INFO     Training average loss at step 135600: 0.079298\n",
      "2023-12-19 08:41:18,918 INFO     Training average positive_sample_loss at step 135700: 0.085374\n",
      "2023-12-19 08:41:18,918 INFO     Training average negative_sample_loss at step 135700: 0.074347\n",
      "2023-12-19 08:41:18,918 INFO     Training average loss at step 135700: 0.079860\n",
      "2023-12-19 08:43:07,514 INFO     Training average positive_sample_loss at step 135800: 0.085509\n",
      "2023-12-19 08:43:07,514 INFO     Training average negative_sample_loss at step 135800: 0.074244\n",
      "2023-12-19 08:43:07,514 INFO     Training average loss at step 135800: 0.079876\n",
      "2023-12-19 08:45:08,978 INFO     Training average positive_sample_loss at step 135900: 0.085794\n",
      "2023-12-19 08:45:08,979 INFO     Training average negative_sample_loss at step 135900: 0.074680\n",
      "2023-12-19 08:45:08,979 INFO     Training average loss at step 135900: 0.080237\n",
      "2023-12-19 08:46:44,298 INFO     Training average positive_sample_loss at step 136000: 0.085778\n",
      "2023-12-19 08:46:44,298 INFO     Training average negative_sample_loss at step 136000: 0.075080\n",
      "2023-12-19 08:46:44,298 INFO     Training average loss at step 136000: 0.080429\n",
      "2023-12-19 08:48:09,244 INFO     Training average positive_sample_loss at step 136100: 0.085994\n",
      "2023-12-19 08:48:09,244 INFO     Training average negative_sample_loss at step 136100: 0.074628\n",
      "2023-12-19 08:48:09,244 INFO     Training average loss at step 136100: 0.080311\n",
      "2023-12-19 08:49:43,793 INFO     Training average positive_sample_loss at step 136200: 0.085893\n",
      "2023-12-19 08:49:43,794 INFO     Training average negative_sample_loss at step 136200: 0.074702\n",
      "2023-12-19 08:49:43,794 INFO     Training average loss at step 136200: 0.080297\n",
      "2023-12-19 08:51:31,121 INFO     Training average positive_sample_loss at step 136300: 0.084864\n",
      "2023-12-19 08:51:31,122 INFO     Training average negative_sample_loss at step 136300: 0.074810\n",
      "2023-12-19 08:51:31,122 INFO     Training average loss at step 136300: 0.079837\n",
      "2023-12-19 08:52:59,843 INFO     Training average positive_sample_loss at step 136400: 0.083957\n",
      "2023-12-19 08:52:59,843 INFO     Training average negative_sample_loss at step 136400: 0.074033\n",
      "2023-12-19 08:52:59,843 INFO     Training average loss at step 136400: 0.078995\n",
      "2023-12-19 08:54:53,600 INFO     Training average positive_sample_loss at step 136500: 0.084672\n",
      "2023-12-19 08:54:53,600 INFO     Training average negative_sample_loss at step 136500: 0.074112\n",
      "2023-12-19 08:54:53,600 INFO     Training average loss at step 136500: 0.079392\n",
      "2023-12-19 08:56:26,067 INFO     Training average positive_sample_loss at step 136600: 0.085070\n",
      "2023-12-19 08:56:26,067 INFO     Training average negative_sample_loss at step 136600: 0.074231\n",
      "2023-12-19 08:56:26,068 INFO     Training average loss at step 136600: 0.079650\n",
      "2023-12-19 08:58:14,090 INFO     Training average positive_sample_loss at step 136700: 0.085392\n",
      "2023-12-19 08:58:14,090 INFO     Training average negative_sample_loss at step 136700: 0.074248\n",
      "2023-12-19 08:58:14,090 INFO     Training average loss at step 136700: 0.079820\n",
      "2023-12-19 09:00:03,096 INFO     Training average positive_sample_loss at step 136800: 0.085272\n",
      "2023-12-19 09:00:03,096 INFO     Training average negative_sample_loss at step 136800: 0.074292\n",
      "2023-12-19 09:00:03,097 INFO     Training average loss at step 136800: 0.079782\n",
      "2023-12-19 09:02:10,759 INFO     Training average positive_sample_loss at step 136900: 0.085617\n",
      "2023-12-19 09:02:10,759 INFO     Training average negative_sample_loss at step 136900: 0.074412\n",
      "2023-12-19 09:02:10,759 INFO     Training average loss at step 136900: 0.080014\n",
      "2023-12-19 09:03:56,123 INFO     Training average positive_sample_loss at step 137000: 0.086098\n",
      "2023-12-19 09:03:56,123 INFO     Training average negative_sample_loss at step 137000: 0.075277\n",
      "2023-12-19 09:03:56,123 INFO     Training average loss at step 137000: 0.080687\n",
      "2023-12-19 09:05:58,373 INFO     Training average positive_sample_loss at step 137100: 0.086143\n",
      "2023-12-19 09:05:58,373 INFO     Training average negative_sample_loss at step 137100: 0.074778\n",
      "2023-12-19 09:05:58,373 INFO     Training average loss at step 137100: 0.080461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 09:08:17,913 INFO     Training average positive_sample_loss at step 137200: 0.086406\n",
      "2023-12-19 09:08:17,913 INFO     Training average negative_sample_loss at step 137200: 0.075203\n",
      "2023-12-19 09:08:17,913 INFO     Training average loss at step 137200: 0.080805\n",
      "2023-12-19 09:10:12,503 INFO     Training average positive_sample_loss at step 137300: 0.083495\n",
      "2023-12-19 09:10:12,504 INFO     Training average negative_sample_loss at step 137300: 0.074573\n",
      "2023-12-19 09:10:12,504 INFO     Training average loss at step 137300: 0.079034\n",
      "2023-12-19 09:12:01,965 INFO     Training average positive_sample_loss at step 137400: 0.084480\n",
      "2023-12-19 09:12:01,965 INFO     Training average negative_sample_loss at step 137400: 0.074176\n",
      "2023-12-19 09:12:01,965 INFO     Training average loss at step 137400: 0.079328\n",
      "2023-12-19 09:13:49,726 INFO     Training average positive_sample_loss at step 137500: 0.085012\n",
      "2023-12-19 09:13:49,726 INFO     Training average negative_sample_loss at step 137500: 0.074000\n",
      "2023-12-19 09:13:49,726 INFO     Training average loss at step 137500: 0.079506\n",
      "2023-12-19 09:15:55,862 INFO     Training average positive_sample_loss at step 137600: 0.085229\n",
      "2023-12-19 09:15:55,863 INFO     Training average negative_sample_loss at step 137600: 0.074198\n",
      "2023-12-19 09:15:55,863 INFO     Training average loss at step 137600: 0.079713\n",
      "2023-12-19 09:17:34,122 INFO     Training average positive_sample_loss at step 137700: 0.085343\n",
      "2023-12-19 09:17:34,123 INFO     Training average negative_sample_loss at step 137700: 0.074415\n",
      "2023-12-19 09:17:34,123 INFO     Training average loss at step 137700: 0.079879\n",
      "2023-12-19 09:19:47,635 INFO     Training average positive_sample_loss at step 137800: 0.085990\n",
      "2023-12-19 09:19:47,635 INFO     Training average negative_sample_loss at step 137800: 0.074629\n",
      "2023-12-19 09:19:47,635 INFO     Training average loss at step 137800: 0.080310\n",
      "2023-12-19 09:21:19,460 INFO     Training average positive_sample_loss at step 137900: 0.085704\n",
      "2023-12-19 09:21:19,461 INFO     Training average negative_sample_loss at step 137900: 0.074803\n",
      "2023-12-19 09:21:19,461 INFO     Training average loss at step 137900: 0.080253\n",
      "2023-12-19 09:23:14,518 INFO     Training average positive_sample_loss at step 138000: 0.085940\n",
      "2023-12-19 09:23:14,518 INFO     Training average negative_sample_loss at step 138000: 0.074863\n",
      "2023-12-19 09:23:14,518 INFO     Training average loss at step 138000: 0.080402\n",
      "2023-12-19 09:24:44,931 INFO     Training average positive_sample_loss at step 138100: 0.085972\n",
      "2023-12-19 09:24:44,931 INFO     Training average negative_sample_loss at step 138100: 0.074996\n",
      "2023-12-19 09:24:44,931 INFO     Training average loss at step 138100: 0.080484\n",
      "2023-12-19 09:26:35,061 INFO     Training average positive_sample_loss at step 138200: 0.084813\n",
      "2023-12-19 09:26:35,062 INFO     Training average negative_sample_loss at step 138200: 0.074603\n",
      "2023-12-19 09:26:35,062 INFO     Training average loss at step 138200: 0.079708\n",
      "2023-12-19 09:28:16,557 INFO     Training average positive_sample_loss at step 138300: 0.084210\n",
      "2023-12-19 09:28:16,557 INFO     Training average negative_sample_loss at step 138300: 0.074258\n",
      "2023-12-19 09:28:16,558 INFO     Training average loss at step 138300: 0.079234\n",
      "2023-12-19 09:29:45,800 INFO     Training average positive_sample_loss at step 138400: 0.084902\n",
      "2023-12-19 09:29:45,801 INFO     Training average negative_sample_loss at step 138400: 0.074371\n",
      "2023-12-19 09:29:45,801 INFO     Training average loss at step 138400: 0.079637\n",
      "2023-12-19 09:31:19,813 INFO     Training average positive_sample_loss at step 138500: 0.085163\n",
      "2023-12-19 09:31:19,814 INFO     Training average negative_sample_loss at step 138500: 0.074292\n",
      "2023-12-19 09:31:19,814 INFO     Training average loss at step 138500: 0.079727\n",
      "2023-12-19 09:32:51,974 INFO     Training average positive_sample_loss at step 138600: 0.085608\n",
      "2023-12-19 09:32:51,974 INFO     Training average negative_sample_loss at step 138600: 0.074090\n",
      "2023-12-19 09:32:51,974 INFO     Training average loss at step 138600: 0.079849\n",
      "2023-12-19 09:34:26,114 INFO     Training average positive_sample_loss at step 138700: 0.085368\n",
      "2023-12-19 09:34:26,114 INFO     Training average negative_sample_loss at step 138700: 0.074601\n",
      "2023-12-19 09:34:26,114 INFO     Training average loss at step 138700: 0.079984\n",
      "2023-12-19 09:36:00,170 INFO     Training average positive_sample_loss at step 138800: 0.085574\n",
      "2023-12-19 09:36:00,171 INFO     Training average negative_sample_loss at step 138800: 0.074662\n",
      "2023-12-19 09:36:00,171 INFO     Training average loss at step 138800: 0.080118\n",
      "2023-12-19 09:37:38,598 INFO     Training average positive_sample_loss at step 138900: 0.085656\n",
      "2023-12-19 09:37:38,599 INFO     Training average negative_sample_loss at step 138900: 0.074627\n",
      "2023-12-19 09:37:38,599 INFO     Training average loss at step 138900: 0.080142\n",
      "2023-12-19 09:39:12,937 INFO     Training average positive_sample_loss at step 139000: 0.085860\n",
      "2023-12-19 09:39:12,937 INFO     Training average negative_sample_loss at step 139000: 0.074415\n",
      "2023-12-19 09:39:12,937 INFO     Training average loss at step 139000: 0.080137\n",
      "2023-12-19 09:41:03,394 INFO     Training average positive_sample_loss at step 139100: 0.085643\n",
      "2023-12-19 09:41:03,395 INFO     Training average negative_sample_loss at step 139100: 0.075016\n",
      "2023-12-19 09:41:03,395 INFO     Training average loss at step 139100: 0.080330\n",
      "2023-12-19 09:42:55,266 INFO     Training average positive_sample_loss at step 139200: 0.083932\n",
      "2023-12-19 09:42:55,267 INFO     Training average negative_sample_loss at step 139200: 0.074466\n",
      "2023-12-19 09:42:55,267 INFO     Training average loss at step 139200: 0.079199\n",
      "2023-12-19 09:44:50,291 INFO     Training average positive_sample_loss at step 139300: 0.084764\n",
      "2023-12-19 09:44:50,291 INFO     Training average negative_sample_loss at step 139300: 0.074285\n",
      "2023-12-19 09:44:50,291 INFO     Training average loss at step 139300: 0.079524\n",
      "2023-12-19 09:47:01,326 INFO     Training average positive_sample_loss at step 139400: 0.085132\n",
      "2023-12-19 09:47:01,327 INFO     Training average negative_sample_loss at step 139400: 0.074358\n",
      "2023-12-19 09:47:01,327 INFO     Training average loss at step 139400: 0.079745\n",
      "2023-12-19 09:49:12,757 INFO     Training average positive_sample_loss at step 139500: 0.084769\n",
      "2023-12-19 09:49:12,757 INFO     Training average negative_sample_loss at step 139500: 0.073821\n",
      "2023-12-19 09:49:12,757 INFO     Training average loss at step 139500: 0.079295\n",
      "2023-12-19 09:51:10,956 INFO     Training average positive_sample_loss at step 139600: 0.085918\n",
      "2023-12-19 09:51:10,957 INFO     Training average negative_sample_loss at step 139600: 0.074733\n",
      "2023-12-19 09:51:10,957 INFO     Training average loss at step 139600: 0.080325\n",
      "2023-12-19 09:52:49,557 INFO     Training average positive_sample_loss at step 139700: 0.085838\n",
      "2023-12-19 09:52:49,557 INFO     Training average negative_sample_loss at step 139700: 0.074642\n",
      "2023-12-19 09:52:49,557 INFO     Training average loss at step 139700: 0.080240\n",
      "2023-12-19 09:54:31,818 INFO     Training average positive_sample_loss at step 139800: 0.085647\n",
      "2023-12-19 09:54:31,818 INFO     Training average negative_sample_loss at step 139800: 0.074516\n",
      "2023-12-19 09:54:31,818 INFO     Training average loss at step 139800: 0.080082\n",
      "2023-12-19 09:56:35,292 INFO     Training average positive_sample_loss at step 139900: 0.085996\n",
      "2023-12-19 09:56:35,292 INFO     Training average negative_sample_loss at step 139900: 0.075055\n",
      "2023-12-19 09:56:35,292 INFO     Training average loss at step 139900: 0.080526\n",
      "2023-12-19 09:58:44,645 INFO     Training average positive_sample_loss at step 140000: 0.085920\n",
      "2023-12-19 09:58:44,645 INFO     Training average negative_sample_loss at step 140000: 0.074696\n",
      "2023-12-19 09:58:44,645 INFO     Training average loss at step 140000: 0.080308\n",
      "2023-12-19 09:58:44,645 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-19 09:58:45,409 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-19 09:59:10,023 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-19 09:59:34,184 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-19 09:59:57,690 INFO     Evaluating the model... (3000/6250)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 10:00:21,876 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-19 10:00:45,466 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-19 10:01:09,045 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-19 10:01:14,622 INFO     Valid MRR at step 140000: 0.451868\n",
      "2023-12-19 10:01:14,623 INFO     Valid MR at step 140000: 214.857770\n",
      "2023-12-19 10:01:14,623 INFO     Valid HITS@1 at step 140000: 0.354690\n",
      "2023-12-19 10:01:14,623 INFO     Valid HITS@3 at step 140000: 0.487130\n",
      "2023-12-19 10:01:14,623 INFO     Valid HITS@10 at step 140000: 0.660990\n",
      "2023-12-19 10:02:53,871 INFO     Training average positive_sample_loss at step 140100: 0.084174\n",
      "2023-12-19 10:02:53,871 INFO     Training average negative_sample_loss at step 140100: 0.074657\n",
      "2023-12-19 10:02:53,871 INFO     Training average loss at step 140100: 0.079415\n",
      "2023-12-19 10:05:05,421 INFO     Training average positive_sample_loss at step 140200: 0.083990\n",
      "2023-12-19 10:05:05,422 INFO     Training average negative_sample_loss at step 140200: 0.074240\n",
      "2023-12-19 10:05:05,422 INFO     Training average loss at step 140200: 0.079115\n",
      "2023-12-19 10:06:58,661 INFO     Training average positive_sample_loss at step 140300: 0.084702\n",
      "2023-12-19 10:06:58,661 INFO     Training average negative_sample_loss at step 140300: 0.074011\n",
      "2023-12-19 10:06:58,661 INFO     Training average loss at step 140300: 0.079356\n",
      "2023-12-19 10:08:34,752 INFO     Training average positive_sample_loss at step 140400: 0.085045\n",
      "2023-12-19 10:08:34,753 INFO     Training average negative_sample_loss at step 140400: 0.073937\n",
      "2023-12-19 10:08:34,753 INFO     Training average loss at step 140400: 0.079491\n",
      "2023-12-19 10:10:21,374 INFO     Training average positive_sample_loss at step 140500: 0.085507\n",
      "2023-12-19 10:10:21,375 INFO     Training average negative_sample_loss at step 140500: 0.074338\n",
      "2023-12-19 10:10:21,375 INFO     Training average loss at step 140500: 0.079923\n",
      "2023-12-19 10:12:12,180 INFO     Training average positive_sample_loss at step 140600: 0.085822\n",
      "2023-12-19 10:12:12,180 INFO     Training average negative_sample_loss at step 140600: 0.074576\n",
      "2023-12-19 10:12:12,180 INFO     Training average loss at step 140600: 0.080199\n",
      "2023-12-19 10:14:14,399 INFO     Training average positive_sample_loss at step 140700: 0.086058\n",
      "2023-12-19 10:14:14,399 INFO     Training average negative_sample_loss at step 140700: 0.074975\n",
      "2023-12-19 10:14:14,399 INFO     Training average loss at step 140700: 0.080517\n",
      "2023-12-19 10:16:23,139 INFO     Training average positive_sample_loss at step 140800: 0.085671\n",
      "2023-12-19 10:16:23,139 INFO     Training average negative_sample_loss at step 140800: 0.074640\n",
      "2023-12-19 10:16:23,139 INFO     Training average loss at step 140800: 0.080156\n",
      "2023-12-19 10:18:25,268 INFO     Training average positive_sample_loss at step 140900: 0.086058\n",
      "2023-12-19 10:18:25,268 INFO     Training average negative_sample_loss at step 140900: 0.074995\n",
      "2023-12-19 10:18:25,268 INFO     Training average loss at step 140900: 0.080526\n",
      "2023-12-19 10:20:29,578 INFO     Training average positive_sample_loss at step 141000: 0.085196\n",
      "2023-12-19 10:20:29,578 INFO     Training average negative_sample_loss at step 141000: 0.074649\n",
      "2023-12-19 10:20:29,578 INFO     Training average loss at step 141000: 0.079923\n",
      "2023-12-19 10:22:14,462 INFO     Training average positive_sample_loss at step 141100: 0.083720\n",
      "2023-12-19 10:22:14,463 INFO     Training average negative_sample_loss at step 141100: 0.074264\n",
      "2023-12-19 10:22:14,463 INFO     Training average loss at step 141100: 0.078992\n",
      "2023-12-19 10:24:02,198 INFO     Training average positive_sample_loss at step 141200: 0.084553\n",
      "2023-12-19 10:24:02,199 INFO     Training average negative_sample_loss at step 141200: 0.074238\n",
      "2023-12-19 10:24:02,199 INFO     Training average loss at step 141200: 0.079395\n",
      "2023-12-19 10:25:36,457 INFO     Training average positive_sample_loss at step 141300: 0.085162\n",
      "2023-12-19 10:25:36,457 INFO     Training average negative_sample_loss at step 141300: 0.074192\n",
      "2023-12-19 10:25:36,457 INFO     Training average loss at step 141300: 0.079677\n",
      "2023-12-19 10:27:22,355 INFO     Training average positive_sample_loss at step 141400: 0.085200\n",
      "2023-12-19 10:27:22,356 INFO     Training average negative_sample_loss at step 141400: 0.074262\n",
      "2023-12-19 10:27:22,356 INFO     Training average loss at step 141400: 0.079731\n",
      "2023-12-19 10:29:01,624 INFO     Training average positive_sample_loss at step 141500: 0.085518\n",
      "2023-12-19 10:29:01,624 INFO     Training average negative_sample_loss at step 141500: 0.074118\n",
      "2023-12-19 10:29:01,624 INFO     Training average loss at step 141500: 0.079818\n",
      "2023-12-19 10:30:34,742 INFO     Training average positive_sample_loss at step 141600: 0.085608\n",
      "2023-12-19 10:30:34,742 INFO     Training average negative_sample_loss at step 141600: 0.074413\n",
      "2023-12-19 10:30:34,743 INFO     Training average loss at step 141600: 0.080011\n",
      "2023-12-19 10:32:09,425 INFO     Training average positive_sample_loss at step 141700: 0.085504\n",
      "2023-12-19 10:32:09,426 INFO     Training average negative_sample_loss at step 141700: 0.074497\n",
      "2023-12-19 10:32:09,426 INFO     Training average loss at step 141700: 0.080000\n",
      "2023-12-19 10:33:43,393 INFO     Training average positive_sample_loss at step 141800: 0.086566\n",
      "2023-12-19 10:33:43,394 INFO     Training average negative_sample_loss at step 141800: 0.075103\n",
      "2023-12-19 10:33:43,394 INFO     Training average loss at step 141800: 0.080834\n",
      "2023-12-19 10:35:21,857 INFO     Training average positive_sample_loss at step 141900: 0.086023\n",
      "2023-12-19 10:35:21,857 INFO     Training average negative_sample_loss at step 141900: 0.075196\n",
      "2023-12-19 10:35:21,857 INFO     Training average loss at step 141900: 0.080610\n",
      "2023-12-19 10:37:32,463 INFO     Training average positive_sample_loss at step 142000: 0.083866\n",
      "2023-12-19 10:37:32,463 INFO     Training average negative_sample_loss at step 142000: 0.074670\n",
      "2023-12-19 10:37:32,463 INFO     Training average loss at step 142000: 0.079268\n",
      "2023-12-19 10:39:24,213 INFO     Training average positive_sample_loss at step 142100: 0.084248\n",
      "2023-12-19 10:39:24,213 INFO     Training average negative_sample_loss at step 142100: 0.074159\n",
      "2023-12-19 10:39:24,213 INFO     Training average loss at step 142100: 0.079204\n",
      "2023-12-19 10:41:00,224 INFO     Training average positive_sample_loss at step 142200: 0.084758\n",
      "2023-12-19 10:41:00,225 INFO     Training average negative_sample_loss at step 142200: 0.074110\n",
      "2023-12-19 10:41:00,225 INFO     Training average loss at step 142200: 0.079434\n",
      "2023-12-19 10:42:36,663 INFO     Training average positive_sample_loss at step 142300: 0.085185\n",
      "2023-12-19 10:42:36,663 INFO     Training average negative_sample_loss at step 142300: 0.074263\n",
      "2023-12-19 10:42:36,663 INFO     Training average loss at step 142300: 0.079724\n",
      "2023-12-19 10:44:32,014 INFO     Training average positive_sample_loss at step 142400: 0.085355\n",
      "2023-12-19 10:44:32,015 INFO     Training average negative_sample_loss at step 142400: 0.073950\n",
      "2023-12-19 10:44:32,015 INFO     Training average loss at step 142400: 0.079653\n",
      "2023-12-19 10:46:04,441 INFO     Training average positive_sample_loss at step 142500: 0.085588\n",
      "2023-12-19 10:46:04,441 INFO     Training average negative_sample_loss at step 142500: 0.074705\n",
      "2023-12-19 10:46:04,442 INFO     Training average loss at step 142500: 0.080147\n",
      "2023-12-19 10:47:36,881 INFO     Training average positive_sample_loss at step 142600: 0.086054\n",
      "2023-12-19 10:47:36,881 INFO     Training average negative_sample_loss at step 142600: 0.074680\n",
      "2023-12-19 10:47:36,881 INFO     Training average loss at step 142600: 0.080367\n",
      "2023-12-19 10:49:08,719 INFO     Training average positive_sample_loss at step 142700: 0.085911\n",
      "2023-12-19 10:49:08,719 INFO     Training average negative_sample_loss at step 142700: 0.074824\n",
      "2023-12-19 10:49:08,719 INFO     Training average loss at step 142700: 0.080367\n",
      "2023-12-19 10:50:41,088 INFO     Training average positive_sample_loss at step 142800: 0.085876\n",
      "2023-12-19 10:50:41,088 INFO     Training average negative_sample_loss at step 142800: 0.074493\n",
      "2023-12-19 10:50:41,088 INFO     Training average loss at step 142800: 0.080184\n",
      "2023-12-19 10:52:28,217 INFO     Training average positive_sample_loss at step 142900: 0.085244\n",
      "2023-12-19 10:52:28,218 INFO     Training average negative_sample_loss at step 142900: 0.075265\n",
      "2023-12-19 10:52:28,218 INFO     Training average loss at step 142900: 0.080254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 10:54:04,767 INFO     Training average positive_sample_loss at step 143000: 0.084112\n",
      "2023-12-19 10:54:04,768 INFO     Training average negative_sample_loss at step 143000: 0.074357\n",
      "2023-12-19 10:54:04,768 INFO     Training average loss at step 143000: 0.079234\n",
      "2023-12-19 10:55:39,100 INFO     Training average positive_sample_loss at step 143100: 0.084600\n",
      "2023-12-19 10:55:39,100 INFO     Training average negative_sample_loss at step 143100: 0.074101\n",
      "2023-12-19 10:55:39,100 INFO     Training average loss at step 143100: 0.079351\n",
      "2023-12-19 10:57:12,355 INFO     Training average positive_sample_loss at step 143200: 0.085077\n",
      "2023-12-19 10:57:12,355 INFO     Training average negative_sample_loss at step 143200: 0.074279\n",
      "2023-12-19 10:57:12,355 INFO     Training average loss at step 143200: 0.079678\n",
      "2023-12-19 10:58:48,290 INFO     Training average positive_sample_loss at step 143300: 0.085063\n",
      "2023-12-19 10:58:48,290 INFO     Training average negative_sample_loss at step 143300: 0.074250\n",
      "2023-12-19 10:58:48,290 INFO     Training average loss at step 143300: 0.079657\n",
      "2023-12-19 11:00:23,065 INFO     Training average positive_sample_loss at step 143400: 0.085140\n",
      "2023-12-19 11:00:23,065 INFO     Training average negative_sample_loss at step 143400: 0.073844\n",
      "2023-12-19 11:00:23,065 INFO     Training average loss at step 143400: 0.079492\n",
      "2023-12-19 11:02:00,786 INFO     Training average positive_sample_loss at step 143500: 0.086169\n",
      "2023-12-19 11:02:00,786 INFO     Training average negative_sample_loss at step 143500: 0.075120\n",
      "2023-12-19 11:02:00,786 INFO     Training average loss at step 143500: 0.080644\n",
      "2023-12-19 11:03:55,621 INFO     Training average positive_sample_loss at step 143600: 0.085820\n",
      "2023-12-19 11:03:55,622 INFO     Training average negative_sample_loss at step 143600: 0.074796\n",
      "2023-12-19 11:03:55,622 INFO     Training average loss at step 143600: 0.080308\n",
      "2023-12-19 11:05:31,285 INFO     Training average positive_sample_loss at step 143700: 0.085906\n",
      "2023-12-19 11:05:31,286 INFO     Training average negative_sample_loss at step 143700: 0.074750\n",
      "2023-12-19 11:05:31,286 INFO     Training average loss at step 143700: 0.080328\n",
      "2023-12-19 11:07:24,967 INFO     Training average positive_sample_loss at step 143800: 0.086075\n",
      "2023-12-19 11:07:24,967 INFO     Training average negative_sample_loss at step 143800: 0.074878\n",
      "2023-12-19 11:07:24,967 INFO     Training average loss at step 143800: 0.080476\n",
      "2023-12-19 11:09:12,639 INFO     Training average positive_sample_loss at step 143900: 0.083554\n",
      "2023-12-19 11:09:12,640 INFO     Training average negative_sample_loss at step 143900: 0.074310\n",
      "2023-12-19 11:09:12,640 INFO     Training average loss at step 143900: 0.078932\n",
      "2023-12-19 11:11:11,772 INFO     Training average positive_sample_loss at step 144000: 0.084290\n",
      "2023-12-19 11:11:11,773 INFO     Training average negative_sample_loss at step 144000: 0.074372\n",
      "2023-12-19 11:11:11,773 INFO     Training average loss at step 144000: 0.079331\n",
      "2023-12-19 11:12:58,249 INFO     Training average positive_sample_loss at step 144100: 0.085093\n",
      "2023-12-19 11:12:58,249 INFO     Training average negative_sample_loss at step 144100: 0.073996\n",
      "2023-12-19 11:12:58,250 INFO     Training average loss at step 144100: 0.079544\n",
      "2023-12-19 11:14:35,555 INFO     Training average positive_sample_loss at step 144200: 0.085332\n",
      "2023-12-19 11:14:35,556 INFO     Training average negative_sample_loss at step 144200: 0.074542\n",
      "2023-12-19 11:14:35,556 INFO     Training average loss at step 144200: 0.079937\n",
      "2023-12-19 11:16:03,824 INFO     Training average positive_sample_loss at step 144300: 0.085761\n",
      "2023-12-19 11:16:03,825 INFO     Training average negative_sample_loss at step 144300: 0.074491\n",
      "2023-12-19 11:16:03,825 INFO     Training average loss at step 144300: 0.080126\n",
      "2023-12-19 11:17:35,805 INFO     Training average positive_sample_loss at step 144400: 0.085503\n",
      "2023-12-19 11:17:35,806 INFO     Training average negative_sample_loss at step 144400: 0.074520\n",
      "2023-12-19 11:17:35,806 INFO     Training average loss at step 144400: 0.080011\n",
      "2023-12-19 11:19:09,619 INFO     Training average positive_sample_loss at step 144500: 0.085735\n",
      "2023-12-19 11:19:09,620 INFO     Training average negative_sample_loss at step 144500: 0.074508\n",
      "2023-12-19 11:19:09,620 INFO     Training average loss at step 144500: 0.080121\n",
      "2023-12-19 11:20:43,899 INFO     Training average positive_sample_loss at step 144600: 0.085872\n",
      "2023-12-19 11:20:43,899 INFO     Training average negative_sample_loss at step 144600: 0.074698\n",
      "2023-12-19 11:20:43,900 INFO     Training average loss at step 144600: 0.080285\n",
      "2023-12-19 11:22:12,241 INFO     Training average positive_sample_loss at step 144700: 0.085851\n",
      "2023-12-19 11:22:12,241 INFO     Training average negative_sample_loss at step 144700: 0.074684\n",
      "2023-12-19 11:22:12,241 INFO     Training average loss at step 144700: 0.080268\n",
      "2023-12-19 11:23:53,386 INFO     Training average positive_sample_loss at step 144800: 0.084821\n",
      "2023-12-19 11:23:53,387 INFO     Training average negative_sample_loss at step 144800: 0.074974\n",
      "2023-12-19 11:23:53,387 INFO     Training average loss at step 144800: 0.079898\n",
      "2023-12-19 11:25:37,723 INFO     Training average positive_sample_loss at step 144900: 0.083885\n",
      "2023-12-19 11:25:37,724 INFO     Training average negative_sample_loss at step 144900: 0.074111\n",
      "2023-12-19 11:25:37,724 INFO     Training average loss at step 144900: 0.078998\n",
      "2023-12-19 11:27:54,285 INFO     Training average positive_sample_loss at step 145000: 0.084694\n",
      "2023-12-19 11:27:54,285 INFO     Training average negative_sample_loss at step 145000: 0.073927\n",
      "2023-12-19 11:27:54,286 INFO     Training average loss at step 145000: 0.079311\n",
      "2023-12-19 11:29:59,261 INFO     Training average positive_sample_loss at step 145100: 0.085401\n",
      "2023-12-19 11:29:59,262 INFO     Training average negative_sample_loss at step 145100: 0.074551\n",
      "2023-12-19 11:29:59,262 INFO     Training average loss at step 145100: 0.079976\n",
      "2023-12-19 11:31:39,789 INFO     Training average positive_sample_loss at step 145200: 0.084740\n",
      "2023-12-19 11:31:39,790 INFO     Training average negative_sample_loss at step 145200: 0.073907\n",
      "2023-12-19 11:31:39,790 INFO     Training average loss at step 145200: 0.079323\n",
      "2023-12-19 11:33:12,525 INFO     Training average positive_sample_loss at step 145300: 0.086026\n",
      "2023-12-19 11:33:12,525 INFO     Training average negative_sample_loss at step 145300: 0.074912\n",
      "2023-12-19 11:33:12,525 INFO     Training average loss at step 145300: 0.080469\n",
      "2023-12-19 11:34:50,299 INFO     Training average positive_sample_loss at step 145400: 0.085510\n",
      "2023-12-19 11:34:50,300 INFO     Training average negative_sample_loss at step 145400: 0.074250\n",
      "2023-12-19 11:34:50,300 INFO     Training average loss at step 145400: 0.079880\n",
      "2023-12-19 11:36:38,365 INFO     Training average positive_sample_loss at step 145500: 0.086201\n",
      "2023-12-19 11:36:38,366 INFO     Training average negative_sample_loss at step 145500: 0.074800\n",
      "2023-12-19 11:36:38,366 INFO     Training average loss at step 145500: 0.080501\n",
      "2023-12-19 11:38:11,474 INFO     Training average positive_sample_loss at step 145600: 0.085808\n",
      "2023-12-19 11:38:11,474 INFO     Training average negative_sample_loss at step 145600: 0.074877\n",
      "2023-12-19 11:38:11,474 INFO     Training average loss at step 145600: 0.080342\n",
      "2023-12-19 11:40:15,078 INFO     Training average positive_sample_loss at step 145700: 0.085634\n",
      "2023-12-19 11:40:15,078 INFO     Training average negative_sample_loss at step 145700: 0.074908\n",
      "2023-12-19 11:40:15,078 INFO     Training average loss at step 145700: 0.080271\n",
      "2023-12-19 11:42:10,374 INFO     Training average positive_sample_loss at step 145800: 0.083673\n",
      "2023-12-19 11:42:10,375 INFO     Training average negative_sample_loss at step 145800: 0.074285\n",
      "2023-12-19 11:42:10,375 INFO     Training average loss at step 145800: 0.078979\n",
      "2023-12-19 11:43:47,293 INFO     Training average positive_sample_loss at step 145900: 0.084971\n",
      "2023-12-19 11:43:47,293 INFO     Training average negative_sample_loss at step 145900: 0.074409\n",
      "2023-12-19 11:43:47,293 INFO     Training average loss at step 145900: 0.079690\n",
      "2023-12-19 11:45:17,524 INFO     Training average positive_sample_loss at step 146000: 0.084903\n",
      "2023-12-19 11:45:17,525 INFO     Training average negative_sample_loss at step 146000: 0.073935\n",
      "2023-12-19 11:45:17,525 INFO     Training average loss at step 146000: 0.079419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 11:46:44,456 INFO     Training average positive_sample_loss at step 146100: 0.085055\n",
      "2023-12-19 11:46:44,457 INFO     Training average negative_sample_loss at step 146100: 0.073795\n",
      "2023-12-19 11:46:44,457 INFO     Training average loss at step 146100: 0.079425\n",
      "2023-12-19 11:48:40,242 INFO     Training average positive_sample_loss at step 146200: 0.085093\n",
      "2023-12-19 11:48:40,242 INFO     Training average negative_sample_loss at step 146200: 0.074128\n",
      "2023-12-19 11:48:40,242 INFO     Training average loss at step 146200: 0.079611\n",
      "2023-12-19 11:50:35,478 INFO     Training average positive_sample_loss at step 146300: 0.085747\n",
      "2023-12-19 11:50:35,478 INFO     Training average negative_sample_loss at step 146300: 0.074342\n",
      "2023-12-19 11:50:35,478 INFO     Training average loss at step 146300: 0.080044\n",
      "2023-12-19 11:52:17,449 INFO     Training average positive_sample_loss at step 146400: 0.085631\n",
      "2023-12-19 11:52:17,450 INFO     Training average negative_sample_loss at step 146400: 0.074492\n",
      "2023-12-19 11:52:17,450 INFO     Training average loss at step 146400: 0.080062\n",
      "2023-12-19 11:54:00,355 INFO     Training average positive_sample_loss at step 146500: 0.086112\n",
      "2023-12-19 11:54:00,355 INFO     Training average negative_sample_loss at step 146500: 0.075108\n",
      "2023-12-19 11:54:00,355 INFO     Training average loss at step 146500: 0.080610\n",
      "2023-12-19 11:55:44,061 INFO     Training average positive_sample_loss at step 146600: 0.085633\n",
      "2023-12-19 11:55:44,061 INFO     Training average negative_sample_loss at step 146600: 0.074792\n",
      "2023-12-19 11:55:44,061 INFO     Training average loss at step 146600: 0.080213\n",
      "2023-12-19 11:57:38,273 INFO     Training average positive_sample_loss at step 146700: 0.084431\n",
      "2023-12-19 11:57:38,274 INFO     Training average negative_sample_loss at step 146700: 0.074637\n",
      "2023-12-19 11:57:38,274 INFO     Training average loss at step 146700: 0.079534\n",
      "2023-12-19 11:59:14,944 INFO     Training average positive_sample_loss at step 146800: 0.084389\n",
      "2023-12-19 11:59:14,944 INFO     Training average negative_sample_loss at step 146800: 0.074535\n",
      "2023-12-19 11:59:14,944 INFO     Training average loss at step 146800: 0.079462\n",
      "2023-12-19 12:00:59,132 INFO     Training average positive_sample_loss at step 146900: 0.084419\n",
      "2023-12-19 12:00:59,132 INFO     Training average negative_sample_loss at step 146900: 0.074063\n",
      "2023-12-19 12:00:59,132 INFO     Training average loss at step 146900: 0.079241\n",
      "2023-12-19 12:02:36,845 INFO     Training average positive_sample_loss at step 147000: 0.085166\n",
      "2023-12-19 12:02:36,846 INFO     Training average negative_sample_loss at step 147000: 0.074311\n",
      "2023-12-19 12:02:36,846 INFO     Training average loss at step 147000: 0.079739\n",
      "2023-12-19 12:04:17,486 INFO     Training average positive_sample_loss at step 147100: 0.085292\n",
      "2023-12-19 12:04:17,486 INFO     Training average negative_sample_loss at step 147100: 0.073946\n",
      "2023-12-19 12:04:17,486 INFO     Training average loss at step 147100: 0.079619\n",
      "2023-12-19 12:06:09,990 INFO     Training average positive_sample_loss at step 147200: 0.085851\n",
      "2023-12-19 12:06:09,990 INFO     Training average negative_sample_loss at step 147200: 0.074286\n",
      "2023-12-19 12:06:09,990 INFO     Training average loss at step 147200: 0.080068\n",
      "2023-12-19 12:07:46,150 INFO     Training average positive_sample_loss at step 147300: 0.085676\n",
      "2023-12-19 12:07:46,151 INFO     Training average negative_sample_loss at step 147300: 0.074632\n",
      "2023-12-19 12:07:46,151 INFO     Training average loss at step 147300: 0.080154\n",
      "2023-12-19 12:09:26,466 INFO     Training average positive_sample_loss at step 147400: 0.085791\n",
      "2023-12-19 12:09:26,467 INFO     Training average negative_sample_loss at step 147400: 0.074691\n",
      "2023-12-19 12:09:26,467 INFO     Training average loss at step 147400: 0.080241\n",
      "2023-12-19 12:10:56,176 INFO     Training average positive_sample_loss at step 147500: 0.085794\n",
      "2023-12-19 12:10:56,177 INFO     Training average negative_sample_loss at step 147500: 0.074670\n",
      "2023-12-19 12:10:56,177 INFO     Training average loss at step 147500: 0.080232\n",
      "2023-12-19 12:12:43,220 INFO     Training average positive_sample_loss at step 147600: 0.085396\n",
      "2023-12-19 12:12:43,221 INFO     Training average negative_sample_loss at step 147600: 0.074688\n",
      "2023-12-19 12:12:43,221 INFO     Training average loss at step 147600: 0.080042\n",
      "2023-12-19 12:14:31,565 INFO     Training average positive_sample_loss at step 147700: 0.083563\n",
      "2023-12-19 12:14:31,566 INFO     Training average negative_sample_loss at step 147700: 0.074251\n",
      "2023-12-19 12:14:31,566 INFO     Training average loss at step 147700: 0.078907\n",
      "2023-12-19 12:16:22,397 INFO     Training average positive_sample_loss at step 147800: 0.084269\n",
      "2023-12-19 12:16:22,397 INFO     Training average negative_sample_loss at step 147800: 0.074273\n",
      "2023-12-19 12:16:22,397 INFO     Training average loss at step 147800: 0.079271\n",
      "2023-12-19 12:17:50,653 INFO     Training average positive_sample_loss at step 147900: 0.085412\n",
      "2023-12-19 12:17:50,653 INFO     Training average negative_sample_loss at step 147900: 0.074282\n",
      "2023-12-19 12:17:50,653 INFO     Training average loss at step 147900: 0.079847\n",
      "2023-12-19 12:19:20,772 INFO     Training average positive_sample_loss at step 148000: 0.085464\n",
      "2023-12-19 12:19:20,772 INFO     Training average negative_sample_loss at step 148000: 0.074248\n",
      "2023-12-19 12:19:20,772 INFO     Training average loss at step 148000: 0.079856\n",
      "2023-12-19 12:21:12,725 INFO     Training average positive_sample_loss at step 148100: 0.085164\n",
      "2023-12-19 12:21:12,725 INFO     Training average negative_sample_loss at step 148100: 0.074170\n",
      "2023-12-19 12:21:12,726 INFO     Training average loss at step 148100: 0.079667\n",
      "2023-12-19 12:22:48,167 INFO     Training average positive_sample_loss at step 148200: 0.085850\n",
      "2023-12-19 12:22:48,168 INFO     Training average negative_sample_loss at step 148200: 0.074591\n",
      "2023-12-19 12:22:48,168 INFO     Training average loss at step 148200: 0.080220\n",
      "2023-12-19 12:24:47,428 INFO     Training average positive_sample_loss at step 148300: 0.085800\n",
      "2023-12-19 12:24:47,429 INFO     Training average negative_sample_loss at step 148300: 0.074542\n",
      "2023-12-19 12:24:47,429 INFO     Training average loss at step 148300: 0.080171\n",
      "2023-12-19 12:26:46,119 INFO     Training average positive_sample_loss at step 148400: 0.085849\n",
      "2023-12-19 12:26:46,120 INFO     Training average negative_sample_loss at step 148400: 0.074824\n",
      "2023-12-19 12:26:46,120 INFO     Training average loss at step 148400: 0.080336\n",
      "2023-12-19 12:28:56,272 INFO     Training average positive_sample_loss at step 148500: 0.085843\n",
      "2023-12-19 12:28:56,272 INFO     Training average negative_sample_loss at step 148500: 0.074883\n",
      "2023-12-19 12:28:56,272 INFO     Training average loss at step 148500: 0.080363\n",
      "2023-12-19 12:30:52,910 INFO     Training average positive_sample_loss at step 148600: 0.083949\n",
      "2023-12-19 12:30:52,910 INFO     Training average negative_sample_loss at step 148600: 0.074611\n",
      "2023-12-19 12:30:52,910 INFO     Training average loss at step 148600: 0.079280\n",
      "2023-12-19 12:32:36,899 INFO     Training average positive_sample_loss at step 148700: 0.084322\n",
      "2023-12-19 12:32:36,899 INFO     Training average negative_sample_loss at step 148700: 0.074100\n",
      "2023-12-19 12:32:36,900 INFO     Training average loss at step 148700: 0.079211\n",
      "2023-12-19 12:34:23,537 INFO     Training average positive_sample_loss at step 148800: 0.084558\n",
      "2023-12-19 12:34:23,538 INFO     Training average negative_sample_loss at step 148800: 0.074053\n",
      "2023-12-19 12:34:23,538 INFO     Training average loss at step 148800: 0.079306\n",
      "2023-12-19 12:36:28,112 INFO     Training average positive_sample_loss at step 148900: 0.085632\n",
      "2023-12-19 12:36:28,112 INFO     Training average negative_sample_loss at step 148900: 0.074430\n",
      "2023-12-19 12:36:28,112 INFO     Training average loss at step 148900: 0.080031\n",
      "2023-12-19 12:38:35,853 INFO     Training average positive_sample_loss at step 149000: 0.085312\n",
      "2023-12-19 12:38:35,854 INFO     Training average negative_sample_loss at step 149000: 0.074264\n",
      "2023-12-19 12:38:35,854 INFO     Training average loss at step 149000: 0.079788\n",
      "2023-12-19 12:40:45,431 INFO     Training average positive_sample_loss at step 149100: 0.085284\n",
      "2023-12-19 12:40:45,432 INFO     Training average negative_sample_loss at step 149100: 0.074302\n",
      "2023-12-19 12:40:45,432 INFO     Training average loss at step 149100: 0.079793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-19 12:42:41,773 INFO     Training average positive_sample_loss at step 149200: 0.085717\n",
      "2023-12-19 12:42:41,773 INFO     Training average negative_sample_loss at step 149200: 0.074394\n",
      "2023-12-19 12:42:41,774 INFO     Training average loss at step 149200: 0.080055\n",
      "2023-12-19 12:45:07,150 INFO     Training average positive_sample_loss at step 149300: 0.085889\n",
      "2023-12-19 12:45:07,150 INFO     Training average negative_sample_loss at step 149300: 0.074931\n",
      "2023-12-19 12:45:07,150 INFO     Training average loss at step 149300: 0.080410\n",
      "2023-12-19 12:47:09,458 INFO     Training average positive_sample_loss at step 149400: 0.085798\n",
      "2023-12-19 12:47:09,459 INFO     Training average negative_sample_loss at step 149400: 0.074714\n",
      "2023-12-19 12:47:09,459 INFO     Training average loss at step 149400: 0.080256\n",
      "2023-12-19 12:49:02,598 INFO     Training average positive_sample_loss at step 149500: 0.085380\n",
      "2023-12-19 12:49:02,598 INFO     Training average negative_sample_loss at step 149500: 0.074774\n",
      "2023-12-19 12:49:02,598 INFO     Training average loss at step 149500: 0.080077\n",
      "2023-12-19 12:50:51,167 INFO     Training average positive_sample_loss at step 149600: 0.083869\n",
      "2023-12-19 12:50:51,167 INFO     Training average negative_sample_loss at step 149600: 0.074636\n",
      "2023-12-19 12:50:51,167 INFO     Training average loss at step 149600: 0.079252\n",
      "2023-12-19 12:52:34,622 INFO     Training average positive_sample_loss at step 149700: 0.085018\n",
      "2023-12-19 12:52:34,622 INFO     Training average negative_sample_loss at step 149700: 0.074549\n",
      "2023-12-19 12:52:34,622 INFO     Training average loss at step 149700: 0.079783\n",
      "2023-12-19 12:54:25,723 INFO     Training average positive_sample_loss at step 149800: 0.084897\n",
      "2023-12-19 12:54:25,724 INFO     Training average negative_sample_loss at step 149800: 0.074019\n",
      "2023-12-19 12:54:25,724 INFO     Training average loss at step 149800: 0.079458\n",
      "2023-12-19 12:56:14,866 INFO     Training average positive_sample_loss at step 149900: 0.085468\n",
      "2023-12-19 12:56:14,867 INFO     Training average negative_sample_loss at step 149900: 0.074362\n",
      "2023-12-19 12:56:14,867 INFO     Training average loss at step 149900: 0.079915\n",
      "2023-12-19 12:58:04,795 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-19 12:58:05,679 INFO     Evaluating the model... (0/6250)\n",
      "2023-12-19 12:58:30,870 INFO     Evaluating the model... (1000/6250)\n",
      "2023-12-19 12:58:55,654 INFO     Evaluating the model... (2000/6250)\n",
      "2023-12-19 12:59:20,245 INFO     Evaluating the model... (3000/6250)\n",
      "2023-12-19 12:59:43,706 INFO     Evaluating the model... (4000/6250)\n",
      "2023-12-19 13:00:06,809 INFO     Evaluating the model... (5000/6250)\n",
      "2023-12-19 13:00:31,081 INFO     Evaluating the model... (6000/6250)\n",
      "2023-12-19 13:00:37,561 INFO     Valid MRR at step 149999: 0.453037\n",
      "2023-12-19 13:00:37,561 INFO     Valid MR at step 149999: 214.351040\n",
      "2023-12-19 13:00:37,561 INFO     Valid HITS@1 at step 149999: 0.355890\n",
      "2023-12-19 13:00:37,561 INFO     Valid HITS@3 at step 149999: 0.488410\n",
      "2023-12-19 13:00:37,561 INFO     Valid HITS@10 at step 149999: 0.661950\n",
      "2023-12-19 13:00:37,561 INFO     Evaluating on Test Dataset...\n",
      "2023-12-19 13:00:38,273 INFO     Evaluating the model... (0/7384)\n",
      "2023-12-19 13:01:03,255 INFO     Evaluating the model... (1000/7384)\n",
      "2023-12-19 13:01:27,873 INFO     Evaluating the model... (2000/7384)\n",
      "2023-12-19 13:01:53,068 INFO     Evaluating the model... (3000/7384)\n",
      "2023-12-19 13:02:18,619 INFO     Evaluating the model... (4000/7384)\n",
      "2023-12-19 13:02:42,150 INFO     Evaluating the model... (5000/7384)\n",
      "2023-12-19 13:03:05,012 INFO     Evaluating the model... (6000/7384)\n",
      "2023-12-19 13:03:29,504 INFO     Evaluating the model... (7000/7384)\n",
      "2023-12-19 13:03:38,958 INFO     Test MRR at step 149999: 0.456159\n",
      "2023-12-19 13:03:38,959 INFO     Test MR at step 149999: 206.151123\n",
      "2023-12-19 13:03:38,959 INFO     Test HITS@1 at step 149999: 0.359068\n",
      "2023-12-19 13:03:38,959 INFO     Test HITS@3 at step 149999: 0.492247\n",
      "2023-12-19 13:03:38,959 INFO     Test HITS@10 at step 149999: 0.663109\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE FB15k 0 0 1024 256 1000 24.0 1.0 0.0001 150000 16 -de --init_checkpoint ../KnowledgeGraphEmbedding_patt/models/RotatE_FB15k_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-28 17:36:32 INFO     Model: RotatE\n",
      "2024-02-28 17:36:32 INFO     Data Path: data/FB15k\n",
      "2024-02-28 17:36:32 INFO     #entity: 14951\n",
      "2024-02-28 17:36:32 INFO     #relation: 1345\n",
      "2024-02-28 17:36:34 INFO     #train: 483142\n",
      "2024-02-28 17:36:34 INFO     #valid: 50000\n",
      "2024-02-28 17:36:34 INFO     #test: 59071\n",
      "2024-02-28 17:36:34 INFO     Model Parameter Configuration:\n",
      "2024-02-28 17:36:34 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2024-02-28 17:36:34 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2024-02-28 17:36:34 INFO     Parameter entity_embedding: torch.Size([14951, 2000]), require_grad = True\n",
      "2024-02-28 17:36:34 INFO     Parameter relation_embedding: torch.Size([1345, 1000]), require_grad = True\n",
      "2024-02-28 17:36:42 INFO     Ramdomly Initializing RotatE Model...\n",
      "2024-02-28 17:36:42 INFO     Start Training...\n",
      "2024-02-28 17:36:42 INFO     init_step = 0\n",
      "2024-02-28 17:36:42 INFO     batch_size = 1024\n",
      "2024-02-28 17:36:42 INFO     negative_adversarial_sampling = 1\n",
      "2024-02-28 17:36:42 INFO     hidden_dim = 1000\n",
      "2024-02-28 17:36:42 INFO     gamma = 24.000000\n",
      "2024-02-28 17:36:42 INFO     negative_adversarial_sampling = True\n",
      "2024-02-28 17:36:42 INFO     adversarial_temperature = 1.000000\n",
      "2024-02-28 17:36:42 INFO     learning_rate = 0\n",
      "2024-02-28 17:37:00 INFO     Training average positive_sample_loss at step 0: 3.175382\n",
      "2024-02-28 17:37:00 INFO     Training average negative_sample_loss at step 0: 0.054206\n",
      "2024-02-28 17:37:00 INFO     Training average loss at step 0: 1.614794\n",
      "2024-02-28 17:37:00 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-28 17:37:01 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-28 17:37:31 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-28 17:38:00 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-28 17:38:34 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-28 17:39:03 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-28 17:39:32 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-28 17:40:06 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-28 17:40:13 INFO     Valid MRR at step 0: 0.004435\n",
      "2024-02-28 17:40:13 INFO     Valid MR at step 0: 7107.801780\n",
      "2024-02-28 17:40:13 INFO     Valid HITS@1 at step 0: 0.003400\n",
      "2024-02-28 17:40:13 INFO     Valid HITS@3 at step 0: 0.004160\n",
      "2024-02-28 17:40:13 INFO     Valid HITS@10 at step 0: 0.005010\n",
      "2024-02-28 17:41:59 INFO     Training average positive_sample_loss at step 100: 2.259410\n",
      "2024-02-28 17:41:59 INFO     Training average negative_sample_loss at step 100: 0.260706\n",
      "2024-02-28 17:41:59 INFO     Training average loss at step 100: 1.260058\n",
      "2024-02-28 17:44:02 INFO     Training average positive_sample_loss at step 200: 1.048741\n",
      "2024-02-28 17:44:02 INFO     Training average negative_sample_loss at step 200: 0.592445\n",
      "2024-02-28 17:44:02 INFO     Training average loss at step 200: 0.820593\n",
      "2024-02-28 17:45:56 INFO     Training average positive_sample_loss at step 300: 0.803112\n",
      "2024-02-28 17:45:56 INFO     Training average negative_sample_loss at step 300: 0.651209\n",
      "2024-02-28 17:45:56 INFO     Training average loss at step 300: 0.727160\n",
      "2024-02-28 17:48:05 INFO     Training average positive_sample_loss at step 400: 0.724167\n",
      "2024-02-28 17:48:05 INFO     Training average negative_sample_loss at step 400: 0.656436\n",
      "2024-02-28 17:48:05 INFO     Training average loss at step 400: 0.690301\n",
      "2024-02-28 17:50:23 INFO     Training average positive_sample_loss at step 500: 0.682015\n",
      "2024-02-28 17:50:23 INFO     Training average negative_sample_loss at step 500: 0.645382\n",
      "2024-02-28 17:50:23 INFO     Training average loss at step 500: 0.663698\n",
      "2024-02-28 17:52:15 INFO     Training average positive_sample_loss at step 600: 0.652572\n",
      "2024-02-28 17:52:15 INFO     Training average negative_sample_loss at step 600: 0.627047\n",
      "2024-02-28 17:52:15 INFO     Training average loss at step 600: 0.639809\n",
      "2024-02-28 17:54:06 INFO     Training average positive_sample_loss at step 700: 0.623236\n",
      "2024-02-28 17:54:06 INFO     Training average negative_sample_loss at step 700: 0.606214\n",
      "2024-02-28 17:54:06 INFO     Training average loss at step 700: 0.614725\n",
      "2024-02-28 17:56:04 INFO     Training average positive_sample_loss at step 800: 0.597520\n",
      "2024-02-28 17:56:04 INFO     Training average negative_sample_loss at step 800: 0.583096\n",
      "2024-02-28 17:56:04 INFO     Training average loss at step 800: 0.590308\n",
      "2024-02-28 17:57:52 INFO     Training average positive_sample_loss at step 900: 0.570370\n",
      "2024-02-28 17:57:52 INFO     Training average negative_sample_loss at step 900: 0.559378\n",
      "2024-02-28 17:57:52 INFO     Training average loss at step 900: 0.564874\n",
      "2024-02-28 17:59:57 INFO     Training average positive_sample_loss at step 1000: 0.494494\n",
      "2024-02-28 17:59:57 INFO     Training average negative_sample_loss at step 1000: 0.513220\n",
      "2024-02-28 17:59:57 INFO     Training average loss at step 1000: 0.503857\n",
      "2024-02-28 18:01:34 INFO     Training average positive_sample_loss at step 1100: 0.468848\n",
      "2024-02-28 18:01:34 INFO     Training average negative_sample_loss at step 1100: 0.455485\n",
      "2024-02-28 18:01:34 INFO     Training average loss at step 1100: 0.462166\n",
      "2024-02-28 18:03:11 INFO     Training average positive_sample_loss at step 1200: 0.459739\n",
      "2024-02-28 18:03:11 INFO     Training average negative_sample_loss at step 1200: 0.440766\n",
      "2024-02-28 18:03:11 INFO     Training average loss at step 1200: 0.450253\n",
      "2024-02-28 18:04:40 INFO     Training average positive_sample_loss at step 1300: 0.446913\n",
      "2024-02-28 18:04:40 INFO     Training average negative_sample_loss at step 1300: 0.427268\n",
      "2024-02-28 18:04:40 INFO     Training average loss at step 1300: 0.437091\n",
      "2024-02-28 18:06:20 INFO     Training average positive_sample_loss at step 1400: 0.436728\n",
      "2024-02-28 18:06:20 INFO     Training average negative_sample_loss at step 1400: 0.414124\n",
      "2024-02-28 18:06:20 INFO     Training average loss at step 1400: 0.425426\n",
      "2024-02-28 18:08:08 INFO     Training average positive_sample_loss at step 1500: 0.423319\n",
      "2024-02-28 18:08:08 INFO     Training average negative_sample_loss at step 1500: 0.401244\n",
      "2024-02-28 18:08:08 INFO     Training average loss at step 1500: 0.412281\n",
      "2024-02-28 18:10:24 INFO     Training average positive_sample_loss at step 1600: 0.408068\n",
      "2024-02-28 18:10:24 INFO     Training average negative_sample_loss at step 1600: 0.385834\n",
      "2024-02-28 18:10:24 INFO     Training average loss at step 1600: 0.396951\n",
      "2024-02-28 18:12:29 INFO     Training average positive_sample_loss at step 1700: 0.395472\n",
      "2024-02-28 18:12:29 INFO     Training average negative_sample_loss at step 1700: 0.372675\n",
      "2024-02-28 18:12:29 INFO     Training average loss at step 1700: 0.384073\n",
      "2024-02-28 18:14:19 INFO     Training average positive_sample_loss at step 1800: 0.382841\n",
      "2024-02-28 18:14:20 INFO     Training average negative_sample_loss at step 1800: 0.360195\n",
      "2024-02-28 18:14:20 INFO     Training average loss at step 1800: 0.371518\n",
      "2024-02-28 18:16:26 INFO     Training average positive_sample_loss at step 1900: 0.361087\n",
      "2024-02-28 18:16:26 INFO     Training average negative_sample_loss at step 1900: 0.347116\n",
      "2024-02-28 18:16:26 INFO     Training average loss at step 1900: 0.354101\n",
      "2024-02-28 18:18:04 INFO     Training average positive_sample_loss at step 2000: 0.318338\n",
      "2024-02-28 18:18:04 INFO     Training average negative_sample_loss at step 2000: 0.305913\n",
      "2024-02-28 18:18:04 INFO     Training average loss at step 2000: 0.312126\n",
      "2024-02-28 18:19:53 INFO     Training average positive_sample_loss at step 2100: 0.318338\n",
      "2024-02-28 18:19:53 INFO     Training average negative_sample_loss at step 2100: 0.295939\n",
      "2024-02-28 18:19:53 INFO     Training average loss at step 2100: 0.307138\n",
      "2024-02-28 18:22:02 INFO     Training average positive_sample_loss at step 2200: 0.314453\n",
      "2024-02-28 18:22:02 INFO     Training average negative_sample_loss at step 2200: 0.290702\n",
      "2024-02-28 18:22:02 INFO     Training average loss at step 2200: 0.302578\n",
      "2024-02-28 18:23:39 INFO     Training average positive_sample_loss at step 2300: 0.308358\n",
      "2024-02-28 18:23:39 INFO     Training average negative_sample_loss at step 2300: 0.284944\n",
      "2024-02-28 18:23:39 INFO     Training average loss at step 2300: 0.296651\n",
      "2024-02-28 18:25:09 INFO     Training average positive_sample_loss at step 2400: 0.302639\n",
      "2024-02-28 18:25:09 INFO     Training average negative_sample_loss at step 2400: 0.279060\n",
      "2024-02-28 18:25:09 INFO     Training average loss at step 2400: 0.290850\n",
      "2024-02-28 18:26:53 INFO     Training average positive_sample_loss at step 2500: 0.296552\n",
      "2024-02-28 18:26:53 INFO     Training average negative_sample_loss at step 2500: 0.274275\n",
      "2024-02-28 18:26:53 INFO     Training average loss at step 2500: 0.285413\n",
      "2024-02-28 18:28:53 INFO     Training average positive_sample_loss at step 2600: 0.290217\n",
      "2024-02-28 18:28:53 INFO     Training average negative_sample_loss at step 2600: 0.267782\n",
      "2024-02-28 18:28:53 INFO     Training average loss at step 2600: 0.279000\n",
      "2024-02-28 18:30:40 INFO     Training average positive_sample_loss at step 2700: 0.283271\n",
      "2024-02-28 18:30:40 INFO     Training average negative_sample_loss at step 2700: 0.261427\n",
      "2024-02-28 18:30:40 INFO     Training average loss at step 2700: 0.272349\n",
      "2024-02-28 18:32:21 INFO     Training average positive_sample_loss at step 2800: 0.276473\n",
      "2024-02-28 18:32:21 INFO     Training average negative_sample_loss at step 2800: 0.256226\n",
      "2024-02-28 18:32:21 INFO     Training average loss at step 2800: 0.266349\n",
      "2024-02-28 18:34:22 INFO     Training average positive_sample_loss at step 2900: 0.247496\n",
      "2024-02-28 18:34:22 INFO     Training average negative_sample_loss at step 2900: 0.238596\n",
      "2024-02-28 18:34:22 INFO     Training average loss at step 2900: 0.243046\n",
      "2024-02-28 18:36:10 INFO     Training average positive_sample_loss at step 3000: 0.243265\n",
      "2024-02-28 18:36:10 INFO     Training average negative_sample_loss at step 3000: 0.224663\n",
      "2024-02-28 18:36:10 INFO     Training average loss at step 3000: 0.233964\n",
      "2024-02-28 18:38:04 INFO     Training average positive_sample_loss at step 3100: 0.241889\n",
      "2024-02-28 18:38:04 INFO     Training average negative_sample_loss at step 3100: 0.222985\n",
      "2024-02-28 18:38:04 INFO     Training average loss at step 3100: 0.232437\n",
      "2024-02-28 18:39:48 INFO     Training average positive_sample_loss at step 3200: 0.241533\n",
      "2024-02-28 18:39:48 INFO     Training average negative_sample_loss at step 3200: 0.221756\n",
      "2024-02-28 18:39:48 INFO     Training average loss at step 3200: 0.231644\n",
      "2024-02-28 18:41:37 INFO     Training average positive_sample_loss at step 3300: 0.238421\n",
      "2024-02-28 18:41:37 INFO     Training average negative_sample_loss at step 3300: 0.219647\n",
      "2024-02-28 18:41:37 INFO     Training average loss at step 3300: 0.229034\n",
      "2024-02-28 18:43:43 INFO     Training average positive_sample_loss at step 3400: 0.235941\n",
      "2024-02-28 18:43:43 INFO     Training average negative_sample_loss at step 3400: 0.217400\n",
      "2024-02-28 18:43:43 INFO     Training average loss at step 3400: 0.226670\n",
      "2024-02-28 18:45:53 INFO     Training average positive_sample_loss at step 3500: 0.234052\n",
      "2024-02-28 18:45:53 INFO     Training average negative_sample_loss at step 3500: 0.215363\n",
      "2024-02-28 18:45:53 INFO     Training average loss at step 3500: 0.224707\n",
      "2024-02-28 18:48:03 INFO     Training average positive_sample_loss at step 3600: 0.229255\n",
      "2024-02-28 18:48:03 INFO     Training average negative_sample_loss at step 3600: 0.212625\n",
      "2024-02-28 18:48:03 INFO     Training average loss at step 3600: 0.220940\n",
      "2024-02-28 18:50:03 INFO     Training average positive_sample_loss at step 3700: 0.225003\n",
      "2024-02-28 18:50:03 INFO     Training average negative_sample_loss at step 3700: 0.208617\n",
      "2024-02-28 18:50:03 INFO     Training average loss at step 3700: 0.216810\n",
      "2024-02-28 18:51:58 INFO     Training average positive_sample_loss at step 3800: 0.213532\n",
      "2024-02-28 18:51:58 INFO     Training average negative_sample_loss at step 3800: 0.203867\n",
      "2024-02-28 18:51:58 INFO     Training average loss at step 3800: 0.208700\n",
      "2024-02-28 18:53:37 INFO     Training average positive_sample_loss at step 3900: 0.200351\n",
      "2024-02-28 18:53:37 INFO     Training average negative_sample_loss at step 3900: 0.187054\n",
      "2024-02-28 18:53:37 INFO     Training average loss at step 3900: 0.193702\n",
      "2024-02-28 18:55:22 INFO     Training average positive_sample_loss at step 4000: 0.202428\n",
      "2024-02-28 18:55:22 INFO     Training average negative_sample_loss at step 4000: 0.186935\n",
      "2024-02-28 18:55:22 INFO     Training average loss at step 4000: 0.194681\n",
      "2024-02-28 18:57:03 INFO     Training average positive_sample_loss at step 4100: 0.203156\n",
      "2024-02-28 18:57:03 INFO     Training average negative_sample_loss at step 4100: 0.187650\n",
      "2024-02-28 18:57:03 INFO     Training average loss at step 4100: 0.195403\n",
      "2024-02-28 18:59:09 INFO     Training average positive_sample_loss at step 4200: 0.202055\n",
      "2024-02-28 18:59:09 INFO     Training average negative_sample_loss at step 4200: 0.186851\n",
      "2024-02-28 18:59:09 INFO     Training average loss at step 4200: 0.194453\n",
      "2024-02-28 19:01:14 INFO     Training average positive_sample_loss at step 4300: 0.200525\n",
      "2024-02-28 19:01:14 INFO     Training average negative_sample_loss at step 4300: 0.186086\n",
      "2024-02-28 19:01:14 INFO     Training average loss at step 4300: 0.193305\n",
      "2024-02-28 19:03:11 INFO     Training average positive_sample_loss at step 4400: 0.200312\n",
      "2024-02-28 19:03:11 INFO     Training average negative_sample_loss at step 4400: 0.185243\n",
      "2024-02-28 19:03:11 INFO     Training average loss at step 4400: 0.192777\n",
      "2024-02-28 19:05:04 INFO     Training average positive_sample_loss at step 4500: 0.198078\n",
      "2024-02-28 19:05:04 INFO     Training average negative_sample_loss at step 4500: 0.183699\n",
      "2024-02-28 19:05:04 INFO     Training average loss at step 4500: 0.190888\n",
      "2024-02-28 19:06:56 INFO     Training average positive_sample_loss at step 4600: 0.195788\n",
      "2024-02-28 19:06:56 INFO     Training average negative_sample_loss at step 4600: 0.182507\n",
      "2024-02-28 19:06:56 INFO     Training average loss at step 4600: 0.189147\n",
      "2024-02-28 19:08:44 INFO     Training average positive_sample_loss at step 4700: 0.194078\n",
      "2024-02-28 19:08:44 INFO     Training average negative_sample_loss at step 4700: 0.180651\n",
      "2024-02-28 19:08:44 INFO     Training average loss at step 4700: 0.187364\n",
      "2024-02-28 19:11:03 INFO     Training average positive_sample_loss at step 4800: 0.175165\n",
      "2024-02-28 19:11:03 INFO     Training average negative_sample_loss at step 4800: 0.168957\n",
      "2024-02-28 19:11:03 INFO     Training average loss at step 4800: 0.172061\n",
      "2024-02-28 19:13:04 INFO     Training average positive_sample_loss at step 4900: 0.178005\n",
      "2024-02-28 19:13:04 INFO     Training average negative_sample_loss at step 4900: 0.164538\n",
      "2024-02-28 19:13:04 INFO     Training average loss at step 4900: 0.171272\n",
      "2024-02-28 19:15:06 INFO     Training average positive_sample_loss at step 5000: 0.178044\n",
      "2024-02-28 19:15:06 INFO     Training average negative_sample_loss at step 5000: 0.165339\n",
      "2024-02-28 19:15:06 INFO     Training average loss at step 5000: 0.171692\n",
      "2024-02-28 19:16:51 INFO     Training average positive_sample_loss at step 5100: 0.179211\n",
      "2024-02-28 19:16:51 INFO     Training average negative_sample_loss at step 5100: 0.166117\n",
      "2024-02-28 19:16:51 INFO     Training average loss at step 5100: 0.172664\n",
      "2024-02-28 19:18:36 INFO     Training average positive_sample_loss at step 5200: 0.179791\n",
      "2024-02-28 19:18:36 INFO     Training average negative_sample_loss at step 5200: 0.166199\n",
      "2024-02-28 19:18:36 INFO     Training average loss at step 5200: 0.172995\n",
      "2024-02-28 19:20:34 INFO     Training average positive_sample_loss at step 5300: 0.179129\n",
      "2024-02-28 19:20:34 INFO     Training average negative_sample_loss at step 5300: 0.166493\n",
      "2024-02-28 19:20:34 INFO     Training average loss at step 5300: 0.172811\n",
      "2024-02-28 19:22:20 INFO     Training average positive_sample_loss at step 5400: 0.178900\n",
      "2024-02-28 19:22:20 INFO     Training average negative_sample_loss at step 5400: 0.166448\n",
      "2024-02-28 19:22:20 INFO     Training average loss at step 5400: 0.172674\n",
      "2024-02-28 19:24:30 INFO     Training average positive_sample_loss at step 5500: 0.177149\n",
      "2024-02-28 19:24:30 INFO     Training average negative_sample_loss at step 5500: 0.165325\n",
      "2024-02-28 19:24:30 INFO     Training average loss at step 5500: 0.171237\n",
      "2024-02-28 19:26:32 INFO     Training average positive_sample_loss at step 5600: 0.175914\n",
      "2024-02-28 19:26:32 INFO     Training average negative_sample_loss at step 5600: 0.163910\n",
      "2024-02-28 19:26:32 INFO     Training average loss at step 5600: 0.169912\n",
      "2024-02-28 19:28:35 INFO     Training average positive_sample_loss at step 5700: 0.166748\n",
      "2024-02-28 19:28:35 INFO     Training average negative_sample_loss at step 5700: 0.160053\n",
      "2024-02-28 19:28:35 INFO     Training average loss at step 5700: 0.163400\n",
      "2024-02-28 19:30:04 INFO     Training average positive_sample_loss at step 5800: 0.159866\n",
      "2024-02-28 19:30:04 INFO     Training average negative_sample_loss at step 5800: 0.149020\n",
      "2024-02-28 19:30:04 INFO     Training average loss at step 5800: 0.154443\n",
      "2024-02-28 19:31:42 INFO     Training average positive_sample_loss at step 5900: 0.162969\n",
      "2024-02-28 19:31:42 INFO     Training average negative_sample_loss at step 5900: 0.150810\n",
      "2024-02-28 19:31:42 INFO     Training average loss at step 5900: 0.156890\n",
      "2024-02-28 19:33:12 INFO     Training average positive_sample_loss at step 6000: 0.163515\n",
      "2024-02-28 19:33:12 INFO     Training average negative_sample_loss at step 6000: 0.151785\n",
      "2024-02-28 19:33:12 INFO     Training average loss at step 6000: 0.157650\n",
      "2024-02-28 19:34:42 INFO     Training average positive_sample_loss at step 6100: 0.164521\n",
      "2024-02-28 19:34:42 INFO     Training average negative_sample_loss at step 6100: 0.152450\n",
      "2024-02-28 19:34:42 INFO     Training average loss at step 6100: 0.158485\n",
      "2024-02-28 19:36:22 INFO     Training average positive_sample_loss at step 6200: 0.164813\n",
      "2024-02-28 19:36:22 INFO     Training average negative_sample_loss at step 6200: 0.152502\n",
      "2024-02-28 19:36:22 INFO     Training average loss at step 6200: 0.158657\n",
      "2024-02-28 19:38:24 INFO     Training average positive_sample_loss at step 6300: 0.164246\n",
      "2024-02-28 19:38:24 INFO     Training average negative_sample_loss at step 6300: 0.152592\n",
      "2024-02-28 19:38:24 INFO     Training average loss at step 6300: 0.158419\n",
      "2024-02-28 19:40:19 INFO     Training average positive_sample_loss at step 6400: 0.164269\n",
      "2024-02-28 19:40:19 INFO     Training average negative_sample_loss at step 6400: 0.152909\n",
      "2024-02-28 19:40:19 INFO     Training average loss at step 6400: 0.158589\n",
      "2024-02-28 19:42:21 INFO     Training average positive_sample_loss at step 6500: 0.163735\n",
      "2024-02-28 19:42:21 INFO     Training average negative_sample_loss at step 6500: 0.152200\n",
      "2024-02-28 19:42:21 INFO     Training average loss at step 6500: 0.157968\n",
      "2024-02-28 19:44:12 INFO     Training average positive_sample_loss at step 6600: 0.161771\n",
      "2024-02-28 19:44:12 INFO     Training average negative_sample_loss at step 6600: 0.151333\n",
      "2024-02-28 19:44:12 INFO     Training average loss at step 6600: 0.156552\n",
      "2024-02-28 19:46:10 INFO     Training average positive_sample_loss at step 6700: 0.146517\n",
      "2024-02-28 19:46:10 INFO     Training average negative_sample_loss at step 6700: 0.140213\n",
      "2024-02-28 19:46:10 INFO     Training average loss at step 6700: 0.143365\n",
      "2024-02-28 19:48:01 INFO     Training average positive_sample_loss at step 6800: 0.150786\n",
      "2024-02-28 19:48:01 INFO     Training average negative_sample_loss at step 6800: 0.139046\n",
      "2024-02-28 19:48:01 INFO     Training average loss at step 6800: 0.144916\n",
      "2024-02-28 19:49:53 INFO     Training average positive_sample_loss at step 6900: 0.152622\n",
      "2024-02-28 19:49:53 INFO     Training average negative_sample_loss at step 6900: 0.140998\n",
      "2024-02-28 19:49:53 INFO     Training average loss at step 6900: 0.146810\n",
      "2024-02-28 19:51:28 INFO     Training average positive_sample_loss at step 7000: 0.153394\n",
      "2024-02-28 19:51:28 INFO     Training average negative_sample_loss at step 7000: 0.141593\n",
      "2024-02-28 19:51:28 INFO     Training average loss at step 7000: 0.147493\n",
      "2024-02-28 19:53:05 INFO     Training average positive_sample_loss at step 7100: 0.154211\n",
      "2024-02-28 19:53:05 INFO     Training average negative_sample_loss at step 7100: 0.142441\n",
      "2024-02-28 19:53:05 INFO     Training average loss at step 7100: 0.148326\n",
      "2024-02-28 19:54:52 INFO     Training average positive_sample_loss at step 7200: 0.154468\n",
      "2024-02-28 19:54:52 INFO     Training average negative_sample_loss at step 7200: 0.143348\n",
      "2024-02-28 19:54:52 INFO     Training average loss at step 7200: 0.148908\n",
      "2024-02-28 19:56:44 INFO     Training average positive_sample_loss at step 7300: 0.154521\n",
      "2024-02-28 19:56:44 INFO     Training average negative_sample_loss at step 7300: 0.143666\n",
      "2024-02-28 19:56:44 INFO     Training average loss at step 7300: 0.149094\n",
      "2024-02-28 19:58:36 INFO     Training average positive_sample_loss at step 7400: 0.154385\n",
      "2024-02-28 19:58:36 INFO     Training average negative_sample_loss at step 7400: 0.142808\n",
      "2024-02-28 19:58:36 INFO     Training average loss at step 7400: 0.148597\n",
      "2024-02-28 20:00:34 INFO     Training average positive_sample_loss at step 7500: 0.153511\n",
      "2024-02-28 20:00:34 INFO     Training average negative_sample_loss at step 7500: 0.142520\n",
      "2024-02-28 20:00:34 INFO     Training average loss at step 7500: 0.148016\n",
      "2024-02-28 20:02:43 INFO     Training average positive_sample_loss at step 7600: 0.144329\n",
      "2024-02-28 20:02:43 INFO     Training average negative_sample_loss at step 7600: 0.137817\n",
      "2024-02-28 20:02:43 INFO     Training average loss at step 7600: 0.141073\n",
      "2024-02-28 20:04:43 INFO     Training average positive_sample_loss at step 7700: 0.141311\n",
      "2024-02-28 20:04:43 INFO     Training average negative_sample_loss at step 7700: 0.130616\n",
      "2024-02-28 20:04:43 INFO     Training average loss at step 7700: 0.135963\n",
      "2024-02-28 20:06:23 INFO     Training average positive_sample_loss at step 7800: 0.143712\n",
      "2024-02-28 20:06:23 INFO     Training average negative_sample_loss at step 7800: 0.131752\n",
      "2024-02-28 20:06:23 INFO     Training average loss at step 7800: 0.137732\n",
      "2024-02-28 20:08:26 INFO     Training average positive_sample_loss at step 7900: 0.144762\n",
      "2024-02-28 20:08:26 INFO     Training average negative_sample_loss at step 7900: 0.134043\n",
      "2024-02-28 20:08:26 INFO     Training average loss at step 7900: 0.139402\n",
      "2024-02-28 20:10:27 INFO     Training average positive_sample_loss at step 8000: 0.146804\n",
      "2024-02-28 20:10:27 INFO     Training average negative_sample_loss at step 8000: 0.135249\n",
      "2024-02-28 20:10:27 INFO     Training average loss at step 8000: 0.141026\n",
      "2024-02-28 20:12:07 INFO     Training average positive_sample_loss at step 8100: 0.146477\n",
      "2024-02-28 20:12:07 INFO     Training average negative_sample_loss at step 8100: 0.135053\n",
      "2024-02-28 20:12:07 INFO     Training average loss at step 8100: 0.140765\n",
      "2024-02-28 20:13:49 INFO     Training average positive_sample_loss at step 8200: 0.146130\n",
      "2024-02-28 20:13:49 INFO     Training average negative_sample_loss at step 8200: 0.135002\n",
      "2024-02-28 20:13:49 INFO     Training average loss at step 8200: 0.140566\n",
      "2024-02-28 20:15:49 INFO     Training average positive_sample_loss at step 8300: 0.147367\n",
      "2024-02-28 20:15:49 INFO     Training average negative_sample_loss at step 8300: 0.136665\n",
      "2024-02-28 20:15:49 INFO     Training average loss at step 8300: 0.142016\n",
      "2024-02-28 20:17:43 INFO     Training average positive_sample_loss at step 8400: 0.146065\n",
      "2024-02-28 20:17:43 INFO     Training average negative_sample_loss at step 8400: 0.135071\n",
      "2024-02-28 20:17:43 INFO     Training average loss at step 8400: 0.140568\n",
      "2024-02-28 20:19:55 INFO     Training average positive_sample_loss at step 8500: 0.145098\n",
      "2024-02-28 20:19:55 INFO     Training average negative_sample_loss at step 8500: 0.135024\n",
      "2024-02-28 20:19:55 INFO     Training average loss at step 8500: 0.140061\n",
      "2024-02-28 20:21:48 INFO     Training average positive_sample_loss at step 8600: 0.132005\n",
      "2024-02-28 20:21:48 INFO     Training average negative_sample_loss at step 8600: 0.124486\n",
      "2024-02-28 20:21:48 INFO     Training average loss at step 8600: 0.128245\n",
      "2024-02-28 20:23:41 INFO     Training average positive_sample_loss at step 8700: 0.137294\n",
      "2024-02-28 20:23:41 INFO     Training average negative_sample_loss at step 8700: 0.125712\n",
      "2024-02-28 20:23:41 INFO     Training average loss at step 8700: 0.131503\n",
      "2024-02-28 20:25:33 INFO     Training average positive_sample_loss at step 8800: 0.138501\n",
      "2024-02-28 20:25:33 INFO     Training average negative_sample_loss at step 8800: 0.127223\n",
      "2024-02-28 20:25:33 INFO     Training average loss at step 8800: 0.132862\n",
      "2024-02-28 20:27:45 INFO     Training average positive_sample_loss at step 8900: 0.139936\n",
      "2024-02-28 20:27:45 INFO     Training average negative_sample_loss at step 8900: 0.128286\n",
      "2024-02-28 20:27:45 INFO     Training average loss at step 8900: 0.134111\n",
      "2024-02-28 20:29:47 INFO     Training average positive_sample_loss at step 9000: 0.139946\n",
      "2024-02-28 20:29:47 INFO     Training average negative_sample_loss at step 9000: 0.128993\n",
      "2024-02-28 20:29:47 INFO     Training average loss at step 9000: 0.134470\n",
      "2024-02-28 20:31:46 INFO     Training average positive_sample_loss at step 9100: 0.141235\n",
      "2024-02-28 20:31:46 INFO     Training average negative_sample_loss at step 9100: 0.130265\n",
      "2024-02-28 20:31:46 INFO     Training average loss at step 9100: 0.135750\n",
      "2024-02-28 20:33:43 INFO     Training average positive_sample_loss at step 9200: 0.140662\n",
      "2024-02-28 20:33:43 INFO     Training average negative_sample_loss at step 9200: 0.129357\n",
      "2024-02-28 20:33:43 INFO     Training average loss at step 9200: 0.135010\n",
      "2024-02-28 20:35:25 INFO     Training average positive_sample_loss at step 9300: 0.140298\n",
      "2024-02-28 20:35:25 INFO     Training average negative_sample_loss at step 9300: 0.129268\n",
      "2024-02-28 20:35:25 INFO     Training average loss at step 9300: 0.134783\n",
      "2024-02-28 20:37:10 INFO     Training average positive_sample_loss at step 9400: 0.140967\n",
      "2024-02-28 20:37:10 INFO     Training average negative_sample_loss at step 9400: 0.129935\n",
      "2024-02-28 20:37:10 INFO     Training average loss at step 9400: 0.135451\n",
      "2024-02-28 20:39:07 INFO     Training average positive_sample_loss at step 9500: 0.131454\n",
      "2024-02-28 20:39:07 INFO     Training average negative_sample_loss at step 9500: 0.124659\n",
      "2024-02-28 20:39:07 INFO     Training average loss at step 9500: 0.128057\n",
      "2024-02-28 20:40:58 INFO     Training average positive_sample_loss at step 9600: 0.130842\n",
      "2024-02-28 20:40:58 INFO     Training average negative_sample_loss at step 9600: 0.120120\n",
      "2024-02-28 20:40:58 INFO     Training average loss at step 9600: 0.125481\n",
      "2024-02-28 20:43:01 INFO     Training average positive_sample_loss at step 9700: 0.133453\n",
      "2024-02-28 20:43:01 INFO     Training average negative_sample_loss at step 9700: 0.122015\n",
      "2024-02-28 20:43:01 INFO     Training average loss at step 9700: 0.127734\n",
      "2024-02-28 20:44:44 INFO     Training average positive_sample_loss at step 9800: 0.133954\n",
      "2024-02-28 20:44:44 INFO     Training average negative_sample_loss at step 9800: 0.122636\n",
      "2024-02-28 20:44:44 INFO     Training average loss at step 9800: 0.128295\n",
      "2024-02-28 20:46:40 INFO     Training average positive_sample_loss at step 9900: 0.135457\n",
      "2024-02-28 20:46:40 INFO     Training average negative_sample_loss at step 9900: 0.123356\n",
      "2024-02-28 20:46:40 INFO     Training average loss at step 9900: 0.129406\n",
      "2024-02-28 20:48:40 INFO     Training average positive_sample_loss at step 10000: 0.135897\n",
      "2024-02-28 20:48:40 INFO     Training average negative_sample_loss at step 10000: 0.124806\n",
      "2024-02-28 20:48:40 INFO     Training average loss at step 10000: 0.130351\n",
      "2024-02-28 20:48:40 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-28 20:48:41 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-28 20:49:13 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-28 20:49:52 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-28 20:50:29 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-28 20:51:01 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-28 20:51:32 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-28 20:52:07 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-28 20:52:15 INFO     Valid MRR at step 10000: 0.345893\n",
      "2024-02-28 20:52:15 INFO     Valid MR at step 10000: 586.518540\n",
      "2024-02-28 20:52:15 INFO     Valid HITS@1 at step 10000: 0.276150\n",
      "2024-02-28 20:52:15 INFO     Valid HITS@3 at step 10000: 0.357950\n",
      "2024-02-28 20:52:15 INFO     Valid HITS@10 at step 10000: 0.500270\n",
      "2024-02-28 20:53:38 INFO     Training average positive_sample_loss at step 10100: 0.135690\n",
      "2024-02-28 20:53:38 INFO     Training average negative_sample_loss at step 10100: 0.124492\n",
      "2024-02-28 20:53:38 INFO     Training average loss at step 10100: 0.130091\n",
      "2024-02-28 20:55:19 INFO     Training average positive_sample_loss at step 10200: 0.136323\n",
      "2024-02-28 20:55:19 INFO     Training average negative_sample_loss at step 10200: 0.124777\n",
      "2024-02-28 20:55:19 INFO     Training average loss at step 10200: 0.130550\n",
      "2024-02-28 20:57:04 INFO     Training average positive_sample_loss at step 10300: 0.136605\n",
      "2024-02-28 20:57:04 INFO     Training average negative_sample_loss at step 10300: 0.125385\n",
      "2024-02-28 20:57:04 INFO     Training average loss at step 10300: 0.130995\n",
      "2024-02-28 20:58:48 INFO     Training average positive_sample_loss at step 10400: 0.132683\n",
      "2024-02-28 20:58:48 INFO     Training average negative_sample_loss at step 10400: 0.124977\n",
      "2024-02-28 20:58:48 INFO     Training average loss at step 10400: 0.128830\n",
      "2024-02-28 21:00:56 INFO     Training average positive_sample_loss at step 10500: 0.125305\n",
      "2024-02-28 21:00:56 INFO     Training average negative_sample_loss at step 10500: 0.115271\n",
      "2024-02-28 21:00:56 INFO     Training average loss at step 10500: 0.120288\n",
      "2024-02-28 21:02:51 INFO     Training average positive_sample_loss at step 10600: 0.127637\n",
      "2024-02-28 21:02:51 INFO     Training average negative_sample_loss at step 10600: 0.116322\n",
      "2024-02-28 21:02:51 INFO     Training average loss at step 10600: 0.121979\n",
      "2024-02-28 21:04:33 INFO     Training average positive_sample_loss at step 10700: 0.129487\n",
      "2024-02-28 21:04:33 INFO     Training average negative_sample_loss at step 10700: 0.117464\n",
      "2024-02-28 21:04:33 INFO     Training average loss at step 10700: 0.123476\n",
      "2024-02-28 21:06:27 INFO     Training average positive_sample_loss at step 10800: 0.131172\n",
      "2024-02-28 21:06:27 INFO     Training average negative_sample_loss at step 10800: 0.119625\n",
      "2024-02-28 21:06:27 INFO     Training average loss at step 10800: 0.125398\n",
      "2024-02-28 21:08:17 INFO     Training average positive_sample_loss at step 10900: 0.131245\n",
      "2024-02-28 21:08:17 INFO     Training average negative_sample_loss at step 10900: 0.120019\n",
      "2024-02-28 21:08:17 INFO     Training average loss at step 10900: 0.125632\n",
      "2024-02-28 21:09:56 INFO     Training average positive_sample_loss at step 11000: 0.132848\n",
      "2024-02-28 21:09:56 INFO     Training average negative_sample_loss at step 11000: 0.121551\n",
      "2024-02-28 21:09:56 INFO     Training average loss at step 11000: 0.127199\n",
      "2024-02-28 21:11:41 INFO     Training average positive_sample_loss at step 11100: 0.133111\n",
      "2024-02-28 21:11:41 INFO     Training average negative_sample_loss at step 11100: 0.121807\n",
      "2024-02-28 21:11:41 INFO     Training average loss at step 11100: 0.127459\n",
      "2024-02-28 21:13:19 INFO     Training average positive_sample_loss at step 11200: 0.132531\n",
      "2024-02-28 21:13:19 INFO     Training average negative_sample_loss at step 11200: 0.121301\n",
      "2024-02-28 21:13:19 INFO     Training average loss at step 11200: 0.126916\n",
      "2024-02-28 21:15:04 INFO     Training average positive_sample_loss at step 11300: 0.132620\n",
      "2024-02-28 21:15:04 INFO     Training average negative_sample_loss at step 11300: 0.121682\n",
      "2024-02-28 21:15:04 INFO     Training average loss at step 11300: 0.127151\n",
      "2024-02-28 21:17:11 INFO     Training average positive_sample_loss at step 11400: 0.122354\n",
      "2024-02-28 21:17:11 INFO     Training average negative_sample_loss at step 11400: 0.114800\n",
      "2024-02-28 21:17:11 INFO     Training average loss at step 11400: 0.118577\n",
      "2024-02-28 21:18:55 INFO     Training average positive_sample_loss at step 11500: 0.124277\n",
      "2024-02-28 21:18:55 INFO     Training average negative_sample_loss at step 11500: 0.112715\n",
      "2024-02-28 21:18:55 INFO     Training average loss at step 11500: 0.118496\n",
      "2024-02-28 21:20:31 INFO     Training average positive_sample_loss at step 11600: 0.126141\n",
      "2024-02-28 21:20:31 INFO     Training average negative_sample_loss at step 11600: 0.114689\n",
      "2024-02-28 21:20:31 INFO     Training average loss at step 11600: 0.120415\n",
      "2024-02-28 21:22:17 INFO     Training average positive_sample_loss at step 11700: 0.126893\n",
      "2024-02-28 21:22:17 INFO     Training average negative_sample_loss at step 11700: 0.115143\n",
      "2024-02-28 21:22:17 INFO     Training average loss at step 11700: 0.121018\n",
      "2024-02-28 21:24:00 INFO     Training average positive_sample_loss at step 11800: 0.128347\n",
      "2024-02-28 21:24:00 INFO     Training average negative_sample_loss at step 11800: 0.116506\n",
      "2024-02-28 21:24:00 INFO     Training average loss at step 11800: 0.122427\n",
      "2024-02-28 21:25:37 INFO     Training average positive_sample_loss at step 11900: 0.129034\n",
      "2024-02-28 21:25:37 INFO     Training average negative_sample_loss at step 11900: 0.117335\n",
      "2024-02-28 21:25:37 INFO     Training average loss at step 11900: 0.123184\n",
      "2024-02-28 21:27:08 INFO     Training average positive_sample_loss at step 12000: 0.129433\n",
      "2024-02-28 21:27:08 INFO     Training average negative_sample_loss at step 12000: 0.117985\n",
      "2024-02-28 21:27:08 INFO     Training average loss at step 12000: 0.123709\n",
      "2024-02-28 21:28:59 INFO     Training average positive_sample_loss at step 12100: 0.128727\n",
      "2024-02-28 21:28:59 INFO     Training average negative_sample_loss at step 12100: 0.117403\n",
      "2024-02-28 21:28:59 INFO     Training average loss at step 12100: 0.123065\n",
      "2024-02-28 21:30:44 INFO     Training average positive_sample_loss at step 12200: 0.129493\n",
      "2024-02-28 21:30:44 INFO     Training average negative_sample_loss at step 12200: 0.117915\n",
      "2024-02-28 21:30:44 INFO     Training average loss at step 12200: 0.123704\n",
      "2024-02-28 21:32:39 INFO     Training average positive_sample_loss at step 12300: 0.124802\n",
      "2024-02-28 21:32:39 INFO     Training average negative_sample_loss at step 12300: 0.116330\n",
      "2024-02-28 21:32:39 INFO     Training average loss at step 12300: 0.120566\n",
      "2024-02-28 21:34:18 INFO     Training average positive_sample_loss at step 12400: 0.119502\n",
      "2024-02-28 21:34:18 INFO     Training average negative_sample_loss at step 12400: 0.108902\n",
      "2024-02-28 21:34:18 INFO     Training average loss at step 12400: 0.114202\n",
      "2024-02-28 21:36:04 INFO     Training average positive_sample_loss at step 12500: 0.122270\n",
      "2024-02-28 21:36:04 INFO     Training average negative_sample_loss at step 12500: 0.111074\n",
      "2024-02-28 21:36:04 INFO     Training average loss at step 12500: 0.116672\n",
      "2024-02-28 21:37:32 INFO     Training average positive_sample_loss at step 12600: 0.123399\n",
      "2024-02-28 21:37:32 INFO     Training average negative_sample_loss at step 12600: 0.111897\n",
      "2024-02-28 21:37:32 INFO     Training average loss at step 12600: 0.117648\n",
      "2024-02-28 21:39:26 INFO     Training average positive_sample_loss at step 12700: 0.125363\n",
      "2024-02-28 21:39:26 INFO     Training average negative_sample_loss at step 12700: 0.113330\n",
      "2024-02-28 21:39:26 INFO     Training average loss at step 12700: 0.119346\n",
      "2024-02-28 21:41:09 INFO     Training average positive_sample_loss at step 12800: 0.125629\n",
      "2024-02-28 21:41:09 INFO     Training average negative_sample_loss at step 12800: 0.114232\n",
      "2024-02-28 21:41:09 INFO     Training average loss at step 12800: 0.119930\n",
      "2024-02-28 21:43:00 INFO     Training average positive_sample_loss at step 12900: 0.126117\n",
      "2024-02-28 21:43:00 INFO     Training average negative_sample_loss at step 12900: 0.114274\n",
      "2024-02-28 21:43:00 INFO     Training average loss at step 12900: 0.120196\n",
      "2024-02-28 21:44:47 INFO     Training average positive_sample_loss at step 13000: 0.127178\n",
      "2024-02-28 21:44:47 INFO     Training average negative_sample_loss at step 13000: 0.115863\n",
      "2024-02-28 21:44:47 INFO     Training average loss at step 13000: 0.121521\n",
      "2024-02-28 21:46:40 INFO     Training average positive_sample_loss at step 13100: 0.127316\n",
      "2024-02-28 21:46:40 INFO     Training average negative_sample_loss at step 13100: 0.115895\n",
      "2024-02-28 21:46:40 INFO     Training average loss at step 13100: 0.121605\n",
      "2024-02-28 21:48:25 INFO     Training average positive_sample_loss at step 13200: 0.126911\n",
      "2024-02-28 21:48:25 INFO     Training average negative_sample_loss at step 13200: 0.115415\n",
      "2024-02-28 21:48:25 INFO     Training average loss at step 13200: 0.121163\n",
      "2024-02-28 21:50:23 INFO     Training average positive_sample_loss at step 13300: 0.116983\n",
      "2024-02-28 21:50:23 INFO     Training average negative_sample_loss at step 13300: 0.108894\n",
      "2024-02-28 21:50:23 INFO     Training average loss at step 13300: 0.112939\n",
      "2024-02-28 21:52:18 INFO     Training average positive_sample_loss at step 13400: 0.119345\n",
      "2024-02-28 21:52:18 INFO     Training average negative_sample_loss at step 13400: 0.107869\n",
      "2024-02-28 21:52:18 INFO     Training average loss at step 13400: 0.113607\n",
      "2024-02-28 21:54:23 INFO     Training average positive_sample_loss at step 13500: 0.120974\n",
      "2024-02-28 21:54:23 INFO     Training average negative_sample_loss at step 13500: 0.109684\n",
      "2024-02-28 21:54:23 INFO     Training average loss at step 13500: 0.115329\n",
      "2024-02-28 21:56:41 INFO     Training average positive_sample_loss at step 13600: 0.122789\n",
      "2024-02-28 21:56:41 INFO     Training average negative_sample_loss at step 13600: 0.110626\n",
      "2024-02-28 21:56:41 INFO     Training average loss at step 13600: 0.116707\n",
      "2024-02-28 21:58:28 INFO     Training average positive_sample_loss at step 13700: 0.123349\n",
      "2024-02-28 21:58:28 INFO     Training average negative_sample_loss at step 13700: 0.111575\n",
      "2024-02-28 21:58:28 INFO     Training average loss at step 13700: 0.117462\n",
      "2024-02-28 22:00:21 INFO     Training average positive_sample_loss at step 13800: 0.123335\n",
      "2024-02-28 22:00:21 INFO     Training average negative_sample_loss at step 13800: 0.111360\n",
      "2024-02-28 22:00:21 INFO     Training average loss at step 13800: 0.117348\n",
      "2024-02-28 22:01:59 INFO     Training average positive_sample_loss at step 13900: 0.124178\n",
      "2024-02-28 22:01:59 INFO     Training average negative_sample_loss at step 13900: 0.112525\n",
      "2024-02-28 22:01:59 INFO     Training average loss at step 13900: 0.118352\n",
      "2024-02-28 22:03:43 INFO     Training average positive_sample_loss at step 14000: 0.124373\n",
      "2024-02-28 22:03:43 INFO     Training average negative_sample_loss at step 14000: 0.112712\n",
      "2024-02-28 22:03:43 INFO     Training average loss at step 14000: 0.118542\n",
      "2024-02-28 22:05:21 INFO     Training average positive_sample_loss at step 14100: 0.124673\n",
      "2024-02-28 22:05:21 INFO     Training average negative_sample_loss at step 14100: 0.113050\n",
      "2024-02-28 22:05:21 INFO     Training average loss at step 14100: 0.118862\n",
      "2024-02-28 22:07:16 INFO     Training average positive_sample_loss at step 14200: 0.119180\n",
      "2024-02-28 22:07:16 INFO     Training average negative_sample_loss at step 14200: 0.111587\n",
      "2024-02-28 22:07:16 INFO     Training average loss at step 14200: 0.115384\n",
      "2024-02-28 22:09:28 INFO     Training average positive_sample_loss at step 14300: 0.115822\n",
      "2024-02-28 22:09:28 INFO     Training average negative_sample_loss at step 14300: 0.104355\n",
      "2024-02-28 22:09:28 INFO     Training average loss at step 14300: 0.110088\n",
      "2024-02-28 22:11:33 INFO     Training average positive_sample_loss at step 14400: 0.117968\n",
      "2024-02-28 22:11:33 INFO     Training average negative_sample_loss at step 14400: 0.106403\n",
      "2024-02-28 22:11:33 INFO     Training average loss at step 14400: 0.112185\n",
      "2024-02-28 22:13:14 INFO     Training average positive_sample_loss at step 14500: 0.119866\n",
      "2024-02-28 22:13:14 INFO     Training average negative_sample_loss at step 14500: 0.107572\n",
      "2024-02-28 22:13:14 INFO     Training average loss at step 14500: 0.113719\n",
      "2024-02-28 22:15:05 INFO     Training average positive_sample_loss at step 14600: 0.120713\n",
      "2024-02-28 22:15:05 INFO     Training average negative_sample_loss at step 14600: 0.108990\n",
      "2024-02-28 22:15:05 INFO     Training average loss at step 14600: 0.114852\n",
      "2024-02-28 22:16:57 INFO     Training average positive_sample_loss at step 14700: 0.121919\n",
      "2024-02-28 22:16:57 INFO     Training average negative_sample_loss at step 14700: 0.110223\n",
      "2024-02-28 22:16:57 INFO     Training average loss at step 14700: 0.116071\n",
      "2024-02-28 22:18:39 INFO     Training average positive_sample_loss at step 14800: 0.122912\n",
      "2024-02-28 22:18:39 INFO     Training average negative_sample_loss at step 14800: 0.111413\n",
      "2024-02-28 22:18:39 INFO     Training average loss at step 14800: 0.117163\n",
      "2024-02-28 22:20:25 INFO     Training average positive_sample_loss at step 14900: 0.122668\n",
      "2024-02-28 22:20:25 INFO     Training average negative_sample_loss at step 14900: 0.110924\n",
      "2024-02-28 22:20:25 INFO     Training average loss at step 14900: 0.116796\n",
      "2024-02-28 22:22:11 INFO     Training average positive_sample_loss at step 15000: 0.122639\n",
      "2024-02-28 22:22:11 INFO     Training average negative_sample_loss at step 15000: 0.111315\n",
      "2024-02-28 22:22:11 INFO     Training average loss at step 15000: 0.116977\n",
      "2024-02-28 22:24:00 INFO     Training average positive_sample_loss at step 15100: 0.122228\n",
      "2024-02-28 22:24:00 INFO     Training average negative_sample_loss at step 15100: 0.111109\n",
      "2024-02-28 22:24:00 INFO     Training average loss at step 15100: 0.116669\n",
      "2024-02-28 22:26:00 INFO     Training average positive_sample_loss at step 15200: 0.111886\n",
      "2024-02-28 22:26:00 INFO     Training average negative_sample_loss at step 15200: 0.103565\n",
      "2024-02-28 22:26:00 INFO     Training average loss at step 15200: 0.107725\n",
      "2024-02-28 22:27:53 INFO     Training average positive_sample_loss at step 15300: 0.115569\n",
      "2024-02-28 22:27:53 INFO     Training average negative_sample_loss at step 15300: 0.103752\n",
      "2024-02-28 22:27:53 INFO     Training average loss at step 15300: 0.109660\n",
      "2024-02-28 22:29:45 INFO     Training average positive_sample_loss at step 15400: 0.117263\n",
      "2024-02-28 22:29:45 INFO     Training average negative_sample_loss at step 15400: 0.105367\n",
      "2024-02-28 22:29:45 INFO     Training average loss at step 15400: 0.111315\n",
      "2024-02-28 22:31:35 INFO     Training average positive_sample_loss at step 15500: 0.118859\n",
      "2024-02-28 22:31:35 INFO     Training average negative_sample_loss at step 15500: 0.107155\n",
      "2024-02-28 22:31:35 INFO     Training average loss at step 15500: 0.113007\n",
      "2024-02-28 22:33:23 INFO     Training average positive_sample_loss at step 15600: 0.119044\n",
      "2024-02-28 22:33:23 INFO     Training average negative_sample_loss at step 15600: 0.107323\n",
      "2024-02-28 22:33:23 INFO     Training average loss at step 15600: 0.113183\n",
      "2024-02-28 22:35:16 INFO     Training average positive_sample_loss at step 15700: 0.120679\n",
      "2024-02-28 22:35:16 INFO     Training average negative_sample_loss at step 15700: 0.108427\n",
      "2024-02-28 22:35:16 INFO     Training average loss at step 15700: 0.114553\n",
      "2024-02-28 22:37:13 INFO     Training average positive_sample_loss at step 15800: 0.120641\n",
      "2024-02-28 22:37:13 INFO     Training average negative_sample_loss at step 15800: 0.108808\n",
      "2024-02-28 22:37:13 INFO     Training average loss at step 15800: 0.114725\n",
      "2024-02-28 22:38:56 INFO     Training average positive_sample_loss at step 15900: 0.120344\n",
      "2024-02-28 22:38:56 INFO     Training average negative_sample_loss at step 15900: 0.108792\n",
      "2024-02-28 22:38:56 INFO     Training average loss at step 15900: 0.114568\n",
      "2024-02-28 22:40:54 INFO     Training average positive_sample_loss at step 16000: 0.121225\n",
      "2024-02-28 22:40:54 INFO     Training average negative_sample_loss at step 16000: 0.110256\n",
      "2024-02-28 22:40:54 INFO     Training average loss at step 16000: 0.115740\n",
      "2024-02-28 22:43:06 INFO     Training average positive_sample_loss at step 16100: 0.114416\n",
      "2024-02-28 22:43:06 INFO     Training average negative_sample_loss at step 16100: 0.106021\n",
      "2024-02-28 22:43:06 INFO     Training average loss at step 16100: 0.110218\n",
      "2024-02-28 22:45:00 INFO     Training average positive_sample_loss at step 16200: 0.113432\n",
      "2024-02-28 22:45:00 INFO     Training average negative_sample_loss at step 16200: 0.101610\n",
      "2024-02-28 22:45:00 INFO     Training average loss at step 16200: 0.107521\n",
      "2024-02-28 22:46:48 INFO     Training average positive_sample_loss at step 16300: 0.115446\n",
      "2024-02-28 22:46:48 INFO     Training average negative_sample_loss at step 16300: 0.103426\n",
      "2024-02-28 22:46:48 INFO     Training average loss at step 16300: 0.109436\n",
      "2024-02-28 22:48:39 INFO     Training average positive_sample_loss at step 16400: 0.117084\n",
      "2024-02-28 22:48:39 INFO     Training average negative_sample_loss at step 16400: 0.105179\n",
      "2024-02-28 22:48:39 INFO     Training average loss at step 16400: 0.111132\n",
      "2024-02-28 22:50:37 INFO     Training average positive_sample_loss at step 16500: 0.117475\n",
      "2024-02-28 22:50:37 INFO     Training average negative_sample_loss at step 16500: 0.105187\n",
      "2024-02-28 22:50:37 INFO     Training average loss at step 16500: 0.111331\n",
      "2024-02-28 22:52:24 INFO     Training average positive_sample_loss at step 16600: 0.118943\n",
      "2024-02-28 22:52:24 INFO     Training average negative_sample_loss at step 16600: 0.107329\n",
      "2024-02-28 22:52:24 INFO     Training average loss at step 16600: 0.113136\n",
      "2024-02-28 22:54:17 INFO     Training average positive_sample_loss at step 16700: 0.118810\n",
      "2024-02-28 22:54:17 INFO     Training average negative_sample_loss at step 16700: 0.106896\n",
      "2024-02-28 22:54:17 INFO     Training average loss at step 16700: 0.112853\n",
      "2024-02-28 22:56:18 INFO     Training average positive_sample_loss at step 16800: 0.119137\n",
      "2024-02-28 22:56:18 INFO     Training average negative_sample_loss at step 16800: 0.107618\n",
      "2024-02-28 22:56:18 INFO     Training average loss at step 16800: 0.113377\n",
      "2024-02-28 22:58:08 INFO     Training average positive_sample_loss at step 16900: 0.119223\n",
      "2024-02-28 22:58:08 INFO     Training average negative_sample_loss at step 16900: 0.107532\n",
      "2024-02-28 22:58:08 INFO     Training average loss at step 16900: 0.113378\n",
      "2024-02-28 23:00:01 INFO     Training average positive_sample_loss at step 17000: 0.117245\n",
      "2024-02-28 23:00:01 INFO     Training average negative_sample_loss at step 17000: 0.107518\n",
      "2024-02-28 23:00:01 INFO     Training average loss at step 17000: 0.112381\n",
      "2024-02-28 23:01:44 INFO     Training average positive_sample_loss at step 17100: 0.109775\n",
      "2024-02-28 23:01:44 INFO     Training average negative_sample_loss at step 17100: 0.099816\n",
      "2024-02-28 23:01:44 INFO     Training average loss at step 17100: 0.104795\n",
      "2024-02-28 23:03:48 INFO     Training average positive_sample_loss at step 17200: 0.112888\n",
      "2024-02-28 23:03:48 INFO     Training average negative_sample_loss at step 17200: 0.100776\n",
      "2024-02-28 23:03:48 INFO     Training average loss at step 17200: 0.106832\n",
      "2024-02-28 23:05:38 INFO     Training average positive_sample_loss at step 17300: 0.114885\n",
      "2024-02-28 23:05:38 INFO     Training average negative_sample_loss at step 17300: 0.102717\n",
      "2024-02-28 23:05:38 INFO     Training average loss at step 17300: 0.108801\n",
      "2024-02-28 23:07:16 INFO     Training average positive_sample_loss at step 17400: 0.115890\n",
      "2024-02-28 23:07:16 INFO     Training average negative_sample_loss at step 17400: 0.103679\n",
      "2024-02-28 23:07:16 INFO     Training average loss at step 17400: 0.109785\n",
      "2024-02-28 23:09:06 INFO     Training average positive_sample_loss at step 17500: 0.116356\n",
      "2024-02-28 23:09:06 INFO     Training average negative_sample_loss at step 17500: 0.104773\n",
      "2024-02-28 23:09:06 INFO     Training average loss at step 17500: 0.110564\n",
      "2024-02-28 23:10:56 INFO     Training average positive_sample_loss at step 17600: 0.117653\n",
      "2024-02-28 23:10:56 INFO     Training average negative_sample_loss at step 17600: 0.105539\n",
      "2024-02-28 23:10:56 INFO     Training average loss at step 17600: 0.111596\n",
      "2024-02-28 23:12:46 INFO     Training average positive_sample_loss at step 17700: 0.117740\n",
      "2024-02-28 23:12:46 INFO     Training average negative_sample_loss at step 17700: 0.106186\n",
      "2024-02-28 23:12:46 INFO     Training average loss at step 17700: 0.111963\n",
      "2024-02-28 23:14:24 INFO     Training average positive_sample_loss at step 17800: 0.118231\n",
      "2024-02-28 23:14:24 INFO     Training average negative_sample_loss at step 17800: 0.106183\n",
      "2024-02-28 23:14:24 INFO     Training average loss at step 17800: 0.112207\n",
      "2024-02-28 23:15:56 INFO     Training average positive_sample_loss at step 17900: 0.118398\n",
      "2024-02-28 23:15:56 INFO     Training average negative_sample_loss at step 17900: 0.106928\n",
      "2024-02-28 23:15:56 INFO     Training average loss at step 17900: 0.112663\n",
      "2024-02-28 23:17:55 INFO     Training average positive_sample_loss at step 18000: 0.110912\n",
      "2024-02-28 23:17:55 INFO     Training average negative_sample_loss at step 18000: 0.102406\n",
      "2024-02-28 23:17:55 INFO     Training average loss at step 18000: 0.106659\n",
      "2024-02-28 23:19:47 INFO     Training average positive_sample_loss at step 18100: 0.110861\n",
      "2024-02-28 23:19:47 INFO     Training average negative_sample_loss at step 18100: 0.099015\n",
      "2024-02-28 23:19:47 INFO     Training average loss at step 18100: 0.104938\n",
      "2024-02-28 23:21:40 INFO     Training average positive_sample_loss at step 18200: 0.113177\n",
      "2024-02-28 23:21:40 INFO     Training average negative_sample_loss at step 18200: 0.101399\n",
      "2024-02-28 23:21:40 INFO     Training average loss at step 18200: 0.107288\n",
      "2024-02-28 23:23:20 INFO     Training average positive_sample_loss at step 18300: 0.113726\n",
      "2024-02-28 23:23:20 INFO     Training average negative_sample_loss at step 18300: 0.101353\n",
      "2024-02-28 23:23:20 INFO     Training average loss at step 18300: 0.107539\n",
      "2024-02-28 23:24:46 INFO     Training average positive_sample_loss at step 18400: 0.114849\n",
      "2024-02-28 23:24:46 INFO     Training average negative_sample_loss at step 18400: 0.102850\n",
      "2024-02-28 23:24:46 INFO     Training average loss at step 18400: 0.108850\n",
      "2024-02-28 23:26:45 INFO     Training average positive_sample_loss at step 18500: 0.116273\n",
      "2024-02-28 23:26:45 INFO     Training average negative_sample_loss at step 18500: 0.104217\n",
      "2024-02-28 23:26:45 INFO     Training average loss at step 18500: 0.110245\n",
      "2024-02-28 23:28:50 INFO     Training average positive_sample_loss at step 18600: 0.116306\n",
      "2024-02-28 23:28:50 INFO     Training average negative_sample_loss at step 18600: 0.104250\n",
      "2024-02-28 23:28:50 INFO     Training average loss at step 18600: 0.110278\n",
      "2024-02-28 23:30:52 INFO     Training average positive_sample_loss at step 18700: 0.116934\n",
      "2024-02-28 23:30:52 INFO     Training average negative_sample_loss at step 18700: 0.104903\n",
      "2024-02-28 23:30:52 INFO     Training average loss at step 18700: 0.110918\n",
      "2024-02-28 23:32:56 INFO     Training average positive_sample_loss at step 18800: 0.116635\n",
      "2024-02-28 23:32:56 INFO     Training average negative_sample_loss at step 18800: 0.105396\n",
      "2024-02-28 23:32:56 INFO     Training average loss at step 18800: 0.111015\n",
      "2024-02-28 23:35:03 INFO     Training average positive_sample_loss at step 18900: 0.113702\n",
      "2024-02-28 23:35:03 INFO     Training average negative_sample_loss at step 18900: 0.104317\n",
      "2024-02-28 23:35:03 INFO     Training average loss at step 18900: 0.109009\n",
      "2024-02-28 23:36:39 INFO     Training average positive_sample_loss at step 19000: 0.108678\n",
      "2024-02-28 23:36:39 INFO     Training average negative_sample_loss at step 19000: 0.097559\n",
      "2024-02-28 23:36:39 INFO     Training average loss at step 19000: 0.103119\n",
      "2024-02-28 23:38:32 INFO     Training average positive_sample_loss at step 19100: 0.110775\n",
      "2024-02-28 23:38:32 INFO     Training average negative_sample_loss at step 19100: 0.098615\n",
      "2024-02-28 23:38:32 INFO     Training average loss at step 19100: 0.104695\n",
      "2024-02-28 23:40:38 INFO     Training average positive_sample_loss at step 19200: 0.113027\n",
      "2024-02-28 23:40:38 INFO     Training average negative_sample_loss at step 19200: 0.100771\n",
      "2024-02-28 23:40:38 INFO     Training average loss at step 19200: 0.106899\n",
      "2024-02-28 23:42:39 INFO     Training average positive_sample_loss at step 19300: 0.114212\n",
      "2024-02-28 23:42:39 INFO     Training average negative_sample_loss at step 19300: 0.102064\n",
      "2024-02-28 23:42:39 INFO     Training average loss at step 19300: 0.108138\n",
      "2024-02-28 23:44:27 INFO     Training average positive_sample_loss at step 19400: 0.114636\n",
      "2024-02-28 23:44:27 INFO     Training average negative_sample_loss at step 19400: 0.102593\n",
      "2024-02-28 23:44:27 INFO     Training average loss at step 19400: 0.108615\n",
      "2024-02-28 23:46:26 INFO     Training average positive_sample_loss at step 19500: 0.115234\n",
      "2024-02-28 23:46:26 INFO     Training average negative_sample_loss at step 19500: 0.103407\n",
      "2024-02-28 23:46:26 INFO     Training average loss at step 19500: 0.109320\n",
      "2024-02-28 23:48:17 INFO     Training average positive_sample_loss at step 19600: 0.114824\n",
      "2024-02-28 23:48:17 INFO     Training average negative_sample_loss at step 19600: 0.103197\n",
      "2024-02-28 23:48:17 INFO     Training average loss at step 19600: 0.109011\n",
      "2024-02-28 23:50:10 INFO     Training average positive_sample_loss at step 19700: 0.115384\n",
      "2024-02-28 23:50:10 INFO     Training average negative_sample_loss at step 19700: 0.103564\n",
      "2024-02-28 23:50:10 INFO     Training average loss at step 19700: 0.109474\n",
      "2024-02-28 23:52:10 INFO     Training average positive_sample_loss at step 19800: 0.116222\n",
      "2024-02-28 23:52:10 INFO     Training average negative_sample_loss at step 19800: 0.104264\n",
      "2024-02-28 23:52:10 INFO     Training average loss at step 19800: 0.110243\n",
      "2024-02-28 23:54:11 INFO     Training average positive_sample_loss at step 19900: 0.107824\n",
      "2024-02-28 23:54:11 INFO     Training average negative_sample_loss at step 19900: 0.099268\n",
      "2024-02-28 23:54:11 INFO     Training average loss at step 19900: 0.103546\n",
      "2024-02-28 23:55:57 INFO     Training average positive_sample_loss at step 20000: 0.108936\n",
      "2024-02-28 23:55:57 INFO     Training average negative_sample_loss at step 20000: 0.096924\n",
      "2024-02-28 23:55:57 INFO     Training average loss at step 20000: 0.102930\n",
      "2024-02-28 23:55:57 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-28 23:55:58 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-28 23:56:31 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-28 23:57:08 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-28 23:57:43 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-28 23:58:13 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-28 23:58:51 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-28 23:59:23 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-28 23:59:30 INFO     Valid MRR at step 20000: 0.381441\n",
      "2024-02-28 23:59:30 INFO     Valid MR at step 20000: 394.400430\n",
      "2024-02-28 23:59:30 INFO     Valid HITS@1 at step 20000: 0.306960\n",
      "2024-02-28 23:59:30 INFO     Valid HITS@3 at step 20000: 0.395570\n",
      "2024-02-28 23:59:30 INFO     Valid HITS@10 at step 20000: 0.546780\n",
      "2024-02-29 00:00:42 INFO     Training average positive_sample_loss at step 20100: 0.111047\n",
      "2024-02-29 00:00:42 INFO     Training average negative_sample_loss at step 20100: 0.098715\n",
      "2024-02-29 00:00:42 INFO     Training average loss at step 20100: 0.104881\n",
      "2024-02-29 00:02:20 INFO     Training average positive_sample_loss at step 20200: 0.112134\n",
      "2024-02-29 00:02:20 INFO     Training average negative_sample_loss at step 20200: 0.100058\n",
      "2024-02-29 00:02:20 INFO     Training average loss at step 20200: 0.106096\n",
      "2024-02-29 00:04:17 INFO     Training average positive_sample_loss at step 20300: 0.113637\n",
      "2024-02-29 00:04:17 INFO     Training average negative_sample_loss at step 20300: 0.101662\n",
      "2024-02-29 00:04:17 INFO     Training average loss at step 20300: 0.107649\n",
      "2024-02-29 00:06:02 INFO     Training average positive_sample_loss at step 20400: 0.114147\n",
      "2024-02-29 00:06:02 INFO     Training average negative_sample_loss at step 20400: 0.101730\n",
      "2024-02-29 00:06:02 INFO     Training average loss at step 20400: 0.107939\n",
      "2024-02-29 00:07:52 INFO     Training average positive_sample_loss at step 20500: 0.114494\n",
      "2024-02-29 00:07:52 INFO     Training average negative_sample_loss at step 20500: 0.102692\n",
      "2024-02-29 00:07:52 INFO     Training average loss at step 20500: 0.108593\n",
      "2024-02-29 00:09:38 INFO     Training average positive_sample_loss at step 20600: 0.114314\n",
      "2024-02-29 00:09:38 INFO     Training average negative_sample_loss at step 20600: 0.102128\n",
      "2024-02-29 00:09:38 INFO     Training average loss at step 20600: 0.108221\n",
      "2024-02-29 00:11:39 INFO     Training average positive_sample_loss at step 20700: 0.114775\n",
      "2024-02-29 00:11:39 INFO     Training average negative_sample_loss at step 20700: 0.102930\n",
      "2024-02-29 00:11:39 INFO     Training average loss at step 20700: 0.108852\n",
      "2024-02-29 00:13:46 INFO     Training average positive_sample_loss at step 20800: 0.110304\n",
      "2024-02-29 00:13:46 INFO     Training average negative_sample_loss at step 20800: 0.101443\n",
      "2024-02-29 00:13:46 INFO     Training average loss at step 20800: 0.105874\n",
      "2024-02-29 00:15:35 INFO     Training average positive_sample_loss at step 20900: 0.107385\n",
      "2024-02-29 00:15:35 INFO     Training average negative_sample_loss at step 20900: 0.095707\n",
      "2024-02-29 00:15:35 INFO     Training average loss at step 20900: 0.101546\n",
      "2024-02-29 00:17:21 INFO     Training average positive_sample_loss at step 21000: 0.109478\n",
      "2024-02-29 00:17:21 INFO     Training average negative_sample_loss at step 21000: 0.097194\n",
      "2024-02-29 00:17:21 INFO     Training average loss at step 21000: 0.103336\n",
      "2024-02-29 00:19:12 INFO     Training average positive_sample_loss at step 21100: 0.111058\n",
      "2024-02-29 00:19:12 INFO     Training average negative_sample_loss at step 21100: 0.099036\n",
      "2024-02-29 00:19:12 INFO     Training average loss at step 21100: 0.105047\n",
      "2024-02-29 00:20:58 INFO     Training average positive_sample_loss at step 21200: 0.112017\n",
      "2024-02-29 00:20:58 INFO     Training average negative_sample_loss at step 21200: 0.099934\n",
      "2024-02-29 00:20:58 INFO     Training average loss at step 21200: 0.105976\n",
      "2024-02-29 00:22:47 INFO     Training average positive_sample_loss at step 21300: 0.112821\n",
      "2024-02-29 00:22:47 INFO     Training average negative_sample_loss at step 21300: 0.100882\n",
      "2024-02-29 00:22:47 INFO     Training average loss at step 21300: 0.106851\n",
      "2024-02-29 00:24:13 INFO     Training average positive_sample_loss at step 21400: 0.113158\n",
      "2024-02-29 00:24:13 INFO     Training average negative_sample_loss at step 21400: 0.101083\n",
      "2024-02-29 00:24:13 INFO     Training average loss at step 21400: 0.107120\n",
      "2024-02-29 00:25:39 INFO     Training average positive_sample_loss at step 21500: 0.113966\n",
      "2024-02-29 00:25:39 INFO     Training average negative_sample_loss at step 21500: 0.101710\n",
      "2024-02-29 00:25:39 INFO     Training average loss at step 21500: 0.107838\n",
      "2024-02-29 00:27:08 INFO     Training average positive_sample_loss at step 21600: 0.114177\n",
      "2024-02-29 00:27:08 INFO     Training average negative_sample_loss at step 21600: 0.102565\n",
      "2024-02-29 00:27:08 INFO     Training average loss at step 21600: 0.108371\n",
      "2024-02-29 00:28:57 INFO     Training average positive_sample_loss at step 21700: 0.113649\n",
      "2024-02-29 00:28:57 INFO     Training average negative_sample_loss at step 21700: 0.101721\n",
      "2024-02-29 00:28:57 INFO     Training average loss at step 21700: 0.107685\n",
      "2024-02-29 00:31:00 INFO     Training average positive_sample_loss at step 21800: 0.104963\n",
      "2024-02-29 00:31:00 INFO     Training average negative_sample_loss at step 21800: 0.096215\n",
      "2024-02-29 00:31:00 INFO     Training average loss at step 21800: 0.100589\n",
      "2024-02-29 00:33:02 INFO     Training average positive_sample_loss at step 21900: 0.107938\n",
      "2024-02-29 00:33:02 INFO     Training average negative_sample_loss at step 21900: 0.095723\n",
      "2024-02-29 00:33:02 INFO     Training average loss at step 21900: 0.101830\n",
      "2024-02-29 00:34:57 INFO     Training average positive_sample_loss at step 22000: 0.109850\n",
      "2024-02-29 00:34:57 INFO     Training average negative_sample_loss at step 22000: 0.097631\n",
      "2024-02-29 00:34:57 INFO     Training average loss at step 22000: 0.103741\n",
      "2024-02-29 00:36:43 INFO     Training average positive_sample_loss at step 22100: 0.110707\n",
      "2024-02-29 00:36:43 INFO     Training average negative_sample_loss at step 22100: 0.098572\n",
      "2024-02-29 00:36:43 INFO     Training average loss at step 22100: 0.104639\n",
      "2024-02-29 00:38:42 INFO     Training average positive_sample_loss at step 22200: 0.111088\n",
      "2024-02-29 00:38:42 INFO     Training average negative_sample_loss at step 22200: 0.098837\n",
      "2024-02-29 00:38:42 INFO     Training average loss at step 22200: 0.104962\n",
      "2024-02-29 00:40:26 INFO     Training average positive_sample_loss at step 22300: 0.111920\n",
      "2024-02-29 00:40:26 INFO     Training average negative_sample_loss at step 22300: 0.100084\n",
      "2024-02-29 00:40:26 INFO     Training average loss at step 22300: 0.106002\n",
      "2024-02-29 00:42:17 INFO     Training average positive_sample_loss at step 22400: 0.112547\n",
      "2024-02-29 00:42:17 INFO     Training average negative_sample_loss at step 22400: 0.100850\n",
      "2024-02-29 00:42:17 INFO     Training average loss at step 22400: 0.106699\n",
      "2024-02-29 00:44:10 INFO     Training average positive_sample_loss at step 22500: 0.113197\n",
      "2024-02-29 00:44:10 INFO     Training average negative_sample_loss at step 22500: 0.101084\n",
      "2024-02-29 00:44:10 INFO     Training average loss at step 22500: 0.107141\n",
      "2024-02-29 00:45:40 INFO     Training average positive_sample_loss at step 22600: 0.113727\n",
      "2024-02-29 00:45:40 INFO     Training average negative_sample_loss at step 22600: 0.102021\n",
      "2024-02-29 00:45:40 INFO     Training average loss at step 22600: 0.107874\n",
      "2024-02-29 00:47:29 INFO     Training average positive_sample_loss at step 22700: 0.107992\n",
      "2024-02-29 00:47:29 INFO     Training average negative_sample_loss at step 22700: 0.098824\n",
      "2024-02-29 00:47:29 INFO     Training average loss at step 22700: 0.103408\n",
      "2024-02-29 00:49:21 INFO     Training average positive_sample_loss at step 22800: 0.105543\n",
      "2024-02-29 00:49:21 INFO     Training average negative_sample_loss at step 22800: 0.093679\n",
      "2024-02-29 00:49:21 INFO     Training average loss at step 22800: 0.099611\n",
      "2024-02-29 00:51:17 INFO     Training average positive_sample_loss at step 22900: 0.108520\n",
      "2024-02-29 00:51:17 INFO     Training average negative_sample_loss at step 22900: 0.096425\n",
      "2024-02-29 00:51:17 INFO     Training average loss at step 22900: 0.102472\n",
      "2024-02-29 00:53:06 INFO     Training average positive_sample_loss at step 23000: 0.109277\n",
      "2024-02-29 00:53:06 INFO     Training average negative_sample_loss at step 23000: 0.097187\n",
      "2024-02-29 00:53:06 INFO     Training average loss at step 23000: 0.103232\n",
      "2024-02-29 00:54:47 INFO     Training average positive_sample_loss at step 23100: 0.110443\n",
      "2024-02-29 00:54:47 INFO     Training average negative_sample_loss at step 23100: 0.097976\n",
      "2024-02-29 00:54:47 INFO     Training average loss at step 23100: 0.104210\n",
      "2024-02-29 00:56:46 INFO     Training average positive_sample_loss at step 23200: 0.111248\n",
      "2024-02-29 00:56:46 INFO     Training average negative_sample_loss at step 23200: 0.098935\n",
      "2024-02-29 00:56:46 INFO     Training average loss at step 23200: 0.105091\n",
      "2024-02-29 00:58:38 INFO     Training average positive_sample_loss at step 23300: 0.112261\n",
      "2024-02-29 00:58:38 INFO     Training average negative_sample_loss at step 23300: 0.100692\n",
      "2024-02-29 00:58:38 INFO     Training average loss at step 23300: 0.106476\n",
      "2024-02-29 01:00:33 INFO     Training average positive_sample_loss at step 23400: 0.112267\n",
      "2024-02-29 01:00:33 INFO     Training average negative_sample_loss at step 23400: 0.099957\n",
      "2024-02-29 01:00:33 INFO     Training average loss at step 23400: 0.106112\n",
      "2024-02-29 01:02:12 INFO     Training average positive_sample_loss at step 23500: 0.112658\n",
      "2024-02-29 01:02:12 INFO     Training average negative_sample_loss at step 23500: 0.100999\n",
      "2024-02-29 01:02:12 INFO     Training average loss at step 23500: 0.106829\n",
      "2024-02-29 01:04:22 INFO     Training average positive_sample_loss at step 23600: 0.112167\n",
      "2024-02-29 01:04:22 INFO     Training average negative_sample_loss at step 23600: 0.100355\n",
      "2024-02-29 01:04:22 INFO     Training average loss at step 23600: 0.106261\n",
      "2024-02-29 01:06:05 INFO     Training average positive_sample_loss at step 23700: 0.102589\n",
      "2024-02-29 01:06:05 INFO     Training average negative_sample_loss at step 23700: 0.093454\n",
      "2024-02-29 01:06:05 INFO     Training average loss at step 23700: 0.098021\n",
      "2024-02-29 01:07:52 INFO     Training average positive_sample_loss at step 23800: 0.106934\n",
      "2024-02-29 01:07:52 INFO     Training average negative_sample_loss at step 23800: 0.094788\n",
      "2024-02-29 01:07:52 INFO     Training average loss at step 23800: 0.100861\n",
      "2024-02-29 01:09:46 INFO     Training average positive_sample_loss at step 23900: 0.108103\n",
      "2024-02-29 01:09:46 INFO     Training average negative_sample_loss at step 23900: 0.096022\n",
      "2024-02-29 01:09:46 INFO     Training average loss at step 23900: 0.102063\n",
      "2024-02-29 01:11:36 INFO     Training average positive_sample_loss at step 24000: 0.109778\n",
      "2024-02-29 01:11:36 INFO     Training average negative_sample_loss at step 24000: 0.097439\n",
      "2024-02-29 01:11:36 INFO     Training average loss at step 24000: 0.103608\n",
      "2024-02-29 01:13:26 INFO     Training average positive_sample_loss at step 24100: 0.110075\n",
      "2024-02-29 01:13:26 INFO     Training average negative_sample_loss at step 24100: 0.097871\n",
      "2024-02-29 01:13:26 INFO     Training average loss at step 24100: 0.103973\n",
      "2024-02-29 01:15:17 INFO     Training average positive_sample_loss at step 24200: 0.110871\n",
      "2024-02-29 01:15:17 INFO     Training average negative_sample_loss at step 24200: 0.098759\n",
      "2024-02-29 01:15:17 INFO     Training average loss at step 24200: 0.104815\n",
      "2024-02-29 01:17:07 INFO     Training average positive_sample_loss at step 24300: 0.110795\n",
      "2024-02-29 01:17:07 INFO     Training average negative_sample_loss at step 24300: 0.099069\n",
      "2024-02-29 01:17:07 INFO     Training average loss at step 24300: 0.104932\n",
      "2024-02-29 01:18:53 INFO     Training average positive_sample_loss at step 24400: 0.111653\n",
      "2024-02-29 01:18:53 INFO     Training average negative_sample_loss at step 24400: 0.099335\n",
      "2024-02-29 01:18:53 INFO     Training average loss at step 24400: 0.105494\n",
      "2024-02-29 01:20:21 INFO     Training average positive_sample_loss at step 24500: 0.112135\n",
      "2024-02-29 01:20:21 INFO     Training average negative_sample_loss at step 24500: 0.100627\n",
      "2024-02-29 01:20:21 INFO     Training average loss at step 24500: 0.106381\n",
      "2024-02-29 01:22:20 INFO     Training average positive_sample_loss at step 24600: 0.105348\n",
      "2024-02-29 01:22:20 INFO     Training average negative_sample_loss at step 24600: 0.096120\n",
      "2024-02-29 01:22:20 INFO     Training average loss at step 24600: 0.100734\n",
      "2024-02-29 01:23:58 INFO     Training average positive_sample_loss at step 24700: 0.104885\n",
      "2024-02-29 01:23:58 INFO     Training average negative_sample_loss at step 24700: 0.093135\n",
      "2024-02-29 01:23:58 INFO     Training average loss at step 24700: 0.099010\n",
      "2024-02-29 01:25:52 INFO     Training average positive_sample_loss at step 24800: 0.106686\n",
      "2024-02-29 01:25:52 INFO     Training average negative_sample_loss at step 24800: 0.094637\n",
      "2024-02-29 01:25:52 INFO     Training average loss at step 24800: 0.100661\n",
      "2024-02-29 01:27:46 INFO     Training average positive_sample_loss at step 24900: 0.108553\n",
      "2024-02-29 01:27:46 INFO     Training average negative_sample_loss at step 24900: 0.096296\n",
      "2024-02-29 01:27:46 INFO     Training average loss at step 24900: 0.102425\n",
      "2024-02-29 01:29:28 INFO     Training average positive_sample_loss at step 25000: 0.109193\n",
      "2024-02-29 01:29:28 INFO     Training average negative_sample_loss at step 25000: 0.096918\n",
      "2024-02-29 01:29:28 INFO     Training average loss at step 25000: 0.103056\n",
      "2024-02-29 01:31:09 INFO     Training average positive_sample_loss at step 25100: 0.110207\n",
      "2024-02-29 01:31:09 INFO     Training average negative_sample_loss at step 25100: 0.098133\n",
      "2024-02-29 01:31:09 INFO     Training average loss at step 25100: 0.104170\n",
      "2024-02-29 01:32:52 INFO     Training average positive_sample_loss at step 25200: 0.110324\n",
      "2024-02-29 01:32:52 INFO     Training average negative_sample_loss at step 25200: 0.097944\n",
      "2024-02-29 01:32:52 INFO     Training average loss at step 25200: 0.104134\n",
      "2024-02-29 01:34:38 INFO     Training average positive_sample_loss at step 25300: 0.110984\n",
      "2024-02-29 01:34:38 INFO     Training average negative_sample_loss at step 25300: 0.099230\n",
      "2024-02-29 01:34:38 INFO     Training average loss at step 25300: 0.105107\n",
      "2024-02-29 01:36:01 INFO     Training average positive_sample_loss at step 25400: 0.111035\n",
      "2024-02-29 01:36:01 INFO     Training average negative_sample_loss at step 25400: 0.099300\n",
      "2024-02-29 01:36:01 INFO     Training average loss at step 25400: 0.105168\n",
      "2024-02-29 01:37:43 INFO     Training average positive_sample_loss at step 25500: 0.109214\n",
      "2024-02-29 01:37:43 INFO     Training average negative_sample_loss at step 25500: 0.098902\n",
      "2024-02-29 01:37:43 INFO     Training average loss at step 25500: 0.104058\n",
      "2024-02-29 01:39:33 INFO     Training average positive_sample_loss at step 25600: 0.102604\n",
      "2024-02-29 01:39:33 INFO     Training average negative_sample_loss at step 25600: 0.091506\n",
      "2024-02-29 01:39:33 INFO     Training average loss at step 25600: 0.097055\n",
      "2024-02-29 01:41:18 INFO     Training average positive_sample_loss at step 25700: 0.105463\n",
      "2024-02-29 01:41:18 INFO     Training average negative_sample_loss at step 25700: 0.093164\n",
      "2024-02-29 01:41:18 INFO     Training average loss at step 25700: 0.099314\n",
      "2024-02-29 01:43:13 INFO     Training average positive_sample_loss at step 25800: 0.107410\n",
      "2024-02-29 01:43:13 INFO     Training average negative_sample_loss at step 25800: 0.095048\n",
      "2024-02-29 01:43:13 INFO     Training average loss at step 25800: 0.101229\n",
      "2024-02-29 01:45:01 INFO     Training average positive_sample_loss at step 25900: 0.108788\n",
      "2024-02-29 01:45:01 INFO     Training average negative_sample_loss at step 25900: 0.096672\n",
      "2024-02-29 01:45:01 INFO     Training average loss at step 25900: 0.102730\n",
      "2024-02-29 01:46:55 INFO     Training average positive_sample_loss at step 26000: 0.109078\n",
      "2024-02-29 01:46:55 INFO     Training average negative_sample_loss at step 26000: 0.096986\n",
      "2024-02-29 01:46:55 INFO     Training average loss at step 26000: 0.103032\n",
      "2024-02-29 01:48:42 INFO     Training average positive_sample_loss at step 26100: 0.109238\n",
      "2024-02-29 01:48:42 INFO     Training average negative_sample_loss at step 26100: 0.097281\n",
      "2024-02-29 01:48:42 INFO     Training average loss at step 26100: 0.103259\n",
      "2024-02-29 01:50:35 INFO     Training average positive_sample_loss at step 26200: 0.110701\n",
      "2024-02-29 01:50:35 INFO     Training average negative_sample_loss at step 26200: 0.098429\n",
      "2024-02-29 01:50:35 INFO     Training average loss at step 26200: 0.104565\n",
      "2024-02-29 01:52:23 INFO     Training average positive_sample_loss at step 26300: 0.110337\n",
      "2024-02-29 01:52:23 INFO     Training average negative_sample_loss at step 26300: 0.098724\n",
      "2024-02-29 01:52:23 INFO     Training average loss at step 26300: 0.104530\n",
      "2024-02-29 01:54:15 INFO     Training average positive_sample_loss at step 26400: 0.110828\n",
      "2024-02-29 01:54:15 INFO     Training average negative_sample_loss at step 26400: 0.099024\n",
      "2024-02-29 01:54:15 INFO     Training average loss at step 26400: 0.104926\n",
      "2024-02-29 01:56:18 INFO     Training average positive_sample_loss at step 26500: 0.103471\n",
      "2024-02-29 01:56:18 INFO     Training average negative_sample_loss at step 26500: 0.094484\n",
      "2024-02-29 01:56:18 INFO     Training average loss at step 26500: 0.098978\n",
      "2024-02-29 01:58:10 INFO     Training average positive_sample_loss at step 26600: 0.104410\n",
      "2024-02-29 01:58:10 INFO     Training average negative_sample_loss at step 26600: 0.092197\n",
      "2024-02-29 01:58:10 INFO     Training average loss at step 26600: 0.098303\n",
      "2024-02-29 01:59:58 INFO     Training average positive_sample_loss at step 26700: 0.105985\n",
      "2024-02-29 01:59:58 INFO     Training average negative_sample_loss at step 26700: 0.093595\n",
      "2024-02-29 01:59:58 INFO     Training average loss at step 26700: 0.099790\n",
      "2024-02-29 02:01:40 INFO     Training average positive_sample_loss at step 26800: 0.106938\n",
      "2024-02-29 02:01:40 INFO     Training average negative_sample_loss at step 26800: 0.095061\n",
      "2024-02-29 02:01:40 INFO     Training average loss at step 26800: 0.100999\n",
      "2024-02-29 02:03:41 INFO     Training average positive_sample_loss at step 26900: 0.108437\n",
      "2024-02-29 02:03:41 INFO     Training average negative_sample_loss at step 26900: 0.096116\n",
      "2024-02-29 02:03:41 INFO     Training average loss at step 26900: 0.102277\n",
      "2024-02-29 02:05:33 INFO     Training average positive_sample_loss at step 27000: 0.108979\n",
      "2024-02-29 02:05:33 INFO     Training average negative_sample_loss at step 27000: 0.096915\n",
      "2024-02-29 02:05:33 INFO     Training average loss at step 27000: 0.102947\n",
      "2024-02-29 02:06:58 INFO     Training average positive_sample_loss at step 27100: 0.109539\n",
      "2024-02-29 02:06:58 INFO     Training average negative_sample_loss at step 27100: 0.097388\n",
      "2024-02-29 02:06:58 INFO     Training average loss at step 27100: 0.103463\n",
      "2024-02-29 02:08:41 INFO     Training average positive_sample_loss at step 27200: 0.109856\n",
      "2024-02-29 02:08:41 INFO     Training average negative_sample_loss at step 27200: 0.097918\n",
      "2024-02-29 02:08:41 INFO     Training average loss at step 27200: 0.103887\n",
      "2024-02-29 02:10:25 INFO     Training average positive_sample_loss at step 27300: 0.109761\n",
      "2024-02-29 02:10:25 INFO     Training average negative_sample_loss at step 27300: 0.097731\n",
      "2024-02-29 02:10:25 INFO     Training average loss at step 27300: 0.103746\n",
      "2024-02-29 02:12:15 INFO     Training average positive_sample_loss at step 27400: 0.106465\n",
      "2024-02-29 02:12:15 INFO     Training average negative_sample_loss at step 27400: 0.096977\n",
      "2024-02-29 02:12:15 INFO     Training average loss at step 27400: 0.101721\n",
      "2024-02-29 02:14:15 INFO     Training average positive_sample_loss at step 27500: 0.102027\n",
      "2024-02-29 02:14:15 INFO     Training average negative_sample_loss at step 27500: 0.090452\n",
      "2024-02-29 02:14:15 INFO     Training average loss at step 27500: 0.096240\n",
      "2024-02-29 02:15:59 INFO     Training average positive_sample_loss at step 27600: 0.104421\n",
      "2024-02-29 02:15:59 INFO     Training average negative_sample_loss at step 27600: 0.092396\n",
      "2024-02-29 02:15:59 INFO     Training average loss at step 27600: 0.098409\n",
      "2024-02-29 02:17:56 INFO     Training average positive_sample_loss at step 27700: 0.106519\n",
      "2024-02-29 02:17:56 INFO     Training average negative_sample_loss at step 27700: 0.093985\n",
      "2024-02-29 02:17:56 INFO     Training average loss at step 27700: 0.100252\n",
      "2024-02-29 02:20:15 INFO     Training average positive_sample_loss at step 27800: 0.107609\n",
      "2024-02-29 02:20:15 INFO     Training average negative_sample_loss at step 27800: 0.095262\n",
      "2024-02-29 02:20:15 INFO     Training average loss at step 27800: 0.101436\n",
      "2024-02-29 02:22:14 INFO     Training average positive_sample_loss at step 27900: 0.108071\n",
      "2024-02-29 02:22:14 INFO     Training average negative_sample_loss at step 27900: 0.096020\n",
      "2024-02-29 02:22:14 INFO     Training average loss at step 27900: 0.102045\n",
      "2024-02-29 02:24:17 INFO     Training average positive_sample_loss at step 28000: 0.109071\n",
      "2024-02-29 02:24:17 INFO     Training average negative_sample_loss at step 28000: 0.096898\n",
      "2024-02-29 02:24:17 INFO     Training average loss at step 28000: 0.102985\n",
      "2024-02-29 02:25:56 INFO     Training average positive_sample_loss at step 28100: 0.109546\n",
      "2024-02-29 02:25:56 INFO     Training average negative_sample_loss at step 28100: 0.097380\n",
      "2024-02-29 02:25:56 INFO     Training average loss at step 28100: 0.103463\n",
      "2024-02-29 02:27:38 INFO     Training average positive_sample_loss at step 28200: 0.109242\n",
      "2024-02-29 02:27:38 INFO     Training average negative_sample_loss at step 28200: 0.097351\n",
      "2024-02-29 02:27:38 INFO     Training average loss at step 28200: 0.103297\n",
      "2024-02-29 02:29:36 INFO     Training average positive_sample_loss at step 28300: 0.109455\n",
      "2024-02-29 02:29:36 INFO     Training average negative_sample_loss at step 28300: 0.097497\n",
      "2024-02-29 02:29:36 INFO     Training average loss at step 28300: 0.103476\n",
      "2024-02-29 02:31:52 INFO     Training average positive_sample_loss at step 28400: 0.101090\n",
      "2024-02-29 02:31:52 INFO     Training average negative_sample_loss at step 28400: 0.091796\n",
      "2024-02-29 02:31:52 INFO     Training average loss at step 28400: 0.096443\n",
      "2024-02-29 02:33:43 INFO     Training average positive_sample_loss at step 28500: 0.103723\n",
      "2024-02-29 02:33:43 INFO     Training average negative_sample_loss at step 28500: 0.091758\n",
      "2024-02-29 02:33:43 INFO     Training average loss at step 28500: 0.097740\n",
      "2024-02-29 02:35:24 INFO     Training average positive_sample_loss at step 28600: 0.105430\n",
      "2024-02-29 02:35:24 INFO     Training average negative_sample_loss at step 28600: 0.093026\n",
      "2024-02-29 02:35:24 INFO     Training average loss at step 28600: 0.099228\n",
      "2024-02-29 02:36:57 INFO     Training average positive_sample_loss at step 28700: 0.106116\n",
      "2024-02-29 02:36:57 INFO     Training average negative_sample_loss at step 28700: 0.093911\n",
      "2024-02-29 02:36:57 INFO     Training average loss at step 28700: 0.100014\n",
      "2024-02-29 02:38:46 INFO     Training average positive_sample_loss at step 28800: 0.108076\n",
      "2024-02-29 02:38:46 INFO     Training average negative_sample_loss at step 28800: 0.095844\n",
      "2024-02-29 02:38:46 INFO     Training average loss at step 28800: 0.101960\n",
      "2024-02-29 02:40:44 INFO     Training average positive_sample_loss at step 28900: 0.108120\n",
      "2024-02-29 02:40:44 INFO     Training average negative_sample_loss at step 28900: 0.096062\n",
      "2024-02-29 02:40:44 INFO     Training average loss at step 28900: 0.102091\n",
      "2024-02-29 02:42:45 INFO     Training average positive_sample_loss at step 29000: 0.108110\n",
      "2024-02-29 02:42:45 INFO     Training average negative_sample_loss at step 29000: 0.096123\n",
      "2024-02-29 02:42:45 INFO     Training average loss at step 29000: 0.102117\n",
      "2024-02-29 02:44:36 INFO     Training average positive_sample_loss at step 29100: 0.108597\n",
      "2024-02-29 02:44:36 INFO     Training average negative_sample_loss at step 29100: 0.096434\n",
      "2024-02-29 02:44:36 INFO     Training average loss at step 29100: 0.102516\n",
      "2024-02-29 02:46:15 INFO     Training average positive_sample_loss at step 29200: 0.109117\n",
      "2024-02-29 02:46:15 INFO     Training average negative_sample_loss at step 29200: 0.096959\n",
      "2024-02-29 02:46:15 INFO     Training average loss at step 29200: 0.103038\n",
      "2024-02-29 02:48:20 INFO     Training average positive_sample_loss at step 29300: 0.105157\n",
      "2024-02-29 02:48:20 INFO     Training average negative_sample_loss at step 29300: 0.095599\n",
      "2024-02-29 02:48:20 INFO     Training average loss at step 29300: 0.100378\n",
      "2024-02-29 02:50:28 INFO     Training average positive_sample_loss at step 29400: 0.101893\n",
      "2024-02-29 02:50:28 INFO     Training average negative_sample_loss at step 29400: 0.090397\n",
      "2024-02-29 02:50:28 INFO     Training average loss at step 29400: 0.096145\n",
      "2024-02-29 02:52:27 INFO     Training average positive_sample_loss at step 29500: 0.104118\n",
      "2024-02-29 02:52:27 INFO     Training average negative_sample_loss at step 29500: 0.091754\n",
      "2024-02-29 02:52:27 INFO     Training average loss at step 29500: 0.097936\n",
      "2024-02-29 02:54:22 INFO     Training average positive_sample_loss at step 29600: 0.105225\n",
      "2024-02-29 02:54:22 INFO     Training average negative_sample_loss at step 29600: 0.093032\n",
      "2024-02-29 02:54:22 INFO     Training average loss at step 29600: 0.099129\n",
      "2024-02-29 02:56:14 INFO     Training average positive_sample_loss at step 29700: 0.106299\n",
      "2024-02-29 02:56:14 INFO     Training average negative_sample_loss at step 29700: 0.094220\n",
      "2024-02-29 02:56:14 INFO     Training average loss at step 29700: 0.100260\n",
      "2024-02-29 02:58:20 INFO     Training average positive_sample_loss at step 29800: 0.107340\n",
      "2024-02-29 02:58:20 INFO     Training average negative_sample_loss at step 29800: 0.095062\n",
      "2024-02-29 02:58:20 INFO     Training average loss at step 29800: 0.101201\n",
      "2024-02-29 03:00:15 INFO     Training average positive_sample_loss at step 29900: 0.108300\n",
      "2024-02-29 03:00:15 INFO     Training average negative_sample_loss at step 29900: 0.095938\n",
      "2024-02-29 03:00:15 INFO     Training average loss at step 29900: 0.102119\n",
      "2024-02-29 03:02:15 INFO     Training average positive_sample_loss at step 30000: 0.108211\n",
      "2024-02-29 03:02:15 INFO     Training average negative_sample_loss at step 30000: 0.096315\n",
      "2024-02-29 03:02:15 INFO     Training average loss at step 30000: 0.102263\n",
      "2024-02-29 03:02:15 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 03:02:16 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-29 03:02:46 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-29 03:03:22 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-29 03:03:51 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-29 03:04:22 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-29 03:05:00 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-29 03:05:32 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-29 03:05:41 INFO     Valid MRR at step 30000: 0.411096\n",
      "2024-02-29 03:05:41 INFO     Valid MR at step 30000: 333.536900\n",
      "2024-02-29 03:05:41 INFO     Valid HITS@1 at step 30000: 0.331110\n",
      "2024-02-29 03:05:41 INFO     Valid HITS@3 at step 30000: 0.431200\n",
      "2024-02-29 03:05:41 INFO     Valid HITS@10 at step 30000: 0.588360\n",
      "2024-02-29 03:07:28 INFO     Training average positive_sample_loss at step 30100: 0.108342\n",
      "2024-02-29 03:07:28 INFO     Training average negative_sample_loss at step 30100: 0.096181\n",
      "2024-02-29 03:07:28 INFO     Training average loss at step 30100: 0.102262\n",
      "2024-02-29 03:09:34 INFO     Training average positive_sample_loss at step 30200: 0.108286\n",
      "2024-02-29 03:09:34 INFO     Training average negative_sample_loss at step 30200: 0.096504\n",
      "2024-02-29 03:09:34 INFO     Training average loss at step 30200: 0.102395\n",
      "2024-02-29 03:11:37 INFO     Training average positive_sample_loss at step 30300: 0.099900\n",
      "2024-02-29 03:11:37 INFO     Training average negative_sample_loss at step 30300: 0.090447\n",
      "2024-02-29 03:11:37 INFO     Training average loss at step 30300: 0.095173\n",
      "2024-02-29 03:13:39 INFO     Training average positive_sample_loss at step 30400: 0.102892\n",
      "2024-02-29 03:13:39 INFO     Training average negative_sample_loss at step 30400: 0.091112\n",
      "2024-02-29 03:13:39 INFO     Training average loss at step 30400: 0.097002\n",
      "2024-02-29 03:15:31 INFO     Training average positive_sample_loss at step 30500: 0.105075\n",
      "2024-02-29 03:15:31 INFO     Training average negative_sample_loss at step 30500: 0.092899\n",
      "2024-02-29 03:15:31 INFO     Training average loss at step 30500: 0.098987\n",
      "2024-02-29 03:17:17 INFO     Training average positive_sample_loss at step 30600: 0.105335\n",
      "2024-02-29 03:17:17 INFO     Training average negative_sample_loss at step 30600: 0.093117\n",
      "2024-02-29 03:17:17 INFO     Training average loss at step 30600: 0.099226\n",
      "2024-02-29 03:18:59 INFO     Training average positive_sample_loss at step 30700: 0.106553\n",
      "2024-02-29 03:18:59 INFO     Training average negative_sample_loss at step 30700: 0.094480\n",
      "2024-02-29 03:18:59 INFO     Training average loss at step 30700: 0.100517\n",
      "2024-02-29 03:20:37 INFO     Training average positive_sample_loss at step 30800: 0.107360\n",
      "2024-02-29 03:20:37 INFO     Training average negative_sample_loss at step 30800: 0.095100\n",
      "2024-02-29 03:20:37 INFO     Training average loss at step 30800: 0.101230\n",
      "2024-02-29 03:22:31 INFO     Training average positive_sample_loss at step 30900: 0.107844\n",
      "2024-02-29 03:22:31 INFO     Training average negative_sample_loss at step 30900: 0.095717\n",
      "2024-02-29 03:22:31 INFO     Training average loss at step 30900: 0.101780\n",
      "2024-02-29 03:24:29 INFO     Training average positive_sample_loss at step 31000: 0.108629\n",
      "2024-02-29 03:24:29 INFO     Training average negative_sample_loss at step 31000: 0.096306\n",
      "2024-02-29 03:24:29 INFO     Training average loss at step 31000: 0.102467\n",
      "2024-02-29 03:26:17 INFO     Training average positive_sample_loss at step 31100: 0.107441\n",
      "2024-02-29 03:26:17 INFO     Training average negative_sample_loss at step 31100: 0.095876\n",
      "2024-02-29 03:26:17 INFO     Training average loss at step 31100: 0.101658\n",
      "2024-02-29 03:28:05 INFO     Training average positive_sample_loss at step 31200: 0.102856\n",
      "2024-02-29 03:28:05 INFO     Training average negative_sample_loss at step 31200: 0.093336\n",
      "2024-02-29 03:28:05 INFO     Training average loss at step 31200: 0.098096\n",
      "2024-02-29 03:29:44 INFO     Training average positive_sample_loss at step 31300: 0.101403\n",
      "2024-02-29 03:29:44 INFO     Training average negative_sample_loss at step 31300: 0.089504\n",
      "2024-02-29 03:29:44 INFO     Training average loss at step 31300: 0.095454\n",
      "2024-02-29 03:31:31 INFO     Training average positive_sample_loss at step 31400: 0.103666\n",
      "2024-02-29 03:31:31 INFO     Training average negative_sample_loss at step 31400: 0.091102\n",
      "2024-02-29 03:31:31 INFO     Training average loss at step 31400: 0.097384\n",
      "2024-02-29 03:33:33 INFO     Training average positive_sample_loss at step 31500: 0.105333\n",
      "2024-02-29 03:33:33 INFO     Training average negative_sample_loss at step 31500: 0.093173\n",
      "2024-02-29 03:33:33 INFO     Training average loss at step 31500: 0.099253\n",
      "2024-02-29 03:35:15 INFO     Training average positive_sample_loss at step 31600: 0.105988\n",
      "2024-02-29 03:35:15 INFO     Training average negative_sample_loss at step 31600: 0.094100\n",
      "2024-02-29 03:35:15 INFO     Training average loss at step 31600: 0.100044\n",
      "2024-02-29 03:37:15 INFO     Training average positive_sample_loss at step 31700: 0.106048\n",
      "2024-02-29 03:37:15 INFO     Training average negative_sample_loss at step 31700: 0.093655\n",
      "2024-02-29 03:37:15 INFO     Training average loss at step 31700: 0.099852\n",
      "2024-02-29 03:39:13 INFO     Training average positive_sample_loss at step 31800: 0.107620\n",
      "2024-02-29 03:39:13 INFO     Training average negative_sample_loss at step 31800: 0.095251\n",
      "2024-02-29 03:39:13 INFO     Training average loss at step 31800: 0.101436\n",
      "2024-02-29 03:41:01 INFO     Training average positive_sample_loss at step 31900: 0.107367\n",
      "2024-02-29 03:41:01 INFO     Training average negative_sample_loss at step 31900: 0.095226\n",
      "2024-02-29 03:41:01 INFO     Training average loss at step 31900: 0.101296\n",
      "2024-02-29 03:42:27 INFO     Training average positive_sample_loss at step 32000: 0.107589\n",
      "2024-02-29 03:42:27 INFO     Training average negative_sample_loss at step 32000: 0.095816\n",
      "2024-02-29 03:42:27 INFO     Training average loss at step 32000: 0.101702\n",
      "2024-02-29 03:44:38 INFO     Training average positive_sample_loss at step 32100: 0.106569\n",
      "2024-02-29 03:44:38 INFO     Training average negative_sample_loss at step 32100: 0.095332\n",
      "2024-02-29 03:44:38 INFO     Training average loss at step 32100: 0.100950\n",
      "2024-02-29 03:46:25 INFO     Training average positive_sample_loss at step 32200: 0.099354\n",
      "2024-02-29 03:46:25 INFO     Training average negative_sample_loss at step 32200: 0.089314\n",
      "2024-02-29 03:46:25 INFO     Training average loss at step 32200: 0.094334\n",
      "2024-02-29 03:48:03 INFO     Training average positive_sample_loss at step 32300: 0.102231\n",
      "2024-02-29 03:48:03 INFO     Training average negative_sample_loss at step 32300: 0.089857\n",
      "2024-02-29 03:48:03 INFO     Training average loss at step 32300: 0.096044\n",
      "2024-02-29 03:49:45 INFO     Training average positive_sample_loss at step 32400: 0.103684\n",
      "2024-02-29 03:49:45 INFO     Training average negative_sample_loss at step 32400: 0.091565\n",
      "2024-02-29 03:49:45 INFO     Training average loss at step 32400: 0.097625\n",
      "2024-02-29 03:51:39 INFO     Training average positive_sample_loss at step 32500: 0.105530\n",
      "2024-02-29 03:51:39 INFO     Training average negative_sample_loss at step 32500: 0.093334\n",
      "2024-02-29 03:51:39 INFO     Training average loss at step 32500: 0.099432\n",
      "2024-02-29 03:53:31 INFO     Training average positive_sample_loss at step 32600: 0.105847\n",
      "2024-02-29 03:53:31 INFO     Training average negative_sample_loss at step 32600: 0.093439\n",
      "2024-02-29 03:53:31 INFO     Training average loss at step 32600: 0.099643\n",
      "2024-02-29 03:55:11 INFO     Training average positive_sample_loss at step 32700: 0.106156\n",
      "2024-02-29 03:55:11 INFO     Training average negative_sample_loss at step 32700: 0.094112\n",
      "2024-02-29 03:55:11 INFO     Training average loss at step 32700: 0.100134\n",
      "2024-02-29 03:56:40 INFO     Training average positive_sample_loss at step 32800: 0.106988\n",
      "2024-02-29 03:56:40 INFO     Training average negative_sample_loss at step 32800: 0.094626\n",
      "2024-02-29 03:56:40 INFO     Training average loss at step 32800: 0.100807\n",
      "2024-02-29 03:58:11 INFO     Training average positive_sample_loss at step 32900: 0.106745\n",
      "2024-02-29 03:58:11 INFO     Training average negative_sample_loss at step 32900: 0.094760\n",
      "2024-02-29 03:58:11 INFO     Training average loss at step 32900: 0.100752\n",
      "2024-02-29 03:59:55 INFO     Training average positive_sample_loss at step 33000: 0.107590\n",
      "2024-02-29 03:59:55 INFO     Training average negative_sample_loss at step 33000: 0.095472\n",
      "2024-02-29 03:59:55 INFO     Training average loss at step 33000: 0.101531\n",
      "2024-02-29 04:01:49 INFO     Training average positive_sample_loss at step 33100: 0.101128\n",
      "2024-02-29 04:01:49 INFO     Training average negative_sample_loss at step 33100: 0.091872\n",
      "2024-02-29 04:01:49 INFO     Training average loss at step 33100: 0.096500\n",
      "2024-02-29 04:03:43 INFO     Training average positive_sample_loss at step 33200: 0.101178\n",
      "2024-02-29 04:03:43 INFO     Training average negative_sample_loss at step 33200: 0.089018\n",
      "2024-02-29 04:03:43 INFO     Training average loss at step 33200: 0.095098\n",
      "2024-02-29 04:05:37 INFO     Training average positive_sample_loss at step 33300: 0.102732\n",
      "2024-02-29 04:05:37 INFO     Training average negative_sample_loss at step 33300: 0.090489\n",
      "2024-02-29 04:05:37 INFO     Training average loss at step 33300: 0.096610\n",
      "2024-02-29 04:07:45 INFO     Training average positive_sample_loss at step 33400: 0.104008\n",
      "2024-02-29 04:07:45 INFO     Training average negative_sample_loss at step 33400: 0.091462\n",
      "2024-02-29 04:07:45 INFO     Training average loss at step 33400: 0.097735\n",
      "2024-02-29 04:09:28 INFO     Training average positive_sample_loss at step 33500: 0.105025\n",
      "2024-02-29 04:09:28 INFO     Training average negative_sample_loss at step 33500: 0.093150\n",
      "2024-02-29 04:09:28 INFO     Training average loss at step 33500: 0.099088\n",
      "2024-02-29 04:11:18 INFO     Training average positive_sample_loss at step 33600: 0.105585\n",
      "2024-02-29 04:11:18 INFO     Training average negative_sample_loss at step 33600: 0.093318\n",
      "2024-02-29 04:11:18 INFO     Training average loss at step 33600: 0.099451\n",
      "2024-02-29 04:13:27 INFO     Training average positive_sample_loss at step 33700: 0.106773\n",
      "2024-02-29 04:13:27 INFO     Training average negative_sample_loss at step 33700: 0.094632\n",
      "2024-02-29 04:13:27 INFO     Training average loss at step 33700: 0.100702\n",
      "2024-02-29 04:15:10 INFO     Training average positive_sample_loss at step 33800: 0.106518\n",
      "2024-02-29 04:15:10 INFO     Training average negative_sample_loss at step 33800: 0.094450\n",
      "2024-02-29 04:15:10 INFO     Training average loss at step 33800: 0.100484\n",
      "2024-02-29 04:17:24 INFO     Training average positive_sample_loss at step 33900: 0.106783\n",
      "2024-02-29 04:17:24 INFO     Training average negative_sample_loss at step 33900: 0.094906\n",
      "2024-02-29 04:17:24 INFO     Training average loss at step 33900: 0.100844\n",
      "2024-02-29 04:19:24 INFO     Training average positive_sample_loss at step 34000: 0.105116\n",
      "2024-02-29 04:19:24 INFO     Training average negative_sample_loss at step 34000: 0.095183\n",
      "2024-02-29 04:19:24 INFO     Training average loss at step 34000: 0.100149\n",
      "2024-02-29 04:21:15 INFO     Training average positive_sample_loss at step 34100: 0.099296\n",
      "2024-02-29 04:21:15 INFO     Training average negative_sample_loss at step 34100: 0.087963\n",
      "2024-02-29 04:21:15 INFO     Training average loss at step 34100: 0.093629\n",
      "2024-02-29 04:23:04 INFO     Training average positive_sample_loss at step 34200: 0.101997\n",
      "2024-02-29 04:23:04 INFO     Training average negative_sample_loss at step 34200: 0.089258\n",
      "2024-02-29 04:23:04 INFO     Training average loss at step 34200: 0.095628\n",
      "2024-02-29 04:24:48 INFO     Training average positive_sample_loss at step 34300: 0.103566\n",
      "2024-02-29 04:24:48 INFO     Training average negative_sample_loss at step 34300: 0.091287\n",
      "2024-02-29 04:24:48 INFO     Training average loss at step 34300: 0.097427\n",
      "2024-02-29 04:26:34 INFO     Training average positive_sample_loss at step 34400: 0.104579\n",
      "2024-02-29 04:26:34 INFO     Training average negative_sample_loss at step 34400: 0.092495\n",
      "2024-02-29 04:26:34 INFO     Training average loss at step 34400: 0.098537\n",
      "2024-02-29 04:28:35 INFO     Training average positive_sample_loss at step 34500: 0.105630\n",
      "2024-02-29 04:28:35 INFO     Training average negative_sample_loss at step 34500: 0.092865\n",
      "2024-02-29 04:28:35 INFO     Training average loss at step 34500: 0.099247\n",
      "2024-02-29 04:30:30 INFO     Training average positive_sample_loss at step 34600: 0.105713\n",
      "2024-02-29 04:30:30 INFO     Training average negative_sample_loss at step 34600: 0.093947\n",
      "2024-02-29 04:30:30 INFO     Training average loss at step 34600: 0.099830\n",
      "2024-02-29 04:32:43 INFO     Training average positive_sample_loss at step 34700: 0.106393\n",
      "2024-02-29 04:32:43 INFO     Training average negative_sample_loss at step 34700: 0.093972\n",
      "2024-02-29 04:32:43 INFO     Training average loss at step 34700: 0.100183\n",
      "2024-02-29 04:34:43 INFO     Training average positive_sample_loss at step 34800: 0.106660\n",
      "2024-02-29 04:34:43 INFO     Training average negative_sample_loss at step 34800: 0.094473\n",
      "2024-02-29 04:34:43 INFO     Training average loss at step 34800: 0.100567\n",
      "2024-02-29 04:36:31 INFO     Training average positive_sample_loss at step 34900: 0.105996\n",
      "2024-02-29 04:36:31 INFO     Training average negative_sample_loss at step 34900: 0.093976\n",
      "2024-02-29 04:36:31 INFO     Training average loss at step 34900: 0.099986\n",
      "2024-02-29 04:38:36 INFO     Training average positive_sample_loss at step 35000: 0.099356\n",
      "2024-02-29 04:38:36 INFO     Training average negative_sample_loss at step 35000: 0.090103\n",
      "2024-02-29 04:38:36 INFO     Training average loss at step 35000: 0.094730\n",
      "2024-02-29 04:40:38 INFO     Training average positive_sample_loss at step 35100: 0.101067\n",
      "2024-02-29 04:40:38 INFO     Training average negative_sample_loss at step 35100: 0.088559\n",
      "2024-02-29 04:40:38 INFO     Training average loss at step 35100: 0.094813\n",
      "2024-02-29 04:42:46 INFO     Training average positive_sample_loss at step 35200: 0.102185\n",
      "2024-02-29 04:42:46 INFO     Training average negative_sample_loss at step 35200: 0.090187\n",
      "2024-02-29 04:42:46 INFO     Training average loss at step 35200: 0.096186\n",
      "2024-02-29 04:44:37 INFO     Training average positive_sample_loss at step 35300: 0.104091\n",
      "2024-02-29 04:44:37 INFO     Training average negative_sample_loss at step 35300: 0.091618\n",
      "2024-02-29 04:44:37 INFO     Training average loss at step 35300: 0.097855\n",
      "2024-02-29 04:46:18 INFO     Training average positive_sample_loss at step 35400: 0.104865\n",
      "2024-02-29 04:46:18 INFO     Training average negative_sample_loss at step 35400: 0.092901\n",
      "2024-02-29 04:46:18 INFO     Training average loss at step 35400: 0.098883\n",
      "2024-02-29 04:47:57 INFO     Training average positive_sample_loss at step 35500: 0.105177\n",
      "2024-02-29 04:47:57 INFO     Training average negative_sample_loss at step 35500: 0.092776\n",
      "2024-02-29 04:47:57 INFO     Training average loss at step 35500: 0.098977\n",
      "2024-02-29 04:49:45 INFO     Training average positive_sample_loss at step 35600: 0.105612\n",
      "2024-02-29 04:49:45 INFO     Training average negative_sample_loss at step 35600: 0.093705\n",
      "2024-02-29 04:49:45 INFO     Training average loss at step 35600: 0.099659\n",
      "2024-02-29 04:51:28 INFO     Training average positive_sample_loss at step 35700: 0.105915\n",
      "2024-02-29 04:51:28 INFO     Training average negative_sample_loss at step 35700: 0.094069\n",
      "2024-02-29 04:51:28 INFO     Training average loss at step 35700: 0.099992\n",
      "2024-02-29 04:53:04 INFO     Training average positive_sample_loss at step 35800: 0.106417\n",
      "2024-02-29 04:53:04 INFO     Training average negative_sample_loss at step 35800: 0.094425\n",
      "2024-02-29 04:53:04 INFO     Training average loss at step 35800: 0.100421\n",
      "2024-02-29 04:55:08 INFO     Training average positive_sample_loss at step 35900: 0.102587\n",
      "2024-02-29 04:55:08 INFO     Training average negative_sample_loss at step 35900: 0.092823\n",
      "2024-02-29 04:55:08 INFO     Training average loss at step 35900: 0.097705\n",
      "2024-02-29 04:56:42 INFO     Training average positive_sample_loss at step 36000: 0.099103\n",
      "2024-02-29 04:56:42 INFO     Training average negative_sample_loss at step 36000: 0.087212\n",
      "2024-02-29 04:56:42 INFO     Training average loss at step 36000: 0.093158\n",
      "2024-02-29 04:58:34 INFO     Training average positive_sample_loss at step 36100: 0.101722\n",
      "2024-02-29 04:58:34 INFO     Training average negative_sample_loss at step 36100: 0.089419\n",
      "2024-02-29 04:58:34 INFO     Training average loss at step 36100: 0.095571\n",
      "2024-02-29 05:00:14 INFO     Training average positive_sample_loss at step 36200: 0.103445\n",
      "2024-02-29 05:00:14 INFO     Training average negative_sample_loss at step 36200: 0.091185\n",
      "2024-02-29 05:00:14 INFO     Training average loss at step 36200: 0.097315\n",
      "2024-02-29 05:01:55 INFO     Training average positive_sample_loss at step 36300: 0.103962\n",
      "2024-02-29 05:01:55 INFO     Training average negative_sample_loss at step 36300: 0.091517\n",
      "2024-02-29 05:01:55 INFO     Training average loss at step 36300: 0.097739\n",
      "2024-02-29 05:03:53 INFO     Training average positive_sample_loss at step 36400: 0.104805\n",
      "2024-02-29 05:03:53 INFO     Training average negative_sample_loss at step 36400: 0.092528\n",
      "2024-02-29 05:03:53 INFO     Training average loss at step 36400: 0.098666\n",
      "2024-02-29 05:05:43 INFO     Training average positive_sample_loss at step 36500: 0.105809\n",
      "2024-02-29 05:05:43 INFO     Training average negative_sample_loss at step 36500: 0.093467\n",
      "2024-02-29 05:05:43 INFO     Training average loss at step 36500: 0.099638\n",
      "2024-02-29 05:07:41 INFO     Training average positive_sample_loss at step 36600: 0.105312\n",
      "2024-02-29 05:07:41 INFO     Training average negative_sample_loss at step 36600: 0.093014\n",
      "2024-02-29 05:07:41 INFO     Training average loss at step 36600: 0.099163\n",
      "2024-02-29 05:09:26 INFO     Training average positive_sample_loss at step 36700: 0.105708\n",
      "2024-02-29 05:09:26 INFO     Training average negative_sample_loss at step 36700: 0.094092\n",
      "2024-02-29 05:09:26 INFO     Training average loss at step 36700: 0.099900\n",
      "2024-02-29 05:11:16 INFO     Training average positive_sample_loss at step 36800: 0.106241\n",
      "2024-02-29 05:11:16 INFO     Training average negative_sample_loss at step 36800: 0.094069\n",
      "2024-02-29 05:11:16 INFO     Training average loss at step 36800: 0.100155\n",
      "2024-02-29 05:13:24 INFO     Training average positive_sample_loss at step 36900: 0.098102\n",
      "2024-02-29 05:13:24 INFO     Training average negative_sample_loss at step 36900: 0.088866\n",
      "2024-02-29 05:13:24 INFO     Training average loss at step 36900: 0.093484\n",
      "2024-02-29 05:15:03 INFO     Training average positive_sample_loss at step 37000: 0.100417\n",
      "2024-02-29 05:15:03 INFO     Training average negative_sample_loss at step 37000: 0.088305\n",
      "2024-02-29 05:15:03 INFO     Training average loss at step 37000: 0.094361\n",
      "2024-02-29 05:16:53 INFO     Training average positive_sample_loss at step 37100: 0.102414\n",
      "2024-02-29 05:16:53 INFO     Training average negative_sample_loss at step 37100: 0.089934\n",
      "2024-02-29 05:16:53 INFO     Training average loss at step 37100: 0.096174\n",
      "2024-02-29 05:18:27 INFO     Training average positive_sample_loss at step 37200: 0.103087\n",
      "2024-02-29 05:18:27 INFO     Training average negative_sample_loss at step 37200: 0.090906\n",
      "2024-02-29 05:18:27 INFO     Training average loss at step 37200: 0.096996\n",
      "2024-02-29 05:20:26 INFO     Training average positive_sample_loss at step 37300: 0.103932\n",
      "2024-02-29 05:20:26 INFO     Training average negative_sample_loss at step 37300: 0.091675\n",
      "2024-02-29 05:20:26 INFO     Training average loss at step 37300: 0.097803\n",
      "2024-02-29 05:22:30 INFO     Training average positive_sample_loss at step 37400: 0.104881\n",
      "2024-02-29 05:22:30 INFO     Training average negative_sample_loss at step 37400: 0.092476\n",
      "2024-02-29 05:22:30 INFO     Training average loss at step 37400: 0.098678\n",
      "2024-02-29 05:24:20 INFO     Training average positive_sample_loss at step 37500: 0.105108\n",
      "2024-02-29 05:24:20 INFO     Training average negative_sample_loss at step 37500: 0.093183\n",
      "2024-02-29 05:24:20 INFO     Training average loss at step 37500: 0.099145\n",
      "2024-02-29 05:26:07 INFO     Training average positive_sample_loss at step 37600: 0.105778\n",
      "2024-02-29 05:26:07 INFO     Training average negative_sample_loss at step 37600: 0.093420\n",
      "2024-02-29 05:26:07 INFO     Training average loss at step 37600: 0.099599\n",
      "2024-02-29 05:27:53 INFO     Training average positive_sample_loss at step 37700: 0.105567\n",
      "2024-02-29 05:27:53 INFO     Training average negative_sample_loss at step 37700: 0.093514\n",
      "2024-02-29 05:27:53 INFO     Training average loss at step 37700: 0.099541\n",
      "2024-02-29 05:29:52 INFO     Training average positive_sample_loss at step 37800: 0.101220\n",
      "2024-02-29 05:29:52 INFO     Training average negative_sample_loss at step 37800: 0.091807\n",
      "2024-02-29 05:29:52 INFO     Training average loss at step 37800: 0.096514\n",
      "2024-02-29 05:31:48 INFO     Training average positive_sample_loss at step 37900: 0.098941\n",
      "2024-02-29 05:31:48 INFO     Training average negative_sample_loss at step 37900: 0.086898\n",
      "2024-02-29 05:31:48 INFO     Training average loss at step 37900: 0.092920\n",
      "2024-02-29 05:33:49 INFO     Training average positive_sample_loss at step 38000: 0.101519\n",
      "2024-02-29 05:33:49 INFO     Training average negative_sample_loss at step 38000: 0.089072\n",
      "2024-02-29 05:33:49 INFO     Training average loss at step 38000: 0.095296\n",
      "2024-02-29 05:35:49 INFO     Training average positive_sample_loss at step 38100: 0.102669\n",
      "2024-02-29 05:35:49 INFO     Training average negative_sample_loss at step 38100: 0.090443\n",
      "2024-02-29 05:35:49 INFO     Training average loss at step 38100: 0.096556\n",
      "2024-02-29 05:37:38 INFO     Training average positive_sample_loss at step 38200: 0.103721\n",
      "2024-02-29 05:37:38 INFO     Training average negative_sample_loss at step 38200: 0.091073\n",
      "2024-02-29 05:37:38 INFO     Training average loss at step 38200: 0.097397\n",
      "2024-02-29 05:39:20 INFO     Training average positive_sample_loss at step 38300: 0.103779\n",
      "2024-02-29 05:39:20 INFO     Training average negative_sample_loss at step 38300: 0.091898\n",
      "2024-02-29 05:39:20 INFO     Training average loss at step 38300: 0.097839\n",
      "2024-02-29 05:41:07 INFO     Training average positive_sample_loss at step 38400: 0.104853\n",
      "2024-02-29 05:41:07 INFO     Training average negative_sample_loss at step 38400: 0.092707\n",
      "2024-02-29 05:41:07 INFO     Training average loss at step 38400: 0.098780\n",
      "2024-02-29 05:42:56 INFO     Training average positive_sample_loss at step 38500: 0.105388\n",
      "2024-02-29 05:42:56 INFO     Training average negative_sample_loss at step 38500: 0.093219\n",
      "2024-02-29 05:42:56 INFO     Training average loss at step 38500: 0.099303\n",
      "2024-02-29 05:44:56 INFO     Training average positive_sample_loss at step 38600: 0.105230\n",
      "2024-02-29 05:44:56 INFO     Training average negative_sample_loss at step 38600: 0.093222\n",
      "2024-02-29 05:44:56 INFO     Training average loss at step 38600: 0.099226\n",
      "2024-02-29 05:46:57 INFO     Training average positive_sample_loss at step 38700: 0.105400\n",
      "2024-02-29 05:46:57 INFO     Training average negative_sample_loss at step 38700: 0.093633\n",
      "2024-02-29 05:46:57 INFO     Training average loss at step 38700: 0.099516\n",
      "2024-02-29 05:49:00 INFO     Training average positive_sample_loss at step 38800: 0.097057\n",
      "2024-02-29 05:49:00 INFO     Training average negative_sample_loss at step 38800: 0.087572\n",
      "2024-02-29 05:49:00 INFO     Training average loss at step 38800: 0.092315\n",
      "2024-02-29 05:50:43 INFO     Training average positive_sample_loss at step 38900: 0.100475\n",
      "2024-02-29 05:50:43 INFO     Training average negative_sample_loss at step 38900: 0.088141\n",
      "2024-02-29 05:50:43 INFO     Training average loss at step 38900: 0.094308\n",
      "2024-02-29 05:52:35 INFO     Training average positive_sample_loss at step 39000: 0.102138\n",
      "2024-02-29 05:52:35 INFO     Training average negative_sample_loss at step 39000: 0.089834\n",
      "2024-02-29 05:52:35 INFO     Training average loss at step 39000: 0.095986\n",
      "2024-02-29 05:54:13 INFO     Training average positive_sample_loss at step 39100: 0.102985\n",
      "2024-02-29 05:54:13 INFO     Training average negative_sample_loss at step 39100: 0.090464\n",
      "2024-02-29 05:54:13 INFO     Training average loss at step 39100: 0.096725\n",
      "2024-02-29 05:55:46 INFO     Training average positive_sample_loss at step 39200: 0.103269\n",
      "2024-02-29 05:55:46 INFO     Training average negative_sample_loss at step 39200: 0.091464\n",
      "2024-02-29 05:55:46 INFO     Training average loss at step 39200: 0.097366\n",
      "2024-02-29 05:57:26 INFO     Training average positive_sample_loss at step 39300: 0.104789\n",
      "2024-02-29 05:57:26 INFO     Training average negative_sample_loss at step 39300: 0.092093\n",
      "2024-02-29 05:57:26 INFO     Training average loss at step 39300: 0.098441\n",
      "2024-02-29 05:59:12 INFO     Training average positive_sample_loss at step 39400: 0.104783\n",
      "2024-02-29 05:59:12 INFO     Training average negative_sample_loss at step 39400: 0.092759\n",
      "2024-02-29 05:59:12 INFO     Training average loss at step 39400: 0.098771\n",
      "2024-02-29 06:01:20 INFO     Training average positive_sample_loss at step 39500: 0.105021\n",
      "2024-02-29 06:01:20 INFO     Training average negative_sample_loss at step 39500: 0.092856\n",
      "2024-02-29 06:01:20 INFO     Training average loss at step 39500: 0.098939\n",
      "2024-02-29 06:02:57 INFO     Training average positive_sample_loss at step 39600: 0.105058\n",
      "2024-02-29 06:02:57 INFO     Training average negative_sample_loss at step 39600: 0.093075\n",
      "2024-02-29 06:02:57 INFO     Training average loss at step 39600: 0.099066\n",
      "2024-02-29 06:04:56 INFO     Training average positive_sample_loss at step 39700: 0.099224\n",
      "2024-02-29 06:04:56 INFO     Training average negative_sample_loss at step 39700: 0.089566\n",
      "2024-02-29 06:04:56 INFO     Training average loss at step 39700: 0.094395\n",
      "2024-02-29 06:06:47 INFO     Training average positive_sample_loss at step 39800: 0.099445\n",
      "2024-02-29 06:06:47 INFO     Training average negative_sample_loss at step 39800: 0.087110\n",
      "2024-02-29 06:06:47 INFO     Training average loss at step 39800: 0.093278\n",
      "2024-02-29 06:08:39 INFO     Training average positive_sample_loss at step 39900: 0.100559\n",
      "2024-02-29 06:08:39 INFO     Training average negative_sample_loss at step 39900: 0.088609\n",
      "2024-02-29 06:08:39 INFO     Training average loss at step 39900: 0.094584\n",
      "2024-02-29 06:10:38 INFO     Training average positive_sample_loss at step 40000: 0.102194\n",
      "2024-02-29 06:10:38 INFO     Training average negative_sample_loss at step 40000: 0.090122\n",
      "2024-02-29 06:10:38 INFO     Training average loss at step 40000: 0.096158\n",
      "2024-02-29 06:10:38 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 06:10:39 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-29 06:11:10 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-29 06:11:47 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-29 06:12:23 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-29 06:12:55 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-29 06:13:31 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-29 06:13:59 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-29 06:14:07 INFO     Valid MRR at step 40000: 0.417048\n",
      "2024-02-29 06:14:07 INFO     Valid MR at step 40000: 300.521120\n",
      "2024-02-29 06:14:07 INFO     Valid HITS@1 at step 40000: 0.333330\n",
      "2024-02-29 06:14:07 INFO     Valid HITS@3 at step 40000: 0.439810\n",
      "2024-02-29 06:14:07 INFO     Valid HITS@10 at step 40000: 0.604110\n",
      "2024-02-29 06:15:27 INFO     Training average positive_sample_loss at step 40100: 0.103040\n",
      "2024-02-29 06:15:27 INFO     Training average negative_sample_loss at step 40100: 0.090659\n",
      "2024-02-29 06:15:27 INFO     Training average loss at step 40100: 0.096850\n",
      "2024-02-29 06:17:20 INFO     Training average positive_sample_loss at step 40200: 0.103984\n",
      "2024-02-29 06:17:20 INFO     Training average negative_sample_loss at step 40200: 0.091543\n",
      "2024-02-29 06:17:20 INFO     Training average loss at step 40200: 0.097764\n",
      "2024-02-29 06:19:07 INFO     Training average positive_sample_loss at step 40300: 0.104321\n",
      "2024-02-29 06:19:07 INFO     Training average negative_sample_loss at step 40300: 0.091953\n",
      "2024-02-29 06:19:07 INFO     Training average loss at step 40300: 0.098137\n",
      "2024-02-29 06:21:09 INFO     Training average positive_sample_loss at step 40400: 0.104759\n",
      "2024-02-29 06:21:09 INFO     Training average negative_sample_loss at step 40400: 0.092743\n",
      "2024-02-29 06:21:09 INFO     Training average loss at step 40400: 0.098751\n",
      "2024-02-29 06:22:41 INFO     Training average positive_sample_loss at step 40500: 0.104657\n",
      "2024-02-29 06:22:41 INFO     Training average negative_sample_loss at step 40500: 0.092475\n",
      "2024-02-29 06:22:41 INFO     Training average loss at step 40500: 0.098566\n",
      "2024-02-29 06:24:37 INFO     Training average positive_sample_loss at step 40600: 0.103365\n",
      "2024-02-29 06:24:37 INFO     Training average negative_sample_loss at step 40600: 0.092541\n",
      "2024-02-29 06:24:37 INFO     Training average loss at step 40600: 0.097953\n",
      "2024-02-29 06:26:50 INFO     Training average positive_sample_loss at step 40700: 0.097052\n",
      "2024-02-29 06:26:50 INFO     Training average negative_sample_loss at step 40700: 0.086239\n",
      "2024-02-29 06:26:50 INFO     Training average loss at step 40700: 0.091645\n",
      "2024-02-29 06:28:53 INFO     Training average positive_sample_loss at step 40800: 0.100140\n",
      "2024-02-29 06:28:53 INFO     Training average negative_sample_loss at step 40800: 0.087931\n",
      "2024-02-29 06:28:53 INFO     Training average loss at step 40800: 0.094036\n",
      "2024-02-29 06:30:54 INFO     Training average positive_sample_loss at step 40900: 0.101651\n",
      "2024-02-29 06:30:54 INFO     Training average negative_sample_loss at step 40900: 0.089380\n",
      "2024-02-29 06:30:54 INFO     Training average loss at step 40900: 0.095516\n",
      "2024-02-29 06:32:59 INFO     Training average positive_sample_loss at step 41000: 0.102344\n",
      "2024-02-29 06:32:59 INFO     Training average negative_sample_loss at step 41000: 0.089876\n",
      "2024-02-29 06:32:59 INFO     Training average loss at step 41000: 0.096110\n",
      "2024-02-29 06:34:42 INFO     Training average positive_sample_loss at step 41100: 0.103363\n",
      "2024-02-29 06:34:42 INFO     Training average negative_sample_loss at step 41100: 0.091258\n",
      "2024-02-29 06:34:42 INFO     Training average loss at step 41100: 0.097310\n",
      "2024-02-29 06:36:34 INFO     Training average positive_sample_loss at step 41200: 0.104054\n",
      "2024-02-29 06:36:34 INFO     Training average negative_sample_loss at step 41200: 0.091832\n",
      "2024-02-29 06:36:34 INFO     Training average loss at step 41200: 0.097943\n",
      "2024-02-29 06:38:16 INFO     Training average positive_sample_loss at step 41300: 0.104288\n",
      "2024-02-29 06:38:16 INFO     Training average negative_sample_loss at step 41300: 0.091897\n",
      "2024-02-29 06:38:16 INFO     Training average loss at step 41300: 0.098092\n",
      "2024-02-29 06:40:08 INFO     Training average positive_sample_loss at step 41400: 0.104877\n",
      "2024-02-29 06:40:08 INFO     Training average negative_sample_loss at step 41400: 0.092903\n",
      "2024-02-29 06:40:08 INFO     Training average loss at step 41400: 0.098890\n",
      "2024-02-29 06:42:01 INFO     Training average positive_sample_loss at step 41500: 0.104249\n",
      "2024-02-29 06:42:01 INFO     Training average negative_sample_loss at step 41500: 0.092028\n",
      "2024-02-29 06:42:01 INFO     Training average loss at step 41500: 0.098138\n",
      "2024-02-29 06:44:03 INFO     Training average positive_sample_loss at step 41600: 0.098607\n",
      "2024-02-29 06:44:03 INFO     Training average negative_sample_loss at step 41600: 0.089076\n",
      "2024-02-29 06:44:03 INFO     Training average loss at step 41600: 0.093841\n",
      "2024-02-29 06:46:03 INFO     Training average positive_sample_loss at step 41700: 0.099143\n",
      "2024-02-29 06:46:03 INFO     Training average negative_sample_loss at step 41700: 0.086888\n",
      "2024-02-29 06:46:03 INFO     Training average loss at step 41700: 0.093015\n",
      "2024-02-29 06:47:58 INFO     Training average positive_sample_loss at step 41800: 0.100928\n",
      "2024-02-29 06:47:58 INFO     Training average negative_sample_loss at step 41800: 0.088636\n",
      "2024-02-29 06:47:58 INFO     Training average loss at step 41800: 0.094782\n",
      "2024-02-29 06:49:46 INFO     Training average positive_sample_loss at step 41900: 0.101375\n",
      "2024-02-29 06:49:46 INFO     Training average negative_sample_loss at step 41900: 0.089478\n",
      "2024-02-29 06:49:46 INFO     Training average loss at step 41900: 0.095427\n",
      "2024-02-29 06:51:25 INFO     Training average positive_sample_loss at step 42000: 0.103150\n",
      "2024-02-29 06:51:25 INFO     Training average negative_sample_loss at step 42000: 0.090910\n",
      "2024-02-29 06:51:25 INFO     Training average loss at step 42000: 0.097030\n",
      "2024-02-29 06:53:20 INFO     Training average positive_sample_loss at step 42100: 0.103568\n",
      "2024-02-29 06:53:20 INFO     Training average negative_sample_loss at step 42100: 0.091042\n",
      "2024-02-29 06:53:20 INFO     Training average loss at step 42100: 0.097305\n",
      "2024-02-29 06:54:59 INFO     Training average positive_sample_loss at step 42200: 0.104187\n",
      "2024-02-29 06:54:59 INFO     Training average negative_sample_loss at step 42200: 0.092127\n",
      "2024-02-29 06:54:59 INFO     Training average loss at step 42200: 0.098157\n",
      "2024-02-29 06:56:36 INFO     Training average positive_sample_loss at step 42300: 0.103650\n",
      "2024-02-29 06:56:36 INFO     Training average negative_sample_loss at step 42300: 0.091338\n",
      "2024-02-29 06:56:36 INFO     Training average loss at step 42300: 0.097494\n",
      "2024-02-29 06:58:23 INFO     Training average positive_sample_loss at step 42400: 0.104040\n",
      "2024-02-29 06:58:23 INFO     Training average negative_sample_loss at step 42400: 0.092207\n",
      "2024-02-29 06:58:23 INFO     Training average loss at step 42400: 0.098124\n",
      "2024-02-29 07:00:29 INFO     Training average positive_sample_loss at step 42500: 0.101374\n",
      "2024-02-29 07:00:29 INFO     Training average negative_sample_loss at step 42500: 0.091351\n",
      "2024-02-29 07:00:29 INFO     Training average loss at step 42500: 0.096363\n",
      "2024-02-29 07:02:28 INFO     Training average positive_sample_loss at step 42600: 0.097592\n",
      "2024-02-29 07:02:28 INFO     Training average negative_sample_loss at step 42600: 0.085957\n",
      "2024-02-29 07:02:28 INFO     Training average loss at step 42600: 0.091775\n",
      "2024-02-29 07:04:12 INFO     Training average positive_sample_loss at step 42700: 0.099645\n",
      "2024-02-29 07:04:12 INFO     Training average negative_sample_loss at step 42700: 0.087405\n",
      "2024-02-29 07:04:12 INFO     Training average loss at step 42700: 0.093525\n",
      "2024-02-29 07:05:44 INFO     Training average positive_sample_loss at step 42800: 0.101133\n",
      "2024-02-29 07:05:44 INFO     Training average negative_sample_loss at step 42800: 0.088917\n",
      "2024-02-29 07:05:44 INFO     Training average loss at step 42800: 0.095025\n",
      "2024-02-29 07:07:28 INFO     Training average positive_sample_loss at step 42900: 0.102357\n",
      "2024-02-29 07:07:28 INFO     Training average negative_sample_loss at step 42900: 0.089664\n",
      "2024-02-29 07:07:28 INFO     Training average loss at step 42900: 0.096011\n",
      "2024-02-29 07:09:14 INFO     Training average positive_sample_loss at step 43000: 0.103103\n",
      "2024-02-29 07:09:14 INFO     Training average negative_sample_loss at step 43000: 0.091065\n",
      "2024-02-29 07:09:14 INFO     Training average loss at step 43000: 0.097084\n",
      "2024-02-29 07:10:59 INFO     Training average positive_sample_loss at step 43100: 0.103846\n",
      "2024-02-29 07:10:59 INFO     Training average negative_sample_loss at step 43100: 0.091646\n",
      "2024-02-29 07:10:59 INFO     Training average loss at step 43100: 0.097746\n",
      "2024-02-29 07:12:55 INFO     Training average positive_sample_loss at step 43200: 0.103765\n",
      "2024-02-29 07:12:55 INFO     Training average negative_sample_loss at step 43200: 0.091507\n",
      "2024-02-29 07:12:55 INFO     Training average loss at step 43200: 0.097636\n",
      "2024-02-29 07:14:42 INFO     Training average positive_sample_loss at step 43300: 0.104165\n",
      "2024-02-29 07:14:42 INFO     Training average negative_sample_loss at step 43300: 0.091965\n",
      "2024-02-29 07:14:42 INFO     Training average loss at step 43300: 0.098065\n",
      "2024-02-29 07:16:38 INFO     Training average positive_sample_loss at step 43400: 0.104054\n",
      "2024-02-29 07:16:38 INFO     Training average negative_sample_loss at step 43400: 0.091895\n",
      "2024-02-29 07:16:38 INFO     Training average loss at step 43400: 0.097975\n",
      "2024-02-29 07:18:32 INFO     Training average positive_sample_loss at step 43500: 0.097351\n",
      "2024-02-29 07:18:32 INFO     Training average negative_sample_loss at step 43500: 0.087505\n",
      "2024-02-29 07:18:32 INFO     Training average loss at step 43500: 0.092428\n",
      "2024-02-29 07:20:12 INFO     Training average positive_sample_loss at step 43600: 0.098626\n",
      "2024-02-29 07:20:12 INFO     Training average negative_sample_loss at step 43600: 0.086705\n",
      "2024-02-29 07:20:12 INFO     Training average loss at step 43600: 0.092665\n",
      "2024-02-29 07:22:07 INFO     Training average positive_sample_loss at step 43700: 0.100548\n",
      "2024-02-29 07:22:07 INFO     Training average negative_sample_loss at step 43700: 0.088319\n",
      "2024-02-29 07:22:07 INFO     Training average loss at step 43700: 0.094434\n",
      "2024-02-29 07:23:48 INFO     Training average positive_sample_loss at step 43800: 0.101118\n",
      "2024-02-29 07:23:48 INFO     Training average negative_sample_loss at step 43800: 0.088992\n",
      "2024-02-29 07:23:48 INFO     Training average loss at step 43800: 0.095055\n",
      "2024-02-29 07:25:35 INFO     Training average positive_sample_loss at step 43900: 0.102896\n",
      "2024-02-29 07:25:35 INFO     Training average negative_sample_loss at step 43900: 0.090720\n",
      "2024-02-29 07:25:35 INFO     Training average loss at step 43900: 0.096808\n",
      "2024-02-29 07:27:03 INFO     Training average positive_sample_loss at step 44000: 0.103544\n",
      "2024-02-29 07:27:03 INFO     Training average negative_sample_loss at step 44000: 0.090942\n",
      "2024-02-29 07:27:03 INFO     Training average loss at step 44000: 0.097243\n",
      "2024-02-29 07:28:37 INFO     Training average positive_sample_loss at step 44100: 0.103662\n",
      "2024-02-29 07:28:37 INFO     Training average negative_sample_loss at step 44100: 0.091360\n",
      "2024-02-29 07:28:37 INFO     Training average loss at step 44100: 0.097511\n",
      "2024-02-29 07:30:13 INFO     Training average positive_sample_loss at step 44200: 0.103595\n",
      "2024-02-29 07:30:13 INFO     Training average negative_sample_loss at step 44200: 0.091505\n",
      "2024-02-29 07:30:13 INFO     Training average loss at step 44200: 0.097550\n",
      "2024-02-29 07:31:53 INFO     Training average positive_sample_loss at step 44300: 0.103588\n",
      "2024-02-29 07:31:53 INFO     Training average negative_sample_loss at step 44300: 0.091648\n",
      "2024-02-29 07:31:53 INFO     Training average loss at step 44300: 0.097618\n",
      "2024-02-29 07:33:46 INFO     Training average positive_sample_loss at step 44400: 0.099769\n",
      "2024-02-29 07:33:46 INFO     Training average negative_sample_loss at step 44400: 0.090190\n",
      "2024-02-29 07:33:46 INFO     Training average loss at step 44400: 0.094979\n",
      "2024-02-29 07:35:22 INFO     Training average positive_sample_loss at step 44500: 0.098019\n",
      "2024-02-29 07:35:22 INFO     Training average negative_sample_loss at step 44500: 0.086112\n",
      "2024-02-29 07:35:22 INFO     Training average loss at step 44500: 0.092065\n",
      "2024-02-29 07:37:11 INFO     Training average positive_sample_loss at step 44600: 0.099366\n",
      "2024-02-29 07:37:11 INFO     Training average negative_sample_loss at step 44600: 0.086985\n",
      "2024-02-29 07:37:11 INFO     Training average loss at step 44600: 0.093176\n",
      "2024-02-29 07:38:59 INFO     Training average positive_sample_loss at step 44700: 0.100988\n",
      "2024-02-29 07:38:59 INFO     Training average negative_sample_loss at step 44700: 0.088891\n",
      "2024-02-29 07:38:59 INFO     Training average loss at step 44700: 0.094939\n",
      "2024-02-29 07:40:51 INFO     Training average positive_sample_loss at step 44800: 0.102154\n",
      "2024-02-29 07:40:51 INFO     Training average negative_sample_loss at step 44800: 0.089511\n",
      "2024-02-29 07:40:51 INFO     Training average loss at step 44800: 0.095832\n",
      "2024-02-29 07:42:38 INFO     Training average positive_sample_loss at step 44900: 0.102558\n",
      "2024-02-29 07:42:38 INFO     Training average negative_sample_loss at step 44900: 0.090638\n",
      "2024-02-29 07:42:38 INFO     Training average loss at step 44900: 0.096598\n",
      "2024-02-29 07:44:30 INFO     Training average positive_sample_loss at step 45000: 0.102899\n",
      "2024-02-29 07:44:30 INFO     Training average negative_sample_loss at step 45000: 0.090841\n",
      "2024-02-29 07:44:30 INFO     Training average loss at step 45000: 0.096870\n",
      "2024-02-29 07:46:23 INFO     Training average positive_sample_loss at step 45100: 0.103238\n",
      "2024-02-29 07:46:23 INFO     Training average negative_sample_loss at step 45100: 0.090794\n",
      "2024-02-29 07:46:23 INFO     Training average loss at step 45100: 0.097016\n",
      "2024-02-29 07:48:08 INFO     Training average positive_sample_loss at step 45200: 0.103755\n",
      "2024-02-29 07:48:08 INFO     Training average negative_sample_loss at step 45200: 0.091772\n",
      "2024-02-29 07:48:08 INFO     Training average loss at step 45200: 0.097763\n",
      "2024-02-29 07:49:57 INFO     Training average positive_sample_loss at step 45300: 0.103724\n",
      "2024-02-29 07:49:57 INFO     Training average negative_sample_loss at step 45300: 0.091863\n",
      "2024-02-29 07:49:57 INFO     Training average loss at step 45300: 0.097793\n",
      "2024-02-29 07:51:51 INFO     Training average positive_sample_loss at step 45400: 0.096015\n",
      "2024-02-29 07:51:51 INFO     Training average negative_sample_loss at step 45400: 0.086542\n",
      "2024-02-29 07:51:51 INFO     Training average loss at step 45400: 0.091278\n",
      "2024-02-29 07:53:25 INFO     Training average positive_sample_loss at step 45500: 0.099334\n",
      "2024-02-29 07:53:25 INFO     Training average negative_sample_loss at step 45500: 0.086912\n",
      "2024-02-29 07:53:25 INFO     Training average loss at step 45500: 0.093123\n",
      "2024-02-29 07:55:06 INFO     Training average positive_sample_loss at step 45600: 0.099779\n",
      "2024-02-29 07:55:06 INFO     Training average negative_sample_loss at step 45600: 0.087575\n",
      "2024-02-29 07:55:06 INFO     Training average loss at step 45600: 0.093677\n",
      "2024-02-29 07:56:43 INFO     Training average positive_sample_loss at step 45700: 0.101605\n",
      "2024-02-29 07:56:43 INFO     Training average negative_sample_loss at step 45700: 0.088847\n",
      "2024-02-29 07:56:43 INFO     Training average loss at step 45700: 0.095226\n",
      "2024-02-29 07:58:13 INFO     Training average positive_sample_loss at step 45800: 0.102328\n",
      "2024-02-29 07:58:13 INFO     Training average negative_sample_loss at step 45800: 0.090233\n",
      "2024-02-29 07:58:13 INFO     Training average loss at step 45800: 0.096281\n",
      "2024-02-29 07:59:51 INFO     Training average positive_sample_loss at step 45900: 0.102618\n",
      "2024-02-29 07:59:51 INFO     Training average negative_sample_loss at step 45900: 0.090470\n",
      "2024-02-29 07:59:51 INFO     Training average loss at step 45900: 0.096544\n",
      "2024-02-29 08:01:35 INFO     Training average positive_sample_loss at step 46000: 0.102762\n",
      "2024-02-29 08:01:35 INFO     Training average negative_sample_loss at step 46000: 0.090568\n",
      "2024-02-29 08:01:35 INFO     Training average loss at step 46000: 0.096665\n",
      "2024-02-29 08:03:36 INFO     Training average positive_sample_loss at step 46100: 0.103482\n",
      "2024-02-29 08:03:36 INFO     Training average negative_sample_loss at step 46100: 0.090993\n",
      "2024-02-29 08:03:36 INFO     Training average loss at step 46100: 0.097237\n",
      "2024-02-29 08:05:27 INFO     Training average positive_sample_loss at step 46200: 0.103619\n",
      "2024-02-29 08:05:27 INFO     Training average negative_sample_loss at step 46200: 0.091630\n",
      "2024-02-29 08:05:27 INFO     Training average loss at step 46200: 0.097625\n",
      "2024-02-29 08:07:26 INFO     Training average positive_sample_loss at step 46300: 0.098703\n",
      "2024-02-29 08:07:26 INFO     Training average negative_sample_loss at step 46300: 0.088944\n",
      "2024-02-29 08:07:26 INFO     Training average loss at step 46300: 0.093824\n",
      "2024-02-29 08:09:15 INFO     Training average positive_sample_loss at step 46400: 0.097792\n",
      "2024-02-29 08:09:15 INFO     Training average negative_sample_loss at step 46400: 0.085585\n",
      "2024-02-29 08:09:15 INFO     Training average loss at step 46400: 0.091688\n",
      "2024-02-29 08:11:11 INFO     Training average positive_sample_loss at step 46500: 0.099112\n",
      "2024-02-29 08:11:11 INFO     Training average negative_sample_loss at step 46500: 0.086690\n",
      "2024-02-29 08:11:11 INFO     Training average loss at step 46500: 0.092901\n",
      "2024-02-29 08:13:09 INFO     Training average positive_sample_loss at step 46600: 0.100530\n",
      "2024-02-29 08:13:09 INFO     Training average negative_sample_loss at step 46600: 0.088205\n",
      "2024-02-29 08:13:09 INFO     Training average loss at step 46600: 0.094367\n",
      "2024-02-29 08:15:09 INFO     Training average positive_sample_loss at step 46700: 0.101263\n",
      "2024-02-29 08:15:09 INFO     Training average negative_sample_loss at step 46700: 0.089153\n",
      "2024-02-29 08:15:09 INFO     Training average loss at step 46700: 0.095208\n",
      "2024-02-29 08:17:07 INFO     Training average positive_sample_loss at step 46800: 0.102487\n",
      "2024-02-29 08:17:07 INFO     Training average negative_sample_loss at step 46800: 0.090265\n",
      "2024-02-29 08:17:07 INFO     Training average loss at step 46800: 0.096376\n",
      "2024-02-29 08:19:00 INFO     Training average positive_sample_loss at step 46900: 0.102746\n",
      "2024-02-29 08:19:00 INFO     Training average negative_sample_loss at step 46900: 0.090482\n",
      "2024-02-29 08:19:00 INFO     Training average loss at step 46900: 0.096614\n",
      "2024-02-29 08:20:44 INFO     Training average positive_sample_loss at step 47000: 0.103092\n",
      "2024-02-29 08:20:44 INFO     Training average negative_sample_loss at step 47000: 0.090743\n",
      "2024-02-29 08:20:44 INFO     Training average loss at step 47000: 0.096917\n",
      "2024-02-29 08:22:36 INFO     Training average positive_sample_loss at step 47100: 0.103270\n",
      "2024-02-29 08:22:36 INFO     Training average negative_sample_loss at step 47100: 0.091554\n",
      "2024-02-29 08:22:36 INFO     Training average loss at step 47100: 0.097412\n",
      "2024-02-29 08:24:48 INFO     Training average positive_sample_loss at step 47200: 0.103190\n",
      "2024-02-29 08:24:48 INFO     Training average negative_sample_loss at step 47200: 0.091348\n",
      "2024-02-29 08:24:48 INFO     Training average loss at step 47200: 0.097269\n",
      "2024-02-29 08:26:35 INFO     Training average positive_sample_loss at step 47300: 0.095391\n",
      "2024-02-29 08:26:35 INFO     Training average negative_sample_loss at step 47300: 0.085660\n",
      "2024-02-29 08:26:35 INFO     Training average loss at step 47300: 0.090525\n",
      "2024-02-29 08:28:31 INFO     Training average positive_sample_loss at step 47400: 0.098251\n",
      "2024-02-29 08:28:31 INFO     Training average negative_sample_loss at step 47400: 0.085966\n",
      "2024-02-29 08:28:31 INFO     Training average loss at step 47400: 0.092108\n",
      "2024-02-29 08:30:07 INFO     Training average positive_sample_loss at step 47500: 0.099873\n",
      "2024-02-29 08:30:07 INFO     Training average negative_sample_loss at step 47500: 0.087491\n",
      "2024-02-29 08:30:07 INFO     Training average loss at step 47500: 0.093682\n",
      "2024-02-29 08:31:58 INFO     Training average positive_sample_loss at step 47600: 0.101945\n",
      "2024-02-29 08:31:58 INFO     Training average negative_sample_loss at step 47600: 0.089190\n",
      "2024-02-29 08:31:58 INFO     Training average loss at step 47600: 0.095568\n",
      "2024-02-29 08:33:46 INFO     Training average positive_sample_loss at step 47700: 0.101723\n",
      "2024-02-29 08:33:46 INFO     Training average negative_sample_loss at step 47700: 0.089587\n",
      "2024-02-29 08:33:46 INFO     Training average loss at step 47700: 0.095655\n",
      "2024-02-29 08:35:24 INFO     Training average positive_sample_loss at step 47800: 0.102060\n",
      "2024-02-29 08:35:24 INFO     Training average negative_sample_loss at step 47800: 0.090036\n",
      "2024-02-29 08:35:24 INFO     Training average loss at step 47800: 0.096048\n",
      "2024-02-29 08:37:01 INFO     Training average positive_sample_loss at step 47900: 0.102726\n",
      "2024-02-29 08:37:01 INFO     Training average negative_sample_loss at step 47900: 0.090403\n",
      "2024-02-29 08:37:01 INFO     Training average loss at step 47900: 0.096564\n",
      "2024-02-29 08:38:35 INFO     Training average positive_sample_loss at step 48000: 0.103082\n",
      "2024-02-29 08:38:35 INFO     Training average negative_sample_loss at step 48000: 0.091038\n",
      "2024-02-29 08:38:35 INFO     Training average loss at step 48000: 0.097060\n",
      "2024-02-29 08:40:23 INFO     Training average positive_sample_loss at step 48100: 0.103094\n",
      "2024-02-29 08:40:23 INFO     Training average negative_sample_loss at step 48100: 0.091004\n",
      "2024-02-29 08:40:23 INFO     Training average loss at step 48100: 0.097049\n",
      "2024-02-29 08:42:26 INFO     Training average positive_sample_loss at step 48200: 0.098142\n",
      "2024-02-29 08:42:26 INFO     Training average negative_sample_loss at step 48200: 0.088409\n",
      "2024-02-29 08:42:26 INFO     Training average loss at step 48200: 0.093275\n",
      "2024-02-29 08:44:10 INFO     Training average positive_sample_loss at step 48300: 0.096646\n",
      "2024-02-29 08:44:10 INFO     Training average negative_sample_loss at step 48300: 0.084656\n",
      "2024-02-29 08:44:10 INFO     Training average loss at step 48300: 0.090651\n",
      "2024-02-29 08:45:46 INFO     Training average positive_sample_loss at step 48400: 0.099157\n",
      "2024-02-29 08:45:46 INFO     Training average negative_sample_loss at step 48400: 0.086810\n",
      "2024-02-29 08:45:46 INFO     Training average loss at step 48400: 0.092983\n",
      "2024-02-29 08:47:21 INFO     Training average positive_sample_loss at step 48500: 0.100574\n",
      "2024-02-29 08:47:21 INFO     Training average negative_sample_loss at step 48500: 0.088159\n",
      "2024-02-29 08:47:21 INFO     Training average loss at step 48500: 0.094367\n",
      "2024-02-29 08:48:58 INFO     Training average positive_sample_loss at step 48600: 0.101388\n",
      "2024-02-29 08:48:58 INFO     Training average negative_sample_loss at step 48600: 0.088734\n",
      "2024-02-29 08:48:58 INFO     Training average loss at step 48600: 0.095061\n",
      "2024-02-29 08:50:52 INFO     Training average positive_sample_loss at step 48700: 0.101806\n",
      "2024-02-29 08:50:52 INFO     Training average negative_sample_loss at step 48700: 0.089496\n",
      "2024-02-29 08:50:52 INFO     Training average loss at step 48700: 0.095651\n",
      "2024-02-29 08:52:42 INFO     Training average positive_sample_loss at step 48800: 0.102355\n",
      "2024-02-29 08:52:42 INFO     Training average negative_sample_loss at step 48800: 0.089949\n",
      "2024-02-29 08:52:42 INFO     Training average loss at step 48800: 0.096152\n",
      "2024-02-29 08:54:24 INFO     Training average positive_sample_loss at step 48900: 0.102699\n",
      "2024-02-29 08:54:24 INFO     Training average negative_sample_loss at step 48900: 0.090996\n",
      "2024-02-29 08:54:24 INFO     Training average loss at step 48900: 0.096847\n",
      "2024-02-29 08:56:23 INFO     Training average positive_sample_loss at step 49000: 0.103360\n",
      "2024-02-29 08:56:23 INFO     Training average negative_sample_loss at step 49000: 0.091176\n",
      "2024-02-29 08:56:23 INFO     Training average loss at step 49000: 0.097268\n",
      "2024-02-29 08:58:34 INFO     Training average positive_sample_loss at step 49100: 0.101845\n",
      "2024-02-29 08:58:34 INFO     Training average negative_sample_loss at step 49100: 0.091493\n",
      "2024-02-29 08:58:34 INFO     Training average loss at step 49100: 0.096669\n",
      "2024-02-29 09:00:12 INFO     Training average positive_sample_loss at step 49200: 0.096071\n",
      "2024-02-29 09:00:12 INFO     Training average negative_sample_loss at step 49200: 0.085055\n",
      "2024-02-29 09:00:12 INFO     Training average loss at step 49200: 0.090563\n",
      "2024-02-29 09:01:48 INFO     Training average positive_sample_loss at step 49300: 0.098667\n",
      "2024-02-29 09:01:48 INFO     Training average negative_sample_loss at step 49300: 0.086343\n",
      "2024-02-29 09:01:48 INFO     Training average loss at step 49300: 0.092505\n",
      "2024-02-29 09:03:29 INFO     Training average positive_sample_loss at step 49400: 0.099822\n",
      "2024-02-29 09:03:29 INFO     Training average negative_sample_loss at step 49400: 0.087389\n",
      "2024-02-29 09:03:29 INFO     Training average loss at step 49400: 0.093606\n",
      "2024-02-29 09:05:10 INFO     Training average positive_sample_loss at step 49500: 0.100683\n",
      "2024-02-29 09:05:10 INFO     Training average negative_sample_loss at step 49500: 0.088245\n",
      "2024-02-29 09:05:10 INFO     Training average loss at step 49500: 0.094464\n",
      "2024-02-29 09:06:55 INFO     Training average positive_sample_loss at step 49600: 0.101675\n",
      "2024-02-29 09:06:55 INFO     Training average negative_sample_loss at step 49600: 0.089139\n",
      "2024-02-29 09:06:55 INFO     Training average loss at step 49600: 0.095407\n",
      "2024-02-29 09:08:48 INFO     Training average positive_sample_loss at step 49700: 0.102230\n",
      "2024-02-29 09:08:48 INFO     Training average negative_sample_loss at step 49700: 0.089995\n",
      "2024-02-29 09:08:48 INFO     Training average loss at step 49700: 0.096113\n",
      "2024-02-29 09:10:27 INFO     Training average positive_sample_loss at step 49800: 0.102615\n",
      "2024-02-29 09:10:27 INFO     Training average negative_sample_loss at step 49800: 0.090150\n",
      "2024-02-29 09:10:27 INFO     Training average loss at step 49800: 0.096383\n",
      "2024-02-29 09:12:10 INFO     Training average positive_sample_loss at step 49900: 0.102361\n",
      "2024-02-29 09:12:10 INFO     Training average negative_sample_loss at step 49900: 0.090511\n",
      "2024-02-29 09:12:10 INFO     Training average loss at step 49900: 0.096436\n",
      "2024-02-29 09:14:01 INFO     Training average positive_sample_loss at step 50000: 0.102746\n",
      "2024-02-29 09:14:01 INFO     Training average negative_sample_loss at step 50000: 0.090644\n",
      "2024-02-29 09:14:01 INFO     Training average loss at step 50000: 0.096695\n",
      "2024-02-29 09:14:01 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 09:14:02 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-29 09:14:31 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-29 09:15:04 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-29 09:15:34 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-29 09:16:04 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-29 09:16:38 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-29 09:17:10 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-29 09:17:18 INFO     Valid MRR at step 50000: 0.420775\n",
      "2024-02-29 09:17:18 INFO     Valid MR at step 50000: 278.547580\n",
      "2024-02-29 09:17:18 INFO     Valid HITS@1 at step 50000: 0.331670\n",
      "2024-02-29 09:17:18 INFO     Valid HITS@3 at step 50000: 0.446420\n",
      "2024-02-29 09:17:18 INFO     Valid HITS@10 at step 50000: 0.619180\n",
      "2024-02-29 09:18:54 INFO     Training average positive_sample_loss at step 50100: 0.096258\n",
      "2024-02-29 09:18:54 INFO     Training average negative_sample_loss at step 50100: 0.086810\n",
      "2024-02-29 09:18:54 INFO     Training average loss at step 50100: 0.091534\n",
      "2024-02-29 09:20:45 INFO     Training average positive_sample_loss at step 50200: 0.097357\n",
      "2024-02-29 09:20:45 INFO     Training average negative_sample_loss at step 50200: 0.084922\n",
      "2024-02-29 09:20:45 INFO     Training average loss at step 50200: 0.091140\n",
      "2024-02-29 09:22:35 INFO     Training average positive_sample_loss at step 50300: 0.099034\n",
      "2024-02-29 09:22:35 INFO     Training average negative_sample_loss at step 50300: 0.086975\n",
      "2024-02-29 09:22:35 INFO     Training average loss at step 50300: 0.093004\n",
      "2024-02-29 09:24:30 INFO     Training average positive_sample_loss at step 50400: 0.099952\n",
      "2024-02-29 09:24:30 INFO     Training average negative_sample_loss at step 50400: 0.087886\n",
      "2024-02-29 09:24:30 INFO     Training average loss at step 50400: 0.093919\n",
      "2024-02-29 09:26:17 INFO     Training average positive_sample_loss at step 50500: 0.101514\n",
      "2024-02-29 09:26:17 INFO     Training average negative_sample_loss at step 50500: 0.089064\n",
      "2024-02-29 09:26:17 INFO     Training average loss at step 50500: 0.095289\n",
      "2024-02-29 09:27:56 INFO     Training average positive_sample_loss at step 50600: 0.101617\n",
      "2024-02-29 09:27:56 INFO     Training average negative_sample_loss at step 50600: 0.089383\n",
      "2024-02-29 09:27:56 INFO     Training average loss at step 50600: 0.095500\n",
      "2024-02-29 09:29:46 INFO     Training average positive_sample_loss at step 50700: 0.102464\n",
      "2024-02-29 09:29:46 INFO     Training average negative_sample_loss at step 50700: 0.090235\n",
      "2024-02-29 09:29:46 INFO     Training average loss at step 50700: 0.096349\n",
      "2024-02-29 09:31:38 INFO     Training average positive_sample_loss at step 50800: 0.102600\n",
      "2024-02-29 09:31:38 INFO     Training average negative_sample_loss at step 50800: 0.090554\n",
      "2024-02-29 09:31:38 INFO     Training average loss at step 50800: 0.096577\n",
      "2024-02-29 09:33:30 INFO     Training average positive_sample_loss at step 50900: 0.102522\n",
      "2024-02-29 09:33:30 INFO     Training average negative_sample_loss at step 50900: 0.090199\n",
      "2024-02-29 09:33:30 INFO     Training average loss at step 50900: 0.096360\n",
      "2024-02-29 09:35:25 INFO     Training average positive_sample_loss at step 51000: 0.099729\n",
      "2024-02-29 09:35:25 INFO     Training average negative_sample_loss at step 51000: 0.089986\n",
      "2024-02-29 09:35:25 INFO     Training average loss at step 51000: 0.094857\n",
      "2024-02-29 09:37:11 INFO     Training average positive_sample_loss at step 51100: 0.096302\n",
      "2024-02-29 09:37:11 INFO     Training average negative_sample_loss at step 51100: 0.084406\n",
      "2024-02-29 09:37:11 INFO     Training average loss at step 51100: 0.090354\n",
      "2024-02-29 09:38:56 INFO     Training average positive_sample_loss at step 51200: 0.098157\n",
      "2024-02-29 09:38:56 INFO     Training average negative_sample_loss at step 51200: 0.085770\n",
      "2024-02-29 09:38:56 INFO     Training average loss at step 51200: 0.091963\n",
      "2024-02-29 09:40:47 INFO     Training average positive_sample_loss at step 51300: 0.099321\n",
      "2024-02-29 09:40:47 INFO     Training average negative_sample_loss at step 51300: 0.086880\n",
      "2024-02-29 09:40:47 INFO     Training average loss at step 51300: 0.093100\n",
      "2024-02-29 09:42:35 INFO     Training average positive_sample_loss at step 51400: 0.100260\n",
      "2024-02-29 09:42:35 INFO     Training average negative_sample_loss at step 51400: 0.088175\n",
      "2024-02-29 09:42:35 INFO     Training average loss at step 51400: 0.094218\n",
      "2024-02-29 09:44:20 INFO     Training average positive_sample_loss at step 51500: 0.101720\n",
      "2024-02-29 09:44:20 INFO     Training average negative_sample_loss at step 51500: 0.089164\n",
      "2024-02-29 09:44:20 INFO     Training average loss at step 51500: 0.095442\n",
      "2024-02-29 09:46:08 INFO     Training average positive_sample_loss at step 51600: 0.101825\n",
      "2024-02-29 09:46:08 INFO     Training average negative_sample_loss at step 51600: 0.089981\n",
      "2024-02-29 09:46:08 INFO     Training average loss at step 51600: 0.095903\n",
      "2024-02-29 09:47:48 INFO     Training average positive_sample_loss at step 51700: 0.102103\n",
      "2024-02-29 09:47:48 INFO     Training average negative_sample_loss at step 51700: 0.089926\n",
      "2024-02-29 09:47:48 INFO     Training average loss at step 51700: 0.096015\n",
      "2024-02-29 09:49:29 INFO     Training average positive_sample_loss at step 51800: 0.102532\n",
      "2024-02-29 09:49:29 INFO     Training average negative_sample_loss at step 51800: 0.090385\n",
      "2024-02-29 09:49:29 INFO     Training average loss at step 51800: 0.096459\n",
      "2024-02-29 09:51:02 INFO     Training average positive_sample_loss at step 51900: 0.102704\n",
      "2024-02-29 09:51:02 INFO     Training average negative_sample_loss at step 51900: 0.090486\n",
      "2024-02-29 09:51:02 INFO     Training average loss at step 51900: 0.096595\n",
      "2024-02-29 09:52:52 INFO     Training average positive_sample_loss at step 52000: 0.095384\n",
      "2024-02-29 09:52:52 INFO     Training average negative_sample_loss at step 52000: 0.085561\n",
      "2024-02-29 09:52:52 INFO     Training average loss at step 52000: 0.090473\n",
      "2024-02-29 09:54:40 INFO     Training average positive_sample_loss at step 52100: 0.097273\n",
      "2024-02-29 09:54:40 INFO     Training average negative_sample_loss at step 52100: 0.085346\n",
      "2024-02-29 09:54:40 INFO     Training average loss at step 52100: 0.091309\n",
      "2024-02-29 09:56:23 INFO     Training average positive_sample_loss at step 52200: 0.098977\n",
      "2024-02-29 09:56:23 INFO     Training average negative_sample_loss at step 52200: 0.086762\n",
      "2024-02-29 09:56:23 INFO     Training average loss at step 52200: 0.092870\n",
      "2024-02-29 09:57:54 INFO     Training average positive_sample_loss at step 52300: 0.100123\n",
      "2024-02-29 09:57:54 INFO     Training average negative_sample_loss at step 52300: 0.087781\n",
      "2024-02-29 09:57:54 INFO     Training average loss at step 52300: 0.093952\n",
      "2024-02-29 09:59:26 INFO     Training average positive_sample_loss at step 52400: 0.100982\n",
      "2024-02-29 09:59:26 INFO     Training average negative_sample_loss at step 52400: 0.088299\n",
      "2024-02-29 09:59:26 INFO     Training average loss at step 52400: 0.094641\n",
      "2024-02-29 10:01:00 INFO     Training average positive_sample_loss at step 52500: 0.101848\n",
      "2024-02-29 10:01:00 INFO     Training average negative_sample_loss at step 52500: 0.089622\n",
      "2024-02-29 10:01:00 INFO     Training average loss at step 52500: 0.095735\n",
      "2024-02-29 10:02:43 INFO     Training average positive_sample_loss at step 52600: 0.101893\n",
      "2024-02-29 10:02:43 INFO     Training average negative_sample_loss at step 52600: 0.089796\n",
      "2024-02-29 10:02:43 INFO     Training average loss at step 52600: 0.095844\n",
      "2024-02-29 10:04:31 INFO     Training average positive_sample_loss at step 52700: 0.101955\n",
      "2024-02-29 10:04:31 INFO     Training average negative_sample_loss at step 52700: 0.089767\n",
      "2024-02-29 10:04:31 INFO     Training average loss at step 52700: 0.095861\n",
      "2024-02-29 10:06:17 INFO     Training average positive_sample_loss at step 52800: 0.102358\n",
      "2024-02-29 10:06:17 INFO     Training average negative_sample_loss at step 52800: 0.090292\n",
      "2024-02-29 10:06:17 INFO     Training average loss at step 52800: 0.096325\n",
      "2024-02-29 10:08:22 INFO     Training average positive_sample_loss at step 52900: 0.098358\n",
      "2024-02-29 10:08:22 INFO     Training average negative_sample_loss at step 52900: 0.088699\n",
      "2024-02-29 10:08:22 INFO     Training average loss at step 52900: 0.093529\n",
      "2024-02-29 10:09:55 INFO     Training average positive_sample_loss at step 53000: 0.096461\n",
      "2024-02-29 10:09:55 INFO     Training average negative_sample_loss at step 53000: 0.084320\n",
      "2024-02-29 10:09:55 INFO     Training average loss at step 53000: 0.090391\n",
      "2024-02-29 10:11:35 INFO     Training average positive_sample_loss at step 53100: 0.097984\n",
      "2024-02-29 10:11:35 INFO     Training average negative_sample_loss at step 53100: 0.085683\n",
      "2024-02-29 10:11:35 INFO     Training average loss at step 53100: 0.091834\n",
      "2024-02-29 10:13:28 INFO     Training average positive_sample_loss at step 53200: 0.099361\n",
      "2024-02-29 10:13:28 INFO     Training average negative_sample_loss at step 53200: 0.087290\n",
      "2024-02-29 10:13:28 INFO     Training average loss at step 53200: 0.093326\n",
      "2024-02-29 10:15:21 INFO     Training average positive_sample_loss at step 53300: 0.100401\n",
      "2024-02-29 10:15:21 INFO     Training average negative_sample_loss at step 53300: 0.087928\n",
      "2024-02-29 10:15:21 INFO     Training average loss at step 53300: 0.094165\n",
      "2024-02-29 10:17:16 INFO     Training average positive_sample_loss at step 53400: 0.101000\n",
      "2024-02-29 10:17:16 INFO     Training average negative_sample_loss at step 53400: 0.088765\n",
      "2024-02-29 10:17:16 INFO     Training average loss at step 53400: 0.094883\n",
      "2024-02-29 10:19:08 INFO     Training average positive_sample_loss at step 53500: 0.101905\n",
      "2024-02-29 10:19:08 INFO     Training average negative_sample_loss at step 53500: 0.089388\n",
      "2024-02-29 10:19:08 INFO     Training average loss at step 53500: 0.095646\n",
      "2024-02-29 10:20:59 INFO     Training average positive_sample_loss at step 53600: 0.101545\n",
      "2024-02-29 10:20:59 INFO     Training average negative_sample_loss at step 53600: 0.089790\n",
      "2024-02-29 10:20:59 INFO     Training average loss at step 53600: 0.095668\n",
      "2024-02-29 10:22:50 INFO     Training average positive_sample_loss at step 53700: 0.101990\n",
      "2024-02-29 10:22:50 INFO     Training average negative_sample_loss at step 53700: 0.089792\n",
      "2024-02-29 10:22:50 INFO     Training average loss at step 53700: 0.095891\n",
      "2024-02-29 10:24:41 INFO     Training average positive_sample_loss at step 53800: 0.102334\n",
      "2024-02-29 10:24:41 INFO     Training average negative_sample_loss at step 53800: 0.090175\n",
      "2024-02-29 10:24:41 INFO     Training average loss at step 53800: 0.096254\n",
      "2024-02-29 10:26:34 INFO     Training average positive_sample_loss at step 53900: 0.094574\n",
      "2024-02-29 10:26:34 INFO     Training average negative_sample_loss at step 53900: 0.084758\n",
      "2024-02-29 10:26:34 INFO     Training average loss at step 53900: 0.089666\n",
      "2024-02-29 10:28:02 INFO     Training average positive_sample_loss at step 54000: 0.097490\n",
      "2024-02-29 10:28:02 INFO     Training average negative_sample_loss at step 54000: 0.085025\n",
      "2024-02-29 10:28:02 INFO     Training average loss at step 54000: 0.091257\n",
      "2024-02-29 10:29:47 INFO     Training average positive_sample_loss at step 54100: 0.098360\n",
      "2024-02-29 10:29:47 INFO     Training average negative_sample_loss at step 54100: 0.086209\n",
      "2024-02-29 10:29:47 INFO     Training average loss at step 54100: 0.092284\n",
      "2024-02-29 10:31:40 INFO     Training average positive_sample_loss at step 54200: 0.100016\n",
      "2024-02-29 10:31:40 INFO     Training average negative_sample_loss at step 54200: 0.087698\n",
      "2024-02-29 10:31:40 INFO     Training average loss at step 54200: 0.093857\n",
      "2024-02-29 10:33:22 INFO     Training average positive_sample_loss at step 54300: 0.100544\n",
      "2024-02-29 10:33:22 INFO     Training average negative_sample_loss at step 54300: 0.088319\n",
      "2024-02-29 10:33:22 INFO     Training average loss at step 54300: 0.094431\n",
      "2024-02-29 10:35:11 INFO     Training average positive_sample_loss at step 54400: 0.101426\n",
      "2024-02-29 10:35:11 INFO     Training average negative_sample_loss at step 54400: 0.089120\n",
      "2024-02-29 10:35:11 INFO     Training average loss at step 54400: 0.095273\n",
      "2024-02-29 10:36:59 INFO     Training average positive_sample_loss at step 54500: 0.101389\n",
      "2024-02-29 10:36:59 INFO     Training average negative_sample_loss at step 54500: 0.088965\n",
      "2024-02-29 10:36:59 INFO     Training average loss at step 54500: 0.095177\n",
      "2024-02-29 10:38:36 INFO     Training average positive_sample_loss at step 54600: 0.102390\n",
      "2024-02-29 10:38:36 INFO     Training average negative_sample_loss at step 54600: 0.090310\n",
      "2024-02-29 10:38:36 INFO     Training average loss at step 54600: 0.096350\n",
      "2024-02-29 10:40:13 INFO     Training average positive_sample_loss at step 54700: 0.101877\n",
      "2024-02-29 10:40:13 INFO     Training average negative_sample_loss at step 54700: 0.089941\n",
      "2024-02-29 10:40:13 INFO     Training average loss at step 54700: 0.095909\n",
      "2024-02-29 10:42:08 INFO     Training average positive_sample_loss at step 54800: 0.097529\n",
      "2024-02-29 10:42:08 INFO     Training average negative_sample_loss at step 54800: 0.087724\n",
      "2024-02-29 10:42:08 INFO     Training average loss at step 54800: 0.092626\n",
      "2024-02-29 10:43:50 INFO     Training average positive_sample_loss at step 54900: 0.095869\n",
      "2024-02-29 10:43:50 INFO     Training average negative_sample_loss at step 54900: 0.083741\n",
      "2024-02-29 10:43:50 INFO     Training average loss at step 54900: 0.089805\n",
      "2024-02-29 10:45:38 INFO     Training average positive_sample_loss at step 55000: 0.098249\n",
      "2024-02-29 10:45:38 INFO     Training average negative_sample_loss at step 55000: 0.085838\n",
      "2024-02-29 10:45:38 INFO     Training average loss at step 55000: 0.092043\n",
      "2024-02-29 10:47:34 INFO     Training average positive_sample_loss at step 55100: 0.099419\n",
      "2024-02-29 10:47:34 INFO     Training average negative_sample_loss at step 55100: 0.087145\n",
      "2024-02-29 10:47:34 INFO     Training average loss at step 55100: 0.093282\n",
      "2024-02-29 10:49:29 INFO     Training average positive_sample_loss at step 55200: 0.100229\n",
      "2024-02-29 10:49:29 INFO     Training average negative_sample_loss at step 55200: 0.088243\n",
      "2024-02-29 10:49:29 INFO     Training average loss at step 55200: 0.094236\n",
      "2024-02-29 10:51:01 INFO     Training average positive_sample_loss at step 55300: 0.100694\n",
      "2024-02-29 10:51:01 INFO     Training average negative_sample_loss at step 55300: 0.088343\n",
      "2024-02-29 10:51:01 INFO     Training average loss at step 55300: 0.094519\n",
      "2024-02-29 10:52:57 INFO     Training average positive_sample_loss at step 55400: 0.101685\n",
      "2024-02-29 10:52:57 INFO     Training average negative_sample_loss at step 55400: 0.089318\n",
      "2024-02-29 10:52:57 INFO     Training average loss at step 55400: 0.095501\n",
      "2024-02-29 10:55:04 INFO     Training average positive_sample_loss at step 55500: 0.101575\n",
      "2024-02-29 10:55:04 INFO     Training average negative_sample_loss at step 55500: 0.089644\n",
      "2024-02-29 10:55:04 INFO     Training average loss at step 55500: 0.095610\n",
      "2024-02-29 10:57:12 INFO     Training average positive_sample_loss at step 55600: 0.102385\n",
      "2024-02-29 10:57:12 INFO     Training average negative_sample_loss at step 55600: 0.090143\n",
      "2024-02-29 10:57:12 INFO     Training average loss at step 55600: 0.096264\n",
      "2024-02-29 10:59:38 INFO     Training average positive_sample_loss at step 55700: 0.100952\n",
      "2024-02-29 10:59:38 INFO     Training average negative_sample_loss at step 55700: 0.089586\n",
      "2024-02-29 10:59:38 INFO     Training average loss at step 55700: 0.095269\n",
      "2024-02-29 11:01:30 INFO     Training average positive_sample_loss at step 55800: 0.094042\n",
      "2024-02-29 11:01:30 INFO     Training average negative_sample_loss at step 55800: 0.083780\n",
      "2024-02-29 11:01:30 INFO     Training average loss at step 55800: 0.088911\n",
      "2024-02-29 11:03:07 INFO     Training average positive_sample_loss at step 55900: 0.097194\n",
      "2024-02-29 11:03:07 INFO     Training average negative_sample_loss at step 55900: 0.085015\n",
      "2024-02-29 11:03:07 INFO     Training average loss at step 55900: 0.091105\n",
      "2024-02-29 11:04:47 INFO     Training average positive_sample_loss at step 56000: 0.099093\n",
      "2024-02-29 11:04:47 INFO     Training average negative_sample_loss at step 56000: 0.086830\n",
      "2024-02-29 11:04:47 INFO     Training average loss at step 56000: 0.092961\n",
      "2024-02-29 11:06:31 INFO     Training average positive_sample_loss at step 56100: 0.100054\n",
      "2024-02-29 11:06:31 INFO     Training average negative_sample_loss at step 56100: 0.087642\n",
      "2024-02-29 11:06:31 INFO     Training average loss at step 56100: 0.093848\n",
      "2024-02-29 11:08:12 INFO     Training average positive_sample_loss at step 56200: 0.100809\n",
      "2024-02-29 11:08:12 INFO     Training average negative_sample_loss at step 56200: 0.088206\n",
      "2024-02-29 11:08:12 INFO     Training average loss at step 56200: 0.094507\n",
      "2024-02-29 11:09:53 INFO     Training average positive_sample_loss at step 56300: 0.100972\n",
      "2024-02-29 11:09:53 INFO     Training average negative_sample_loss at step 56300: 0.088753\n",
      "2024-02-29 11:09:53 INFO     Training average loss at step 56300: 0.094863\n",
      "2024-02-29 11:11:47 INFO     Training average positive_sample_loss at step 56400: 0.101524\n",
      "2024-02-29 11:11:47 INFO     Training average negative_sample_loss at step 56400: 0.089412\n",
      "2024-02-29 11:11:47 INFO     Training average loss at step 56400: 0.095468\n",
      "2024-02-29 11:13:32 INFO     Training average positive_sample_loss at step 56500: 0.101749\n",
      "2024-02-29 11:13:32 INFO     Training average negative_sample_loss at step 56500: 0.089784\n",
      "2024-02-29 11:13:32 INFO     Training average loss at step 56500: 0.095766\n",
      "2024-02-29 11:15:16 INFO     Training average positive_sample_loss at step 56600: 0.101408\n",
      "2024-02-29 11:15:16 INFO     Training average negative_sample_loss at step 56600: 0.089361\n",
      "2024-02-29 11:15:16 INFO     Training average loss at step 56600: 0.095384\n",
      "2024-02-29 11:17:20 INFO     Training average positive_sample_loss at step 56700: 0.096107\n",
      "2024-02-29 11:17:20 INFO     Training average negative_sample_loss at step 56700: 0.086371\n",
      "2024-02-29 11:17:20 INFO     Training average loss at step 56700: 0.091239\n",
      "2024-02-29 11:18:58 INFO     Training average positive_sample_loss at step 56800: 0.096376\n",
      "2024-02-29 11:18:58 INFO     Training average negative_sample_loss at step 56800: 0.083853\n",
      "2024-02-29 11:18:58 INFO     Training average loss at step 56800: 0.090114\n",
      "2024-02-29 11:20:48 INFO     Training average positive_sample_loss at step 56900: 0.098341\n",
      "2024-02-29 11:20:48 INFO     Training average negative_sample_loss at step 56900: 0.085921\n",
      "2024-02-29 11:20:48 INFO     Training average loss at step 56900: 0.092131\n",
      "2024-02-29 11:22:41 INFO     Training average positive_sample_loss at step 57000: 0.099096\n",
      "2024-02-29 11:22:41 INFO     Training average negative_sample_loss at step 57000: 0.086880\n",
      "2024-02-29 11:22:41 INFO     Training average loss at step 57000: 0.092988\n",
      "2024-02-29 11:24:26 INFO     Training average positive_sample_loss at step 57100: 0.100123\n",
      "2024-02-29 11:24:26 INFO     Training average negative_sample_loss at step 57100: 0.088074\n",
      "2024-02-29 11:24:26 INFO     Training average loss at step 57100: 0.094098\n",
      "2024-02-29 11:26:21 INFO     Training average positive_sample_loss at step 57200: 0.100739\n",
      "2024-02-29 11:26:21 INFO     Training average negative_sample_loss at step 57200: 0.088540\n",
      "2024-02-29 11:26:21 INFO     Training average loss at step 57200: 0.094640\n",
      "2024-02-29 11:28:08 INFO     Training average positive_sample_loss at step 57300: 0.101131\n",
      "2024-02-29 11:28:08 INFO     Training average negative_sample_loss at step 57300: 0.088839\n",
      "2024-02-29 11:28:08 INFO     Training average loss at step 57300: 0.094985\n",
      "2024-02-29 11:29:52 INFO     Training average positive_sample_loss at step 57400: 0.101521\n",
      "2024-02-29 11:29:52 INFO     Training average negative_sample_loss at step 57400: 0.089286\n",
      "2024-02-29 11:29:52 INFO     Training average loss at step 57400: 0.095404\n",
      "2024-02-29 11:31:45 INFO     Training average positive_sample_loss at step 57500: 0.101353\n",
      "2024-02-29 11:31:45 INFO     Training average negative_sample_loss at step 57500: 0.089380\n",
      "2024-02-29 11:31:45 INFO     Training average loss at step 57500: 0.095367\n",
      "2024-02-29 11:33:49 INFO     Training average positive_sample_loss at step 57600: 0.099564\n",
      "2024-02-29 11:33:49 INFO     Training average negative_sample_loss at step 57600: 0.089356\n",
      "2024-02-29 11:33:49 INFO     Training average loss at step 57600: 0.094460\n",
      "2024-02-29 11:35:40 INFO     Training average positive_sample_loss at step 57700: 0.094768\n",
      "2024-02-29 11:35:40 INFO     Training average negative_sample_loss at step 57700: 0.083313\n",
      "2024-02-29 11:35:40 INFO     Training average loss at step 57700: 0.089040\n",
      "2024-02-29 11:37:36 INFO     Training average positive_sample_loss at step 57800: 0.097580\n",
      "2024-02-29 11:37:36 INFO     Training average negative_sample_loss at step 57800: 0.085270\n",
      "2024-02-29 11:37:36 INFO     Training average loss at step 57800: 0.091425\n",
      "2024-02-29 11:39:18 INFO     Training average positive_sample_loss at step 57900: 0.098887\n",
      "2024-02-29 11:39:18 INFO     Training average negative_sample_loss at step 57900: 0.086440\n",
      "2024-02-29 11:39:18 INFO     Training average loss at step 57900: 0.092664\n",
      "2024-02-29 11:41:02 INFO     Training average positive_sample_loss at step 58000: 0.099576\n",
      "2024-02-29 11:41:02 INFO     Training average negative_sample_loss at step 58000: 0.087056\n",
      "2024-02-29 11:41:02 INFO     Training average loss at step 58000: 0.093316\n",
      "2024-02-29 11:42:34 INFO     Training average positive_sample_loss at step 58100: 0.100268\n",
      "2024-02-29 11:42:34 INFO     Training average negative_sample_loss at step 58100: 0.088395\n",
      "2024-02-29 11:42:34 INFO     Training average loss at step 58100: 0.094331\n",
      "2024-02-29 11:44:10 INFO     Training average positive_sample_loss at step 58200: 0.100704\n",
      "2024-02-29 11:44:10 INFO     Training average negative_sample_loss at step 58200: 0.088215\n",
      "2024-02-29 11:44:10 INFO     Training average loss at step 58200: 0.094459\n",
      "2024-02-29 11:45:48 INFO     Training average positive_sample_loss at step 58300: 0.101083\n",
      "2024-02-29 11:45:48 INFO     Training average negative_sample_loss at step 58300: 0.088943\n",
      "2024-02-29 11:45:48 INFO     Training average loss at step 58300: 0.095013\n",
      "2024-02-29 11:47:36 INFO     Training average positive_sample_loss at step 58400: 0.101189\n",
      "2024-02-29 11:47:36 INFO     Training average negative_sample_loss at step 58400: 0.089219\n",
      "2024-02-29 11:47:36 INFO     Training average loss at step 58400: 0.095204\n",
      "2024-02-29 11:49:30 INFO     Training average positive_sample_loss at step 58500: 0.101626\n",
      "2024-02-29 11:49:30 INFO     Training average negative_sample_loss at step 58500: 0.089439\n",
      "2024-02-29 11:49:30 INFO     Training average loss at step 58500: 0.095533\n",
      "2024-02-29 11:51:38 INFO     Training average positive_sample_loss at step 58600: 0.095451\n",
      "2024-02-29 11:51:38 INFO     Training average negative_sample_loss at step 58600: 0.085882\n",
      "2024-02-29 11:51:38 INFO     Training average loss at step 58600: 0.090667\n",
      "2024-02-29 11:53:40 INFO     Training average positive_sample_loss at step 58700: 0.096397\n",
      "2024-02-29 11:53:40 INFO     Training average negative_sample_loss at step 58700: 0.084163\n",
      "2024-02-29 11:53:40 INFO     Training average loss at step 58700: 0.090280\n",
      "2024-02-29 11:55:29 INFO     Training average positive_sample_loss at step 58800: 0.097582\n",
      "2024-02-29 11:55:29 INFO     Training average negative_sample_loss at step 58800: 0.085027\n",
      "2024-02-29 11:55:29 INFO     Training average loss at step 58800: 0.091304\n",
      "2024-02-29 11:57:25 INFO     Training average positive_sample_loss at step 58900: 0.099291\n",
      "2024-02-29 11:57:25 INFO     Training average negative_sample_loss at step 58900: 0.087122\n",
      "2024-02-29 11:57:25 INFO     Training average loss at step 58900: 0.093207\n",
      "2024-02-29 11:59:11 INFO     Training average positive_sample_loss at step 59000: 0.099512\n",
      "2024-02-29 11:59:11 INFO     Training average negative_sample_loss at step 59000: 0.087031\n",
      "2024-02-29 11:59:11 INFO     Training average loss at step 59000: 0.093272\n",
      "2024-02-29 12:00:57 INFO     Training average positive_sample_loss at step 59100: 0.100470\n",
      "2024-02-29 12:00:57 INFO     Training average negative_sample_loss at step 59100: 0.088314\n",
      "2024-02-29 12:00:57 INFO     Training average loss at step 59100: 0.094392\n",
      "2024-02-29 12:02:56 INFO     Training average positive_sample_loss at step 59200: 0.101448\n",
      "2024-02-29 12:02:56 INFO     Training average negative_sample_loss at step 59200: 0.088810\n",
      "2024-02-29 12:02:56 INFO     Training average loss at step 59200: 0.095129\n",
      "2024-02-29 12:04:48 INFO     Training average positive_sample_loss at step 59300: 0.100793\n",
      "2024-02-29 12:04:48 INFO     Training average negative_sample_loss at step 59300: 0.089097\n",
      "2024-02-29 12:04:48 INFO     Training average loss at step 59300: 0.094945\n",
      "2024-02-29 12:06:52 INFO     Training average positive_sample_loss at step 59400: 0.101372\n",
      "2024-02-29 12:06:52 INFO     Training average negative_sample_loss at step 59400: 0.089046\n",
      "2024-02-29 12:06:52 INFO     Training average loss at step 59400: 0.095209\n",
      "2024-02-29 12:08:49 INFO     Training average positive_sample_loss at step 59500: 0.098447\n",
      "2024-02-29 12:08:49 INFO     Training average negative_sample_loss at step 59500: 0.088649\n",
      "2024-02-29 12:08:49 INFO     Training average loss at step 59500: 0.093548\n",
      "2024-02-29 12:10:25 INFO     Training average positive_sample_loss at step 59600: 0.094586\n",
      "2024-02-29 12:10:25 INFO     Training average negative_sample_loss at step 59600: 0.082773\n",
      "2024-02-29 12:10:25 INFO     Training average loss at step 59600: 0.088680\n",
      "2024-02-29 12:12:13 INFO     Training average positive_sample_loss at step 59700: 0.097259\n",
      "2024-02-29 12:12:13 INFO     Training average negative_sample_loss at step 59700: 0.084811\n",
      "2024-02-29 12:12:13 INFO     Training average loss at step 59700: 0.091035\n",
      "2024-02-29 12:14:00 INFO     Training average positive_sample_loss at step 59800: 0.098550\n",
      "2024-02-29 12:14:00 INFO     Training average negative_sample_loss at step 59800: 0.086069\n",
      "2024-02-29 12:14:00 INFO     Training average loss at step 59800: 0.092310\n",
      "2024-02-29 12:15:37 INFO     Training average positive_sample_loss at step 59900: 0.099720\n",
      "2024-02-29 12:15:37 INFO     Training average negative_sample_loss at step 59900: 0.087534\n",
      "2024-02-29 12:15:37 INFO     Training average loss at step 59900: 0.093627\n",
      "2024-02-29 12:17:15 INFO     Training average positive_sample_loss at step 60000: 0.099792\n",
      "2024-02-29 12:17:15 INFO     Training average negative_sample_loss at step 60000: 0.087719\n",
      "2024-02-29 12:17:15 INFO     Training average loss at step 60000: 0.093756\n",
      "2024-02-29 12:17:15 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 12:17:16 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-29 12:17:50 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-29 12:18:27 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-29 12:19:00 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-29 12:19:32 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-29 12:20:08 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-29 12:20:40 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-29 12:20:47 INFO     Valid MRR at step 60000: 0.423522\n",
      "2024-02-29 12:20:47 INFO     Valid MR at step 60000: 264.040440\n",
      "2024-02-29 12:20:47 INFO     Valid HITS@1 at step 60000: 0.334230\n",
      "2024-02-29 12:20:47 INFO     Valid HITS@3 at step 60000: 0.448790\n",
      "2024-02-29 12:20:47 INFO     Valid HITS@10 at step 60000: 0.623150\n",
      "2024-02-29 12:22:24 INFO     Training average positive_sample_loss at step 60100: 0.101241\n",
      "2024-02-29 12:22:24 INFO     Training average negative_sample_loss at step 60100: 0.088873\n",
      "2024-02-29 12:22:24 INFO     Training average loss at step 60100: 0.095057\n",
      "2024-02-29 12:24:31 INFO     Training average positive_sample_loss at step 60200: 0.100982\n",
      "2024-02-29 12:24:31 INFO     Training average negative_sample_loss at step 60200: 0.088455\n",
      "2024-02-29 12:24:31 INFO     Training average loss at step 60200: 0.094719\n",
      "2024-02-29 12:26:21 INFO     Training average positive_sample_loss at step 60300: 0.101383\n",
      "2024-02-29 12:26:21 INFO     Training average negative_sample_loss at step 60300: 0.089367\n",
      "2024-02-29 12:26:21 INFO     Training average loss at step 60300: 0.095375\n",
      "2024-02-29 12:28:16 INFO     Training average positive_sample_loss at step 60400: 0.100781\n",
      "2024-02-29 12:28:16 INFO     Training average negative_sample_loss at step 60400: 0.088860\n",
      "2024-02-29 12:28:16 INFO     Training average loss at step 60400: 0.094821\n",
      "2024-02-29 12:30:14 INFO     Training average positive_sample_loss at step 60500: 0.094215\n",
      "2024-02-29 12:30:14 INFO     Training average negative_sample_loss at step 60500: 0.084411\n",
      "2024-02-29 12:30:14 INFO     Training average loss at step 60500: 0.089313\n",
      "2024-02-29 12:31:58 INFO     Training average positive_sample_loss at step 60600: 0.096514\n",
      "2024-02-29 12:31:58 INFO     Training average negative_sample_loss at step 60600: 0.084313\n",
      "2024-02-29 12:31:58 INFO     Training average loss at step 60600: 0.090413\n",
      "2024-02-29 12:33:48 INFO     Training average positive_sample_loss at step 60700: 0.097551\n",
      "2024-02-29 12:33:48 INFO     Training average negative_sample_loss at step 60700: 0.085173\n",
      "2024-02-29 12:33:48 INFO     Training average loss at step 60700: 0.091362\n",
      "2024-02-29 12:35:50 INFO     Training average positive_sample_loss at step 60800: 0.099289\n",
      "2024-02-29 12:35:50 INFO     Training average negative_sample_loss at step 60800: 0.086762\n",
      "2024-02-29 12:35:50 INFO     Training average loss at step 60800: 0.093025\n",
      "2024-02-29 12:37:49 INFO     Training average positive_sample_loss at step 60900: 0.099993\n",
      "2024-02-29 12:37:49 INFO     Training average negative_sample_loss at step 60900: 0.087758\n",
      "2024-02-29 12:37:49 INFO     Training average loss at step 60900: 0.093876\n",
      "2024-02-29 12:39:17 INFO     Training average positive_sample_loss at step 61000: 0.100103\n",
      "2024-02-29 12:39:17 INFO     Training average negative_sample_loss at step 61000: 0.087617\n",
      "2024-02-29 12:39:17 INFO     Training average loss at step 61000: 0.093860\n",
      "2024-02-29 12:41:01 INFO     Training average positive_sample_loss at step 61100: 0.101070\n",
      "2024-02-29 12:41:01 INFO     Training average negative_sample_loss at step 61100: 0.088836\n",
      "2024-02-29 12:41:01 INFO     Training average loss at step 61100: 0.094953\n",
      "2024-02-29 12:42:42 INFO     Training average positive_sample_loss at step 61200: 0.100822\n",
      "2024-02-29 12:42:42 INFO     Training average negative_sample_loss at step 61200: 0.088516\n",
      "2024-02-29 12:42:42 INFO     Training average loss at step 61200: 0.094669\n",
      "2024-02-29 12:44:29 INFO     Training average positive_sample_loss at step 61300: 0.100712\n",
      "2024-02-29 12:44:29 INFO     Training average negative_sample_loss at step 61300: 0.088939\n",
      "2024-02-29 12:44:29 INFO     Training average loss at step 61300: 0.094826\n",
      "2024-02-29 12:46:39 INFO     Training average positive_sample_loss at step 61400: 0.096809\n",
      "2024-02-29 12:46:39 INFO     Training average negative_sample_loss at step 61400: 0.087062\n",
      "2024-02-29 12:46:39 INFO     Training average loss at step 61400: 0.091936\n",
      "2024-02-29 12:48:28 INFO     Training average positive_sample_loss at step 61500: 0.095000\n",
      "2024-02-29 12:48:28 INFO     Training average negative_sample_loss at step 61500: 0.082910\n",
      "2024-02-29 12:48:28 INFO     Training average loss at step 61500: 0.088955\n",
      "2024-02-29 12:50:27 INFO     Training average positive_sample_loss at step 61600: 0.097071\n",
      "2024-02-29 12:50:27 INFO     Training average negative_sample_loss at step 61600: 0.084980\n",
      "2024-02-29 12:50:27 INFO     Training average loss at step 61600: 0.091026\n",
      "2024-02-29 12:52:28 INFO     Training average positive_sample_loss at step 61700: 0.098677\n",
      "2024-02-29 12:52:28 INFO     Training average negative_sample_loss at step 61700: 0.086209\n",
      "2024-02-29 12:52:28 INFO     Training average loss at step 61700: 0.092443\n",
      "2024-02-29 12:54:20 INFO     Training average positive_sample_loss at step 61800: 0.099345\n",
      "2024-02-29 12:54:20 INFO     Training average negative_sample_loss at step 61800: 0.087232\n",
      "2024-02-29 12:54:20 INFO     Training average loss at step 61800: 0.093289\n",
      "2024-02-29 12:56:15 INFO     Training average positive_sample_loss at step 61900: 0.100150\n",
      "2024-02-29 12:56:15 INFO     Training average negative_sample_loss at step 61900: 0.087398\n",
      "2024-02-29 12:56:15 INFO     Training average loss at step 61900: 0.093774\n",
      "2024-02-29 12:58:13 INFO     Training average positive_sample_loss at step 62000: 0.100793\n",
      "2024-02-29 12:58:13 INFO     Training average negative_sample_loss at step 62000: 0.088659\n",
      "2024-02-29 12:58:13 INFO     Training average loss at step 62000: 0.094726\n",
      "2024-02-29 13:00:03 INFO     Training average positive_sample_loss at step 62100: 0.100523\n",
      "2024-02-29 13:00:03 INFO     Training average negative_sample_loss at step 62100: 0.088273\n",
      "2024-02-29 13:00:03 INFO     Training average loss at step 62100: 0.094398\n",
      "2024-02-29 13:01:59 INFO     Training average positive_sample_loss at step 62200: 0.101281\n",
      "2024-02-29 13:01:59 INFO     Training average negative_sample_loss at step 62200: 0.089393\n",
      "2024-02-29 13:01:59 INFO     Training average loss at step 62200: 0.095337\n",
      "2024-02-29 13:03:52 INFO     Training average positive_sample_loss at step 62300: 0.100923\n",
      "2024-02-29 13:03:52 INFO     Training average negative_sample_loss at step 62300: 0.089056\n",
      "2024-02-29 13:03:52 INFO     Training average loss at step 62300: 0.094990\n",
      "2024-02-29 13:05:48 INFO     Training average positive_sample_loss at step 62400: 0.093153\n",
      "2024-02-29 13:05:48 INFO     Training average negative_sample_loss at step 62400: 0.083352\n",
      "2024-02-29 13:05:48 INFO     Training average loss at step 62400: 0.088253\n",
      "2024-02-29 13:07:41 INFO     Training average positive_sample_loss at step 62500: 0.096236\n",
      "2024-02-29 13:07:41 INFO     Training average negative_sample_loss at step 62500: 0.083987\n",
      "2024-02-29 13:07:41 INFO     Training average loss at step 62500: 0.090111\n",
      "2024-02-29 13:09:21 INFO     Training average positive_sample_loss at step 62600: 0.098057\n",
      "2024-02-29 13:09:21 INFO     Training average negative_sample_loss at step 62600: 0.085412\n",
      "2024-02-29 13:09:21 INFO     Training average loss at step 62600: 0.091734\n",
      "2024-02-29 13:10:54 INFO     Training average positive_sample_loss at step 62700: 0.099227\n",
      "2024-02-29 13:10:54 INFO     Training average negative_sample_loss at step 62700: 0.087092\n",
      "2024-02-29 13:10:54 INFO     Training average loss at step 62700: 0.093159\n",
      "2024-02-29 13:12:38 INFO     Training average positive_sample_loss at step 62800: 0.099675\n",
      "2024-02-29 13:12:38 INFO     Training average negative_sample_loss at step 62800: 0.087395\n",
      "2024-02-29 13:12:38 INFO     Training average loss at step 62800: 0.093535\n",
      "2024-02-29 13:14:28 INFO     Training average positive_sample_loss at step 62900: 0.100467\n",
      "2024-02-29 13:14:28 INFO     Training average negative_sample_loss at step 62900: 0.088232\n",
      "2024-02-29 13:14:28 INFO     Training average loss at step 62900: 0.094350\n",
      "2024-02-29 13:16:16 INFO     Training average positive_sample_loss at step 63000: 0.100190\n",
      "2024-02-29 13:16:16 INFO     Training average negative_sample_loss at step 63000: 0.088015\n",
      "2024-02-29 13:16:16 INFO     Training average loss at step 63000: 0.094103\n",
      "2024-02-29 13:18:16 INFO     Training average positive_sample_loss at step 63100: 0.100835\n",
      "2024-02-29 13:18:16 INFO     Training average negative_sample_loss at step 63100: 0.088685\n",
      "2024-02-29 13:18:16 INFO     Training average loss at step 63100: 0.094760\n",
      "2024-02-29 13:20:13 INFO     Training average positive_sample_loss at step 63200: 0.100851\n",
      "2024-02-29 13:20:13 INFO     Training average negative_sample_loss at step 63200: 0.088520\n",
      "2024-02-29 13:20:13 INFO     Training average loss at step 63200: 0.094686\n",
      "2024-02-29 13:22:15 INFO     Training average positive_sample_loss at step 63300: 0.095913\n",
      "2024-02-29 13:22:15 INFO     Training average negative_sample_loss at step 63300: 0.086519\n",
      "2024-02-29 13:22:15 INFO     Training average loss at step 63300: 0.091216\n",
      "2024-02-29 13:24:00 INFO     Training average positive_sample_loss at step 63400: 0.095705\n",
      "2024-02-29 13:24:00 INFO     Training average negative_sample_loss at step 63400: 0.083496\n",
      "2024-02-29 13:24:00 INFO     Training average loss at step 63400: 0.089601\n",
      "2024-02-29 13:25:41 INFO     Training average positive_sample_loss at step 63500: 0.096358\n",
      "2024-02-29 13:25:41 INFO     Training average negative_sample_loss at step 63500: 0.084267\n",
      "2024-02-29 13:25:41 INFO     Training average loss at step 63500: 0.090312\n",
      "2024-02-29 13:27:32 INFO     Training average positive_sample_loss at step 63600: 0.098265\n",
      "2024-02-29 13:27:32 INFO     Training average negative_sample_loss at step 63600: 0.086080\n",
      "2024-02-29 13:27:32 INFO     Training average loss at step 63600: 0.092173\n",
      "2024-02-29 13:29:22 INFO     Training average positive_sample_loss at step 63700: 0.099861\n",
      "2024-02-29 13:29:22 INFO     Training average negative_sample_loss at step 63700: 0.087255\n",
      "2024-02-29 13:29:22 INFO     Training average loss at step 63700: 0.093558\n",
      "2024-02-29 13:31:40 INFO     Training average positive_sample_loss at step 63800: 0.100103\n",
      "2024-02-29 13:31:40 INFO     Training average negative_sample_loss at step 63800: 0.087761\n",
      "2024-02-29 13:31:40 INFO     Training average loss at step 63800: 0.093932\n",
      "2024-02-29 13:33:44 INFO     Training average positive_sample_loss at step 63900: 0.099975\n",
      "2024-02-29 13:33:44 INFO     Training average negative_sample_loss at step 63900: 0.088009\n",
      "2024-02-29 13:33:44 INFO     Training average loss at step 63900: 0.093992\n",
      "2024-02-29 13:35:25 INFO     Training average positive_sample_loss at step 64000: 0.100276\n",
      "2024-02-29 13:35:25 INFO     Training average negative_sample_loss at step 64000: 0.088193\n",
      "2024-02-29 13:35:25 INFO     Training average loss at step 64000: 0.094234\n",
      "2024-02-29 13:37:13 INFO     Training average positive_sample_loss at step 64100: 0.101414\n",
      "2024-02-29 13:37:13 INFO     Training average negative_sample_loss at step 64100: 0.088826\n",
      "2024-02-29 13:37:13 INFO     Training average loss at step 64100: 0.095120\n",
      "2024-02-29 13:39:34 INFO     Training average positive_sample_loss at step 64200: 0.099375\n",
      "2024-02-29 13:39:34 INFO     Training average negative_sample_loss at step 64200: 0.088773\n",
      "2024-02-29 13:39:34 INFO     Training average loss at step 64200: 0.094074\n",
      "2024-02-29 13:41:13 INFO     Training average positive_sample_loss at step 64300: 0.093684\n",
      "2024-02-29 13:41:13 INFO     Training average negative_sample_loss at step 64300: 0.082783\n",
      "2024-02-29 13:41:13 INFO     Training average loss at step 64300: 0.088234\n",
      "2024-02-29 13:43:01 INFO     Training average positive_sample_loss at step 64400: 0.096891\n",
      "2024-02-29 13:43:01 INFO     Training average negative_sample_loss at step 64400: 0.084398\n",
      "2024-02-29 13:43:01 INFO     Training average loss at step 64400: 0.090644\n",
      "2024-02-29 13:44:54 INFO     Training average positive_sample_loss at step 64500: 0.097379\n",
      "2024-02-29 13:44:54 INFO     Training average negative_sample_loss at step 64500: 0.085395\n",
      "2024-02-29 13:44:54 INFO     Training average loss at step 64500: 0.091387\n",
      "2024-02-29 13:46:44 INFO     Training average positive_sample_loss at step 64600: 0.098665\n",
      "2024-02-29 13:46:44 INFO     Training average negative_sample_loss at step 64600: 0.086329\n",
      "2024-02-29 13:46:44 INFO     Training average loss at step 64600: 0.092497\n",
      "2024-02-29 13:48:30 INFO     Training average positive_sample_loss at step 64700: 0.099474\n",
      "2024-02-29 13:48:30 INFO     Training average negative_sample_loss at step 64700: 0.087174\n",
      "2024-02-29 13:48:30 INFO     Training average loss at step 64700: 0.093324\n",
      "2024-02-29 13:50:06 INFO     Training average positive_sample_loss at step 64800: 0.100200\n",
      "2024-02-29 13:50:06 INFO     Training average negative_sample_loss at step 64800: 0.088137\n",
      "2024-02-29 13:50:06 INFO     Training average loss at step 64800: 0.094168\n",
      "2024-02-29 13:51:56 INFO     Training average positive_sample_loss at step 64900: 0.100807\n",
      "2024-02-29 13:51:56 INFO     Training average negative_sample_loss at step 64900: 0.088234\n",
      "2024-02-29 13:51:56 INFO     Training average loss at step 64900: 0.094520\n",
      "2024-02-29 13:53:38 INFO     Training average positive_sample_loss at step 65000: 0.100056\n",
      "2024-02-29 13:53:38 INFO     Training average negative_sample_loss at step 65000: 0.088100\n",
      "2024-02-29 13:53:38 INFO     Training average loss at step 65000: 0.094078\n",
      "2024-02-29 13:55:26 INFO     Training average positive_sample_loss at step 65100: 0.100599\n",
      "2024-02-29 13:55:26 INFO     Training average negative_sample_loss at step 65100: 0.088577\n",
      "2024-02-29 13:55:26 INFO     Training average loss at step 65100: 0.094588\n",
      "2024-02-29 13:57:15 INFO     Training average positive_sample_loss at step 65200: 0.094777\n",
      "2024-02-29 13:57:15 INFO     Training average negative_sample_loss at step 65200: 0.084994\n",
      "2024-02-29 13:57:15 INFO     Training average loss at step 65200: 0.089885\n",
      "2024-02-29 13:59:01 INFO     Training average positive_sample_loss at step 65300: 0.095384\n",
      "2024-02-29 13:59:01 INFO     Training average negative_sample_loss at step 65300: 0.083193\n",
      "2024-02-29 13:59:01 INFO     Training average loss at step 65300: 0.089289\n",
      "2024-02-29 14:00:51 INFO     Training average positive_sample_loss at step 65400: 0.097067\n",
      "2024-02-29 14:00:51 INFO     Training average negative_sample_loss at step 65400: 0.084869\n",
      "2024-02-29 14:00:51 INFO     Training average loss at step 65400: 0.090968\n",
      "2024-02-29 14:02:38 INFO     Training average positive_sample_loss at step 65500: 0.098144\n",
      "2024-02-29 14:02:38 INFO     Training average negative_sample_loss at step 65500: 0.085746\n",
      "2024-02-29 14:02:38 INFO     Training average loss at step 65500: 0.091945\n",
      "2024-02-29 14:04:19 INFO     Training average positive_sample_loss at step 65600: 0.099039\n",
      "2024-02-29 14:04:19 INFO     Training average negative_sample_loss at step 65600: 0.086964\n",
      "2024-02-29 14:04:19 INFO     Training average loss at step 65600: 0.093002\n",
      "2024-02-29 14:06:08 INFO     Training average positive_sample_loss at step 65700: 0.099704\n",
      "2024-02-29 14:06:08 INFO     Training average negative_sample_loss at step 65700: 0.087484\n",
      "2024-02-29 14:06:08 INFO     Training average loss at step 65700: 0.093594\n",
      "2024-02-29 14:07:57 INFO     Training average positive_sample_loss at step 65800: 0.100552\n",
      "2024-02-29 14:07:57 INFO     Training average negative_sample_loss at step 65800: 0.088207\n",
      "2024-02-29 14:07:57 INFO     Training average loss at step 65800: 0.094379\n",
      "2024-02-29 14:09:43 INFO     Training average positive_sample_loss at step 65900: 0.100271\n",
      "2024-02-29 14:09:43 INFO     Training average negative_sample_loss at step 65900: 0.088068\n",
      "2024-02-29 14:09:43 INFO     Training average loss at step 65900: 0.094170\n",
      "2024-02-29 14:11:33 INFO     Training average positive_sample_loss at step 66000: 0.101019\n",
      "2024-02-29 14:11:33 INFO     Training average negative_sample_loss at step 66000: 0.088914\n",
      "2024-02-29 14:11:33 INFO     Training average loss at step 66000: 0.094967\n",
      "2024-02-29 14:13:26 INFO     Training average positive_sample_loss at step 66100: 0.098204\n",
      "2024-02-29 14:13:26 INFO     Training average negative_sample_loss at step 66100: 0.088139\n",
      "2024-02-29 14:13:26 INFO     Training average loss at step 66100: 0.093171\n",
      "2024-02-29 14:15:10 INFO     Training average positive_sample_loss at step 66200: 0.094443\n",
      "2024-02-29 14:15:10 INFO     Training average negative_sample_loss at step 66200: 0.082470\n",
      "2024-02-29 14:15:10 INFO     Training average loss at step 66200: 0.088457\n",
      "2024-02-29 14:16:48 INFO     Training average positive_sample_loss at step 66300: 0.096519\n",
      "2024-02-29 14:16:48 INFO     Training average negative_sample_loss at step 66300: 0.084304\n",
      "2024-02-29 14:16:48 INFO     Training average loss at step 66300: 0.090411\n",
      "2024-02-29 14:18:39 INFO     Training average positive_sample_loss at step 66400: 0.097116\n",
      "2024-02-29 14:18:39 INFO     Training average negative_sample_loss at step 66400: 0.084855\n",
      "2024-02-29 14:18:39 INFO     Training average loss at step 66400: 0.090986\n",
      "2024-02-29 14:20:30 INFO     Training average positive_sample_loss at step 66500: 0.098548\n",
      "2024-02-29 14:20:30 INFO     Training average negative_sample_loss at step 66500: 0.086460\n",
      "2024-02-29 14:20:30 INFO     Training average loss at step 66500: 0.092504\n",
      "2024-02-29 14:22:21 INFO     Training average positive_sample_loss at step 66600: 0.099679\n",
      "2024-02-29 14:22:21 INFO     Training average negative_sample_loss at step 66600: 0.087325\n",
      "2024-02-29 14:22:21 INFO     Training average loss at step 66600: 0.093502\n",
      "2024-02-29 14:24:14 INFO     Training average positive_sample_loss at step 66700: 0.099686\n",
      "2024-02-29 14:24:14 INFO     Training average negative_sample_loss at step 66700: 0.087276\n",
      "2024-02-29 14:24:14 INFO     Training average loss at step 66700: 0.093481\n",
      "2024-02-29 14:25:51 INFO     Training average positive_sample_loss at step 66800: 0.100593\n",
      "2024-02-29 14:25:51 INFO     Training average negative_sample_loss at step 66800: 0.088190\n",
      "2024-02-29 14:25:51 INFO     Training average loss at step 66800: 0.094392\n",
      "2024-02-29 14:27:26 INFO     Training average positive_sample_loss at step 66900: 0.100106\n",
      "2024-02-29 14:27:26 INFO     Training average negative_sample_loss at step 66900: 0.088285\n",
      "2024-02-29 14:27:26 INFO     Training average loss at step 66900: 0.094196\n",
      "2024-02-29 14:29:17 INFO     Training average positive_sample_loss at step 67000: 0.100400\n",
      "2024-02-29 14:29:17 INFO     Training average negative_sample_loss at step 67000: 0.088146\n",
      "2024-02-29 14:29:17 INFO     Training average loss at step 67000: 0.094273\n",
      "2024-02-29 14:31:16 INFO     Training average positive_sample_loss at step 67100: 0.093750\n",
      "2024-02-29 14:31:16 INFO     Training average negative_sample_loss at step 67100: 0.084088\n",
      "2024-02-29 14:31:16 INFO     Training average loss at step 67100: 0.088919\n",
      "2024-02-29 14:33:12 INFO     Training average positive_sample_loss at step 67200: 0.095261\n",
      "2024-02-29 14:33:12 INFO     Training average negative_sample_loss at step 67200: 0.083064\n",
      "2024-02-29 14:33:12 INFO     Training average loss at step 67200: 0.089162\n",
      "2024-02-29 14:34:48 INFO     Training average positive_sample_loss at step 67300: 0.096854\n",
      "2024-02-29 14:34:48 INFO     Training average negative_sample_loss at step 67300: 0.084668\n",
      "2024-02-29 14:34:48 INFO     Training average loss at step 67300: 0.090761\n",
      "2024-02-29 14:36:37 INFO     Training average positive_sample_loss at step 67400: 0.098364\n",
      "2024-02-29 14:36:37 INFO     Training average negative_sample_loss at step 67400: 0.086165\n",
      "2024-02-29 14:36:37 INFO     Training average loss at step 67400: 0.092265\n",
      "2024-02-29 14:38:36 INFO     Training average positive_sample_loss at step 67500: 0.099195\n",
      "2024-02-29 14:38:36 INFO     Training average negative_sample_loss at step 67500: 0.086576\n",
      "2024-02-29 14:38:36 INFO     Training average loss at step 67500: 0.092886\n",
      "2024-02-29 14:40:14 INFO     Training average positive_sample_loss at step 67600: 0.099540\n",
      "2024-02-29 14:40:14 INFO     Training average negative_sample_loss at step 67600: 0.087099\n",
      "2024-02-29 14:40:14 INFO     Training average loss at step 67600: 0.093320\n",
      "2024-02-29 14:41:41 INFO     Training average positive_sample_loss at step 67700: 0.099932\n",
      "2024-02-29 14:41:41 INFO     Training average negative_sample_loss at step 67700: 0.087639\n",
      "2024-02-29 14:41:41 INFO     Training average loss at step 67700: 0.093785\n",
      "2024-02-29 14:43:31 INFO     Training average positive_sample_loss at step 67800: 0.100334\n",
      "2024-02-29 14:43:31 INFO     Training average negative_sample_loss at step 67800: 0.088313\n",
      "2024-02-29 14:43:31 INFO     Training average loss at step 67800: 0.094324\n",
      "2024-02-29 14:45:39 INFO     Training average positive_sample_loss at step 67900: 0.100672\n",
      "2024-02-29 14:45:39 INFO     Training average negative_sample_loss at step 67900: 0.088736\n",
      "2024-02-29 14:45:39 INFO     Training average loss at step 67900: 0.094704\n",
      "2024-02-29 14:47:50 INFO     Training average positive_sample_loss at step 68000: 0.097267\n",
      "2024-02-29 14:47:50 INFO     Training average negative_sample_loss at step 68000: 0.087194\n",
      "2024-02-29 14:47:50 INFO     Training average loss at step 68000: 0.092230\n",
      "2024-02-29 14:49:27 INFO     Training average positive_sample_loss at step 68100: 0.093614\n",
      "2024-02-29 14:49:27 INFO     Training average negative_sample_loss at step 68100: 0.081802\n",
      "2024-02-29 14:49:27 INFO     Training average loss at step 68100: 0.087708\n",
      "2024-02-29 14:51:07 INFO     Training average positive_sample_loss at step 68200: 0.096707\n",
      "2024-02-29 14:51:07 INFO     Training average negative_sample_loss at step 68200: 0.084348\n",
      "2024-02-29 14:51:07 INFO     Training average loss at step 68200: 0.090527\n",
      "2024-02-29 14:53:06 INFO     Training average positive_sample_loss at step 68300: 0.098289\n",
      "2024-02-29 14:53:06 INFO     Training average negative_sample_loss at step 68300: 0.085615\n",
      "2024-02-29 14:53:06 INFO     Training average loss at step 68300: 0.091952\n",
      "2024-02-29 14:54:56 INFO     Training average positive_sample_loss at step 68400: 0.097892\n",
      "2024-02-29 14:54:56 INFO     Training average negative_sample_loss at step 68400: 0.085780\n",
      "2024-02-29 14:54:56 INFO     Training average loss at step 68400: 0.091836\n",
      "2024-02-29 14:56:54 INFO     Training average positive_sample_loss at step 68500: 0.099329\n",
      "2024-02-29 14:56:54 INFO     Training average negative_sample_loss at step 68500: 0.086995\n",
      "2024-02-29 14:56:54 INFO     Training average loss at step 68500: 0.093162\n",
      "2024-02-29 14:58:45 INFO     Training average positive_sample_loss at step 68600: 0.100335\n",
      "2024-02-29 14:58:45 INFO     Training average negative_sample_loss at step 68600: 0.087886\n",
      "2024-02-29 14:58:45 INFO     Training average loss at step 68600: 0.094110\n",
      "2024-02-29 15:00:34 INFO     Training average positive_sample_loss at step 68700: 0.099907\n",
      "2024-02-29 15:00:34 INFO     Training average negative_sample_loss at step 68700: 0.087787\n",
      "2024-02-29 15:00:34 INFO     Training average loss at step 68700: 0.093847\n",
      "2024-02-29 15:02:22 INFO     Training average positive_sample_loss at step 68800: 0.100342\n",
      "2024-02-29 15:02:22 INFO     Training average negative_sample_loss at step 68800: 0.088218\n",
      "2024-02-29 15:02:22 INFO     Training average loss at step 68800: 0.094280\n",
      "2024-02-29 15:04:21 INFO     Training average positive_sample_loss at step 68900: 0.100602\n",
      "2024-02-29 15:04:21 INFO     Training average negative_sample_loss at step 68900: 0.088353\n",
      "2024-02-29 15:04:21 INFO     Training average loss at step 68900: 0.094477\n",
      "2024-02-29 15:06:31 INFO     Training average positive_sample_loss at step 69000: 0.093350\n",
      "2024-02-29 15:06:31 INFO     Training average negative_sample_loss at step 69000: 0.083811\n",
      "2024-02-29 15:06:31 INFO     Training average loss at step 69000: 0.088580\n",
      "2024-02-29 15:08:43 INFO     Training average positive_sample_loss at step 69100: 0.095631\n",
      "2024-02-29 15:08:43 INFO     Training average negative_sample_loss at step 69100: 0.083474\n",
      "2024-02-29 15:08:43 INFO     Training average loss at step 69100: 0.089552\n",
      "2024-02-29 15:10:30 INFO     Training average positive_sample_loss at step 69200: 0.096569\n",
      "2024-02-29 15:10:30 INFO     Training average negative_sample_loss at step 69200: 0.084462\n",
      "2024-02-29 15:10:30 INFO     Training average loss at step 69200: 0.090515\n",
      "2024-02-29 15:12:23 INFO     Training average positive_sample_loss at step 69300: 0.097885\n",
      "2024-02-29 15:12:23 INFO     Training average negative_sample_loss at step 69300: 0.085569\n",
      "2024-02-29 15:12:23 INFO     Training average loss at step 69300: 0.091727\n",
      "2024-02-29 15:14:15 INFO     Training average positive_sample_loss at step 69400: 0.099013\n",
      "2024-02-29 15:14:15 INFO     Training average negative_sample_loss at step 69400: 0.086619\n",
      "2024-02-29 15:14:15 INFO     Training average loss at step 69400: 0.092816\n",
      "2024-02-29 15:16:03 INFO     Training average positive_sample_loss at step 69500: 0.099228\n",
      "2024-02-29 15:16:03 INFO     Training average negative_sample_loss at step 69500: 0.086988\n",
      "2024-02-29 15:16:03 INFO     Training average loss at step 69500: 0.093108\n",
      "2024-02-29 15:17:55 INFO     Training average positive_sample_loss at step 69600: 0.100333\n",
      "2024-02-29 15:17:55 INFO     Training average negative_sample_loss at step 69600: 0.087891\n",
      "2024-02-29 15:17:55 INFO     Training average loss at step 69600: 0.094112\n",
      "2024-02-29 15:19:52 INFO     Training average positive_sample_loss at step 69700: 0.100193\n",
      "2024-02-29 15:19:52 INFO     Training average negative_sample_loss at step 69700: 0.088379\n",
      "2024-02-29 15:19:52 INFO     Training average loss at step 69700: 0.094286\n",
      "2024-02-29 15:21:42 INFO     Training average positive_sample_loss at step 69800: 0.100515\n",
      "2024-02-29 15:21:42 INFO     Training average negative_sample_loss at step 69800: 0.088252\n",
      "2024-02-29 15:21:42 INFO     Training average loss at step 69800: 0.094384\n",
      "2024-02-29 15:23:57 INFO     Training average positive_sample_loss at step 69900: 0.095963\n",
      "2024-02-29 15:23:57 INFO     Training average negative_sample_loss at step 69900: 0.086175\n",
      "2024-02-29 15:23:57 INFO     Training average loss at step 69900: 0.091069\n",
      "2024-02-29 15:25:56 INFO     Training average positive_sample_loss at step 70000: 0.094261\n",
      "2024-02-29 15:25:56 INFO     Training average negative_sample_loss at step 70000: 0.082387\n",
      "2024-02-29 15:25:56 INFO     Training average loss at step 70000: 0.088324\n",
      "2024-02-29 15:25:56 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 15:25:57 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-29 15:26:31 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-29 15:27:09 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-29 15:27:43 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-29 15:28:14 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-29 15:28:53 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-29 15:29:24 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-29 15:29:32 INFO     Valid MRR at step 70000: 0.429039\n",
      "2024-02-29 15:29:32 INFO     Valid MR at step 70000: 257.887500\n",
      "2024-02-29 15:29:32 INFO     Valid HITS@1 at step 70000: 0.337810\n",
      "2024-02-29 15:29:32 INFO     Valid HITS@3 at step 70000: 0.455420\n",
      "2024-02-29 15:29:32 INFO     Valid HITS@10 at step 70000: 0.632510\n",
      "2024-02-29 15:31:11 INFO     Training average positive_sample_loss at step 70100: 0.096441\n",
      "2024-02-29 15:31:11 INFO     Training average negative_sample_loss at step 70100: 0.083884\n",
      "2024-02-29 15:31:11 INFO     Training average loss at step 70100: 0.090162\n",
      "2024-02-29 15:33:02 INFO     Training average positive_sample_loss at step 70200: 0.098024\n",
      "2024-02-29 15:33:02 INFO     Training average negative_sample_loss at step 70200: 0.085698\n",
      "2024-02-29 15:33:02 INFO     Training average loss at step 70200: 0.091861\n",
      "2024-02-29 15:34:50 INFO     Training average positive_sample_loss at step 70300: 0.098451\n",
      "2024-02-29 15:34:50 INFO     Training average negative_sample_loss at step 70300: 0.086214\n",
      "2024-02-29 15:34:50 INFO     Training average loss at step 70300: 0.092332\n",
      "2024-02-29 15:36:39 INFO     Training average positive_sample_loss at step 70400: 0.098827\n",
      "2024-02-29 15:36:39 INFO     Training average negative_sample_loss at step 70400: 0.086655\n",
      "2024-02-29 15:36:39 INFO     Training average loss at step 70400: 0.092741\n",
      "2024-02-29 15:38:35 INFO     Training average positive_sample_loss at step 70500: 0.099525\n",
      "2024-02-29 15:38:35 INFO     Training average negative_sample_loss at step 70500: 0.087040\n",
      "2024-02-29 15:38:35 INFO     Training average loss at step 70500: 0.093282\n",
      "2024-02-29 15:40:34 INFO     Training average positive_sample_loss at step 70600: 0.099409\n",
      "2024-02-29 15:40:34 INFO     Training average negative_sample_loss at step 70600: 0.087628\n",
      "2024-02-29 15:40:34 INFO     Training average loss at step 70600: 0.093518\n",
      "2024-02-29 15:42:19 INFO     Training average positive_sample_loss at step 70700: 0.100647\n",
      "2024-02-29 15:42:19 INFO     Training average negative_sample_loss at step 70700: 0.088492\n",
      "2024-02-29 15:42:19 INFO     Training average loss at step 70700: 0.094570\n",
      "2024-02-29 15:44:15 INFO     Training average positive_sample_loss at step 70800: 0.100237\n",
      "2024-02-29 15:44:15 INFO     Training average negative_sample_loss at step 70800: 0.088261\n",
      "2024-02-29 15:44:15 INFO     Training average loss at step 70800: 0.094249\n",
      "2024-02-29 15:45:48 INFO     Training average positive_sample_loss at step 70900: 0.092461\n",
      "2024-02-29 15:45:48 INFO     Training average negative_sample_loss at step 70900: 0.082666\n",
      "2024-02-29 15:45:48 INFO     Training average loss at step 70900: 0.087563\n",
      "2024-02-29 15:47:32 INFO     Training average positive_sample_loss at step 71000: 0.095298\n",
      "2024-02-29 15:47:32 INFO     Training average negative_sample_loss at step 71000: 0.083207\n",
      "2024-02-29 15:47:32 INFO     Training average loss at step 71000: 0.089252\n",
      "2024-02-29 15:49:27 INFO     Training average positive_sample_loss at step 71100: 0.097175\n",
      "2024-02-29 15:49:27 INFO     Training average negative_sample_loss at step 71100: 0.084671\n",
      "2024-02-29 15:49:27 INFO     Training average loss at step 71100: 0.090923\n",
      "2024-02-29 15:51:14 INFO     Training average positive_sample_loss at step 71200: 0.097787\n",
      "2024-02-29 15:51:14 INFO     Training average negative_sample_loss at step 71200: 0.085306\n",
      "2024-02-29 15:51:14 INFO     Training average loss at step 71200: 0.091546\n",
      "2024-02-29 15:53:01 INFO     Training average positive_sample_loss at step 71300: 0.099066\n",
      "2024-02-29 15:53:01 INFO     Training average negative_sample_loss at step 71300: 0.086869\n",
      "2024-02-29 15:53:01 INFO     Training average loss at step 71300: 0.092967\n",
      "2024-02-29 15:54:55 INFO     Training average positive_sample_loss at step 71400: 0.099499\n",
      "2024-02-29 15:54:55 INFO     Training average negative_sample_loss at step 71400: 0.087441\n",
      "2024-02-29 15:54:55 INFO     Training average loss at step 71400: 0.093470\n",
      "2024-02-29 15:56:48 INFO     Training average positive_sample_loss at step 71500: 0.099313\n",
      "2024-02-29 15:56:48 INFO     Training average negative_sample_loss at step 71500: 0.087291\n",
      "2024-02-29 15:56:48 INFO     Training average loss at step 71500: 0.093302\n",
      "2024-02-29 15:58:37 INFO     Training average positive_sample_loss at step 71600: 0.100243\n",
      "2024-02-29 15:58:37 INFO     Training average negative_sample_loss at step 71600: 0.087970\n",
      "2024-02-29 15:58:37 INFO     Training average loss at step 71600: 0.094106\n",
      "2024-02-29 16:00:26 INFO     Training average positive_sample_loss at step 71700: 0.100029\n",
      "2024-02-29 16:00:26 INFO     Training average negative_sample_loss at step 71700: 0.087915\n",
      "2024-02-29 16:00:26 INFO     Training average loss at step 71700: 0.093972\n",
      "2024-02-29 16:02:24 INFO     Training average positive_sample_loss at step 71800: 0.094696\n",
      "2024-02-29 16:02:24 INFO     Training average negative_sample_loss at step 71800: 0.084896\n",
      "2024-02-29 16:02:24 INFO     Training average loss at step 71800: 0.089796\n",
      "2024-02-29 16:04:11 INFO     Training average positive_sample_loss at step 71900: 0.093956\n",
      "2024-02-29 16:04:11 INFO     Training average negative_sample_loss at step 71900: 0.082001\n",
      "2024-02-29 16:04:11 INFO     Training average loss at step 71900: 0.087978\n",
      "2024-02-29 16:05:47 INFO     Training average positive_sample_loss at step 72000: 0.096554\n",
      "2024-02-29 16:05:47 INFO     Training average negative_sample_loss at step 72000: 0.084162\n",
      "2024-02-29 16:05:47 INFO     Training average loss at step 72000: 0.090358\n",
      "2024-02-29 16:07:34 INFO     Training average positive_sample_loss at step 72100: 0.097770\n",
      "2024-02-29 16:07:34 INFO     Training average negative_sample_loss at step 72100: 0.085356\n",
      "2024-02-29 16:07:34 INFO     Training average loss at step 72100: 0.091563\n",
      "2024-02-29 16:09:12 INFO     Training average positive_sample_loss at step 72200: 0.098536\n",
      "2024-02-29 16:09:12 INFO     Training average negative_sample_loss at step 72200: 0.086293\n",
      "2024-02-29 16:09:12 INFO     Training average loss at step 72200: 0.092415\n",
      "2024-02-29 16:11:01 INFO     Training average positive_sample_loss at step 72300: 0.099050\n",
      "2024-02-29 16:11:01 INFO     Training average negative_sample_loss at step 72300: 0.086968\n",
      "2024-02-29 16:11:01 INFO     Training average loss at step 72300: 0.093009\n",
      "2024-02-29 16:12:47 INFO     Training average positive_sample_loss at step 72400: 0.099448\n",
      "2024-02-29 16:12:47 INFO     Training average negative_sample_loss at step 72400: 0.087149\n",
      "2024-02-29 16:12:47 INFO     Training average loss at step 72400: 0.093298\n",
      "2024-02-29 16:14:35 INFO     Training average positive_sample_loss at step 72500: 0.100190\n",
      "2024-02-29 16:14:35 INFO     Training average negative_sample_loss at step 72500: 0.087910\n",
      "2024-02-29 16:14:35 INFO     Training average loss at step 72500: 0.094050\n",
      "2024-02-29 16:16:30 INFO     Training average positive_sample_loss at step 72600: 0.099873\n",
      "2024-02-29 16:16:30 INFO     Training average negative_sample_loss at step 72600: 0.087518\n",
      "2024-02-29 16:16:30 INFO     Training average loss at step 72600: 0.093695\n",
      "2024-02-29 16:18:29 INFO     Training average positive_sample_loss at step 72700: 0.098674\n",
      "2024-02-29 16:18:29 INFO     Training average negative_sample_loss at step 72700: 0.088088\n",
      "2024-02-29 16:18:29 INFO     Training average loss at step 72700: 0.093381\n",
      "2024-02-29 16:20:03 INFO     Training average positive_sample_loss at step 72800: 0.093322\n",
      "2024-02-29 16:20:03 INFO     Training average negative_sample_loss at step 72800: 0.082103\n",
      "2024-02-29 16:20:03 INFO     Training average loss at step 72800: 0.087712\n",
      "2024-02-29 16:21:59 INFO     Training average positive_sample_loss at step 72900: 0.095266\n",
      "2024-02-29 16:21:59 INFO     Training average negative_sample_loss at step 72900: 0.083044\n",
      "2024-02-29 16:21:59 INFO     Training average loss at step 72900: 0.089155\n",
      "2024-02-29 16:24:05 INFO     Training average positive_sample_loss at step 73000: 0.097362\n",
      "2024-02-29 16:24:05 INFO     Training average negative_sample_loss at step 73000: 0.084848\n",
      "2024-02-29 16:24:05 INFO     Training average loss at step 73000: 0.091105\n",
      "2024-02-29 16:25:55 INFO     Training average positive_sample_loss at step 73100: 0.097904\n",
      "2024-02-29 16:25:55 INFO     Training average negative_sample_loss at step 73100: 0.085652\n",
      "2024-02-29 16:25:55 INFO     Training average loss at step 73100: 0.091778\n",
      "2024-02-29 16:27:56 INFO     Training average positive_sample_loss at step 73200: 0.098910\n",
      "2024-02-29 16:27:56 INFO     Training average negative_sample_loss at step 73200: 0.086647\n",
      "2024-02-29 16:27:56 INFO     Training average loss at step 73200: 0.092779\n",
      "2024-02-29 16:29:51 INFO     Training average positive_sample_loss at step 73300: 0.099465\n",
      "2024-02-29 16:29:51 INFO     Training average negative_sample_loss at step 73300: 0.087074\n",
      "2024-02-29 16:29:51 INFO     Training average loss at step 73300: 0.093269\n",
      "2024-02-29 16:31:43 INFO     Training average positive_sample_loss at step 73400: 0.099471\n",
      "2024-02-29 16:31:43 INFO     Training average negative_sample_loss at step 73400: 0.087418\n",
      "2024-02-29 16:31:43 INFO     Training average loss at step 73400: 0.093444\n",
      "2024-02-29 16:33:29 INFO     Training average positive_sample_loss at step 73500: 0.099619\n",
      "2024-02-29 16:33:29 INFO     Training average negative_sample_loss at step 73500: 0.087246\n",
      "2024-02-29 16:33:29 INFO     Training average loss at step 73500: 0.093433\n",
      "2024-02-29 16:35:25 INFO     Training average positive_sample_loss at step 73600: 0.099528\n",
      "2024-02-29 16:35:25 INFO     Training average negative_sample_loss at step 73600: 0.087465\n",
      "2024-02-29 16:35:25 INFO     Training average loss at step 73600: 0.093497\n",
      "2024-02-29 16:37:15 INFO     Training average positive_sample_loss at step 73700: 0.094023\n",
      "2024-02-29 16:37:15 INFO     Training average negative_sample_loss at step 73700: 0.084401\n",
      "2024-02-29 16:37:15 INFO     Training average loss at step 73700: 0.089212\n",
      "2024-02-29 16:39:04 INFO     Training average positive_sample_loss at step 73800: 0.095086\n",
      "2024-02-29 16:39:04 INFO     Training average negative_sample_loss at step 73800: 0.083018\n",
      "2024-02-29 16:39:04 INFO     Training average loss at step 73800: 0.089052\n",
      "2024-02-29 16:40:55 INFO     Training average positive_sample_loss at step 73900: 0.096368\n",
      "2024-02-29 16:40:55 INFO     Training average negative_sample_loss at step 73900: 0.083833\n",
      "2024-02-29 16:40:55 INFO     Training average loss at step 73900: 0.090100\n",
      "2024-02-29 16:42:31 INFO     Training average positive_sample_loss at step 74000: 0.097874\n",
      "2024-02-29 16:42:31 INFO     Training average negative_sample_loss at step 74000: 0.085337\n",
      "2024-02-29 16:42:31 INFO     Training average loss at step 74000: 0.091606\n",
      "2024-02-29 16:44:00 INFO     Training average positive_sample_loss at step 74100: 0.098649\n",
      "2024-02-29 16:44:00 INFO     Training average negative_sample_loss at step 74100: 0.086372\n",
      "2024-02-29 16:44:00 INFO     Training average loss at step 74100: 0.092510\n",
      "2024-02-29 16:45:30 INFO     Training average positive_sample_loss at step 74200: 0.099279\n",
      "2024-02-29 16:45:30 INFO     Training average negative_sample_loss at step 74200: 0.086949\n",
      "2024-02-29 16:45:30 INFO     Training average loss at step 74200: 0.093114\n",
      "2024-02-29 16:47:23 INFO     Training average positive_sample_loss at step 74300: 0.099122\n",
      "2024-02-29 16:47:23 INFO     Training average negative_sample_loss at step 74300: 0.087257\n",
      "2024-02-29 16:47:23 INFO     Training average loss at step 74300: 0.093190\n",
      "2024-02-29 16:49:02 INFO     Training average positive_sample_loss at step 74400: 0.099228\n",
      "2024-02-29 16:49:02 INFO     Training average negative_sample_loss at step 74400: 0.087002\n",
      "2024-02-29 16:49:02 INFO     Training average loss at step 74400: 0.093115\n",
      "2024-02-29 16:50:44 INFO     Training average positive_sample_loss at step 74500: 0.099569\n",
      "2024-02-29 16:50:44 INFO     Training average negative_sample_loss at step 74500: 0.087535\n",
      "2024-02-29 16:50:44 INFO     Training average loss at step 74500: 0.093552\n",
      "2024-02-29 16:52:30 INFO     Training average positive_sample_loss at step 74600: 0.096924\n",
      "2024-02-29 16:52:30 INFO     Training average negative_sample_loss at step 74600: 0.086620\n",
      "2024-02-29 16:52:30 INFO     Training average loss at step 74600: 0.091772\n",
      "2024-02-29 16:54:11 INFO     Training average positive_sample_loss at step 74700: 0.093699\n",
      "2024-02-29 16:54:11 INFO     Training average negative_sample_loss at step 74700: 0.081913\n",
      "2024-02-29 16:54:11 INFO     Training average loss at step 74700: 0.087806\n",
      "2024-02-29 16:55:48 INFO     Training average positive_sample_loss at step 74800: 0.095520\n",
      "2024-02-29 16:55:48 INFO     Training average negative_sample_loss at step 74800: 0.083351\n",
      "2024-02-29 16:55:48 INFO     Training average loss at step 74800: 0.089435\n",
      "2024-02-29 16:57:35 INFO     Training average positive_sample_loss at step 74900: 0.097201\n",
      "2024-02-29 16:57:35 INFO     Training average negative_sample_loss at step 74900: 0.084727\n",
      "2024-02-29 16:57:35 INFO     Training average loss at step 74900: 0.090964\n",
      "2024-02-29 16:59:21 INFO     Change learning_rate to 0.000010 at step 75000\n",
      "2024-02-29 16:59:21 INFO     Training average positive_sample_loss at step 75000: 0.097450\n",
      "2024-02-29 16:59:21 INFO     Training average negative_sample_loss at step 75000: 0.085117\n",
      "2024-02-29 16:59:21 INFO     Training average loss at step 75000: 0.091283\n",
      "2024-02-29 17:00:47 INFO     Training average positive_sample_loss at step 75100: 0.101778\n",
      "2024-02-29 17:00:47 INFO     Training average negative_sample_loss at step 75100: 0.082143\n",
      "2024-02-29 17:00:47 INFO     Training average loss at step 75100: 0.091960\n",
      "2024-02-29 17:02:36 INFO     Training average positive_sample_loss at step 75200: 0.099062\n",
      "2024-02-29 17:02:36 INFO     Training average negative_sample_loss at step 75200: 0.081949\n",
      "2024-02-29 17:02:36 INFO     Training average loss at step 75200: 0.090505\n",
      "2024-02-29 17:04:19 INFO     Training average positive_sample_loss at step 75300: 0.097098\n",
      "2024-02-29 17:04:19 INFO     Training average negative_sample_loss at step 75300: 0.082517\n",
      "2024-02-29 17:04:19 INFO     Training average loss at step 75300: 0.089808\n",
      "2024-02-29 17:06:08 INFO     Training average positive_sample_loss at step 75400: 0.095796\n",
      "2024-02-29 17:06:08 INFO     Training average negative_sample_loss at step 75400: 0.082065\n",
      "2024-02-29 17:06:08 INFO     Training average loss at step 75400: 0.088930\n",
      "2024-02-29 17:07:39 INFO     Training average positive_sample_loss at step 75500: 0.094820\n",
      "2024-02-29 17:07:39 INFO     Training average negative_sample_loss at step 75500: 0.082350\n",
      "2024-02-29 17:07:39 INFO     Training average loss at step 75500: 0.088585\n",
      "2024-02-29 17:09:33 INFO     Training average positive_sample_loss at step 75600: 0.086390\n",
      "2024-02-29 17:09:33 INFO     Training average negative_sample_loss at step 75600: 0.080730\n",
      "2024-02-29 17:09:33 INFO     Training average loss at step 75600: 0.083560\n",
      "2024-02-29 17:11:13 INFO     Training average positive_sample_loss at step 75700: 0.086618\n",
      "2024-02-29 17:11:13 INFO     Training average negative_sample_loss at step 75700: 0.078783\n",
      "2024-02-29 17:11:13 INFO     Training average loss at step 75700: 0.082700\n",
      "2024-02-29 17:13:05 INFO     Training average positive_sample_loss at step 75800: 0.087311\n",
      "2024-02-29 17:13:05 INFO     Training average negative_sample_loss at step 75800: 0.077986\n",
      "2024-02-29 17:13:05 INFO     Training average loss at step 75800: 0.082649\n",
      "2024-02-29 17:14:59 INFO     Training average positive_sample_loss at step 75900: 0.087229\n",
      "2024-02-29 17:14:59 INFO     Training average negative_sample_loss at step 75900: 0.077297\n",
      "2024-02-29 17:14:59 INFO     Training average loss at step 75900: 0.082263\n",
      "2024-02-29 17:16:53 INFO     Training average positive_sample_loss at step 76000: 0.088184\n",
      "2024-02-29 17:16:53 INFO     Training average negative_sample_loss at step 76000: 0.077650\n",
      "2024-02-29 17:16:53 INFO     Training average loss at step 76000: 0.082917\n",
      "2024-02-29 17:18:53 INFO     Training average positive_sample_loss at step 76100: 0.088458\n",
      "2024-02-29 17:18:53 INFO     Training average negative_sample_loss at step 76100: 0.077466\n",
      "2024-02-29 17:18:53 INFO     Training average loss at step 76100: 0.082962\n",
      "2024-02-29 17:21:15 INFO     Training average positive_sample_loss at step 76200: 0.088052\n",
      "2024-02-29 17:21:15 INFO     Training average negative_sample_loss at step 76200: 0.077408\n",
      "2024-02-29 17:21:15 INFO     Training average loss at step 76200: 0.082730\n",
      "2024-02-29 17:23:34 INFO     Training average positive_sample_loss at step 76300: 0.088367\n",
      "2024-02-29 17:23:34 INFO     Training average negative_sample_loss at step 76300: 0.077883\n",
      "2024-02-29 17:23:34 INFO     Training average loss at step 76300: 0.083125\n",
      "2024-02-29 17:25:30 INFO     Training average positive_sample_loss at step 76400: 0.088492\n",
      "2024-02-29 17:25:30 INFO     Training average negative_sample_loss at step 76400: 0.077734\n",
      "2024-02-29 17:25:30 INFO     Training average loss at step 76400: 0.083113\n",
      "2024-02-29 17:27:30 INFO     Training average positive_sample_loss at step 76500: 0.087139\n",
      "2024-02-29 17:27:30 INFO     Training average negative_sample_loss at step 76500: 0.077410\n",
      "2024-02-29 17:27:30 INFO     Training average loss at step 76500: 0.082274\n",
      "2024-02-29 17:29:07 INFO     Training average positive_sample_loss at step 76600: 0.086075\n",
      "2024-02-29 17:29:07 INFO     Training average negative_sample_loss at step 76600: 0.077061\n",
      "2024-02-29 17:29:07 INFO     Training average loss at step 76600: 0.081568\n",
      "2024-02-29 17:31:05 INFO     Training average positive_sample_loss at step 76700: 0.086667\n",
      "2024-02-29 17:31:05 INFO     Training average negative_sample_loss at step 76700: 0.076581\n",
      "2024-02-29 17:31:05 INFO     Training average loss at step 76700: 0.081624\n",
      "2024-02-29 17:32:51 INFO     Training average positive_sample_loss at step 76800: 0.087375\n",
      "2024-02-29 17:32:51 INFO     Training average negative_sample_loss at step 76800: 0.076786\n",
      "2024-02-29 17:32:51 INFO     Training average loss at step 76800: 0.082081\n",
      "2024-02-29 17:34:47 INFO     Training average positive_sample_loss at step 76900: 0.087133\n",
      "2024-02-29 17:34:47 INFO     Training average negative_sample_loss at step 76900: 0.076518\n",
      "2024-02-29 17:34:47 INFO     Training average loss at step 76900: 0.081826\n",
      "2024-02-29 17:36:32 INFO     Training average positive_sample_loss at step 77000: 0.087382\n",
      "2024-02-29 17:36:32 INFO     Training average negative_sample_loss at step 77000: 0.076567\n",
      "2024-02-29 17:36:32 INFO     Training average loss at step 77000: 0.081975\n",
      "2024-02-29 17:38:15 INFO     Training average positive_sample_loss at step 77100: 0.087922\n",
      "2024-02-29 17:38:15 INFO     Training average negative_sample_loss at step 77100: 0.076612\n",
      "2024-02-29 17:38:15 INFO     Training average loss at step 77100: 0.082267\n",
      "2024-02-29 17:40:29 INFO     Training average positive_sample_loss at step 77200: 0.087575\n",
      "2024-02-29 17:40:29 INFO     Training average negative_sample_loss at step 77200: 0.077055\n",
      "2024-02-29 17:40:29 INFO     Training average loss at step 77200: 0.082315\n",
      "2024-02-29 17:42:35 INFO     Training average positive_sample_loss at step 77300: 0.087355\n",
      "2024-02-29 17:42:35 INFO     Training average negative_sample_loss at step 77300: 0.076692\n",
      "2024-02-29 17:42:35 INFO     Training average loss at step 77300: 0.082024\n",
      "2024-02-29 17:44:26 INFO     Training average positive_sample_loss at step 77400: 0.087576\n",
      "2024-02-29 17:44:26 INFO     Training average negative_sample_loss at step 77400: 0.076542\n",
      "2024-02-29 17:44:26 INFO     Training average loss at step 77400: 0.082059\n",
      "2024-02-29 17:46:17 INFO     Training average positive_sample_loss at step 77500: 0.085702\n",
      "2024-02-29 17:46:17 INFO     Training average negative_sample_loss at step 77500: 0.076592\n",
      "2024-02-29 17:46:17 INFO     Training average loss at step 77500: 0.081147\n",
      "2024-02-29 17:48:10 INFO     Training average positive_sample_loss at step 77600: 0.086599\n",
      "2024-02-29 17:48:10 INFO     Training average negative_sample_loss at step 77600: 0.076497\n",
      "2024-02-29 17:48:10 INFO     Training average loss at step 77600: 0.081548\n",
      "2024-02-29 17:50:03 INFO     Training average positive_sample_loss at step 77700: 0.085900\n",
      "2024-02-29 17:50:03 INFO     Training average negative_sample_loss at step 77700: 0.076175\n",
      "2024-02-29 17:50:03 INFO     Training average loss at step 77700: 0.081037\n",
      "2024-02-29 17:51:55 INFO     Training average positive_sample_loss at step 77800: 0.086606\n",
      "2024-02-29 17:51:55 INFO     Training average negative_sample_loss at step 77800: 0.075753\n",
      "2024-02-29 17:51:55 INFO     Training average loss at step 77800: 0.081179\n",
      "2024-02-29 17:53:29 INFO     Training average positive_sample_loss at step 77900: 0.087025\n",
      "2024-02-29 17:53:29 INFO     Training average negative_sample_loss at step 77900: 0.076009\n",
      "2024-02-29 17:53:29 INFO     Training average loss at step 77900: 0.081517\n",
      "2024-02-29 17:55:03 INFO     Training average positive_sample_loss at step 78000: 0.086513\n",
      "2024-02-29 17:55:03 INFO     Training average negative_sample_loss at step 78000: 0.075749\n",
      "2024-02-29 17:55:03 INFO     Training average loss at step 78000: 0.081131\n",
      "2024-02-29 17:56:44 INFO     Training average positive_sample_loss at step 78100: 0.087306\n",
      "2024-02-29 17:56:44 INFO     Training average negative_sample_loss at step 78100: 0.076339\n",
      "2024-02-29 17:56:44 INFO     Training average loss at step 78100: 0.081823\n",
      "2024-02-29 17:58:31 INFO     Training average positive_sample_loss at step 78200: 0.087844\n",
      "2024-02-29 17:58:31 INFO     Training average negative_sample_loss at step 78200: 0.076590\n",
      "2024-02-29 17:58:31 INFO     Training average loss at step 78200: 0.082217\n",
      "2024-02-29 18:00:28 INFO     Training average positive_sample_loss at step 78300: 0.087172\n",
      "2024-02-29 18:00:28 INFO     Training average negative_sample_loss at step 78300: 0.076314\n",
      "2024-02-29 18:00:28 INFO     Training average loss at step 78300: 0.081743\n",
      "2024-02-29 18:02:25 INFO     Training average positive_sample_loss at step 78400: 0.086054\n",
      "2024-02-29 18:02:25 INFO     Training average negative_sample_loss at step 78400: 0.076303\n",
      "2024-02-29 18:02:25 INFO     Training average loss at step 78400: 0.081179\n",
      "2024-02-29 18:04:20 INFO     Training average positive_sample_loss at step 78500: 0.085364\n",
      "2024-02-29 18:04:20 INFO     Training average negative_sample_loss at step 78500: 0.075779\n",
      "2024-02-29 18:04:20 INFO     Training average loss at step 78500: 0.080572\n",
      "2024-02-29 18:06:07 INFO     Training average positive_sample_loss at step 78600: 0.085839\n",
      "2024-02-29 18:06:07 INFO     Training average negative_sample_loss at step 78600: 0.075278\n",
      "2024-02-29 18:06:07 INFO     Training average loss at step 78600: 0.080558\n",
      "2024-02-29 18:08:01 INFO     Training average positive_sample_loss at step 78700: 0.086443\n",
      "2024-02-29 18:08:01 INFO     Training average negative_sample_loss at step 78700: 0.075733\n",
      "2024-02-29 18:08:01 INFO     Training average loss at step 78700: 0.081088\n",
      "2024-02-29 18:10:12 INFO     Training average positive_sample_loss at step 78800: 0.086156\n",
      "2024-02-29 18:10:12 INFO     Training average negative_sample_loss at step 78800: 0.075421\n",
      "2024-02-29 18:10:12 INFO     Training average loss at step 78800: 0.080789\n",
      "2024-02-29 18:12:04 INFO     Training average positive_sample_loss at step 78900: 0.086493\n",
      "2024-02-29 18:12:04 INFO     Training average negative_sample_loss at step 78900: 0.075461\n",
      "2024-02-29 18:12:04 INFO     Training average loss at step 78900: 0.080977\n",
      "2024-02-29 18:13:52 INFO     Training average positive_sample_loss at step 79000: 0.087203\n",
      "2024-02-29 18:13:52 INFO     Training average negative_sample_loss at step 79000: 0.076193\n",
      "2024-02-29 18:13:52 INFO     Training average loss at step 79000: 0.081698\n",
      "2024-02-29 18:15:48 INFO     Training average positive_sample_loss at step 79100: 0.087645\n",
      "2024-02-29 18:15:48 INFO     Training average negative_sample_loss at step 79100: 0.076476\n",
      "2024-02-29 18:15:48 INFO     Training average loss at step 79100: 0.082061\n",
      "2024-02-29 18:17:43 INFO     Training average positive_sample_loss at step 79200: 0.087175\n",
      "2024-02-29 18:17:43 INFO     Training average negative_sample_loss at step 79200: 0.076196\n",
      "2024-02-29 18:17:43 INFO     Training average loss at step 79200: 0.081686\n",
      "2024-02-29 18:19:45 INFO     Training average positive_sample_loss at step 79300: 0.087311\n",
      "2024-02-29 18:19:45 INFO     Training average negative_sample_loss at step 79300: 0.076300\n",
      "2024-02-29 18:19:45 INFO     Training average loss at step 79300: 0.081806\n",
      "2024-02-29 18:21:44 INFO     Training average positive_sample_loss at step 79400: 0.084553\n",
      "2024-02-29 18:21:44 INFO     Training average negative_sample_loss at step 79400: 0.075730\n",
      "2024-02-29 18:21:44 INFO     Training average loss at step 79400: 0.080141\n",
      "2024-02-29 18:23:45 INFO     Training average positive_sample_loss at step 79500: 0.085461\n",
      "2024-02-29 18:23:45 INFO     Training average negative_sample_loss at step 79500: 0.075177\n",
      "2024-02-29 18:23:45 INFO     Training average loss at step 79500: 0.080319\n",
      "2024-02-29 18:25:40 INFO     Training average positive_sample_loss at step 79600: 0.085733\n",
      "2024-02-29 18:25:40 INFO     Training average negative_sample_loss at step 79600: 0.075479\n",
      "2024-02-29 18:25:40 INFO     Training average loss at step 79600: 0.080606\n",
      "2024-02-29 18:27:39 INFO     Training average positive_sample_loss at step 79700: 0.086594\n",
      "2024-02-29 18:27:39 INFO     Training average negative_sample_loss at step 79700: 0.075124\n",
      "2024-02-29 18:27:39 INFO     Training average loss at step 79700: 0.080859\n",
      "2024-02-29 18:29:10 INFO     Training average positive_sample_loss at step 79800: 0.087028\n",
      "2024-02-29 18:29:10 INFO     Training average negative_sample_loss at step 79800: 0.075898\n",
      "2024-02-29 18:29:10 INFO     Training average loss at step 79800: 0.081463\n",
      "2024-02-29 18:30:47 INFO     Training average positive_sample_loss at step 79900: 0.086540\n",
      "2024-02-29 18:30:47 INFO     Training average negative_sample_loss at step 79900: 0.075676\n",
      "2024-02-29 18:30:47 INFO     Training average loss at step 79900: 0.081108\n",
      "2024-02-29 18:32:48 INFO     Training average positive_sample_loss at step 80000: 0.086920\n",
      "2024-02-29 18:32:48 INFO     Training average negative_sample_loss at step 80000: 0.075691\n",
      "2024-02-29 18:32:48 INFO     Training average loss at step 80000: 0.081306\n",
      "2024-02-29 18:32:48 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 18:32:49 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-29 18:33:24 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-29 18:34:04 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-29 18:34:39 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-29 18:35:11 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-29 18:35:47 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-29 18:36:21 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-29 18:36:30 INFO     Valid MRR at step 80000: 0.436045\n",
      "2024-02-29 18:36:30 INFO     Valid MR at step 80000: 228.630190\n",
      "2024-02-29 18:36:30 INFO     Valid HITS@1 at step 80000: 0.340870\n",
      "2024-02-29 18:36:30 INFO     Valid HITS@3 at step 80000: 0.466190\n",
      "2024-02-29 18:36:30 INFO     Valid HITS@10 at step 80000: 0.648040\n",
      "2024-02-29 18:37:59 INFO     Training average positive_sample_loss at step 80100: 0.086844\n",
      "2024-02-29 18:37:59 INFO     Training average negative_sample_loss at step 80100: 0.076057\n",
      "2024-02-29 18:37:59 INFO     Training average loss at step 80100: 0.081451\n",
      "2024-02-29 18:39:57 INFO     Training average positive_sample_loss at step 80200: 0.087222\n",
      "2024-02-29 18:39:57 INFO     Training average negative_sample_loss at step 80200: 0.076114\n",
      "2024-02-29 18:39:57 INFO     Training average loss at step 80200: 0.081668\n",
      "2024-02-29 18:42:13 INFO     Training average positive_sample_loss at step 80300: 0.085498\n",
      "2024-02-29 18:42:13 INFO     Training average negative_sample_loss at step 80300: 0.075812\n",
      "2024-02-29 18:42:13 INFO     Training average loss at step 80300: 0.080655\n",
      "2024-02-29 18:43:52 INFO     Training average positive_sample_loss at step 80400: 0.085049\n",
      "2024-02-29 18:43:52 INFO     Training average negative_sample_loss at step 80400: 0.075189\n",
      "2024-02-29 18:43:52 INFO     Training average loss at step 80400: 0.080119\n",
      "2024-02-29 18:45:38 INFO     Training average positive_sample_loss at step 80500: 0.085631\n",
      "2024-02-29 18:45:38 INFO     Training average negative_sample_loss at step 80500: 0.075081\n",
      "2024-02-29 18:45:38 INFO     Training average loss at step 80500: 0.080356\n",
      "2024-02-29 18:47:43 INFO     Training average positive_sample_loss at step 80600: 0.085879\n",
      "2024-02-29 18:47:43 INFO     Training average negative_sample_loss at step 80600: 0.075277\n",
      "2024-02-29 18:47:43 INFO     Training average loss at step 80600: 0.080578\n",
      "2024-02-29 18:49:48 INFO     Training average positive_sample_loss at step 80700: 0.086505\n",
      "2024-02-29 18:49:48 INFO     Training average negative_sample_loss at step 80700: 0.075054\n",
      "2024-02-29 18:49:48 INFO     Training average loss at step 80700: 0.080779\n",
      "2024-02-29 18:51:47 INFO     Training average positive_sample_loss at step 80800: 0.086497\n",
      "2024-02-29 18:51:47 INFO     Training average negative_sample_loss at step 80800: 0.075586\n",
      "2024-02-29 18:51:47 INFO     Training average loss at step 80800: 0.081042\n",
      "2024-02-29 18:53:40 INFO     Training average positive_sample_loss at step 80900: 0.086446\n",
      "2024-02-29 18:53:40 INFO     Training average negative_sample_loss at step 80900: 0.075499\n",
      "2024-02-29 18:53:40 INFO     Training average loss at step 80900: 0.080973\n",
      "2024-02-29 18:55:31 INFO     Training average positive_sample_loss at step 81000: 0.086903\n",
      "2024-02-29 18:55:31 INFO     Training average negative_sample_loss at step 81000: 0.075711\n",
      "2024-02-29 18:55:31 INFO     Training average loss at step 81000: 0.081307\n",
      "2024-02-29 18:57:25 INFO     Training average positive_sample_loss at step 81100: 0.087453\n",
      "2024-02-29 18:57:25 INFO     Training average negative_sample_loss at step 81100: 0.076362\n",
      "2024-02-29 18:57:25 INFO     Training average loss at step 81100: 0.081907\n",
      "2024-02-29 18:59:32 INFO     Training average positive_sample_loss at step 81200: 0.086401\n",
      "2024-02-29 18:59:32 INFO     Training average negative_sample_loss at step 81200: 0.075768\n",
      "2024-02-29 18:59:32 INFO     Training average loss at step 81200: 0.081084\n",
      "2024-02-29 19:01:23 INFO     Training average positive_sample_loss at step 81300: 0.084564\n",
      "2024-02-29 19:01:23 INFO     Training average negative_sample_loss at step 81300: 0.075444\n",
      "2024-02-29 19:01:23 INFO     Training average loss at step 81300: 0.080004\n",
      "2024-02-29 19:03:07 INFO     Training average positive_sample_loss at step 81400: 0.085308\n",
      "2024-02-29 19:03:07 INFO     Training average negative_sample_loss at step 81400: 0.074897\n",
      "2024-02-29 19:03:07 INFO     Training average loss at step 81400: 0.080103\n",
      "2024-02-29 19:05:11 INFO     Training average positive_sample_loss at step 81500: 0.086200\n",
      "2024-02-29 19:05:11 INFO     Training average negative_sample_loss at step 81500: 0.075416\n",
      "2024-02-29 19:05:11 INFO     Training average loss at step 81500: 0.080808\n",
      "2024-02-29 19:06:53 INFO     Training average positive_sample_loss at step 81600: 0.086192\n",
      "2024-02-29 19:06:53 INFO     Training average negative_sample_loss at step 81600: 0.075086\n",
      "2024-02-29 19:06:53 INFO     Training average loss at step 81600: 0.080639\n",
      "2024-02-29 19:08:29 INFO     Training average positive_sample_loss at step 81700: 0.086250\n",
      "2024-02-29 19:08:29 INFO     Training average negative_sample_loss at step 81700: 0.075374\n",
      "2024-02-29 19:08:29 INFO     Training average loss at step 81700: 0.080812\n",
      "2024-02-29 19:10:01 INFO     Training average positive_sample_loss at step 81800: 0.086693\n",
      "2024-02-29 19:10:01 INFO     Training average negative_sample_loss at step 81800: 0.075338\n",
      "2024-02-29 19:10:01 INFO     Training average loss at step 81800: 0.081015\n",
      "2024-02-29 19:11:40 INFO     Training average positive_sample_loss at step 81900: 0.086870\n",
      "2024-02-29 19:11:40 INFO     Training average negative_sample_loss at step 81900: 0.075739\n",
      "2024-02-29 19:11:40 INFO     Training average loss at step 81900: 0.081304\n",
      "2024-02-29 19:13:18 INFO     Training average positive_sample_loss at step 82000: 0.086772\n",
      "2024-02-29 19:13:18 INFO     Training average negative_sample_loss at step 82000: 0.075701\n",
      "2024-02-29 19:13:18 INFO     Training average loss at step 82000: 0.081237\n",
      "2024-02-29 19:14:54 INFO     Training average positive_sample_loss at step 82100: 0.087246\n",
      "2024-02-29 19:14:54 INFO     Training average negative_sample_loss at step 82100: 0.076158\n",
      "2024-02-29 19:14:54 INFO     Training average loss at step 82100: 0.081702\n",
      "2024-02-29 19:16:59 INFO     Training average positive_sample_loss at step 82200: 0.084425\n",
      "2024-02-29 19:16:59 INFO     Training average negative_sample_loss at step 82200: 0.075348\n",
      "2024-02-29 19:16:59 INFO     Training average loss at step 82200: 0.079886\n",
      "2024-02-29 19:18:44 INFO     Training average positive_sample_loss at step 82300: 0.085081\n",
      "2024-02-29 19:18:44 INFO     Training average negative_sample_loss at step 82300: 0.075050\n",
      "2024-02-29 19:18:44 INFO     Training average loss at step 82300: 0.080065\n",
      "2024-02-29 19:20:33 INFO     Training average positive_sample_loss at step 82400: 0.085652\n",
      "2024-02-29 19:20:33 INFO     Training average negative_sample_loss at step 82400: 0.074846\n",
      "2024-02-29 19:20:33 INFO     Training average loss at step 82400: 0.080249\n",
      "2024-02-29 19:22:34 INFO     Training average positive_sample_loss at step 82500: 0.085819\n",
      "2024-02-29 19:22:34 INFO     Training average negative_sample_loss at step 82500: 0.075153\n",
      "2024-02-29 19:22:34 INFO     Training average loss at step 82500: 0.080486\n",
      "2024-02-29 19:24:27 INFO     Training average positive_sample_loss at step 82600: 0.086223\n",
      "2024-02-29 19:24:27 INFO     Training average negative_sample_loss at step 82600: 0.074964\n",
      "2024-02-29 19:24:27 INFO     Training average loss at step 82600: 0.080593\n",
      "2024-02-29 19:26:23 INFO     Training average positive_sample_loss at step 82700: 0.086064\n",
      "2024-02-29 19:26:23 INFO     Training average negative_sample_loss at step 82700: 0.075074\n",
      "2024-02-29 19:26:23 INFO     Training average loss at step 82700: 0.080569\n",
      "2024-02-29 19:28:10 INFO     Training average positive_sample_loss at step 82800: 0.086781\n",
      "2024-02-29 19:28:10 INFO     Training average negative_sample_loss at step 82800: 0.075358\n",
      "2024-02-29 19:28:10 INFO     Training average loss at step 82800: 0.081070\n",
      "2024-02-29 19:30:11 INFO     Training average positive_sample_loss at step 82900: 0.087469\n",
      "2024-02-29 19:30:11 INFO     Training average negative_sample_loss at step 82900: 0.076097\n",
      "2024-02-29 19:30:11 INFO     Training average loss at step 82900: 0.081783\n",
      "2024-02-29 19:32:14 INFO     Training average positive_sample_loss at step 83000: 0.086910\n",
      "2024-02-29 19:32:14 INFO     Training average negative_sample_loss at step 83000: 0.075500\n",
      "2024-02-29 19:32:14 INFO     Training average loss at step 83000: 0.081205\n",
      "2024-02-29 19:34:21 INFO     Training average positive_sample_loss at step 83100: 0.085865\n",
      "2024-02-29 19:34:21 INFO     Training average negative_sample_loss at step 83100: 0.075447\n",
      "2024-02-29 19:34:21 INFO     Training average loss at step 83100: 0.080656\n",
      "2024-02-29 19:36:15 INFO     Training average positive_sample_loss at step 83200: 0.084214\n",
      "2024-02-29 19:36:15 INFO     Training average negative_sample_loss at step 83200: 0.075014\n",
      "2024-02-29 19:36:15 INFO     Training average loss at step 83200: 0.079614\n",
      "2024-02-29 19:38:02 INFO     Training average positive_sample_loss at step 83300: 0.085433\n",
      "2024-02-29 19:38:02 INFO     Training average negative_sample_loss at step 83300: 0.075067\n",
      "2024-02-29 19:38:02 INFO     Training average loss at step 83300: 0.080250\n",
      "2024-02-29 19:39:56 INFO     Training average positive_sample_loss at step 83400: 0.085743\n",
      "2024-02-29 19:39:56 INFO     Training average negative_sample_loss at step 83400: 0.074985\n",
      "2024-02-29 19:39:56 INFO     Training average loss at step 83400: 0.080364\n",
      "2024-02-29 19:41:57 INFO     Training average positive_sample_loss at step 83500: 0.085778\n",
      "2024-02-29 19:41:57 INFO     Training average negative_sample_loss at step 83500: 0.074984\n",
      "2024-02-29 19:41:57 INFO     Training average loss at step 83500: 0.080381\n",
      "2024-02-29 19:43:45 INFO     Training average positive_sample_loss at step 83600: 0.086376\n",
      "2024-02-29 19:43:45 INFO     Training average negative_sample_loss at step 83600: 0.075115\n",
      "2024-02-29 19:43:45 INFO     Training average loss at step 83600: 0.080745\n",
      "2024-02-29 19:45:35 INFO     Training average positive_sample_loss at step 83700: 0.086816\n",
      "2024-02-29 19:45:35 INFO     Training average negative_sample_loss at step 83700: 0.075313\n",
      "2024-02-29 19:45:35 INFO     Training average loss at step 83700: 0.081064\n",
      "2024-02-29 19:47:29 INFO     Training average positive_sample_loss at step 83800: 0.086531\n",
      "2024-02-29 19:47:29 INFO     Training average negative_sample_loss at step 83800: 0.075628\n",
      "2024-02-29 19:47:29 INFO     Training average loss at step 83800: 0.081080\n",
      "2024-02-29 19:49:29 INFO     Training average positive_sample_loss at step 83900: 0.086842\n",
      "2024-02-29 19:49:29 INFO     Training average negative_sample_loss at step 83900: 0.075392\n",
      "2024-02-29 19:49:29 INFO     Training average loss at step 83900: 0.081117\n",
      "2024-02-29 19:51:05 INFO     Training average positive_sample_loss at step 84000: 0.086908\n",
      "2024-02-29 19:51:05 INFO     Training average negative_sample_loss at step 84000: 0.076070\n",
      "2024-02-29 19:51:05 INFO     Training average loss at step 84000: 0.081489\n",
      "2024-02-29 19:53:05 INFO     Training average positive_sample_loss at step 84100: 0.084235\n",
      "2024-02-29 19:53:05 INFO     Training average negative_sample_loss at step 84100: 0.075035\n",
      "2024-02-29 19:53:05 INFO     Training average loss at step 84100: 0.079635\n",
      "2024-02-29 19:55:04 INFO     Training average positive_sample_loss at step 84200: 0.084960\n",
      "2024-02-29 19:55:04 INFO     Training average negative_sample_loss at step 84200: 0.074845\n",
      "2024-02-29 19:55:04 INFO     Training average loss at step 84200: 0.079903\n",
      "2024-02-29 19:57:09 INFO     Training average positive_sample_loss at step 84300: 0.085736\n",
      "2024-02-29 19:57:09 INFO     Training average negative_sample_loss at step 84300: 0.074889\n",
      "2024-02-29 19:57:09 INFO     Training average loss at step 84300: 0.080313\n",
      "2024-02-29 19:58:46 INFO     Training average positive_sample_loss at step 84400: 0.086036\n",
      "2024-02-29 19:58:46 INFO     Training average negative_sample_loss at step 84400: 0.075127\n",
      "2024-02-29 19:58:46 INFO     Training average loss at step 84400: 0.080582\n",
      "2024-02-29 20:00:39 INFO     Training average positive_sample_loss at step 84500: 0.086290\n",
      "2024-02-29 20:00:39 INFO     Training average negative_sample_loss at step 84500: 0.075086\n",
      "2024-02-29 20:00:39 INFO     Training average loss at step 84500: 0.080688\n",
      "2024-02-29 20:02:34 INFO     Training average positive_sample_loss at step 84600: 0.086503\n",
      "2024-02-29 20:02:34 INFO     Training average negative_sample_loss at step 84600: 0.075563\n",
      "2024-02-29 20:02:34 INFO     Training average loss at step 84600: 0.081033\n",
      "2024-02-29 20:04:32 INFO     Training average positive_sample_loss at step 84700: 0.086063\n",
      "2024-02-29 20:04:32 INFO     Training average negative_sample_loss at step 84700: 0.075251\n",
      "2024-02-29 20:04:32 INFO     Training average loss at step 84700: 0.080657\n",
      "2024-02-29 20:06:23 INFO     Training average positive_sample_loss at step 84800: 0.086964\n",
      "2024-02-29 20:06:23 INFO     Training average negative_sample_loss at step 84800: 0.075348\n",
      "2024-02-29 20:06:23 INFO     Training average loss at step 84800: 0.081156\n",
      "2024-02-29 20:08:05 INFO     Training average positive_sample_loss at step 84900: 0.086569\n",
      "2024-02-29 20:08:05 INFO     Training average negative_sample_loss at step 84900: 0.075386\n",
      "2024-02-29 20:08:05 INFO     Training average loss at step 84900: 0.080978\n",
      "2024-02-29 20:10:20 INFO     Training average positive_sample_loss at step 85000: 0.085412\n",
      "2024-02-29 20:10:20 INFO     Training average negative_sample_loss at step 85000: 0.075722\n",
      "2024-02-29 20:10:20 INFO     Training average loss at step 85000: 0.080567\n",
      "2024-02-29 20:11:48 INFO     Training average positive_sample_loss at step 85100: 0.084186\n",
      "2024-02-29 20:11:48 INFO     Training average negative_sample_loss at step 85100: 0.074641\n",
      "2024-02-29 20:11:48 INFO     Training average loss at step 85100: 0.079413\n",
      "2024-02-29 20:13:38 INFO     Training average positive_sample_loss at step 85200: 0.085364\n",
      "2024-02-29 20:13:38 INFO     Training average negative_sample_loss at step 85200: 0.074437\n",
      "2024-02-29 20:13:38 INFO     Training average loss at step 85200: 0.079901\n",
      "2024-02-29 20:15:25 INFO     Training average positive_sample_loss at step 85300: 0.085360\n",
      "2024-02-29 20:15:25 INFO     Training average negative_sample_loss at step 85300: 0.074639\n",
      "2024-02-29 20:15:25 INFO     Training average loss at step 85300: 0.080000\n",
      "2024-02-29 20:17:11 INFO     Training average positive_sample_loss at step 85400: 0.086207\n",
      "2024-02-29 20:17:11 INFO     Training average negative_sample_loss at step 85400: 0.075154\n",
      "2024-02-29 20:17:11 INFO     Training average loss at step 85400: 0.080681\n",
      "2024-02-29 20:18:53 INFO     Training average positive_sample_loss at step 85500: 0.086961\n",
      "2024-02-29 20:18:53 INFO     Training average negative_sample_loss at step 85500: 0.075399\n",
      "2024-02-29 20:18:53 INFO     Training average loss at step 85500: 0.081180\n",
      "2024-02-29 20:20:31 INFO     Training average positive_sample_loss at step 85600: 0.086465\n",
      "2024-02-29 20:20:31 INFO     Training average negative_sample_loss at step 85600: 0.075414\n",
      "2024-02-29 20:20:31 INFO     Training average loss at step 85600: 0.080939\n",
      "2024-02-29 20:22:42 INFO     Training average positive_sample_loss at step 85700: 0.086341\n",
      "2024-02-29 20:22:42 INFO     Training average negative_sample_loss at step 85700: 0.075452\n",
      "2024-02-29 20:22:42 INFO     Training average loss at step 85700: 0.080896\n",
      "2024-02-29 20:24:49 INFO     Training average positive_sample_loss at step 85800: 0.086758\n",
      "2024-02-29 20:24:49 INFO     Training average negative_sample_loss at step 85800: 0.075450\n",
      "2024-02-29 20:24:49 INFO     Training average loss at step 85800: 0.081104\n",
      "2024-02-29 20:26:46 INFO     Training average positive_sample_loss at step 85900: 0.087039\n",
      "2024-02-29 20:26:46 INFO     Training average negative_sample_loss at step 85900: 0.075939\n",
      "2024-02-29 20:26:46 INFO     Training average loss at step 85900: 0.081489\n",
      "2024-02-29 20:29:01 INFO     Training average positive_sample_loss at step 86000: 0.084070\n",
      "2024-02-29 20:29:01 INFO     Training average negative_sample_loss at step 86000: 0.075218\n",
      "2024-02-29 20:29:01 INFO     Training average loss at step 86000: 0.079644\n",
      "2024-02-29 20:30:36 INFO     Training average positive_sample_loss at step 86100: 0.085137\n",
      "2024-02-29 20:30:36 INFO     Training average negative_sample_loss at step 86100: 0.074929\n",
      "2024-02-29 20:30:36 INFO     Training average loss at step 86100: 0.080033\n",
      "2024-02-29 20:32:03 INFO     Training average positive_sample_loss at step 86200: 0.085698\n",
      "2024-02-29 20:32:03 INFO     Training average negative_sample_loss at step 86200: 0.074810\n",
      "2024-02-29 20:32:03 INFO     Training average loss at step 86200: 0.080254\n",
      "2024-02-29 20:34:02 INFO     Training average positive_sample_loss at step 86300: 0.085487\n",
      "2024-02-29 20:34:02 INFO     Training average negative_sample_loss at step 86300: 0.074441\n",
      "2024-02-29 20:34:02 INFO     Training average loss at step 86300: 0.079964\n",
      "2024-02-29 20:35:59 INFO     Training average positive_sample_loss at step 86400: 0.086009\n",
      "2024-02-29 20:35:59 INFO     Training average negative_sample_loss at step 86400: 0.075162\n",
      "2024-02-29 20:35:59 INFO     Training average loss at step 86400: 0.080585\n",
      "2024-02-29 20:37:56 INFO     Training average positive_sample_loss at step 86500: 0.086431\n",
      "2024-02-29 20:37:56 INFO     Training average negative_sample_loss at step 86500: 0.075084\n",
      "2024-02-29 20:37:56 INFO     Training average loss at step 86500: 0.080758\n",
      "2024-02-29 20:39:39 INFO     Training average positive_sample_loss at step 86600: 0.086285\n",
      "2024-02-29 20:39:39 INFO     Training average negative_sample_loss at step 86600: 0.075432\n",
      "2024-02-29 20:39:39 INFO     Training average loss at step 86600: 0.080858\n",
      "2024-02-29 20:41:34 INFO     Training average positive_sample_loss at step 86700: 0.086828\n",
      "2024-02-29 20:41:34 INFO     Training average negative_sample_loss at step 86700: 0.075595\n",
      "2024-02-29 20:41:34 INFO     Training average loss at step 86700: 0.081211\n",
      "2024-02-29 20:43:24 INFO     Training average positive_sample_loss at step 86800: 0.086914\n",
      "2024-02-29 20:43:24 INFO     Training average negative_sample_loss at step 86800: 0.075115\n",
      "2024-02-29 20:43:24 INFO     Training average loss at step 86800: 0.081015\n",
      "2024-02-29 20:45:38 INFO     Training average positive_sample_loss at step 86900: 0.085384\n",
      "2024-02-29 20:45:38 INFO     Training average negative_sample_loss at step 86900: 0.075638\n",
      "2024-02-29 20:45:38 INFO     Training average loss at step 86900: 0.080511\n",
      "2024-02-29 20:47:22 INFO     Training average positive_sample_loss at step 87000: 0.084520\n",
      "2024-02-29 20:47:22 INFO     Training average negative_sample_loss at step 87000: 0.075061\n",
      "2024-02-29 20:47:22 INFO     Training average loss at step 87000: 0.079791\n",
      "2024-02-29 20:48:52 INFO     Training average positive_sample_loss at step 87100: 0.085495\n",
      "2024-02-29 20:48:52 INFO     Training average negative_sample_loss at step 87100: 0.074945\n",
      "2024-02-29 20:48:52 INFO     Training average loss at step 87100: 0.080220\n",
      "2024-02-29 20:50:42 INFO     Training average positive_sample_loss at step 87200: 0.085215\n",
      "2024-02-29 20:50:42 INFO     Training average negative_sample_loss at step 87200: 0.074567\n",
      "2024-02-29 20:50:42 INFO     Training average loss at step 87200: 0.079891\n",
      "2024-02-29 20:52:15 INFO     Training average positive_sample_loss at step 87300: 0.085893\n",
      "2024-02-29 20:52:15 INFO     Training average negative_sample_loss at step 87300: 0.074719\n",
      "2024-02-29 20:52:15 INFO     Training average loss at step 87300: 0.080306\n",
      "2024-02-29 20:53:48 INFO     Training average positive_sample_loss at step 87400: 0.086251\n",
      "2024-02-29 20:53:48 INFO     Training average negative_sample_loss at step 87400: 0.075152\n",
      "2024-02-29 20:53:48 INFO     Training average loss at step 87400: 0.080701\n",
      "2024-02-29 20:55:34 INFO     Training average positive_sample_loss at step 87500: 0.086412\n",
      "2024-02-29 20:55:34 INFO     Training average negative_sample_loss at step 87500: 0.075242\n",
      "2024-02-29 20:55:34 INFO     Training average loss at step 87500: 0.080827\n",
      "2024-02-29 20:57:26 INFO     Training average positive_sample_loss at step 87600: 0.086238\n",
      "2024-02-29 20:57:26 INFO     Training average negative_sample_loss at step 87600: 0.075110\n",
      "2024-02-29 20:57:26 INFO     Training average loss at step 87600: 0.080674\n",
      "2024-02-29 20:59:10 INFO     Training average positive_sample_loss at step 87700: 0.086983\n",
      "2024-02-29 20:59:10 INFO     Training average negative_sample_loss at step 87700: 0.075608\n",
      "2024-02-29 20:59:10 INFO     Training average loss at step 87700: 0.081296\n",
      "2024-02-29 21:01:17 INFO     Training average positive_sample_loss at step 87800: 0.086487\n",
      "2024-02-29 21:01:17 INFO     Training average negative_sample_loss at step 87800: 0.075345\n",
      "2024-02-29 21:01:17 INFO     Training average loss at step 87800: 0.080916\n",
      "2024-02-29 21:03:09 INFO     Training average positive_sample_loss at step 87900: 0.084433\n",
      "2024-02-29 21:03:09 INFO     Training average negative_sample_loss at step 87900: 0.075466\n",
      "2024-02-29 21:03:09 INFO     Training average loss at step 87900: 0.079950\n",
      "2024-02-29 21:05:02 INFO     Training average positive_sample_loss at step 88000: 0.085270\n",
      "2024-02-29 21:05:02 INFO     Training average negative_sample_loss at step 88000: 0.075148\n",
      "2024-02-29 21:05:02 INFO     Training average loss at step 88000: 0.080209\n",
      "2024-02-29 21:07:10 INFO     Training average positive_sample_loss at step 88100: 0.085371\n",
      "2024-02-29 21:07:10 INFO     Training average negative_sample_loss at step 88100: 0.074980\n",
      "2024-02-29 21:07:10 INFO     Training average loss at step 88100: 0.080175\n",
      "2024-02-29 21:09:10 INFO     Training average positive_sample_loss at step 88200: 0.085839\n",
      "2024-02-29 21:09:10 INFO     Training average negative_sample_loss at step 88200: 0.074726\n",
      "2024-02-29 21:09:10 INFO     Training average loss at step 88200: 0.080282\n",
      "2024-02-29 21:10:35 INFO     Training average positive_sample_loss at step 88300: 0.085881\n",
      "2024-02-29 21:10:35 INFO     Training average negative_sample_loss at step 88300: 0.074415\n",
      "2024-02-29 21:10:35 INFO     Training average loss at step 88300: 0.080148\n",
      "2024-02-29 21:12:18 INFO     Training average positive_sample_loss at step 88400: 0.086244\n",
      "2024-02-29 21:12:18 INFO     Training average negative_sample_loss at step 88400: 0.075132\n",
      "2024-02-29 21:12:18 INFO     Training average loss at step 88400: 0.080688\n",
      "2024-02-29 21:13:52 INFO     Training average positive_sample_loss at step 88500: 0.086435\n",
      "2024-02-29 21:13:52 INFO     Training average negative_sample_loss at step 88500: 0.075445\n",
      "2024-02-29 21:13:52 INFO     Training average loss at step 88500: 0.080940\n",
      "2024-02-29 21:15:36 INFO     Training average positive_sample_loss at step 88600: 0.086554\n",
      "2024-02-29 21:15:36 INFO     Training average negative_sample_loss at step 88600: 0.075396\n",
      "2024-02-29 21:15:36 INFO     Training average loss at step 88600: 0.080975\n",
      "2024-02-29 21:17:35 INFO     Training average positive_sample_loss at step 88700: 0.086395\n",
      "2024-02-29 21:17:35 INFO     Training average negative_sample_loss at step 88700: 0.075443\n",
      "2024-02-29 21:17:35 INFO     Training average loss at step 88700: 0.080919\n",
      "2024-02-29 21:19:41 INFO     Training average positive_sample_loss at step 88800: 0.085257\n",
      "2024-02-29 21:19:41 INFO     Training average negative_sample_loss at step 88800: 0.075377\n",
      "2024-02-29 21:19:41 INFO     Training average loss at step 88800: 0.080317\n",
      "2024-02-29 21:21:35 INFO     Training average positive_sample_loss at step 88900: 0.084667\n",
      "2024-02-29 21:21:35 INFO     Training average negative_sample_loss at step 88900: 0.074768\n",
      "2024-02-29 21:21:35 INFO     Training average loss at step 88900: 0.079718\n",
      "2024-02-29 21:23:12 INFO     Training average positive_sample_loss at step 89000: 0.085270\n",
      "2024-02-29 21:23:12 INFO     Training average negative_sample_loss at step 89000: 0.074641\n",
      "2024-02-29 21:23:12 INFO     Training average loss at step 89000: 0.079955\n",
      "2024-02-29 21:25:01 INFO     Training average positive_sample_loss at step 89100: 0.085860\n",
      "2024-02-29 21:25:01 INFO     Training average negative_sample_loss at step 89100: 0.075015\n",
      "2024-02-29 21:25:01 INFO     Training average loss at step 89100: 0.080437\n",
      "2024-02-29 21:26:54 INFO     Training average positive_sample_loss at step 89200: 0.085917\n",
      "2024-02-29 21:26:54 INFO     Training average negative_sample_loss at step 89200: 0.074500\n",
      "2024-02-29 21:26:54 INFO     Training average loss at step 89200: 0.080208\n",
      "2024-02-29 21:28:27 INFO     Training average positive_sample_loss at step 89300: 0.085767\n",
      "2024-02-29 21:28:27 INFO     Training average negative_sample_loss at step 89300: 0.074852\n",
      "2024-02-29 21:28:27 INFO     Training average loss at step 89300: 0.080310\n",
      "2024-02-29 21:29:56 INFO     Training average positive_sample_loss at step 89400: 0.086433\n",
      "2024-02-29 21:29:56 INFO     Training average negative_sample_loss at step 89400: 0.075328\n",
      "2024-02-29 21:29:56 INFO     Training average loss at step 89400: 0.080880\n",
      "2024-02-29 21:31:31 INFO     Training average positive_sample_loss at step 89500: 0.086726\n",
      "2024-02-29 21:31:31 INFO     Training average negative_sample_loss at step 89500: 0.075525\n",
      "2024-02-29 21:31:31 INFO     Training average loss at step 89500: 0.081125\n",
      "2024-02-29 21:33:13 INFO     Training average positive_sample_loss at step 89600: 0.086277\n",
      "2024-02-29 21:33:13 INFO     Training average negative_sample_loss at step 89600: 0.075366\n",
      "2024-02-29 21:33:13 INFO     Training average loss at step 89600: 0.080821\n",
      "2024-02-29 21:35:11 INFO     Training average positive_sample_loss at step 89700: 0.085925\n",
      "2024-02-29 21:35:11 INFO     Training average negative_sample_loss at step 89700: 0.075411\n",
      "2024-02-29 21:35:11 INFO     Training average loss at step 89700: 0.080668\n",
      "2024-02-29 21:36:45 INFO     Training average positive_sample_loss at step 89800: 0.084194\n",
      "2024-02-29 21:36:45 INFO     Training average negative_sample_loss at step 89800: 0.074813\n",
      "2024-02-29 21:36:45 INFO     Training average loss at step 89800: 0.079503\n",
      "2024-02-29 21:38:24 INFO     Training average positive_sample_loss at step 89900: 0.085097\n",
      "2024-02-29 21:38:24 INFO     Training average negative_sample_loss at step 89900: 0.074748\n",
      "2024-02-29 21:38:24 INFO     Training average loss at step 89900: 0.079922\n",
      "2024-02-29 21:39:59 INFO     Training average positive_sample_loss at step 90000: 0.085675\n",
      "2024-02-29 21:39:59 INFO     Training average negative_sample_loss at step 90000: 0.074470\n",
      "2024-02-29 21:39:59 INFO     Training average loss at step 90000: 0.080072\n",
      "2024-02-29 21:39:59 INFO     Evaluating on Valid Dataset...\n",
      "2024-02-29 21:40:00 INFO     Evaluating the model... (0/6250)\n",
      "2024-02-29 21:40:38 INFO     Evaluating the model... (1000/6250)\n",
      "2024-02-29 21:41:13 INFO     Evaluating the model... (2000/6250)\n",
      "2024-02-29 21:41:49 INFO     Evaluating the model... (3000/6250)\n",
      "2024-02-29 21:42:23 INFO     Evaluating the model... (4000/6250)\n",
      "2024-02-29 21:42:58 INFO     Evaluating the model... (5000/6250)\n",
      "2024-02-29 21:43:29 INFO     Evaluating the model... (6000/6250)\n",
      "2024-02-29 21:43:37 INFO     Valid MRR at step 90000: 0.437841\n",
      "2024-02-29 21:43:37 INFO     Valid MR at step 90000: 223.170580\n",
      "2024-02-29 21:43:37 INFO     Valid HITS@1 at step 90000: 0.340900\n",
      "2024-02-29 21:43:37 INFO     Valid HITS@3 at step 90000: 0.469460\n",
      "2024-02-29 21:43:37 INFO     Valid HITS@10 at step 90000: 0.651540\n",
      "2024-02-29 21:45:03 INFO     Training average positive_sample_loss at step 90100: 0.085726\n",
      "2024-02-29 21:45:03 INFO     Training average negative_sample_loss at step 90100: 0.074626\n",
      "2024-02-29 21:45:03 INFO     Training average loss at step 90100: 0.080176\n",
      "2024-02-29 21:46:44 INFO     Training average positive_sample_loss at step 90200: 0.086254\n",
      "2024-02-29 21:46:44 INFO     Training average negative_sample_loss at step 90200: 0.075133\n",
      "2024-02-29 21:46:44 INFO     Training average loss at step 90200: 0.080694\n",
      "2024-02-29 21:48:16 INFO     Training average positive_sample_loss at step 90300: 0.086067\n",
      "2024-02-29 21:48:16 INFO     Training average negative_sample_loss at step 90300: 0.075240\n",
      "2024-02-29 21:48:16 INFO     Training average loss at step 90300: 0.080653\n",
      "2024-02-29 21:49:57 INFO     Training average positive_sample_loss at step 90400: 0.086746\n",
      "2024-02-29 21:49:57 INFO     Training average negative_sample_loss at step 90400: 0.075100\n",
      "2024-02-29 21:49:57 INFO     Training average loss at step 90400: 0.080923\n",
      "2024-02-29 21:51:30 INFO     Training average positive_sample_loss at step 90500: 0.086297\n",
      "2024-02-29 21:51:30 INFO     Training average negative_sample_loss at step 90500: 0.075495\n",
      "2024-02-29 21:51:30 INFO     Training average loss at step 90500: 0.080896\n",
      "2024-02-29 21:53:03 INFO     Training average positive_sample_loss at step 90600: 0.086491\n",
      "2024-02-29 21:53:03 INFO     Training average negative_sample_loss at step 90600: 0.075571\n",
      "2024-02-29 21:53:03 INFO     Training average loss at step 90600: 0.081031\n",
      "2024-02-29 21:54:53 INFO     Training average positive_sample_loss at step 90700: 0.084815\n",
      "2024-02-29 21:54:53 INFO     Training average negative_sample_loss at step 90700: 0.075199\n",
      "2024-02-29 21:54:53 INFO     Training average loss at step 90700: 0.080007\n",
      "2024-02-29 21:56:44 INFO     Training average positive_sample_loss at step 90800: 0.084733\n",
      "2024-02-29 21:56:44 INFO     Training average negative_sample_loss at step 90800: 0.074827\n",
      "2024-02-29 21:56:44 INFO     Training average loss at step 90800: 0.079780\n",
      "2024-02-29 21:58:19 INFO     Training average positive_sample_loss at step 90900: 0.085363\n",
      "2024-02-29 21:58:19 INFO     Training average negative_sample_loss at step 90900: 0.074394\n",
      "2024-02-29 21:58:19 INFO     Training average loss at step 90900: 0.079878\n",
      "2024-02-29 22:00:05 INFO     Training average positive_sample_loss at step 91000: 0.086022\n",
      "2024-02-29 22:00:05 INFO     Training average negative_sample_loss at step 91000: 0.074847\n",
      "2024-02-29 22:00:05 INFO     Training average loss at step 91000: 0.080434\n",
      "2024-02-29 22:01:58 INFO     Training average positive_sample_loss at step 91100: 0.085770\n",
      "2024-02-29 22:01:58 INFO     Training average negative_sample_loss at step 91100: 0.074972\n",
      "2024-02-29 22:01:58 INFO     Training average loss at step 91100: 0.080371\n",
      "2024-02-29 22:03:36 INFO     Training average positive_sample_loss at step 91200: 0.085803\n",
      "2024-02-29 22:03:36 INFO     Training average negative_sample_loss at step 91200: 0.074620\n",
      "2024-02-29 22:03:36 INFO     Training average loss at step 91200: 0.080211\n",
      "2024-02-29 22:05:28 INFO     Training average positive_sample_loss at step 91300: 0.086350\n",
      "2024-02-29 22:05:28 INFO     Training average negative_sample_loss at step 91300: 0.075012\n",
      "2024-02-29 22:05:28 INFO     Training average loss at step 91300: 0.080681\n",
      "2024-02-29 22:07:23 INFO     Training average positive_sample_loss at step 91400: 0.085874\n",
      "2024-02-29 22:07:23 INFO     Training average negative_sample_loss at step 91400: 0.075261\n",
      "2024-02-29 22:07:23 INFO     Training average loss at step 91400: 0.080567\n",
      "2024-02-29 22:09:14 INFO     Training average positive_sample_loss at step 91500: 0.086868\n",
      "2024-02-29 22:09:14 INFO     Training average negative_sample_loss at step 91500: 0.075268\n",
      "2024-02-29 22:09:14 INFO     Training average loss at step 91500: 0.081068\n",
      "2024-02-29 22:11:29 INFO     Training average positive_sample_loss at step 91600: 0.085640\n",
      "2024-02-29 22:11:29 INFO     Training average negative_sample_loss at step 91600: 0.075510\n",
      "2024-02-29 22:11:29 INFO     Training average loss at step 91600: 0.080575\n",
      "2024-02-29 22:13:12 INFO     Training average positive_sample_loss at step 91700: 0.084229\n",
      "2024-02-29 22:13:12 INFO     Training average negative_sample_loss at step 91700: 0.074291\n",
      "2024-02-29 22:13:12 INFO     Training average loss at step 91700: 0.079260\n",
      "2024-02-29 22:15:00 INFO     Training average positive_sample_loss at step 91800: 0.085247\n",
      "2024-02-29 22:15:00 INFO     Training average negative_sample_loss at step 91800: 0.075086\n",
      "2024-02-29 22:15:00 INFO     Training average loss at step 91800: 0.080166\n",
      "2024-02-29 22:16:50 INFO     Training average positive_sample_loss at step 91900: 0.085489\n",
      "2024-02-29 22:16:50 INFO     Training average negative_sample_loss at step 91900: 0.074631\n",
      "2024-02-29 22:16:50 INFO     Training average loss at step 91900: 0.080060\n",
      "2024-02-29 22:18:54 INFO     Training average positive_sample_loss at step 92000: 0.085647\n",
      "2024-02-29 22:18:54 INFO     Training average negative_sample_loss at step 92000: 0.074703\n",
      "2024-02-29 22:18:54 INFO     Training average loss at step 92000: 0.080175\n",
      "2024-02-29 22:20:49 INFO     Training average positive_sample_loss at step 92100: 0.085722\n",
      "2024-02-29 22:20:49 INFO     Training average negative_sample_loss at step 92100: 0.074869\n",
      "2024-02-29 22:20:49 INFO     Training average loss at step 92100: 0.080295\n",
      "2024-02-29 22:22:44 INFO     Training average positive_sample_loss at step 92200: 0.086259\n",
      "2024-02-29 22:22:44 INFO     Training average negative_sample_loss at step 92200: 0.074910\n",
      "2024-02-29 22:22:44 INFO     Training average loss at step 92200: 0.080585\n",
      "2024-02-29 22:24:49 INFO     Training average positive_sample_loss at step 92300: 0.086840\n",
      "2024-02-29 22:24:49 INFO     Training average negative_sample_loss at step 92300: 0.075618\n",
      "2024-02-29 22:24:49 INFO     Training average loss at step 92300: 0.081229\n",
      "2024-02-29 22:26:50 INFO     Training average positive_sample_loss at step 92400: 0.086523\n",
      "2024-02-29 22:26:50 INFO     Training average negative_sample_loss at step 92400: 0.075187\n",
      "2024-02-29 22:26:50 INFO     Training average loss at step 92400: 0.080855\n",
      "2024-02-29 22:28:41 INFO     Training average positive_sample_loss at step 92500: 0.086626\n",
      "2024-02-29 22:28:41 INFO     Training average negative_sample_loss at step 92500: 0.075591\n",
      "2024-02-29 22:28:41 INFO     Training average loss at step 92500: 0.081108\n",
      "2024-02-29 22:30:43 INFO     Training average positive_sample_loss at step 92600: 0.084278\n",
      "2024-02-29 22:30:43 INFO     Training average negative_sample_loss at step 92600: 0.075172\n",
      "2024-02-29 22:30:43 INFO     Training average loss at step 92600: 0.079725\n",
      "2024-02-29 22:32:28 INFO     Training average positive_sample_loss at step 92700: 0.084609\n",
      "2024-02-29 22:32:28 INFO     Training average negative_sample_loss at step 92700: 0.074635\n",
      "2024-02-29 22:32:28 INFO     Training average loss at step 92700: 0.079622\n",
      "2024-02-29 22:34:20 INFO     Training average positive_sample_loss at step 92800: 0.085354\n",
      "2024-02-29 22:34:20 INFO     Training average negative_sample_loss at step 92800: 0.074285\n",
      "2024-02-29 22:34:20 INFO     Training average loss at step 92800: 0.079819\n",
      "2024-02-29 22:36:00 INFO     Training average positive_sample_loss at step 92900: 0.085949\n",
      "2024-02-29 22:36:00 INFO     Training average negative_sample_loss at step 92900: 0.074833\n",
      "2024-02-29 22:36:00 INFO     Training average loss at step 92900: 0.080391\n",
      "2024-02-29 22:37:32 INFO     Training average positive_sample_loss at step 93000: 0.085417\n",
      "2024-02-29 22:37:32 INFO     Training average negative_sample_loss at step 93000: 0.074657\n",
      "2024-02-29 22:37:32 INFO     Training average loss at step 93000: 0.080037\n",
      "2024-02-29 22:39:22 INFO     Training average positive_sample_loss at step 93100: 0.086943\n",
      "2024-02-29 22:39:22 INFO     Training average negative_sample_loss at step 93100: 0.075684\n",
      "2024-02-29 22:39:22 INFO     Training average loss at step 93100: 0.081313\n",
      "2024-02-29 22:40:53 INFO     Training average positive_sample_loss at step 93200: 0.085986\n",
      "2024-02-29 22:40:53 INFO     Training average negative_sample_loss at step 93200: 0.074956\n",
      "2024-02-29 22:40:53 INFO     Training average loss at step 93200: 0.080471\n",
      "2024-02-29 22:42:22 INFO     Training average positive_sample_loss at step 93300: 0.086239\n",
      "2024-02-29 22:42:22 INFO     Training average negative_sample_loss at step 93300: 0.074958\n",
      "2024-02-29 22:42:22 INFO     Training average loss at step 93300: 0.080598\n",
      "2024-02-29 22:44:11 INFO     Training average positive_sample_loss at step 93400: 0.086572\n",
      "2024-02-29 22:44:11 INFO     Training average negative_sample_loss at step 93400: 0.075190\n",
      "2024-02-29 22:44:11 INFO     Training average loss at step 93400: 0.080881\n",
      "2024-02-29 22:46:12 INFO     Training average positive_sample_loss at step 93500: 0.085121\n",
      "2024-02-29 22:46:12 INFO     Training average negative_sample_loss at step 93500: 0.074911\n",
      "2024-02-29 22:46:12 INFO     Training average loss at step 93500: 0.080016\n",
      "2024-02-29 22:47:54 INFO     Training average positive_sample_loss at step 93600: 0.084826\n",
      "2024-02-29 22:47:54 INFO     Training average negative_sample_loss at step 93600: 0.075266\n",
      "2024-02-29 22:47:54 INFO     Training average loss at step 93600: 0.080046\n",
      "2024-02-29 22:49:37 INFO     Training average positive_sample_loss at step 93700: 0.084732\n",
      "2024-02-29 22:49:37 INFO     Training average negative_sample_loss at step 93700: 0.074313\n",
      "2024-02-29 22:49:37 INFO     Training average loss at step 93700: 0.079522\n",
      "2024-02-29 22:51:25 INFO     Training average positive_sample_loss at step 93800: 0.085470\n",
      "2024-02-29 22:51:25 INFO     Training average negative_sample_loss at step 93800: 0.074692\n",
      "2024-02-29 22:51:25 INFO     Training average loss at step 93800: 0.080081\n",
      "2024-02-29 22:53:05 INFO     Training average positive_sample_loss at step 93900: 0.085963\n",
      "2024-02-29 22:53:05 INFO     Training average negative_sample_loss at step 93900: 0.074941\n",
      "2024-02-29 22:53:05 INFO     Training average loss at step 93900: 0.080452\n",
      "2024-02-29 22:54:48 INFO     Training average positive_sample_loss at step 94000: 0.086560\n",
      "2024-02-29 22:54:48 INFO     Training average negative_sample_loss at step 94000: 0.075385\n",
      "2024-02-29 22:54:48 INFO     Training average loss at step 94000: 0.080972\n",
      "2024-02-29 22:56:27 INFO     Training average positive_sample_loss at step 94100: 0.086273\n",
      "2024-02-29 22:56:27 INFO     Training average negative_sample_loss at step 94100: 0.074878\n",
      "2024-02-29 22:56:27 INFO     Training average loss at step 94100: 0.080575\n",
      "2024-02-29 22:58:23 INFO     Training average positive_sample_loss at step 94200: 0.085796\n",
      "2024-02-29 22:58:23 INFO     Training average negative_sample_loss at step 94200: 0.074893\n",
      "2024-02-29 22:58:23 INFO     Training average loss at step 94200: 0.080345\n",
      "2024-02-29 23:00:19 INFO     Training average positive_sample_loss at step 94300: 0.086486\n",
      "2024-02-29 23:00:19 INFO     Training average negative_sample_loss at step 94300: 0.075486\n",
      "2024-02-29 23:00:19 INFO     Training average loss at step 94300: 0.080986\n",
      "2024-02-29 23:02:15 INFO     Training average positive_sample_loss at step 94400: 0.086411\n",
      "2024-02-29 23:02:15 INFO     Training average negative_sample_loss at step 94400: 0.075161\n",
      "2024-02-29 23:02:15 INFO     Training average loss at step 94400: 0.080786\n",
      "2024-02-29 23:03:54 INFO     Training average positive_sample_loss at step 94500: 0.083930\n",
      "2024-02-29 23:03:54 INFO     Training average negative_sample_loss at step 94500: 0.074599\n",
      "2024-02-29 23:03:54 INFO     Training average loss at step 94500: 0.079265\n",
      "2024-02-29 23:05:42 INFO     Training average positive_sample_loss at step 94600: 0.084836\n",
      "2024-02-29 23:05:42 INFO     Training average negative_sample_loss at step 94600: 0.074515\n",
      "2024-02-29 23:05:42 INFO     Training average loss at step 94600: 0.079676\n",
      "2024-02-29 23:07:23 INFO     Training average positive_sample_loss at step 94700: 0.085969\n",
      "2024-02-29 23:07:23 INFO     Training average negative_sample_loss at step 94700: 0.074853\n",
      "2024-02-29 23:07:23 INFO     Training average loss at step 94700: 0.080411\n",
      "2024-02-29 23:09:04 INFO     Training average positive_sample_loss at step 94800: 0.085668\n",
      "2024-02-29 23:09:04 INFO     Training average negative_sample_loss at step 94800: 0.074728\n",
      "2024-02-29 23:09:04 INFO     Training average loss at step 94800: 0.080198\n",
      "2024-02-29 23:10:41 INFO     Training average positive_sample_loss at step 94900: 0.085704\n",
      "2024-02-29 23:10:41 INFO     Training average negative_sample_loss at step 94900: 0.074472\n",
      "2024-02-29 23:10:41 INFO     Training average loss at step 94900: 0.080088\n",
      "2024-02-29 23:12:27 INFO     Training average positive_sample_loss at step 95000: 0.085857\n",
      "2024-02-29 23:12:27 INFO     Training average negative_sample_loss at step 95000: 0.075031\n",
      "2024-02-29 23:12:27 INFO     Training average loss at step 95000: 0.080444\n",
      "2024-02-29 23:14:03 INFO     Training average positive_sample_loss at step 95100: 0.086164\n",
      "2024-02-29 23:14:03 INFO     Training average negative_sample_loss at step 95100: 0.075304\n",
      "2024-02-29 23:14:03 INFO     Training average loss at step 95100: 0.080734\n",
      "2024-02-29 23:16:00 INFO     Training average positive_sample_loss at step 95200: 0.086439\n",
      "2024-02-29 23:16:00 INFO     Training average negative_sample_loss at step 95200: 0.075323\n",
      "2024-02-29 23:16:00 INFO     Training average loss at step 95200: 0.080881\n",
      "2024-02-29 23:18:11 INFO     Training average positive_sample_loss at step 95300: 0.086368\n",
      "2024-02-29 23:18:11 INFO     Training average negative_sample_loss at step 95300: 0.075263\n",
      "2024-02-29 23:18:11 INFO     Training average loss at step 95300: 0.080816\n",
      "2024-02-29 23:20:12 INFO     Training average positive_sample_loss at step 95400: 0.084769\n",
      "2024-02-29 23:20:12 INFO     Training average negative_sample_loss at step 95400: 0.074955\n",
      "2024-02-29 23:20:12 INFO     Training average loss at step 95400: 0.079862\n",
      "2024-02-29 23:21:53 INFO     Training average positive_sample_loss at step 95500: 0.084581\n",
      "2024-02-29 23:21:53 INFO     Training average negative_sample_loss at step 95500: 0.074405\n",
      "2024-02-29 23:21:53 INFO     Training average loss at step 95500: 0.079493\n",
      "2024-02-29 23:23:36 INFO     Training average positive_sample_loss at step 95600: 0.085381\n",
      "2024-02-29 23:23:36 INFO     Training average negative_sample_loss at step 95600: 0.074849\n",
      "2024-02-29 23:23:36 INFO     Training average loss at step 95600: 0.080115\n",
      "2024-02-29 23:25:19 INFO     Training average positive_sample_loss at step 95700: 0.085561\n",
      "2024-02-29 23:25:19 INFO     Training average negative_sample_loss at step 95700: 0.075012\n",
      "2024-02-29 23:25:19 INFO     Training average loss at step 95700: 0.080287\n",
      "2024-02-29 23:27:07 INFO     Training average positive_sample_loss at step 95800: 0.085655\n",
      "2024-02-29 23:27:07 INFO     Training average negative_sample_loss at step 95800: 0.074673\n",
      "2024-02-29 23:27:07 INFO     Training average loss at step 95800: 0.080164\n",
      "2024-02-29 23:28:57 INFO     Training average positive_sample_loss at step 95900: 0.086478\n",
      "2024-02-29 23:28:57 INFO     Training average negative_sample_loss at step 95900: 0.074867\n",
      "2024-02-29 23:28:57 INFO     Training average loss at step 95900: 0.080672\n",
      "2024-02-29 23:30:52 INFO     Training average positive_sample_loss at step 96000: 0.085781\n",
      "2024-02-29 23:30:52 INFO     Training average negative_sample_loss at step 96000: 0.074692\n",
      "2024-02-29 23:30:52 INFO     Training average loss at step 96000: 0.080236\n",
      "2024-02-29 23:32:34 INFO     Training average positive_sample_loss at step 96100: 0.086811\n",
      "2024-02-29 23:32:34 INFO     Training average negative_sample_loss at step 96100: 0.075395\n",
      "2024-02-29 23:32:34 INFO     Training average loss at step 96100: 0.081103\n",
      "2024-02-29 23:34:31 INFO     Training average positive_sample_loss at step 96200: 0.086112\n",
      "2024-02-29 23:34:31 INFO     Training average negative_sample_loss at step 96200: 0.075212\n",
      "2024-02-29 23:34:31 INFO     Training average loss at step 96200: 0.080662\n",
      "2024-02-29 23:36:52 INFO     Training average positive_sample_loss at step 96300: 0.086057\n",
      "2024-02-29 23:36:52 INFO     Training average negative_sample_loss at step 96300: 0.075331\n",
      "2024-02-29 23:36:52 INFO     Training average loss at step 96300: 0.080694\n",
      "2024-02-29 23:38:34 INFO     Training average positive_sample_loss at step 96400: 0.084061\n",
      "2024-02-29 23:38:34 INFO     Training average negative_sample_loss at step 96400: 0.074758\n",
      "2024-02-29 23:38:34 INFO     Training average loss at step 96400: 0.079409\n",
      "2024-02-29 23:40:13 INFO     Training average positive_sample_loss at step 96500: 0.084630\n",
      "2024-02-29 23:40:13 INFO     Training average negative_sample_loss at step 96500: 0.074343\n",
      "2024-02-29 23:40:13 INFO     Training average loss at step 96500: 0.079486\n",
      "2024-02-29 23:42:05 INFO     Training average positive_sample_loss at step 96600: 0.085389\n",
      "2024-02-29 23:42:05 INFO     Training average negative_sample_loss at step 96600: 0.074412\n",
      "2024-02-29 23:42:05 INFO     Training average loss at step 96600: 0.079900\n",
      "2024-02-29 23:43:56 INFO     Training average positive_sample_loss at step 96700: 0.085070\n",
      "2024-02-29 23:43:56 INFO     Training average negative_sample_loss at step 96700: 0.074165\n",
      "2024-02-29 23:43:56 INFO     Training average loss at step 96700: 0.079618\n",
      "2024-02-29 23:45:51 INFO     Training average positive_sample_loss at step 96800: 0.086494\n",
      "2024-02-29 23:45:51 INFO     Training average negative_sample_loss at step 96800: 0.075093\n",
      "2024-02-29 23:45:51 INFO     Training average loss at step 96800: 0.080794\n",
      "2024-02-29 23:47:30 INFO     Training average positive_sample_loss at step 96900: 0.086262\n",
      "2024-02-29 23:47:30 INFO     Training average negative_sample_loss at step 96900: 0.075088\n",
      "2024-02-29 23:47:30 INFO     Training average loss at step 96900: 0.080675\n",
      "2024-02-29 23:49:00 INFO     Training average positive_sample_loss at step 97000: 0.086052\n",
      "2024-02-29 23:49:00 INFO     Training average negative_sample_loss at step 97000: 0.075010\n",
      "2024-02-29 23:49:00 INFO     Training average loss at step 97000: 0.080531\n",
      "2024-02-29 23:50:43 INFO     Training average positive_sample_loss at step 97100: 0.086620\n",
      "2024-02-29 23:50:43 INFO     Training average negative_sample_loss at step 97100: 0.075271\n",
      "2024-02-29 23:50:43 INFO     Training average loss at step 97100: 0.080946\n",
      "2024-02-29 23:52:38 INFO     Training average positive_sample_loss at step 97200: 0.086614\n",
      "2024-02-29 23:52:38 INFO     Training average negative_sample_loss at step 97200: 0.075557\n",
      "2024-02-29 23:52:38 INFO     Training average loss at step 97200: 0.081085\n",
      "2024-02-29 23:54:31 INFO     Training average positive_sample_loss at step 97300: 0.084758\n",
      "2024-02-29 23:54:31 INFO     Training average negative_sample_loss at step 97300: 0.075006\n",
      "2024-02-29 23:54:31 INFO     Training average loss at step 97300: 0.079882\n",
      "2024-02-29 23:56:28 INFO     Training average positive_sample_loss at step 97400: 0.085252\n",
      "2024-02-29 23:56:28 INFO     Training average negative_sample_loss at step 97400: 0.075160\n",
      "2024-02-29 23:56:28 INFO     Training average loss at step 97400: 0.080206\n",
      "2024-02-29 23:58:13 INFO     Training average positive_sample_loss at step 97500: 0.085008\n",
      "2024-02-29 23:58:13 INFO     Training average negative_sample_loss at step 97500: 0.074294\n",
      "2024-02-29 23:58:13 INFO     Training average loss at step 97500: 0.079651\n",
      "2024-02-29 23:59:51 INFO     Training average positive_sample_loss at step 97600: 0.085395\n",
      "2024-02-29 23:59:51 INFO     Training average negative_sample_loss at step 97600: 0.074453\n",
      "2024-02-29 23:59:51 INFO     Training average loss at step 97600: 0.079924\n",
      "2024-03-01 00:01:28 INFO     Training average positive_sample_loss at step 97700: 0.085667\n",
      "2024-03-01 00:01:28 INFO     Training average negative_sample_loss at step 97700: 0.074689\n",
      "2024-03-01 00:01:28 INFO     Training average loss at step 97700: 0.080178\n",
      "2024-03-01 00:03:02 INFO     Training average positive_sample_loss at step 97800: 0.085601\n",
      "2024-03-01 00:03:02 INFO     Training average negative_sample_loss at step 97800: 0.074519\n",
      "2024-03-01 00:03:02 INFO     Training average loss at step 97800: 0.080060\n",
      "2024-03-01 00:04:33 INFO     Training average positive_sample_loss at step 97900: 0.086028\n",
      "2024-03-01 00:04:33 INFO     Training average negative_sample_loss at step 97900: 0.075091\n",
      "2024-03-01 00:04:33 INFO     Training average loss at step 97900: 0.080560\n",
      "2024-03-01 00:06:03 INFO     Training average positive_sample_loss at step 98000: 0.086179\n",
      "2024-03-01 00:06:03 INFO     Training average negative_sample_loss at step 98000: 0.074888\n",
      "2024-03-01 00:06:03 INFO     Training average loss at step 98000: 0.080534\n",
      "2024-03-01 00:07:56 INFO     Training average positive_sample_loss at step 98100: 0.086265\n",
      "2024-03-01 00:07:56 INFO     Training average negative_sample_loss at step 98100: 0.074983\n",
      "2024-03-01 00:07:56 INFO     Training average loss at step 98100: 0.080624\n",
      "2024-03-01 00:10:03 INFO     Training average positive_sample_loss at step 98200: 0.085526\n",
      "2024-03-01 00:10:03 INFO     Training average negative_sample_loss at step 98200: 0.075033\n",
      "2024-03-01 00:10:03 INFO     Training average loss at step 98200: 0.080279\n",
      "2024-03-01 00:11:47 INFO     Training average positive_sample_loss at step 98300: 0.083943\n",
      "2024-03-01 00:11:47 INFO     Training average negative_sample_loss at step 98300: 0.074832\n",
      "2024-03-01 00:11:47 INFO     Training average loss at step 98300: 0.079387\n",
      "2024-03-01 00:13:45 INFO     Training average positive_sample_loss at step 98400: 0.085217\n",
      "2024-03-01 00:13:45 INFO     Training average negative_sample_loss at step 98400: 0.074381\n",
      "2024-03-01 00:13:45 INFO     Training average loss at step 98400: 0.079799\n",
      "2024-03-01 00:15:35 INFO     Training average positive_sample_loss at step 98500: 0.085372\n",
      "2024-03-01 00:15:35 INFO     Training average negative_sample_loss at step 98500: 0.074420\n",
      "2024-03-01 00:15:35 INFO     Training average loss at step 98500: 0.079896\n",
      "2024-03-01 00:17:03 INFO     Training average positive_sample_loss at step 98600: 0.085783\n",
      "2024-03-01 00:17:03 INFO     Training average negative_sample_loss at step 98600: 0.074470\n",
      "2024-03-01 00:17:03 INFO     Training average loss at step 98600: 0.080127\n",
      "2024-03-01 00:18:41 INFO     Training average positive_sample_loss at step 98700: 0.085928\n",
      "2024-03-01 00:18:41 INFO     Training average negative_sample_loss at step 98700: 0.074954\n",
      "2024-03-01 00:18:41 INFO     Training average loss at step 98700: 0.080441\n",
      "2024-03-01 00:20:16 INFO     Training average positive_sample_loss at step 98800: 0.085983\n",
      "2024-03-01 00:20:16 INFO     Training average negative_sample_loss at step 98800: 0.074787\n",
      "2024-03-01 00:20:16 INFO     Training average loss at step 98800: 0.080385\n",
      "2024-03-01 00:22:01 INFO     Training average positive_sample_loss at step 98900: 0.086014\n",
      "2024-03-01 00:22:01 INFO     Training average negative_sample_loss at step 98900: 0.074752\n",
      "2024-03-01 00:22:01 INFO     Training average loss at step 98900: 0.080383\n",
      "2024-03-01 00:23:32 INFO     Training average positive_sample_loss at step 99000: 0.086427\n",
      "2024-03-01 00:23:32 INFO     Training average negative_sample_loss at step 99000: 0.075364\n",
      "2024-03-01 00:23:32 INFO     Training average loss at step 99000: 0.080895\n",
      "2024-03-01 00:25:03 INFO     Training average positive_sample_loss at step 99100: 0.086582\n",
      "2024-03-01 00:25:03 INFO     Training average negative_sample_loss at step 99100: 0.075488\n",
      "2024-03-01 00:25:03 INFO     Training average loss at step 99100: 0.081035\n",
      "2024-03-01 00:26:59 INFO     Training average positive_sample_loss at step 99200: 0.084235\n",
      "2024-03-01 00:26:59 INFO     Training average negative_sample_loss at step 99200: 0.074994\n",
      "2024-03-01 00:26:59 INFO     Training average loss at step 99200: 0.079614\n",
      "2024-03-01 00:28:38 INFO     Training average positive_sample_loss at step 99300: 0.085113\n",
      "2024-03-01 00:28:38 INFO     Training average negative_sample_loss at step 99300: 0.074556\n",
      "2024-03-01 00:28:38 INFO     Training average loss at step 99300: 0.079835\n",
      "2024-03-01 00:30:26 INFO     Training average positive_sample_loss at step 99400: 0.085399\n",
      "2024-03-01 00:30:26 INFO     Training average negative_sample_loss at step 99400: 0.074751\n",
      "2024-03-01 00:30:26 INFO     Training average loss at step 99400: 0.080075\n",
      "2024-03-01 00:32:11 INFO     Training average positive_sample_loss at step 99500: 0.085219\n",
      "2024-03-01 00:32:11 INFO     Training average negative_sample_loss at step 99500: 0.074525\n",
      "2024-03-01 00:32:11 INFO     Training average loss at step 99500: 0.079872\n",
      "2024-03-01 00:33:42 INFO     Training average positive_sample_loss at step 99600: 0.086085\n",
      "2024-03-01 00:33:42 INFO     Training average negative_sample_loss at step 99600: 0.074952\n",
      "2024-03-01 00:33:42 INFO     Training average loss at step 99600: 0.080518\n",
      "2024-03-01 00:35:19 INFO     Training average positive_sample_loss at step 99700: 0.085506\n",
      "2024-03-01 00:35:19 INFO     Training average negative_sample_loss at step 99700: 0.074487\n",
      "2024-03-01 00:35:19 INFO     Training average loss at step 99700: 0.079996\n",
      "2024-03-01 00:37:10 INFO     Training average positive_sample_loss at step 99800: 0.085916\n",
      "2024-03-01 00:37:10 INFO     Training average negative_sample_loss at step 99800: 0.074852\n",
      "2024-03-01 00:37:10 INFO     Training average loss at step 99800: 0.080384\n",
      "2024-03-01 00:38:56 INFO     Training average positive_sample_loss at step 99900: 0.086013\n",
      "2024-03-01 00:38:56 INFO     Training average negative_sample_loss at step 99900: 0.074927\n",
      "2024-03-01 00:38:56 INFO     Training average loss at step 99900: 0.080470\n",
      "2024-03-01 00:40:57 INFO     Training average positive_sample_loss at step 100000: 0.086613\n",
      "2024-03-01 00:40:57 INFO     Training average negative_sample_loss at step 100000: 0.075224\n",
      "2024-03-01 00:40:57 INFO     Training average loss at step 100000: 0.080918\n",
      "2024-03-01 00:40:57 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 00:40:58 INFO     Evaluating the model... (0/6250)\n",
      "2024-03-01 00:41:33 INFO     Evaluating the model... (1000/6250)\n",
      "2024-03-01 00:42:05 INFO     Evaluating the model... (2000/6250)\n",
      "2024-03-01 00:42:36 INFO     Evaluating the model... (3000/6250)\n",
      "2024-03-01 00:43:09 INFO     Evaluating the model... (4000/6250)\n",
      "2024-03-01 00:43:38 INFO     Evaluating the model... (5000/6250)\n",
      "2024-03-01 00:44:08 INFO     Evaluating the model... (6000/6250)\n",
      "2024-03-01 00:44:15 INFO     Valid MRR at step 100000: 0.443569\n",
      "2024-03-01 00:44:15 INFO     Valid MR at step 100000: 220.218870\n",
      "2024-03-01 00:44:15 INFO     Valid HITS@1 at step 100000: 0.346730\n",
      "2024-03-01 00:44:15 INFO     Valid HITS@3 at step 100000: 0.476090\n",
      "2024-03-01 00:44:15 INFO     Valid HITS@10 at step 100000: 0.655600\n",
      "2024-03-01 00:45:57 INFO     Training average positive_sample_loss at step 100100: 0.085245\n",
      "2024-03-01 00:45:57 INFO     Training average negative_sample_loss at step 100100: 0.075118\n",
      "2024-03-01 00:45:57 INFO     Training average loss at step 100100: 0.080181\n",
      "2024-03-01 00:47:42 INFO     Training average positive_sample_loss at step 100200: 0.084032\n",
      "2024-03-01 00:47:42 INFO     Training average negative_sample_loss at step 100200: 0.074768\n",
      "2024-03-01 00:47:42 INFO     Training average loss at step 100200: 0.079400\n",
      "2024-03-01 00:49:40 INFO     Training average positive_sample_loss at step 100300: 0.084908\n",
      "2024-03-01 00:49:40 INFO     Training average negative_sample_loss at step 100300: 0.074544\n",
      "2024-03-01 00:49:40 INFO     Training average loss at step 100300: 0.079726\n",
      "2024-03-01 00:51:38 INFO     Training average positive_sample_loss at step 100400: 0.085473\n",
      "2024-03-01 00:51:38 INFO     Training average negative_sample_loss at step 100400: 0.074676\n",
      "2024-03-01 00:51:38 INFO     Training average loss at step 100400: 0.080074\n",
      "2024-03-01 00:53:16 INFO     Training average positive_sample_loss at step 100500: 0.085756\n",
      "2024-03-01 00:53:16 INFO     Training average negative_sample_loss at step 100500: 0.074650\n",
      "2024-03-01 00:53:16 INFO     Training average loss at step 100500: 0.080203\n",
      "2024-03-01 00:55:08 INFO     Training average positive_sample_loss at step 100600: 0.086556\n",
      "2024-03-01 00:55:08 INFO     Training average negative_sample_loss at step 100600: 0.074734\n",
      "2024-03-01 00:55:08 INFO     Training average loss at step 100600: 0.080645\n",
      "2024-03-01 00:56:34 INFO     Training average positive_sample_loss at step 100700: 0.086072\n",
      "2024-03-01 00:56:34 INFO     Training average negative_sample_loss at step 100700: 0.074988\n",
      "2024-03-01 00:56:34 INFO     Training average loss at step 100700: 0.080530\n",
      "2024-03-01 00:58:14 INFO     Training average positive_sample_loss at step 100800: 0.085916\n",
      "2024-03-01 00:58:14 INFO     Training average negative_sample_loss at step 100800: 0.074780\n",
      "2024-03-01 00:58:14 INFO     Training average loss at step 100800: 0.080348\n",
      "2024-03-01 01:00:06 INFO     Training average positive_sample_loss at step 100900: 0.086258\n",
      "2024-03-01 01:00:06 INFO     Training average negative_sample_loss at step 100900: 0.075472\n",
      "2024-03-01 01:00:06 INFO     Training average loss at step 100900: 0.080865\n",
      "2024-03-01 01:01:56 INFO     Training average positive_sample_loss at step 101000: 0.086390\n",
      "2024-03-01 01:01:56 INFO     Training average negative_sample_loss at step 101000: 0.075063\n",
      "2024-03-01 01:01:56 INFO     Training average loss at step 101000: 0.080726\n",
      "2024-03-01 01:03:55 INFO     Training average positive_sample_loss at step 101100: 0.084056\n",
      "2024-03-01 01:03:55 INFO     Training average negative_sample_loss at step 101100: 0.074958\n",
      "2024-03-01 01:03:55 INFO     Training average loss at step 101100: 0.079507\n",
      "2024-03-01 01:05:40 INFO     Training average positive_sample_loss at step 101200: 0.084576\n",
      "2024-03-01 01:05:40 INFO     Training average negative_sample_loss at step 101200: 0.074427\n",
      "2024-03-01 01:05:40 INFO     Training average loss at step 101200: 0.079501\n",
      "2024-03-01 01:07:08 INFO     Training average positive_sample_loss at step 101300: 0.084820\n",
      "2024-03-01 01:07:08 INFO     Training average negative_sample_loss at step 101300: 0.074129\n",
      "2024-03-01 01:07:08 INFO     Training average loss at step 101300: 0.079475\n",
      "2024-03-01 01:08:49 INFO     Training average positive_sample_loss at step 101400: 0.085537\n",
      "2024-03-01 01:08:49 INFO     Training average negative_sample_loss at step 101400: 0.074538\n",
      "2024-03-01 01:08:49 INFO     Training average loss at step 101400: 0.080038\n",
      "2024-03-01 01:10:44 INFO     Training average positive_sample_loss at step 101500: 0.085899\n",
      "2024-03-01 01:10:44 INFO     Training average negative_sample_loss at step 101500: 0.074458\n",
      "2024-03-01 01:10:44 INFO     Training average loss at step 101500: 0.080179\n",
      "2024-03-01 01:12:31 INFO     Training average positive_sample_loss at step 101600: 0.085817\n",
      "2024-03-01 01:12:31 INFO     Training average negative_sample_loss at step 101600: 0.074849\n",
      "2024-03-01 01:12:31 INFO     Training average loss at step 101600: 0.080333\n",
      "2024-03-01 01:14:20 INFO     Training average positive_sample_loss at step 101700: 0.086205\n",
      "2024-03-01 01:14:20 INFO     Training average negative_sample_loss at step 101700: 0.074932\n",
      "2024-03-01 01:14:20 INFO     Training average loss at step 101700: 0.080568\n",
      "2024-03-01 01:16:01 INFO     Training average positive_sample_loss at step 101800: 0.086225\n",
      "2024-03-01 01:16:01 INFO     Training average negative_sample_loss at step 101800: 0.075268\n",
      "2024-03-01 01:16:01 INFO     Training average loss at step 101800: 0.080747\n",
      "2024-03-01 01:18:03 INFO     Training average positive_sample_loss at step 101900: 0.086629\n",
      "2024-03-01 01:18:03 INFO     Training average negative_sample_loss at step 101900: 0.075319\n",
      "2024-03-01 01:18:03 INFO     Training average loss at step 101900: 0.080974\n",
      "2024-03-01 01:20:14 INFO     Training average positive_sample_loss at step 102000: 0.085335\n",
      "2024-03-01 01:20:14 INFO     Training average negative_sample_loss at step 102000: 0.075312\n",
      "2024-03-01 01:20:14 INFO     Training average loss at step 102000: 0.080323\n",
      "2024-03-01 01:22:11 INFO     Training average positive_sample_loss at step 102100: 0.084792\n",
      "2024-03-01 01:22:11 INFO     Training average negative_sample_loss at step 102100: 0.074763\n",
      "2024-03-01 01:22:11 INFO     Training average loss at step 102100: 0.079778\n",
      "2024-03-01 01:24:05 INFO     Training average positive_sample_loss at step 102200: 0.084790\n",
      "2024-03-01 01:24:05 INFO     Training average negative_sample_loss at step 102200: 0.074475\n",
      "2024-03-01 01:24:05 INFO     Training average loss at step 102200: 0.079633\n",
      "2024-03-01 01:26:11 INFO     Training average positive_sample_loss at step 102300: 0.085355\n",
      "2024-03-01 01:26:11 INFO     Training average negative_sample_loss at step 102300: 0.074238\n",
      "2024-03-01 01:26:11 INFO     Training average loss at step 102300: 0.079796\n",
      "2024-03-01 01:28:06 INFO     Training average positive_sample_loss at step 102400: 0.085826\n",
      "2024-03-01 01:28:06 INFO     Training average negative_sample_loss at step 102400: 0.074615\n",
      "2024-03-01 01:28:06 INFO     Training average loss at step 102400: 0.080221\n",
      "2024-03-01 01:29:39 INFO     Training average positive_sample_loss at step 102500: 0.085622\n",
      "2024-03-01 01:29:39 INFO     Training average negative_sample_loss at step 102500: 0.074434\n",
      "2024-03-01 01:29:39 INFO     Training average loss at step 102500: 0.080028\n",
      "2024-03-01 01:31:18 INFO     Training average positive_sample_loss at step 102600: 0.085582\n",
      "2024-03-01 01:31:18 INFO     Training average negative_sample_loss at step 102600: 0.074924\n",
      "2024-03-01 01:31:18 INFO     Training average loss at step 102600: 0.080253\n",
      "2024-03-01 01:33:09 INFO     Training average positive_sample_loss at step 102700: 0.086041\n",
      "2024-03-01 01:33:09 INFO     Training average negative_sample_loss at step 102700: 0.074738\n",
      "2024-03-01 01:33:09 INFO     Training average loss at step 102700: 0.080390\n",
      "2024-03-01 01:34:54 INFO     Training average positive_sample_loss at step 102800: 0.086554\n",
      "2024-03-01 01:34:54 INFO     Training average negative_sample_loss at step 102800: 0.075327\n",
      "2024-03-01 01:34:54 INFO     Training average loss at step 102800: 0.080941\n",
      "2024-03-01 01:36:48 INFO     Training average positive_sample_loss at step 102900: 0.086272\n",
      "2024-03-01 01:36:48 INFO     Training average negative_sample_loss at step 102900: 0.075412\n",
      "2024-03-01 01:36:48 INFO     Training average loss at step 102900: 0.080842\n",
      "2024-03-01 01:38:35 INFO     Training average positive_sample_loss at step 103000: 0.083764\n",
      "2024-03-01 01:38:35 INFO     Training average negative_sample_loss at step 103000: 0.074650\n",
      "2024-03-01 01:38:35 INFO     Training average loss at step 103000: 0.079207\n",
      "2024-03-01 01:40:24 INFO     Training average positive_sample_loss at step 103100: 0.084866\n",
      "2024-03-01 01:40:24 INFO     Training average negative_sample_loss at step 103100: 0.074416\n",
      "2024-03-01 01:40:24 INFO     Training average loss at step 103100: 0.079641\n",
      "2024-03-01 01:42:14 INFO     Training average positive_sample_loss at step 103200: 0.085060\n",
      "2024-03-01 01:42:14 INFO     Training average negative_sample_loss at step 103200: 0.074212\n",
      "2024-03-01 01:42:14 INFO     Training average loss at step 103200: 0.079636\n",
      "2024-03-01 01:43:47 INFO     Training average positive_sample_loss at step 103300: 0.085788\n",
      "2024-03-01 01:43:47 INFO     Training average negative_sample_loss at step 103300: 0.074779\n",
      "2024-03-01 01:43:47 INFO     Training average loss at step 103300: 0.080283\n",
      "2024-03-01 01:45:33 INFO     Training average positive_sample_loss at step 103400: 0.085992\n",
      "2024-03-01 01:45:33 INFO     Training average negative_sample_loss at step 103400: 0.074760\n",
      "2024-03-01 01:45:33 INFO     Training average loss at step 103400: 0.080376\n",
      "2024-03-01 01:47:27 INFO     Training average positive_sample_loss at step 103500: 0.086003\n",
      "2024-03-01 01:47:27 INFO     Training average negative_sample_loss at step 103500: 0.074944\n",
      "2024-03-01 01:47:27 INFO     Training average loss at step 103500: 0.080473\n",
      "2024-03-01 01:49:16 INFO     Training average positive_sample_loss at step 103600: 0.086034\n",
      "2024-03-01 01:49:16 INFO     Training average negative_sample_loss at step 103600: 0.074852\n",
      "2024-03-01 01:49:16 INFO     Training average loss at step 103600: 0.080443\n",
      "2024-03-01 01:51:07 INFO     Training average positive_sample_loss at step 103700: 0.086467\n",
      "2024-03-01 01:51:07 INFO     Training average negative_sample_loss at step 103700: 0.075291\n",
      "2024-03-01 01:51:07 INFO     Training average loss at step 103700: 0.080879\n",
      "2024-03-01 01:52:38 INFO     Training average positive_sample_loss at step 103800: 0.085856\n",
      "2024-03-01 01:52:38 INFO     Training average negative_sample_loss at step 103800: 0.075067\n",
      "2024-03-01 01:52:38 INFO     Training average loss at step 103800: 0.080461\n",
      "2024-03-01 01:54:33 INFO     Training average positive_sample_loss at step 103900: 0.084834\n",
      "2024-03-01 01:54:33 INFO     Training average negative_sample_loss at step 103900: 0.075096\n",
      "2024-03-01 01:54:33 INFO     Training average loss at step 103900: 0.079965\n",
      "2024-03-01 01:56:11 INFO     Training average positive_sample_loss at step 104000: 0.084308\n",
      "2024-03-01 01:56:11 INFO     Training average negative_sample_loss at step 104000: 0.074210\n",
      "2024-03-01 01:56:11 INFO     Training average loss at step 104000: 0.079259\n",
      "2024-03-01 01:58:06 INFO     Training average positive_sample_loss at step 104100: 0.085097\n",
      "2024-03-01 01:58:06 INFO     Training average negative_sample_loss at step 104100: 0.074558\n",
      "2024-03-01 01:58:06 INFO     Training average loss at step 104100: 0.079827\n",
      "2024-03-01 01:59:42 INFO     Training average positive_sample_loss at step 104200: 0.085374\n",
      "2024-03-01 01:59:42 INFO     Training average negative_sample_loss at step 104200: 0.074326\n",
      "2024-03-01 01:59:42 INFO     Training average loss at step 104200: 0.079850\n",
      "2024-03-01 02:01:33 INFO     Training average positive_sample_loss at step 104300: 0.085744\n",
      "2024-03-01 02:01:33 INFO     Training average negative_sample_loss at step 104300: 0.074697\n",
      "2024-03-01 02:01:33 INFO     Training average loss at step 104300: 0.080221\n",
      "2024-03-01 02:03:10 INFO     Training average positive_sample_loss at step 104400: 0.086188\n",
      "2024-03-01 02:03:10 INFO     Training average negative_sample_loss at step 104400: 0.074906\n",
      "2024-03-01 02:03:10 INFO     Training average loss at step 104400: 0.080547\n",
      "2024-03-01 02:05:04 INFO     Training average positive_sample_loss at step 104500: 0.085789\n",
      "2024-03-01 02:05:04 INFO     Training average negative_sample_loss at step 104500: 0.074600\n",
      "2024-03-01 02:05:04 INFO     Training average loss at step 104500: 0.080194\n",
      "2024-03-01 02:06:53 INFO     Training average positive_sample_loss at step 104600: 0.086226\n",
      "2024-03-01 02:06:53 INFO     Training average negative_sample_loss at step 104600: 0.075075\n",
      "2024-03-01 02:06:53 INFO     Training average loss at step 104600: 0.080651\n",
      "2024-03-01 02:08:38 INFO     Training average positive_sample_loss at step 104700: 0.086327\n",
      "2024-03-01 02:08:38 INFO     Training average negative_sample_loss at step 104700: 0.075566\n",
      "2024-03-01 02:08:38 INFO     Training average loss at step 104700: 0.080947\n",
      "2024-03-01 02:10:32 INFO     Training average positive_sample_loss at step 104800: 0.085991\n",
      "2024-03-01 02:10:32 INFO     Training average negative_sample_loss at step 104800: 0.075092\n",
      "2024-03-01 02:10:32 INFO     Training average loss at step 104800: 0.080541\n",
      "2024-03-01 02:12:20 INFO     Training average positive_sample_loss at step 104900: 0.083927\n",
      "2024-03-01 02:12:20 INFO     Training average negative_sample_loss at step 104900: 0.074528\n",
      "2024-03-01 02:12:20 INFO     Training average loss at step 104900: 0.079228\n",
      "2024-03-01 02:14:12 INFO     Training average positive_sample_loss at step 105000: 0.084729\n",
      "2024-03-01 02:14:12 INFO     Training average negative_sample_loss at step 105000: 0.074378\n",
      "2024-03-01 02:14:12 INFO     Training average loss at step 105000: 0.079553\n",
      "2024-03-01 02:16:21 INFO     Training average positive_sample_loss at step 105100: 0.085287\n",
      "2024-03-01 02:16:21 INFO     Training average negative_sample_loss at step 105100: 0.074456\n",
      "2024-03-01 02:16:21 INFO     Training average loss at step 105100: 0.079872\n",
      "2024-03-01 02:17:58 INFO     Training average positive_sample_loss at step 105200: 0.085676\n",
      "2024-03-01 02:17:58 INFO     Training average negative_sample_loss at step 105200: 0.074350\n",
      "2024-03-01 02:17:58 INFO     Training average loss at step 105200: 0.080013\n",
      "2024-03-01 02:19:30 INFO     Training average positive_sample_loss at step 105300: 0.085749\n",
      "2024-03-01 02:19:30 INFO     Training average negative_sample_loss at step 105300: 0.074713\n",
      "2024-03-01 02:19:30 INFO     Training average loss at step 105300: 0.080231\n",
      "2024-03-01 02:21:09 INFO     Training average positive_sample_loss at step 105400: 0.086049\n",
      "2024-03-01 02:21:09 INFO     Training average negative_sample_loss at step 105400: 0.074943\n",
      "2024-03-01 02:21:09 INFO     Training average loss at step 105400: 0.080496\n",
      "2024-03-01 02:22:38 INFO     Training average positive_sample_loss at step 105500: 0.085862\n",
      "2024-03-01 02:22:38 INFO     Training average negative_sample_loss at step 105500: 0.074772\n",
      "2024-03-01 02:22:38 INFO     Training average loss at step 105500: 0.080317\n",
      "2024-03-01 02:24:19 INFO     Training average positive_sample_loss at step 105600: 0.086216\n",
      "2024-03-01 02:24:19 INFO     Training average negative_sample_loss at step 105600: 0.074527\n",
      "2024-03-01 02:24:19 INFO     Training average loss at step 105600: 0.080371\n",
      "2024-03-01 02:26:12 INFO     Training average positive_sample_loss at step 105700: 0.086416\n",
      "2024-03-01 02:26:12 INFO     Training average negative_sample_loss at step 105700: 0.075432\n",
      "2024-03-01 02:26:12 INFO     Training average loss at step 105700: 0.080924\n",
      "2024-03-01 02:28:13 INFO     Training average positive_sample_loss at step 105800: 0.084524\n",
      "2024-03-01 02:28:13 INFO     Training average negative_sample_loss at step 105800: 0.074939\n",
      "2024-03-01 02:28:13 INFO     Training average loss at step 105800: 0.079732\n",
      "2024-03-01 02:29:53 INFO     Training average positive_sample_loss at step 105900: 0.084488\n",
      "2024-03-01 02:29:53 INFO     Training average negative_sample_loss at step 105900: 0.074390\n",
      "2024-03-01 02:29:53 INFO     Training average loss at step 105900: 0.079439\n",
      "2024-03-01 02:31:46 INFO     Training average positive_sample_loss at step 106000: 0.085258\n",
      "2024-03-01 02:31:46 INFO     Training average negative_sample_loss at step 106000: 0.074733\n",
      "2024-03-01 02:31:46 INFO     Training average loss at step 106000: 0.079995\n",
      "2024-03-01 02:33:23 INFO     Training average positive_sample_loss at step 106100: 0.085381\n",
      "2024-03-01 02:33:23 INFO     Training average negative_sample_loss at step 106100: 0.074353\n",
      "2024-03-01 02:33:23 INFO     Training average loss at step 106100: 0.079867\n",
      "2024-03-01 02:34:55 INFO     Training average positive_sample_loss at step 106200: 0.085593\n",
      "2024-03-01 02:34:55 INFO     Training average negative_sample_loss at step 106200: 0.074710\n",
      "2024-03-01 02:34:55 INFO     Training average loss at step 106200: 0.080152\n",
      "2024-03-01 02:36:31 INFO     Training average positive_sample_loss at step 106300: 0.085491\n",
      "2024-03-01 02:36:31 INFO     Training average negative_sample_loss at step 106300: 0.074457\n",
      "2024-03-01 02:36:31 INFO     Training average loss at step 106300: 0.079974\n",
      "2024-03-01 02:38:04 INFO     Training average positive_sample_loss at step 106400: 0.086119\n",
      "2024-03-01 02:38:04 INFO     Training average negative_sample_loss at step 106400: 0.074845\n",
      "2024-03-01 02:38:04 INFO     Training average loss at step 106400: 0.080482\n",
      "2024-03-01 02:40:08 INFO     Training average positive_sample_loss at step 106500: 0.086068\n",
      "2024-03-01 02:40:08 INFO     Training average negative_sample_loss at step 106500: 0.074978\n",
      "2024-03-01 02:40:08 INFO     Training average loss at step 106500: 0.080523\n",
      "2024-03-01 02:41:59 INFO     Training average positive_sample_loss at step 106600: 0.086425\n",
      "2024-03-01 02:41:59 INFO     Training average negative_sample_loss at step 106600: 0.075248\n",
      "2024-03-01 02:41:59 INFO     Training average loss at step 106600: 0.080836\n",
      "2024-03-01 02:43:51 INFO     Training average positive_sample_loss at step 106700: 0.085606\n",
      "2024-03-01 02:43:51 INFO     Training average negative_sample_loss at step 106700: 0.074979\n",
      "2024-03-01 02:43:51 INFO     Training average loss at step 106700: 0.080292\n",
      "2024-03-01 02:45:31 INFO     Training average positive_sample_loss at step 106800: 0.084012\n",
      "2024-03-01 02:45:31 INFO     Training average negative_sample_loss at step 106800: 0.074455\n",
      "2024-03-01 02:45:31 INFO     Training average loss at step 106800: 0.079233\n",
      "2024-03-01 02:47:16 INFO     Training average positive_sample_loss at step 106900: 0.084995\n",
      "2024-03-01 02:47:16 INFO     Training average negative_sample_loss at step 106900: 0.074482\n",
      "2024-03-01 02:47:16 INFO     Training average loss at step 106900: 0.079739\n",
      "2024-03-01 02:49:02 INFO     Training average positive_sample_loss at step 107000: 0.085339\n",
      "2024-03-01 02:49:02 INFO     Training average negative_sample_loss at step 107000: 0.074395\n",
      "2024-03-01 02:49:02 INFO     Training average loss at step 107000: 0.079867\n",
      "2024-03-01 02:50:53 INFO     Training average positive_sample_loss at step 107100: 0.085740\n",
      "2024-03-01 02:50:53 INFO     Training average negative_sample_loss at step 107100: 0.074757\n",
      "2024-03-01 02:50:53 INFO     Training average loss at step 107100: 0.080249\n",
      "2024-03-01 02:52:49 INFO     Training average positive_sample_loss at step 107200: 0.085764\n",
      "2024-03-01 02:52:49 INFO     Training average negative_sample_loss at step 107200: 0.074839\n",
      "2024-03-01 02:52:49 INFO     Training average loss at step 107200: 0.080302\n",
      "2024-03-01 02:54:38 INFO     Training average positive_sample_loss at step 107300: 0.085421\n",
      "2024-03-01 02:54:38 INFO     Training average negative_sample_loss at step 107300: 0.074167\n",
      "2024-03-01 02:54:38 INFO     Training average loss at step 107300: 0.079794\n",
      "2024-03-01 02:56:08 INFO     Training average positive_sample_loss at step 107400: 0.086016\n",
      "2024-03-01 02:56:08 INFO     Training average negative_sample_loss at step 107400: 0.075037\n",
      "2024-03-01 02:56:08 INFO     Training average loss at step 107400: 0.080527\n",
      "2024-03-01 02:57:37 INFO     Training average positive_sample_loss at step 107500: 0.086690\n",
      "2024-03-01 02:57:37 INFO     Training average negative_sample_loss at step 107500: 0.075525\n",
      "2024-03-01 02:57:37 INFO     Training average loss at step 107500: 0.081108\n",
      "2024-03-01 02:59:30 INFO     Training average positive_sample_loss at step 107600: 0.085762\n",
      "2024-03-01 02:59:30 INFO     Training average negative_sample_loss at step 107600: 0.075083\n",
      "2024-03-01 02:59:30 INFO     Training average loss at step 107600: 0.080423\n",
      "2024-03-01 03:01:35 INFO     Training average positive_sample_loss at step 107700: 0.084464\n",
      "2024-03-01 03:01:35 INFO     Training average negative_sample_loss at step 107700: 0.074518\n",
      "2024-03-01 03:01:35 INFO     Training average loss at step 107700: 0.079491\n",
      "2024-03-01 03:03:20 INFO     Training average positive_sample_loss at step 107800: 0.084571\n",
      "2024-03-01 03:03:20 INFO     Training average negative_sample_loss at step 107800: 0.074578\n",
      "2024-03-01 03:03:20 INFO     Training average loss at step 107800: 0.079574\n",
      "2024-03-01 03:05:07 INFO     Training average positive_sample_loss at step 107900: 0.085600\n",
      "2024-03-01 03:05:07 INFO     Training average negative_sample_loss at step 107900: 0.074469\n",
      "2024-03-01 03:05:07 INFO     Training average loss at step 107900: 0.080034\n",
      "2024-03-01 03:06:58 INFO     Training average positive_sample_loss at step 108000: 0.085279\n",
      "2024-03-01 03:06:58 INFO     Training average negative_sample_loss at step 108000: 0.074352\n",
      "2024-03-01 03:06:58 INFO     Training average loss at step 108000: 0.079815\n",
      "2024-03-01 03:08:45 INFO     Training average positive_sample_loss at step 108100: 0.085079\n",
      "2024-03-01 03:08:45 INFO     Training average negative_sample_loss at step 108100: 0.074189\n",
      "2024-03-01 03:08:45 INFO     Training average loss at step 108100: 0.079634\n",
      "2024-03-01 03:10:36 INFO     Training average positive_sample_loss at step 108200: 0.086149\n",
      "2024-03-01 03:10:36 INFO     Training average negative_sample_loss at step 108200: 0.074784\n",
      "2024-03-01 03:10:36 INFO     Training average loss at step 108200: 0.080466\n",
      "2024-03-01 03:12:28 INFO     Training average positive_sample_loss at step 108300: 0.085965\n",
      "2024-03-01 03:12:28 INFO     Training average negative_sample_loss at step 108300: 0.075060\n",
      "2024-03-01 03:12:28 INFO     Training average loss at step 108300: 0.080513\n",
      "2024-03-01 03:14:24 INFO     Training average positive_sample_loss at step 108400: 0.086192\n",
      "2024-03-01 03:14:24 INFO     Training average negative_sample_loss at step 108400: 0.074930\n",
      "2024-03-01 03:14:24 INFO     Training average loss at step 108400: 0.080561\n",
      "2024-03-01 03:16:12 INFO     Training average positive_sample_loss at step 108500: 0.085918\n",
      "2024-03-01 03:16:12 INFO     Training average negative_sample_loss at step 108500: 0.074876\n",
      "2024-03-01 03:16:12 INFO     Training average loss at step 108500: 0.080397\n",
      "2024-03-01 03:17:59 INFO     Training average positive_sample_loss at step 108600: 0.085379\n",
      "2024-03-01 03:17:59 INFO     Training average negative_sample_loss at step 108600: 0.075067\n",
      "2024-03-01 03:17:59 INFO     Training average loss at step 108600: 0.080223\n",
      "2024-03-01 03:19:34 INFO     Training average positive_sample_loss at step 108700: 0.083846\n",
      "2024-03-01 03:19:34 INFO     Training average negative_sample_loss at step 108700: 0.074175\n",
      "2024-03-01 03:19:34 INFO     Training average loss at step 108700: 0.079011\n",
      "2024-03-01 03:21:27 INFO     Training average positive_sample_loss at step 108800: 0.084790\n",
      "2024-03-01 03:21:27 INFO     Training average negative_sample_loss at step 108800: 0.074468\n",
      "2024-03-01 03:21:27 INFO     Training average loss at step 108800: 0.079629\n",
      "2024-03-01 03:23:19 INFO     Training average positive_sample_loss at step 108900: 0.085149\n",
      "2024-03-01 03:23:19 INFO     Training average negative_sample_loss at step 108900: 0.074373\n",
      "2024-03-01 03:23:19 INFO     Training average loss at step 108900: 0.079761\n",
      "2024-03-01 03:25:04 INFO     Training average positive_sample_loss at step 109000: 0.085522\n",
      "2024-03-01 03:25:04 INFO     Training average negative_sample_loss at step 109000: 0.074374\n",
      "2024-03-01 03:25:04 INFO     Training average loss at step 109000: 0.079948\n",
      "2024-03-01 03:26:40 INFO     Training average positive_sample_loss at step 109100: 0.086359\n",
      "2024-03-01 03:26:40 INFO     Training average negative_sample_loss at step 109100: 0.074797\n",
      "2024-03-01 03:26:40 INFO     Training average loss at step 109100: 0.080578\n",
      "2024-03-01 03:28:16 INFO     Training average positive_sample_loss at step 109200: 0.086090\n",
      "2024-03-01 03:28:16 INFO     Training average negative_sample_loss at step 109200: 0.075291\n",
      "2024-03-01 03:28:16 INFO     Training average loss at step 109200: 0.080690\n",
      "2024-03-01 03:29:56 INFO     Training average positive_sample_loss at step 109300: 0.086287\n",
      "2024-03-01 03:29:56 INFO     Training average negative_sample_loss at step 109300: 0.074925\n",
      "2024-03-01 03:29:56 INFO     Training average loss at step 109300: 0.080606\n",
      "2024-03-01 03:32:01 INFO     Training average positive_sample_loss at step 109400: 0.086172\n",
      "2024-03-01 03:32:01 INFO     Training average negative_sample_loss at step 109400: 0.075126\n",
      "2024-03-01 03:32:01 INFO     Training average loss at step 109400: 0.080649\n",
      "2024-03-01 03:34:39 INFO     Training average positive_sample_loss at step 109500: 0.085838\n",
      "2024-03-01 03:34:39 INFO     Training average negative_sample_loss at step 109500: 0.074721\n",
      "2024-03-01 03:34:39 INFO     Training average loss at step 109500: 0.080280\n",
      "2024-03-01 03:36:38 INFO     Training average positive_sample_loss at step 109600: 0.084181\n",
      "2024-03-01 03:36:38 INFO     Training average negative_sample_loss at step 109600: 0.075149\n",
      "2024-03-01 03:36:38 INFO     Training average loss at step 109600: 0.079665\n",
      "2024-03-01 03:38:17 INFO     Training average positive_sample_loss at step 109700: 0.084776\n",
      "2024-03-01 03:38:17 INFO     Training average negative_sample_loss at step 109700: 0.074307\n",
      "2024-03-01 03:38:17 INFO     Training average loss at step 109700: 0.079541\n",
      "2024-03-01 03:40:22 INFO     Training average positive_sample_loss at step 109800: 0.085092\n",
      "2024-03-01 03:40:22 INFO     Training average negative_sample_loss at step 109800: 0.074081\n",
      "2024-03-01 03:40:22 INFO     Training average loss at step 109800: 0.079586\n",
      "2024-03-01 03:42:24 INFO     Training average positive_sample_loss at step 109900: 0.085206\n",
      "2024-03-01 03:42:24 INFO     Training average negative_sample_loss at step 109900: 0.074315\n",
      "2024-03-01 03:42:24 INFO     Training average loss at step 109900: 0.079761\n",
      "2024-03-01 03:44:19 INFO     Training average positive_sample_loss at step 110000: 0.085859\n",
      "2024-03-01 03:44:19 INFO     Training average negative_sample_loss at step 110000: 0.074459\n",
      "2024-03-01 03:44:19 INFO     Training average loss at step 110000: 0.080159\n",
      "2024-03-01 03:44:19 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 03:44:20 INFO     Evaluating the model... (0/6250)\n",
      "2024-03-01 03:44:57 INFO     Evaluating the model... (1000/6250)\n",
      "2024-03-01 03:45:29 INFO     Evaluating the model... (2000/6250)\n",
      "2024-03-01 03:45:59 INFO     Evaluating the model... (3000/6250)\n",
      "2024-03-01 03:46:34 INFO     Evaluating the model... (4000/6250)\n",
      "2024-03-01 03:47:03 INFO     Evaluating the model... (5000/6250)\n",
      "2024-03-01 03:47:32 INFO     Evaluating the model... (6000/6250)\n",
      "2024-03-01 03:47:39 INFO     Valid MRR at step 110000: 0.445337\n",
      "2024-03-01 03:47:39 INFO     Valid MR at step 110000: 218.873630\n",
      "2024-03-01 03:47:39 INFO     Valid HITS@1 at step 110000: 0.348260\n",
      "2024-03-01 03:47:39 INFO     Valid HITS@3 at step 110000: 0.479080\n",
      "2024-03-01 03:47:39 INFO     Valid HITS@10 at step 110000: 0.656770\n",
      "2024-03-01 03:49:15 INFO     Training average positive_sample_loss at step 110100: 0.085381\n",
      "2024-03-01 03:49:15 INFO     Training average negative_sample_loss at step 110100: 0.074804\n",
      "2024-03-01 03:49:15 INFO     Training average loss at step 110100: 0.080092\n",
      "2024-03-01 03:51:05 INFO     Training average positive_sample_loss at step 110200: 0.085885\n",
      "2024-03-01 03:51:05 INFO     Training average negative_sample_loss at step 110200: 0.074695\n",
      "2024-03-01 03:51:05 INFO     Training average loss at step 110200: 0.080290\n",
      "2024-03-01 03:52:54 INFO     Training average positive_sample_loss at step 110300: 0.086206\n",
      "2024-03-01 03:52:54 INFO     Training average negative_sample_loss at step 110300: 0.074869\n",
      "2024-03-01 03:52:54 INFO     Training average loss at step 110300: 0.080537\n",
      "2024-03-01 03:54:47 INFO     Training average positive_sample_loss at step 110400: 0.086138\n",
      "2024-03-01 03:54:47 INFO     Training average negative_sample_loss at step 110400: 0.075061\n",
      "2024-03-01 03:54:47 INFO     Training average loss at step 110400: 0.080599\n",
      "2024-03-01 03:56:46 INFO     Training average positive_sample_loss at step 110500: 0.084810\n",
      "2024-03-01 03:56:46 INFO     Training average negative_sample_loss at step 110500: 0.075069\n",
      "2024-03-01 03:56:46 INFO     Training average loss at step 110500: 0.079940\n",
      "2024-03-01 03:58:34 INFO     Training average positive_sample_loss at step 110600: 0.084141\n",
      "2024-03-01 03:58:34 INFO     Training average negative_sample_loss at step 110600: 0.074298\n",
      "2024-03-01 03:58:34 INFO     Training average loss at step 110600: 0.079220\n",
      "2024-03-01 04:00:23 INFO     Training average positive_sample_loss at step 110700: 0.085120\n",
      "2024-03-01 04:00:23 INFO     Training average negative_sample_loss at step 110700: 0.074381\n",
      "2024-03-01 04:00:23 INFO     Training average loss at step 110700: 0.079751\n",
      "2024-03-01 04:02:30 INFO     Training average positive_sample_loss at step 110800: 0.085506\n",
      "2024-03-01 04:02:30 INFO     Training average negative_sample_loss at step 110800: 0.074694\n",
      "2024-03-01 04:02:30 INFO     Training average loss at step 110800: 0.080100\n",
      "2024-03-01 04:04:21 INFO     Training average positive_sample_loss at step 110900: 0.085466\n",
      "2024-03-01 04:04:21 INFO     Training average negative_sample_loss at step 110900: 0.074323\n",
      "2024-03-01 04:04:21 INFO     Training average loss at step 110900: 0.079895\n",
      "2024-03-01 04:06:37 INFO     Training average positive_sample_loss at step 111000: 0.085711\n",
      "2024-03-01 04:06:37 INFO     Training average negative_sample_loss at step 111000: 0.074543\n",
      "2024-03-01 04:06:37 INFO     Training average loss at step 111000: 0.080127\n",
      "2024-03-01 04:08:42 INFO     Training average positive_sample_loss at step 111100: 0.086166\n",
      "2024-03-01 04:08:42 INFO     Training average negative_sample_loss at step 111100: 0.075051\n",
      "2024-03-01 04:08:42 INFO     Training average loss at step 111100: 0.080608\n",
      "2024-03-01 04:10:25 INFO     Training average positive_sample_loss at step 111200: 0.086153\n",
      "2024-03-01 04:10:25 INFO     Training average negative_sample_loss at step 111200: 0.074968\n",
      "2024-03-01 04:10:25 INFO     Training average loss at step 111200: 0.080561\n",
      "2024-03-01 04:12:36 INFO     Training average positive_sample_loss at step 111300: 0.086213\n",
      "2024-03-01 04:12:36 INFO     Training average negative_sample_loss at step 111300: 0.075376\n",
      "2024-03-01 04:12:36 INFO     Training average loss at step 111300: 0.080794\n",
      "2024-03-01 04:14:21 INFO     Training average positive_sample_loss at step 111400: 0.086275\n",
      "2024-03-01 04:14:21 INFO     Training average negative_sample_loss at step 111400: 0.075016\n",
      "2024-03-01 04:14:21 INFO     Training average loss at step 111400: 0.080645\n",
      "2024-03-01 04:16:19 INFO     Training average positive_sample_loss at step 111500: 0.083972\n",
      "2024-03-01 04:16:19 INFO     Training average negative_sample_loss at step 111500: 0.074722\n",
      "2024-03-01 04:16:19 INFO     Training average loss at step 111500: 0.079347\n",
      "2024-03-01 04:18:15 INFO     Training average positive_sample_loss at step 111600: 0.084448\n",
      "2024-03-01 04:18:15 INFO     Training average negative_sample_loss at step 111600: 0.074182\n",
      "2024-03-01 04:18:15 INFO     Training average loss at step 111600: 0.079315\n",
      "2024-03-01 04:20:17 INFO     Training average positive_sample_loss at step 111700: 0.085000\n",
      "2024-03-01 04:20:17 INFO     Training average negative_sample_loss at step 111700: 0.074182\n",
      "2024-03-01 04:20:17 INFO     Training average loss at step 111700: 0.079591\n",
      "2024-03-01 04:22:17 INFO     Training average positive_sample_loss at step 111800: 0.085429\n",
      "2024-03-01 04:22:17 INFO     Training average negative_sample_loss at step 111800: 0.074522\n",
      "2024-03-01 04:22:17 INFO     Training average loss at step 111800: 0.079975\n",
      "2024-03-01 04:24:06 INFO     Training average positive_sample_loss at step 111900: 0.085703\n",
      "2024-03-01 04:24:06 INFO     Training average negative_sample_loss at step 111900: 0.074504\n",
      "2024-03-01 04:24:06 INFO     Training average loss at step 111900: 0.080104\n",
      "2024-03-01 04:26:09 INFO     Training average positive_sample_loss at step 112000: 0.085975\n",
      "2024-03-01 04:26:09 INFO     Training average negative_sample_loss at step 112000: 0.074759\n",
      "2024-03-01 04:26:09 INFO     Training average loss at step 112000: 0.080367\n",
      "2024-03-01 04:28:05 INFO     Training average positive_sample_loss at step 112100: 0.086336\n",
      "2024-03-01 04:28:05 INFO     Training average negative_sample_loss at step 112100: 0.075110\n",
      "2024-03-01 04:28:05 INFO     Training average loss at step 112100: 0.080723\n",
      "2024-03-01 04:30:00 INFO     Training average positive_sample_loss at step 112200: 0.085911\n",
      "2024-03-01 04:30:00 INFO     Training average negative_sample_loss at step 112200: 0.074804\n",
      "2024-03-01 04:30:00 INFO     Training average loss at step 112200: 0.080357\n",
      "2024-03-01 04:32:06 INFO     Training average positive_sample_loss at step 112300: 0.086359\n",
      "2024-03-01 04:32:06 INFO     Training average negative_sample_loss at step 112300: 0.075302\n",
      "2024-03-01 04:32:06 INFO     Training average loss at step 112300: 0.080831\n",
      "2024-03-01 04:34:11 INFO     Training average positive_sample_loss at step 112400: 0.084313\n",
      "2024-03-01 04:34:11 INFO     Training average negative_sample_loss at step 112400: 0.074629\n",
      "2024-03-01 04:34:11 INFO     Training average loss at step 112400: 0.079471\n",
      "2024-03-01 04:36:01 INFO     Training average positive_sample_loss at step 112500: 0.084337\n",
      "2024-03-01 04:36:01 INFO     Training average negative_sample_loss at step 112500: 0.074230\n",
      "2024-03-01 04:36:01 INFO     Training average loss at step 112500: 0.079284\n",
      "2024-03-01 04:38:00 INFO     Training average positive_sample_loss at step 112600: 0.085235\n",
      "2024-03-01 04:38:00 INFO     Training average negative_sample_loss at step 112600: 0.074730\n",
      "2024-03-01 04:38:00 INFO     Training average loss at step 112600: 0.079983\n",
      "2024-03-01 04:39:59 INFO     Training average positive_sample_loss at step 112700: 0.085175\n",
      "2024-03-01 04:39:59 INFO     Training average negative_sample_loss at step 112700: 0.074247\n",
      "2024-03-01 04:39:59 INFO     Training average loss at step 112700: 0.079711\n",
      "2024-03-01 04:41:54 INFO     Training average positive_sample_loss at step 112800: 0.085332\n",
      "2024-03-01 04:41:54 INFO     Training average negative_sample_loss at step 112800: 0.074319\n",
      "2024-03-01 04:41:54 INFO     Training average loss at step 112800: 0.079826\n",
      "2024-03-01 04:43:47 INFO     Training average positive_sample_loss at step 112900: 0.085920\n",
      "2024-03-01 04:43:47 INFO     Training average negative_sample_loss at step 112900: 0.074664\n",
      "2024-03-01 04:43:47 INFO     Training average loss at step 112900: 0.080292\n",
      "2024-03-01 04:45:46 INFO     Training average positive_sample_loss at step 113000: 0.086120\n",
      "2024-03-01 04:45:46 INFO     Training average negative_sample_loss at step 113000: 0.075130\n",
      "2024-03-01 04:45:46 INFO     Training average loss at step 113000: 0.080625\n",
      "2024-03-01 04:47:31 INFO     Training average positive_sample_loss at step 113100: 0.086159\n",
      "2024-03-01 04:47:31 INFO     Training average negative_sample_loss at step 113100: 0.074964\n",
      "2024-03-01 04:47:31 INFO     Training average loss at step 113100: 0.080561\n",
      "2024-03-01 04:49:27 INFO     Training average positive_sample_loss at step 113200: 0.086198\n",
      "2024-03-01 04:49:27 INFO     Training average negative_sample_loss at step 113200: 0.074773\n",
      "2024-03-01 04:49:27 INFO     Training average loss at step 113200: 0.080485\n",
      "2024-03-01 04:51:41 INFO     Training average positive_sample_loss at step 113300: 0.085961\n",
      "2024-03-01 04:51:41 INFO     Training average negative_sample_loss at step 113300: 0.075164\n",
      "2024-03-01 04:51:41 INFO     Training average loss at step 113300: 0.080562\n",
      "2024-03-01 04:53:27 INFO     Training average positive_sample_loss at step 113400: 0.084654\n",
      "2024-03-01 04:53:27 INFO     Training average negative_sample_loss at step 113400: 0.075158\n",
      "2024-03-01 04:53:27 INFO     Training average loss at step 113400: 0.079906\n",
      "2024-03-01 04:55:23 INFO     Training average positive_sample_loss at step 113500: 0.084823\n",
      "2024-03-01 04:55:23 INFO     Training average negative_sample_loss at step 113500: 0.074537\n",
      "2024-03-01 04:55:23 INFO     Training average loss at step 113500: 0.079680\n",
      "2024-03-01 04:57:32 INFO     Training average positive_sample_loss at step 113600: 0.084813\n",
      "2024-03-01 04:57:32 INFO     Training average negative_sample_loss at step 113600: 0.074199\n",
      "2024-03-01 04:57:32 INFO     Training average loss at step 113600: 0.079506\n",
      "2024-03-01 04:59:36 INFO     Training average positive_sample_loss at step 113700: 0.085287\n",
      "2024-03-01 04:59:36 INFO     Training average negative_sample_loss at step 113700: 0.074398\n",
      "2024-03-01 04:59:36 INFO     Training average loss at step 113700: 0.079842\n",
      "2024-03-01 05:01:18 INFO     Training average positive_sample_loss at step 113800: 0.085837\n",
      "2024-03-01 05:01:18 INFO     Training average negative_sample_loss at step 113800: 0.074556\n",
      "2024-03-01 05:01:18 INFO     Training average loss at step 113800: 0.080196\n",
      "2024-03-01 05:02:47 INFO     Training average positive_sample_loss at step 113900: 0.085874\n",
      "2024-03-01 05:02:47 INFO     Training average negative_sample_loss at step 113900: 0.074630\n",
      "2024-03-01 05:02:47 INFO     Training average loss at step 113900: 0.080252\n",
      "2024-03-01 05:04:25 INFO     Training average positive_sample_loss at step 114000: 0.085707\n",
      "2024-03-01 05:04:25 INFO     Training average negative_sample_loss at step 114000: 0.074788\n",
      "2024-03-01 05:04:25 INFO     Training average loss at step 114000: 0.080247\n",
      "2024-03-01 05:06:36 INFO     Training average positive_sample_loss at step 114100: 0.086031\n",
      "2024-03-01 05:06:36 INFO     Training average negative_sample_loss at step 114100: 0.074759\n",
      "2024-03-01 05:06:36 INFO     Training average loss at step 114100: 0.080395\n",
      "2024-03-01 05:08:29 INFO     Training average positive_sample_loss at step 114200: 0.086237\n",
      "2024-03-01 05:08:29 INFO     Training average negative_sample_loss at step 114200: 0.075193\n",
      "2024-03-01 05:08:29 INFO     Training average loss at step 114200: 0.080715\n",
      "2024-03-01 05:10:24 INFO     Training average positive_sample_loss at step 114300: 0.084078\n",
      "2024-03-01 05:10:24 INFO     Training average negative_sample_loss at step 114300: 0.074648\n",
      "2024-03-01 05:10:24 INFO     Training average loss at step 114300: 0.079363\n",
      "2024-03-01 05:12:35 INFO     Training average positive_sample_loss at step 114400: 0.084522\n",
      "2024-03-01 05:12:35 INFO     Training average negative_sample_loss at step 114400: 0.074082\n",
      "2024-03-01 05:12:35 INFO     Training average loss at step 114400: 0.079302\n",
      "2024-03-01 05:14:31 INFO     Training average positive_sample_loss at step 114500: 0.084951\n",
      "2024-03-01 05:14:31 INFO     Training average negative_sample_loss at step 114500: 0.074177\n",
      "2024-03-01 05:14:31 INFO     Training average loss at step 114500: 0.079564\n",
      "2024-03-01 05:16:27 INFO     Training average positive_sample_loss at step 114600: 0.084940\n",
      "2024-03-01 05:16:27 INFO     Training average negative_sample_loss at step 114600: 0.073972\n",
      "2024-03-01 05:16:27 INFO     Training average loss at step 114600: 0.079456\n",
      "2024-03-01 05:18:29 INFO     Training average positive_sample_loss at step 114700: 0.085872\n",
      "2024-03-01 05:18:29 INFO     Training average negative_sample_loss at step 114700: 0.074731\n",
      "2024-03-01 05:18:29 INFO     Training average loss at step 114700: 0.080302\n",
      "2024-03-01 05:20:17 INFO     Training average positive_sample_loss at step 114800: 0.085783\n",
      "2024-03-01 05:20:17 INFO     Training average negative_sample_loss at step 114800: 0.074883\n",
      "2024-03-01 05:20:17 INFO     Training average loss at step 114800: 0.080333\n",
      "2024-03-01 05:21:58 INFO     Training average positive_sample_loss at step 114900: 0.085822\n",
      "2024-03-01 05:21:58 INFO     Training average negative_sample_loss at step 114900: 0.074849\n",
      "2024-03-01 05:21:58 INFO     Training average loss at step 114900: 0.080336\n",
      "2024-03-01 05:23:47 INFO     Training average positive_sample_loss at step 115000: 0.086193\n",
      "2024-03-01 05:23:47 INFO     Training average negative_sample_loss at step 115000: 0.075141\n",
      "2024-03-01 05:23:47 INFO     Training average loss at step 115000: 0.080667\n",
      "2024-03-01 05:25:44 INFO     Training average positive_sample_loss at step 115100: 0.086239\n",
      "2024-03-01 05:25:44 INFO     Training average negative_sample_loss at step 115100: 0.074968\n",
      "2024-03-01 05:25:44 INFO     Training average loss at step 115100: 0.080604\n",
      "2024-03-01 05:27:38 INFO     Training average positive_sample_loss at step 115200: 0.085391\n",
      "2024-03-01 05:27:38 INFO     Training average negative_sample_loss at step 115200: 0.075184\n",
      "2024-03-01 05:27:38 INFO     Training average loss at step 115200: 0.080287\n",
      "2024-03-01 05:29:33 INFO     Training average positive_sample_loss at step 115300: 0.084294\n",
      "2024-03-01 05:29:33 INFO     Training average negative_sample_loss at step 115300: 0.074605\n",
      "2024-03-01 05:29:33 INFO     Training average loss at step 115300: 0.079449\n",
      "2024-03-01 05:31:10 INFO     Training average positive_sample_loss at step 115400: 0.084804\n",
      "2024-03-01 05:31:10 INFO     Training average negative_sample_loss at step 115400: 0.074074\n",
      "2024-03-01 05:31:10 INFO     Training average loss at step 115400: 0.079439\n",
      "2024-03-01 05:33:19 INFO     Training average positive_sample_loss at step 115500: 0.084982\n",
      "2024-03-01 05:33:19 INFO     Training average negative_sample_loss at step 115500: 0.074209\n",
      "2024-03-01 05:33:19 INFO     Training average loss at step 115500: 0.079595\n",
      "2024-03-01 05:35:23 INFO     Training average positive_sample_loss at step 115600: 0.085240\n",
      "2024-03-01 05:35:23 INFO     Training average negative_sample_loss at step 115600: 0.074157\n",
      "2024-03-01 05:35:23 INFO     Training average loss at step 115600: 0.079698\n",
      "2024-03-01 05:37:12 INFO     Training average positive_sample_loss at step 115700: 0.085811\n",
      "2024-03-01 05:37:12 INFO     Training average negative_sample_loss at step 115700: 0.074954\n",
      "2024-03-01 05:37:12 INFO     Training average loss at step 115700: 0.080383\n",
      "2024-03-01 05:38:54 INFO     Training average positive_sample_loss at step 115800: 0.086128\n",
      "2024-03-01 05:38:54 INFO     Training average negative_sample_loss at step 115800: 0.074434\n",
      "2024-03-01 05:38:54 INFO     Training average loss at step 115800: 0.080281\n",
      "2024-03-01 05:40:57 INFO     Training average positive_sample_loss at step 115900: 0.085976\n",
      "2024-03-01 05:40:57 INFO     Training average negative_sample_loss at step 115900: 0.074690\n",
      "2024-03-01 05:40:57 INFO     Training average loss at step 115900: 0.080333\n",
      "2024-03-01 05:42:47 INFO     Training average positive_sample_loss at step 116000: 0.085961\n",
      "2024-03-01 05:42:47 INFO     Training average negative_sample_loss at step 116000: 0.074848\n",
      "2024-03-01 05:42:47 INFO     Training average loss at step 116000: 0.080405\n",
      "2024-03-01 05:44:25 INFO     Training average positive_sample_loss at step 116100: 0.086244\n",
      "2024-03-01 05:44:25 INFO     Training average negative_sample_loss at step 116100: 0.075408\n",
      "2024-03-01 05:44:25 INFO     Training average loss at step 116100: 0.080826\n",
      "2024-03-01 05:46:24 INFO     Training average positive_sample_loss at step 116200: 0.084299\n",
      "2024-03-01 05:46:24 INFO     Training average negative_sample_loss at step 116200: 0.074929\n",
      "2024-03-01 05:46:24 INFO     Training average loss at step 116200: 0.079614\n",
      "2024-03-01 05:48:12 INFO     Training average positive_sample_loss at step 116300: 0.084758\n",
      "2024-03-01 05:48:12 INFO     Training average negative_sample_loss at step 116300: 0.074426\n",
      "2024-03-01 05:48:12 INFO     Training average loss at step 116300: 0.079592\n",
      "2024-03-01 05:50:02 INFO     Training average positive_sample_loss at step 116400: 0.085364\n",
      "2024-03-01 05:50:02 INFO     Training average negative_sample_loss at step 116400: 0.074460\n",
      "2024-03-01 05:50:02 INFO     Training average loss at step 116400: 0.079912\n",
      "2024-03-01 05:51:52 INFO     Training average positive_sample_loss at step 116500: 0.084815\n",
      "2024-03-01 05:51:52 INFO     Training average negative_sample_loss at step 116500: 0.073977\n",
      "2024-03-01 05:51:52 INFO     Training average loss at step 116500: 0.079396\n",
      "2024-03-01 05:53:42 INFO     Training average positive_sample_loss at step 116600: 0.085944\n",
      "2024-03-01 05:53:42 INFO     Training average negative_sample_loss at step 116600: 0.074536\n",
      "2024-03-01 05:53:42 INFO     Training average loss at step 116600: 0.080240\n",
      "2024-03-01 05:55:29 INFO     Training average positive_sample_loss at step 116700: 0.085166\n",
      "2024-03-01 05:55:29 INFO     Training average negative_sample_loss at step 116700: 0.074400\n",
      "2024-03-01 05:55:29 INFO     Training average loss at step 116700: 0.079783\n",
      "2024-03-01 05:57:03 INFO     Training average positive_sample_loss at step 116800: 0.085894\n",
      "2024-03-01 05:57:03 INFO     Training average negative_sample_loss at step 116800: 0.074901\n",
      "2024-03-01 05:57:03 INFO     Training average loss at step 116800: 0.080397\n",
      "2024-03-01 05:58:39 INFO     Training average positive_sample_loss at step 116900: 0.086042\n",
      "2024-03-01 05:58:39 INFO     Training average negative_sample_loss at step 116900: 0.074814\n",
      "2024-03-01 05:58:39 INFO     Training average loss at step 116900: 0.080428\n",
      "2024-03-01 06:00:25 INFO     Training average positive_sample_loss at step 117000: 0.085994\n",
      "2024-03-01 06:00:25 INFO     Training average negative_sample_loss at step 117000: 0.075155\n",
      "2024-03-01 06:00:25 INFO     Training average loss at step 117000: 0.080575\n",
      "2024-03-01 06:02:22 INFO     Training average positive_sample_loss at step 117100: 0.084735\n",
      "2024-03-01 06:02:22 INFO     Training average negative_sample_loss at step 117100: 0.074922\n",
      "2024-03-01 06:02:22 INFO     Training average loss at step 117100: 0.079829\n",
      "2024-03-01 06:04:02 INFO     Training average positive_sample_loss at step 117200: 0.084399\n",
      "2024-03-01 06:04:02 INFO     Training average negative_sample_loss at step 117200: 0.074469\n",
      "2024-03-01 06:04:02 INFO     Training average loss at step 117200: 0.079434\n",
      "2024-03-01 06:05:41 INFO     Training average positive_sample_loss at step 117300: 0.085099\n",
      "2024-03-01 06:05:41 INFO     Training average negative_sample_loss at step 117300: 0.074232\n",
      "2024-03-01 06:05:41 INFO     Training average loss at step 117300: 0.079665\n",
      "2024-03-01 06:07:32 INFO     Training average positive_sample_loss at step 117400: 0.085487\n",
      "2024-03-01 06:07:32 INFO     Training average negative_sample_loss at step 117400: 0.074521\n",
      "2024-03-01 06:07:32 INFO     Training average loss at step 117400: 0.080004\n",
      "2024-03-01 06:09:24 INFO     Training average positive_sample_loss at step 117500: 0.085150\n",
      "2024-03-01 06:09:24 INFO     Training average negative_sample_loss at step 117500: 0.074240\n",
      "2024-03-01 06:09:24 INFO     Training average loss at step 117500: 0.079695\n",
      "2024-03-01 06:11:20 INFO     Training average positive_sample_loss at step 117600: 0.085163\n",
      "2024-03-01 06:11:20 INFO     Training average negative_sample_loss at step 117600: 0.074595\n",
      "2024-03-01 06:11:20 INFO     Training average loss at step 117600: 0.079879\n",
      "2024-03-01 06:13:07 INFO     Training average positive_sample_loss at step 117700: 0.086260\n",
      "2024-03-01 06:13:07 INFO     Training average negative_sample_loss at step 117700: 0.074765\n",
      "2024-03-01 06:13:07 INFO     Training average loss at step 117700: 0.080512\n",
      "2024-03-01 06:15:10 INFO     Training average positive_sample_loss at step 117800: 0.086150\n",
      "2024-03-01 06:15:10 INFO     Training average negative_sample_loss at step 117800: 0.075199\n",
      "2024-03-01 06:15:10 INFO     Training average loss at step 117800: 0.080674\n",
      "2024-03-01 06:17:00 INFO     Training average positive_sample_loss at step 117900: 0.086283\n",
      "2024-03-01 06:17:00 INFO     Training average negative_sample_loss at step 117900: 0.075176\n",
      "2024-03-01 06:17:00 INFO     Training average loss at step 117900: 0.080729\n",
      "2024-03-01 06:19:10 INFO     Training average positive_sample_loss at step 118000: 0.086088\n",
      "2024-03-01 06:19:10 INFO     Training average negative_sample_loss at step 118000: 0.074814\n",
      "2024-03-01 06:19:10 INFO     Training average loss at step 118000: 0.080451\n",
      "2024-03-01 06:20:50 INFO     Training average positive_sample_loss at step 118100: 0.083843\n",
      "2024-03-01 06:20:50 INFO     Training average negative_sample_loss at step 118100: 0.074482\n",
      "2024-03-01 06:20:50 INFO     Training average loss at step 118100: 0.079163\n",
      "2024-03-01 06:22:37 INFO     Training average positive_sample_loss at step 118200: 0.084396\n",
      "2024-03-01 06:22:37 INFO     Training average negative_sample_loss at step 118200: 0.074122\n",
      "2024-03-01 06:22:37 INFO     Training average loss at step 118200: 0.079259\n",
      "2024-03-01 06:24:34 INFO     Training average positive_sample_loss at step 118300: 0.085060\n",
      "2024-03-01 06:24:34 INFO     Training average negative_sample_loss at step 118300: 0.074303\n",
      "2024-03-01 06:24:34 INFO     Training average loss at step 118300: 0.079681\n",
      "2024-03-01 06:26:19 INFO     Training average positive_sample_loss at step 118400: 0.085019\n",
      "2024-03-01 06:26:19 INFO     Training average negative_sample_loss at step 118400: 0.074034\n",
      "2024-03-01 06:26:19 INFO     Training average loss at step 118400: 0.079527\n",
      "2024-03-01 06:28:13 INFO     Training average positive_sample_loss at step 118500: 0.085306\n",
      "2024-03-01 06:28:13 INFO     Training average negative_sample_loss at step 118500: 0.074428\n",
      "2024-03-01 06:28:13 INFO     Training average loss at step 118500: 0.079867\n",
      "2024-03-01 06:30:00 INFO     Training average positive_sample_loss at step 118600: 0.085821\n",
      "2024-03-01 06:30:00 INFO     Training average negative_sample_loss at step 118600: 0.074839\n",
      "2024-03-01 06:30:00 INFO     Training average loss at step 118600: 0.080330\n",
      "2024-03-01 06:31:47 INFO     Training average positive_sample_loss at step 118700: 0.086163\n",
      "2024-03-01 06:31:47 INFO     Training average negative_sample_loss at step 118700: 0.074836\n",
      "2024-03-01 06:31:47 INFO     Training average loss at step 118700: 0.080500\n",
      "2024-03-01 06:33:50 INFO     Training average positive_sample_loss at step 118800: 0.086151\n",
      "2024-03-01 06:33:50 INFO     Training average negative_sample_loss at step 118800: 0.074800\n",
      "2024-03-01 06:33:50 INFO     Training average loss at step 118800: 0.080475\n",
      "2024-03-01 06:35:31 INFO     Training average positive_sample_loss at step 118900: 0.086712\n",
      "2024-03-01 06:35:31 INFO     Training average negative_sample_loss at step 118900: 0.075196\n",
      "2024-03-01 06:35:31 INFO     Training average loss at step 118900: 0.080954\n",
      "2024-03-01 06:37:53 INFO     Training average positive_sample_loss at step 119000: 0.084781\n",
      "2024-03-01 06:37:53 INFO     Training average negative_sample_loss at step 119000: 0.075266\n",
      "2024-03-01 06:37:53 INFO     Training average loss at step 119000: 0.080024\n",
      "2024-03-01 06:39:31 INFO     Training average positive_sample_loss at step 119100: 0.084013\n",
      "2024-03-01 06:39:31 INFO     Training average negative_sample_loss at step 119100: 0.074127\n",
      "2024-03-01 06:39:31 INFO     Training average loss at step 119100: 0.079070\n",
      "2024-03-01 06:41:07 INFO     Training average positive_sample_loss at step 119200: 0.084740\n",
      "2024-03-01 06:41:07 INFO     Training average negative_sample_loss at step 119200: 0.074053\n",
      "2024-03-01 06:41:07 INFO     Training average loss at step 119200: 0.079397\n",
      "2024-03-01 06:42:47 INFO     Training average positive_sample_loss at step 119300: 0.085357\n",
      "2024-03-01 06:42:47 INFO     Training average negative_sample_loss at step 119300: 0.074340\n",
      "2024-03-01 06:42:47 INFO     Training average loss at step 119300: 0.079849\n",
      "2024-03-01 06:44:25 INFO     Training average positive_sample_loss at step 119400: 0.085691\n",
      "2024-03-01 06:44:25 INFO     Training average negative_sample_loss at step 119400: 0.074522\n",
      "2024-03-01 06:44:25 INFO     Training average loss at step 119400: 0.080106\n",
      "2024-03-01 06:46:21 INFO     Training average positive_sample_loss at step 119500: 0.085863\n",
      "2024-03-01 06:46:21 INFO     Training average negative_sample_loss at step 119500: 0.074634\n",
      "2024-03-01 06:46:21 INFO     Training average loss at step 119500: 0.080248\n",
      "2024-03-01 06:48:27 INFO     Training average positive_sample_loss at step 119600: 0.085799\n",
      "2024-03-01 06:48:27 INFO     Training average negative_sample_loss at step 119600: 0.074844\n",
      "2024-03-01 06:48:27 INFO     Training average loss at step 119600: 0.080321\n",
      "2024-03-01 06:50:10 INFO     Training average positive_sample_loss at step 119700: 0.086117\n",
      "2024-03-01 06:50:10 INFO     Training average negative_sample_loss at step 119700: 0.074911\n",
      "2024-03-01 06:50:10 INFO     Training average loss at step 119700: 0.080514\n",
      "2024-03-01 06:52:01 INFO     Training average positive_sample_loss at step 119800: 0.086035\n",
      "2024-03-01 06:52:01 INFO     Training average negative_sample_loss at step 119800: 0.075127\n",
      "2024-03-01 06:52:01 INFO     Training average loss at step 119800: 0.080581\n",
      "2024-03-01 06:54:17 INFO     Training average positive_sample_loss at step 119900: 0.085447\n",
      "2024-03-01 06:54:17 INFO     Training average negative_sample_loss at step 119900: 0.074760\n",
      "2024-03-01 06:54:17 INFO     Training average loss at step 119900: 0.080103\n",
      "2024-03-01 06:56:04 INFO     Training average positive_sample_loss at step 120000: 0.083465\n",
      "2024-03-01 06:56:04 INFO     Training average negative_sample_loss at step 120000: 0.074170\n",
      "2024-03-01 06:56:04 INFO     Training average loss at step 120000: 0.078818\n",
      "2024-03-01 06:56:04 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 06:56:05 INFO     Evaluating the model... (0/6250)\n",
      "2024-03-01 06:56:41 INFO     Evaluating the model... (1000/6250)\n",
      "2024-03-01 06:57:12 INFO     Evaluating the model... (2000/6250)\n",
      "2024-03-01 06:57:48 INFO     Evaluating the model... (3000/6250)\n",
      "2024-03-01 06:58:24 INFO     Evaluating the model... (4000/6250)\n",
      "2024-03-01 06:58:57 INFO     Evaluating the model... (5000/6250)\n",
      "2024-03-01 06:59:28 INFO     Evaluating the model... (6000/6250)\n",
      "2024-03-01 06:59:37 INFO     Valid MRR at step 120000: 0.443738\n",
      "2024-03-01 06:59:37 INFO     Valid MR at step 120000: 217.664800\n",
      "2024-03-01 06:59:37 INFO     Valid HITS@1 at step 120000: 0.346900\n",
      "2024-03-01 06:59:37 INFO     Valid HITS@3 at step 120000: 0.475110\n",
      "2024-03-01 06:59:37 INFO     Valid HITS@10 at step 120000: 0.657270\n",
      "2024-03-01 07:01:11 INFO     Training average positive_sample_loss at step 120100: 0.084905\n",
      "2024-03-01 07:01:11 INFO     Training average negative_sample_loss at step 120100: 0.074393\n",
      "2024-03-01 07:01:11 INFO     Training average loss at step 120100: 0.079649\n",
      "2024-03-01 07:03:02 INFO     Training average positive_sample_loss at step 120200: 0.085209\n",
      "2024-03-01 07:03:02 INFO     Training average negative_sample_loss at step 120200: 0.074525\n",
      "2024-03-01 07:03:02 INFO     Training average loss at step 120200: 0.079867\n",
      "2024-03-01 07:04:59 INFO     Training average positive_sample_loss at step 120300: 0.084920\n",
      "2024-03-01 07:04:59 INFO     Training average negative_sample_loss at step 120300: 0.073992\n",
      "2024-03-01 07:04:59 INFO     Training average loss at step 120300: 0.079456\n",
      "2024-03-01 07:07:00 INFO     Training average positive_sample_loss at step 120400: 0.085562\n",
      "2024-03-01 07:07:00 INFO     Training average negative_sample_loss at step 120400: 0.074442\n",
      "2024-03-01 07:07:00 INFO     Training average loss at step 120400: 0.080002\n",
      "2024-03-01 07:08:51 INFO     Training average positive_sample_loss at step 120500: 0.085972\n",
      "2024-03-01 07:08:51 INFO     Training average negative_sample_loss at step 120500: 0.074778\n",
      "2024-03-01 07:08:51 INFO     Training average loss at step 120500: 0.080375\n",
      "2024-03-01 07:10:35 INFO     Training average positive_sample_loss at step 120600: 0.085636\n",
      "2024-03-01 07:10:35 INFO     Training average negative_sample_loss at step 120600: 0.074477\n",
      "2024-03-01 07:10:35 INFO     Training average loss at step 120600: 0.080056\n",
      "2024-03-01 07:12:22 INFO     Training average positive_sample_loss at step 120700: 0.086520\n",
      "2024-03-01 07:12:22 INFO     Training average negative_sample_loss at step 120700: 0.075321\n",
      "2024-03-01 07:12:22 INFO     Training average loss at step 120700: 0.080921\n",
      "2024-03-01 07:14:26 INFO     Training average positive_sample_loss at step 120800: 0.085921\n",
      "2024-03-01 07:14:26 INFO     Training average negative_sample_loss at step 120800: 0.074982\n",
      "2024-03-01 07:14:26 INFO     Training average loss at step 120800: 0.080452\n",
      "2024-03-01 07:16:21 INFO     Training average positive_sample_loss at step 120900: 0.084435\n",
      "2024-03-01 07:16:21 INFO     Training average negative_sample_loss at step 120900: 0.074698\n",
      "2024-03-01 07:16:21 INFO     Training average loss at step 120900: 0.079567\n",
      "2024-03-01 07:17:59 INFO     Training average positive_sample_loss at step 121000: 0.084516\n",
      "2024-03-01 07:17:59 INFO     Training average negative_sample_loss at step 121000: 0.074524\n",
      "2024-03-01 07:17:59 INFO     Training average loss at step 121000: 0.079520\n",
      "2024-03-01 07:19:35 INFO     Training average positive_sample_loss at step 121100: 0.085200\n",
      "2024-03-01 07:19:35 INFO     Training average negative_sample_loss at step 121100: 0.074181\n",
      "2024-03-01 07:19:35 INFO     Training average loss at step 121100: 0.079691\n",
      "2024-03-01 07:21:30 INFO     Training average positive_sample_loss at step 121200: 0.085616\n",
      "2024-03-01 07:21:30 INFO     Training average negative_sample_loss at step 121200: 0.074661\n",
      "2024-03-01 07:21:30 INFO     Training average loss at step 121200: 0.080138\n",
      "2024-03-01 07:23:11 INFO     Training average positive_sample_loss at step 121300: 0.085614\n",
      "2024-03-01 07:23:11 INFO     Training average negative_sample_loss at step 121300: 0.074713\n",
      "2024-03-01 07:23:11 INFO     Training average loss at step 121300: 0.080164\n",
      "2024-03-01 07:24:58 INFO     Training average positive_sample_loss at step 121400: 0.085698\n",
      "2024-03-01 07:24:58 INFO     Training average negative_sample_loss at step 121400: 0.074779\n",
      "2024-03-01 07:24:58 INFO     Training average loss at step 121400: 0.080239\n",
      "2024-03-01 07:26:32 INFO     Training average positive_sample_loss at step 121500: 0.085387\n",
      "2024-03-01 07:26:32 INFO     Training average negative_sample_loss at step 121500: 0.074565\n",
      "2024-03-01 07:26:32 INFO     Training average loss at step 121500: 0.079976\n",
      "2024-03-01 07:28:28 INFO     Training average positive_sample_loss at step 121600: 0.085893\n",
      "2024-03-01 07:28:28 INFO     Training average negative_sample_loss at step 121600: 0.074577\n",
      "2024-03-01 07:28:28 INFO     Training average loss at step 121600: 0.080235\n",
      "2024-03-01 07:30:08 INFO     Training average positive_sample_loss at step 121700: 0.086370\n",
      "2024-03-01 07:30:08 INFO     Training average negative_sample_loss at step 121700: 0.075216\n",
      "2024-03-01 07:30:08 INFO     Training average loss at step 121700: 0.080793\n",
      "2024-03-01 07:32:09 INFO     Training average positive_sample_loss at step 121800: 0.085102\n",
      "2024-03-01 07:32:09 INFO     Training average negative_sample_loss at step 121800: 0.074900\n",
      "2024-03-01 07:32:09 INFO     Training average loss at step 121800: 0.080001\n",
      "2024-03-01 07:34:06 INFO     Training average positive_sample_loss at step 121900: 0.083532\n",
      "2024-03-01 07:34:06 INFO     Training average negative_sample_loss at step 121900: 0.073816\n",
      "2024-03-01 07:34:06 INFO     Training average loss at step 121900: 0.078674\n",
      "2024-03-01 07:35:54 INFO     Training average positive_sample_loss at step 122000: 0.084263\n",
      "2024-03-01 07:35:54 INFO     Training average negative_sample_loss at step 122000: 0.073918\n",
      "2024-03-01 07:35:54 INFO     Training average loss at step 122000: 0.079091\n",
      "2024-03-01 07:37:35 INFO     Training average positive_sample_loss at step 122100: 0.085748\n",
      "2024-03-01 07:37:35 INFO     Training average negative_sample_loss at step 122100: 0.074552\n",
      "2024-03-01 07:37:35 INFO     Training average loss at step 122100: 0.080150\n",
      "2024-03-01 07:39:24 INFO     Training average positive_sample_loss at step 122200: 0.085253\n",
      "2024-03-01 07:39:24 INFO     Training average negative_sample_loss at step 122200: 0.074517\n",
      "2024-03-01 07:39:24 INFO     Training average loss at step 122200: 0.079885\n",
      "2024-03-01 07:41:08 INFO     Training average positive_sample_loss at step 122300: 0.086111\n",
      "2024-03-01 07:41:08 INFO     Training average negative_sample_loss at step 122300: 0.074638\n",
      "2024-03-01 07:41:08 INFO     Training average loss at step 122300: 0.080374\n",
      "2024-03-01 07:42:50 INFO     Training average positive_sample_loss at step 122400: 0.085857\n",
      "2024-03-01 07:42:50 INFO     Training average negative_sample_loss at step 122400: 0.074691\n",
      "2024-03-01 07:42:50 INFO     Training average loss at step 122400: 0.080274\n",
      "2024-03-01 07:44:47 INFO     Training average positive_sample_loss at step 122500: 0.085783\n",
      "2024-03-01 07:44:47 INFO     Training average negative_sample_loss at step 122500: 0.074615\n",
      "2024-03-01 07:44:47 INFO     Training average loss at step 122500: 0.080199\n",
      "2024-03-01 07:46:44 INFO     Training average positive_sample_loss at step 122600: 0.085706\n",
      "2024-03-01 07:46:44 INFO     Training average negative_sample_loss at step 122600: 0.074954\n",
      "2024-03-01 07:46:44 INFO     Training average loss at step 122600: 0.080330\n",
      "2024-03-01 07:48:35 INFO     Training average positive_sample_loss at step 122700: 0.086736\n",
      "2024-03-01 07:48:35 INFO     Training average negative_sample_loss at step 122700: 0.075377\n",
      "2024-03-01 07:48:35 INFO     Training average loss at step 122700: 0.081056\n",
      "2024-03-01 07:50:35 INFO     Training average positive_sample_loss at step 122800: 0.083441\n",
      "2024-03-01 07:50:35 INFO     Training average negative_sample_loss at step 122800: 0.074421\n",
      "2024-03-01 07:50:35 INFO     Training average loss at step 122800: 0.078931\n",
      "2024-03-01 07:52:22 INFO     Training average positive_sample_loss at step 122900: 0.084643\n",
      "2024-03-01 07:52:22 INFO     Training average negative_sample_loss at step 122900: 0.074505\n",
      "2024-03-01 07:52:22 INFO     Training average loss at step 122900: 0.079574\n",
      "2024-03-01 07:54:10 INFO     Training average positive_sample_loss at step 123000: 0.084760\n",
      "2024-03-01 07:54:10 INFO     Training average negative_sample_loss at step 123000: 0.074153\n",
      "2024-03-01 07:54:10 INFO     Training average loss at step 123000: 0.079456\n",
      "2024-03-01 07:55:46 INFO     Training average positive_sample_loss at step 123100: 0.085565\n",
      "2024-03-01 07:55:46 INFO     Training average negative_sample_loss at step 123100: 0.074319\n",
      "2024-03-01 07:55:46 INFO     Training average loss at step 123100: 0.079942\n",
      "2024-03-01 07:57:31 INFO     Training average positive_sample_loss at step 123200: 0.085415\n",
      "2024-03-01 07:57:31 INFO     Training average negative_sample_loss at step 123200: 0.074063\n",
      "2024-03-01 07:57:31 INFO     Training average loss at step 123200: 0.079739\n",
      "2024-03-01 07:59:26 INFO     Training average positive_sample_loss at step 123300: 0.085948\n",
      "2024-03-01 07:59:26 INFO     Training average negative_sample_loss at step 123300: 0.074717\n",
      "2024-03-01 07:59:26 INFO     Training average loss at step 123300: 0.080333\n",
      "2024-03-01 08:01:24 INFO     Training average positive_sample_loss at step 123400: 0.085996\n",
      "2024-03-01 08:01:24 INFO     Training average negative_sample_loss at step 123400: 0.074567\n",
      "2024-03-01 08:01:24 INFO     Training average loss at step 123400: 0.080281\n",
      "2024-03-01 08:03:04 INFO     Training average positive_sample_loss at step 123500: 0.085444\n",
      "2024-03-01 08:03:04 INFO     Training average negative_sample_loss at step 123500: 0.074762\n",
      "2024-03-01 08:03:04 INFO     Training average loss at step 123500: 0.080103\n",
      "2024-03-01 08:04:54 INFO     Training average positive_sample_loss at step 123600: 0.086518\n",
      "2024-03-01 08:04:54 INFO     Training average negative_sample_loss at step 123600: 0.075189\n",
      "2024-03-01 08:04:54 INFO     Training average loss at step 123600: 0.080854\n",
      "2024-03-01 08:06:41 INFO     Training average positive_sample_loss at step 123700: 0.085265\n",
      "2024-03-01 08:06:41 INFO     Training average negative_sample_loss at step 123700: 0.074975\n",
      "2024-03-01 08:06:41 INFO     Training average loss at step 123700: 0.080120\n",
      "2024-03-01 08:08:25 INFO     Training average positive_sample_loss at step 123800: 0.084331\n",
      "2024-03-01 08:08:25 INFO     Training average negative_sample_loss at step 123800: 0.074870\n",
      "2024-03-01 08:08:25 INFO     Training average loss at step 123800: 0.079600\n",
      "2024-03-01 08:10:18 INFO     Training average positive_sample_loss at step 123900: 0.084567\n",
      "2024-03-01 08:10:18 INFO     Training average negative_sample_loss at step 123900: 0.074122\n",
      "2024-03-01 08:10:18 INFO     Training average loss at step 123900: 0.079344\n",
      "2024-03-01 08:12:09 INFO     Training average positive_sample_loss at step 124000: 0.084919\n",
      "2024-03-01 08:12:09 INFO     Training average negative_sample_loss at step 124000: 0.074337\n",
      "2024-03-01 08:12:09 INFO     Training average loss at step 124000: 0.079628\n",
      "2024-03-01 08:13:42 INFO     Training average positive_sample_loss at step 124100: 0.085043\n",
      "2024-03-01 08:13:42 INFO     Training average negative_sample_loss at step 124100: 0.073865\n",
      "2024-03-01 08:13:42 INFO     Training average loss at step 124100: 0.079454\n",
      "2024-03-01 08:15:14 INFO     Training average positive_sample_loss at step 124200: 0.085950\n",
      "2024-03-01 08:15:14 INFO     Training average negative_sample_loss at step 124200: 0.074637\n",
      "2024-03-01 08:15:14 INFO     Training average loss at step 124200: 0.080294\n",
      "2024-03-01 08:16:54 INFO     Training average positive_sample_loss at step 124300: 0.086079\n",
      "2024-03-01 08:16:54 INFO     Training average negative_sample_loss at step 124300: 0.074828\n",
      "2024-03-01 08:16:54 INFO     Training average loss at step 124300: 0.080453\n",
      "2024-03-01 08:18:46 INFO     Training average positive_sample_loss at step 124400: 0.086127\n",
      "2024-03-01 08:18:46 INFO     Training average negative_sample_loss at step 124400: 0.074806\n",
      "2024-03-01 08:18:46 INFO     Training average loss at step 124400: 0.080466\n",
      "2024-03-01 08:20:27 INFO     Training average positive_sample_loss at step 124500: 0.085577\n",
      "2024-03-01 08:20:27 INFO     Training average negative_sample_loss at step 124500: 0.074545\n",
      "2024-03-01 08:20:27 INFO     Training average loss at step 124500: 0.080061\n",
      "2024-03-01 08:22:17 INFO     Training average positive_sample_loss at step 124600: 0.086083\n",
      "2024-03-01 08:22:17 INFO     Training average negative_sample_loss at step 124600: 0.074932\n",
      "2024-03-01 08:22:17 INFO     Training average loss at step 124600: 0.080508\n",
      "2024-03-01 08:24:24 INFO     Training average positive_sample_loss at step 124700: 0.083694\n",
      "2024-03-01 08:24:24 INFO     Training average negative_sample_loss at step 124700: 0.074602\n",
      "2024-03-01 08:24:24 INFO     Training average loss at step 124700: 0.079148\n",
      "2024-03-01 08:26:18 INFO     Training average positive_sample_loss at step 124800: 0.084137\n",
      "2024-03-01 08:26:18 INFO     Training average negative_sample_loss at step 124800: 0.074095\n",
      "2024-03-01 08:26:18 INFO     Training average loss at step 124800: 0.079116\n",
      "2024-03-01 08:28:15 INFO     Training average positive_sample_loss at step 124900: 0.085454\n",
      "2024-03-01 08:28:15 INFO     Training average negative_sample_loss at step 124900: 0.074329\n",
      "2024-03-01 08:28:15 INFO     Training average loss at step 124900: 0.079892\n",
      "2024-03-01 08:30:00 INFO     Training average positive_sample_loss at step 125000: 0.085012\n",
      "2024-03-01 08:30:00 INFO     Training average negative_sample_loss at step 125000: 0.074112\n",
      "2024-03-01 08:30:00 INFO     Training average loss at step 125000: 0.079562\n",
      "2024-03-01 08:31:47 INFO     Training average positive_sample_loss at step 125100: 0.085682\n",
      "2024-03-01 08:31:47 INFO     Training average negative_sample_loss at step 125100: 0.074647\n",
      "2024-03-01 08:31:47 INFO     Training average loss at step 125100: 0.080165\n",
      "2024-03-01 08:33:28 INFO     Training average positive_sample_loss at step 125200: 0.085388\n",
      "2024-03-01 08:33:28 INFO     Training average negative_sample_loss at step 125200: 0.074847\n",
      "2024-03-01 08:33:28 INFO     Training average loss at step 125200: 0.080117\n",
      "2024-03-01 08:35:16 INFO     Training average positive_sample_loss at step 125300: 0.085887\n",
      "2024-03-01 08:35:16 INFO     Training average negative_sample_loss at step 125300: 0.074634\n",
      "2024-03-01 08:35:16 INFO     Training average loss at step 125300: 0.080260\n",
      "2024-03-01 08:37:18 INFO     Training average positive_sample_loss at step 125400: 0.086545\n",
      "2024-03-01 08:37:18 INFO     Training average negative_sample_loss at step 125400: 0.074784\n",
      "2024-03-01 08:37:18 INFO     Training average loss at step 125400: 0.080664\n",
      "2024-03-01 08:38:52 INFO     Training average positive_sample_loss at step 125500: 0.085733\n",
      "2024-03-01 08:38:52 INFO     Training average negative_sample_loss at step 125500: 0.074784\n",
      "2024-03-01 08:38:52 INFO     Training average loss at step 125500: 0.080258\n",
      "2024-03-01 08:40:37 INFO     Training average positive_sample_loss at step 125600: 0.084799\n",
      "2024-03-01 08:40:37 INFO     Training average negative_sample_loss at step 125600: 0.074971\n",
      "2024-03-01 08:40:37 INFO     Training average loss at step 125600: 0.079885\n",
      "2024-03-01 08:42:22 INFO     Training average positive_sample_loss at step 125700: 0.084195\n",
      "2024-03-01 08:42:22 INFO     Training average negative_sample_loss at step 125700: 0.074457\n",
      "2024-03-01 08:42:22 INFO     Training average loss at step 125700: 0.079326\n",
      "2024-03-01 08:44:09 INFO     Training average positive_sample_loss at step 125800: 0.084365\n",
      "2024-03-01 08:44:09 INFO     Training average negative_sample_loss at step 125800: 0.073890\n",
      "2024-03-01 08:44:09 INFO     Training average loss at step 125800: 0.079127\n",
      "2024-03-01 08:46:13 INFO     Training average positive_sample_loss at step 125900: 0.085339\n",
      "2024-03-01 08:46:13 INFO     Training average negative_sample_loss at step 125900: 0.074391\n",
      "2024-03-01 08:46:13 INFO     Training average loss at step 125900: 0.079865\n",
      "2024-03-01 08:48:01 INFO     Training average positive_sample_loss at step 126000: 0.085718\n",
      "2024-03-01 08:48:01 INFO     Training average negative_sample_loss at step 126000: 0.074538\n",
      "2024-03-01 08:48:01 INFO     Training average loss at step 126000: 0.080128\n",
      "2024-03-01 08:49:33 INFO     Training average positive_sample_loss at step 126100: 0.085800\n",
      "2024-03-01 08:49:33 INFO     Training average negative_sample_loss at step 126100: 0.074355\n",
      "2024-03-01 08:49:33 INFO     Training average loss at step 126100: 0.080077\n",
      "2024-03-01 08:51:22 INFO     Training average positive_sample_loss at step 126200: 0.085478\n",
      "2024-03-01 08:51:22 INFO     Training average negative_sample_loss at step 126200: 0.074525\n",
      "2024-03-01 08:51:22 INFO     Training average loss at step 126200: 0.080002\n",
      "2024-03-01 08:53:13 INFO     Training average positive_sample_loss at step 126300: 0.086039\n",
      "2024-03-01 08:53:13 INFO     Training average negative_sample_loss at step 126300: 0.074923\n",
      "2024-03-01 08:53:13 INFO     Training average loss at step 126300: 0.080481\n",
      "2024-03-01 08:54:56 INFO     Training average positive_sample_loss at step 126400: 0.085959\n",
      "2024-03-01 08:54:56 INFO     Training average negative_sample_loss at step 126400: 0.074952\n",
      "2024-03-01 08:54:56 INFO     Training average loss at step 126400: 0.080455\n",
      "2024-03-01 08:57:02 INFO     Training average positive_sample_loss at step 126500: 0.086244\n",
      "2024-03-01 08:57:02 INFO     Training average negative_sample_loss at step 126500: 0.075309\n",
      "2024-03-01 08:57:02 INFO     Training average loss at step 126500: 0.080777\n",
      "2024-03-01 08:58:51 INFO     Training average positive_sample_loss at step 126600: 0.084128\n",
      "2024-03-01 08:58:51 INFO     Training average negative_sample_loss at step 126600: 0.074776\n",
      "2024-03-01 08:58:51 INFO     Training average loss at step 126600: 0.079452\n",
      "2024-03-01 09:00:46 INFO     Training average positive_sample_loss at step 126700: 0.084538\n",
      "2024-03-01 09:00:46 INFO     Training average negative_sample_loss at step 126700: 0.074105\n",
      "2024-03-01 09:00:46 INFO     Training average loss at step 126700: 0.079322\n",
      "2024-03-01 09:02:39 INFO     Training average positive_sample_loss at step 126800: 0.084597\n",
      "2024-03-01 09:02:39 INFO     Training average negative_sample_loss at step 126800: 0.073794\n",
      "2024-03-01 09:02:39 INFO     Training average loss at step 126800: 0.079195\n",
      "2024-03-01 09:04:36 INFO     Training average positive_sample_loss at step 126900: 0.085385\n",
      "2024-03-01 09:04:36 INFO     Training average negative_sample_loss at step 126900: 0.074406\n",
      "2024-03-01 09:04:36 INFO     Training average loss at step 126900: 0.079895\n",
      "2024-03-01 09:06:35 INFO     Training average positive_sample_loss at step 127000: 0.085646\n",
      "2024-03-01 09:06:35 INFO     Training average negative_sample_loss at step 127000: 0.074601\n",
      "2024-03-01 09:06:35 INFO     Training average loss at step 127000: 0.080124\n",
      "2024-03-01 09:08:23 INFO     Training average positive_sample_loss at step 127100: 0.085377\n",
      "2024-03-01 09:08:23 INFO     Training average negative_sample_loss at step 127100: 0.074652\n",
      "2024-03-01 09:08:23 INFO     Training average loss at step 127100: 0.080015\n",
      "2024-03-01 09:10:13 INFO     Training average positive_sample_loss at step 127200: 0.086004\n",
      "2024-03-01 09:10:13 INFO     Training average negative_sample_loss at step 127200: 0.074384\n",
      "2024-03-01 09:10:13 INFO     Training average loss at step 127200: 0.080194\n",
      "2024-03-01 09:12:04 INFO     Training average positive_sample_loss at step 127300: 0.086063\n",
      "2024-03-01 09:12:04 INFO     Training average negative_sample_loss at step 127300: 0.074780\n",
      "2024-03-01 09:12:04 INFO     Training average loss at step 127300: 0.080422\n",
      "2024-03-01 09:14:01 INFO     Training average positive_sample_loss at step 127400: 0.086218\n",
      "2024-03-01 09:14:01 INFO     Training average negative_sample_loss at step 127400: 0.074767\n",
      "2024-03-01 09:14:01 INFO     Training average loss at step 127400: 0.080492\n",
      "2024-03-01 09:16:03 INFO     Training average positive_sample_loss at step 127500: 0.084526\n",
      "2024-03-01 09:16:03 INFO     Training average negative_sample_loss at step 127500: 0.074931\n",
      "2024-03-01 09:16:03 INFO     Training average loss at step 127500: 0.079728\n",
      "2024-03-01 09:17:53 INFO     Training average positive_sample_loss at step 127600: 0.084356\n",
      "2024-03-01 09:17:53 INFO     Training average negative_sample_loss at step 127600: 0.074554\n",
      "2024-03-01 09:17:53 INFO     Training average loss at step 127600: 0.079455\n",
      "2024-03-01 09:19:32 INFO     Training average positive_sample_loss at step 127700: 0.084683\n",
      "2024-03-01 09:19:32 INFO     Training average negative_sample_loss at step 127700: 0.074132\n",
      "2024-03-01 09:19:32 INFO     Training average loss at step 127700: 0.079408\n",
      "2024-03-01 09:21:28 INFO     Training average positive_sample_loss at step 127800: 0.084722\n",
      "2024-03-01 09:21:28 INFO     Training average negative_sample_loss at step 127800: 0.073849\n",
      "2024-03-01 09:21:28 INFO     Training average loss at step 127800: 0.079285\n",
      "2024-03-01 09:23:36 INFO     Training average positive_sample_loss at step 127900: 0.085433\n",
      "2024-03-01 09:23:36 INFO     Training average negative_sample_loss at step 127900: 0.074641\n",
      "2024-03-01 09:23:36 INFO     Training average loss at step 127900: 0.080037\n",
      "2024-03-01 09:25:37 INFO     Training average positive_sample_loss at step 128000: 0.085560\n",
      "2024-03-01 09:25:37 INFO     Training average negative_sample_loss at step 128000: 0.074190\n",
      "2024-03-01 09:25:37 INFO     Training average loss at step 128000: 0.079875\n",
      "2024-03-01 09:27:06 INFO     Training average positive_sample_loss at step 128100: 0.086092\n",
      "2024-03-01 09:27:06 INFO     Training average negative_sample_loss at step 128100: 0.074827\n",
      "2024-03-01 09:27:06 INFO     Training average loss at step 128100: 0.080459\n",
      "2024-03-01 09:28:49 INFO     Training average positive_sample_loss at step 128200: 0.085988\n",
      "2024-03-01 09:28:49 INFO     Training average negative_sample_loss at step 128200: 0.074861\n",
      "2024-03-01 09:28:49 INFO     Training average loss at step 128200: 0.080424\n",
      "2024-03-01 09:30:16 INFO     Training average positive_sample_loss at step 128300: 0.086082\n",
      "2024-03-01 09:30:16 INFO     Training average negative_sample_loss at step 128300: 0.075090\n",
      "2024-03-01 09:30:16 INFO     Training average loss at step 128300: 0.080586\n",
      "2024-03-01 09:32:25 INFO     Training average positive_sample_loss at step 128400: 0.085669\n",
      "2024-03-01 09:32:25 INFO     Training average negative_sample_loss at step 128400: 0.074882\n",
      "2024-03-01 09:32:25 INFO     Training average loss at step 128400: 0.080275\n",
      "2024-03-01 09:34:15 INFO     Training average positive_sample_loss at step 128500: 0.083584\n",
      "2024-03-01 09:34:15 INFO     Training average negative_sample_loss at step 128500: 0.074178\n",
      "2024-03-01 09:34:15 INFO     Training average loss at step 128500: 0.078881\n",
      "2024-03-01 09:36:09 INFO     Training average positive_sample_loss at step 128600: 0.084539\n",
      "2024-03-01 09:36:09 INFO     Training average negative_sample_loss at step 128600: 0.074338\n",
      "2024-03-01 09:36:09 INFO     Training average loss at step 128600: 0.079438\n",
      "2024-03-01 09:38:03 INFO     Training average positive_sample_loss at step 128700: 0.085378\n",
      "2024-03-01 09:38:03 INFO     Training average negative_sample_loss at step 128700: 0.074720\n",
      "2024-03-01 09:38:03 INFO     Training average loss at step 128700: 0.080049\n",
      "2024-03-01 09:39:52 INFO     Training average positive_sample_loss at step 128800: 0.085315\n",
      "2024-03-01 09:39:52 INFO     Training average negative_sample_loss at step 128800: 0.074140\n",
      "2024-03-01 09:39:52 INFO     Training average loss at step 128800: 0.079727\n",
      "2024-03-01 09:41:39 INFO     Training average positive_sample_loss at step 128900: 0.085378\n",
      "2024-03-01 09:41:39 INFO     Training average negative_sample_loss at step 128900: 0.074018\n",
      "2024-03-01 09:41:39 INFO     Training average loss at step 128900: 0.079698\n",
      "2024-03-01 09:43:31 INFO     Training average positive_sample_loss at step 129000: 0.085573\n",
      "2024-03-01 09:43:31 INFO     Training average negative_sample_loss at step 129000: 0.074358\n",
      "2024-03-01 09:43:31 INFO     Training average loss at step 129000: 0.079965\n",
      "2024-03-01 09:45:15 INFO     Training average positive_sample_loss at step 129100: 0.085893\n",
      "2024-03-01 09:45:15 INFO     Training average negative_sample_loss at step 129100: 0.074576\n",
      "2024-03-01 09:45:15 INFO     Training average loss at step 129100: 0.080235\n",
      "2024-03-01 09:47:11 INFO     Training average positive_sample_loss at step 129200: 0.086190\n",
      "2024-03-01 09:47:11 INFO     Training average negative_sample_loss at step 129200: 0.075075\n",
      "2024-03-01 09:47:11 INFO     Training average loss at step 129200: 0.080632\n",
      "2024-03-01 09:49:12 INFO     Training average positive_sample_loss at step 129300: 0.086251\n",
      "2024-03-01 09:49:12 INFO     Training average negative_sample_loss at step 129300: 0.075143\n",
      "2024-03-01 09:49:12 INFO     Training average loss at step 129300: 0.080697\n",
      "2024-03-01 09:51:21 INFO     Training average positive_sample_loss at step 129400: 0.084139\n",
      "2024-03-01 09:51:21 INFO     Training average negative_sample_loss at step 129400: 0.074454\n",
      "2024-03-01 09:51:21 INFO     Training average loss at step 129400: 0.079296\n",
      "2024-03-01 09:53:15 INFO     Training average positive_sample_loss at step 129500: 0.084090\n",
      "2024-03-01 09:53:15 INFO     Training average negative_sample_loss at step 129500: 0.074390\n",
      "2024-03-01 09:53:15 INFO     Training average loss at step 129500: 0.079240\n",
      "2024-03-01 09:55:05 INFO     Training average positive_sample_loss at step 129600: 0.085039\n",
      "2024-03-01 09:55:05 INFO     Training average negative_sample_loss at step 129600: 0.074240\n",
      "2024-03-01 09:55:05 INFO     Training average loss at step 129600: 0.079640\n",
      "2024-03-01 09:57:01 INFO     Training average positive_sample_loss at step 129700: 0.084670\n",
      "2024-03-01 09:57:01 INFO     Training average negative_sample_loss at step 129700: 0.073853\n",
      "2024-03-01 09:57:01 INFO     Training average loss at step 129700: 0.079262\n",
      "2024-03-01 09:58:59 INFO     Training average positive_sample_loss at step 129800: 0.085690\n",
      "2024-03-01 09:58:59 INFO     Training average negative_sample_loss at step 129800: 0.074338\n",
      "2024-03-01 09:58:59 INFO     Training average loss at step 129800: 0.080014\n",
      "2024-03-01 10:01:06 INFO     Training average positive_sample_loss at step 129900: 0.085806\n",
      "2024-03-01 10:01:06 INFO     Training average negative_sample_loss at step 129900: 0.074631\n",
      "2024-03-01 10:01:06 INFO     Training average loss at step 129900: 0.080218\n",
      "2024-03-01 10:03:03 INFO     Training average positive_sample_loss at step 130000: 0.085808\n",
      "2024-03-01 10:03:03 INFO     Training average negative_sample_loss at step 130000: 0.074634\n",
      "2024-03-01 10:03:03 INFO     Training average loss at step 130000: 0.080221\n",
      "2024-03-01 10:03:03 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 10:03:04 INFO     Evaluating the model... (0/6250)\n",
      "2024-03-01 10:03:41 INFO     Evaluating the model... (1000/6250)\n",
      "2024-03-01 10:04:16 INFO     Evaluating the model... (2000/6250)\n",
      "2024-03-01 10:04:50 INFO     Evaluating the model... (3000/6250)\n",
      "2024-03-01 10:05:25 INFO     Evaluating the model... (4000/6250)\n",
      "2024-03-01 10:05:57 INFO     Evaluating the model... (5000/6250)\n",
      "2024-03-01 10:06:30 INFO     Evaluating the model... (6000/6250)\n",
      "2024-03-01 10:06:38 INFO     Valid MRR at step 130000: 0.445031\n",
      "2024-03-01 10:06:38 INFO     Valid MR at step 130000: 215.934650\n",
      "2024-03-01 10:06:38 INFO     Valid HITS@1 at step 130000: 0.346900\n",
      "2024-03-01 10:06:38 INFO     Valid HITS@3 at step 130000: 0.478470\n",
      "2024-03-01 10:06:38 INFO     Valid HITS@10 at step 130000: 0.659380\n",
      "2024-03-01 10:08:14 INFO     Training average positive_sample_loss at step 130100: 0.085973\n",
      "2024-03-01 10:08:14 INFO     Training average negative_sample_loss at step 130100: 0.074799\n",
      "2024-03-01 10:08:14 INFO     Training average loss at step 130100: 0.080386\n",
      "2024-03-01 10:10:13 INFO     Training average positive_sample_loss at step 130200: 0.086067\n",
      "2024-03-01 10:10:13 INFO     Training average negative_sample_loss at step 130200: 0.075053\n",
      "2024-03-01 10:10:13 INFO     Training average loss at step 130200: 0.080560\n",
      "2024-03-01 10:12:02 INFO     Training average positive_sample_loss at step 130300: 0.085288\n",
      "2024-03-01 10:12:02 INFO     Training average negative_sample_loss at step 130300: 0.075074\n",
      "2024-03-01 10:12:02 INFO     Training average loss at step 130300: 0.080181\n",
      "2024-03-01 10:14:02 INFO     Training average positive_sample_loss at step 130400: 0.083922\n",
      "2024-03-01 10:14:02 INFO     Training average negative_sample_loss at step 130400: 0.074306\n",
      "2024-03-01 10:14:02 INFO     Training average loss at step 130400: 0.079114\n",
      "2024-03-01 10:16:11 INFO     Training average positive_sample_loss at step 130500: 0.084394\n",
      "2024-03-01 10:16:11 INFO     Training average negative_sample_loss at step 130500: 0.074038\n",
      "2024-03-01 10:16:11 INFO     Training average loss at step 130500: 0.079216\n",
      "2024-03-01 10:17:49 INFO     Training average positive_sample_loss at step 130600: 0.085074\n",
      "2024-03-01 10:17:49 INFO     Training average negative_sample_loss at step 130600: 0.074018\n",
      "2024-03-01 10:17:49 INFO     Training average loss at step 130600: 0.079546\n",
      "2024-03-01 10:19:49 INFO     Training average positive_sample_loss at step 130700: 0.085114\n",
      "2024-03-01 10:19:49 INFO     Training average negative_sample_loss at step 130700: 0.074280\n",
      "2024-03-01 10:19:49 INFO     Training average loss at step 130700: 0.079697\n",
      "2024-03-01 10:21:47 INFO     Training average positive_sample_loss at step 130800: 0.085835\n",
      "2024-03-01 10:21:47 INFO     Training average negative_sample_loss at step 130800: 0.074502\n",
      "2024-03-01 10:21:47 INFO     Training average loss at step 130800: 0.080169\n",
      "2024-03-01 10:23:38 INFO     Training average positive_sample_loss at step 130900: 0.085711\n",
      "2024-03-01 10:23:38 INFO     Training average negative_sample_loss at step 130900: 0.074527\n",
      "2024-03-01 10:23:38 INFO     Training average loss at step 130900: 0.080119\n",
      "2024-03-01 10:25:31 INFO     Training average positive_sample_loss at step 131000: 0.085801\n",
      "2024-03-01 10:25:31 INFO     Training average negative_sample_loss at step 131000: 0.074606\n",
      "2024-03-01 10:25:31 INFO     Training average loss at step 131000: 0.080204\n",
      "2024-03-01 10:27:32 INFO     Training average positive_sample_loss at step 131100: 0.086266\n",
      "2024-03-01 10:27:32 INFO     Training average negative_sample_loss at step 131100: 0.075120\n",
      "2024-03-01 10:27:32 INFO     Training average loss at step 131100: 0.080693\n",
      "2024-03-01 10:29:41 INFO     Training average positive_sample_loss at step 131200: 0.086313\n",
      "2024-03-01 10:29:41 INFO     Training average negative_sample_loss at step 131200: 0.075112\n",
      "2024-03-01 10:29:41 INFO     Training average loss at step 131200: 0.080713\n",
      "2024-03-01 10:31:52 INFO     Training average positive_sample_loss at step 131300: 0.083681\n",
      "2024-03-01 10:31:52 INFO     Training average negative_sample_loss at step 131300: 0.074491\n",
      "2024-03-01 10:31:52 INFO     Training average loss at step 131300: 0.079086\n",
      "2024-03-01 10:33:47 INFO     Training average positive_sample_loss at step 131400: 0.084234\n",
      "2024-03-01 10:33:47 INFO     Training average negative_sample_loss at step 131400: 0.073941\n",
      "2024-03-01 10:33:47 INFO     Training average loss at step 131400: 0.079087\n",
      "2024-03-01 10:35:43 INFO     Training average positive_sample_loss at step 131500: 0.084791\n",
      "2024-03-01 10:35:43 INFO     Training average negative_sample_loss at step 131500: 0.074241\n",
      "2024-03-01 10:35:43 INFO     Training average loss at step 131500: 0.079516\n",
      "2024-03-01 10:37:41 INFO     Training average positive_sample_loss at step 131600: 0.084801\n",
      "2024-03-01 10:37:41 INFO     Training average negative_sample_loss at step 131600: 0.074152\n",
      "2024-03-01 10:37:41 INFO     Training average loss at step 131600: 0.079477\n",
      "2024-03-01 10:39:41 INFO     Training average positive_sample_loss at step 131700: 0.085836\n",
      "2024-03-01 10:39:41 INFO     Training average negative_sample_loss at step 131700: 0.074459\n",
      "2024-03-01 10:39:41 INFO     Training average loss at step 131700: 0.080148\n",
      "2024-03-01 10:41:28 INFO     Training average positive_sample_loss at step 131800: 0.085686\n",
      "2024-03-01 10:41:28 INFO     Training average negative_sample_loss at step 131800: 0.074550\n",
      "2024-03-01 10:41:28 INFO     Training average loss at step 131800: 0.080118\n",
      "2024-03-01 10:43:08 INFO     Training average positive_sample_loss at step 131900: 0.085776\n",
      "2024-03-01 10:43:08 INFO     Training average negative_sample_loss at step 131900: 0.074596\n",
      "2024-03-01 10:43:08 INFO     Training average loss at step 131900: 0.080186\n",
      "2024-03-01 10:45:24 INFO     Training average positive_sample_loss at step 132000: 0.086033\n",
      "2024-03-01 10:45:24 INFO     Training average negative_sample_loss at step 132000: 0.074651\n",
      "2024-03-01 10:45:24 INFO     Training average loss at step 132000: 0.080342\n",
      "2024-03-01 10:47:20 INFO     Training average positive_sample_loss at step 132100: 0.086180\n",
      "2024-03-01 10:47:20 INFO     Training average negative_sample_loss at step 132100: 0.075428\n",
      "2024-03-01 10:47:20 INFO     Training average loss at step 132100: 0.080804\n",
      "2024-03-01 10:49:38 INFO     Training average positive_sample_loss at step 132200: 0.085255\n",
      "2024-03-01 10:49:38 INFO     Training average negative_sample_loss at step 132200: 0.074938\n",
      "2024-03-01 10:49:38 INFO     Training average loss at step 132200: 0.080097\n",
      "2024-03-01 10:51:29 INFO     Training average positive_sample_loss at step 132300: 0.083796\n",
      "2024-03-01 10:51:29 INFO     Training average negative_sample_loss at step 132300: 0.073976\n",
      "2024-03-01 10:51:29 INFO     Training average loss at step 132300: 0.078886\n",
      "2024-03-01 10:53:16 INFO     Training average positive_sample_loss at step 132400: 0.085011\n",
      "2024-03-01 10:53:16 INFO     Training average negative_sample_loss at step 132400: 0.074151\n",
      "2024-03-01 10:53:16 INFO     Training average loss at step 132400: 0.079581\n",
      "2024-03-01 10:55:13 INFO     Training average positive_sample_loss at step 132500: 0.084796\n",
      "2024-03-01 10:55:13 INFO     Training average negative_sample_loss at step 132500: 0.073841\n",
      "2024-03-01 10:55:13 INFO     Training average loss at step 132500: 0.079319\n",
      "2024-03-01 10:57:09 INFO     Training average positive_sample_loss at step 132600: 0.085569\n",
      "2024-03-01 10:57:09 INFO     Training average negative_sample_loss at step 132600: 0.074561\n",
      "2024-03-01 10:57:09 INFO     Training average loss at step 132600: 0.080065\n",
      "2024-03-01 10:58:58 INFO     Training average positive_sample_loss at step 132700: 0.085524\n",
      "2024-03-01 10:58:58 INFO     Training average negative_sample_loss at step 132700: 0.074400\n",
      "2024-03-01 10:58:58 INFO     Training average loss at step 132700: 0.079962\n",
      "2024-03-01 11:00:34 INFO     Training average positive_sample_loss at step 132800: 0.085714\n",
      "2024-03-01 11:00:34 INFO     Training average negative_sample_loss at step 132800: 0.074667\n",
      "2024-03-01 11:00:34 INFO     Training average loss at step 132800: 0.080190\n",
      "2024-03-01 11:02:25 INFO     Training average positive_sample_loss at step 132900: 0.086130\n",
      "2024-03-01 11:02:25 INFO     Training average negative_sample_loss at step 132900: 0.074955\n",
      "2024-03-01 11:02:25 INFO     Training average loss at step 132900: 0.080543\n",
      "2024-03-01 11:04:28 INFO     Training average positive_sample_loss at step 133000: 0.085329\n",
      "2024-03-01 11:04:28 INFO     Training average negative_sample_loss at step 133000: 0.074449\n",
      "2024-03-01 11:04:28 INFO     Training average loss at step 133000: 0.079889\n",
      "2024-03-01 11:06:24 INFO     Training average positive_sample_loss at step 133100: 0.086289\n",
      "2024-03-01 11:06:24 INFO     Training average negative_sample_loss at step 133100: 0.075055\n",
      "2024-03-01 11:06:24 INFO     Training average loss at step 133100: 0.080672\n",
      "2024-03-01 11:08:30 INFO     Training average positive_sample_loss at step 133200: 0.083851\n",
      "2024-03-01 11:08:30 INFO     Training average negative_sample_loss at step 133200: 0.074494\n",
      "2024-03-01 11:08:30 INFO     Training average loss at step 133200: 0.079172\n",
      "2024-03-01 11:10:05 INFO     Training average positive_sample_loss at step 133300: 0.084317\n",
      "2024-03-01 11:10:05 INFO     Training average negative_sample_loss at step 133300: 0.073943\n",
      "2024-03-01 11:10:05 INFO     Training average loss at step 133300: 0.079130\n",
      "2024-03-01 11:11:50 INFO     Training average positive_sample_loss at step 133400: 0.085090\n",
      "2024-03-01 11:11:50 INFO     Training average negative_sample_loss at step 133400: 0.074245\n",
      "2024-03-01 11:11:50 INFO     Training average loss at step 133400: 0.079668\n",
      "2024-03-01 11:13:50 INFO     Training average positive_sample_loss at step 133500: 0.084926\n",
      "2024-03-01 11:13:50 INFO     Training average negative_sample_loss at step 133500: 0.073913\n",
      "2024-03-01 11:13:50 INFO     Training average loss at step 133500: 0.079420\n",
      "2024-03-01 11:15:51 INFO     Training average positive_sample_loss at step 133600: 0.085634\n",
      "2024-03-01 11:15:51 INFO     Training average negative_sample_loss at step 133600: 0.074337\n",
      "2024-03-01 11:15:51 INFO     Training average loss at step 133600: 0.079985\n",
      "2024-03-01 11:17:57 INFO     Training average positive_sample_loss at step 133700: 0.085717\n",
      "2024-03-01 11:17:57 INFO     Training average negative_sample_loss at step 133700: 0.074536\n",
      "2024-03-01 11:17:57 INFO     Training average loss at step 133700: 0.080126\n",
      "2024-03-01 11:19:51 INFO     Training average positive_sample_loss at step 133800: 0.085445\n",
      "2024-03-01 11:19:51 INFO     Training average negative_sample_loss at step 133800: 0.074614\n",
      "2024-03-01 11:19:51 INFO     Training average loss at step 133800: 0.080029\n",
      "2024-03-01 11:21:45 INFO     Training average positive_sample_loss at step 133900: 0.085992\n",
      "2024-03-01 11:21:45 INFO     Training average negative_sample_loss at step 133900: 0.074714\n",
      "2024-03-01 11:21:45 INFO     Training average loss at step 133900: 0.080353\n",
      "2024-03-01 11:23:44 INFO     Training average positive_sample_loss at step 134000: 0.086016\n",
      "2024-03-01 11:23:44 INFO     Training average negative_sample_loss at step 134000: 0.074954\n",
      "2024-03-01 11:23:44 INFO     Training average loss at step 134000: 0.080485\n",
      "2024-03-01 11:25:47 INFO     Training average positive_sample_loss at step 134100: 0.084715\n",
      "2024-03-01 11:25:47 INFO     Training average negative_sample_loss at step 134100: 0.075214\n",
      "2024-03-01 11:25:47 INFO     Training average loss at step 134100: 0.079964\n",
      "2024-03-01 11:27:29 INFO     Training average positive_sample_loss at step 134200: 0.083968\n",
      "2024-03-01 11:27:29 INFO     Training average negative_sample_loss at step 134200: 0.074177\n",
      "2024-03-01 11:27:29 INFO     Training average loss at step 134200: 0.079073\n",
      "2024-03-01 11:29:24 INFO     Training average positive_sample_loss at step 134300: 0.084794\n",
      "2024-03-01 11:29:24 INFO     Training average negative_sample_loss at step 134300: 0.074244\n",
      "2024-03-01 11:29:24 INFO     Training average loss at step 134300: 0.079519\n",
      "2024-03-01 11:31:05 INFO     Training average positive_sample_loss at step 134400: 0.085086\n",
      "2024-03-01 11:31:05 INFO     Training average negative_sample_loss at step 134400: 0.074207\n",
      "2024-03-01 11:31:05 INFO     Training average loss at step 134400: 0.079646\n",
      "2024-03-01 11:33:13 INFO     Training average positive_sample_loss at step 134500: 0.085669\n",
      "2024-03-01 11:33:13 INFO     Training average negative_sample_loss at step 134500: 0.074352\n",
      "2024-03-01 11:33:13 INFO     Training average loss at step 134500: 0.080010\n",
      "2024-03-01 11:34:51 INFO     Training average positive_sample_loss at step 134600: 0.085402\n",
      "2024-03-01 11:34:51 INFO     Training average negative_sample_loss at step 134600: 0.074376\n",
      "2024-03-01 11:34:51 INFO     Training average loss at step 134600: 0.079889\n",
      "2024-03-01 11:36:38 INFO     Training average positive_sample_loss at step 134700: 0.086099\n",
      "2024-03-01 11:36:38 INFO     Training average negative_sample_loss at step 134700: 0.074603\n",
      "2024-03-01 11:36:38 INFO     Training average loss at step 134700: 0.080351\n",
      "2024-03-01 11:38:32 INFO     Training average positive_sample_loss at step 134800: 0.085442\n",
      "2024-03-01 11:38:32 INFO     Training average negative_sample_loss at step 134800: 0.074610\n",
      "2024-03-01 11:38:32 INFO     Training average loss at step 134800: 0.080026\n",
      "2024-03-01 11:40:25 INFO     Training average positive_sample_loss at step 134900: 0.085971\n",
      "2024-03-01 11:40:25 INFO     Training average negative_sample_loss at step 134900: 0.075006\n",
      "2024-03-01 11:40:25 INFO     Training average loss at step 134900: 0.080489\n",
      "2024-03-01 11:42:29 INFO     Training average positive_sample_loss at step 135000: 0.085777\n",
      "2024-03-01 11:42:29 INFO     Training average negative_sample_loss at step 135000: 0.074832\n",
      "2024-03-01 11:42:29 INFO     Training average loss at step 135000: 0.080305\n",
      "2024-03-01 11:44:24 INFO     Training average positive_sample_loss at step 135100: 0.083738\n",
      "2024-03-01 11:44:24 INFO     Training average negative_sample_loss at step 135100: 0.074328\n",
      "2024-03-01 11:44:24 INFO     Training average loss at step 135100: 0.079033\n",
      "2024-03-01 11:46:09 INFO     Training average positive_sample_loss at step 135200: 0.084335\n",
      "2024-03-01 11:46:09 INFO     Training average negative_sample_loss at step 135200: 0.074120\n",
      "2024-03-01 11:46:09 INFO     Training average loss at step 135200: 0.079227\n",
      "2024-03-01 11:47:57 INFO     Training average positive_sample_loss at step 135300: 0.085131\n",
      "2024-03-01 11:47:57 INFO     Training average negative_sample_loss at step 135300: 0.074343\n",
      "2024-03-01 11:47:57 INFO     Training average loss at step 135300: 0.079737\n",
      "2024-03-01 11:49:51 INFO     Training average positive_sample_loss at step 135400: 0.085198\n",
      "2024-03-01 11:49:51 INFO     Training average negative_sample_loss at step 135400: 0.074213\n",
      "2024-03-01 11:49:51 INFO     Training average loss at step 135400: 0.079705\n",
      "2024-03-01 11:51:35 INFO     Training average positive_sample_loss at step 135500: 0.085680\n",
      "2024-03-01 11:51:35 INFO     Training average negative_sample_loss at step 135500: 0.074493\n",
      "2024-03-01 11:51:35 INFO     Training average loss at step 135500: 0.080087\n",
      "2024-03-01 11:53:24 INFO     Training average positive_sample_loss at step 135600: 0.085385\n",
      "2024-03-01 11:53:24 INFO     Training average negative_sample_loss at step 135600: 0.074283\n",
      "2024-03-01 11:53:24 INFO     Training average loss at step 135600: 0.079834\n",
      "2024-03-01 11:55:03 INFO     Training average positive_sample_loss at step 135700: 0.086080\n",
      "2024-03-01 11:55:03 INFO     Training average negative_sample_loss at step 135700: 0.074867\n",
      "2024-03-01 11:55:03 INFO     Training average loss at step 135700: 0.080474\n",
      "2024-03-01 11:56:30 INFO     Training average positive_sample_loss at step 135800: 0.085987\n",
      "2024-03-01 11:56:30 INFO     Training average negative_sample_loss at step 135800: 0.074682\n",
      "2024-03-01 11:56:30 INFO     Training average loss at step 135800: 0.080334\n",
      "2024-03-01 11:58:01 INFO     Training average positive_sample_loss at step 135900: 0.085932\n",
      "2024-03-01 11:58:01 INFO     Training average negative_sample_loss at step 135900: 0.074739\n",
      "2024-03-01 11:58:01 INFO     Training average loss at step 135900: 0.080335\n",
      "2024-03-01 12:00:05 INFO     Training average positive_sample_loss at step 136000: 0.084010\n",
      "2024-03-01 12:00:05 INFO     Training average negative_sample_loss at step 136000: 0.074553\n",
      "2024-03-01 12:00:05 INFO     Training average loss at step 136000: 0.079281\n",
      "2024-03-01 12:01:52 INFO     Training average positive_sample_loss at step 136100: 0.084246\n",
      "2024-03-01 12:01:52 INFO     Training average negative_sample_loss at step 136100: 0.074100\n",
      "2024-03-01 12:01:52 INFO     Training average loss at step 136100: 0.079173\n",
      "2024-03-01 12:04:20 INFO     Training average positive_sample_loss at step 136200: 0.084732\n",
      "2024-03-01 12:04:20 INFO     Training average negative_sample_loss at step 136200: 0.074178\n",
      "2024-03-01 12:04:20 INFO     Training average loss at step 136200: 0.079455\n",
      "2024-03-01 12:06:25 INFO     Training average positive_sample_loss at step 136300: 0.085380\n",
      "2024-03-01 12:06:25 INFO     Training average negative_sample_loss at step 136300: 0.073857\n",
      "2024-03-01 12:06:25 INFO     Training average loss at step 136300: 0.079618\n",
      "2024-03-01 12:08:27 INFO     Training average positive_sample_loss at step 136400: 0.085744\n",
      "2024-03-01 12:08:27 INFO     Training average negative_sample_loss at step 136400: 0.074505\n",
      "2024-03-01 12:08:27 INFO     Training average loss at step 136400: 0.080124\n",
      "2024-03-01 12:10:06 INFO     Training average positive_sample_loss at step 136500: 0.085803\n",
      "2024-03-01 12:10:06 INFO     Training average negative_sample_loss at step 136500: 0.074978\n",
      "2024-03-01 12:10:06 INFO     Training average loss at step 136500: 0.080391\n",
      "2024-03-01 12:12:00 INFO     Training average positive_sample_loss at step 136600: 0.085483\n",
      "2024-03-01 12:12:00 INFO     Training average negative_sample_loss at step 136600: 0.074415\n",
      "2024-03-01 12:12:00 INFO     Training average loss at step 136600: 0.079949\n",
      "2024-03-01 12:14:06 INFO     Training average positive_sample_loss at step 136700: 0.085332\n",
      "2024-03-01 12:14:06 INFO     Training average negative_sample_loss at step 136700: 0.074442\n",
      "2024-03-01 12:14:06 INFO     Training average loss at step 136700: 0.079887\n",
      "2024-03-01 12:16:04 INFO     Training average positive_sample_loss at step 136800: 0.086036\n",
      "2024-03-01 12:16:04 INFO     Training average negative_sample_loss at step 136800: 0.074730\n",
      "2024-03-01 12:16:04 INFO     Training average loss at step 136800: 0.080383\n",
      "2024-03-01 12:18:23 INFO     Training average positive_sample_loss at step 136900: 0.085478\n",
      "2024-03-01 12:18:23 INFO     Training average negative_sample_loss at step 136900: 0.074779\n",
      "2024-03-01 12:18:23 INFO     Training average loss at step 136900: 0.080129\n",
      "2024-03-01 12:20:01 INFO     Training average positive_sample_loss at step 137000: 0.083896\n",
      "2024-03-01 12:20:01 INFO     Training average negative_sample_loss at step 137000: 0.074383\n",
      "2024-03-01 12:20:01 INFO     Training average loss at step 137000: 0.079139\n",
      "2024-03-01 12:21:54 INFO     Training average positive_sample_loss at step 137100: 0.084327\n",
      "2024-03-01 12:21:54 INFO     Training average negative_sample_loss at step 137100: 0.073985\n",
      "2024-03-01 12:21:54 INFO     Training average loss at step 137100: 0.079156\n",
      "2024-03-01 12:23:45 INFO     Training average positive_sample_loss at step 137200: 0.085164\n",
      "2024-03-01 12:23:45 INFO     Training average negative_sample_loss at step 137200: 0.074468\n",
      "2024-03-01 12:23:45 INFO     Training average loss at step 137200: 0.079816\n",
      "2024-03-01 12:25:31 INFO     Training average positive_sample_loss at step 137300: 0.085827\n",
      "2024-03-01 12:25:31 INFO     Training average negative_sample_loss at step 137300: 0.074768\n",
      "2024-03-01 12:25:31 INFO     Training average loss at step 137300: 0.080298\n",
      "2024-03-01 12:27:05 INFO     Training average positive_sample_loss at step 137400: 0.085503\n",
      "2024-03-01 12:27:05 INFO     Training average negative_sample_loss at step 137400: 0.074173\n",
      "2024-03-01 12:27:05 INFO     Training average loss at step 137400: 0.079838\n",
      "2024-03-01 12:28:48 INFO     Training average positive_sample_loss at step 137500: 0.085368\n",
      "2024-03-01 12:28:48 INFO     Training average negative_sample_loss at step 137500: 0.074603\n",
      "2024-03-01 12:28:48 INFO     Training average loss at step 137500: 0.079986\n",
      "2024-03-01 12:30:35 INFO     Training average positive_sample_loss at step 137600: 0.085969\n",
      "2024-03-01 12:30:35 INFO     Training average negative_sample_loss at step 137600: 0.074541\n",
      "2024-03-01 12:30:35 INFO     Training average loss at step 137600: 0.080255\n",
      "2024-03-01 12:32:22 INFO     Training average positive_sample_loss at step 137700: 0.085889\n",
      "2024-03-01 12:32:22 INFO     Training average negative_sample_loss at step 137700: 0.074761\n",
      "2024-03-01 12:32:22 INFO     Training average loss at step 137700: 0.080325\n",
      "2024-03-01 12:34:21 INFO     Training average positive_sample_loss at step 137800: 0.085804\n",
      "2024-03-01 12:34:21 INFO     Training average negative_sample_loss at step 137800: 0.074599\n",
      "2024-03-01 12:34:21 INFO     Training average loss at step 137800: 0.080202\n",
      "2024-03-01 12:36:32 INFO     Training average positive_sample_loss at step 137900: 0.084228\n",
      "2024-03-01 12:36:32 INFO     Training average negative_sample_loss at step 137900: 0.074659\n",
      "2024-03-01 12:36:32 INFO     Training average loss at step 137900: 0.079443\n",
      "2024-03-01 12:38:20 INFO     Training average positive_sample_loss at step 138000: 0.084254\n",
      "2024-03-01 12:38:20 INFO     Training average negative_sample_loss at step 138000: 0.074173\n",
      "2024-03-01 12:38:20 INFO     Training average loss at step 138000: 0.079213\n",
      "2024-03-01 12:40:19 INFO     Training average positive_sample_loss at step 138100: 0.084805\n",
      "2024-03-01 12:40:19 INFO     Training average negative_sample_loss at step 138100: 0.074163\n",
      "2024-03-01 12:40:19 INFO     Training average loss at step 138100: 0.079484\n",
      "2024-03-01 12:42:22 INFO     Training average positive_sample_loss at step 138200: 0.085015\n",
      "2024-03-01 12:42:22 INFO     Training average negative_sample_loss at step 138200: 0.074138\n",
      "2024-03-01 12:42:22 INFO     Training average loss at step 138200: 0.079576\n",
      "2024-03-01 12:44:24 INFO     Training average positive_sample_loss at step 138300: 0.085584\n",
      "2024-03-01 12:44:24 INFO     Training average negative_sample_loss at step 138300: 0.074637\n",
      "2024-03-01 12:44:24 INFO     Training average loss at step 138300: 0.080110\n",
      "2024-03-01 12:46:21 INFO     Training average positive_sample_loss at step 138400: 0.085586\n",
      "2024-03-01 12:46:21 INFO     Training average negative_sample_loss at step 138400: 0.074280\n",
      "2024-03-01 12:46:21 INFO     Training average loss at step 138400: 0.079933\n",
      "2024-03-01 12:48:07 INFO     Training average positive_sample_loss at step 138500: 0.085493\n",
      "2024-03-01 12:48:07 INFO     Training average negative_sample_loss at step 138500: 0.074229\n",
      "2024-03-01 12:48:07 INFO     Training average loss at step 138500: 0.079861\n",
      "2024-03-01 12:49:52 INFO     Training average positive_sample_loss at step 138600: 0.085752\n",
      "2024-03-01 12:49:52 INFO     Training average negative_sample_loss at step 138600: 0.074505\n",
      "2024-03-01 12:49:52 INFO     Training average loss at step 138600: 0.080128\n",
      "2024-03-01 12:51:44 INFO     Training average positive_sample_loss at step 138700: 0.085879\n",
      "2024-03-01 12:51:44 INFO     Training average negative_sample_loss at step 138700: 0.074911\n",
      "2024-03-01 12:51:44 INFO     Training average loss at step 138700: 0.080395\n",
      "2024-03-01 12:53:48 INFO     Training average positive_sample_loss at step 138800: 0.085010\n",
      "2024-03-01 12:53:48 INFO     Training average negative_sample_loss at step 138800: 0.074665\n",
      "2024-03-01 12:53:48 INFO     Training average loss at step 138800: 0.079837\n",
      "2024-03-01 12:55:29 INFO     Training average positive_sample_loss at step 138900: 0.083597\n",
      "2024-03-01 12:55:29 INFO     Training average negative_sample_loss at step 138900: 0.073904\n",
      "2024-03-01 12:55:29 INFO     Training average loss at step 138900: 0.078751\n",
      "2024-03-01 12:57:21 INFO     Training average positive_sample_loss at step 139000: 0.084900\n",
      "2024-03-01 12:57:21 INFO     Training average negative_sample_loss at step 139000: 0.074429\n",
      "2024-03-01 12:57:21 INFO     Training average loss at step 139000: 0.079665\n",
      "2024-03-01 12:59:21 INFO     Training average positive_sample_loss at step 139100: 0.084833\n",
      "2024-03-01 12:59:21 INFO     Training average negative_sample_loss at step 139100: 0.074017\n",
      "2024-03-01 12:59:21 INFO     Training average loss at step 139100: 0.079425\n",
      "2024-03-01 13:01:07 INFO     Training average positive_sample_loss at step 139200: 0.085295\n",
      "2024-03-01 13:01:07 INFO     Training average negative_sample_loss at step 139200: 0.074207\n",
      "2024-03-01 13:01:07 INFO     Training average loss at step 139200: 0.079751\n",
      "2024-03-01 13:03:01 INFO     Training average positive_sample_loss at step 139300: 0.085786\n",
      "2024-03-01 13:03:01 INFO     Training average negative_sample_loss at step 139300: 0.074221\n",
      "2024-03-01 13:03:01 INFO     Training average loss at step 139300: 0.080004\n",
      "2024-03-01 13:04:58 INFO     Training average positive_sample_loss at step 139400: 0.085735\n",
      "2024-03-01 13:04:58 INFO     Training average negative_sample_loss at step 139400: 0.074667\n",
      "2024-03-01 13:04:58 INFO     Training average loss at step 139400: 0.080201\n",
      "2024-03-01 13:07:01 INFO     Training average positive_sample_loss at step 139500: 0.085927\n",
      "2024-03-01 13:07:01 INFO     Training average negative_sample_loss at step 139500: 0.074733\n",
      "2024-03-01 13:07:01 INFO     Training average loss at step 139500: 0.080330\n",
      "2024-03-01 13:09:05 INFO     Training average positive_sample_loss at step 139600: 0.085704\n",
      "2024-03-01 13:09:05 INFO     Training average negative_sample_loss at step 139600: 0.074733\n",
      "2024-03-01 13:09:05 INFO     Training average loss at step 139600: 0.080218\n",
      "2024-03-01 13:11:05 INFO     Training average positive_sample_loss at step 139700: 0.086069\n",
      "2024-03-01 13:11:05 INFO     Training average negative_sample_loss at step 139700: 0.074742\n",
      "2024-03-01 13:11:05 INFO     Training average loss at step 139700: 0.080406\n",
      "2024-03-01 13:13:07 INFO     Training average positive_sample_loss at step 139800: 0.084085\n",
      "2024-03-01 13:13:07 INFO     Training average negative_sample_loss at step 139800: 0.074943\n",
      "2024-03-01 13:13:07 INFO     Training average loss at step 139800: 0.079514\n",
      "2024-03-01 13:15:04 INFO     Training average positive_sample_loss at step 139900: 0.084359\n",
      "2024-03-01 13:15:04 INFO     Training average negative_sample_loss at step 139900: 0.073967\n",
      "2024-03-01 13:15:04 INFO     Training average loss at step 139900: 0.079163\n",
      "2024-03-01 13:16:57 INFO     Training average positive_sample_loss at step 140000: 0.084728\n",
      "2024-03-01 13:16:57 INFO     Training average negative_sample_loss at step 140000: 0.073981\n",
      "2024-03-01 13:16:57 INFO     Training average loss at step 140000: 0.079354\n",
      "2024-03-01 13:16:57 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 13:16:58 INFO     Evaluating the model... (0/6250)\n",
      "2024-03-01 13:17:35 INFO     Evaluating the model... (1000/6250)\n",
      "2024-03-01 13:18:08 INFO     Evaluating the model... (2000/6250)\n",
      "2024-03-01 13:18:41 INFO     Evaluating the model... (3000/6250)\n",
      "2024-03-01 13:19:16 INFO     Evaluating the model... (4000/6250)\n",
      "2024-03-01 13:19:47 INFO     Evaluating the model... (5000/6250)\n",
      "2024-03-01 13:20:17 INFO     Evaluating the model... (6000/6250)\n",
      "2024-03-01 13:20:25 INFO     Valid MRR at step 140000: 0.445620\n",
      "2024-03-01 13:20:25 INFO     Valid MR at step 140000: 215.131640\n",
      "2024-03-01 13:20:25 INFO     Valid HITS@1 at step 140000: 0.347370\n",
      "2024-03-01 13:20:25 INFO     Valid HITS@3 at step 140000: 0.478590\n",
      "2024-03-01 13:20:25 INFO     Valid HITS@10 at step 140000: 0.661600\n",
      "2024-03-01 13:22:00 INFO     Training average positive_sample_loss at step 140100: 0.085486\n",
      "2024-03-01 13:22:00 INFO     Training average negative_sample_loss at step 140100: 0.074444\n",
      "2024-03-01 13:22:00 INFO     Training average loss at step 140100: 0.079965\n",
      "2024-03-01 13:23:28 INFO     Training average positive_sample_loss at step 140200: 0.085192\n",
      "2024-03-01 13:23:28 INFO     Training average negative_sample_loss at step 140200: 0.074391\n",
      "2024-03-01 13:23:28 INFO     Training average loss at step 140200: 0.079791\n",
      "2024-03-01 13:25:21 INFO     Training average positive_sample_loss at step 140300: 0.085388\n",
      "2024-03-01 13:25:21 INFO     Training average negative_sample_loss at step 140300: 0.074535\n",
      "2024-03-01 13:25:21 INFO     Training average loss at step 140300: 0.079961\n",
      "2024-03-01 13:27:02 INFO     Training average positive_sample_loss at step 140400: 0.085552\n",
      "2024-03-01 13:27:02 INFO     Training average negative_sample_loss at step 140400: 0.074296\n",
      "2024-03-01 13:27:02 INFO     Training average loss at step 140400: 0.079924\n",
      "2024-03-01 13:28:58 INFO     Training average positive_sample_loss at step 140500: 0.085998\n",
      "2024-03-01 13:28:58 INFO     Training average negative_sample_loss at step 140500: 0.074753\n",
      "2024-03-01 13:28:58 INFO     Training average loss at step 140500: 0.080375\n",
      "2024-03-01 13:30:41 INFO     Training average positive_sample_loss at step 140600: 0.086067\n",
      "2024-03-01 13:30:41 INFO     Training average negative_sample_loss at step 140600: 0.074785\n",
      "2024-03-01 13:30:41 INFO     Training average loss at step 140600: 0.080426\n",
      "2024-03-01 13:32:39 INFO     Training average positive_sample_loss at step 140700: 0.084519\n",
      "2024-03-01 13:32:39 INFO     Training average negative_sample_loss at step 140700: 0.074621\n",
      "2024-03-01 13:32:39 INFO     Training average loss at step 140700: 0.079570\n",
      "2024-03-01 13:34:34 INFO     Training average positive_sample_loss at step 140800: 0.084280\n",
      "2024-03-01 13:34:34 INFO     Training average negative_sample_loss at step 140800: 0.074325\n",
      "2024-03-01 13:34:34 INFO     Training average loss at step 140800: 0.079302\n",
      "2024-03-01 13:36:26 INFO     Training average positive_sample_loss at step 140900: 0.084891\n",
      "2024-03-01 13:36:26 INFO     Training average negative_sample_loss at step 140900: 0.074241\n",
      "2024-03-01 13:36:26 INFO     Training average loss at step 140900: 0.079566\n",
      "2024-03-01 13:38:19 INFO     Training average positive_sample_loss at step 141000: 0.084889\n",
      "2024-03-01 13:38:19 INFO     Training average negative_sample_loss at step 141000: 0.074015\n",
      "2024-03-01 13:38:19 INFO     Training average loss at step 141000: 0.079452\n",
      "2024-03-01 13:40:05 INFO     Training average positive_sample_loss at step 141100: 0.085031\n",
      "2024-03-01 13:40:05 INFO     Training average negative_sample_loss at step 141100: 0.074156\n",
      "2024-03-01 13:40:05 INFO     Training average loss at step 141100: 0.079593\n",
      "2024-03-01 13:42:03 INFO     Training average positive_sample_loss at step 141200: 0.085431\n",
      "2024-03-01 13:42:03 INFO     Training average negative_sample_loss at step 141200: 0.074353\n",
      "2024-03-01 13:42:03 INFO     Training average loss at step 141200: 0.079892\n",
      "2024-03-01 13:44:07 INFO     Training average positive_sample_loss at step 141300: 0.086265\n",
      "2024-03-01 13:44:07 INFO     Training average negative_sample_loss at step 141300: 0.074890\n",
      "2024-03-01 13:44:07 INFO     Training average loss at step 141300: 0.080577\n",
      "2024-03-01 13:46:08 INFO     Training average positive_sample_loss at step 141400: 0.085641\n",
      "2024-03-01 13:46:08 INFO     Training average negative_sample_loss at step 141400: 0.074677\n",
      "2024-03-01 13:46:08 INFO     Training average loss at step 141400: 0.080159\n",
      "2024-03-01 13:48:05 INFO     Training average positive_sample_loss at step 141500: 0.085770\n",
      "2024-03-01 13:48:05 INFO     Training average negative_sample_loss at step 141500: 0.074294\n",
      "2024-03-01 13:48:05 INFO     Training average loss at step 141500: 0.080032\n",
      "2024-03-01 13:50:11 INFO     Training average positive_sample_loss at step 141600: 0.085819\n",
      "2024-03-01 13:50:11 INFO     Training average negative_sample_loss at step 141600: 0.075021\n",
      "2024-03-01 13:50:11 INFO     Training average loss at step 141600: 0.080420\n",
      "2024-03-01 13:52:00 INFO     Training average positive_sample_loss at step 141700: 0.083029\n",
      "2024-03-01 13:52:00 INFO     Training average negative_sample_loss at step 141700: 0.074107\n",
      "2024-03-01 13:52:00 INFO     Training average loss at step 141700: 0.078568\n",
      "2024-03-01 13:53:55 INFO     Training average positive_sample_loss at step 141800: 0.084211\n",
      "2024-03-01 13:53:55 INFO     Training average negative_sample_loss at step 141800: 0.073911\n",
      "2024-03-01 13:53:55 INFO     Training average loss at step 141800: 0.079061\n",
      "2024-03-01 13:55:39 INFO     Training average positive_sample_loss at step 141900: 0.084932\n",
      "2024-03-01 13:55:39 INFO     Training average negative_sample_loss at step 141900: 0.073983\n",
      "2024-03-01 13:55:39 INFO     Training average loss at step 141900: 0.079458\n",
      "2024-03-01 13:57:28 INFO     Training average positive_sample_loss at step 142000: 0.085471\n",
      "2024-03-01 13:57:28 INFO     Training average negative_sample_loss at step 142000: 0.074388\n",
      "2024-03-01 13:57:28 INFO     Training average loss at step 142000: 0.079930\n",
      "2024-03-01 13:58:55 INFO     Training average positive_sample_loss at step 142100: 0.085387\n",
      "2024-03-01 13:58:55 INFO     Training average negative_sample_loss at step 142100: 0.074312\n",
      "2024-03-01 13:58:55 INFO     Training average loss at step 142100: 0.079849\n",
      "2024-03-01 14:00:30 INFO     Training average positive_sample_loss at step 142200: 0.085441\n",
      "2024-03-01 14:00:30 INFO     Training average negative_sample_loss at step 142200: 0.074298\n",
      "2024-03-01 14:00:30 INFO     Training average loss at step 142200: 0.079870\n",
      "2024-03-01 14:02:14 INFO     Training average positive_sample_loss at step 142300: 0.085987\n",
      "2024-03-01 14:02:14 INFO     Training average negative_sample_loss at step 142300: 0.074721\n",
      "2024-03-01 14:02:14 INFO     Training average loss at step 142300: 0.080354\n",
      "2024-03-01 14:04:12 INFO     Training average positive_sample_loss at step 142400: 0.086431\n",
      "2024-03-01 14:04:12 INFO     Training average negative_sample_loss at step 142400: 0.075041\n",
      "2024-03-01 14:04:12 INFO     Training average loss at step 142400: 0.080736\n",
      "2024-03-01 14:06:05 INFO     Training average positive_sample_loss at step 142500: 0.086039\n",
      "2024-03-01 14:06:05 INFO     Training average negative_sample_loss at step 142500: 0.074876\n",
      "2024-03-01 14:06:05 INFO     Training average loss at step 142500: 0.080458\n",
      "2024-03-01 14:08:02 INFO     Training average positive_sample_loss at step 142600: 0.084516\n",
      "2024-03-01 14:08:02 INFO     Training average negative_sample_loss at step 142600: 0.075009\n",
      "2024-03-01 14:08:02 INFO     Training average loss at step 142600: 0.079763\n",
      "2024-03-01 14:09:43 INFO     Training average positive_sample_loss at step 142700: 0.084027\n",
      "2024-03-01 14:09:43 INFO     Training average negative_sample_loss at step 142700: 0.074103\n",
      "2024-03-01 14:09:43 INFO     Training average loss at step 142700: 0.079065\n",
      "2024-03-01 14:11:36 INFO     Training average positive_sample_loss at step 142800: 0.084774\n",
      "2024-03-01 14:11:36 INFO     Training average negative_sample_loss at step 142800: 0.073926\n",
      "2024-03-01 14:11:36 INFO     Training average loss at step 142800: 0.079350\n",
      "2024-03-01 14:13:28 INFO     Training average positive_sample_loss at step 142900: 0.084972\n",
      "2024-03-01 14:13:28 INFO     Training average negative_sample_loss at step 142900: 0.074011\n",
      "2024-03-01 14:13:28 INFO     Training average loss at step 142900: 0.079492\n",
      "2024-03-01 14:15:13 INFO     Training average positive_sample_loss at step 143000: 0.085111\n",
      "2024-03-01 14:15:13 INFO     Training average negative_sample_loss at step 143000: 0.074067\n",
      "2024-03-01 14:15:13 INFO     Training average loss at step 143000: 0.079589\n",
      "2024-03-01 14:17:13 INFO     Training average positive_sample_loss at step 143100: 0.085138\n",
      "2024-03-01 14:17:13 INFO     Training average negative_sample_loss at step 143100: 0.074178\n",
      "2024-03-01 14:17:13 INFO     Training average loss at step 143100: 0.079658\n",
      "2024-03-01 14:19:12 INFO     Training average positive_sample_loss at step 143200: 0.085842\n",
      "2024-03-01 14:19:12 INFO     Training average negative_sample_loss at step 143200: 0.074421\n",
      "2024-03-01 14:19:12 INFO     Training average loss at step 143200: 0.080132\n",
      "2024-03-01 14:20:55 INFO     Training average positive_sample_loss at step 143300: 0.085465\n",
      "2024-03-01 14:20:55 INFO     Training average negative_sample_loss at step 143300: 0.074504\n",
      "2024-03-01 14:20:55 INFO     Training average loss at step 143300: 0.079985\n",
      "2024-03-01 14:22:47 INFO     Training average positive_sample_loss at step 143400: 0.086304\n",
      "2024-03-01 14:22:47 INFO     Training average negative_sample_loss at step 143400: 0.075149\n",
      "2024-03-01 14:22:47 INFO     Training average loss at step 143400: 0.080726\n",
      "2024-03-01 14:24:39 INFO     Training average positive_sample_loss at step 143500: 0.085932\n",
      "2024-03-01 14:24:39 INFO     Training average negative_sample_loss at step 143500: 0.075053\n",
      "2024-03-01 14:24:39 INFO     Training average loss at step 143500: 0.080492\n",
      "2024-03-01 14:26:29 INFO     Training average positive_sample_loss at step 143600: 0.083793\n",
      "2024-03-01 14:26:29 INFO     Training average negative_sample_loss at step 143600: 0.074230\n",
      "2024-03-01 14:26:29 INFO     Training average loss at step 143600: 0.079012\n",
      "2024-03-01 14:28:10 INFO     Training average positive_sample_loss at step 143700: 0.084284\n",
      "2024-03-01 14:28:10 INFO     Training average negative_sample_loss at step 143700: 0.073732\n",
      "2024-03-01 14:28:10 INFO     Training average loss at step 143700: 0.079008\n",
      "2024-03-01 14:29:59 INFO     Training average positive_sample_loss at step 143800: 0.084842\n",
      "2024-03-01 14:29:59 INFO     Training average negative_sample_loss at step 143800: 0.074350\n",
      "2024-03-01 14:29:59 INFO     Training average loss at step 143800: 0.079596\n",
      "2024-03-01 14:31:55 INFO     Training average positive_sample_loss at step 143900: 0.085272\n",
      "2024-03-01 14:31:55 INFO     Training average negative_sample_loss at step 143900: 0.074322\n",
      "2024-03-01 14:31:55 INFO     Training average loss at step 143900: 0.079797\n",
      "2024-03-01 14:33:31 INFO     Training average positive_sample_loss at step 144000: 0.085625\n",
      "2024-03-01 14:33:31 INFO     Training average negative_sample_loss at step 144000: 0.074675\n",
      "2024-03-01 14:33:31 INFO     Training average loss at step 144000: 0.080150\n",
      "2024-03-01 14:35:06 INFO     Training average positive_sample_loss at step 144100: 0.085605\n",
      "2024-03-01 14:35:06 INFO     Training average negative_sample_loss at step 144100: 0.074295\n",
      "2024-03-01 14:35:06 INFO     Training average loss at step 144100: 0.079950\n",
      "2024-03-01 14:36:46 INFO     Training average positive_sample_loss at step 144200: 0.085622\n",
      "2024-03-01 14:36:46 INFO     Training average negative_sample_loss at step 144200: 0.074822\n",
      "2024-03-01 14:36:46 INFO     Training average loss at step 144200: 0.080222\n",
      "2024-03-01 14:38:45 INFO     Training average positive_sample_loss at step 144300: 0.085718\n",
      "2024-03-01 14:38:45 INFO     Training average negative_sample_loss at step 144300: 0.074410\n",
      "2024-03-01 14:38:45 INFO     Training average loss at step 144300: 0.080064\n",
      "2024-03-01 14:40:35 INFO     Training average positive_sample_loss at step 144400: 0.085761\n",
      "2024-03-01 14:40:35 INFO     Training average negative_sample_loss at step 144400: 0.074506\n",
      "2024-03-01 14:40:35 INFO     Training average loss at step 144400: 0.080134\n",
      "2024-03-01 14:42:24 INFO     Training average positive_sample_loss at step 144500: 0.084194\n",
      "2024-03-01 14:42:24 INFO     Training average negative_sample_loss at step 144500: 0.074610\n",
      "2024-03-01 14:42:24 INFO     Training average loss at step 144500: 0.079402\n",
      "2024-03-01 14:44:15 INFO     Training average positive_sample_loss at step 144600: 0.083829\n",
      "2024-03-01 14:44:15 INFO     Training average negative_sample_loss at step 144600: 0.074079\n",
      "2024-03-01 14:44:15 INFO     Training average loss at step 144600: 0.078954\n",
      "2024-03-01 14:46:17 INFO     Training average positive_sample_loss at step 144700: 0.084799\n",
      "2024-03-01 14:46:17 INFO     Training average negative_sample_loss at step 144700: 0.074145\n",
      "2024-03-01 14:46:17 INFO     Training average loss at step 144700: 0.079472\n",
      "2024-03-01 14:48:20 INFO     Training average positive_sample_loss at step 144800: 0.085519\n",
      "2024-03-01 14:48:20 INFO     Training average negative_sample_loss at step 144800: 0.074301\n",
      "2024-03-01 14:48:20 INFO     Training average loss at step 144800: 0.079910\n",
      "2024-03-01 14:50:09 INFO     Training average positive_sample_loss at step 144900: 0.085234\n",
      "2024-03-01 14:50:09 INFO     Training average negative_sample_loss at step 144900: 0.073991\n",
      "2024-03-01 14:50:09 INFO     Training average loss at step 144900: 0.079612\n",
      "2024-03-01 14:52:03 INFO     Training average positive_sample_loss at step 145000: 0.085634\n",
      "2024-03-01 14:52:03 INFO     Training average negative_sample_loss at step 145000: 0.074648\n",
      "2024-03-01 14:52:03 INFO     Training average loss at step 145000: 0.080141\n",
      "2024-03-01 14:54:06 INFO     Training average positive_sample_loss at step 145100: 0.086041\n",
      "2024-03-01 14:54:06 INFO     Training average negative_sample_loss at step 145100: 0.074943\n",
      "2024-03-01 14:54:06 INFO     Training average loss at step 145100: 0.080492\n",
      "2024-03-01 14:56:11 INFO     Training average positive_sample_loss at step 145200: 0.085564\n",
      "2024-03-01 14:56:11 INFO     Training average negative_sample_loss at step 145200: 0.074442\n",
      "2024-03-01 14:56:11 INFO     Training average loss at step 145200: 0.080003\n",
      "2024-03-01 14:58:03 INFO     Training average positive_sample_loss at step 145300: 0.085361\n",
      "2024-03-01 14:58:03 INFO     Training average negative_sample_loss at step 145300: 0.074501\n",
      "2024-03-01 14:58:03 INFO     Training average loss at step 145300: 0.079931\n",
      "2024-03-01 15:00:06 INFO     Training average positive_sample_loss at step 145400: 0.085749\n",
      "2024-03-01 15:00:06 INFO     Training average negative_sample_loss at step 145400: 0.074786\n",
      "2024-03-01 15:00:06 INFO     Training average loss at step 145400: 0.080267\n",
      "2024-03-01 15:01:52 INFO     Training average positive_sample_loss at step 145500: 0.083613\n",
      "2024-03-01 15:01:52 INFO     Training average negative_sample_loss at step 145500: 0.073913\n",
      "2024-03-01 15:01:52 INFO     Training average loss at step 145500: 0.078763\n",
      "2024-03-01 15:03:41 INFO     Training average positive_sample_loss at step 145600: 0.084848\n",
      "2024-03-01 15:03:41 INFO     Training average negative_sample_loss at step 145600: 0.074788\n",
      "2024-03-01 15:03:41 INFO     Training average loss at step 145600: 0.079818\n",
      "2024-03-01 15:05:38 INFO     Training average positive_sample_loss at step 145700: 0.085136\n",
      "2024-03-01 15:05:38 INFO     Training average negative_sample_loss at step 145700: 0.074364\n",
      "2024-03-01 15:05:38 INFO     Training average loss at step 145700: 0.079750\n",
      "2024-03-01 15:07:30 INFO     Training average positive_sample_loss at step 145800: 0.085363\n",
      "2024-03-01 15:07:30 INFO     Training average negative_sample_loss at step 145800: 0.074153\n",
      "2024-03-01 15:07:30 INFO     Training average loss at step 145800: 0.079758\n",
      "2024-03-01 15:09:21 INFO     Training average positive_sample_loss at step 145900: 0.085523\n",
      "2024-03-01 15:09:21 INFO     Training average negative_sample_loss at step 145900: 0.074439\n",
      "2024-03-01 15:09:21 INFO     Training average loss at step 145900: 0.079981\n",
      "2024-03-01 15:11:14 INFO     Training average positive_sample_loss at step 146000: 0.085386\n",
      "2024-03-01 15:11:14 INFO     Training average negative_sample_loss at step 146000: 0.074659\n",
      "2024-03-01 15:11:14 INFO     Training average loss at step 146000: 0.080023\n",
      "2024-03-01 15:13:00 INFO     Training average positive_sample_loss at step 146100: 0.085348\n",
      "2024-03-01 15:13:00 INFO     Training average negative_sample_loss at step 146100: 0.074065\n",
      "2024-03-01 15:13:00 INFO     Training average loss at step 146100: 0.079706\n",
      "2024-03-01 15:14:59 INFO     Training average positive_sample_loss at step 146200: 0.086026\n",
      "2024-03-01 15:14:59 INFO     Training average negative_sample_loss at step 146200: 0.074698\n",
      "2024-03-01 15:14:59 INFO     Training average loss at step 146200: 0.080362\n",
      "2024-03-01 15:16:56 INFO     Training average positive_sample_loss at step 146300: 0.085786\n",
      "2024-03-01 15:16:56 INFO     Training average negative_sample_loss at step 146300: 0.074382\n",
      "2024-03-01 15:16:56 INFO     Training average loss at step 146300: 0.080084\n",
      "2024-03-01 15:19:05 INFO     Training average positive_sample_loss at step 146400: 0.084008\n",
      "2024-03-01 15:19:05 INFO     Training average negative_sample_loss at step 146400: 0.074335\n",
      "2024-03-01 15:19:05 INFO     Training average loss at step 146400: 0.079171\n",
      "2024-03-01 15:20:51 INFO     Training average positive_sample_loss at step 146500: 0.084547\n",
      "2024-03-01 15:20:51 INFO     Training average negative_sample_loss at step 146500: 0.074579\n",
      "2024-03-01 15:20:51 INFO     Training average loss at step 146500: 0.079563\n",
      "2024-03-01 15:22:27 INFO     Training average positive_sample_loss at step 146600: 0.084601\n",
      "2024-03-01 15:22:27 INFO     Training average negative_sample_loss at step 146600: 0.074224\n",
      "2024-03-01 15:22:27 INFO     Training average loss at step 146600: 0.079412\n",
      "2024-03-01 15:24:10 INFO     Training average positive_sample_loss at step 146700: 0.085145\n",
      "2024-03-01 15:24:10 INFO     Training average negative_sample_loss at step 146700: 0.074274\n",
      "2024-03-01 15:24:10 INFO     Training average loss at step 146700: 0.079710\n",
      "2024-03-01 15:25:51 INFO     Training average positive_sample_loss at step 146800: 0.085678\n",
      "2024-03-01 15:25:51 INFO     Training average negative_sample_loss at step 146800: 0.074396\n",
      "2024-03-01 15:25:51 INFO     Training average loss at step 146800: 0.080037\n",
      "2024-03-01 15:27:26 INFO     Training average positive_sample_loss at step 146900: 0.085353\n",
      "2024-03-01 15:27:26 INFO     Training average negative_sample_loss at step 146900: 0.074132\n",
      "2024-03-01 15:27:26 INFO     Training average loss at step 146900: 0.079743\n",
      "2024-03-01 15:29:16 INFO     Training average positive_sample_loss at step 147000: 0.085573\n",
      "2024-03-01 15:29:16 INFO     Training average negative_sample_loss at step 147000: 0.074436\n",
      "2024-03-01 15:29:16 INFO     Training average loss at step 147000: 0.080004\n",
      "2024-03-01 15:31:12 INFO     Training average positive_sample_loss at step 147100: 0.086059\n",
      "2024-03-01 15:31:12 INFO     Training average negative_sample_loss at step 147100: 0.074849\n",
      "2024-03-01 15:31:12 INFO     Training average loss at step 147100: 0.080454\n",
      "2024-03-01 15:33:06 INFO     Training average positive_sample_loss at step 147200: 0.085220\n",
      "2024-03-01 15:33:06 INFO     Training average negative_sample_loss at step 147200: 0.074377\n",
      "2024-03-01 15:33:06 INFO     Training average loss at step 147200: 0.079799\n",
      "2024-03-01 15:34:59 INFO     Training average positive_sample_loss at step 147300: 0.084798\n",
      "2024-03-01 15:34:59 INFO     Training average negative_sample_loss at step 147300: 0.074381\n",
      "2024-03-01 15:34:59 INFO     Training average loss at step 147300: 0.079589\n",
      "2024-03-01 15:36:37 INFO     Training average positive_sample_loss at step 147400: 0.083930\n",
      "2024-03-01 15:36:37 INFO     Training average negative_sample_loss at step 147400: 0.074211\n",
      "2024-03-01 15:36:37 INFO     Training average loss at step 147400: 0.079071\n",
      "2024-03-01 15:38:24 INFO     Training average positive_sample_loss at step 147500: 0.084496\n",
      "2024-03-01 15:38:24 INFO     Training average negative_sample_loss at step 147500: 0.074146\n",
      "2024-03-01 15:38:24 INFO     Training average loss at step 147500: 0.079321\n",
      "2024-03-01 15:39:53 INFO     Training average positive_sample_loss at step 147600: 0.085579\n",
      "2024-03-01 15:39:53 INFO     Training average negative_sample_loss at step 147600: 0.074529\n",
      "2024-03-01 15:39:53 INFO     Training average loss at step 147600: 0.080054\n",
      "2024-03-01 15:41:48 INFO     Training average positive_sample_loss at step 147700: 0.085140\n",
      "2024-03-01 15:41:48 INFO     Training average negative_sample_loss at step 147700: 0.074109\n",
      "2024-03-01 15:41:48 INFO     Training average loss at step 147700: 0.079625\n",
      "2024-03-01 15:43:38 INFO     Training average positive_sample_loss at step 147800: 0.085317\n",
      "2024-03-01 15:43:38 INFO     Training average negative_sample_loss at step 147800: 0.074511\n",
      "2024-03-01 15:43:38 INFO     Training average loss at step 147800: 0.079914\n",
      "2024-03-01 15:45:28 INFO     Training average positive_sample_loss at step 147900: 0.085681\n",
      "2024-03-01 15:45:28 INFO     Training average negative_sample_loss at step 147900: 0.074337\n",
      "2024-03-01 15:45:28 INFO     Training average loss at step 147900: 0.080009\n",
      "2024-03-01 15:47:16 INFO     Training average positive_sample_loss at step 148000: 0.086103\n",
      "2024-03-01 15:47:16 INFO     Training average negative_sample_loss at step 148000: 0.074824\n",
      "2024-03-01 15:47:16 INFO     Training average loss at step 148000: 0.080463\n",
      "2024-03-01 15:48:48 INFO     Training average positive_sample_loss at step 148100: 0.085735\n",
      "2024-03-01 15:48:48 INFO     Training average negative_sample_loss at step 148100: 0.074507\n",
      "2024-03-01 15:48:48 INFO     Training average loss at step 148100: 0.080121\n",
      "2024-03-01 15:50:25 INFO     Training average positive_sample_loss at step 148200: 0.085605\n",
      "2024-03-01 15:50:25 INFO     Training average negative_sample_loss at step 148200: 0.074803\n",
      "2024-03-01 15:50:25 INFO     Training average loss at step 148200: 0.080204\n",
      "2024-03-01 15:52:21 INFO     Training average positive_sample_loss at step 148300: 0.083870\n",
      "2024-03-01 15:52:21 INFO     Training average negative_sample_loss at step 148300: 0.074615\n",
      "2024-03-01 15:52:21 INFO     Training average loss at step 148300: 0.079243\n",
      "2024-03-01 15:54:13 INFO     Training average positive_sample_loss at step 148400: 0.084389\n",
      "2024-03-01 15:54:13 INFO     Training average negative_sample_loss at step 148400: 0.074368\n",
      "2024-03-01 15:54:13 INFO     Training average loss at step 148400: 0.079378\n",
      "2024-03-01 15:56:02 INFO     Training average positive_sample_loss at step 148500: 0.084449\n",
      "2024-03-01 15:56:02 INFO     Training average negative_sample_loss at step 148500: 0.073806\n",
      "2024-03-01 15:56:02 INFO     Training average loss at step 148500: 0.079127\n",
      "2024-03-01 15:57:48 INFO     Training average positive_sample_loss at step 148600: 0.084938\n",
      "2024-03-01 15:57:48 INFO     Training average negative_sample_loss at step 148600: 0.073913\n",
      "2024-03-01 15:57:48 INFO     Training average loss at step 148600: 0.079426\n",
      "2024-03-01 15:59:27 INFO     Training average positive_sample_loss at step 148700: 0.085822\n",
      "2024-03-01 15:59:27 INFO     Training average negative_sample_loss at step 148700: 0.074417\n",
      "2024-03-01 15:59:27 INFO     Training average loss at step 148700: 0.080120\n",
      "2024-03-01 16:01:01 INFO     Training average positive_sample_loss at step 148800: 0.085710\n",
      "2024-03-01 16:01:01 INFO     Training average negative_sample_loss at step 148800: 0.074293\n",
      "2024-03-01 16:01:01 INFO     Training average loss at step 148800: 0.080001\n",
      "2024-03-01 16:02:38 INFO     Training average positive_sample_loss at step 148900: 0.086201\n",
      "2024-03-01 16:02:38 INFO     Training average negative_sample_loss at step 148900: 0.074969\n",
      "2024-03-01 16:02:38 INFO     Training average loss at step 148900: 0.080585\n",
      "2024-03-01 16:04:10 INFO     Training average positive_sample_loss at step 149000: 0.085564\n",
      "2024-03-01 16:04:10 INFO     Training average negative_sample_loss at step 149000: 0.074728\n",
      "2024-03-01 16:04:10 INFO     Training average loss at step 149000: 0.080146\n",
      "2024-03-01 16:05:55 INFO     Training average positive_sample_loss at step 149100: 0.085553\n",
      "2024-03-01 16:05:55 INFO     Training average negative_sample_loss at step 149100: 0.074274\n",
      "2024-03-01 16:05:55 INFO     Training average loss at step 149100: 0.079914\n",
      "2024-03-01 16:07:50 INFO     Training average positive_sample_loss at step 149200: 0.084639\n",
      "2024-03-01 16:07:50 INFO     Training average negative_sample_loss at step 149200: 0.074448\n",
      "2024-03-01 16:07:50 INFO     Training average loss at step 149200: 0.079543\n",
      "2024-03-01 16:09:35 INFO     Training average positive_sample_loss at step 149300: 0.083915\n",
      "2024-03-01 16:09:35 INFO     Training average negative_sample_loss at step 149300: 0.074244\n",
      "2024-03-01 16:09:35 INFO     Training average loss at step 149300: 0.079080\n",
      "2024-03-01 16:11:25 INFO     Training average positive_sample_loss at step 149400: 0.084490\n",
      "2024-03-01 16:11:25 INFO     Training average negative_sample_loss at step 149400: 0.074173\n",
      "2024-03-01 16:11:25 INFO     Training average loss at step 149400: 0.079332\n",
      "2024-03-01 16:13:06 INFO     Training average positive_sample_loss at step 149500: 0.085002\n",
      "2024-03-01 16:13:06 INFO     Training average negative_sample_loss at step 149500: 0.074165\n",
      "2024-03-01 16:13:06 INFO     Training average loss at step 149500: 0.079583\n",
      "2024-03-01 16:14:55 INFO     Training average positive_sample_loss at step 149600: 0.085219\n",
      "2024-03-01 16:14:55 INFO     Training average negative_sample_loss at step 149600: 0.074051\n",
      "2024-03-01 16:14:55 INFO     Training average loss at step 149600: 0.079635\n",
      "2024-03-01 16:16:46 INFO     Training average positive_sample_loss at step 149700: 0.085602\n",
      "2024-03-01 16:16:46 INFO     Training average negative_sample_loss at step 149700: 0.074276\n",
      "2024-03-01 16:16:46 INFO     Training average loss at step 149700: 0.079939\n",
      "2024-03-01 16:18:27 INFO     Training average positive_sample_loss at step 149800: 0.085710\n",
      "2024-03-01 16:18:27 INFO     Training average negative_sample_loss at step 149800: 0.074744\n",
      "2024-03-01 16:18:27 INFO     Training average loss at step 149800: 0.080227\n",
      "2024-03-01 16:20:17 INFO     Training average positive_sample_loss at step 149900: 0.085534\n",
      "2024-03-01 16:20:17 INFO     Training average negative_sample_loss at step 149900: 0.074325\n",
      "2024-03-01 16:20:17 INFO     Training average loss at step 149900: 0.079929\n",
      "2024-03-01 16:22:20 INFO     Evaluating on Valid Dataset...\n",
      "2024-03-01 16:22:21 INFO     Evaluating the model... (0/6250)\n",
      "2024-03-01 16:22:56 INFO     Evaluating the model... (1000/6250)\n",
      "2024-03-01 16:23:27 INFO     Evaluating the model... (2000/6250)\n",
      "2024-03-01 16:24:00 INFO     Evaluating the model... (3000/6250)\n",
      "2024-03-01 16:24:35 INFO     Evaluating the model... (4000/6250)\n",
      "2024-03-01 16:25:04 INFO     Evaluating the model... (5000/6250)\n",
      "2024-03-01 16:25:34 INFO     Evaluating the model... (6000/6250)\n",
      "2024-03-01 16:25:42 INFO     Valid MRR at step 149999: 0.447865\n",
      "2024-03-01 16:25:42 INFO     Valid MR at step 149999: 214.244530\n",
      "2024-03-01 16:25:42 INFO     Valid HITS@1 at step 149999: 0.350320\n",
      "2024-03-01 16:25:42 INFO     Valid HITS@3 at step 149999: 0.480370\n",
      "2024-03-01 16:25:42 INFO     Valid HITS@10 at step 149999: 0.662010\n",
      "2024-03-01 16:25:42 INFO     Evaluating on Test Dataset...\n",
      "2024-03-01 16:25:43 INFO     Evaluating the model... (0/7384)\n",
      "2024-03-01 16:26:15 INFO     Evaluating the model... (1000/7384)\n",
      "2024-03-01 16:26:49 INFO     Evaluating the model... (2000/7384)\n",
      "2024-03-01 16:27:22 INFO     Evaluating the model... (3000/7384)\n",
      "2024-03-01 16:27:52 INFO     Evaluating the model... (4000/7384)\n",
      "2024-03-01 16:28:20 INFO     Evaluating the model... (5000/7384)\n",
      "2024-03-01 16:28:49 INFO     Evaluating the model... (6000/7384)\n",
      "2024-03-01 16:29:17 INFO     Evaluating the model... (7000/7384)\n",
      "2024-03-01 16:29:29 INFO     Test MRR at step 149999: 0.450408\n",
      "2024-03-01 16:29:29 INFO     Test MR at step 149999: 208.217941\n",
      "2024-03-01 16:29:29 INFO     Test HITS@1 at step 149999: 0.352880\n",
      "2024-03-01 16:29:29 INFO     Test HITS@3 at step 149999: 0.484104\n",
      "2024-03-01 16:29:29 INFO     Test HITS@10 at step 149999: 0.662584\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE FB15k 0 0 1024 256 1000 24.0 1.0 0.0001 150000 16 -de"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
