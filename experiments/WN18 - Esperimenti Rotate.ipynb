{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con Self. Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1/KnowledgeGraphEmbedding\n"
     ]
    }
   ],
   "source": [
    "%cd KnowledgeGraphEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-01 15:26:26,342 INFO     Model: RotatE\n",
      "2023-12-01 15:26:26,346 INFO     Data Path: data/wn18\n",
      "2023-12-01 15:26:26,346 INFO     #entity: 40943\n",
      "2023-12-01 15:26:26,346 INFO     #relation: 18\n",
      "2023-12-01 15:26:26,441 INFO     #train: 141442\n",
      "2023-12-01 15:26:26,444 INFO     #valid: 5000\n",
      "2023-12-01 15:26:26,448 INFO     #test: 5000\n",
      "2023-12-01 15:26:26,658 INFO     Model Parameter Configuration:\n",
      "2023-12-01 15:26:26,659 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-01 15:26:26,659 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-01 15:26:26,659 INFO     Parameter entity_embedding: torch.Size([40943, 1000]), require_grad = True\n",
      "2023-12-01 15:26:26,659 INFO     Parameter relation_embedding: torch.Size([18, 500]), require_grad = True\n",
      "2023-12-01 15:26:29,357 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-01 15:26:29,358 INFO     Start Training...\n",
      "2023-12-01 15:26:29,358 INFO     init_step = 0\n",
      "2023-12-01 15:26:29,358 INFO     batch_size = 512\n",
      "2023-12-01 15:26:29,358 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-01 15:26:29,358 INFO     hidden_dim = 500\n",
      "2023-12-01 15:26:29,358 INFO     gamma = 12.000000\n",
      "2023-12-01 15:26:29,358 INFO     negative_adversarial_sampling = True\n",
      "2023-12-01 15:26:29,358 INFO     adversarial_temperature = 0.500000\n",
      "2023-12-01 15:26:29,358 INFO     learning_rate = 0\n",
      "2023-12-01 15:26:40,496 INFO     Training average positive_sample_loss at step 0: 2.692591\n",
      "2023-12-01 15:26:40,497 INFO     Training average negative_sample_loss at step 0: 0.077210\n",
      "2023-12-01 15:26:40,497 INFO     Training average loss at step 0: 1.384900\n",
      "2023-12-01 15:26:40,497 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 15:26:41,025 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 15:27:15,287 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 15:27:24,149 INFO     Valid MRR at step 0: 0.000542\n",
      "2023-12-01 15:27:24,149 INFO     Valid MR at step 0: 20454.944300\n",
      "2023-12-01 15:27:24,149 INFO     Valid HITS@1 at step 0: 0.000200\n",
      "2023-12-01 15:27:24,149 INFO     Valid HITS@3 at step 0: 0.000400\n",
      "2023-12-01 15:27:24,149 INFO     Valid HITS@10 at step 0: 0.000600\n",
      "2023-12-01 15:27:29,791 INFO     Training average positive_sample_loss at step 100: 3.522616\n",
      "2023-12-01 15:27:29,792 INFO     Training average negative_sample_loss at step 100: 0.042707\n",
      "2023-12-01 15:27:29,792 INFO     Training average loss at step 100: 1.782662\n",
      "2023-12-01 15:27:35,166 INFO     Training average positive_sample_loss at step 200: 3.143545\n",
      "2023-12-01 15:27:35,166 INFO     Training average negative_sample_loss at step 200: 0.084798\n",
      "2023-12-01 15:27:35,166 INFO     Training average loss at step 200: 1.614171\n",
      "2023-12-01 15:27:40,559 INFO     Training average positive_sample_loss at step 300: 2.416923\n",
      "2023-12-01 15:27:40,560 INFO     Training average negative_sample_loss at step 300: 0.162439\n",
      "2023-12-01 15:27:40,560 INFO     Training average loss at step 300: 1.289681\n",
      "2023-12-01 15:27:45,985 INFO     Training average positive_sample_loss at step 400: 1.818968\n",
      "2023-12-01 15:27:45,985 INFO     Training average negative_sample_loss at step 400: 0.246894\n",
      "2023-12-01 15:27:45,985 INFO     Training average loss at step 400: 1.032931\n",
      "2023-12-01 15:27:51,403 INFO     Training average positive_sample_loss at step 500: 1.359205\n",
      "2023-12-01 15:27:51,403 INFO     Training average negative_sample_loss at step 500: 0.319396\n",
      "2023-12-01 15:27:51,404 INFO     Training average loss at step 500: 0.839300\n",
      "2023-12-01 15:27:57,428 INFO     Training average positive_sample_loss at step 600: 0.907108\n",
      "2023-12-01 15:27:57,429 INFO     Training average negative_sample_loss at step 600: 0.374022\n",
      "2023-12-01 15:27:57,429 INFO     Training average loss at step 600: 0.640565\n",
      "2023-12-01 15:28:02,886 INFO     Training average positive_sample_loss at step 700: 0.641998\n",
      "2023-12-01 15:28:02,886 INFO     Training average negative_sample_loss at step 700: 0.386993\n",
      "2023-12-01 15:28:02,886 INFO     Training average loss at step 700: 0.514495\n",
      "2023-12-01 15:28:08,317 INFO     Training average positive_sample_loss at step 800: 0.567811\n",
      "2023-12-01 15:28:08,317 INFO     Training average negative_sample_loss at step 800: 0.382875\n",
      "2023-12-01 15:28:08,317 INFO     Training average loss at step 800: 0.475343\n",
      "2023-12-01 15:28:13,748 INFO     Training average positive_sample_loss at step 900: 0.504040\n",
      "2023-12-01 15:28:13,749 INFO     Training average negative_sample_loss at step 900: 0.375194\n",
      "2023-12-01 15:28:13,749 INFO     Training average loss at step 900: 0.439617\n",
      "2023-12-01 15:28:19,168 INFO     Training average positive_sample_loss at step 1000: 0.446513\n",
      "2023-12-01 15:28:19,168 INFO     Training average negative_sample_loss at step 1000: 0.363164\n",
      "2023-12-01 15:28:19,168 INFO     Training average loss at step 1000: 0.404838\n",
      "2023-12-01 15:28:24,633 INFO     Training average positive_sample_loss at step 1100: 0.402723\n",
      "2023-12-01 15:28:24,634 INFO     Training average negative_sample_loss at step 1100: 0.349970\n",
      "2023-12-01 15:28:24,634 INFO     Training average loss at step 1100: 0.376347\n",
      "2023-12-01 15:28:30,535 INFO     Training average positive_sample_loss at step 1200: 0.312859\n",
      "2023-12-01 15:28:30,535 INFO     Training average negative_sample_loss at step 1200: 0.325929\n",
      "2023-12-01 15:28:30,535 INFO     Training average loss at step 1200: 0.319394\n",
      "2023-12-01 15:28:35,969 INFO     Training average positive_sample_loss at step 1300: 0.308199\n",
      "2023-12-01 15:28:35,970 INFO     Training average negative_sample_loss at step 1300: 0.298277\n",
      "2023-12-01 15:28:35,970 INFO     Training average loss at step 1300: 0.303238\n",
      "2023-12-01 15:28:41,405 INFO     Training average positive_sample_loss at step 1400: 0.300170\n",
      "2023-12-01 15:28:41,405 INFO     Training average negative_sample_loss at step 1400: 0.279884\n",
      "2023-12-01 15:28:41,405 INFO     Training average loss at step 1400: 0.290027\n",
      "2023-12-01 15:28:46,856 INFO     Training average positive_sample_loss at step 1500: 0.287750\n",
      "2023-12-01 15:28:46,856 INFO     Training average negative_sample_loss at step 1500: 0.265328\n",
      "2023-12-01 15:28:46,856 INFO     Training average loss at step 1500: 0.276539\n",
      "2023-12-01 15:28:52,301 INFO     Training average positive_sample_loss at step 1600: 0.273275\n",
      "2023-12-01 15:28:52,301 INFO     Training average negative_sample_loss at step 1600: 0.250988\n",
      "2023-12-01 15:28:52,301 INFO     Training average loss at step 1600: 0.262131\n",
      "2023-12-01 15:28:58,194 INFO     Training average positive_sample_loss at step 1700: 0.243986\n",
      "2023-12-01 15:28:58,194 INFO     Training average negative_sample_loss at step 1700: 0.235901\n",
      "2023-12-01 15:28:58,194 INFO     Training average loss at step 1700: 0.239944\n",
      "2023-12-01 15:29:03,627 INFO     Training average positive_sample_loss at step 1800: 0.219137\n",
      "2023-12-01 15:29:03,628 INFO     Training average negative_sample_loss at step 1800: 0.214836\n",
      "2023-12-01 15:29:03,628 INFO     Training average loss at step 1800: 0.216987\n",
      "2023-12-01 15:29:09,061 INFO     Training average positive_sample_loss at step 1900: 0.219891\n",
      "2023-12-01 15:29:09,061 INFO     Training average negative_sample_loss at step 1900: 0.201367\n",
      "2023-12-01 15:29:09,061 INFO     Training average loss at step 1900: 0.210629\n",
      "2023-12-01 15:29:14,495 INFO     Training average positive_sample_loss at step 2000: 0.213972\n",
      "2023-12-01 15:29:14,495 INFO     Training average negative_sample_loss at step 2000: 0.189935\n",
      "2023-12-01 15:29:14,495 INFO     Training average loss at step 2000: 0.201953\n",
      "2023-12-01 15:29:19,970 INFO     Training average positive_sample_loss at step 2100: 0.205757\n",
      "2023-12-01 15:29:19,971 INFO     Training average negative_sample_loss at step 2100: 0.180033\n",
      "2023-12-01 15:29:19,971 INFO     Training average loss at step 2100: 0.192895\n",
      "2023-12-01 15:29:25,429 INFO     Training average positive_sample_loss at step 2200: 0.196362\n",
      "2023-12-01 15:29:25,429 INFO     Training average negative_sample_loss at step 2200: 0.171268\n",
      "2023-12-01 15:29:25,429 INFO     Training average loss at step 2200: 0.183815\n",
      "2023-12-01 15:29:31,279 INFO     Training average positive_sample_loss at step 2300: 0.167301\n",
      "2023-12-01 15:29:31,280 INFO     Training average negative_sample_loss at step 2300: 0.159708\n",
      "2023-12-01 15:29:31,280 INFO     Training average loss at step 2300: 0.163504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:29:36,730 INFO     Training average positive_sample_loss at step 2400: 0.165104\n",
      "2023-12-01 15:29:36,731 INFO     Training average negative_sample_loss at step 2400: 0.146814\n",
      "2023-12-01 15:29:36,731 INFO     Training average loss at step 2400: 0.155959\n",
      "2023-12-01 15:29:42,177 INFO     Training average positive_sample_loss at step 2500: 0.164024\n",
      "2023-12-01 15:29:42,177 INFO     Training average negative_sample_loss at step 2500: 0.139276\n",
      "2023-12-01 15:29:42,177 INFO     Training average loss at step 2500: 0.151650\n",
      "2023-12-01 15:29:47,637 INFO     Training average positive_sample_loss at step 2600: 0.160081\n",
      "2023-12-01 15:29:47,637 INFO     Training average negative_sample_loss at step 2600: 0.132740\n",
      "2023-12-01 15:29:47,637 INFO     Training average loss at step 2600: 0.146410\n",
      "2023-12-01 15:29:53,089 INFO     Training average positive_sample_loss at step 2700: 0.154308\n",
      "2023-12-01 15:29:53,089 INFO     Training average negative_sample_loss at step 2700: 0.127006\n",
      "2023-12-01 15:29:53,089 INFO     Training average loss at step 2700: 0.140657\n",
      "2023-12-01 15:29:59,013 INFO     Training average positive_sample_loss at step 2800: 0.141176\n",
      "2023-12-01 15:29:59,014 INFO     Training average negative_sample_loss at step 2800: 0.121472\n",
      "2023-12-01 15:29:59,014 INFO     Training average loss at step 2800: 0.131324\n",
      "2023-12-01 15:30:04,494 INFO     Training average positive_sample_loss at step 2900: 0.127470\n",
      "2023-12-01 15:30:04,495 INFO     Training average negative_sample_loss at step 2900: 0.111729\n",
      "2023-12-01 15:30:04,495 INFO     Training average loss at step 2900: 0.119599\n",
      "2023-12-01 15:30:09,974 INFO     Training average positive_sample_loss at step 3000: 0.128668\n",
      "2023-12-01 15:30:09,974 INFO     Training average negative_sample_loss at step 3000: 0.105524\n",
      "2023-12-01 15:30:09,974 INFO     Training average loss at step 3000: 0.117096\n",
      "2023-12-01 15:30:15,472 INFO     Training average positive_sample_loss at step 3100: 0.125913\n",
      "2023-12-01 15:30:15,473 INFO     Training average negative_sample_loss at step 3100: 0.100519\n",
      "2023-12-01 15:30:15,473 INFO     Training average loss at step 3100: 0.113216\n",
      "2023-12-01 15:30:20,948 INFO     Training average positive_sample_loss at step 3200: 0.122308\n",
      "2023-12-01 15:30:20,948 INFO     Training average negative_sample_loss at step 3200: 0.095983\n",
      "2023-12-01 15:30:20,948 INFO     Training average loss at step 3200: 0.109146\n",
      "2023-12-01 15:30:26,417 INFO     Training average positive_sample_loss at step 3300: 0.118729\n",
      "2023-12-01 15:30:26,418 INFO     Training average negative_sample_loss at step 3300: 0.093006\n",
      "2023-12-01 15:30:26,418 INFO     Training average loss at step 3300: 0.105868\n",
      "2023-12-01 15:30:32,409 INFO     Training average positive_sample_loss at step 3400: 0.102645\n",
      "2023-12-01 15:30:32,409 INFO     Training average negative_sample_loss at step 3400: 0.087650\n",
      "2023-12-01 15:30:32,410 INFO     Training average loss at step 3400: 0.095148\n",
      "2023-12-01 15:30:37,830 INFO     Training average positive_sample_loss at step 3500: 0.102050\n",
      "2023-12-01 15:30:37,830 INFO     Training average negative_sample_loss at step 3500: 0.081850\n",
      "2023-12-01 15:30:37,830 INFO     Training average loss at step 3500: 0.091950\n",
      "2023-12-01 15:30:43,272 INFO     Training average positive_sample_loss at step 3600: 0.101346\n",
      "2023-12-01 15:30:43,272 INFO     Training average negative_sample_loss at step 3600: 0.077817\n",
      "2023-12-01 15:30:43,272 INFO     Training average loss at step 3600: 0.089582\n",
      "2023-12-01 15:30:48,728 INFO     Training average positive_sample_loss at step 3700: 0.098963\n",
      "2023-12-01 15:30:48,728 INFO     Training average negative_sample_loss at step 3700: 0.074593\n",
      "2023-12-01 15:30:48,728 INFO     Training average loss at step 3700: 0.086778\n",
      "2023-12-01 15:30:54,181 INFO     Training average positive_sample_loss at step 3800: 0.096522\n",
      "2023-12-01 15:30:54,182 INFO     Training average negative_sample_loss at step 3800: 0.072590\n",
      "2023-12-01 15:30:54,182 INFO     Training average loss at step 3800: 0.084556\n",
      "2023-12-01 15:31:00,185 INFO     Training average positive_sample_loss at step 3900: 0.090220\n",
      "2023-12-01 15:31:00,185 INFO     Training average negative_sample_loss at step 3900: 0.069535\n",
      "2023-12-01 15:31:00,185 INFO     Training average loss at step 3900: 0.079878\n",
      "2023-12-01 15:31:05,681 INFO     Training average positive_sample_loss at step 4000: 0.080893\n",
      "2023-12-01 15:31:05,681 INFO     Training average negative_sample_loss at step 4000: 0.065036\n",
      "2023-12-01 15:31:05,681 INFO     Training average loss at step 4000: 0.072965\n",
      "2023-12-01 15:31:11,131 INFO     Training average positive_sample_loss at step 4100: 0.081671\n",
      "2023-12-01 15:31:11,131 INFO     Training average negative_sample_loss at step 4100: 0.061206\n",
      "2023-12-01 15:31:11,131 INFO     Training average loss at step 4100: 0.071439\n",
      "2023-12-01 15:31:16,611 INFO     Training average positive_sample_loss at step 4200: 0.081351\n",
      "2023-12-01 15:31:16,611 INFO     Training average negative_sample_loss at step 4200: 0.059079\n",
      "2023-12-01 15:31:16,611 INFO     Training average loss at step 4200: 0.070215\n",
      "2023-12-01 15:31:22,065 INFO     Training average positive_sample_loss at step 4300: 0.079379\n",
      "2023-12-01 15:31:22,065 INFO     Training average negative_sample_loss at step 4300: 0.057177\n",
      "2023-12-01 15:31:22,065 INFO     Training average loss at step 4300: 0.068278\n",
      "2023-12-01 15:31:27,483 INFO     Training average positive_sample_loss at step 4400: 0.076939\n",
      "2023-12-01 15:31:27,483 INFO     Training average negative_sample_loss at step 4400: 0.055283\n",
      "2023-12-01 15:31:27,483 INFO     Training average loss at step 4400: 0.066111\n",
      "2023-12-01 15:31:33,495 INFO     Training average positive_sample_loss at step 4500: 0.068381\n",
      "2023-12-01 15:31:33,496 INFO     Training average negative_sample_loss at step 4500: 0.052834\n",
      "2023-12-01 15:31:33,496 INFO     Training average loss at step 4500: 0.060607\n",
      "2023-12-01 15:31:38,951 INFO     Training average positive_sample_loss at step 4600: 0.066709\n",
      "2023-12-01 15:31:38,951 INFO     Training average negative_sample_loss at step 4600: 0.049460\n",
      "2023-12-01 15:31:38,951 INFO     Training average loss at step 4600: 0.058084\n",
      "2023-12-01 15:31:44,393 INFO     Training average positive_sample_loss at step 4700: 0.066632\n",
      "2023-12-01 15:31:44,393 INFO     Training average negative_sample_loss at step 4700: 0.047306\n",
      "2023-12-01 15:31:44,393 INFO     Training average loss at step 4700: 0.056969\n",
      "2023-12-01 15:31:49,844 INFO     Training average positive_sample_loss at step 4800: 0.065712\n",
      "2023-12-01 15:31:49,845 INFO     Training average negative_sample_loss at step 4800: 0.045799\n",
      "2023-12-01 15:31:49,845 INFO     Training average loss at step 4800: 0.055755\n",
      "2023-12-01 15:31:55,310 INFO     Training average positive_sample_loss at step 4900: 0.064378\n",
      "2023-12-01 15:31:55,310 INFO     Training average negative_sample_loss at step 4900: 0.044530\n",
      "2023-12-01 15:31:55,310 INFO     Training average loss at step 4900: 0.054454\n",
      "2023-12-01 15:32:01,370 INFO     Training average positive_sample_loss at step 5000: 0.061159\n",
      "2023-12-01 15:32:01,370 INFO     Training average negative_sample_loss at step 5000: 0.042951\n",
      "2023-12-01 15:32:01,370 INFO     Training average loss at step 5000: 0.052055\n",
      "2023-12-01 15:32:06,825 INFO     Training average positive_sample_loss at step 5100: 0.054210\n",
      "2023-12-01 15:32:06,825 INFO     Training average negative_sample_loss at step 5100: 0.040527\n",
      "2023-12-01 15:32:06,825 INFO     Training average loss at step 5100: 0.047368\n",
      "2023-12-01 15:32:12,249 INFO     Training average positive_sample_loss at step 5200: 0.055204\n",
      "2023-12-01 15:32:12,250 INFO     Training average negative_sample_loss at step 5200: 0.038481\n",
      "2023-12-01 15:32:12,250 INFO     Training average loss at step 5200: 0.046842\n",
      "2023-12-01 15:32:17,668 INFO     Training average positive_sample_loss at step 5300: 0.054945\n",
      "2023-12-01 15:32:17,668 INFO     Training average negative_sample_loss at step 5300: 0.037137\n",
      "2023-12-01 15:32:17,668 INFO     Training average loss at step 5300: 0.046041\n",
      "2023-12-01 15:32:23,129 INFO     Training average positive_sample_loss at step 5400: 0.054010\n",
      "2023-12-01 15:32:23,130 INFO     Training average negative_sample_loss at step 5400: 0.036064\n",
      "2023-12-01 15:32:23,130 INFO     Training average loss at step 5400: 0.045037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:32:28,586 INFO     Training average positive_sample_loss at step 5500: 0.052589\n",
      "2023-12-01 15:32:28,586 INFO     Training average negative_sample_loss at step 5500: 0.035160\n",
      "2023-12-01 15:32:28,586 INFO     Training average loss at step 5500: 0.043875\n",
      "2023-12-01 15:32:34,626 INFO     Training average positive_sample_loss at step 5600: 0.047079\n",
      "2023-12-01 15:32:34,626 INFO     Training average negative_sample_loss at step 5600: 0.033770\n",
      "2023-12-01 15:32:34,626 INFO     Training average loss at step 5600: 0.040425\n",
      "2023-12-01 15:32:40,086 INFO     Training average positive_sample_loss at step 5700: 0.045637\n",
      "2023-12-01 15:32:40,086 INFO     Training average negative_sample_loss at step 5700: 0.031673\n",
      "2023-12-01 15:32:40,086 INFO     Training average loss at step 5700: 0.038655\n",
      "2023-12-01 15:32:45,559 INFO     Training average positive_sample_loss at step 5800: 0.046009\n",
      "2023-12-01 15:32:45,559 INFO     Training average negative_sample_loss at step 5800: 0.030411\n",
      "2023-12-01 15:32:45,559 INFO     Training average loss at step 5800: 0.038210\n",
      "2023-12-01 15:32:51,021 INFO     Training average positive_sample_loss at step 5900: 0.045941\n",
      "2023-12-01 15:32:51,021 INFO     Training average negative_sample_loss at step 5900: 0.029830\n",
      "2023-12-01 15:32:51,021 INFO     Training average loss at step 5900: 0.037886\n",
      "2023-12-01 15:32:56,479 INFO     Training average positive_sample_loss at step 6000: 0.045011\n",
      "2023-12-01 15:32:56,480 INFO     Training average negative_sample_loss at step 6000: 0.029007\n",
      "2023-12-01 15:32:56,480 INFO     Training average loss at step 6000: 0.037009\n",
      "2023-12-01 15:33:02,422 INFO     Training average positive_sample_loss at step 6100: 0.042995\n",
      "2023-12-01 15:33:02,423 INFO     Training average negative_sample_loss at step 6100: 0.028178\n",
      "2023-12-01 15:33:02,423 INFO     Training average loss at step 6100: 0.035587\n",
      "2023-12-01 15:33:07,904 INFO     Training average positive_sample_loss at step 6200: 0.037531\n",
      "2023-12-01 15:33:07,905 INFO     Training average negative_sample_loss at step 6200: 0.026602\n",
      "2023-12-01 15:33:07,905 INFO     Training average loss at step 6200: 0.032067\n",
      "2023-12-01 15:33:13,412 INFO     Training average positive_sample_loss at step 6300: 0.038762\n",
      "2023-12-01 15:33:13,412 INFO     Training average negative_sample_loss at step 6300: 0.025516\n",
      "2023-12-01 15:33:13,412 INFO     Training average loss at step 6300: 0.032139\n",
      "2023-12-01 15:33:18,912 INFO     Training average positive_sample_loss at step 6400: 0.038984\n",
      "2023-12-01 15:33:18,912 INFO     Training average negative_sample_loss at step 6400: 0.024730\n",
      "2023-12-01 15:33:18,912 INFO     Training average loss at step 6400: 0.031857\n",
      "2023-12-01 15:33:24,414 INFO     Training average positive_sample_loss at step 6500: 0.038496\n",
      "2023-12-01 15:33:24,415 INFO     Training average negative_sample_loss at step 6500: 0.024086\n",
      "2023-12-01 15:33:24,415 INFO     Training average loss at step 6500: 0.031291\n",
      "2023-12-01 15:33:29,898 INFO     Training average positive_sample_loss at step 6600: 0.037628\n",
      "2023-12-01 15:33:29,899 INFO     Training average negative_sample_loss at step 6600: 0.023645\n",
      "2023-12-01 15:33:29,899 INFO     Training average loss at step 6600: 0.030637\n",
      "2023-12-01 15:33:36,004 INFO     Training average positive_sample_loss at step 6700: 0.034026\n",
      "2023-12-01 15:33:36,004 INFO     Training average negative_sample_loss at step 6700: 0.022844\n",
      "2023-12-01 15:33:36,004 INFO     Training average loss at step 6700: 0.028435\n",
      "2023-12-01 15:33:41,426 INFO     Training average positive_sample_loss at step 6800: 0.032713\n",
      "2023-12-01 15:33:41,426 INFO     Training average negative_sample_loss at step 6800: 0.021595\n",
      "2023-12-01 15:33:41,426 INFO     Training average loss at step 6800: 0.027154\n",
      "2023-12-01 15:33:46,876 INFO     Training average positive_sample_loss at step 6900: 0.033342\n",
      "2023-12-01 15:33:46,877 INFO     Training average negative_sample_loss at step 6900: 0.020979\n",
      "2023-12-01 15:33:46,877 INFO     Training average loss at step 6900: 0.027160\n",
      "2023-12-01 15:33:52,336 INFO     Training average positive_sample_loss at step 7000: 0.032844\n",
      "2023-12-01 15:33:52,337 INFO     Training average negative_sample_loss at step 7000: 0.020325\n",
      "2023-12-01 15:33:52,337 INFO     Training average loss at step 7000: 0.026584\n",
      "2023-12-01 15:33:57,824 INFO     Training average positive_sample_loss at step 7100: 0.032396\n",
      "2023-12-01 15:33:57,824 INFO     Training average negative_sample_loss at step 7100: 0.019846\n",
      "2023-12-01 15:33:57,824 INFO     Training average loss at step 7100: 0.026121\n",
      "2023-12-01 15:34:03,287 INFO     Training average positive_sample_loss at step 7200: 0.031791\n",
      "2023-12-01 15:34:03,288 INFO     Training average negative_sample_loss at step 7200: 0.019572\n",
      "2023-12-01 15:34:03,288 INFO     Training average loss at step 7200: 0.025682\n",
      "2023-12-01 15:34:09,334 INFO     Training average positive_sample_loss at step 7300: 0.027445\n",
      "2023-12-01 15:34:09,335 INFO     Training average negative_sample_loss at step 7300: 0.018694\n",
      "2023-12-01 15:34:09,335 INFO     Training average loss at step 7300: 0.023069\n",
      "2023-12-01 15:34:14,759 INFO     Training average positive_sample_loss at step 7400: 0.028405\n",
      "2023-12-01 15:34:14,760 INFO     Training average negative_sample_loss at step 7400: 0.017855\n",
      "2023-12-01 15:34:14,760 INFO     Training average loss at step 7400: 0.023130\n",
      "2023-12-01 15:34:20,219 INFO     Training average positive_sample_loss at step 7500: 0.028768\n",
      "2023-12-01 15:34:20,220 INFO     Training average negative_sample_loss at step 7500: 0.017418\n",
      "2023-12-01 15:34:20,220 INFO     Training average loss at step 7500: 0.023093\n",
      "2023-12-01 15:34:25,700 INFO     Training average positive_sample_loss at step 7600: 0.028201\n",
      "2023-12-01 15:34:25,700 INFO     Training average negative_sample_loss at step 7600: 0.017022\n",
      "2023-12-01 15:34:25,700 INFO     Training average loss at step 7600: 0.022612\n",
      "2023-12-01 15:34:31,163 INFO     Training average positive_sample_loss at step 7700: 0.027942\n",
      "2023-12-01 15:34:31,163 INFO     Training average negative_sample_loss at step 7700: 0.016792\n",
      "2023-12-01 15:34:31,163 INFO     Training average loss at step 7700: 0.022367\n",
      "2023-12-01 15:34:37,140 INFO     Training average positive_sample_loss at step 7800: 0.025653\n",
      "2023-12-01 15:34:37,140 INFO     Training average negative_sample_loss at step 7800: 0.016404\n",
      "2023-12-01 15:34:37,140 INFO     Training average loss at step 7800: 0.021029\n",
      "2023-12-01 15:34:42,570 INFO     Training average positive_sample_loss at step 7900: 0.024373\n",
      "2023-12-01 15:34:42,570 INFO     Training average negative_sample_loss at step 7900: 0.015539\n",
      "2023-12-01 15:34:42,571 INFO     Training average loss at step 7900: 0.019956\n",
      "2023-12-01 15:34:48,029 INFO     Training average positive_sample_loss at step 8000: 0.025071\n",
      "2023-12-01 15:34:48,029 INFO     Training average negative_sample_loss at step 8000: 0.015290\n",
      "2023-12-01 15:34:48,029 INFO     Training average loss at step 8000: 0.020181\n",
      "2023-12-01 15:34:53,495 INFO     Training average positive_sample_loss at step 8100: 0.024927\n",
      "2023-12-01 15:34:53,496 INFO     Training average negative_sample_loss at step 8100: 0.014825\n",
      "2023-12-01 15:34:53,496 INFO     Training average loss at step 8100: 0.019876\n",
      "2023-12-01 15:34:59,001 INFO     Training average positive_sample_loss at step 8200: 0.024548\n",
      "2023-12-01 15:34:59,002 INFO     Training average negative_sample_loss at step 8200: 0.014737\n",
      "2023-12-01 15:34:59,002 INFO     Training average loss at step 8200: 0.019642\n",
      "2023-12-01 15:35:04,547 INFO     Training average positive_sample_loss at step 8300: 0.024081\n",
      "2023-12-01 15:35:04,548 INFO     Training average negative_sample_loss at step 8300: 0.014434\n",
      "2023-12-01 15:35:04,548 INFO     Training average loss at step 8300: 0.019257\n",
      "2023-12-01 15:35:10,556 INFO     Training average positive_sample_loss at step 8400: 0.021113\n",
      "2023-12-01 15:35:10,557 INFO     Training average negative_sample_loss at step 8400: 0.013830\n",
      "2023-12-01 15:35:10,557 INFO     Training average loss at step 8400: 0.017471\n",
      "2023-12-01 15:35:16,023 INFO     Training average positive_sample_loss at step 8500: 0.021848\n",
      "2023-12-01 15:35:16,023 INFO     Training average negative_sample_loss at step 8500: 0.013268\n",
      "2023-12-01 15:35:16,023 INFO     Training average loss at step 8500: 0.017558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:35:21,519 INFO     Training average positive_sample_loss at step 8600: 0.021888\n",
      "2023-12-01 15:35:21,519 INFO     Training average negative_sample_loss at step 8600: 0.013132\n",
      "2023-12-01 15:35:21,519 INFO     Training average loss at step 8600: 0.017510\n",
      "2023-12-01 15:35:26,993 INFO     Training average positive_sample_loss at step 8700: 0.021897\n",
      "2023-12-01 15:35:26,993 INFO     Training average negative_sample_loss at step 8700: 0.012955\n",
      "2023-12-01 15:35:26,993 INFO     Training average loss at step 8700: 0.017426\n",
      "2023-12-01 15:35:32,495 INFO     Training average positive_sample_loss at step 8800: 0.021700\n",
      "2023-12-01 15:35:32,496 INFO     Training average negative_sample_loss at step 8800: 0.012958\n",
      "2023-12-01 15:35:32,496 INFO     Training average loss at step 8800: 0.017329\n",
      "2023-12-01 15:35:38,551 INFO     Training average positive_sample_loss at step 8900: 0.020316\n",
      "2023-12-01 15:35:38,552 INFO     Training average negative_sample_loss at step 8900: 0.012735\n",
      "2023-12-01 15:35:38,552 INFO     Training average loss at step 8900: 0.016526\n",
      "2023-12-01 15:35:44,007 INFO     Training average positive_sample_loss at step 9000: 0.018904\n",
      "2023-12-01 15:35:44,007 INFO     Training average negative_sample_loss at step 9000: 0.011959\n",
      "2023-12-01 15:35:44,007 INFO     Training average loss at step 9000: 0.015432\n",
      "2023-12-01 15:35:49,455 INFO     Training average positive_sample_loss at step 9100: 0.019531\n",
      "2023-12-01 15:35:49,455 INFO     Training average negative_sample_loss at step 9100: 0.011690\n",
      "2023-12-01 15:35:49,455 INFO     Training average loss at step 9100: 0.015611\n",
      "2023-12-01 15:35:54,893 INFO     Training average positive_sample_loss at step 9200: 0.019601\n",
      "2023-12-01 15:35:54,894 INFO     Training average negative_sample_loss at step 9200: 0.011551\n",
      "2023-12-01 15:35:54,894 INFO     Training average loss at step 9200: 0.015576\n",
      "2023-12-01 15:36:00,328 INFO     Training average positive_sample_loss at step 9300: 0.019636\n",
      "2023-12-01 15:36:00,329 INFO     Training average negative_sample_loss at step 9300: 0.011601\n",
      "2023-12-01 15:36:00,329 INFO     Training average loss at step 9300: 0.015619\n",
      "2023-12-01 15:36:05,788 INFO     Training average positive_sample_loss at step 9400: 0.019218\n",
      "2023-12-01 15:36:05,789 INFO     Training average negative_sample_loss at step 9400: 0.011517\n",
      "2023-12-01 15:36:05,789 INFO     Training average loss at step 9400: 0.015367\n",
      "2023-12-01 15:36:11,738 INFO     Training average positive_sample_loss at step 9500: 0.017090\n",
      "2023-12-01 15:36:11,738 INFO     Training average negative_sample_loss at step 9500: 0.011136\n",
      "2023-12-01 15:36:11,738 INFO     Training average loss at step 9500: 0.014113\n",
      "2023-12-01 15:36:17,155 INFO     Training average positive_sample_loss at step 9600: 0.017304\n",
      "2023-12-01 15:36:17,156 INFO     Training average negative_sample_loss at step 9600: 0.010696\n",
      "2023-12-01 15:36:17,156 INFO     Training average loss at step 9600: 0.014000\n",
      "2023-12-01 15:36:22,556 INFO     Training average positive_sample_loss at step 9700: 0.017843\n",
      "2023-12-01 15:36:22,556 INFO     Training average negative_sample_loss at step 9700: 0.010601\n",
      "2023-12-01 15:36:22,556 INFO     Training average loss at step 9700: 0.014222\n",
      "2023-12-01 15:36:27,971 INFO     Training average positive_sample_loss at step 9800: 0.017643\n",
      "2023-12-01 15:36:27,971 INFO     Training average negative_sample_loss at step 9800: 0.010447\n",
      "2023-12-01 15:36:27,971 INFO     Training average loss at step 9800: 0.014045\n",
      "2023-12-01 15:36:33,390 INFO     Training average positive_sample_loss at step 9900: 0.017331\n",
      "2023-12-01 15:36:33,391 INFO     Training average negative_sample_loss at step 9900: 0.010361\n",
      "2023-12-01 15:36:33,391 INFO     Training average loss at step 9900: 0.013846\n",
      "2023-12-01 15:36:47,501 INFO     Training average positive_sample_loss at step 10000: 0.016569\n",
      "2023-12-01 15:36:47,502 INFO     Training average negative_sample_loss at step 10000: 0.010327\n",
      "2023-12-01 15:36:47,502 INFO     Training average loss at step 10000: 0.013448\n",
      "2023-12-01 15:36:47,502 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 15:36:48,709 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 15:37:25,979 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 15:37:32,750 INFO     Valid MRR at step 10000: 0.943736\n",
      "2023-12-01 15:37:32,751 INFO     Valid MR at step 10000: 524.307000\n",
      "2023-12-01 15:37:32,751 INFO     Valid HITS@1 at step 10000: 0.937500\n",
      "2023-12-01 15:37:32,751 INFO     Valid HITS@3 at step 10000: 0.948500\n",
      "2023-12-01 15:37:32,751 INFO     Valid HITS@10 at step 10000: 0.952700\n",
      "2023-12-01 15:37:38,221 INFO     Training average positive_sample_loss at step 10100: 0.015450\n",
      "2023-12-01 15:37:38,222 INFO     Training average negative_sample_loss at step 10100: 0.009928\n",
      "2023-12-01 15:37:38,222 INFO     Training average loss at step 10100: 0.012689\n",
      "2023-12-01 15:37:43,679 INFO     Training average positive_sample_loss at step 10200: 0.015998\n",
      "2023-12-01 15:37:43,680 INFO     Training average negative_sample_loss at step 10200: 0.009732\n",
      "2023-12-01 15:37:43,680 INFO     Training average loss at step 10200: 0.012865\n",
      "2023-12-01 15:37:49,132 INFO     Training average positive_sample_loss at step 10300: 0.016233\n",
      "2023-12-01 15:37:49,132 INFO     Training average negative_sample_loss at step 10300: 0.009744\n",
      "2023-12-01 15:37:49,132 INFO     Training average loss at step 10300: 0.012988\n",
      "2023-12-01 15:37:54,573 INFO     Training average positive_sample_loss at step 10400: 0.016099\n",
      "2023-12-01 15:37:54,573 INFO     Training average negative_sample_loss at step 10400: 0.009706\n",
      "2023-12-01 15:37:54,573 INFO     Training average loss at step 10400: 0.012903\n",
      "2023-12-01 15:37:59,995 INFO     Training average positive_sample_loss at step 10500: 0.015900\n",
      "2023-12-01 15:37:59,995 INFO     Training average negative_sample_loss at step 10500: 0.009534\n",
      "2023-12-01 15:37:59,995 INFO     Training average loss at step 10500: 0.012717\n",
      "2023-12-01 15:38:06,002 INFO     Training average positive_sample_loss at step 10600: 0.014277\n",
      "2023-12-01 15:38:06,003 INFO     Training average negative_sample_loss at step 10600: 0.009408\n",
      "2023-12-01 15:38:06,003 INFO     Training average loss at step 10600: 0.011843\n",
      "2023-12-01 15:38:11,458 INFO     Training average positive_sample_loss at step 10700: 0.014364\n",
      "2023-12-01 15:38:11,458 INFO     Training average negative_sample_loss at step 10700: 0.009195\n",
      "2023-12-01 15:38:11,458 INFO     Training average loss at step 10700: 0.011780\n",
      "2023-12-01 15:38:16,911 INFO     Training average positive_sample_loss at step 10800: 0.014962\n",
      "2023-12-01 15:38:16,911 INFO     Training average negative_sample_loss at step 10800: 0.009257\n",
      "2023-12-01 15:38:16,911 INFO     Training average loss at step 10800: 0.012110\n",
      "2023-12-01 15:38:22,381 INFO     Training average positive_sample_loss at step 10900: 0.014902\n",
      "2023-12-01 15:38:22,381 INFO     Training average negative_sample_loss at step 10900: 0.009276\n",
      "2023-12-01 15:38:22,381 INFO     Training average loss at step 10900: 0.012089\n",
      "2023-12-01 15:38:27,845 INFO     Training average positive_sample_loss at step 11000: 0.014833\n",
      "2023-12-01 15:38:27,845 INFO     Training average negative_sample_loss at step 11000: 0.009036\n",
      "2023-12-01 15:38:27,845 INFO     Training average loss at step 11000: 0.011935\n",
      "2023-12-01 15:38:33,819 INFO     Training average positive_sample_loss at step 11100: 0.014135\n",
      "2023-12-01 15:38:33,820 INFO     Training average negative_sample_loss at step 11100: 0.009135\n",
      "2023-12-01 15:38:33,820 INFO     Training average loss at step 11100: 0.011635\n",
      "2023-12-01 15:38:39,267 INFO     Training average positive_sample_loss at step 11200: 0.013046\n",
      "2023-12-01 15:38:39,267 INFO     Training average negative_sample_loss at step 11200: 0.008812\n",
      "2023-12-01 15:38:39,267 INFO     Training average loss at step 11200: 0.010929\n",
      "2023-12-01 15:38:44,701 INFO     Training average positive_sample_loss at step 11300: 0.013681\n",
      "2023-12-01 15:38:44,702 INFO     Training average negative_sample_loss at step 11300: 0.008597\n",
      "2023-12-01 15:38:44,702 INFO     Training average loss at step 11300: 0.011139\n",
      "2023-12-01 15:38:50,127 INFO     Training average positive_sample_loss at step 11400: 0.013863\n",
      "2023-12-01 15:38:50,127 INFO     Training average negative_sample_loss at step 11400: 0.008677\n",
      "2023-12-01 15:38:50,127 INFO     Training average loss at step 11400: 0.011270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:38:55,570 INFO     Training average positive_sample_loss at step 11500: 0.013776\n",
      "2023-12-01 15:38:55,570 INFO     Training average negative_sample_loss at step 11500: 0.008764\n",
      "2023-12-01 15:38:55,570 INFO     Training average loss at step 11500: 0.011270\n",
      "2023-12-01 15:39:01,006 INFO     Training average positive_sample_loss at step 11600: 0.013864\n",
      "2023-12-01 15:39:01,006 INFO     Training average negative_sample_loss at step 11600: 0.008491\n",
      "2023-12-01 15:39:01,006 INFO     Training average loss at step 11600: 0.011177\n",
      "2023-12-01 15:39:07,026 INFO     Training average positive_sample_loss at step 11700: 0.012394\n",
      "2023-12-01 15:39:07,026 INFO     Training average negative_sample_loss at step 11700: 0.008437\n",
      "2023-12-01 15:39:07,026 INFO     Training average loss at step 11700: 0.010415\n",
      "2023-12-01 15:39:12,456 INFO     Training average positive_sample_loss at step 11800: 0.012420\n",
      "2023-12-01 15:39:12,456 INFO     Training average negative_sample_loss at step 11800: 0.008074\n",
      "2023-12-01 15:39:12,456 INFO     Training average loss at step 11800: 0.010247\n",
      "2023-12-01 15:39:17,885 INFO     Training average positive_sample_loss at step 11900: 0.012834\n",
      "2023-12-01 15:39:17,886 INFO     Training average negative_sample_loss at step 11900: 0.008548\n",
      "2023-12-01 15:39:17,886 INFO     Training average loss at step 11900: 0.010691\n",
      "2023-12-01 15:39:23,279 INFO     Training average positive_sample_loss at step 12000: 0.013091\n",
      "2023-12-01 15:39:23,279 INFO     Training average negative_sample_loss at step 12000: 0.008199\n",
      "2023-12-01 15:39:23,279 INFO     Training average loss at step 12000: 0.010645\n",
      "2023-12-01 15:39:28,646 INFO     Training average positive_sample_loss at step 12100: 0.012943\n",
      "2023-12-01 15:39:28,647 INFO     Training average negative_sample_loss at step 12100: 0.008336\n",
      "2023-12-01 15:39:28,647 INFO     Training average loss at step 12100: 0.010639\n",
      "2023-12-01 15:39:34,581 INFO     Training average positive_sample_loss at step 12200: 0.012572\n",
      "2023-12-01 15:39:34,582 INFO     Training average negative_sample_loss at step 12200: 0.008478\n",
      "2023-12-01 15:39:34,582 INFO     Training average loss at step 12200: 0.010525\n",
      "2023-12-01 15:39:40,019 INFO     Training average positive_sample_loss at step 12300: 0.011440\n",
      "2023-12-01 15:39:40,020 INFO     Training average negative_sample_loss at step 12300: 0.007914\n",
      "2023-12-01 15:39:40,020 INFO     Training average loss at step 12300: 0.009677\n",
      "2023-12-01 15:39:45,464 INFO     Training average positive_sample_loss at step 12400: 0.012033\n",
      "2023-12-01 15:39:45,464 INFO     Training average negative_sample_loss at step 12400: 0.008132\n",
      "2023-12-01 15:39:45,465 INFO     Training average loss at step 12400: 0.010083\n",
      "2023-12-01 15:39:50,874 INFO     Training average positive_sample_loss at step 12500: 0.012138\n",
      "2023-12-01 15:39:50,874 INFO     Training average negative_sample_loss at step 12500: 0.008008\n",
      "2023-12-01 15:39:50,874 INFO     Training average loss at step 12500: 0.010073\n",
      "2023-12-01 15:39:56,302 INFO     Training average positive_sample_loss at step 12600: 0.012320\n",
      "2023-12-01 15:39:56,302 INFO     Training average negative_sample_loss at step 12600: 0.007969\n",
      "2023-12-01 15:39:56,302 INFO     Training average loss at step 12600: 0.010144\n",
      "2023-12-01 15:40:01,723 INFO     Training average positive_sample_loss at step 12700: 0.012128\n",
      "2023-12-01 15:40:01,723 INFO     Training average negative_sample_loss at step 12700: 0.007846\n",
      "2023-12-01 15:40:01,723 INFO     Training average loss at step 12700: 0.009987\n",
      "2023-12-01 15:40:07,806 INFO     Training average positive_sample_loss at step 12800: 0.011215\n",
      "2023-12-01 15:40:07,807 INFO     Training average negative_sample_loss at step 12800: 0.007891\n",
      "2023-12-01 15:40:07,807 INFO     Training average loss at step 12800: 0.009553\n",
      "2023-12-01 15:40:13,361 INFO     Training average positive_sample_loss at step 12900: 0.011058\n",
      "2023-12-01 15:40:13,362 INFO     Training average negative_sample_loss at step 12900: 0.007609\n",
      "2023-12-01 15:40:13,362 INFO     Training average loss at step 12900: 0.009334\n",
      "2023-12-01 15:40:18,837 INFO     Training average positive_sample_loss at step 13000: 0.011606\n",
      "2023-12-01 15:40:18,837 INFO     Training average negative_sample_loss at step 13000: 0.007719\n",
      "2023-12-01 15:40:18,837 INFO     Training average loss at step 13000: 0.009663\n",
      "2023-12-01 15:40:24,310 INFO     Training average positive_sample_loss at step 13100: 0.011683\n",
      "2023-12-01 15:40:24,311 INFO     Training average negative_sample_loss at step 13100: 0.007704\n",
      "2023-12-01 15:40:24,311 INFO     Training average loss at step 13100: 0.009694\n",
      "2023-12-01 15:40:29,767 INFO     Training average positive_sample_loss at step 13200: 0.011540\n",
      "2023-12-01 15:40:29,767 INFO     Training average negative_sample_loss at step 13200: 0.008016\n",
      "2023-12-01 15:40:29,767 INFO     Training average loss at step 13200: 0.009778\n",
      "2023-12-01 15:40:35,786 INFO     Training average positive_sample_loss at step 13300: 0.011475\n",
      "2023-12-01 15:40:35,786 INFO     Training average negative_sample_loss at step 13300: 0.007825\n",
      "2023-12-01 15:40:35,786 INFO     Training average loss at step 13300: 0.009650\n",
      "2023-12-01 15:40:41,272 INFO     Training average positive_sample_loss at step 13400: 0.010243\n",
      "2023-12-01 15:40:41,273 INFO     Training average negative_sample_loss at step 13400: 0.007547\n",
      "2023-12-01 15:40:41,273 INFO     Training average loss at step 13400: 0.008895\n",
      "2023-12-01 15:40:46,714 INFO     Training average positive_sample_loss at step 13500: 0.010802\n",
      "2023-12-01 15:40:46,714 INFO     Training average negative_sample_loss at step 13500: 0.007560\n",
      "2023-12-01 15:40:46,714 INFO     Training average loss at step 13500: 0.009181\n",
      "2023-12-01 15:40:52,205 INFO     Training average positive_sample_loss at step 13600: 0.011100\n",
      "2023-12-01 15:40:52,205 INFO     Training average negative_sample_loss at step 13600: 0.007742\n",
      "2023-12-01 15:40:52,205 INFO     Training average loss at step 13600: 0.009421\n",
      "2023-12-01 15:40:57,695 INFO     Training average positive_sample_loss at step 13700: 0.011153\n",
      "2023-12-01 15:40:57,695 INFO     Training average negative_sample_loss at step 13700: 0.007409\n",
      "2023-12-01 15:40:57,695 INFO     Training average loss at step 13700: 0.009281\n",
      "2023-12-01 15:41:03,160 INFO     Training average positive_sample_loss at step 13800: 0.011001\n",
      "2023-12-01 15:41:03,160 INFO     Training average negative_sample_loss at step 13800: 0.007590\n",
      "2023-12-01 15:41:03,160 INFO     Training average loss at step 13800: 0.009296\n",
      "2023-12-01 15:41:09,169 INFO     Training average positive_sample_loss at step 13900: 0.010380\n",
      "2023-12-01 15:41:09,169 INFO     Training average negative_sample_loss at step 13900: 0.007555\n",
      "2023-12-01 15:41:09,169 INFO     Training average loss at step 13900: 0.008968\n",
      "2023-12-01 15:41:14,590 INFO     Training average positive_sample_loss at step 14000: 0.010175\n",
      "2023-12-01 15:41:14,590 INFO     Training average negative_sample_loss at step 14000: 0.007472\n",
      "2023-12-01 15:41:14,591 INFO     Training average loss at step 14000: 0.008823\n",
      "2023-12-01 15:41:20,046 INFO     Training average positive_sample_loss at step 14100: 0.010423\n",
      "2023-12-01 15:41:20,046 INFO     Training average negative_sample_loss at step 14100: 0.007485\n",
      "2023-12-01 15:41:20,046 INFO     Training average loss at step 14100: 0.008954\n",
      "2023-12-01 15:41:25,473 INFO     Training average positive_sample_loss at step 14200: 0.010785\n",
      "2023-12-01 15:41:25,474 INFO     Training average negative_sample_loss at step 14200: 0.007392\n",
      "2023-12-01 15:41:25,474 INFO     Training average loss at step 14200: 0.009089\n",
      "2023-12-01 15:41:30,924 INFO     Training average positive_sample_loss at step 14300: 0.010783\n",
      "2023-12-01 15:41:30,924 INFO     Training average negative_sample_loss at step 14300: 0.007832\n",
      "2023-12-01 15:41:30,924 INFO     Training average loss at step 14300: 0.009308\n",
      "2023-12-01 15:41:36,461 INFO     Training average positive_sample_loss at step 14400: 0.010626\n",
      "2023-12-01 15:41:36,461 INFO     Training average negative_sample_loss at step 14400: 0.007676\n",
      "2023-12-01 15:41:36,461 INFO     Training average loss at step 14400: 0.009151\n",
      "2023-12-01 15:41:42,515 INFO     Training average positive_sample_loss at step 14500: 0.009526\n",
      "2023-12-01 15:41:42,515 INFO     Training average negative_sample_loss at step 14500: 0.007527\n",
      "2023-12-01 15:41:42,515 INFO     Training average loss at step 14500: 0.008527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:41:48,020 INFO     Training average positive_sample_loss at step 14600: 0.010022\n",
      "2023-12-01 15:41:48,021 INFO     Training average negative_sample_loss at step 14600: 0.007263\n",
      "2023-12-01 15:41:48,021 INFO     Training average loss at step 14600: 0.008642\n",
      "2023-12-01 15:41:53,508 INFO     Training average positive_sample_loss at step 14700: 0.010260\n",
      "2023-12-01 15:41:53,508 INFO     Training average negative_sample_loss at step 14700: 0.007058\n",
      "2023-12-01 15:41:53,508 INFO     Training average loss at step 14700: 0.008659\n",
      "2023-12-01 15:41:59,005 INFO     Training average positive_sample_loss at step 14800: 0.010395\n",
      "2023-12-01 15:41:59,006 INFO     Training average negative_sample_loss at step 14800: 0.007804\n",
      "2023-12-01 15:41:59,006 INFO     Training average loss at step 14800: 0.009100\n",
      "2023-12-01 15:42:04,496 INFO     Training average positive_sample_loss at step 14900: 0.010286\n",
      "2023-12-01 15:42:04,496 INFO     Training average negative_sample_loss at step 14900: 0.007297\n",
      "2023-12-01 15:42:04,496 INFO     Training average loss at step 14900: 0.008792\n",
      "2023-12-01 15:42:10,531 INFO     Training average positive_sample_loss at step 15000: 0.009518\n",
      "2023-12-01 15:42:10,532 INFO     Training average negative_sample_loss at step 15000: 0.007017\n",
      "2023-12-01 15:42:10,532 INFO     Training average loss at step 15000: 0.008267\n",
      "2023-12-01 15:42:15,954 INFO     Training average positive_sample_loss at step 15100: 0.009348\n",
      "2023-12-01 15:42:15,954 INFO     Training average negative_sample_loss at step 15100: 0.007558\n",
      "2023-12-01 15:42:15,955 INFO     Training average loss at step 15100: 0.008453\n",
      "2023-12-01 15:42:21,398 INFO     Training average positive_sample_loss at step 15200: 0.009733\n",
      "2023-12-01 15:42:21,399 INFO     Training average negative_sample_loss at step 15200: 0.007107\n",
      "2023-12-01 15:42:21,399 INFO     Training average loss at step 15200: 0.008420\n",
      "2023-12-01 15:42:26,878 INFO     Training average positive_sample_loss at step 15300: 0.009987\n",
      "2023-12-01 15:42:26,878 INFO     Training average negative_sample_loss at step 15300: 0.007701\n",
      "2023-12-01 15:42:26,878 INFO     Training average loss at step 15300: 0.008844\n",
      "2023-12-01 15:42:32,377 INFO     Training average positive_sample_loss at step 15400: 0.010139\n",
      "2023-12-01 15:42:32,378 INFO     Training average negative_sample_loss at step 15400: 0.007398\n",
      "2023-12-01 15:42:32,378 INFO     Training average loss at step 15400: 0.008769\n",
      "2023-12-01 15:42:37,902 INFO     Training average positive_sample_loss at step 15500: 0.009994\n",
      "2023-12-01 15:42:37,902 INFO     Training average negative_sample_loss at step 15500: 0.007213\n",
      "2023-12-01 15:42:37,902 INFO     Training average loss at step 15500: 0.008603\n",
      "2023-12-01 15:42:43,888 INFO     Training average positive_sample_loss at step 15600: 0.008915\n",
      "2023-12-01 15:42:43,888 INFO     Training average negative_sample_loss at step 15600: 0.007318\n",
      "2023-12-01 15:42:43,888 INFO     Training average loss at step 15600: 0.008116\n",
      "2023-12-01 15:42:49,332 INFO     Training average positive_sample_loss at step 15700: 0.009271\n",
      "2023-12-01 15:42:49,333 INFO     Training average negative_sample_loss at step 15700: 0.007242\n",
      "2023-12-01 15:42:49,333 INFO     Training average loss at step 15700: 0.008256\n",
      "2023-12-01 15:42:54,800 INFO     Training average positive_sample_loss at step 15800: 0.009563\n",
      "2023-12-01 15:42:54,800 INFO     Training average negative_sample_loss at step 15800: 0.007191\n",
      "2023-12-01 15:42:54,800 INFO     Training average loss at step 15800: 0.008377\n",
      "2023-12-01 15:43:00,277 INFO     Training average positive_sample_loss at step 15900: 0.009760\n",
      "2023-12-01 15:43:00,277 INFO     Training average negative_sample_loss at step 15900: 0.007370\n",
      "2023-12-01 15:43:00,277 INFO     Training average loss at step 15900: 0.008565\n",
      "2023-12-01 15:43:05,735 INFO     Training average positive_sample_loss at step 16000: 0.009706\n",
      "2023-12-01 15:43:05,735 INFO     Training average negative_sample_loss at step 16000: 0.007406\n",
      "2023-12-01 15:43:05,735 INFO     Training average loss at step 16000: 0.008556\n",
      "2023-12-01 15:43:11,717 INFO     Training average positive_sample_loss at step 16100: 0.009238\n",
      "2023-12-01 15:43:11,717 INFO     Training average negative_sample_loss at step 16100: 0.007618\n",
      "2023-12-01 15:43:11,717 INFO     Training average loss at step 16100: 0.008428\n",
      "2023-12-01 15:43:17,156 INFO     Training average positive_sample_loss at step 16200: 0.008861\n",
      "2023-12-01 15:43:17,156 INFO     Training average negative_sample_loss at step 16200: 0.007702\n",
      "2023-12-01 15:43:17,156 INFO     Training average loss at step 16200: 0.008282\n",
      "2023-12-01 15:43:22,583 INFO     Training average positive_sample_loss at step 16300: 0.009329\n",
      "2023-12-01 15:43:22,583 INFO     Training average negative_sample_loss at step 16300: 0.007095\n",
      "2023-12-01 15:43:22,584 INFO     Training average loss at step 16300: 0.008212\n",
      "2023-12-01 15:43:27,977 INFO     Training average positive_sample_loss at step 16400: 0.009476\n",
      "2023-12-01 15:43:27,978 INFO     Training average negative_sample_loss at step 16400: 0.007441\n",
      "2023-12-01 15:43:27,978 INFO     Training average loss at step 16400: 0.008459\n",
      "2023-12-01 15:43:33,367 INFO     Training average positive_sample_loss at step 16500: 0.009549\n",
      "2023-12-01 15:43:33,367 INFO     Training average negative_sample_loss at step 16500: 0.007331\n",
      "2023-12-01 15:43:33,367 INFO     Training average loss at step 16500: 0.008440\n",
      "2023-12-01 15:43:38,787 INFO     Training average positive_sample_loss at step 16600: 0.009448\n",
      "2023-12-01 15:43:38,788 INFO     Training average negative_sample_loss at step 16600: 0.007568\n",
      "2023-12-01 15:43:38,788 INFO     Training average loss at step 16600: 0.008508\n",
      "2023-12-01 15:43:44,739 INFO     Training average positive_sample_loss at step 16700: 0.008552\n",
      "2023-12-01 15:43:44,740 INFO     Training average negative_sample_loss at step 16700: 0.007332\n",
      "2023-12-01 15:43:44,740 INFO     Training average loss at step 16700: 0.007942\n",
      "2023-12-01 15:43:50,234 INFO     Training average positive_sample_loss at step 16800: 0.008811\n",
      "2023-12-01 15:43:50,235 INFO     Training average negative_sample_loss at step 16800: 0.007135\n",
      "2023-12-01 15:43:50,235 INFO     Training average loss at step 16800: 0.007973\n",
      "2023-12-01 15:43:55,690 INFO     Training average positive_sample_loss at step 16900: 0.009195\n",
      "2023-12-01 15:43:55,690 INFO     Training average negative_sample_loss at step 16900: 0.007220\n",
      "2023-12-01 15:43:55,691 INFO     Training average loss at step 16900: 0.008208\n",
      "2023-12-01 15:44:01,135 INFO     Training average positive_sample_loss at step 17000: 0.009320\n",
      "2023-12-01 15:44:01,136 INFO     Training average negative_sample_loss at step 17000: 0.007252\n",
      "2023-12-01 15:44:01,136 INFO     Training average loss at step 17000: 0.008286\n",
      "2023-12-01 15:44:06,605 INFO     Training average positive_sample_loss at step 17100: 0.009312\n",
      "2023-12-01 15:44:06,605 INFO     Training average negative_sample_loss at step 17100: 0.007149\n",
      "2023-12-01 15:44:06,605 INFO     Training average loss at step 17100: 0.008231\n",
      "2023-12-01 15:44:12,637 INFO     Training average positive_sample_loss at step 17200: 0.008866\n",
      "2023-12-01 15:44:12,637 INFO     Training average negative_sample_loss at step 17200: 0.007323\n",
      "2023-12-01 15:44:12,637 INFO     Training average loss at step 17200: 0.008094\n",
      "2023-12-01 15:44:18,112 INFO     Training average positive_sample_loss at step 17300: 0.008332\n",
      "2023-12-01 15:44:18,112 INFO     Training average negative_sample_loss at step 17300: 0.006858\n",
      "2023-12-01 15:44:18,112 INFO     Training average loss at step 17300: 0.007595\n",
      "2023-12-01 15:44:23,572 INFO     Training average positive_sample_loss at step 17400: 0.008753\n",
      "2023-12-01 15:44:23,573 INFO     Training average negative_sample_loss at step 17400: 0.007702\n",
      "2023-12-01 15:44:23,573 INFO     Training average loss at step 17400: 0.008227\n",
      "2023-12-01 15:44:29,024 INFO     Training average positive_sample_loss at step 17500: 0.009125\n",
      "2023-12-01 15:44:29,025 INFO     Training average negative_sample_loss at step 17500: 0.007301\n",
      "2023-12-01 15:44:29,025 INFO     Training average loss at step 17500: 0.008213\n",
      "2023-12-01 15:44:34,490 INFO     Training average positive_sample_loss at step 17600: 0.009035\n",
      "2023-12-01 15:44:34,490 INFO     Training average negative_sample_loss at step 17600: 0.007248\n",
      "2023-12-01 15:44:34,490 INFO     Training average loss at step 17600: 0.008141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:44:39,946 INFO     Training average positive_sample_loss at step 17700: 0.009060\n",
      "2023-12-01 15:44:39,947 INFO     Training average negative_sample_loss at step 17700: 0.006771\n",
      "2023-12-01 15:44:39,947 INFO     Training average loss at step 17700: 0.007916\n",
      "2023-12-01 15:44:45,893 INFO     Training average positive_sample_loss at step 17800: 0.008243\n",
      "2023-12-01 15:44:45,893 INFO     Training average negative_sample_loss at step 17800: 0.007268\n",
      "2023-12-01 15:44:45,894 INFO     Training average loss at step 17800: 0.007756\n",
      "2023-12-01 15:44:51,323 INFO     Training average positive_sample_loss at step 17900: 0.008404\n",
      "2023-12-01 15:44:51,323 INFO     Training average negative_sample_loss at step 17900: 0.007052\n",
      "2023-12-01 15:44:51,323 INFO     Training average loss at step 17900: 0.007728\n",
      "2023-12-01 15:44:56,793 INFO     Training average positive_sample_loss at step 18000: 0.008847\n",
      "2023-12-01 15:44:56,793 INFO     Training average negative_sample_loss at step 18000: 0.007110\n",
      "2023-12-01 15:44:56,793 INFO     Training average loss at step 18000: 0.007979\n",
      "2023-12-01 15:45:02,278 INFO     Training average positive_sample_loss at step 18100: 0.008931\n",
      "2023-12-01 15:45:02,278 INFO     Training average negative_sample_loss at step 18100: 0.007524\n",
      "2023-12-01 15:45:02,278 INFO     Training average loss at step 18100: 0.008227\n",
      "2023-12-01 15:45:07,768 INFO     Training average positive_sample_loss at step 18200: 0.008977\n",
      "2023-12-01 15:45:07,768 INFO     Training average negative_sample_loss at step 18200: 0.007131\n",
      "2023-12-01 15:45:07,768 INFO     Training average loss at step 18200: 0.008054\n",
      "2023-12-01 15:45:13,800 INFO     Training average positive_sample_loss at step 18300: 0.008693\n",
      "2023-12-01 15:45:13,801 INFO     Training average negative_sample_loss at step 18300: 0.007201\n",
      "2023-12-01 15:45:13,801 INFO     Training average loss at step 18300: 0.007947\n",
      "2023-12-01 15:45:19,270 INFO     Training average positive_sample_loss at step 18400: 0.008026\n",
      "2023-12-01 15:45:19,271 INFO     Training average negative_sample_loss at step 18400: 0.007018\n",
      "2023-12-01 15:45:19,271 INFO     Training average loss at step 18400: 0.007522\n",
      "2023-12-01 15:45:24,729 INFO     Training average positive_sample_loss at step 18500: 0.008397\n",
      "2023-12-01 15:45:24,730 INFO     Training average negative_sample_loss at step 18500: 0.006837\n",
      "2023-12-01 15:45:24,730 INFO     Training average loss at step 18500: 0.007617\n",
      "2023-12-01 15:45:30,238 INFO     Training average positive_sample_loss at step 18600: 0.008705\n",
      "2023-12-01 15:45:30,239 INFO     Training average negative_sample_loss at step 18600: 0.007859\n",
      "2023-12-01 15:45:30,239 INFO     Training average loss at step 18600: 0.008282\n",
      "2023-12-01 15:45:35,705 INFO     Training average positive_sample_loss at step 18700: 0.008778\n",
      "2023-12-01 15:45:35,706 INFO     Training average negative_sample_loss at step 18700: 0.007588\n",
      "2023-12-01 15:45:35,706 INFO     Training average loss at step 18700: 0.008183\n",
      "2023-12-01 15:45:41,155 INFO     Training average positive_sample_loss at step 18800: 0.008756\n",
      "2023-12-01 15:45:41,155 INFO     Training average negative_sample_loss at step 18800: 0.007029\n",
      "2023-12-01 15:45:41,155 INFO     Training average loss at step 18800: 0.007893\n",
      "2023-12-01 15:45:47,141 INFO     Training average positive_sample_loss at step 18900: 0.008108\n",
      "2023-12-01 15:45:47,142 INFO     Training average negative_sample_loss at step 18900: 0.007579\n",
      "2023-12-01 15:45:47,142 INFO     Training average loss at step 18900: 0.007844\n",
      "2023-12-01 15:45:52,637 INFO     Training average positive_sample_loss at step 19000: 0.008172\n",
      "2023-12-01 15:45:52,638 INFO     Training average negative_sample_loss at step 19000: 0.007148\n",
      "2023-12-01 15:45:52,638 INFO     Training average loss at step 19000: 0.007660\n",
      "2023-12-01 15:45:58,162 INFO     Training average positive_sample_loss at step 19100: 0.008451\n",
      "2023-12-01 15:45:58,162 INFO     Training average negative_sample_loss at step 19100: 0.007391\n",
      "2023-12-01 15:45:58,162 INFO     Training average loss at step 19100: 0.007921\n",
      "2023-12-01 15:46:03,624 INFO     Training average positive_sample_loss at step 19200: 0.008695\n",
      "2023-12-01 15:46:03,624 INFO     Training average negative_sample_loss at step 19200: 0.006915\n",
      "2023-12-01 15:46:03,624 INFO     Training average loss at step 19200: 0.007805\n",
      "2023-12-01 15:46:09,093 INFO     Training average positive_sample_loss at step 19300: 0.008626\n",
      "2023-12-01 15:46:09,093 INFO     Training average negative_sample_loss at step 19300: 0.007190\n",
      "2023-12-01 15:46:09,093 INFO     Training average loss at step 19300: 0.007908\n",
      "2023-12-01 15:46:15,108 INFO     Training average positive_sample_loss at step 19400: 0.008529\n",
      "2023-12-01 15:46:15,108 INFO     Training average negative_sample_loss at step 19400: 0.007900\n",
      "2023-12-01 15:46:15,108 INFO     Training average loss at step 19400: 0.008214\n",
      "2023-12-01 15:46:20,563 INFO     Training average positive_sample_loss at step 19500: 0.007748\n",
      "2023-12-01 15:46:20,563 INFO     Training average negative_sample_loss at step 19500: 0.007358\n",
      "2023-12-01 15:46:20,564 INFO     Training average loss at step 19500: 0.007553\n",
      "2023-12-01 15:46:26,046 INFO     Training average positive_sample_loss at step 19600: 0.008261\n",
      "2023-12-01 15:46:26,046 INFO     Training average negative_sample_loss at step 19600: 0.007137\n",
      "2023-12-01 15:46:26,046 INFO     Training average loss at step 19600: 0.007699\n",
      "2023-12-01 15:46:31,526 INFO     Training average positive_sample_loss at step 19700: 0.008394\n",
      "2023-12-01 15:46:31,526 INFO     Training average negative_sample_loss at step 19700: 0.007212\n",
      "2023-12-01 15:46:31,526 INFO     Training average loss at step 19700: 0.007803\n",
      "2023-12-01 15:46:36,999 INFO     Training average positive_sample_loss at step 19800: 0.008711\n",
      "2023-12-01 15:46:37,000 INFO     Training average negative_sample_loss at step 19800: 0.007088\n",
      "2023-12-01 15:46:37,000 INFO     Training average loss at step 19800: 0.007900\n",
      "2023-12-01 15:46:42,471 INFO     Training average positive_sample_loss at step 19900: 0.008506\n",
      "2023-12-01 15:46:42,472 INFO     Training average negative_sample_loss at step 19900: 0.007329\n",
      "2023-12-01 15:46:42,472 INFO     Training average loss at step 19900: 0.007918\n",
      "2023-12-01 15:47:02,133 INFO     Training average positive_sample_loss at step 20000: 0.007930\n",
      "2023-12-01 15:47:02,133 INFO     Training average negative_sample_loss at step 20000: 0.007327\n",
      "2023-12-01 15:47:02,133 INFO     Training average loss at step 20000: 0.007628\n",
      "2023-12-01 15:47:02,133 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 15:47:02,821 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 15:47:39,172 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 15:47:47,956 INFO     Valid MRR at step 20000: 0.947979\n",
      "2023-12-01 15:47:47,957 INFO     Valid MR at step 20000: 397.128900\n",
      "2023-12-01 15:47:47,957 INFO     Valid HITS@1 at step 20000: 0.942800\n",
      "2023-12-01 15:47:47,957 INFO     Valid HITS@3 at step 20000: 0.951100\n",
      "2023-12-01 15:47:47,957 INFO     Valid HITS@10 at step 20000: 0.956700\n",
      "2023-12-01 15:47:53,410 INFO     Training average positive_sample_loss at step 20100: 0.007819\n",
      "2023-12-01 15:47:53,411 INFO     Training average negative_sample_loss at step 20100: 0.007390\n",
      "2023-12-01 15:47:53,411 INFO     Training average loss at step 20100: 0.007604\n",
      "2023-12-01 15:47:58,859 INFO     Training average positive_sample_loss at step 20200: 0.008194\n",
      "2023-12-01 15:47:58,860 INFO     Training average negative_sample_loss at step 20200: 0.006977\n",
      "2023-12-01 15:47:58,860 INFO     Training average loss at step 20200: 0.007585\n",
      "2023-12-01 15:48:04,303 INFO     Training average positive_sample_loss at step 20300: 0.008428\n",
      "2023-12-01 15:48:04,304 INFO     Training average negative_sample_loss at step 20300: 0.006932\n",
      "2023-12-01 15:48:04,304 INFO     Training average loss at step 20300: 0.007680\n",
      "2023-12-01 15:48:09,750 INFO     Training average positive_sample_loss at step 20400: 0.008473\n",
      "2023-12-01 15:48:09,750 INFO     Training average negative_sample_loss at step 20400: 0.007472\n",
      "2023-12-01 15:48:09,750 INFO     Training average loss at step 20400: 0.007973\n",
      "2023-12-01 15:48:15,816 INFO     Training average positive_sample_loss at step 20500: 0.008323\n",
      "2023-12-01 15:48:15,817 INFO     Training average negative_sample_loss at step 20500: 0.007119\n",
      "2023-12-01 15:48:15,817 INFO     Training average loss at step 20500: 0.007721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:48:21,239 INFO     Training average positive_sample_loss at step 20600: 0.007513\n",
      "2023-12-01 15:48:21,240 INFO     Training average negative_sample_loss at step 20600: 0.007425\n",
      "2023-12-01 15:48:21,240 INFO     Training average loss at step 20600: 0.007469\n",
      "2023-12-01 15:48:26,654 INFO     Training average positive_sample_loss at step 20700: 0.007900\n",
      "2023-12-01 15:48:26,654 INFO     Training average negative_sample_loss at step 20700: 0.007554\n",
      "2023-12-01 15:48:26,654 INFO     Training average loss at step 20700: 0.007727\n",
      "2023-12-01 15:48:32,108 INFO     Training average positive_sample_loss at step 20800: 0.008133\n",
      "2023-12-01 15:48:32,109 INFO     Training average negative_sample_loss at step 20800: 0.007186\n",
      "2023-12-01 15:48:32,109 INFO     Training average loss at step 20800: 0.007659\n",
      "2023-12-01 15:48:37,577 INFO     Training average positive_sample_loss at step 20900: 0.008300\n",
      "2023-12-01 15:48:37,577 INFO     Training average negative_sample_loss at step 20900: 0.007099\n",
      "2023-12-01 15:48:37,577 INFO     Training average loss at step 20900: 0.007700\n",
      "2023-12-01 15:48:43,031 INFO     Training average positive_sample_loss at step 21000: 0.008325\n",
      "2023-12-01 15:48:43,031 INFO     Training average negative_sample_loss at step 21000: 0.007562\n",
      "2023-12-01 15:48:43,031 INFO     Training average loss at step 21000: 0.007944\n",
      "2023-12-01 15:48:49,062 INFO     Training average positive_sample_loss at step 21100: 0.007860\n",
      "2023-12-01 15:48:49,062 INFO     Training average negative_sample_loss at step 21100: 0.007268\n",
      "2023-12-01 15:48:49,062 INFO     Training average loss at step 21100: 0.007564\n",
      "2023-12-01 15:48:54,522 INFO     Training average positive_sample_loss at step 21200: 0.007613\n",
      "2023-12-01 15:48:54,522 INFO     Training average negative_sample_loss at step 21200: 0.007398\n",
      "2023-12-01 15:48:54,523 INFO     Training average loss at step 21200: 0.007506\n",
      "2023-12-01 15:48:59,992 INFO     Training average positive_sample_loss at step 21300: 0.008016\n",
      "2023-12-01 15:48:59,992 INFO     Training average negative_sample_loss at step 21300: 0.007795\n",
      "2023-12-01 15:48:59,992 INFO     Training average loss at step 21300: 0.007906\n",
      "2023-12-01 15:49:05,460 INFO     Training average positive_sample_loss at step 21400: 0.008162\n",
      "2023-12-01 15:49:05,461 INFO     Training average negative_sample_loss at step 21400: 0.007034\n",
      "2023-12-01 15:49:05,461 INFO     Training average loss at step 21400: 0.007598\n",
      "2023-12-01 15:49:10,927 INFO     Training average positive_sample_loss at step 21500: 0.008258\n",
      "2023-12-01 15:49:10,927 INFO     Training average negative_sample_loss at step 21500: 0.007397\n",
      "2023-12-01 15:49:10,927 INFO     Training average loss at step 21500: 0.007827\n",
      "2023-12-01 15:49:16,444 INFO     Training average positive_sample_loss at step 21600: 0.008214\n",
      "2023-12-01 15:49:16,444 INFO     Training average negative_sample_loss at step 21600: 0.006902\n",
      "2023-12-01 15:49:16,444 INFO     Training average loss at step 21600: 0.007558\n",
      "2023-12-01 15:49:22,434 INFO     Training average positive_sample_loss at step 21700: 0.007359\n",
      "2023-12-01 15:49:22,435 INFO     Training average negative_sample_loss at step 21700: 0.007372\n",
      "2023-12-01 15:49:22,435 INFO     Training average loss at step 21700: 0.007365\n",
      "2023-12-01 15:49:27,903 INFO     Training average positive_sample_loss at step 21800: 0.007815\n",
      "2023-12-01 15:49:27,904 INFO     Training average negative_sample_loss at step 21800: 0.007203\n",
      "2023-12-01 15:49:27,904 INFO     Training average loss at step 21800: 0.007509\n",
      "2023-12-01 15:49:33,373 INFO     Training average positive_sample_loss at step 21900: 0.008060\n",
      "2023-12-01 15:49:33,373 INFO     Training average negative_sample_loss at step 21900: 0.007275\n",
      "2023-12-01 15:49:33,373 INFO     Training average loss at step 21900: 0.007668\n",
      "2023-12-01 15:49:38,881 INFO     Training average positive_sample_loss at step 22000: 0.008206\n",
      "2023-12-01 15:49:38,882 INFO     Training average negative_sample_loss at step 22000: 0.007185\n",
      "2023-12-01 15:49:38,882 INFO     Training average loss at step 22000: 0.007695\n",
      "2023-12-01 15:49:44,351 INFO     Training average positive_sample_loss at step 22100: 0.008076\n",
      "2023-12-01 15:49:44,352 INFO     Training average negative_sample_loss at step 22100: 0.006788\n",
      "2023-12-01 15:49:44,352 INFO     Training average loss at step 22100: 0.007432\n",
      "2023-12-01 15:49:50,356 INFO     Training average positive_sample_loss at step 22200: 0.007715\n",
      "2023-12-01 15:49:50,356 INFO     Training average negative_sample_loss at step 22200: 0.007264\n",
      "2023-12-01 15:49:50,356 INFO     Training average loss at step 22200: 0.007489\n",
      "2023-12-01 15:49:55,809 INFO     Training average positive_sample_loss at step 22300: 0.007509\n",
      "2023-12-01 15:49:55,809 INFO     Training average negative_sample_loss at step 22300: 0.006905\n",
      "2023-12-01 15:49:55,809 INFO     Training average loss at step 22300: 0.007207\n",
      "2023-12-01 15:50:01,290 INFO     Training average positive_sample_loss at step 22400: 0.007787\n",
      "2023-12-01 15:50:01,290 INFO     Training average negative_sample_loss at step 22400: 0.007721\n",
      "2023-12-01 15:50:01,290 INFO     Training average loss at step 22400: 0.007754\n",
      "2023-12-01 15:50:06,781 INFO     Training average positive_sample_loss at step 22500: 0.007982\n",
      "2023-12-01 15:50:06,781 INFO     Training average negative_sample_loss at step 22500: 0.006961\n",
      "2023-12-01 15:50:06,781 INFO     Training average loss at step 22500: 0.007471\n",
      "2023-12-01 15:50:12,264 INFO     Training average positive_sample_loss at step 22600: 0.008162\n",
      "2023-12-01 15:50:12,264 INFO     Training average negative_sample_loss at step 22600: 0.007033\n",
      "2023-12-01 15:50:12,264 INFO     Training average loss at step 22600: 0.007598\n",
      "2023-12-01 15:50:17,749 INFO     Training average positive_sample_loss at step 22700: 0.007961\n",
      "2023-12-01 15:50:17,750 INFO     Training average negative_sample_loss at step 22700: 0.007545\n",
      "2023-12-01 15:50:17,750 INFO     Training average loss at step 22700: 0.007753\n",
      "2023-12-01 15:50:23,749 INFO     Training average positive_sample_loss at step 22800: 0.007345\n",
      "2023-12-01 15:50:23,750 INFO     Training average negative_sample_loss at step 22800: 0.007324\n",
      "2023-12-01 15:50:23,750 INFO     Training average loss at step 22800: 0.007334\n",
      "2023-12-01 15:50:29,179 INFO     Training average positive_sample_loss at step 22900: 0.007592\n",
      "2023-12-01 15:50:29,179 INFO     Training average negative_sample_loss at step 22900: 0.007272\n",
      "2023-12-01 15:50:29,179 INFO     Training average loss at step 22900: 0.007432\n",
      "2023-12-01 15:50:34,637 INFO     Training average positive_sample_loss at step 23000: 0.007845\n",
      "2023-12-01 15:50:34,638 INFO     Training average negative_sample_loss at step 23000: 0.006821\n",
      "2023-12-01 15:50:34,638 INFO     Training average loss at step 23000: 0.007333\n",
      "2023-12-01 15:50:40,089 INFO     Training average positive_sample_loss at step 23100: 0.007920\n",
      "2023-12-01 15:50:40,089 INFO     Training average negative_sample_loss at step 23100: 0.007329\n",
      "2023-12-01 15:50:40,089 INFO     Training average loss at step 23100: 0.007625\n",
      "2023-12-01 15:50:45,526 INFO     Training average positive_sample_loss at step 23200: 0.008058\n",
      "2023-12-01 15:50:45,526 INFO     Training average negative_sample_loss at step 23200: 0.007857\n",
      "2023-12-01 15:50:45,527 INFO     Training average loss at step 23200: 0.007958\n",
      "2023-12-01 15:50:51,563 INFO     Training average positive_sample_loss at step 23300: 0.007568\n",
      "2023-12-01 15:50:51,563 INFO     Training average negative_sample_loss at step 23300: 0.007684\n",
      "2023-12-01 15:50:51,563 INFO     Training average loss at step 23300: 0.007626\n",
      "2023-12-01 15:50:57,017 INFO     Training average positive_sample_loss at step 23400: 0.007328\n",
      "2023-12-01 15:50:57,017 INFO     Training average negative_sample_loss at step 23400: 0.007778\n",
      "2023-12-01 15:50:57,017 INFO     Training average loss at step 23400: 0.007553\n",
      "2023-12-01 15:51:02,469 INFO     Training average positive_sample_loss at step 23500: 0.007881\n",
      "2023-12-01 15:51:02,469 INFO     Training average negative_sample_loss at step 23500: 0.007204\n",
      "2023-12-01 15:51:02,469 INFO     Training average loss at step 23500: 0.007542\n",
      "2023-12-01 15:51:07,886 INFO     Training average positive_sample_loss at step 23600: 0.007859\n",
      "2023-12-01 15:51:07,887 INFO     Training average negative_sample_loss at step 23600: 0.007082\n",
      "2023-12-01 15:51:07,887 INFO     Training average loss at step 23600: 0.007471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:51:13,315 INFO     Training average positive_sample_loss at step 23700: 0.007889\n",
      "2023-12-01 15:51:13,315 INFO     Training average negative_sample_loss at step 23700: 0.007120\n",
      "2023-12-01 15:51:13,316 INFO     Training average loss at step 23700: 0.007505\n",
      "2023-12-01 15:51:18,704 INFO     Training average positive_sample_loss at step 23800: 0.007892\n",
      "2023-12-01 15:51:18,705 INFO     Training average negative_sample_loss at step 23800: 0.007314\n",
      "2023-12-01 15:51:18,705 INFO     Training average loss at step 23800: 0.007603\n",
      "2023-12-01 15:51:24,761 INFO     Training average positive_sample_loss at step 23900: 0.007125\n",
      "2023-12-01 15:51:24,761 INFO     Training average negative_sample_loss at step 23900: 0.007647\n",
      "2023-12-01 15:51:24,761 INFO     Training average loss at step 23900: 0.007386\n",
      "2023-12-01 15:51:30,200 INFO     Training average positive_sample_loss at step 24000: 0.007503\n",
      "2023-12-01 15:51:30,201 INFO     Training average negative_sample_loss at step 24000: 0.007315\n",
      "2023-12-01 15:51:30,201 INFO     Training average loss at step 24000: 0.007409\n",
      "2023-12-01 15:51:35,657 INFO     Training average positive_sample_loss at step 24100: 0.007722\n",
      "2023-12-01 15:51:35,657 INFO     Training average negative_sample_loss at step 24100: 0.007437\n",
      "2023-12-01 15:51:35,657 INFO     Training average loss at step 24100: 0.007580\n",
      "2023-12-01 15:51:41,130 INFO     Training average positive_sample_loss at step 24200: 0.007992\n",
      "2023-12-01 15:51:41,130 INFO     Training average negative_sample_loss at step 24200: 0.007655\n",
      "2023-12-01 15:51:41,130 INFO     Training average loss at step 24200: 0.007824\n",
      "2023-12-01 15:51:46,588 INFO     Training average positive_sample_loss at step 24300: 0.007919\n",
      "2023-12-01 15:51:46,588 INFO     Training average negative_sample_loss at step 24300: 0.006672\n",
      "2023-12-01 15:51:46,588 INFO     Training average loss at step 24300: 0.007296\n",
      "2023-12-01 15:51:52,613 INFO     Training average positive_sample_loss at step 24400: 0.007564\n",
      "2023-12-01 15:51:52,614 INFO     Training average negative_sample_loss at step 24400: 0.007249\n",
      "2023-12-01 15:51:52,614 INFO     Training average loss at step 24400: 0.007406\n",
      "2023-12-01 15:51:58,058 INFO     Training average positive_sample_loss at step 24500: 0.007135\n",
      "2023-12-01 15:51:58,058 INFO     Training average negative_sample_loss at step 24500: 0.007200\n",
      "2023-12-01 15:51:58,058 INFO     Training average loss at step 24500: 0.007168\n",
      "2023-12-01 15:52:03,528 INFO     Training average positive_sample_loss at step 24600: 0.007590\n",
      "2023-12-01 15:52:03,528 INFO     Training average negative_sample_loss at step 24600: 0.007108\n",
      "2023-12-01 15:52:03,528 INFO     Training average loss at step 24600: 0.007349\n",
      "2023-12-01 15:52:09,032 INFO     Training average positive_sample_loss at step 24700: 0.007649\n",
      "2023-12-01 15:52:09,032 INFO     Training average negative_sample_loss at step 24700: 0.007041\n",
      "2023-12-01 15:52:09,033 INFO     Training average loss at step 24700: 0.007345\n",
      "2023-12-01 15:52:14,520 INFO     Training average positive_sample_loss at step 24800: 0.007877\n",
      "2023-12-01 15:52:14,521 INFO     Training average negative_sample_loss at step 24800: 0.007449\n",
      "2023-12-01 15:52:14,521 INFO     Training average loss at step 24800: 0.007663\n",
      "2023-12-01 15:52:19,991 INFO     Training average positive_sample_loss at step 24900: 0.007912\n",
      "2023-12-01 15:52:19,992 INFO     Training average negative_sample_loss at step 24900: 0.007411\n",
      "2023-12-01 15:52:19,992 INFO     Training average loss at step 24900: 0.007662\n",
      "2023-12-01 15:52:26,015 INFO     Training average positive_sample_loss at step 25000: 0.007111\n",
      "2023-12-01 15:52:26,016 INFO     Training average negative_sample_loss at step 25000: 0.007635\n",
      "2023-12-01 15:52:26,016 INFO     Training average loss at step 25000: 0.007373\n",
      "2023-12-01 15:52:31,452 INFO     Training average positive_sample_loss at step 25100: 0.007269\n",
      "2023-12-01 15:52:31,453 INFO     Training average negative_sample_loss at step 25100: 0.007316\n",
      "2023-12-01 15:52:31,453 INFO     Training average loss at step 25100: 0.007293\n",
      "2023-12-01 15:52:36,897 INFO     Training average positive_sample_loss at step 25200: 0.007588\n",
      "2023-12-01 15:52:36,898 INFO     Training average negative_sample_loss at step 25200: 0.006967\n",
      "2023-12-01 15:52:36,898 INFO     Training average loss at step 25200: 0.007277\n",
      "2023-12-01 15:52:42,362 INFO     Training average positive_sample_loss at step 25300: 0.007738\n",
      "2023-12-01 15:52:42,363 INFO     Training average negative_sample_loss at step 25300: 0.007263\n",
      "2023-12-01 15:52:42,363 INFO     Training average loss at step 25300: 0.007501\n",
      "2023-12-01 15:52:47,823 INFO     Training average positive_sample_loss at step 25400: 0.007815\n",
      "2023-12-01 15:52:47,823 INFO     Training average negative_sample_loss at step 25400: 0.007958\n",
      "2023-12-01 15:52:47,823 INFO     Training average loss at step 25400: 0.007887\n",
      "2023-12-01 15:52:53,878 INFO     Training average positive_sample_loss at step 25500: 0.007537\n",
      "2023-12-01 15:52:53,878 INFO     Training average negative_sample_loss at step 25500: 0.007125\n",
      "2023-12-01 15:52:53,878 INFO     Training average loss at step 25500: 0.007331\n",
      "2023-12-01 15:52:59,383 INFO     Training average positive_sample_loss at step 25600: 0.007008\n",
      "2023-12-01 15:52:59,384 INFO     Training average negative_sample_loss at step 25600: 0.006930\n",
      "2023-12-01 15:52:59,384 INFO     Training average loss at step 25600: 0.006969\n",
      "2023-12-01 15:53:04,869 INFO     Training average positive_sample_loss at step 25700: 0.007541\n",
      "2023-12-01 15:53:04,869 INFO     Training average negative_sample_loss at step 25700: 0.007325\n",
      "2023-12-01 15:53:04,869 INFO     Training average loss at step 25700: 0.007433\n",
      "2023-12-01 15:53:10,370 INFO     Training average positive_sample_loss at step 25800: 0.007554\n",
      "2023-12-01 15:53:10,370 INFO     Training average negative_sample_loss at step 25800: 0.006811\n",
      "2023-12-01 15:53:10,370 INFO     Training average loss at step 25800: 0.007182\n",
      "2023-12-01 15:53:15,877 INFO     Training average positive_sample_loss at step 25900: 0.007600\n",
      "2023-12-01 15:53:15,877 INFO     Training average negative_sample_loss at step 25900: 0.006737\n",
      "2023-12-01 15:53:15,877 INFO     Training average loss at step 25900: 0.007168\n",
      "2023-12-01 15:53:21,343 INFO     Training average positive_sample_loss at step 26000: 0.007710\n",
      "2023-12-01 15:53:21,344 INFO     Training average negative_sample_loss at step 26000: 0.006991\n",
      "2023-12-01 15:53:21,344 INFO     Training average loss at step 26000: 0.007350\n",
      "2023-12-01 15:53:27,337 INFO     Training average positive_sample_loss at step 26100: 0.007138\n",
      "2023-12-01 15:53:27,337 INFO     Training average negative_sample_loss at step 26100: 0.007369\n",
      "2023-12-01 15:53:27,337 INFO     Training average loss at step 26100: 0.007253\n",
      "2023-12-01 15:53:32,818 INFO     Training average positive_sample_loss at step 26200: 0.007170\n",
      "2023-12-01 15:53:32,818 INFO     Training average negative_sample_loss at step 26200: 0.007398\n",
      "2023-12-01 15:53:32,818 INFO     Training average loss at step 26200: 0.007284\n",
      "2023-12-01 15:53:38,315 INFO     Training average positive_sample_loss at step 26300: 0.007457\n",
      "2023-12-01 15:53:38,315 INFO     Training average negative_sample_loss at step 26300: 0.007063\n",
      "2023-12-01 15:53:38,315 INFO     Training average loss at step 26300: 0.007260\n",
      "2023-12-01 15:53:43,795 INFO     Training average positive_sample_loss at step 26400: 0.007741\n",
      "2023-12-01 15:53:43,796 INFO     Training average negative_sample_loss at step 26400: 0.007723\n",
      "2023-12-01 15:53:43,796 INFO     Training average loss at step 26400: 0.007732\n",
      "2023-12-01 15:53:49,262 INFO     Training average positive_sample_loss at step 26500: 0.007706\n",
      "2023-12-01 15:53:49,262 INFO     Training average negative_sample_loss at step 26500: 0.007085\n",
      "2023-12-01 15:53:49,262 INFO     Training average loss at step 26500: 0.007395\n",
      "2023-12-01 15:53:55,274 INFO     Training average positive_sample_loss at step 26600: 0.007537\n",
      "2023-12-01 15:53:55,275 INFO     Training average negative_sample_loss at step 26600: 0.007297\n",
      "2023-12-01 15:53:55,275 INFO     Training average loss at step 26600: 0.007417\n",
      "2023-12-01 15:54:00,716 INFO     Training average positive_sample_loss at step 26700: 0.006978\n",
      "2023-12-01 15:54:00,716 INFO     Training average negative_sample_loss at step 26700: 0.007483\n",
      "2023-12-01 15:54:00,716 INFO     Training average loss at step 26700: 0.007230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:54:06,158 INFO     Training average positive_sample_loss at step 26800: 0.007282\n",
      "2023-12-01 15:54:06,158 INFO     Training average negative_sample_loss at step 26800: 0.007979\n",
      "2023-12-01 15:54:06,158 INFO     Training average loss at step 26800: 0.007631\n",
      "2023-12-01 15:54:11,645 INFO     Training average positive_sample_loss at step 26900: 0.007621\n",
      "2023-12-01 15:54:11,645 INFO     Training average negative_sample_loss at step 26900: 0.007646\n",
      "2023-12-01 15:54:11,645 INFO     Training average loss at step 26900: 0.007634\n",
      "2023-12-01 15:54:17,096 INFO     Training average positive_sample_loss at step 27000: 0.007743\n",
      "2023-12-01 15:54:17,097 INFO     Training average negative_sample_loss at step 27000: 0.007482\n",
      "2023-12-01 15:54:17,097 INFO     Training average loss at step 27000: 0.007613\n",
      "2023-12-01 15:54:22,554 INFO     Training average positive_sample_loss at step 27100: 0.007735\n",
      "2023-12-01 15:54:22,554 INFO     Training average negative_sample_loss at step 27100: 0.007125\n",
      "2023-12-01 15:54:22,554 INFO     Training average loss at step 27100: 0.007430\n",
      "2023-12-01 15:54:28,523 INFO     Training average positive_sample_loss at step 27200: 0.007062\n",
      "2023-12-01 15:54:28,523 INFO     Training average negative_sample_loss at step 27200: 0.006926\n",
      "2023-12-01 15:54:28,523 INFO     Training average loss at step 27200: 0.006994\n",
      "2023-12-01 15:54:33,990 INFO     Training average positive_sample_loss at step 27300: 0.007118\n",
      "2023-12-01 15:54:33,990 INFO     Training average negative_sample_loss at step 27300: 0.007733\n",
      "2023-12-01 15:54:33,990 INFO     Training average loss at step 27300: 0.007426\n",
      "2023-12-01 15:54:39,433 INFO     Training average positive_sample_loss at step 27400: 0.007432\n",
      "2023-12-01 15:54:39,434 INFO     Training average negative_sample_loss at step 27400: 0.007302\n",
      "2023-12-01 15:54:39,434 INFO     Training average loss at step 27400: 0.007367\n",
      "2023-12-01 15:54:44,886 INFO     Training average positive_sample_loss at step 27500: 0.007564\n",
      "2023-12-01 15:54:44,886 INFO     Training average negative_sample_loss at step 27500: 0.007461\n",
      "2023-12-01 15:54:44,886 INFO     Training average loss at step 27500: 0.007513\n",
      "2023-12-01 15:54:50,318 INFO     Training average positive_sample_loss at step 27600: 0.007748\n",
      "2023-12-01 15:54:50,319 INFO     Training average negative_sample_loss at step 27600: 0.007549\n",
      "2023-12-01 15:54:50,319 INFO     Training average loss at step 27600: 0.007649\n",
      "2023-12-01 15:54:56,030 INFO     Training average positive_sample_loss at step 27700: 0.007717\n",
      "2023-12-01 15:54:56,031 INFO     Training average negative_sample_loss at step 27700: 0.008382\n",
      "2023-12-01 15:54:56,031 INFO     Training average loss at step 27700: 0.008050\n",
      "2023-12-01 15:55:01,801 INFO     Training average positive_sample_loss at step 27800: 0.006758\n",
      "2023-12-01 15:55:01,801 INFO     Training average negative_sample_loss at step 27800: 0.006938\n",
      "2023-12-01 15:55:01,801 INFO     Training average loss at step 27800: 0.006848\n",
      "2023-12-01 15:55:07,275 INFO     Training average positive_sample_loss at step 27900: 0.007281\n",
      "2023-12-01 15:55:07,275 INFO     Training average negative_sample_loss at step 27900: 0.007662\n",
      "2023-12-01 15:55:07,275 INFO     Training average loss at step 27900: 0.007472\n",
      "2023-12-01 15:55:12,789 INFO     Training average positive_sample_loss at step 28000: 0.007380\n",
      "2023-12-01 15:55:12,790 INFO     Training average negative_sample_loss at step 28000: 0.007313\n",
      "2023-12-01 15:55:12,790 INFO     Training average loss at step 28000: 0.007346\n",
      "2023-12-01 15:55:18,244 INFO     Training average positive_sample_loss at step 28100: 0.007577\n",
      "2023-12-01 15:55:18,244 INFO     Training average negative_sample_loss at step 28100: 0.007949\n",
      "2023-12-01 15:55:18,244 INFO     Training average loss at step 28100: 0.007763\n",
      "2023-12-01 15:55:23,728 INFO     Training average positive_sample_loss at step 28200: 0.007673\n",
      "2023-12-01 15:55:23,729 INFO     Training average negative_sample_loss at step 28200: 0.007547\n",
      "2023-12-01 15:55:23,729 INFO     Training average loss at step 28200: 0.007610\n",
      "2023-12-01 15:55:29,742 INFO     Training average positive_sample_loss at step 28300: 0.007158\n",
      "2023-12-01 15:55:29,743 INFO     Training average negative_sample_loss at step 28300: 0.007511\n",
      "2023-12-01 15:55:29,743 INFO     Training average loss at step 28300: 0.007334\n",
      "2023-12-01 15:55:35,177 INFO     Training average positive_sample_loss at step 28400: 0.007047\n",
      "2023-12-01 15:55:35,177 INFO     Training average negative_sample_loss at step 28400: 0.006598\n",
      "2023-12-01 15:55:35,177 INFO     Training average loss at step 28400: 0.006823\n",
      "2023-12-01 15:55:40,654 INFO     Training average positive_sample_loss at step 28500: 0.007311\n",
      "2023-12-01 15:55:40,654 INFO     Training average negative_sample_loss at step 28500: 0.007578\n",
      "2023-12-01 15:55:40,655 INFO     Training average loss at step 28500: 0.007445\n",
      "2023-12-01 15:55:46,110 INFO     Training average positive_sample_loss at step 28600: 0.007578\n",
      "2023-12-01 15:55:46,110 INFO     Training average negative_sample_loss at step 28600: 0.007299\n",
      "2023-12-01 15:55:46,110 INFO     Training average loss at step 28600: 0.007439\n",
      "2023-12-01 15:55:51,571 INFO     Training average positive_sample_loss at step 28700: 0.007499\n",
      "2023-12-01 15:55:51,571 INFO     Training average negative_sample_loss at step 28700: 0.007099\n",
      "2023-12-01 15:55:51,571 INFO     Training average loss at step 28700: 0.007299\n",
      "2023-12-01 15:55:57,056 INFO     Training average positive_sample_loss at step 28800: 0.007552\n",
      "2023-12-01 15:55:57,057 INFO     Training average negative_sample_loss at step 28800: 0.007510\n",
      "2023-12-01 15:55:57,057 INFO     Training average loss at step 28800: 0.007531\n",
      "2023-12-01 15:56:03,106 INFO     Training average positive_sample_loss at step 28900: 0.006703\n",
      "2023-12-01 15:56:03,106 INFO     Training average negative_sample_loss at step 28900: 0.007254\n",
      "2023-12-01 15:56:03,106 INFO     Training average loss at step 28900: 0.006978\n",
      "2023-12-01 15:56:08,592 INFO     Training average positive_sample_loss at step 29000: 0.007109\n",
      "2023-12-01 15:56:08,593 INFO     Training average negative_sample_loss at step 29000: 0.008089\n",
      "2023-12-01 15:56:08,593 INFO     Training average loss at step 29000: 0.007599\n",
      "2023-12-01 15:56:14,063 INFO     Training average positive_sample_loss at step 29100: 0.007435\n",
      "2023-12-01 15:56:14,063 INFO     Training average negative_sample_loss at step 29100: 0.007499\n",
      "2023-12-01 15:56:14,063 INFO     Training average loss at step 29100: 0.007467\n",
      "2023-12-01 15:56:19,552 INFO     Training average positive_sample_loss at step 29200: 0.007442\n",
      "2023-12-01 15:56:19,552 INFO     Training average negative_sample_loss at step 29200: 0.007301\n",
      "2023-12-01 15:56:19,552 INFO     Training average loss at step 29200: 0.007371\n",
      "2023-12-01 15:56:25,039 INFO     Training average positive_sample_loss at step 29300: 0.007583\n",
      "2023-12-01 15:56:25,039 INFO     Training average negative_sample_loss at step 29300: 0.007183\n",
      "2023-12-01 15:56:25,039 INFO     Training average loss at step 29300: 0.007383\n",
      "2023-12-01 15:56:31,118 INFO     Training average positive_sample_loss at step 29400: 0.007205\n",
      "2023-12-01 15:56:31,119 INFO     Training average negative_sample_loss at step 29400: 0.008087\n",
      "2023-12-01 15:56:31,119 INFO     Training average loss at step 29400: 0.007646\n",
      "2023-12-01 15:56:36,597 INFO     Training average positive_sample_loss at step 29500: 0.007084\n",
      "2023-12-01 15:56:36,598 INFO     Training average negative_sample_loss at step 29500: 0.007823\n",
      "2023-12-01 15:56:36,598 INFO     Training average loss at step 29500: 0.007453\n",
      "2023-12-01 15:56:42,075 INFO     Training average positive_sample_loss at step 29600: 0.007318\n",
      "2023-12-01 15:56:42,075 INFO     Training average negative_sample_loss at step 29600: 0.007138\n",
      "2023-12-01 15:56:42,075 INFO     Training average loss at step 29600: 0.007228\n",
      "2023-12-01 15:56:47,591 INFO     Training average positive_sample_loss at step 29700: 0.007365\n",
      "2023-12-01 15:56:47,591 INFO     Training average negative_sample_loss at step 29700: 0.007423\n",
      "2023-12-01 15:56:47,591 INFO     Training average loss at step 29700: 0.007394\n",
      "2023-12-01 15:56:53,068 INFO     Training average positive_sample_loss at step 29800: 0.007496\n",
      "2023-12-01 15:56:53,068 INFO     Training average negative_sample_loss at step 29800: 0.008106\n",
      "2023-12-01 15:56:53,068 INFO     Training average loss at step 29800: 0.007801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 15:56:58,549 INFO     Training average positive_sample_loss at step 29900: 0.007508\n",
      "2023-12-01 15:56:58,550 INFO     Training average negative_sample_loss at step 29900: 0.007051\n",
      "2023-12-01 15:56:58,550 INFO     Training average loss at step 29900: 0.007280\n",
      "2023-12-01 15:57:13,618 INFO     Training average positive_sample_loss at step 30000: 0.006883\n",
      "2023-12-01 15:57:13,619 INFO     Training average negative_sample_loss at step 30000: 0.008019\n",
      "2023-12-01 15:57:13,619 INFO     Training average loss at step 30000: 0.007451\n",
      "2023-12-01 15:57:13,619 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 15:57:14,413 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 15:57:52,230 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 15:58:00,571 INFO     Valid MRR at step 30000: 0.948994\n",
      "2023-12-01 15:58:00,572 INFO     Valid MR at step 30000: 350.240900\n",
      "2023-12-01 15:58:00,572 INFO     Valid HITS@1 at step 30000: 0.943900\n",
      "2023-12-01 15:58:00,572 INFO     Valid HITS@3 at step 30000: 0.951300\n",
      "2023-12-01 15:58:00,572 INFO     Valid HITS@10 at step 30000: 0.957600\n",
      "2023-12-01 15:58:06,033 INFO     Training average positive_sample_loss at step 30100: 0.006988\n",
      "2023-12-01 15:58:06,034 INFO     Training average negative_sample_loss at step 30100: 0.007759\n",
      "2023-12-01 15:58:06,034 INFO     Training average loss at step 30100: 0.007374\n",
      "2023-12-01 15:58:11,497 INFO     Training average positive_sample_loss at step 30200: 0.007467\n",
      "2023-12-01 15:58:11,498 INFO     Training average negative_sample_loss at step 30200: 0.008461\n",
      "2023-12-01 15:58:11,498 INFO     Training average loss at step 30200: 0.007964\n",
      "2023-12-01 15:58:16,948 INFO     Training average positive_sample_loss at step 30300: 0.007604\n",
      "2023-12-01 15:58:16,949 INFO     Training average negative_sample_loss at step 30300: 0.007230\n",
      "2023-12-01 15:58:16,949 INFO     Training average loss at step 30300: 0.007417\n",
      "2023-12-01 15:58:22,415 INFO     Training average positive_sample_loss at step 30400: 0.007477\n",
      "2023-12-01 15:58:22,416 INFO     Training average negative_sample_loss at step 30400: 0.007430\n",
      "2023-12-01 15:58:22,416 INFO     Training average loss at step 30400: 0.007453\n",
      "2023-12-01 15:58:28,432 INFO     Training average positive_sample_loss at step 30500: 0.007166\n",
      "2023-12-01 15:58:28,432 INFO     Training average negative_sample_loss at step 30500: 0.007343\n",
      "2023-12-01 15:58:28,433 INFO     Training average loss at step 30500: 0.007254\n",
      "2023-12-01 15:58:33,885 INFO     Training average positive_sample_loss at step 30600: 0.006801\n",
      "2023-12-01 15:58:33,885 INFO     Training average negative_sample_loss at step 30600: 0.008259\n",
      "2023-12-01 15:58:33,885 INFO     Training average loss at step 30600: 0.007530\n",
      "2023-12-01 15:58:39,335 INFO     Training average positive_sample_loss at step 30700: 0.007246\n",
      "2023-12-01 15:58:39,335 INFO     Training average negative_sample_loss at step 30700: 0.007620\n",
      "2023-12-01 15:58:39,335 INFO     Training average loss at step 30700: 0.007433\n",
      "2023-12-01 15:58:44,802 INFO     Training average positive_sample_loss at step 30800: 0.007580\n",
      "2023-12-01 15:58:44,803 INFO     Training average negative_sample_loss at step 30800: 0.007399\n",
      "2023-12-01 15:58:44,803 INFO     Training average loss at step 30800: 0.007490\n",
      "2023-12-01 15:58:50,285 INFO     Training average positive_sample_loss at step 30900: 0.007496\n",
      "2023-12-01 15:58:50,285 INFO     Training average negative_sample_loss at step 30900: 0.007137\n",
      "2023-12-01 15:58:50,285 INFO     Training average loss at step 30900: 0.007317\n",
      "2023-12-01 15:58:55,787 INFO     Training average positive_sample_loss at step 31000: 0.007576\n",
      "2023-12-01 15:58:55,787 INFO     Training average negative_sample_loss at step 31000: 0.007814\n",
      "2023-12-01 15:58:55,787 INFO     Training average loss at step 31000: 0.007695\n",
      "2023-12-01 15:59:01,771 INFO     Training average positive_sample_loss at step 31100: 0.006667\n",
      "2023-12-01 15:59:01,772 INFO     Training average negative_sample_loss at step 31100: 0.008143\n",
      "2023-12-01 15:59:01,772 INFO     Training average loss at step 31100: 0.007405\n",
      "2023-12-01 15:59:07,195 INFO     Training average positive_sample_loss at step 31200: 0.006993\n",
      "2023-12-01 15:59:07,195 INFO     Training average negative_sample_loss at step 31200: 0.007184\n",
      "2023-12-01 15:59:07,195 INFO     Training average loss at step 31200: 0.007089\n",
      "2023-12-01 15:59:12,618 INFO     Training average positive_sample_loss at step 31300: 0.007256\n",
      "2023-12-01 15:59:12,618 INFO     Training average negative_sample_loss at step 31300: 0.006739\n",
      "2023-12-01 15:59:12,618 INFO     Training average loss at step 31300: 0.006998\n",
      "2023-12-01 15:59:18,055 INFO     Training average positive_sample_loss at step 31400: 0.007474\n",
      "2023-12-01 15:59:18,056 INFO     Training average negative_sample_loss at step 31400: 0.007371\n",
      "2023-12-01 15:59:18,056 INFO     Training average loss at step 31400: 0.007423\n",
      "2023-12-01 15:59:23,464 INFO     Training average positive_sample_loss at step 31500: 0.007453\n",
      "2023-12-01 15:59:23,465 INFO     Training average negative_sample_loss at step 31500: 0.007650\n",
      "2023-12-01 15:59:23,465 INFO     Training average loss at step 31500: 0.007551\n",
      "2023-12-01 15:59:29,565 INFO     Training average positive_sample_loss at step 31600: 0.007284\n",
      "2023-12-01 15:59:29,566 INFO     Training average negative_sample_loss at step 31600: 0.008157\n",
      "2023-12-01 15:59:29,566 INFO     Training average loss at step 31600: 0.007720\n",
      "2023-12-01 15:59:34,984 INFO     Training average positive_sample_loss at step 31700: 0.006880\n",
      "2023-12-01 15:59:34,984 INFO     Training average negative_sample_loss at step 31700: 0.007542\n",
      "2023-12-01 15:59:34,984 INFO     Training average loss at step 31700: 0.007211\n",
      "2023-12-01 15:59:40,432 INFO     Training average positive_sample_loss at step 31800: 0.007161\n",
      "2023-12-01 15:59:40,432 INFO     Training average negative_sample_loss at step 31800: 0.007259\n",
      "2023-12-01 15:59:40,433 INFO     Training average loss at step 31800: 0.007210\n",
      "2023-12-01 15:59:45,871 INFO     Training average positive_sample_loss at step 31900: 0.007332\n",
      "2023-12-01 15:59:45,871 INFO     Training average negative_sample_loss at step 31900: 0.006826\n",
      "2023-12-01 15:59:45,871 INFO     Training average loss at step 31900: 0.007079\n",
      "2023-12-01 15:59:51,315 INFO     Training average positive_sample_loss at step 32000: 0.007503\n",
      "2023-12-01 15:59:51,315 INFO     Training average negative_sample_loss at step 32000: 0.007856\n",
      "2023-12-01 15:59:51,315 INFO     Training average loss at step 32000: 0.007679\n",
      "2023-12-01 15:59:56,773 INFO     Training average positive_sample_loss at step 32100: 0.007375\n",
      "2023-12-01 15:59:56,773 INFO     Training average negative_sample_loss at step 32100: 0.007467\n",
      "2023-12-01 15:59:56,774 INFO     Training average loss at step 32100: 0.007421\n",
      "2023-12-01 16:00:02,785 INFO     Training average positive_sample_loss at step 32200: 0.006818\n",
      "2023-12-01 16:00:02,785 INFO     Training average negative_sample_loss at step 32200: 0.007571\n",
      "2023-12-01 16:00:02,785 INFO     Training average loss at step 32200: 0.007194\n",
      "2023-12-01 16:00:08,272 INFO     Training average positive_sample_loss at step 32300: 0.007011\n",
      "2023-12-01 16:00:08,272 INFO     Training average negative_sample_loss at step 32300: 0.007792\n",
      "2023-12-01 16:00:08,272 INFO     Training average loss at step 32300: 0.007401\n",
      "2023-12-01 16:00:13,754 INFO     Training average positive_sample_loss at step 32400: 0.007274\n",
      "2023-12-01 16:00:13,754 INFO     Training average negative_sample_loss at step 32400: 0.007969\n",
      "2023-12-01 16:00:13,754 INFO     Training average loss at step 32400: 0.007621\n",
      "2023-12-01 16:00:19,218 INFO     Training average positive_sample_loss at step 32500: 0.007417\n",
      "2023-12-01 16:00:19,218 INFO     Training average negative_sample_loss at step 32500: 0.007692\n",
      "2023-12-01 16:00:19,219 INFO     Training average loss at step 32500: 0.007555\n",
      "2023-12-01 16:00:24,697 INFO     Training average positive_sample_loss at step 32600: 0.007466\n",
      "2023-12-01 16:00:24,698 INFO     Training average negative_sample_loss at step 32600: 0.007288\n",
      "2023-12-01 16:00:24,698 INFO     Training average loss at step 32600: 0.007377\n",
      "2023-12-01 16:00:30,743 INFO     Training average positive_sample_loss at step 32700: 0.007167\n",
      "2023-12-01 16:00:30,743 INFO     Training average negative_sample_loss at step 32700: 0.007224\n",
      "2023-12-01 16:00:30,744 INFO     Training average loss at step 32700: 0.007196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:00:36,171 INFO     Training average positive_sample_loss at step 32800: 0.006644\n",
      "2023-12-01 16:00:36,172 INFO     Training average negative_sample_loss at step 32800: 0.007130\n",
      "2023-12-01 16:00:36,172 INFO     Training average loss at step 32800: 0.006887\n",
      "2023-12-01 16:00:41,593 INFO     Training average positive_sample_loss at step 32900: 0.007042\n",
      "2023-12-01 16:00:41,593 INFO     Training average negative_sample_loss at step 32900: 0.006732\n",
      "2023-12-01 16:00:41,593 INFO     Training average loss at step 32900: 0.006887\n",
      "2023-12-01 16:00:47,013 INFO     Training average positive_sample_loss at step 33000: 0.007281\n",
      "2023-12-01 16:00:47,013 INFO     Training average negative_sample_loss at step 33000: 0.007109\n",
      "2023-12-01 16:00:47,013 INFO     Training average loss at step 33000: 0.007195\n",
      "2023-12-01 16:00:52,433 INFO     Training average positive_sample_loss at step 33100: 0.007373\n",
      "2023-12-01 16:00:52,433 INFO     Training average negative_sample_loss at step 33100: 0.007255\n",
      "2023-12-01 16:00:52,433 INFO     Training average loss at step 33100: 0.007314\n",
      "2023-12-01 16:00:57,864 INFO     Training average positive_sample_loss at step 33200: 0.007322\n",
      "2023-12-01 16:00:57,865 INFO     Training average negative_sample_loss at step 33200: 0.007616\n",
      "2023-12-01 16:00:57,865 INFO     Training average loss at step 33200: 0.007469\n",
      "2023-12-01 16:01:03,876 INFO     Training average positive_sample_loss at step 33300: 0.006709\n",
      "2023-12-01 16:01:03,876 INFO     Training average negative_sample_loss at step 33300: 0.007252\n",
      "2023-12-01 16:01:03,876 INFO     Training average loss at step 33300: 0.006981\n",
      "2023-12-01 16:01:09,299 INFO     Training average positive_sample_loss at step 33400: 0.006851\n",
      "2023-12-01 16:01:09,299 INFO     Training average negative_sample_loss at step 33400: 0.007694\n",
      "2023-12-01 16:01:09,299 INFO     Training average loss at step 33400: 0.007273\n",
      "2023-12-01 16:01:14,731 INFO     Training average positive_sample_loss at step 33500: 0.007229\n",
      "2023-12-01 16:01:14,732 INFO     Training average negative_sample_loss at step 33500: 0.007064\n",
      "2023-12-01 16:01:14,732 INFO     Training average loss at step 33500: 0.007147\n",
      "2023-12-01 16:01:20,162 INFO     Training average positive_sample_loss at step 33600: 0.007317\n",
      "2023-12-01 16:01:20,163 INFO     Training average negative_sample_loss at step 33600: 0.007951\n",
      "2023-12-01 16:01:20,163 INFO     Training average loss at step 33600: 0.007634\n",
      "2023-12-01 16:01:25,583 INFO     Training average positive_sample_loss at step 33700: 0.007421\n",
      "2023-12-01 16:01:25,583 INFO     Training average negative_sample_loss at step 33700: 0.007969\n",
      "2023-12-01 16:01:25,583 INFO     Training average loss at step 33700: 0.007695\n",
      "2023-12-01 16:01:31,630 INFO     Training average positive_sample_loss at step 33800: 0.007348\n",
      "2023-12-01 16:01:31,630 INFO     Training average negative_sample_loss at step 33800: 0.007653\n",
      "2023-12-01 16:01:31,630 INFO     Training average loss at step 33800: 0.007501\n",
      "2023-12-01 16:01:37,032 INFO     Training average positive_sample_loss at step 33900: 0.006543\n",
      "2023-12-01 16:01:37,033 INFO     Training average negative_sample_loss at step 33900: 0.007349\n",
      "2023-12-01 16:01:37,033 INFO     Training average loss at step 33900: 0.006946\n",
      "2023-12-01 16:01:42,471 INFO     Training average positive_sample_loss at step 34000: 0.006935\n",
      "2023-12-01 16:01:42,471 INFO     Training average negative_sample_loss at step 34000: 0.007193\n",
      "2023-12-01 16:01:42,471 INFO     Training average loss at step 34000: 0.007064\n",
      "2023-12-01 16:01:47,909 INFO     Training average positive_sample_loss at step 34100: 0.007230\n",
      "2023-12-01 16:01:47,909 INFO     Training average negative_sample_loss at step 34100: 0.007257\n",
      "2023-12-01 16:01:47,909 INFO     Training average loss at step 34100: 0.007244\n",
      "2023-12-01 16:01:53,359 INFO     Training average positive_sample_loss at step 34200: 0.007375\n",
      "2023-12-01 16:01:53,359 INFO     Training average negative_sample_loss at step 34200: 0.007556\n",
      "2023-12-01 16:01:53,359 INFO     Training average loss at step 34200: 0.007466\n",
      "2023-12-01 16:01:58,802 INFO     Training average positive_sample_loss at step 34300: 0.007348\n",
      "2023-12-01 16:01:58,803 INFO     Training average negative_sample_loss at step 34300: 0.007482\n",
      "2023-12-01 16:01:58,803 INFO     Training average loss at step 34300: 0.007415\n",
      "2023-12-01 16:02:04,792 INFO     Training average positive_sample_loss at step 34400: 0.006748\n",
      "2023-12-01 16:02:04,792 INFO     Training average negative_sample_loss at step 34400: 0.007773\n",
      "2023-12-01 16:02:04,792 INFO     Training average loss at step 34400: 0.007260\n",
      "2023-12-01 16:02:10,219 INFO     Training average positive_sample_loss at step 34500: 0.006803\n",
      "2023-12-01 16:02:10,219 INFO     Training average negative_sample_loss at step 34500: 0.006757\n",
      "2023-12-01 16:02:10,219 INFO     Training average loss at step 34500: 0.006780\n",
      "2023-12-01 16:02:15,629 INFO     Training average positive_sample_loss at step 34600: 0.007075\n",
      "2023-12-01 16:02:15,629 INFO     Training average negative_sample_loss at step 34600: 0.007865\n",
      "2023-12-01 16:02:15,629 INFO     Training average loss at step 34600: 0.007470\n",
      "2023-12-01 16:02:21,077 INFO     Training average positive_sample_loss at step 34700: 0.007387\n",
      "2023-12-01 16:02:21,077 INFO     Training average negative_sample_loss at step 34700: 0.006770\n",
      "2023-12-01 16:02:21,077 INFO     Training average loss at step 34700: 0.007078\n",
      "2023-12-01 16:02:26,513 INFO     Training average positive_sample_loss at step 34800: 0.007326\n",
      "2023-12-01 16:02:26,513 INFO     Training average negative_sample_loss at step 34800: 0.008096\n",
      "2023-12-01 16:02:26,513 INFO     Training average loss at step 34800: 0.007711\n",
      "2023-12-01 16:02:31,931 INFO     Training average positive_sample_loss at step 34900: 0.007401\n",
      "2023-12-01 16:02:31,932 INFO     Training average negative_sample_loss at step 34900: 0.007089\n",
      "2023-12-01 16:02:31,932 INFO     Training average loss at step 34900: 0.007245\n",
      "2023-12-01 16:02:38,036 INFO     Training average positive_sample_loss at step 35000: 0.006509\n",
      "2023-12-01 16:02:38,037 INFO     Training average negative_sample_loss at step 35000: 0.007400\n",
      "2023-12-01 16:02:38,037 INFO     Training average loss at step 35000: 0.006954\n",
      "2023-12-01 16:02:43,471 INFO     Training average positive_sample_loss at step 35100: 0.006984\n",
      "2023-12-01 16:02:43,472 INFO     Training average negative_sample_loss at step 35100: 0.007467\n",
      "2023-12-01 16:02:43,472 INFO     Training average loss at step 35100: 0.007226\n",
      "2023-12-01 16:02:48,895 INFO     Training average positive_sample_loss at step 35200: 0.007263\n",
      "2023-12-01 16:02:48,895 INFO     Training average negative_sample_loss at step 35200: 0.007304\n",
      "2023-12-01 16:02:48,895 INFO     Training average loss at step 35200: 0.007283\n",
      "2023-12-01 16:02:54,330 INFO     Training average positive_sample_loss at step 35300: 0.007175\n",
      "2023-12-01 16:02:54,330 INFO     Training average negative_sample_loss at step 35300: 0.006763\n",
      "2023-12-01 16:02:54,330 INFO     Training average loss at step 35300: 0.006969\n",
      "2023-12-01 16:02:59,757 INFO     Training average positive_sample_loss at step 35400: 0.007276\n",
      "2023-12-01 16:02:59,757 INFO     Training average negative_sample_loss at step 35400: 0.007509\n",
      "2023-12-01 16:02:59,757 INFO     Training average loss at step 35400: 0.007392\n",
      "2023-12-01 16:03:05,842 INFO     Training average positive_sample_loss at step 35500: 0.006853\n",
      "2023-12-01 16:03:05,843 INFO     Training average negative_sample_loss at step 35500: 0.007505\n",
      "2023-12-01 16:03:05,843 INFO     Training average loss at step 35500: 0.007179\n",
      "2023-12-01 16:03:11,301 INFO     Training average positive_sample_loss at step 35600: 0.006659\n",
      "2023-12-01 16:03:11,301 INFO     Training average negative_sample_loss at step 35600: 0.007164\n",
      "2023-12-01 16:03:11,301 INFO     Training average loss at step 35600: 0.006912\n",
      "2023-12-01 16:03:16,767 INFO     Training average positive_sample_loss at step 35700: 0.006982\n",
      "2023-12-01 16:03:16,768 INFO     Training average negative_sample_loss at step 35700: 0.007125\n",
      "2023-12-01 16:03:16,768 INFO     Training average loss at step 35700: 0.007053\n",
      "2023-12-01 16:03:22,201 INFO     Training average positive_sample_loss at step 35800: 0.007330\n",
      "2023-12-01 16:03:22,202 INFO     Training average negative_sample_loss at step 35800: 0.007738\n",
      "2023-12-01 16:03:22,202 INFO     Training average loss at step 35800: 0.007534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:03:27,634 INFO     Training average positive_sample_loss at step 35900: 0.007245\n",
      "2023-12-01 16:03:27,634 INFO     Training average negative_sample_loss at step 35900: 0.007678\n",
      "2023-12-01 16:03:27,634 INFO     Training average loss at step 35900: 0.007461\n",
      "2023-12-01 16:03:33,135 INFO     Training average positive_sample_loss at step 36000: 0.007152\n",
      "2023-12-01 16:03:33,135 INFO     Training average negative_sample_loss at step 36000: 0.007138\n",
      "2023-12-01 16:03:33,135 INFO     Training average loss at step 36000: 0.007145\n",
      "2023-12-01 16:03:39,138 INFO     Training average positive_sample_loss at step 36100: 0.006504\n",
      "2023-12-01 16:03:39,139 INFO     Training average negative_sample_loss at step 36100: 0.006755\n",
      "2023-12-01 16:03:39,139 INFO     Training average loss at step 36100: 0.006629\n",
      "2023-12-01 16:03:44,569 INFO     Training average positive_sample_loss at step 36200: 0.006844\n",
      "2023-12-01 16:03:44,569 INFO     Training average negative_sample_loss at step 36200: 0.007479\n",
      "2023-12-01 16:03:44,569 INFO     Training average loss at step 36200: 0.007161\n",
      "2023-12-01 16:03:50,019 INFO     Training average positive_sample_loss at step 36300: 0.007088\n",
      "2023-12-01 16:03:50,019 INFO     Training average negative_sample_loss at step 36300: 0.007060\n",
      "2023-12-01 16:03:50,019 INFO     Training average loss at step 36300: 0.007074\n",
      "2023-12-01 16:03:55,481 INFO     Training average positive_sample_loss at step 36400: 0.007392\n",
      "2023-12-01 16:03:55,482 INFO     Training average negative_sample_loss at step 36400: 0.007547\n",
      "2023-12-01 16:03:55,482 INFO     Training average loss at step 36400: 0.007469\n",
      "2023-12-01 16:04:00,934 INFO     Training average positive_sample_loss at step 36500: 0.007266\n",
      "2023-12-01 16:04:00,934 INFO     Training average negative_sample_loss at step 36500: 0.007289\n",
      "2023-12-01 16:04:00,934 INFO     Training average loss at step 36500: 0.007278\n",
      "2023-12-01 16:04:06,989 INFO     Training average positive_sample_loss at step 36600: 0.006888\n",
      "2023-12-01 16:04:06,990 INFO     Training average negative_sample_loss at step 36600: 0.007329\n",
      "2023-12-01 16:04:06,990 INFO     Training average loss at step 36600: 0.007108\n",
      "2023-12-01 16:04:12,470 INFO     Training average positive_sample_loss at step 36700: 0.006618\n",
      "2023-12-01 16:04:12,470 INFO     Training average negative_sample_loss at step 36700: 0.006921\n",
      "2023-12-01 16:04:12,470 INFO     Training average loss at step 36700: 0.006769\n",
      "2023-12-01 16:04:17,937 INFO     Training average positive_sample_loss at step 36800: 0.006937\n",
      "2023-12-01 16:04:17,938 INFO     Training average negative_sample_loss at step 36800: 0.006941\n",
      "2023-12-01 16:04:17,938 INFO     Training average loss at step 36800: 0.006939\n",
      "2023-12-01 16:04:23,392 INFO     Training average positive_sample_loss at step 36900: 0.007261\n",
      "2023-12-01 16:04:23,392 INFO     Training average negative_sample_loss at step 36900: 0.007361\n",
      "2023-12-01 16:04:23,392 INFO     Training average loss at step 36900: 0.007311\n",
      "2023-12-01 16:04:28,832 INFO     Training average positive_sample_loss at step 37000: 0.007226\n",
      "2023-12-01 16:04:28,832 INFO     Training average negative_sample_loss at step 37000: 0.007372\n",
      "2023-12-01 16:04:28,832 INFO     Training average loss at step 37000: 0.007299\n",
      "2023-12-01 16:04:34,303 INFO     Training average positive_sample_loss at step 37100: 0.007220\n",
      "2023-12-01 16:04:34,304 INFO     Training average negative_sample_loss at step 37100: 0.007410\n",
      "2023-12-01 16:04:34,304 INFO     Training average loss at step 37100: 0.007315\n",
      "2023-12-01 16:04:40,322 INFO     Training average positive_sample_loss at step 37200: 0.006490\n",
      "2023-12-01 16:04:40,322 INFO     Training average negative_sample_loss at step 37200: 0.007062\n",
      "2023-12-01 16:04:40,322 INFO     Training average loss at step 37200: 0.006776\n",
      "2023-12-01 16:04:45,774 INFO     Training average positive_sample_loss at step 37300: 0.006723\n",
      "2023-12-01 16:04:45,774 INFO     Training average negative_sample_loss at step 37300: 0.007077\n",
      "2023-12-01 16:04:45,775 INFO     Training average loss at step 37300: 0.006900\n",
      "2023-12-01 16:04:51,211 INFO     Training average positive_sample_loss at step 37400: 0.007119\n",
      "2023-12-01 16:04:51,211 INFO     Training average negative_sample_loss at step 37400: 0.007223\n",
      "2023-12-01 16:04:51,211 INFO     Training average loss at step 37400: 0.007171\n",
      "2023-12-01 16:04:56,648 INFO     Training average positive_sample_loss at step 37500: 0.007328\n",
      "2023-12-01 16:04:56,648 INFO     Training average negative_sample_loss at step 37500: 0.008305\n",
      "2023-12-01 16:04:56,648 INFO     Training average loss at step 37500: 0.007817\n",
      "2023-12-01 16:05:02,081 INFO     Training average positive_sample_loss at step 37600: 0.007258\n",
      "2023-12-01 16:05:02,081 INFO     Training average negative_sample_loss at step 37600: 0.007748\n",
      "2023-12-01 16:05:02,081 INFO     Training average loss at step 37600: 0.007503\n",
      "2023-12-01 16:05:08,088 INFO     Training average positive_sample_loss at step 37700: 0.006903\n",
      "2023-12-01 16:05:08,088 INFO     Training average negative_sample_loss at step 37700: 0.008019\n",
      "2023-12-01 16:05:08,088 INFO     Training average loss at step 37700: 0.007461\n",
      "2023-12-01 16:05:13,532 INFO     Training average positive_sample_loss at step 37800: 0.006611\n",
      "2023-12-01 16:05:13,533 INFO     Training average negative_sample_loss at step 37800: 0.007576\n",
      "2023-12-01 16:05:13,533 INFO     Training average loss at step 37800: 0.007093\n",
      "2023-12-01 16:05:18,993 INFO     Training average positive_sample_loss at step 37900: 0.007068\n",
      "2023-12-01 16:05:18,993 INFO     Training average negative_sample_loss at step 37900: 0.006950\n",
      "2023-12-01 16:05:18,993 INFO     Training average loss at step 37900: 0.007009\n",
      "2023-12-01 16:05:24,386 INFO     Training average positive_sample_loss at step 38000: 0.007207\n",
      "2023-12-01 16:05:24,386 INFO     Training average negative_sample_loss at step 38000: 0.007390\n",
      "2023-12-01 16:05:24,386 INFO     Training average loss at step 38000: 0.007299\n",
      "2023-12-01 16:05:29,750 INFO     Training average positive_sample_loss at step 38100: 0.007173\n",
      "2023-12-01 16:05:29,750 INFO     Training average negative_sample_loss at step 38100: 0.006796\n",
      "2023-12-01 16:05:29,750 INFO     Training average loss at step 38100: 0.006984\n",
      "2023-12-01 16:05:35,106 INFO     Training average positive_sample_loss at step 38200: 0.007118\n",
      "2023-12-01 16:05:35,106 INFO     Training average negative_sample_loss at step 38200: 0.006580\n",
      "2023-12-01 16:05:35,106 INFO     Training average loss at step 38200: 0.006849\n",
      "2023-12-01 16:05:41,113 INFO     Training average positive_sample_loss at step 38300: 0.006551\n",
      "2023-12-01 16:05:41,114 INFO     Training average negative_sample_loss at step 38300: 0.007462\n",
      "2023-12-01 16:05:41,114 INFO     Training average loss at step 38300: 0.007006\n",
      "2023-12-01 16:05:46,557 INFO     Training average positive_sample_loss at step 38400: 0.006786\n",
      "2023-12-01 16:05:46,557 INFO     Training average negative_sample_loss at step 38400: 0.007682\n",
      "2023-12-01 16:05:46,557 INFO     Training average loss at step 38400: 0.007234\n",
      "2023-12-01 16:05:51,995 INFO     Training average positive_sample_loss at step 38500: 0.006923\n",
      "2023-12-01 16:05:51,995 INFO     Training average negative_sample_loss at step 38500: 0.007684\n",
      "2023-12-01 16:05:51,995 INFO     Training average loss at step 38500: 0.007304\n",
      "2023-12-01 16:05:57,452 INFO     Training average positive_sample_loss at step 38600: 0.007255\n",
      "2023-12-01 16:05:57,452 INFO     Training average negative_sample_loss at step 38600: 0.007566\n",
      "2023-12-01 16:05:57,452 INFO     Training average loss at step 38600: 0.007411\n",
      "2023-12-01 16:06:02,911 INFO     Training average positive_sample_loss at step 38700: 0.007382\n",
      "2023-12-01 16:06:02,911 INFO     Training average negative_sample_loss at step 38700: 0.008179\n",
      "2023-12-01 16:06:02,911 INFO     Training average loss at step 38700: 0.007781\n",
      "2023-12-01 16:06:08,865 INFO     Training average positive_sample_loss at step 38800: 0.006999\n",
      "2023-12-01 16:06:08,865 INFO     Training average negative_sample_loss at step 38800: 0.006829\n",
      "2023-12-01 16:06:08,865 INFO     Training average loss at step 38800: 0.006914\n",
      "2023-12-01 16:06:14,302 INFO     Training average positive_sample_loss at step 38900: 0.006532\n",
      "2023-12-01 16:06:14,302 INFO     Training average negative_sample_loss at step 38900: 0.007786\n",
      "2023-12-01 16:06:14,303 INFO     Training average loss at step 38900: 0.007159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:06:19,799 INFO     Training average positive_sample_loss at step 39000: 0.006904\n",
      "2023-12-01 16:06:19,799 INFO     Training average negative_sample_loss at step 39000: 0.006840\n",
      "2023-12-01 16:06:19,799 INFO     Training average loss at step 39000: 0.006872\n",
      "2023-12-01 16:06:25,269 INFO     Training average positive_sample_loss at step 39100: 0.007206\n",
      "2023-12-01 16:06:25,269 INFO     Training average negative_sample_loss at step 39100: 0.007014\n",
      "2023-12-01 16:06:25,269 INFO     Training average loss at step 39100: 0.007110\n",
      "2023-12-01 16:06:30,731 INFO     Training average positive_sample_loss at step 39200: 0.007176\n",
      "2023-12-01 16:06:30,732 INFO     Training average negative_sample_loss at step 39200: 0.007761\n",
      "2023-12-01 16:06:30,732 INFO     Training average loss at step 39200: 0.007468\n",
      "2023-12-01 16:06:36,191 INFO     Training average positive_sample_loss at step 39300: 0.007272\n",
      "2023-12-01 16:06:36,191 INFO     Training average negative_sample_loss at step 39300: 0.007187\n",
      "2023-12-01 16:06:36,191 INFO     Training average loss at step 39300: 0.007229\n",
      "2023-12-01 16:06:42,165 INFO     Training average positive_sample_loss at step 39400: 0.006499\n",
      "2023-12-01 16:06:42,165 INFO     Training average negative_sample_loss at step 39400: 0.007158\n",
      "2023-12-01 16:06:42,165 INFO     Training average loss at step 39400: 0.006829\n",
      "2023-12-01 16:06:47,588 INFO     Training average positive_sample_loss at step 39500: 0.006782\n",
      "2023-12-01 16:06:47,588 INFO     Training average negative_sample_loss at step 39500: 0.008024\n",
      "2023-12-01 16:06:47,588 INFO     Training average loss at step 39500: 0.007403\n",
      "2023-12-01 16:06:53,066 INFO     Training average positive_sample_loss at step 39600: 0.007017\n",
      "2023-12-01 16:06:53,066 INFO     Training average negative_sample_loss at step 39600: 0.007950\n",
      "2023-12-01 16:06:53,066 INFO     Training average loss at step 39600: 0.007483\n",
      "2023-12-01 16:06:58,489 INFO     Training average positive_sample_loss at step 39700: 0.007096\n",
      "2023-12-01 16:06:58,489 INFO     Training average negative_sample_loss at step 39700: 0.007261\n",
      "2023-12-01 16:06:58,489 INFO     Training average loss at step 39700: 0.007179\n",
      "2023-12-01 16:07:03,930 INFO     Training average positive_sample_loss at step 39800: 0.007150\n",
      "2023-12-01 16:07:03,930 INFO     Training average negative_sample_loss at step 39800: 0.007657\n",
      "2023-12-01 16:07:03,930 INFO     Training average loss at step 39800: 0.007404\n",
      "2023-12-01 16:07:10,009 INFO     Training average positive_sample_loss at step 39900: 0.007068\n",
      "2023-12-01 16:07:10,009 INFO     Training average negative_sample_loss at step 39900: 0.007364\n",
      "2023-12-01 16:07:10,009 INFO     Training average loss at step 39900: 0.007216\n",
      "2023-12-01 16:07:15,426 INFO     Change learning_rate to 0.000010 at step 40000\n",
      "2023-12-01 16:07:19,623 INFO     Training average positive_sample_loss at step 40000: 0.006511\n",
      "2023-12-01 16:07:19,623 INFO     Training average negative_sample_loss at step 40000: 0.007405\n",
      "2023-12-01 16:07:19,623 INFO     Training average loss at step 40000: 0.006958\n",
      "2023-12-01 16:07:19,623 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 16:07:20,665 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 16:07:55,696 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 16:08:03,695 INFO     Valid MRR at step 40000: 0.948910\n",
      "2023-12-01 16:08:03,695 INFO     Valid MR at step 40000: 326.488600\n",
      "2023-12-01 16:08:03,695 INFO     Valid HITS@1 at step 40000: 0.943300\n",
      "2023-12-01 16:08:03,695 INFO     Valid HITS@3 at step 40000: 0.952000\n",
      "2023-12-01 16:08:03,695 INFO     Valid HITS@10 at step 40000: 0.958100\n",
      "2023-12-01 16:08:09,137 INFO     Training average positive_sample_loss at step 40100: 0.006799\n",
      "2023-12-01 16:08:09,138 INFO     Training average negative_sample_loss at step 40100: 0.007158\n",
      "2023-12-01 16:08:09,138 INFO     Training average loss at step 40100: 0.006979\n",
      "2023-12-01 16:08:14,557 INFO     Training average positive_sample_loss at step 40200: 0.006648\n",
      "2023-12-01 16:08:14,558 INFO     Training average negative_sample_loss at step 40200: 0.007854\n",
      "2023-12-01 16:08:14,558 INFO     Training average loss at step 40200: 0.007251\n",
      "2023-12-01 16:08:19,999 INFO     Training average positive_sample_loss at step 40300: 0.006560\n",
      "2023-12-01 16:08:19,999 INFO     Training average negative_sample_loss at step 40300: 0.006903\n",
      "2023-12-01 16:08:19,999 INFO     Training average loss at step 40300: 0.006731\n",
      "2023-12-01 16:08:25,478 INFO     Training average positive_sample_loss at step 40400: 0.006574\n",
      "2023-12-01 16:08:25,478 INFO     Training average negative_sample_loss at step 40400: 0.007167\n",
      "2023-12-01 16:08:25,478 INFO     Training average loss at step 40400: 0.006871\n",
      "2023-12-01 16:08:31,494 INFO     Training average positive_sample_loss at step 40500: 0.006070\n",
      "2023-12-01 16:08:31,494 INFO     Training average negative_sample_loss at step 40500: 0.006977\n",
      "2023-12-01 16:08:31,494 INFO     Training average loss at step 40500: 0.006523\n",
      "2023-12-01 16:08:36,920 INFO     Training average positive_sample_loss at step 40600: 0.005910\n",
      "2023-12-01 16:08:36,920 INFO     Training average negative_sample_loss at step 40600: 0.007323\n",
      "2023-12-01 16:08:36,920 INFO     Training average loss at step 40600: 0.006617\n",
      "2023-12-01 16:08:42,380 INFO     Training average positive_sample_loss at step 40700: 0.005792\n",
      "2023-12-01 16:08:42,380 INFO     Training average negative_sample_loss at step 40700: 0.007527\n",
      "2023-12-01 16:08:42,381 INFO     Training average loss at step 40700: 0.006660\n",
      "2023-12-01 16:08:47,856 INFO     Training average positive_sample_loss at step 40800: 0.005879\n",
      "2023-12-01 16:08:47,857 INFO     Training average negative_sample_loss at step 40800: 0.007523\n",
      "2023-12-01 16:08:47,857 INFO     Training average loss at step 40800: 0.006701\n",
      "2023-12-01 16:08:53,293 INFO     Training average positive_sample_loss at step 40900: 0.005876\n",
      "2023-12-01 16:08:53,293 INFO     Training average negative_sample_loss at step 40900: 0.007219\n",
      "2023-12-01 16:08:53,293 INFO     Training average loss at step 40900: 0.006548\n",
      "2023-12-01 16:08:59,409 INFO     Training average positive_sample_loss at step 41000: 0.005784\n",
      "2023-12-01 16:08:59,410 INFO     Training average negative_sample_loss at step 41000: 0.007051\n",
      "2023-12-01 16:08:59,410 INFO     Training average loss at step 41000: 0.006417\n",
      "2023-12-01 16:09:04,870 INFO     Training average positive_sample_loss at step 41100: 0.005547\n",
      "2023-12-01 16:09:04,870 INFO     Training average negative_sample_loss at step 41100: 0.007431\n",
      "2023-12-01 16:09:04,870 INFO     Training average loss at step 41100: 0.006489\n",
      "2023-12-01 16:09:10,342 INFO     Training average positive_sample_loss at step 41200: 0.005553\n",
      "2023-12-01 16:09:10,343 INFO     Training average negative_sample_loss at step 41200: 0.007650\n",
      "2023-12-01 16:09:10,343 INFO     Training average loss at step 41200: 0.006602\n",
      "2023-12-01 16:09:15,827 INFO     Training average positive_sample_loss at step 41300: 0.005661\n",
      "2023-12-01 16:09:15,828 INFO     Training average negative_sample_loss at step 41300: 0.007118\n",
      "2023-12-01 16:09:15,828 INFO     Training average loss at step 41300: 0.006390\n",
      "2023-12-01 16:09:21,305 INFO     Training average positive_sample_loss at step 41400: 0.005629\n",
      "2023-12-01 16:09:21,305 INFO     Training average negative_sample_loss at step 41400: 0.007442\n",
      "2023-12-01 16:09:21,305 INFO     Training average loss at step 41400: 0.006536\n",
      "2023-12-01 16:09:26,754 INFO     Training average positive_sample_loss at step 41500: 0.005655\n",
      "2023-12-01 16:09:26,755 INFO     Training average negative_sample_loss at step 41500: 0.007410\n",
      "2023-12-01 16:09:26,755 INFO     Training average loss at step 41500: 0.006532\n",
      "2023-12-01 16:09:32,728 INFO     Training average positive_sample_loss at step 41600: 0.005504\n",
      "2023-12-01 16:09:32,728 INFO     Training average negative_sample_loss at step 41600: 0.007146\n",
      "2023-12-01 16:09:32,728 INFO     Training average loss at step 41600: 0.006325\n",
      "2023-12-01 16:09:38,165 INFO     Training average positive_sample_loss at step 41700: 0.005421\n",
      "2023-12-01 16:09:38,166 INFO     Training average negative_sample_loss at step 41700: 0.007600\n",
      "2023-12-01 16:09:38,166 INFO     Training average loss at step 41700: 0.006511\n",
      "2023-12-01 16:09:43,644 INFO     Training average positive_sample_loss at step 41800: 0.005452\n",
      "2023-12-01 16:09:43,644 INFO     Training average negative_sample_loss at step 41800: 0.006687\n",
      "2023-12-01 16:09:43,644 INFO     Training average loss at step 41800: 0.006069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:09:49,155 INFO     Training average positive_sample_loss at step 41900: 0.005499\n",
      "2023-12-01 16:09:49,155 INFO     Training average negative_sample_loss at step 41900: 0.006712\n",
      "2023-12-01 16:09:49,155 INFO     Training average loss at step 41900: 0.006105\n",
      "2023-12-01 16:09:54,609 INFO     Training average positive_sample_loss at step 42000: 0.005463\n",
      "2023-12-01 16:09:54,609 INFO     Training average negative_sample_loss at step 42000: 0.007113\n",
      "2023-12-01 16:09:54,609 INFO     Training average loss at step 42000: 0.006288\n",
      "2023-12-01 16:10:00,195 INFO     Training average positive_sample_loss at step 42100: 0.005592\n",
      "2023-12-01 16:10:00,195 INFO     Training average negative_sample_loss at step 42100: 0.006720\n",
      "2023-12-01 16:10:00,195 INFO     Training average loss at step 42100: 0.006156\n",
      "2023-12-01 16:10:06,209 INFO     Training average positive_sample_loss at step 42200: 0.005309\n",
      "2023-12-01 16:10:06,210 INFO     Training average negative_sample_loss at step 42200: 0.006976\n",
      "2023-12-01 16:10:06,210 INFO     Training average loss at step 42200: 0.006142\n",
      "2023-12-01 16:10:11,657 INFO     Training average positive_sample_loss at step 42300: 0.005393\n",
      "2023-12-01 16:10:11,658 INFO     Training average negative_sample_loss at step 42300: 0.006946\n",
      "2023-12-01 16:10:11,658 INFO     Training average loss at step 42300: 0.006169\n",
      "2023-12-01 16:10:17,096 INFO     Training average positive_sample_loss at step 42400: 0.005419\n",
      "2023-12-01 16:10:17,096 INFO     Training average negative_sample_loss at step 42400: 0.007400\n",
      "2023-12-01 16:10:17,096 INFO     Training average loss at step 42400: 0.006409\n",
      "2023-12-01 16:10:22,585 INFO     Training average positive_sample_loss at step 42500: 0.005465\n",
      "2023-12-01 16:10:22,586 INFO     Training average negative_sample_loss at step 42500: 0.007304\n",
      "2023-12-01 16:10:22,586 INFO     Training average loss at step 42500: 0.006385\n",
      "2023-12-01 16:10:28,064 INFO     Training average positive_sample_loss at step 42600: 0.005449\n",
      "2023-12-01 16:10:28,064 INFO     Training average negative_sample_loss at step 42600: 0.007657\n",
      "2023-12-01 16:10:28,064 INFO     Training average loss at step 42600: 0.006553\n",
      "2023-12-01 16:10:34,130 INFO     Training average positive_sample_loss at step 42700: 0.005368\n",
      "2023-12-01 16:10:34,130 INFO     Training average negative_sample_loss at step 42700: 0.007630\n",
      "2023-12-01 16:10:34,130 INFO     Training average loss at step 42700: 0.006499\n",
      "2023-12-01 16:10:39,588 INFO     Training average positive_sample_loss at step 42800: 0.005366\n",
      "2023-12-01 16:10:39,589 INFO     Training average negative_sample_loss at step 42800: 0.007489\n",
      "2023-12-01 16:10:39,589 INFO     Training average loss at step 42800: 0.006427\n",
      "2023-12-01 16:10:45,038 INFO     Training average positive_sample_loss at step 42900: 0.005336\n",
      "2023-12-01 16:10:45,038 INFO     Training average negative_sample_loss at step 42900: 0.007775\n",
      "2023-12-01 16:10:45,038 INFO     Training average loss at step 42900: 0.006555\n",
      "2023-12-01 16:10:50,515 INFO     Training average positive_sample_loss at step 43000: 0.005348\n",
      "2023-12-01 16:10:50,516 INFO     Training average negative_sample_loss at step 43000: 0.007148\n",
      "2023-12-01 16:10:50,516 INFO     Training average loss at step 43000: 0.006248\n",
      "2023-12-01 16:10:55,987 INFO     Training average positive_sample_loss at step 43100: 0.005404\n",
      "2023-12-01 16:10:55,987 INFO     Training average negative_sample_loss at step 43100: 0.007735\n",
      "2023-12-01 16:10:55,987 INFO     Training average loss at step 43100: 0.006569\n",
      "2023-12-01 16:11:01,449 INFO     Training average positive_sample_loss at step 43200: 0.005412\n",
      "2023-12-01 16:11:01,449 INFO     Training average negative_sample_loss at step 43200: 0.006817\n",
      "2023-12-01 16:11:01,449 INFO     Training average loss at step 43200: 0.006115\n",
      "2023-12-01 16:11:07,463 INFO     Training average positive_sample_loss at step 43300: 0.005254\n",
      "2023-12-01 16:11:07,463 INFO     Training average negative_sample_loss at step 43300: 0.007189\n",
      "2023-12-01 16:11:07,463 INFO     Training average loss at step 43300: 0.006221\n",
      "2023-12-01 16:11:12,912 INFO     Training average positive_sample_loss at step 43400: 0.005331\n",
      "2023-12-01 16:11:12,913 INFO     Training average negative_sample_loss at step 43400: 0.007495\n",
      "2023-12-01 16:11:12,913 INFO     Training average loss at step 43400: 0.006413\n",
      "2023-12-01 16:11:18,353 INFO     Training average positive_sample_loss at step 43500: 0.005352\n",
      "2023-12-01 16:11:18,353 INFO     Training average negative_sample_loss at step 43500: 0.007184\n",
      "2023-12-01 16:11:18,353 INFO     Training average loss at step 43500: 0.006268\n",
      "2023-12-01 16:11:23,822 INFO     Training average positive_sample_loss at step 43600: 0.005331\n",
      "2023-12-01 16:11:23,822 INFO     Training average negative_sample_loss at step 43600: 0.006598\n",
      "2023-12-01 16:11:23,822 INFO     Training average loss at step 43600: 0.005965\n",
      "2023-12-01 16:11:29,296 INFO     Training average positive_sample_loss at step 43700: 0.005385\n",
      "2023-12-01 16:11:29,296 INFO     Training average negative_sample_loss at step 43700: 0.006673\n",
      "2023-12-01 16:11:29,296 INFO     Training average loss at step 43700: 0.006029\n",
      "2023-12-01 16:11:35,295 INFO     Training average positive_sample_loss at step 43800: 0.005320\n",
      "2023-12-01 16:11:35,296 INFO     Training average negative_sample_loss at step 43800: 0.007168\n",
      "2023-12-01 16:11:35,296 INFO     Training average loss at step 43800: 0.006244\n",
      "2023-12-01 16:11:40,771 INFO     Training average positive_sample_loss at step 43900: 0.005245\n",
      "2023-12-01 16:11:40,772 INFO     Training average negative_sample_loss at step 43900: 0.007147\n",
      "2023-12-01 16:11:40,772 INFO     Training average loss at step 43900: 0.006196\n",
      "2023-12-01 16:11:46,293 INFO     Training average positive_sample_loss at step 44000: 0.005300\n",
      "2023-12-01 16:11:46,293 INFO     Training average negative_sample_loss at step 44000: 0.007434\n",
      "2023-12-01 16:11:46,293 INFO     Training average loss at step 44000: 0.006367\n",
      "2023-12-01 16:11:51,827 INFO     Training average positive_sample_loss at step 44100: 0.005308\n",
      "2023-12-01 16:11:51,827 INFO     Training average negative_sample_loss at step 44100: 0.007859\n",
      "2023-12-01 16:11:51,827 INFO     Training average loss at step 44100: 0.006583\n",
      "2023-12-01 16:11:57,327 INFO     Training average positive_sample_loss at step 44200: 0.005363\n",
      "2023-12-01 16:11:57,328 INFO     Training average negative_sample_loss at step 44200: 0.007103\n",
      "2023-12-01 16:11:57,328 INFO     Training average loss at step 44200: 0.006233\n",
      "2023-12-01 16:12:02,913 INFO     Training average positive_sample_loss at step 44300: 0.005417\n",
      "2023-12-01 16:12:02,913 INFO     Training average negative_sample_loss at step 44300: 0.007144\n",
      "2023-12-01 16:12:02,913 INFO     Training average loss at step 44300: 0.006280\n",
      "2023-12-01 16:12:09,004 INFO     Training average positive_sample_loss at step 44400: 0.005254\n",
      "2023-12-01 16:12:09,005 INFO     Training average negative_sample_loss at step 44400: 0.007578\n",
      "2023-12-01 16:12:09,005 INFO     Training average loss at step 44400: 0.006416\n",
      "2023-12-01 16:12:14,544 INFO     Training average positive_sample_loss at step 44500: 0.005301\n",
      "2023-12-01 16:12:14,545 INFO     Training average negative_sample_loss at step 44500: 0.008152\n",
      "2023-12-01 16:12:14,545 INFO     Training average loss at step 44500: 0.006727\n",
      "2023-12-01 16:12:20,050 INFO     Training average positive_sample_loss at step 44600: 0.005280\n",
      "2023-12-01 16:12:20,051 INFO     Training average negative_sample_loss at step 44600: 0.006846\n",
      "2023-12-01 16:12:20,051 INFO     Training average loss at step 44600: 0.006063\n",
      "2023-12-01 16:12:25,517 INFO     Training average positive_sample_loss at step 44700: 0.005352\n",
      "2023-12-01 16:12:25,518 INFO     Training average negative_sample_loss at step 44700: 0.006846\n",
      "2023-12-01 16:12:25,518 INFO     Training average loss at step 44700: 0.006099\n",
      "2023-12-01 16:12:31,000 INFO     Training average positive_sample_loss at step 44800: 0.005355\n",
      "2023-12-01 16:12:31,000 INFO     Training average negative_sample_loss at step 44800: 0.007695\n",
      "2023-12-01 16:12:31,000 INFO     Training average loss at step 44800: 0.006525\n",
      "2023-12-01 16:12:37,140 INFO     Training average positive_sample_loss at step 44900: 0.005329\n",
      "2023-12-01 16:12:37,140 INFO     Training average negative_sample_loss at step 44900: 0.007811\n",
      "2023-12-01 16:12:37,140 INFO     Training average loss at step 44900: 0.006570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:12:42,608 INFO     Training average positive_sample_loss at step 45000: 0.005236\n",
      "2023-12-01 16:12:42,608 INFO     Training average negative_sample_loss at step 45000: 0.006767\n",
      "2023-12-01 16:12:42,608 INFO     Training average loss at step 45000: 0.006001\n",
      "2023-12-01 16:12:48,049 INFO     Training average positive_sample_loss at step 45100: 0.005293\n",
      "2023-12-01 16:12:48,050 INFO     Training average negative_sample_loss at step 45100: 0.007309\n",
      "2023-12-01 16:12:48,050 INFO     Training average loss at step 45100: 0.006301\n",
      "2023-12-01 16:12:53,491 INFO     Training average positive_sample_loss at step 45200: 0.005292\n",
      "2023-12-01 16:12:53,491 INFO     Training average negative_sample_loss at step 45200: 0.007491\n",
      "2023-12-01 16:12:53,491 INFO     Training average loss at step 45200: 0.006391\n",
      "2023-12-01 16:12:58,932 INFO     Training average positive_sample_loss at step 45300: 0.005355\n",
      "2023-12-01 16:12:58,932 INFO     Training average negative_sample_loss at step 45300: 0.007260\n",
      "2023-12-01 16:12:58,932 INFO     Training average loss at step 45300: 0.006307\n",
      "2023-12-01 16:13:04,386 INFO     Training average positive_sample_loss at step 45400: 0.005401\n",
      "2023-12-01 16:13:04,386 INFO     Training average negative_sample_loss at step 45400: 0.006633\n",
      "2023-12-01 16:13:04,386 INFO     Training average loss at step 45400: 0.006017\n",
      "2023-12-01 16:13:10,472 INFO     Training average positive_sample_loss at step 45500: 0.005225\n",
      "2023-12-01 16:13:10,472 INFO     Training average negative_sample_loss at step 45500: 0.007750\n",
      "2023-12-01 16:13:10,472 INFO     Training average loss at step 45500: 0.006488\n",
      "2023-12-01 16:13:15,941 INFO     Training average positive_sample_loss at step 45600: 0.005294\n",
      "2023-12-01 16:13:15,942 INFO     Training average negative_sample_loss at step 45600: 0.006972\n",
      "2023-12-01 16:13:15,942 INFO     Training average loss at step 45600: 0.006133\n",
      "2023-12-01 16:13:21,426 INFO     Training average positive_sample_loss at step 45700: 0.005242\n",
      "2023-12-01 16:13:21,427 INFO     Training average negative_sample_loss at step 45700: 0.006603\n",
      "2023-12-01 16:13:21,427 INFO     Training average loss at step 45700: 0.005922\n",
      "2023-12-01 16:13:26,924 INFO     Training average positive_sample_loss at step 45800: 0.005330\n",
      "2023-12-01 16:13:26,924 INFO     Training average negative_sample_loss at step 45800: 0.007070\n",
      "2023-12-01 16:13:26,924 INFO     Training average loss at step 45800: 0.006200\n",
      "2023-12-01 16:13:32,431 INFO     Training average positive_sample_loss at step 45900: 0.005353\n",
      "2023-12-01 16:13:32,431 INFO     Training average negative_sample_loss at step 45900: 0.007029\n",
      "2023-12-01 16:13:32,431 INFO     Training average loss at step 45900: 0.006191\n",
      "2023-12-01 16:13:38,486 INFO     Training average positive_sample_loss at step 46000: 0.005346\n",
      "2023-12-01 16:13:38,486 INFO     Training average negative_sample_loss at step 46000: 0.006182\n",
      "2023-12-01 16:13:38,486 INFO     Training average loss at step 46000: 0.005764\n",
      "2023-12-01 16:13:43,929 INFO     Training average positive_sample_loss at step 46100: 0.005241\n",
      "2023-12-01 16:13:43,929 INFO     Training average negative_sample_loss at step 46100: 0.006995\n",
      "2023-12-01 16:13:43,929 INFO     Training average loss at step 46100: 0.006118\n",
      "2023-12-01 16:13:49,382 INFO     Training average positive_sample_loss at step 46200: 0.005280\n",
      "2023-12-01 16:13:49,382 INFO     Training average negative_sample_loss at step 46200: 0.007378\n",
      "2023-12-01 16:13:49,382 INFO     Training average loss at step 46200: 0.006329\n",
      "2023-12-01 16:13:54,846 INFO     Training average positive_sample_loss at step 46300: 0.005295\n",
      "2023-12-01 16:13:54,846 INFO     Training average negative_sample_loss at step 46300: 0.007133\n",
      "2023-12-01 16:13:54,847 INFO     Training average loss at step 46300: 0.006214\n",
      "2023-12-01 16:14:00,280 INFO     Training average positive_sample_loss at step 46400: 0.005382\n",
      "2023-12-01 16:14:00,280 INFO     Training average negative_sample_loss at step 46400: 0.008021\n",
      "2023-12-01 16:14:00,281 INFO     Training average loss at step 46400: 0.006701\n",
      "2023-12-01 16:14:05,710 INFO     Training average positive_sample_loss at step 46500: 0.005358\n",
      "2023-12-01 16:14:05,710 INFO     Training average negative_sample_loss at step 46500: 0.006973\n",
      "2023-12-01 16:14:05,710 INFO     Training average loss at step 46500: 0.006166\n",
      "2023-12-01 16:14:11,682 INFO     Training average positive_sample_loss at step 46600: 0.005245\n",
      "2023-12-01 16:14:11,682 INFO     Training average negative_sample_loss at step 46600: 0.006847\n",
      "2023-12-01 16:14:11,682 INFO     Training average loss at step 46600: 0.006046\n",
      "2023-12-01 16:14:17,127 INFO     Training average positive_sample_loss at step 46700: 0.005257\n",
      "2023-12-01 16:14:17,127 INFO     Training average negative_sample_loss at step 46700: 0.007134\n",
      "2023-12-01 16:14:17,127 INFO     Training average loss at step 46700: 0.006195\n",
      "2023-12-01 16:14:22,586 INFO     Training average positive_sample_loss at step 46800: 0.005311\n",
      "2023-12-01 16:14:22,586 INFO     Training average negative_sample_loss at step 46800: 0.006882\n",
      "2023-12-01 16:14:22,586 INFO     Training average loss at step 46800: 0.006096\n",
      "2023-12-01 16:14:28,050 INFO     Training average positive_sample_loss at step 46900: 0.005308\n",
      "2023-12-01 16:14:28,050 INFO     Training average negative_sample_loss at step 46900: 0.007384\n",
      "2023-12-01 16:14:28,050 INFO     Training average loss at step 46900: 0.006346\n",
      "2023-12-01 16:14:33,531 INFO     Training average positive_sample_loss at step 47000: 0.005382\n",
      "2023-12-01 16:14:33,532 INFO     Training average negative_sample_loss at step 47000: 0.007856\n",
      "2023-12-01 16:14:33,532 INFO     Training average loss at step 47000: 0.006619\n",
      "2023-12-01 16:14:39,579 INFO     Training average positive_sample_loss at step 47100: 0.005334\n",
      "2023-12-01 16:14:39,579 INFO     Training average negative_sample_loss at step 47100: 0.006710\n",
      "2023-12-01 16:14:39,579 INFO     Training average loss at step 47100: 0.006022\n",
      "2023-12-01 16:14:44,980 INFO     Training average positive_sample_loss at step 47200: 0.005215\n",
      "2023-12-01 16:14:44,980 INFO     Training average negative_sample_loss at step 47200: 0.006554\n",
      "2023-12-01 16:14:44,980 INFO     Training average loss at step 47200: 0.005885\n",
      "2023-12-01 16:14:50,396 INFO     Training average positive_sample_loss at step 47300: 0.005270\n",
      "2023-12-01 16:14:50,396 INFO     Training average negative_sample_loss at step 47300: 0.007585\n",
      "2023-12-01 16:14:50,396 INFO     Training average loss at step 47300: 0.006428\n",
      "2023-12-01 16:14:55,830 INFO     Training average positive_sample_loss at step 47400: 0.005310\n",
      "2023-12-01 16:14:55,830 INFO     Training average negative_sample_loss at step 47400: 0.007386\n",
      "2023-12-01 16:14:55,830 INFO     Training average loss at step 47400: 0.006348\n",
      "2023-12-01 16:15:01,282 INFO     Training average positive_sample_loss at step 47500: 0.005361\n",
      "2023-12-01 16:15:01,282 INFO     Training average negative_sample_loss at step 47500: 0.007325\n",
      "2023-12-01 16:15:01,283 INFO     Training average loss at step 47500: 0.006343\n",
      "2023-12-01 16:15:06,735 INFO     Training average positive_sample_loss at step 47600: 0.005353\n",
      "2023-12-01 16:15:06,736 INFO     Training average negative_sample_loss at step 47600: 0.006947\n",
      "2023-12-01 16:15:06,736 INFO     Training average loss at step 47600: 0.006150\n",
      "2023-12-01 16:15:12,739 INFO     Training average positive_sample_loss at step 47700: 0.005248\n",
      "2023-12-01 16:15:12,739 INFO     Training average negative_sample_loss at step 47700: 0.007066\n",
      "2023-12-01 16:15:12,739 INFO     Training average loss at step 47700: 0.006157\n",
      "2023-12-01 16:15:18,150 INFO     Training average positive_sample_loss at step 47800: 0.005218\n",
      "2023-12-01 16:15:18,150 INFO     Training average negative_sample_loss at step 47800: 0.007574\n",
      "2023-12-01 16:15:18,150 INFO     Training average loss at step 47800: 0.006396\n",
      "2023-12-01 16:15:23,577 INFO     Training average positive_sample_loss at step 47900: 0.005299\n",
      "2023-12-01 16:15:23,578 INFO     Training average negative_sample_loss at step 47900: 0.006695\n",
      "2023-12-01 16:15:23,578 INFO     Training average loss at step 47900: 0.005997\n",
      "2023-12-01 16:15:29,005 INFO     Training average positive_sample_loss at step 48000: 0.005321\n",
      "2023-12-01 16:15:29,006 INFO     Training average negative_sample_loss at step 48000: 0.006774\n",
      "2023-12-01 16:15:29,006 INFO     Training average loss at step 48000: 0.006047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:15:34,438 INFO     Training average positive_sample_loss at step 48100: 0.005386\n",
      "2023-12-01 16:15:34,439 INFO     Training average negative_sample_loss at step 48100: 0.007081\n",
      "2023-12-01 16:15:34,439 INFO     Training average loss at step 48100: 0.006233\n",
      "2023-12-01 16:15:40,432 INFO     Training average positive_sample_loss at step 48200: 0.005359\n",
      "2023-12-01 16:15:40,433 INFO     Training average negative_sample_loss at step 48200: 0.007345\n",
      "2023-12-01 16:15:40,433 INFO     Training average loss at step 48200: 0.006352\n",
      "2023-12-01 16:15:45,852 INFO     Training average positive_sample_loss at step 48300: 0.005239\n",
      "2023-12-01 16:15:45,853 INFO     Training average negative_sample_loss at step 48300: 0.006309\n",
      "2023-12-01 16:15:45,853 INFO     Training average loss at step 48300: 0.005774\n",
      "2023-12-01 16:15:51,290 INFO     Training average positive_sample_loss at step 48400: 0.005258\n",
      "2023-12-01 16:15:51,290 INFO     Training average negative_sample_loss at step 48400: 0.006872\n",
      "2023-12-01 16:15:51,290 INFO     Training average loss at step 48400: 0.006065\n",
      "2023-12-01 16:15:56,805 INFO     Training average positive_sample_loss at step 48500: 0.005299\n",
      "2023-12-01 16:15:56,805 INFO     Training average negative_sample_loss at step 48500: 0.007628\n",
      "2023-12-01 16:15:56,805 INFO     Training average loss at step 48500: 0.006464\n",
      "2023-12-01 16:16:02,417 INFO     Training average positive_sample_loss at step 48600: 0.005319\n",
      "2023-12-01 16:16:02,418 INFO     Training average negative_sample_loss at step 48600: 0.006857\n",
      "2023-12-01 16:16:02,418 INFO     Training average loss at step 48600: 0.006088\n",
      "2023-12-01 16:16:07,880 INFO     Training average positive_sample_loss at step 48700: 0.005355\n",
      "2023-12-01 16:16:07,881 INFO     Training average negative_sample_loss at step 48700: 0.007083\n",
      "2023-12-01 16:16:07,881 INFO     Training average loss at step 48700: 0.006219\n",
      "2023-12-01 16:16:13,879 INFO     Training average positive_sample_loss at step 48800: 0.005306\n",
      "2023-12-01 16:16:13,880 INFO     Training average negative_sample_loss at step 48800: 0.006929\n",
      "2023-12-01 16:16:13,880 INFO     Training average loss at step 48800: 0.006117\n",
      "2023-12-01 16:16:19,324 INFO     Training average positive_sample_loss at step 48900: 0.005250\n",
      "2023-12-01 16:16:19,324 INFO     Training average negative_sample_loss at step 48900: 0.006907\n",
      "2023-12-01 16:16:19,324 INFO     Training average loss at step 48900: 0.006079\n",
      "2023-12-01 16:16:24,782 INFO     Training average positive_sample_loss at step 49000: 0.005299\n",
      "2023-12-01 16:16:24,782 INFO     Training average negative_sample_loss at step 49000: 0.007013\n",
      "2023-12-01 16:16:24,782 INFO     Training average loss at step 49000: 0.006156\n",
      "2023-12-01 16:16:30,273 INFO     Training average positive_sample_loss at step 49100: 0.005298\n",
      "2023-12-01 16:16:30,274 INFO     Training average negative_sample_loss at step 49100: 0.007028\n",
      "2023-12-01 16:16:30,274 INFO     Training average loss at step 49100: 0.006163\n",
      "2023-12-01 16:16:35,733 INFO     Training average positive_sample_loss at step 49200: 0.005350\n",
      "2023-12-01 16:16:35,734 INFO     Training average negative_sample_loss at step 49200: 0.007615\n",
      "2023-12-01 16:16:35,734 INFO     Training average loss at step 49200: 0.006483\n",
      "2023-12-01 16:16:41,217 INFO     Training average positive_sample_loss at step 49300: 0.005369\n",
      "2023-12-01 16:16:41,218 INFO     Training average negative_sample_loss at step 49300: 0.006482\n",
      "2023-12-01 16:16:41,218 INFO     Training average loss at step 49300: 0.005925\n",
      "2023-12-01 16:16:47,206 INFO     Training average positive_sample_loss at step 49400: 0.005231\n",
      "2023-12-01 16:16:47,206 INFO     Training average negative_sample_loss at step 49400: 0.008063\n",
      "2023-12-01 16:16:47,206 INFO     Training average loss at step 49400: 0.006647\n",
      "2023-12-01 16:16:52,648 INFO     Training average positive_sample_loss at step 49500: 0.005263\n",
      "2023-12-01 16:16:52,649 INFO     Training average negative_sample_loss at step 49500: 0.006880\n",
      "2023-12-01 16:16:52,649 INFO     Training average loss at step 49500: 0.006072\n",
      "2023-12-01 16:16:58,102 INFO     Training average positive_sample_loss at step 49600: 0.005279\n",
      "2023-12-01 16:16:58,102 INFO     Training average negative_sample_loss at step 49600: 0.007225\n",
      "2023-12-01 16:16:58,102 INFO     Training average loss at step 49600: 0.006252\n",
      "2023-12-01 16:17:03,547 INFO     Training average positive_sample_loss at step 49700: 0.005333\n",
      "2023-12-01 16:17:03,548 INFO     Training average negative_sample_loss at step 49700: 0.007275\n",
      "2023-12-01 16:17:03,548 INFO     Training average loss at step 49700: 0.006304\n",
      "2023-12-01 16:17:08,974 INFO     Training average positive_sample_loss at step 49800: 0.005413\n",
      "2023-12-01 16:17:08,974 INFO     Training average negative_sample_loss at step 49800: 0.006235\n",
      "2023-12-01 16:17:08,974 INFO     Training average loss at step 49800: 0.005824\n",
      "2023-12-01 16:17:15,052 INFO     Training average positive_sample_loss at step 49900: 0.005327\n",
      "2023-12-01 16:17:15,053 INFO     Training average negative_sample_loss at step 49900: 0.008136\n",
      "2023-12-01 16:17:15,053 INFO     Training average loss at step 49900: 0.006732\n",
      "2023-12-01 16:17:35,266 INFO     Training average positive_sample_loss at step 50000: 0.005256\n",
      "2023-12-01 16:17:35,267 INFO     Training average negative_sample_loss at step 50000: 0.007035\n",
      "2023-12-01 16:17:35,267 INFO     Training average loss at step 50000: 0.006145\n",
      "2023-12-01 16:17:35,267 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 16:17:36,100 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 16:18:08,953 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 16:18:16,120 INFO     Valid MRR at step 50000: 0.949943\n",
      "2023-12-01 16:18:16,121 INFO     Valid MR at step 50000: 318.674600\n",
      "2023-12-01 16:18:16,121 INFO     Valid HITS@1 at step 50000: 0.945200\n",
      "2023-12-01 16:18:16,121 INFO     Valid HITS@3 at step 50000: 0.952000\n",
      "2023-12-01 16:18:16,121 INFO     Valid HITS@10 at step 50000: 0.957800\n",
      "2023-12-01 16:18:21,587 INFO     Training average positive_sample_loss at step 50100: 0.005315\n",
      "2023-12-01 16:18:21,587 INFO     Training average negative_sample_loss at step 50100: 0.006442\n",
      "2023-12-01 16:18:21,588 INFO     Training average loss at step 50100: 0.005879\n",
      "2023-12-01 16:18:27,046 INFO     Training average positive_sample_loss at step 50200: 0.005318\n",
      "2023-12-01 16:18:27,047 INFO     Training average negative_sample_loss at step 50200: 0.006611\n",
      "2023-12-01 16:18:27,047 INFO     Training average loss at step 50200: 0.005964\n",
      "2023-12-01 16:18:32,491 INFO     Training average positive_sample_loss at step 50300: 0.005389\n",
      "2023-12-01 16:18:32,491 INFO     Training average negative_sample_loss at step 50300: 0.006249\n",
      "2023-12-01 16:18:32,491 INFO     Training average loss at step 50300: 0.005819\n",
      "2023-12-01 16:18:37,983 INFO     Training average positive_sample_loss at step 50400: 0.005319\n",
      "2023-12-01 16:18:37,983 INFO     Training average negative_sample_loss at step 50400: 0.007113\n",
      "2023-12-01 16:18:37,983 INFO     Training average loss at step 50400: 0.006216\n",
      "2023-12-01 16:18:43,932 INFO     Training average positive_sample_loss at step 50500: 0.005311\n",
      "2023-12-01 16:18:43,932 INFO     Training average negative_sample_loss at step 50500: 0.007014\n",
      "2023-12-01 16:18:43,932 INFO     Training average loss at step 50500: 0.006162\n",
      "2023-12-01 16:18:49,396 INFO     Training average positive_sample_loss at step 50600: 0.005248\n",
      "2023-12-01 16:18:49,397 INFO     Training average negative_sample_loss at step 50600: 0.006846\n",
      "2023-12-01 16:18:49,397 INFO     Training average loss at step 50600: 0.006047\n",
      "2023-12-01 16:18:54,840 INFO     Training average positive_sample_loss at step 50700: 0.005289\n",
      "2023-12-01 16:18:54,841 INFO     Training average negative_sample_loss at step 50700: 0.007047\n",
      "2023-12-01 16:18:54,841 INFO     Training average loss at step 50700: 0.006168\n",
      "2023-12-01 16:19:00,300 INFO     Training average positive_sample_loss at step 50800: 0.005289\n",
      "2023-12-01 16:19:00,300 INFO     Training average negative_sample_loss at step 50800: 0.006938\n",
      "2023-12-01 16:19:00,300 INFO     Training average loss at step 50800: 0.006114\n",
      "2023-12-01 16:19:05,762 INFO     Training average positive_sample_loss at step 50900: 0.005391\n",
      "2023-12-01 16:19:05,763 INFO     Training average negative_sample_loss at step 50900: 0.006858\n",
      "2023-12-01 16:19:05,763 INFO     Training average loss at step 50900: 0.006125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:19:11,746 INFO     Training average positive_sample_loss at step 51000: 0.005327\n",
      "2023-12-01 16:19:11,747 INFO     Training average negative_sample_loss at step 51000: 0.007324\n",
      "2023-12-01 16:19:11,747 INFO     Training average loss at step 51000: 0.006326\n",
      "2023-12-01 16:19:17,174 INFO     Training average positive_sample_loss at step 51100: 0.005250\n",
      "2023-12-01 16:19:17,174 INFO     Training average negative_sample_loss at step 51100: 0.007335\n",
      "2023-12-01 16:19:17,174 INFO     Training average loss at step 51100: 0.006292\n",
      "2023-12-01 16:19:22,621 INFO     Training average positive_sample_loss at step 51200: 0.005313\n",
      "2023-12-01 16:19:22,621 INFO     Training average negative_sample_loss at step 51200: 0.007316\n",
      "2023-12-01 16:19:22,621 INFO     Training average loss at step 51200: 0.006315\n",
      "2023-12-01 16:19:28,094 INFO     Training average positive_sample_loss at step 51300: 0.005293\n",
      "2023-12-01 16:19:28,094 INFO     Training average negative_sample_loss at step 51300: 0.006959\n",
      "2023-12-01 16:19:28,094 INFO     Training average loss at step 51300: 0.006126\n",
      "2023-12-01 16:19:33,566 INFO     Training average positive_sample_loss at step 51400: 0.005374\n",
      "2023-12-01 16:19:33,566 INFO     Training average negative_sample_loss at step 51400: 0.007554\n",
      "2023-12-01 16:19:33,566 INFO     Training average loss at step 51400: 0.006464\n",
      "2023-12-01 16:19:39,030 INFO     Training average positive_sample_loss at step 51500: 0.005355\n",
      "2023-12-01 16:19:39,031 INFO     Training average negative_sample_loss at step 51500: 0.007430\n",
      "2023-12-01 16:19:39,031 INFO     Training average loss at step 51500: 0.006393\n",
      "2023-12-01 16:19:45,048 INFO     Training average positive_sample_loss at step 51600: 0.005237\n",
      "2023-12-01 16:19:45,048 INFO     Training average negative_sample_loss at step 51600: 0.006632\n",
      "2023-12-01 16:19:45,048 INFO     Training average loss at step 51600: 0.005934\n",
      "2023-12-01 16:19:50,531 INFO     Training average positive_sample_loss at step 51700: 0.005245\n",
      "2023-12-01 16:19:50,532 INFO     Training average negative_sample_loss at step 51700: 0.006580\n",
      "2023-12-01 16:19:50,532 INFO     Training average loss at step 51700: 0.005912\n",
      "2023-12-01 16:19:56,029 INFO     Training average positive_sample_loss at step 51800: 0.005332\n",
      "2023-12-01 16:19:56,030 INFO     Training average negative_sample_loss at step 51800: 0.007394\n",
      "2023-12-01 16:19:56,030 INFO     Training average loss at step 51800: 0.006363\n",
      "2023-12-01 16:20:01,722 INFO     Training average positive_sample_loss at step 51900: 0.005314\n",
      "2023-12-01 16:20:01,723 INFO     Training average negative_sample_loss at step 51900: 0.007923\n",
      "2023-12-01 16:20:01,723 INFO     Training average loss at step 51900: 0.006619\n",
      "2023-12-01 16:20:07,206 INFO     Training average positive_sample_loss at step 52000: 0.005342\n",
      "2023-12-01 16:20:07,206 INFO     Training average negative_sample_loss at step 52000: 0.006876\n",
      "2023-12-01 16:20:07,206 INFO     Training average loss at step 52000: 0.006109\n",
      "2023-12-01 16:20:13,246 INFO     Training average positive_sample_loss at step 52100: 0.005372\n",
      "2023-12-01 16:20:13,247 INFO     Training average negative_sample_loss at step 52100: 0.007446\n",
      "2023-12-01 16:20:13,247 INFO     Training average loss at step 52100: 0.006409\n",
      "2023-12-01 16:20:18,696 INFO     Training average positive_sample_loss at step 52200: 0.005246\n",
      "2023-12-01 16:20:18,696 INFO     Training average negative_sample_loss at step 52200: 0.006990\n",
      "2023-12-01 16:20:18,696 INFO     Training average loss at step 52200: 0.006118\n",
      "2023-12-01 16:20:24,148 INFO     Training average positive_sample_loss at step 52300: 0.005223\n",
      "2023-12-01 16:20:24,148 INFO     Training average negative_sample_loss at step 52300: 0.006306\n",
      "2023-12-01 16:20:24,148 INFO     Training average loss at step 52300: 0.005765\n",
      "2023-12-01 16:20:29,599 INFO     Training average positive_sample_loss at step 52400: 0.005323\n",
      "2023-12-01 16:20:29,599 INFO     Training average negative_sample_loss at step 52400: 0.006852\n",
      "2023-12-01 16:20:29,599 INFO     Training average loss at step 52400: 0.006088\n",
      "2023-12-01 16:20:35,023 INFO     Training average positive_sample_loss at step 52500: 0.005370\n",
      "2023-12-01 16:20:35,023 INFO     Training average negative_sample_loss at step 52500: 0.007316\n",
      "2023-12-01 16:20:35,023 INFO     Training average loss at step 52500: 0.006343\n",
      "2023-12-01 16:20:40,419 INFO     Training average positive_sample_loss at step 52600: 0.005389\n",
      "2023-12-01 16:20:40,419 INFO     Training average negative_sample_loss at step 52600: 0.006882\n",
      "2023-12-01 16:20:40,419 INFO     Training average loss at step 52600: 0.006135\n",
      "2023-12-01 16:20:46,411 INFO     Training average positive_sample_loss at step 52700: 0.005283\n",
      "2023-12-01 16:20:46,411 INFO     Training average negative_sample_loss at step 52700: 0.007264\n",
      "2023-12-01 16:20:46,412 INFO     Training average loss at step 52700: 0.006274\n",
      "2023-12-01 16:20:51,843 INFO     Training average positive_sample_loss at step 52800: 0.005314\n",
      "2023-12-01 16:20:51,844 INFO     Training average negative_sample_loss at step 52800: 0.006634\n",
      "2023-12-01 16:20:51,844 INFO     Training average loss at step 52800: 0.005974\n",
      "2023-12-01 16:20:57,282 INFO     Training average positive_sample_loss at step 52900: 0.005301\n",
      "2023-12-01 16:20:57,282 INFO     Training average negative_sample_loss at step 52900: 0.006928\n",
      "2023-12-01 16:20:57,282 INFO     Training average loss at step 52900: 0.006114\n",
      "2023-12-01 16:21:02,744 INFO     Training average positive_sample_loss at step 53000: 0.005295\n",
      "2023-12-01 16:21:02,745 INFO     Training average negative_sample_loss at step 53000: 0.006839\n",
      "2023-12-01 16:21:02,745 INFO     Training average loss at step 53000: 0.006067\n",
      "2023-12-01 16:21:08,167 INFO     Training average positive_sample_loss at step 53100: 0.005335\n",
      "2023-12-01 16:21:08,167 INFO     Training average negative_sample_loss at step 53100: 0.006266\n",
      "2023-12-01 16:21:08,167 INFO     Training average loss at step 53100: 0.005801\n",
      "2023-12-01 16:21:14,162 INFO     Training average positive_sample_loss at step 53200: 0.005282\n",
      "2023-12-01 16:21:14,162 INFO     Training average negative_sample_loss at step 53200: 0.007297\n",
      "2023-12-01 16:21:14,162 INFO     Training average loss at step 53200: 0.006289\n",
      "2023-12-01 16:21:19,620 INFO     Training average positive_sample_loss at step 53300: 0.005291\n",
      "2023-12-01 16:21:19,620 INFO     Training average negative_sample_loss at step 53300: 0.007624\n",
      "2023-12-01 16:21:19,621 INFO     Training average loss at step 53300: 0.006457\n",
      "2023-12-01 16:21:25,062 INFO     Training average positive_sample_loss at step 53400: 0.005267\n",
      "2023-12-01 16:21:25,062 INFO     Training average negative_sample_loss at step 53400: 0.006431\n",
      "2023-12-01 16:21:25,062 INFO     Training average loss at step 53400: 0.005849\n",
      "2023-12-01 16:21:30,491 INFO     Training average positive_sample_loss at step 53500: 0.005270\n",
      "2023-12-01 16:21:30,491 INFO     Training average negative_sample_loss at step 53500: 0.007470\n",
      "2023-12-01 16:21:30,491 INFO     Training average loss at step 53500: 0.006370\n",
      "2023-12-01 16:21:35,968 INFO     Training average positive_sample_loss at step 53600: 0.005319\n",
      "2023-12-01 16:21:35,968 INFO     Training average negative_sample_loss at step 53600: 0.006760\n",
      "2023-12-01 16:21:35,968 INFO     Training average loss at step 53600: 0.006039\n",
      "2023-12-01 16:21:41,385 INFO     Training average positive_sample_loss at step 53700: 0.005401\n",
      "2023-12-01 16:21:41,385 INFO     Training average negative_sample_loss at step 53700: 0.006826\n",
      "2023-12-01 16:21:41,385 INFO     Training average loss at step 53700: 0.006114\n",
      "2023-12-01 16:21:47,381 INFO     Training average positive_sample_loss at step 53800: 0.005302\n",
      "2023-12-01 16:21:47,381 INFO     Training average negative_sample_loss at step 53800: 0.006963\n",
      "2023-12-01 16:21:47,381 INFO     Training average loss at step 53800: 0.006132\n",
      "2023-12-01 16:21:52,819 INFO     Training average positive_sample_loss at step 53900: 0.005272\n",
      "2023-12-01 16:21:52,820 INFO     Training average negative_sample_loss at step 53900: 0.006926\n",
      "2023-12-01 16:21:52,820 INFO     Training average loss at step 53900: 0.006099\n",
      "2023-12-01 16:21:58,312 INFO     Training average positive_sample_loss at step 54000: 0.005310\n",
      "2023-12-01 16:21:58,312 INFO     Training average negative_sample_loss at step 54000: 0.006614\n",
      "2023-12-01 16:21:58,312 INFO     Training average loss at step 54000: 0.005962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:22:03,821 INFO     Training average positive_sample_loss at step 54100: 0.005282\n",
      "2023-12-01 16:22:03,822 INFO     Training average negative_sample_loss at step 54100: 0.007638\n",
      "2023-12-01 16:22:03,822 INFO     Training average loss at step 54100: 0.006460\n",
      "2023-12-01 16:22:09,259 INFO     Training average positive_sample_loss at step 54200: 0.005373\n",
      "2023-12-01 16:22:09,259 INFO     Training average negative_sample_loss at step 54200: 0.006859\n",
      "2023-12-01 16:22:09,259 INFO     Training average loss at step 54200: 0.006116\n",
      "2023-12-01 16:22:15,191 INFO     Training average positive_sample_loss at step 54300: 0.005347\n",
      "2023-12-01 16:22:15,191 INFO     Training average negative_sample_loss at step 54300: 0.006974\n",
      "2023-12-01 16:22:15,191 INFO     Training average loss at step 54300: 0.006161\n",
      "2023-12-01 16:22:20,648 INFO     Training average positive_sample_loss at step 54400: 0.005245\n",
      "2023-12-01 16:22:20,648 INFO     Training average negative_sample_loss at step 54400: 0.007632\n",
      "2023-12-01 16:22:20,649 INFO     Training average loss at step 54400: 0.006439\n",
      "2023-12-01 16:22:26,148 INFO     Training average positive_sample_loss at step 54500: 0.005271\n",
      "2023-12-01 16:22:26,148 INFO     Training average negative_sample_loss at step 54500: 0.006918\n",
      "2023-12-01 16:22:26,148 INFO     Training average loss at step 54500: 0.006095\n",
      "2023-12-01 16:22:31,621 INFO     Training average positive_sample_loss at step 54600: 0.005333\n",
      "2023-12-01 16:22:31,621 INFO     Training average negative_sample_loss at step 54600: 0.006951\n",
      "2023-12-01 16:22:31,621 INFO     Training average loss at step 54600: 0.006142\n",
      "2023-12-01 16:22:37,061 INFO     Training average positive_sample_loss at step 54700: 0.005336\n",
      "2023-12-01 16:22:37,062 INFO     Training average negative_sample_loss at step 54700: 0.006515\n",
      "2023-12-01 16:22:37,062 INFO     Training average loss at step 54700: 0.005926\n",
      "2023-12-01 16:22:42,534 INFO     Training average positive_sample_loss at step 54800: 0.005325\n",
      "2023-12-01 16:22:42,535 INFO     Training average negative_sample_loss at step 54800: 0.006823\n",
      "2023-12-01 16:22:42,535 INFO     Training average loss at step 54800: 0.006074\n",
      "2023-12-01 16:22:48,567 INFO     Training average positive_sample_loss at step 54900: 0.005336\n",
      "2023-12-01 16:22:48,568 INFO     Training average negative_sample_loss at step 54900: 0.006940\n",
      "2023-12-01 16:22:48,568 INFO     Training average loss at step 54900: 0.006138\n",
      "2023-12-01 16:22:54,047 INFO     Training average positive_sample_loss at step 55000: 0.005259\n",
      "2023-12-01 16:22:54,048 INFO     Training average negative_sample_loss at step 55000: 0.006705\n",
      "2023-12-01 16:22:54,048 INFO     Training average loss at step 55000: 0.005982\n",
      "2023-12-01 16:22:59,518 INFO     Training average positive_sample_loss at step 55100: 0.005325\n",
      "2023-12-01 16:22:59,519 INFO     Training average negative_sample_loss at step 55100: 0.006857\n",
      "2023-12-01 16:22:59,519 INFO     Training average loss at step 55100: 0.006091\n",
      "2023-12-01 16:23:04,983 INFO     Training average positive_sample_loss at step 55200: 0.005315\n",
      "2023-12-01 16:23:04,983 INFO     Training average negative_sample_loss at step 55200: 0.007042\n",
      "2023-12-01 16:23:04,983 INFO     Training average loss at step 55200: 0.006178\n",
      "2023-12-01 16:23:10,432 INFO     Training average positive_sample_loss at step 55300: 0.005336\n",
      "2023-12-01 16:23:10,433 INFO     Training average negative_sample_loss at step 55300: 0.006783\n",
      "2023-12-01 16:23:10,433 INFO     Training average loss at step 55300: 0.006059\n",
      "2023-12-01 16:23:16,128 INFO     Training average positive_sample_loss at step 55400: 0.005399\n",
      "2023-12-01 16:23:16,128 INFO     Training average negative_sample_loss at step 55400: 0.007294\n",
      "2023-12-01 16:23:16,128 INFO     Training average loss at step 55400: 0.006346\n",
      "2023-12-01 16:23:21,832 INFO     Training average positive_sample_loss at step 55500: 0.005253\n",
      "2023-12-01 16:23:21,832 INFO     Training average negative_sample_loss at step 55500: 0.006844\n",
      "2023-12-01 16:23:21,832 INFO     Training average loss at step 55500: 0.006049\n",
      "2023-12-01 16:23:27,244 INFO     Training average positive_sample_loss at step 55600: 0.005254\n",
      "2023-12-01 16:23:27,244 INFO     Training average negative_sample_loss at step 55600: 0.006806\n",
      "2023-12-01 16:23:27,245 INFO     Training average loss at step 55600: 0.006030\n",
      "2023-12-01 16:23:32,646 INFO     Training average positive_sample_loss at step 55700: 0.005282\n",
      "2023-12-01 16:23:32,646 INFO     Training average negative_sample_loss at step 55700: 0.007116\n",
      "2023-12-01 16:23:32,647 INFO     Training average loss at step 55700: 0.006199\n",
      "2023-12-01 16:23:38,078 INFO     Training average positive_sample_loss at step 55800: 0.005373\n",
      "2023-12-01 16:23:38,078 INFO     Training average negative_sample_loss at step 55800: 0.006905\n",
      "2023-12-01 16:23:38,078 INFO     Training average loss at step 55800: 0.006139\n",
      "2023-12-01 16:23:43,532 INFO     Training average positive_sample_loss at step 55900: 0.005336\n",
      "2023-12-01 16:23:43,532 INFO     Training average negative_sample_loss at step 55900: 0.007265\n",
      "2023-12-01 16:23:43,532 INFO     Training average loss at step 55900: 0.006300\n",
      "2023-12-01 16:23:49,622 INFO     Training average positive_sample_loss at step 56000: 0.005328\n",
      "2023-12-01 16:23:49,622 INFO     Training average negative_sample_loss at step 56000: 0.006332\n",
      "2023-12-01 16:23:49,622 INFO     Training average loss at step 56000: 0.005830\n",
      "2023-12-01 16:23:55,082 INFO     Training average positive_sample_loss at step 56100: 0.005282\n",
      "2023-12-01 16:23:55,082 INFO     Training average negative_sample_loss at step 56100: 0.007274\n",
      "2023-12-01 16:23:55,082 INFO     Training average loss at step 56100: 0.006278\n",
      "2023-12-01 16:24:00,604 INFO     Training average positive_sample_loss at step 56200: 0.005322\n",
      "2023-12-01 16:24:00,605 INFO     Training average negative_sample_loss at step 56200: 0.007220\n",
      "2023-12-01 16:24:00,605 INFO     Training average loss at step 56200: 0.006271\n",
      "2023-12-01 16:24:06,115 INFO     Training average positive_sample_loss at step 56300: 0.005286\n",
      "2023-12-01 16:24:06,115 INFO     Training average negative_sample_loss at step 56300: 0.007446\n",
      "2023-12-01 16:24:06,115 INFO     Training average loss at step 56300: 0.006366\n",
      "2023-12-01 16:24:11,600 INFO     Training average positive_sample_loss at step 56400: 0.005370\n",
      "2023-12-01 16:24:11,601 INFO     Training average negative_sample_loss at step 56400: 0.006292\n",
      "2023-12-01 16:24:11,601 INFO     Training average loss at step 56400: 0.005831\n",
      "2023-12-01 16:24:17,110 INFO     Training average positive_sample_loss at step 56500: 0.005345\n",
      "2023-12-01 16:24:17,110 INFO     Training average negative_sample_loss at step 56500: 0.006963\n",
      "2023-12-01 16:24:17,110 INFO     Training average loss at step 56500: 0.006154\n",
      "2023-12-01 16:24:23,210 INFO     Training average positive_sample_loss at step 56600: 0.005218\n",
      "2023-12-01 16:24:23,211 INFO     Training average negative_sample_loss at step 56600: 0.007213\n",
      "2023-12-01 16:24:23,211 INFO     Training average loss at step 56600: 0.006216\n",
      "2023-12-01 16:24:28,711 INFO     Training average positive_sample_loss at step 56700: 0.005296\n",
      "2023-12-01 16:24:28,711 INFO     Training average negative_sample_loss at step 56700: 0.006921\n",
      "2023-12-01 16:24:28,712 INFO     Training average loss at step 56700: 0.006109\n",
      "2023-12-01 16:24:34,221 INFO     Training average positive_sample_loss at step 56800: 0.005305\n",
      "2023-12-01 16:24:34,222 INFO     Training average negative_sample_loss at step 56800: 0.007019\n",
      "2023-12-01 16:24:34,222 INFO     Training average loss at step 56800: 0.006162\n",
      "2023-12-01 16:24:39,811 INFO     Training average positive_sample_loss at step 56900: 0.005354\n",
      "2023-12-01 16:24:39,811 INFO     Training average negative_sample_loss at step 56900: 0.007249\n",
      "2023-12-01 16:24:39,811 INFO     Training average loss at step 56900: 0.006301\n",
      "2023-12-01 16:24:45,290 INFO     Training average positive_sample_loss at step 57000: 0.005395\n",
      "2023-12-01 16:24:45,290 INFO     Training average negative_sample_loss at step 57000: 0.006650\n",
      "2023-12-01 16:24:45,290 INFO     Training average loss at step 57000: 0.006023\n",
      "2023-12-01 16:24:51,323 INFO     Training average positive_sample_loss at step 57100: 0.005287\n",
      "2023-12-01 16:24:51,323 INFO     Training average negative_sample_loss at step 57100: 0.006530\n",
      "2023-12-01 16:24:51,323 INFO     Training average loss at step 57100: 0.005909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:24:56,826 INFO     Training average positive_sample_loss at step 57200: 0.005266\n",
      "2023-12-01 16:24:56,827 INFO     Training average negative_sample_loss at step 57200: 0.007027\n",
      "2023-12-01 16:24:56,827 INFO     Training average loss at step 57200: 0.006146\n",
      "2023-12-01 16:25:02,305 INFO     Training average positive_sample_loss at step 57300: 0.005268\n",
      "2023-12-01 16:25:02,305 INFO     Training average negative_sample_loss at step 57300: 0.006334\n",
      "2023-12-01 16:25:02,305 INFO     Training average loss at step 57300: 0.005801\n",
      "2023-12-01 16:25:07,799 INFO     Training average positive_sample_loss at step 57400: 0.005321\n",
      "2023-12-01 16:25:07,799 INFO     Training average negative_sample_loss at step 57400: 0.006978\n",
      "2023-12-01 16:25:07,799 INFO     Training average loss at step 57400: 0.006150\n",
      "2023-12-01 16:25:13,282 INFO     Training average positive_sample_loss at step 57500: 0.005321\n",
      "2023-12-01 16:25:13,282 INFO     Training average negative_sample_loss at step 57500: 0.007002\n",
      "2023-12-01 16:25:13,282 INFO     Training average loss at step 57500: 0.006161\n",
      "2023-12-01 16:25:18,790 INFO     Training average positive_sample_loss at step 57600: 0.005446\n",
      "2023-12-01 16:25:18,791 INFO     Training average negative_sample_loss at step 57600: 0.006713\n",
      "2023-12-01 16:25:18,791 INFO     Training average loss at step 57600: 0.006079\n",
      "2023-12-01 16:25:24,814 INFO     Training average positive_sample_loss at step 57700: 0.005289\n",
      "2023-12-01 16:25:24,815 INFO     Training average negative_sample_loss at step 57700: 0.007202\n",
      "2023-12-01 16:25:24,815 INFO     Training average loss at step 57700: 0.006246\n",
      "2023-12-01 16:25:30,239 INFO     Training average positive_sample_loss at step 57800: 0.005266\n",
      "2023-12-01 16:25:30,239 INFO     Training average negative_sample_loss at step 57800: 0.006587\n",
      "2023-12-01 16:25:30,239 INFO     Training average loss at step 57800: 0.005927\n",
      "2023-12-01 16:25:35,715 INFO     Training average positive_sample_loss at step 57900: 0.005307\n",
      "2023-12-01 16:25:35,716 INFO     Training average negative_sample_loss at step 57900: 0.006681\n",
      "2023-12-01 16:25:35,716 INFO     Training average loss at step 57900: 0.005994\n",
      "2023-12-01 16:25:41,174 INFO     Training average positive_sample_loss at step 58000: 0.005289\n",
      "2023-12-01 16:25:41,174 INFO     Training average negative_sample_loss at step 58000: 0.007301\n",
      "2023-12-01 16:25:41,174 INFO     Training average loss at step 58000: 0.006295\n",
      "2023-12-01 16:25:46,612 INFO     Training average positive_sample_loss at step 58100: 0.005354\n",
      "2023-12-01 16:25:46,613 INFO     Training average negative_sample_loss at step 58100: 0.006611\n",
      "2023-12-01 16:25:46,613 INFO     Training average loss at step 58100: 0.005982\n",
      "2023-12-01 16:25:52,603 INFO     Training average positive_sample_loss at step 58200: 0.005314\n",
      "2023-12-01 16:25:52,604 INFO     Training average negative_sample_loss at step 58200: 0.007091\n",
      "2023-12-01 16:25:52,604 INFO     Training average loss at step 58200: 0.006202\n",
      "2023-12-01 16:25:58,065 INFO     Training average positive_sample_loss at step 58300: 0.005261\n",
      "2023-12-01 16:25:58,066 INFO     Training average negative_sample_loss at step 58300: 0.006596\n",
      "2023-12-01 16:25:58,066 INFO     Training average loss at step 58300: 0.005928\n",
      "2023-12-01 16:26:03,545 INFO     Training average positive_sample_loss at step 58400: 0.005244\n",
      "2023-12-01 16:26:03,545 INFO     Training average negative_sample_loss at step 58400: 0.007396\n",
      "2023-12-01 16:26:03,546 INFO     Training average loss at step 58400: 0.006320\n",
      "2023-12-01 16:26:09,072 INFO     Training average positive_sample_loss at step 58500: 0.005371\n",
      "2023-12-01 16:26:09,073 INFO     Training average negative_sample_loss at step 58500: 0.007296\n",
      "2023-12-01 16:26:09,073 INFO     Training average loss at step 58500: 0.006333\n",
      "2023-12-01 16:26:14,544 INFO     Training average positive_sample_loss at step 58600: 0.005388\n",
      "2023-12-01 16:26:14,544 INFO     Training average negative_sample_loss at step 58600: 0.007201\n",
      "2023-12-01 16:26:14,544 INFO     Training average loss at step 58600: 0.006295\n",
      "2023-12-01 16:26:20,015 INFO     Training average positive_sample_loss at step 58700: 0.005351\n",
      "2023-12-01 16:26:20,015 INFO     Training average negative_sample_loss at step 58700: 0.006562\n",
      "2023-12-01 16:26:20,015 INFO     Training average loss at step 58700: 0.005957\n",
      "2023-12-01 16:26:26,012 INFO     Training average positive_sample_loss at step 58800: 0.005287\n",
      "2023-12-01 16:26:26,013 INFO     Training average negative_sample_loss at step 58800: 0.006719\n",
      "2023-12-01 16:26:26,013 INFO     Training average loss at step 58800: 0.006003\n",
      "2023-12-01 16:26:31,509 INFO     Training average positive_sample_loss at step 58900: 0.005269\n",
      "2023-12-01 16:26:31,510 INFO     Training average negative_sample_loss at step 58900: 0.006725\n",
      "2023-12-01 16:26:31,510 INFO     Training average loss at step 58900: 0.005997\n",
      "2023-12-01 16:26:36,975 INFO     Training average positive_sample_loss at step 59000: 0.005280\n",
      "2023-12-01 16:26:36,976 INFO     Training average negative_sample_loss at step 59000: 0.007035\n",
      "2023-12-01 16:26:36,976 INFO     Training average loss at step 59000: 0.006158\n",
      "2023-12-01 16:26:42,427 INFO     Training average positive_sample_loss at step 59100: 0.005363\n",
      "2023-12-01 16:26:42,428 INFO     Training average negative_sample_loss at step 59100: 0.006697\n",
      "2023-12-01 16:26:42,428 INFO     Training average loss at step 59100: 0.006030\n",
      "2023-12-01 16:26:47,838 INFO     Training average positive_sample_loss at step 59200: 0.005351\n",
      "2023-12-01 16:26:47,838 INFO     Training average negative_sample_loss at step 59200: 0.006427\n",
      "2023-12-01 16:26:47,838 INFO     Training average loss at step 59200: 0.005889\n",
      "2023-12-01 16:26:53,847 INFO     Training average positive_sample_loss at step 59300: 0.005335\n",
      "2023-12-01 16:26:53,847 INFO     Training average negative_sample_loss at step 59300: 0.006856\n",
      "2023-12-01 16:26:53,847 INFO     Training average loss at step 59300: 0.006096\n",
      "2023-12-01 16:26:59,344 INFO     Training average positive_sample_loss at step 59400: 0.005250\n",
      "2023-12-01 16:26:59,345 INFO     Training average negative_sample_loss at step 59400: 0.006842\n",
      "2023-12-01 16:26:59,345 INFO     Training average loss at step 59400: 0.006046\n",
      "2023-12-01 16:27:04,838 INFO     Training average positive_sample_loss at step 59500: 0.005272\n",
      "2023-12-01 16:27:04,838 INFO     Training average negative_sample_loss at step 59500: 0.006549\n",
      "2023-12-01 16:27:04,838 INFO     Training average loss at step 59500: 0.005911\n",
      "2023-12-01 16:27:10,321 INFO     Training average positive_sample_loss at step 59600: 0.005299\n",
      "2023-12-01 16:27:10,322 INFO     Training average negative_sample_loss at step 59600: 0.006509\n",
      "2023-12-01 16:27:10,322 INFO     Training average loss at step 59600: 0.005904\n",
      "2023-12-01 16:27:15,791 INFO     Training average positive_sample_loss at step 59700: 0.005368\n",
      "2023-12-01 16:27:15,792 INFO     Training average negative_sample_loss at step 59700: 0.006648\n",
      "2023-12-01 16:27:15,792 INFO     Training average loss at step 59700: 0.006008\n",
      "2023-12-01 16:27:21,243 INFO     Training average positive_sample_loss at step 59800: 0.005405\n",
      "2023-12-01 16:27:21,243 INFO     Training average negative_sample_loss at step 59800: 0.007103\n",
      "2023-12-01 16:27:21,243 INFO     Training average loss at step 59800: 0.006254\n",
      "2023-12-01 16:27:27,234 INFO     Training average positive_sample_loss at step 59900: 0.005285\n",
      "2023-12-01 16:27:27,235 INFO     Training average negative_sample_loss at step 59900: 0.007191\n",
      "2023-12-01 16:27:27,235 INFO     Training average loss at step 59900: 0.006238\n",
      "2023-12-01 16:27:41,121 INFO     Training average positive_sample_loss at step 60000: 0.005303\n",
      "2023-12-01 16:27:41,121 INFO     Training average negative_sample_loss at step 60000: 0.006629\n",
      "2023-12-01 16:27:41,121 INFO     Training average loss at step 60000: 0.005966\n",
      "2023-12-01 16:27:41,121 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 16:27:41,763 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 16:28:19,748 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 16:28:28,034 INFO     Valid MRR at step 60000: 0.949800\n",
      "2023-12-01 16:28:28,034 INFO     Valid MR at step 60000: 316.819000\n",
      "2023-12-01 16:28:28,034 INFO     Valid HITS@1 at step 60000: 0.945000\n",
      "2023-12-01 16:28:28,035 INFO     Valid HITS@3 at step 60000: 0.952100\n",
      "2023-12-01 16:28:28,035 INFO     Valid HITS@10 at step 60000: 0.957800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:28:33,556 INFO     Training average positive_sample_loss at step 60100: 0.005246\n",
      "2023-12-01 16:28:33,556 INFO     Training average negative_sample_loss at step 60100: 0.006309\n",
      "2023-12-01 16:28:33,556 INFO     Training average loss at step 60100: 0.005778\n",
      "2023-12-01 16:28:39,025 INFO     Training average positive_sample_loss at step 60200: 0.005378\n",
      "2023-12-01 16:28:39,025 INFO     Training average negative_sample_loss at step 60200: 0.006899\n",
      "2023-12-01 16:28:39,025 INFO     Training average loss at step 60200: 0.006139\n",
      "2023-12-01 16:28:44,518 INFO     Training average positive_sample_loss at step 60300: 0.005307\n",
      "2023-12-01 16:28:44,518 INFO     Training average negative_sample_loss at step 60300: 0.007164\n",
      "2023-12-01 16:28:44,518 INFO     Training average loss at step 60300: 0.006236\n",
      "2023-12-01 16:28:50,662 INFO     Training average positive_sample_loss at step 60400: 0.005353\n",
      "2023-12-01 16:28:50,663 INFO     Training average negative_sample_loss at step 60400: 0.006813\n",
      "2023-12-01 16:28:50,663 INFO     Training average loss at step 60400: 0.006083\n",
      "2023-12-01 16:28:56,117 INFO     Training average positive_sample_loss at step 60500: 0.005236\n",
      "2023-12-01 16:28:56,117 INFO     Training average negative_sample_loss at step 60500: 0.007718\n",
      "2023-12-01 16:28:56,117 INFO     Training average loss at step 60500: 0.006477\n",
      "2023-12-01 16:29:01,590 INFO     Training average positive_sample_loss at step 60600: 0.005315\n",
      "2023-12-01 16:29:01,591 INFO     Training average negative_sample_loss at step 60600: 0.006732\n",
      "2023-12-01 16:29:01,591 INFO     Training average loss at step 60600: 0.006023\n",
      "2023-12-01 16:29:07,062 INFO     Training average positive_sample_loss at step 60700: 0.005333\n",
      "2023-12-01 16:29:07,063 INFO     Training average negative_sample_loss at step 60700: 0.007394\n",
      "2023-12-01 16:29:07,063 INFO     Training average loss at step 60700: 0.006364\n",
      "2023-12-01 16:29:12,535 INFO     Training average positive_sample_loss at step 60800: 0.005317\n",
      "2023-12-01 16:29:12,535 INFO     Training average negative_sample_loss at step 60800: 0.006514\n",
      "2023-12-01 16:29:12,535 INFO     Training average loss at step 60800: 0.005915\n",
      "2023-12-01 16:29:18,019 INFO     Training average positive_sample_loss at step 60900: 0.005362\n",
      "2023-12-01 16:29:18,020 INFO     Training average negative_sample_loss at step 60900: 0.007006\n",
      "2023-12-01 16:29:18,020 INFO     Training average loss at step 60900: 0.006184\n",
      "2023-12-01 16:29:24,053 INFO     Training average positive_sample_loss at step 61000: 0.005293\n",
      "2023-12-01 16:29:24,053 INFO     Training average negative_sample_loss at step 61000: 0.006589\n",
      "2023-12-01 16:29:24,053 INFO     Training average loss at step 61000: 0.005941\n",
      "2023-12-01 16:29:29,536 INFO     Training average positive_sample_loss at step 61100: 0.005255\n",
      "2023-12-01 16:29:29,536 INFO     Training average negative_sample_loss at step 61100: 0.007225\n",
      "2023-12-01 16:29:29,536 INFO     Training average loss at step 61100: 0.006240\n",
      "2023-12-01 16:29:35,025 INFO     Training average positive_sample_loss at step 61200: 0.005301\n",
      "2023-12-01 16:29:35,026 INFO     Training average negative_sample_loss at step 61200: 0.007072\n",
      "2023-12-01 16:29:35,026 INFO     Training average loss at step 61200: 0.006186\n",
      "2023-12-01 16:29:40,537 INFO     Training average positive_sample_loss at step 61300: 0.005376\n",
      "2023-12-01 16:29:40,538 INFO     Training average negative_sample_loss at step 61300: 0.007731\n",
      "2023-12-01 16:29:40,538 INFO     Training average loss at step 61300: 0.006553\n",
      "2023-12-01 16:29:46,044 INFO     Training average positive_sample_loss at step 61400: 0.005329\n",
      "2023-12-01 16:29:46,044 INFO     Training average negative_sample_loss at step 61400: 0.007004\n",
      "2023-12-01 16:29:46,044 INFO     Training average loss at step 61400: 0.006167\n",
      "2023-12-01 16:29:52,092 INFO     Training average positive_sample_loss at step 61500: 0.005337\n",
      "2023-12-01 16:29:52,092 INFO     Training average negative_sample_loss at step 61500: 0.006476\n",
      "2023-12-01 16:29:52,093 INFO     Training average loss at step 61500: 0.005907\n",
      "2023-12-01 16:29:57,640 INFO     Training average positive_sample_loss at step 61600: 0.005235\n",
      "2023-12-01 16:29:57,640 INFO     Training average negative_sample_loss at step 61600: 0.006379\n",
      "2023-12-01 16:29:57,640 INFO     Training average loss at step 61600: 0.005807\n",
      "2023-12-01 16:30:03,097 INFO     Training average positive_sample_loss at step 61700: 0.005282\n",
      "2023-12-01 16:30:03,097 INFO     Training average negative_sample_loss at step 61700: 0.006930\n",
      "2023-12-01 16:30:03,097 INFO     Training average loss at step 61700: 0.006106\n",
      "2023-12-01 16:30:08,552 INFO     Training average positive_sample_loss at step 61800: 0.005299\n",
      "2023-12-01 16:30:08,553 INFO     Training average negative_sample_loss at step 61800: 0.007420\n",
      "2023-12-01 16:30:08,553 INFO     Training average loss at step 61800: 0.006360\n",
      "2023-12-01 16:30:14,003 INFO     Training average positive_sample_loss at step 61900: 0.005330\n",
      "2023-12-01 16:30:14,003 INFO     Training average negative_sample_loss at step 61900: 0.007184\n",
      "2023-12-01 16:30:14,003 INFO     Training average loss at step 61900: 0.006257\n",
      "2023-12-01 16:30:19,458 INFO     Training average positive_sample_loss at step 62000: 0.005376\n",
      "2023-12-01 16:30:19,458 INFO     Training average negative_sample_loss at step 62000: 0.006397\n",
      "2023-12-01 16:30:19,458 INFO     Training average loss at step 62000: 0.005887\n",
      "2023-12-01 16:30:25,443 INFO     Training average positive_sample_loss at step 62100: 0.005355\n",
      "2023-12-01 16:30:25,444 INFO     Training average negative_sample_loss at step 62100: 0.007027\n",
      "2023-12-01 16:30:25,444 INFO     Training average loss at step 62100: 0.006191\n",
      "2023-12-01 16:30:30,867 INFO     Training average positive_sample_loss at step 62200: 0.005229\n",
      "2023-12-01 16:30:30,867 INFO     Training average negative_sample_loss at step 62200: 0.007437\n",
      "2023-12-01 16:30:30,867 INFO     Training average loss at step 62200: 0.006333\n",
      "2023-12-01 16:30:36,285 INFO     Training average positive_sample_loss at step 62300: 0.005325\n",
      "2023-12-01 16:30:36,285 INFO     Training average negative_sample_loss at step 62300: 0.007427\n",
      "2023-12-01 16:30:36,285 INFO     Training average loss at step 62300: 0.006376\n",
      "2023-12-01 16:30:41,715 INFO     Training average positive_sample_loss at step 62400: 0.005344\n",
      "2023-12-01 16:30:41,716 INFO     Training average negative_sample_loss at step 62400: 0.007153\n",
      "2023-12-01 16:30:41,716 INFO     Training average loss at step 62400: 0.006249\n",
      "2023-12-01 16:30:47,146 INFO     Training average positive_sample_loss at step 62500: 0.005375\n",
      "2023-12-01 16:30:47,146 INFO     Training average negative_sample_loss at step 62500: 0.006925\n",
      "2023-12-01 16:30:47,146 INFO     Training average loss at step 62500: 0.006150\n",
      "2023-12-01 16:30:52,608 INFO     Training average positive_sample_loss at step 62600: 0.005341\n",
      "2023-12-01 16:30:52,608 INFO     Training average negative_sample_loss at step 62600: 0.007363\n",
      "2023-12-01 16:30:52,609 INFO     Training average loss at step 62600: 0.006352\n",
      "2023-12-01 16:30:58,689 INFO     Training average positive_sample_loss at step 62700: 0.005287\n",
      "2023-12-01 16:30:58,689 INFO     Training average negative_sample_loss at step 62700: 0.007003\n",
      "2023-12-01 16:30:58,689 INFO     Training average loss at step 62700: 0.006145\n",
      "2023-12-01 16:31:04,149 INFO     Training average positive_sample_loss at step 62800: 0.005250\n",
      "2023-12-01 16:31:04,150 INFO     Training average negative_sample_loss at step 62800: 0.006698\n",
      "2023-12-01 16:31:04,150 INFO     Training average loss at step 62800: 0.005974\n",
      "2023-12-01 16:31:09,655 INFO     Training average positive_sample_loss at step 62900: 0.005345\n",
      "2023-12-01 16:31:09,655 INFO     Training average negative_sample_loss at step 62900: 0.007139\n",
      "2023-12-01 16:31:09,655 INFO     Training average loss at step 62900: 0.006242\n",
      "2023-12-01 16:31:15,132 INFO     Training average positive_sample_loss at step 63000: 0.005319\n",
      "2023-12-01 16:31:15,132 INFO     Training average negative_sample_loss at step 63000: 0.007003\n",
      "2023-12-01 16:31:15,132 INFO     Training average loss at step 63000: 0.006161\n",
      "2023-12-01 16:31:20,579 INFO     Training average positive_sample_loss at step 63100: 0.005349\n",
      "2023-12-01 16:31:20,579 INFO     Training average negative_sample_loss at step 63100: 0.006847\n",
      "2023-12-01 16:31:20,580 INFO     Training average loss at step 63100: 0.006098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:31:26,581 INFO     Training average positive_sample_loss at step 63200: 0.005311\n",
      "2023-12-01 16:31:26,582 INFO     Training average negative_sample_loss at step 63200: 0.006633\n",
      "2023-12-01 16:31:26,582 INFO     Training average loss at step 63200: 0.005972\n",
      "2023-12-01 16:31:32,063 INFO     Training average positive_sample_loss at step 63300: 0.005228\n",
      "2023-12-01 16:31:32,063 INFO     Training average negative_sample_loss at step 63300: 0.006112\n",
      "2023-12-01 16:31:32,063 INFO     Training average loss at step 63300: 0.005670\n",
      "2023-12-01 16:31:37,546 INFO     Training average positive_sample_loss at step 63400: 0.005317\n",
      "2023-12-01 16:31:37,547 INFO     Training average negative_sample_loss at step 63400: 0.007325\n",
      "2023-12-01 16:31:37,547 INFO     Training average loss at step 63400: 0.006321\n",
      "2023-12-01 16:31:43,015 INFO     Training average positive_sample_loss at step 63500: 0.005386\n",
      "2023-12-01 16:31:43,015 INFO     Training average negative_sample_loss at step 63500: 0.007197\n",
      "2023-12-01 16:31:43,015 INFO     Training average loss at step 63500: 0.006291\n",
      "2023-12-01 16:31:48,500 INFO     Training average positive_sample_loss at step 63600: 0.005345\n",
      "2023-12-01 16:31:48,500 INFO     Training average negative_sample_loss at step 63600: 0.006947\n",
      "2023-12-01 16:31:48,500 INFO     Training average loss at step 63600: 0.006146\n",
      "2023-12-01 16:31:53,999 INFO     Training average positive_sample_loss at step 63700: 0.005351\n",
      "2023-12-01 16:31:53,999 INFO     Training average negative_sample_loss at step 63700: 0.006557\n",
      "2023-12-01 16:31:53,999 INFO     Training average loss at step 63700: 0.005954\n",
      "2023-12-01 16:32:00,014 INFO     Training average positive_sample_loss at step 63800: 0.005223\n",
      "2023-12-01 16:32:00,014 INFO     Training average negative_sample_loss at step 63800: 0.006869\n",
      "2023-12-01 16:32:00,014 INFO     Training average loss at step 63800: 0.006046\n",
      "2023-12-01 16:32:05,464 INFO     Training average positive_sample_loss at step 63900: 0.005325\n",
      "2023-12-01 16:32:05,464 INFO     Training average negative_sample_loss at step 63900: 0.006437\n",
      "2023-12-01 16:32:05,464 INFO     Training average loss at step 63900: 0.005881\n",
      "2023-12-01 16:32:10,930 INFO     Training average positive_sample_loss at step 64000: 0.005284\n",
      "2023-12-01 16:32:10,931 INFO     Training average negative_sample_loss at step 64000: 0.006611\n",
      "2023-12-01 16:32:10,931 INFO     Training average loss at step 64000: 0.005947\n",
      "2023-12-01 16:32:16,356 INFO     Training average positive_sample_loss at step 64100: 0.005360\n",
      "2023-12-01 16:32:16,356 INFO     Training average negative_sample_loss at step 64100: 0.007139\n",
      "2023-12-01 16:32:16,356 INFO     Training average loss at step 64100: 0.006249\n",
      "2023-12-01 16:32:21,808 INFO     Training average positive_sample_loss at step 64200: 0.005322\n",
      "2023-12-01 16:32:21,809 INFO     Training average negative_sample_loss at step 64200: 0.006718\n",
      "2023-12-01 16:32:21,809 INFO     Training average loss at step 64200: 0.006020\n",
      "2023-12-01 16:32:27,780 INFO     Training average positive_sample_loss at step 64300: 0.005336\n",
      "2023-12-01 16:32:27,780 INFO     Training average negative_sample_loss at step 64300: 0.007165\n",
      "2023-12-01 16:32:27,780 INFO     Training average loss at step 64300: 0.006250\n",
      "2023-12-01 16:32:33,183 INFO     Training average positive_sample_loss at step 64400: 0.005298\n",
      "2023-12-01 16:32:33,183 INFO     Training average negative_sample_loss at step 64400: 0.006814\n",
      "2023-12-01 16:32:33,183 INFO     Training average loss at step 64400: 0.006056\n",
      "2023-12-01 16:32:38,591 INFO     Training average positive_sample_loss at step 64500: 0.005330\n",
      "2023-12-01 16:32:38,591 INFO     Training average negative_sample_loss at step 64500: 0.007621\n",
      "2023-12-01 16:32:38,591 INFO     Training average loss at step 64500: 0.006475\n",
      "2023-12-01 16:32:43,995 INFO     Training average positive_sample_loss at step 64600: 0.005313\n",
      "2023-12-01 16:32:43,995 INFO     Training average negative_sample_loss at step 64600: 0.006586\n",
      "2023-12-01 16:32:43,995 INFO     Training average loss at step 64600: 0.005949\n",
      "2023-12-01 16:32:49,365 INFO     Training average positive_sample_loss at step 64700: 0.005337\n",
      "2023-12-01 16:32:49,366 INFO     Training average negative_sample_loss at step 64700: 0.006801\n",
      "2023-12-01 16:32:49,366 INFO     Training average loss at step 64700: 0.006069\n",
      "2023-12-01 16:32:54,774 INFO     Training average positive_sample_loss at step 64800: 0.005315\n",
      "2023-12-01 16:32:54,774 INFO     Training average negative_sample_loss at step 64800: 0.006887\n",
      "2023-12-01 16:32:54,774 INFO     Training average loss at step 64800: 0.006101\n",
      "2023-12-01 16:33:00,808 INFO     Training average positive_sample_loss at step 64900: 0.005251\n",
      "2023-12-01 16:33:00,809 INFO     Training average negative_sample_loss at step 64900: 0.006651\n",
      "2023-12-01 16:33:00,809 INFO     Training average loss at step 64900: 0.005951\n",
      "2023-12-01 16:33:06,312 INFO     Training average positive_sample_loss at step 65000: 0.005290\n",
      "2023-12-01 16:33:06,313 INFO     Training average negative_sample_loss at step 65000: 0.007434\n",
      "2023-12-01 16:33:06,313 INFO     Training average loss at step 65000: 0.006362\n",
      "2023-12-01 16:33:11,749 INFO     Training average positive_sample_loss at step 65100: 0.005283\n",
      "2023-12-01 16:33:11,749 INFO     Training average negative_sample_loss at step 65100: 0.006617\n",
      "2023-12-01 16:33:11,749 INFO     Training average loss at step 65100: 0.005950\n",
      "2023-12-01 16:33:17,181 INFO     Training average positive_sample_loss at step 65200: 0.005313\n",
      "2023-12-01 16:33:17,181 INFO     Training average negative_sample_loss at step 65200: 0.006959\n",
      "2023-12-01 16:33:17,181 INFO     Training average loss at step 65200: 0.006136\n",
      "2023-12-01 16:33:22,613 INFO     Training average positive_sample_loss at step 65300: 0.005373\n",
      "2023-12-01 16:33:22,614 INFO     Training average negative_sample_loss at step 65300: 0.006600\n",
      "2023-12-01 16:33:22,614 INFO     Training average loss at step 65300: 0.005986\n",
      "2023-12-01 16:33:28,643 INFO     Training average positive_sample_loss at step 65400: 0.005332\n",
      "2023-12-01 16:33:28,643 INFO     Training average negative_sample_loss at step 65400: 0.007183\n",
      "2023-12-01 16:33:28,643 INFO     Training average loss at step 65400: 0.006257\n",
      "2023-12-01 16:33:34,101 INFO     Training average positive_sample_loss at step 65500: 0.005237\n",
      "2023-12-01 16:33:34,101 INFO     Training average negative_sample_loss at step 65500: 0.007208\n",
      "2023-12-01 16:33:34,101 INFO     Training average loss at step 65500: 0.006222\n",
      "2023-12-01 16:33:39,549 INFO     Training average positive_sample_loss at step 65600: 0.005293\n",
      "2023-12-01 16:33:39,549 INFO     Training average negative_sample_loss at step 65600: 0.006312\n",
      "2023-12-01 16:33:39,549 INFO     Training average loss at step 65600: 0.005802\n",
      "2023-12-01 16:33:45,034 INFO     Training average positive_sample_loss at step 65700: 0.005330\n",
      "2023-12-01 16:33:45,034 INFO     Training average negative_sample_loss at step 65700: 0.006728\n",
      "2023-12-01 16:33:45,034 INFO     Training average loss at step 65700: 0.006029\n",
      "2023-12-01 16:33:50,470 INFO     Training average positive_sample_loss at step 65800: 0.005357\n",
      "2023-12-01 16:33:50,470 INFO     Training average negative_sample_loss at step 65800: 0.007337\n",
      "2023-12-01 16:33:50,470 INFO     Training average loss at step 65800: 0.006347\n",
      "2023-12-01 16:33:55,922 INFO     Training average positive_sample_loss at step 65900: 0.005372\n",
      "2023-12-01 16:33:55,922 INFO     Training average negative_sample_loss at step 65900: 0.007143\n",
      "2023-12-01 16:33:55,922 INFO     Training average loss at step 65900: 0.006258\n",
      "2023-12-01 16:34:01,934 INFO     Training average positive_sample_loss at step 66000: 0.005254\n",
      "2023-12-01 16:34:01,934 INFO     Training average negative_sample_loss at step 66000: 0.007073\n",
      "2023-12-01 16:34:01,934 INFO     Training average loss at step 66000: 0.006163\n",
      "2023-12-01 16:34:07,382 INFO     Training average positive_sample_loss at step 66100: 0.005272\n",
      "2023-12-01 16:34:07,382 INFO     Training average negative_sample_loss at step 66100: 0.006156\n",
      "2023-12-01 16:34:07,382 INFO     Training average loss at step 66100: 0.005714\n",
      "2023-12-01 16:34:12,852 INFO     Training average positive_sample_loss at step 66200: 0.005299\n",
      "2023-12-01 16:34:12,852 INFO     Training average negative_sample_loss at step 66200: 0.006838\n",
      "2023-12-01 16:34:12,852 INFO     Training average loss at step 66200: 0.006068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:34:18,297 INFO     Training average positive_sample_loss at step 66300: 0.005329\n",
      "2023-12-01 16:34:18,298 INFO     Training average negative_sample_loss at step 66300: 0.007245\n",
      "2023-12-01 16:34:18,298 INFO     Training average loss at step 66300: 0.006287\n",
      "2023-12-01 16:34:23,755 INFO     Training average positive_sample_loss at step 66400: 0.005321\n",
      "2023-12-01 16:34:23,755 INFO     Training average negative_sample_loss at step 66400: 0.006764\n",
      "2023-12-01 16:34:23,755 INFO     Training average loss at step 66400: 0.006042\n",
      "2023-12-01 16:34:29,832 INFO     Training average positive_sample_loss at step 66500: 0.005379\n",
      "2023-12-01 16:34:29,833 INFO     Training average negative_sample_loss at step 66500: 0.007321\n",
      "2023-12-01 16:34:29,833 INFO     Training average loss at step 66500: 0.006350\n",
      "2023-12-01 16:34:35,279 INFO     Training average positive_sample_loss at step 66600: 0.005275\n",
      "2023-12-01 16:34:35,279 INFO     Training average negative_sample_loss at step 66600: 0.006470\n",
      "2023-12-01 16:34:35,279 INFO     Training average loss at step 66600: 0.005872\n",
      "2023-12-01 16:34:40,754 INFO     Training average positive_sample_loss at step 66700: 0.005301\n",
      "2023-12-01 16:34:40,754 INFO     Training average negative_sample_loss at step 66700: 0.007136\n",
      "2023-12-01 16:34:40,754 INFO     Training average loss at step 66700: 0.006219\n",
      "2023-12-01 16:34:46,207 INFO     Training average positive_sample_loss at step 66800: 0.005253\n",
      "2023-12-01 16:34:46,207 INFO     Training average negative_sample_loss at step 66800: 0.007064\n",
      "2023-12-01 16:34:46,207 INFO     Training average loss at step 66800: 0.006158\n",
      "2023-12-01 16:34:51,690 INFO     Training average positive_sample_loss at step 66900: 0.005374\n",
      "2023-12-01 16:34:51,690 INFO     Training average negative_sample_loss at step 66900: 0.007173\n",
      "2023-12-01 16:34:51,690 INFO     Training average loss at step 66900: 0.006273\n",
      "2023-12-01 16:34:57,125 INFO     Training average positive_sample_loss at step 67000: 0.005384\n",
      "2023-12-01 16:34:57,125 INFO     Training average negative_sample_loss at step 67000: 0.006128\n",
      "2023-12-01 16:34:57,125 INFO     Training average loss at step 67000: 0.005756\n",
      "2023-12-01 16:35:03,141 INFO     Training average positive_sample_loss at step 67100: 0.005242\n",
      "2023-12-01 16:35:03,141 INFO     Training average negative_sample_loss at step 67100: 0.006458\n",
      "2023-12-01 16:35:03,141 INFO     Training average loss at step 67100: 0.005850\n",
      "2023-12-01 16:35:08,583 INFO     Training average positive_sample_loss at step 67200: 0.005261\n",
      "2023-12-01 16:35:08,584 INFO     Training average negative_sample_loss at step 67200: 0.006891\n",
      "2023-12-01 16:35:08,584 INFO     Training average loss at step 67200: 0.006076\n",
      "2023-12-01 16:35:14,001 INFO     Training average positive_sample_loss at step 67300: 0.005360\n",
      "2023-12-01 16:35:14,001 INFO     Training average negative_sample_loss at step 67300: 0.006099\n",
      "2023-12-01 16:35:14,002 INFO     Training average loss at step 67300: 0.005730\n",
      "2023-12-01 16:35:19,405 INFO     Training average positive_sample_loss at step 67400: 0.005269\n",
      "2023-12-01 16:35:19,406 INFO     Training average negative_sample_loss at step 67400: 0.006831\n",
      "2023-12-01 16:35:19,406 INFO     Training average loss at step 67400: 0.006050\n",
      "2023-12-01 16:35:24,814 INFO     Training average positive_sample_loss at step 67500: 0.005358\n",
      "2023-12-01 16:35:24,814 INFO     Training average negative_sample_loss at step 67500: 0.006752\n",
      "2023-12-01 16:35:24,814 INFO     Training average loss at step 67500: 0.006055\n",
      "2023-12-01 16:35:30,798 INFO     Training average positive_sample_loss at step 67600: 0.005303\n",
      "2023-12-01 16:35:30,799 INFO     Training average negative_sample_loss at step 67600: 0.006802\n",
      "2023-12-01 16:35:30,799 INFO     Training average loss at step 67600: 0.006052\n",
      "2023-12-01 16:35:36,240 INFO     Training average positive_sample_loss at step 67700: 0.005209\n",
      "2023-12-01 16:35:36,241 INFO     Training average negative_sample_loss at step 67700: 0.006415\n",
      "2023-12-01 16:35:36,241 INFO     Training average loss at step 67700: 0.005812\n",
      "2023-12-01 16:35:41,675 INFO     Training average positive_sample_loss at step 67800: 0.005335\n",
      "2023-12-01 16:35:41,675 INFO     Training average negative_sample_loss at step 67800: 0.007039\n",
      "2023-12-01 16:35:41,675 INFO     Training average loss at step 67800: 0.006187\n",
      "2023-12-01 16:35:47,099 INFO     Training average positive_sample_loss at step 67900: 0.005278\n",
      "2023-12-01 16:35:47,099 INFO     Training average negative_sample_loss at step 67900: 0.006856\n",
      "2023-12-01 16:35:47,099 INFO     Training average loss at step 67900: 0.006067\n",
      "2023-12-01 16:35:52,536 INFO     Training average positive_sample_loss at step 68000: 0.005353\n",
      "2023-12-01 16:35:52,536 INFO     Training average negative_sample_loss at step 68000: 0.007082\n",
      "2023-12-01 16:35:52,536 INFO     Training average loss at step 68000: 0.006217\n",
      "2023-12-01 16:35:58,003 INFO     Training average positive_sample_loss at step 68100: 0.005356\n",
      "2023-12-01 16:35:58,003 INFO     Training average negative_sample_loss at step 68100: 0.006815\n",
      "2023-12-01 16:35:58,003 INFO     Training average loss at step 68100: 0.006086\n",
      "2023-12-01 16:36:04,001 INFO     Training average positive_sample_loss at step 68200: 0.005287\n",
      "2023-12-01 16:36:04,001 INFO     Training average negative_sample_loss at step 68200: 0.006293\n",
      "2023-12-01 16:36:04,001 INFO     Training average loss at step 68200: 0.005790\n",
      "2023-12-01 16:36:09,447 INFO     Training average positive_sample_loss at step 68300: 0.005258\n",
      "2023-12-01 16:36:09,448 INFO     Training average negative_sample_loss at step 68300: 0.007516\n",
      "2023-12-01 16:36:09,448 INFO     Training average loss at step 68300: 0.006387\n",
      "2023-12-01 16:36:14,892 INFO     Training average positive_sample_loss at step 68400: 0.005331\n",
      "2023-12-01 16:36:14,892 INFO     Training average negative_sample_loss at step 68400: 0.007086\n",
      "2023-12-01 16:36:14,892 INFO     Training average loss at step 68400: 0.006208\n",
      "2023-12-01 16:36:20,335 INFO     Training average positive_sample_loss at step 68500: 0.005355\n",
      "2023-12-01 16:36:20,336 INFO     Training average negative_sample_loss at step 68500: 0.006877\n",
      "2023-12-01 16:36:20,336 INFO     Training average loss at step 68500: 0.006116\n",
      "2023-12-01 16:36:25,779 INFO     Training average positive_sample_loss at step 68600: 0.005294\n",
      "2023-12-01 16:36:25,779 INFO     Training average negative_sample_loss at step 68600: 0.006847\n",
      "2023-12-01 16:36:25,779 INFO     Training average loss at step 68600: 0.006071\n",
      "2023-12-01 16:36:31,803 INFO     Training average positive_sample_loss at step 68700: 0.005354\n",
      "2023-12-01 16:36:31,803 INFO     Training average negative_sample_loss at step 68700: 0.007347\n",
      "2023-12-01 16:36:31,803 INFO     Training average loss at step 68700: 0.006350\n",
      "2023-12-01 16:36:37,246 INFO     Training average positive_sample_loss at step 68800: 0.005240\n",
      "2023-12-01 16:36:37,246 INFO     Training average negative_sample_loss at step 68800: 0.007265\n",
      "2023-12-01 16:36:37,246 INFO     Training average loss at step 68800: 0.006253\n",
      "2023-12-01 16:36:42,732 INFO     Training average positive_sample_loss at step 68900: 0.005265\n",
      "2023-12-01 16:36:42,733 INFO     Training average negative_sample_loss at step 68900: 0.006686\n",
      "2023-12-01 16:36:42,733 INFO     Training average loss at step 68900: 0.005975\n",
      "2023-12-01 16:36:48,203 INFO     Training average positive_sample_loss at step 69000: 0.005284\n",
      "2023-12-01 16:36:48,204 INFO     Training average negative_sample_loss at step 69000: 0.006011\n",
      "2023-12-01 16:36:48,204 INFO     Training average loss at step 69000: 0.005647\n",
      "2023-12-01 16:36:53,653 INFO     Training average positive_sample_loss at step 69100: 0.005370\n",
      "2023-12-01 16:36:53,654 INFO     Training average negative_sample_loss at step 69100: 0.007045\n",
      "2023-12-01 16:36:53,654 INFO     Training average loss at step 69100: 0.006208\n",
      "2023-12-01 16:36:59,122 INFO     Training average positive_sample_loss at step 69200: 0.005328\n",
      "2023-12-01 16:36:59,122 INFO     Training average negative_sample_loss at step 69200: 0.006618\n",
      "2023-12-01 16:36:59,122 INFO     Training average loss at step 69200: 0.005973\n",
      "2023-12-01 16:37:05,202 INFO     Training average positive_sample_loss at step 69300: 0.005308\n",
      "2023-12-01 16:37:05,202 INFO     Training average negative_sample_loss at step 69300: 0.006584\n",
      "2023-12-01 16:37:05,202 INFO     Training average loss at step 69300: 0.005946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:37:10,698 INFO     Training average positive_sample_loss at step 69400: 0.005260\n",
      "2023-12-01 16:37:10,698 INFO     Training average negative_sample_loss at step 69400: 0.006790\n",
      "2023-12-01 16:37:10,698 INFO     Training average loss at step 69400: 0.006025\n",
      "2023-12-01 16:37:16,157 INFO     Training average positive_sample_loss at step 69500: 0.005281\n",
      "2023-12-01 16:37:16,157 INFO     Training average negative_sample_loss at step 69500: 0.007521\n",
      "2023-12-01 16:37:16,157 INFO     Training average loss at step 69500: 0.006401\n",
      "2023-12-01 16:37:21,577 INFO     Training average positive_sample_loss at step 69600: 0.005272\n",
      "2023-12-01 16:37:21,578 INFO     Training average negative_sample_loss at step 69600: 0.007557\n",
      "2023-12-01 16:37:21,578 INFO     Training average loss at step 69600: 0.006414\n",
      "2023-12-01 16:37:27,014 INFO     Training average positive_sample_loss at step 69700: 0.005360\n",
      "2023-12-01 16:37:27,014 INFO     Training average negative_sample_loss at step 69700: 0.007269\n",
      "2023-12-01 16:37:27,014 INFO     Training average loss at step 69700: 0.006315\n",
      "2023-12-01 16:37:32,506 INFO     Training average positive_sample_loss at step 69800: 0.005421\n",
      "2023-12-01 16:37:32,507 INFO     Training average negative_sample_loss at step 69800: 0.007814\n",
      "2023-12-01 16:37:32,507 INFO     Training average loss at step 69800: 0.006618\n",
      "2023-12-01 16:37:38,420 INFO     Training average positive_sample_loss at step 69900: 0.005212\n",
      "2023-12-01 16:37:38,421 INFO     Training average negative_sample_loss at step 69900: 0.006564\n",
      "2023-12-01 16:37:38,421 INFO     Training average loss at step 69900: 0.005888\n",
      "2023-12-01 16:37:51,843 INFO     Training average positive_sample_loss at step 70000: 0.005287\n",
      "2023-12-01 16:37:51,843 INFO     Training average negative_sample_loss at step 70000: 0.006565\n",
      "2023-12-01 16:37:51,843 INFO     Training average loss at step 70000: 0.005926\n",
      "2023-12-01 16:37:51,843 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 16:37:52,543 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 16:38:29,157 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 16:38:37,355 INFO     Valid MRR at step 70000: 0.950080\n",
      "2023-12-01 16:38:37,356 INFO     Valid MR at step 70000: 317.731400\n",
      "2023-12-01 16:38:37,356 INFO     Valid HITS@1 at step 70000: 0.945600\n",
      "2023-12-01 16:38:37,356 INFO     Valid HITS@3 at step 70000: 0.952200\n",
      "2023-12-01 16:38:37,356 INFO     Valid HITS@10 at step 70000: 0.957800\n",
      "2023-12-01 16:38:42,845 INFO     Training average positive_sample_loss at step 70100: 0.005256\n",
      "2023-12-01 16:38:42,845 INFO     Training average negative_sample_loss at step 70100: 0.006392\n",
      "2023-12-01 16:38:42,845 INFO     Training average loss at step 70100: 0.005824\n",
      "2023-12-01 16:38:48,325 INFO     Training average positive_sample_loss at step 70200: 0.005334\n",
      "2023-12-01 16:38:48,326 INFO     Training average negative_sample_loss at step 70200: 0.006877\n",
      "2023-12-01 16:38:48,326 INFO     Training average loss at step 70200: 0.006106\n",
      "2023-12-01 16:38:53,784 INFO     Training average positive_sample_loss at step 70300: 0.005366\n",
      "2023-12-01 16:38:53,784 INFO     Training average negative_sample_loss at step 70300: 0.006768\n",
      "2023-12-01 16:38:53,784 INFO     Training average loss at step 70300: 0.006067\n",
      "2023-12-01 16:38:59,829 INFO     Training average positive_sample_loss at step 70400: 0.005353\n",
      "2023-12-01 16:38:59,829 INFO     Training average negative_sample_loss at step 70400: 0.007339\n",
      "2023-12-01 16:38:59,829 INFO     Training average loss at step 70400: 0.006346\n",
      "2023-12-01 16:39:05,273 INFO     Training average positive_sample_loss at step 70500: 0.005225\n",
      "2023-12-01 16:39:05,273 INFO     Training average negative_sample_loss at step 70500: 0.006526\n",
      "2023-12-01 16:39:05,273 INFO     Training average loss at step 70500: 0.005876\n",
      "2023-12-01 16:39:10,704 INFO     Training average positive_sample_loss at step 70600: 0.005307\n",
      "2023-12-01 16:39:10,704 INFO     Training average negative_sample_loss at step 70600: 0.007477\n",
      "2023-12-01 16:39:10,704 INFO     Training average loss at step 70600: 0.006392\n",
      "2023-12-01 16:39:16,112 INFO     Training average positive_sample_loss at step 70700: 0.005347\n",
      "2023-12-01 16:39:16,112 INFO     Training average negative_sample_loss at step 70700: 0.006167\n",
      "2023-12-01 16:39:16,112 INFO     Training average loss at step 70700: 0.005757\n",
      "2023-12-01 16:39:21,518 INFO     Training average positive_sample_loss at step 70800: 0.005326\n",
      "2023-12-01 16:39:21,518 INFO     Training average negative_sample_loss at step 70800: 0.006279\n",
      "2023-12-01 16:39:21,518 INFO     Training average loss at step 70800: 0.005803\n",
      "2023-12-01 16:39:26,996 INFO     Training average positive_sample_loss at step 70900: 0.005357\n",
      "2023-12-01 16:39:26,996 INFO     Training average negative_sample_loss at step 70900: 0.006538\n",
      "2023-12-01 16:39:26,996 INFO     Training average loss at step 70900: 0.005947\n",
      "2023-12-01 16:39:33,025 INFO     Training average positive_sample_loss at step 71000: 0.005173\n",
      "2023-12-01 16:39:33,026 INFO     Training average negative_sample_loss at step 71000: 0.006472\n",
      "2023-12-01 16:39:33,026 INFO     Training average loss at step 71000: 0.005823\n",
      "2023-12-01 16:39:38,497 INFO     Training average positive_sample_loss at step 71100: 0.005255\n",
      "2023-12-01 16:39:38,497 INFO     Training average negative_sample_loss at step 71100: 0.006630\n",
      "2023-12-01 16:39:38,498 INFO     Training average loss at step 71100: 0.005942\n",
      "2023-12-01 16:39:44,007 INFO     Training average positive_sample_loss at step 71200: 0.005321\n",
      "2023-12-01 16:39:44,008 INFO     Training average negative_sample_loss at step 71200: 0.007168\n",
      "2023-12-01 16:39:44,008 INFO     Training average loss at step 71200: 0.006244\n",
      "2023-12-01 16:39:49,443 INFO     Training average positive_sample_loss at step 71300: 0.005364\n",
      "2023-12-01 16:39:49,443 INFO     Training average negative_sample_loss at step 71300: 0.006423\n",
      "2023-12-01 16:39:49,444 INFO     Training average loss at step 71300: 0.005894\n",
      "2023-12-01 16:39:54,904 INFO     Training average positive_sample_loss at step 71400: 0.005383\n",
      "2023-12-01 16:39:54,904 INFO     Training average negative_sample_loss at step 71400: 0.007025\n",
      "2023-12-01 16:39:54,904 INFO     Training average loss at step 71400: 0.006204\n",
      "2023-12-01 16:40:00,928 INFO     Training average positive_sample_loss at step 71500: 0.005318\n",
      "2023-12-01 16:40:00,928 INFO     Training average negative_sample_loss at step 71500: 0.006912\n",
      "2023-12-01 16:40:00,928 INFO     Training average loss at step 71500: 0.006115\n",
      "2023-12-01 16:40:06,356 INFO     Training average positive_sample_loss at step 71600: 0.005255\n",
      "2023-12-01 16:40:06,356 INFO     Training average negative_sample_loss at step 71600: 0.006642\n",
      "2023-12-01 16:40:06,356 INFO     Training average loss at step 71600: 0.005948\n",
      "2023-12-01 16:40:11,809 INFO     Training average positive_sample_loss at step 71700: 0.005275\n",
      "2023-12-01 16:40:11,809 INFO     Training average negative_sample_loss at step 71700: 0.006817\n",
      "2023-12-01 16:40:11,809 INFO     Training average loss at step 71700: 0.006046\n",
      "2023-12-01 16:40:17,259 INFO     Training average positive_sample_loss at step 71800: 0.005292\n",
      "2023-12-01 16:40:17,259 INFO     Training average negative_sample_loss at step 71800: 0.006272\n",
      "2023-12-01 16:40:17,259 INFO     Training average loss at step 71800: 0.005782\n",
      "2023-12-01 16:40:22,691 INFO     Training average positive_sample_loss at step 71900: 0.005329\n",
      "2023-12-01 16:40:22,691 INFO     Training average negative_sample_loss at step 71900: 0.006700\n",
      "2023-12-01 16:40:22,691 INFO     Training average loss at step 71900: 0.006015\n",
      "2023-12-01 16:40:28,148 INFO     Training average positive_sample_loss at step 72000: 0.005348\n",
      "2023-12-01 16:40:28,148 INFO     Training average negative_sample_loss at step 72000: 0.006508\n",
      "2023-12-01 16:40:28,148 INFO     Training average loss at step 72000: 0.005928\n",
      "2023-12-01 16:40:34,122 INFO     Training average positive_sample_loss at step 72100: 0.005264\n",
      "2023-12-01 16:40:34,123 INFO     Training average negative_sample_loss at step 72100: 0.007490\n",
      "2023-12-01 16:40:34,123 INFO     Training average loss at step 72100: 0.006377\n",
      "2023-12-01 16:40:39,584 INFO     Training average positive_sample_loss at step 72200: 0.005249\n",
      "2023-12-01 16:40:39,584 INFO     Training average negative_sample_loss at step 72200: 0.007002\n",
      "2023-12-01 16:40:39,584 INFO     Training average loss at step 72200: 0.006126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:40:45,053 INFO     Training average positive_sample_loss at step 72300: 0.005277\n",
      "2023-12-01 16:40:45,053 INFO     Training average negative_sample_loss at step 72300: 0.006796\n",
      "2023-12-01 16:40:45,054 INFO     Training average loss at step 72300: 0.006037\n",
      "2023-12-01 16:40:50,542 INFO     Training average positive_sample_loss at step 72400: 0.005353\n",
      "2023-12-01 16:40:50,543 INFO     Training average negative_sample_loss at step 72400: 0.007247\n",
      "2023-12-01 16:40:50,543 INFO     Training average loss at step 72400: 0.006300\n",
      "2023-12-01 16:40:56,043 INFO     Training average positive_sample_loss at step 72500: 0.005346\n",
      "2023-12-01 16:40:56,043 INFO     Training average negative_sample_loss at step 72500: 0.007094\n",
      "2023-12-01 16:40:56,043 INFO     Training average loss at step 72500: 0.006220\n",
      "2023-12-01 16:41:02,087 INFO     Training average positive_sample_loss at step 72600: 0.005354\n",
      "2023-12-01 16:41:02,088 INFO     Training average negative_sample_loss at step 72600: 0.006776\n",
      "2023-12-01 16:41:02,088 INFO     Training average loss at step 72600: 0.006065\n",
      "2023-12-01 16:41:07,557 INFO     Training average positive_sample_loss at step 72700: 0.005218\n",
      "2023-12-01 16:41:07,558 INFO     Training average negative_sample_loss at step 72700: 0.006995\n",
      "2023-12-01 16:41:07,558 INFO     Training average loss at step 72700: 0.006107\n",
      "2023-12-01 16:41:13,029 INFO     Training average positive_sample_loss at step 72800: 0.005236\n",
      "2023-12-01 16:41:13,030 INFO     Training average negative_sample_loss at step 72800: 0.007152\n",
      "2023-12-01 16:41:13,030 INFO     Training average loss at step 72800: 0.006194\n",
      "2023-12-01 16:41:18,520 INFO     Training average positive_sample_loss at step 72900: 0.005361\n",
      "2023-12-01 16:41:18,520 INFO     Training average negative_sample_loss at step 72900: 0.006913\n",
      "2023-12-01 16:41:18,520 INFO     Training average loss at step 72900: 0.006137\n",
      "2023-12-01 16:41:24,018 INFO     Training average positive_sample_loss at step 73000: 0.005316\n",
      "2023-12-01 16:41:24,019 INFO     Training average negative_sample_loss at step 73000: 0.006872\n",
      "2023-12-01 16:41:24,019 INFO     Training average loss at step 73000: 0.006094\n",
      "2023-12-01 16:41:29,503 INFO     Training average positive_sample_loss at step 73100: 0.005356\n",
      "2023-12-01 16:41:29,503 INFO     Training average negative_sample_loss at step 73100: 0.006730\n",
      "2023-12-01 16:41:29,503 INFO     Training average loss at step 73100: 0.006043\n",
      "2023-12-01 16:41:35,543 INFO     Training average positive_sample_loss at step 73200: 0.005278\n",
      "2023-12-01 16:41:35,543 INFO     Training average negative_sample_loss at step 73200: 0.007039\n",
      "2023-12-01 16:41:35,543 INFO     Training average loss at step 73200: 0.006158\n",
      "2023-12-01 16:41:40,992 INFO     Training average positive_sample_loss at step 73300: 0.005215\n",
      "2023-12-01 16:41:40,992 INFO     Training average negative_sample_loss at step 73300: 0.008140\n",
      "2023-12-01 16:41:40,992 INFO     Training average loss at step 73300: 0.006677\n",
      "2023-12-01 16:41:46,467 INFO     Training average positive_sample_loss at step 73400: 0.005305\n",
      "2023-12-01 16:41:46,468 INFO     Training average negative_sample_loss at step 73400: 0.006913\n",
      "2023-12-01 16:41:46,468 INFO     Training average loss at step 73400: 0.006109\n",
      "2023-12-01 16:41:51,945 INFO     Training average positive_sample_loss at step 73500: 0.005313\n",
      "2023-12-01 16:41:51,945 INFO     Training average negative_sample_loss at step 73500: 0.006743\n",
      "2023-12-01 16:41:51,945 INFO     Training average loss at step 73500: 0.006028\n",
      "2023-12-01 16:41:57,418 INFO     Training average positive_sample_loss at step 73600: 0.005371\n",
      "2023-12-01 16:41:57,418 INFO     Training average negative_sample_loss at step 73600: 0.006960\n",
      "2023-12-01 16:41:57,418 INFO     Training average loss at step 73600: 0.006166\n",
      "2023-12-01 16:42:03,512 INFO     Training average positive_sample_loss at step 73700: 0.005349\n",
      "2023-12-01 16:42:03,512 INFO     Training average negative_sample_loss at step 73700: 0.007283\n",
      "2023-12-01 16:42:03,512 INFO     Training average loss at step 73700: 0.006316\n",
      "2023-12-01 16:42:08,984 INFO     Training average positive_sample_loss at step 73800: 0.005211\n",
      "2023-12-01 16:42:08,984 INFO     Training average negative_sample_loss at step 73800: 0.006321\n",
      "2023-12-01 16:42:08,984 INFO     Training average loss at step 73800: 0.005766\n",
      "2023-12-01 16:42:14,447 INFO     Training average positive_sample_loss at step 73900: 0.005280\n",
      "2023-12-01 16:42:14,448 INFO     Training average negative_sample_loss at step 73900: 0.006813\n",
      "2023-12-01 16:42:14,448 INFO     Training average loss at step 73900: 0.006046\n",
      "2023-12-01 16:42:19,941 INFO     Training average positive_sample_loss at step 74000: 0.005277\n",
      "2023-12-01 16:42:19,942 INFO     Training average negative_sample_loss at step 74000: 0.007034\n",
      "2023-12-01 16:42:19,942 INFO     Training average loss at step 74000: 0.006156\n",
      "2023-12-01 16:42:25,444 INFO     Training average positive_sample_loss at step 74100: 0.005373\n",
      "2023-12-01 16:42:25,444 INFO     Training average negative_sample_loss at step 74100: 0.007045\n",
      "2023-12-01 16:42:25,445 INFO     Training average loss at step 74100: 0.006209\n",
      "2023-12-01 16:42:30,960 INFO     Training average positive_sample_loss at step 74200: 0.005348\n",
      "2023-12-01 16:42:30,960 INFO     Training average negative_sample_loss at step 74200: 0.006423\n",
      "2023-12-01 16:42:30,960 INFO     Training average loss at step 74200: 0.005885\n",
      "2023-12-01 16:42:37,006 INFO     Training average positive_sample_loss at step 74300: 0.005297\n",
      "2023-12-01 16:42:37,007 INFO     Training average negative_sample_loss at step 74300: 0.007449\n",
      "2023-12-01 16:42:37,007 INFO     Training average loss at step 74300: 0.006373\n",
      "2023-12-01 16:42:42,428 INFO     Training average positive_sample_loss at step 74400: 0.005224\n",
      "2023-12-01 16:42:42,428 INFO     Training average negative_sample_loss at step 74400: 0.006626\n",
      "2023-12-01 16:42:42,428 INFO     Training average loss at step 74400: 0.005925\n",
      "2023-12-01 16:42:47,839 INFO     Training average positive_sample_loss at step 74500: 0.005250\n",
      "2023-12-01 16:42:47,839 INFO     Training average negative_sample_loss at step 74500: 0.006313\n",
      "2023-12-01 16:42:47,839 INFO     Training average loss at step 74500: 0.005781\n",
      "2023-12-01 16:42:53,241 INFO     Training average positive_sample_loss at step 74600: 0.005345\n",
      "2023-12-01 16:42:53,241 INFO     Training average negative_sample_loss at step 74600: 0.007013\n",
      "2023-12-01 16:42:53,241 INFO     Training average loss at step 74600: 0.006179\n",
      "2023-12-01 16:42:58,650 INFO     Training average positive_sample_loss at step 74700: 0.005351\n",
      "2023-12-01 16:42:58,650 INFO     Training average negative_sample_loss at step 74700: 0.007164\n",
      "2023-12-01 16:42:58,650 INFO     Training average loss at step 74700: 0.006258\n",
      "2023-12-01 16:43:04,667 INFO     Training average positive_sample_loss at step 74800: 0.005342\n",
      "2023-12-01 16:43:04,668 INFO     Training average negative_sample_loss at step 74800: 0.006895\n",
      "2023-12-01 16:43:04,668 INFO     Training average loss at step 74800: 0.006119\n",
      "2023-12-01 16:43:10,173 INFO     Training average positive_sample_loss at step 74900: 0.005211\n",
      "2023-12-01 16:43:10,173 INFO     Training average negative_sample_loss at step 74900: 0.006331\n",
      "2023-12-01 16:43:10,173 INFO     Training average loss at step 74900: 0.005771\n",
      "2023-12-01 16:43:15,670 INFO     Training average positive_sample_loss at step 75000: 0.005262\n",
      "2023-12-01 16:43:15,670 INFO     Training average negative_sample_loss at step 75000: 0.007432\n",
      "2023-12-01 16:43:15,671 INFO     Training average loss at step 75000: 0.006347\n",
      "2023-12-01 16:43:21,147 INFO     Training average positive_sample_loss at step 75100: 0.005325\n",
      "2023-12-01 16:43:21,148 INFO     Training average negative_sample_loss at step 75100: 0.006188\n",
      "2023-12-01 16:43:21,148 INFO     Training average loss at step 75100: 0.005756\n",
      "2023-12-01 16:43:26,629 INFO     Training average positive_sample_loss at step 75200: 0.005286\n",
      "2023-12-01 16:43:26,630 INFO     Training average negative_sample_loss at step 75200: 0.007181\n",
      "2023-12-01 16:43:26,630 INFO     Training average loss at step 75200: 0.006234\n",
      "2023-12-01 16:43:32,091 INFO     Training average positive_sample_loss at step 75300: 0.005355\n",
      "2023-12-01 16:43:32,091 INFO     Training average negative_sample_loss at step 75300: 0.006548\n",
      "2023-12-01 16:43:32,091 INFO     Training average loss at step 75300: 0.005951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:43:38,118 INFO     Training average positive_sample_loss at step 75400: 0.005274\n",
      "2023-12-01 16:43:38,119 INFO     Training average negative_sample_loss at step 75400: 0.007011\n",
      "2023-12-01 16:43:38,119 INFO     Training average loss at step 75400: 0.006142\n",
      "2023-12-01 16:43:43,576 INFO     Training average positive_sample_loss at step 75500: 0.005257\n",
      "2023-12-01 16:43:43,576 INFO     Training average negative_sample_loss at step 75500: 0.007045\n",
      "2023-12-01 16:43:43,576 INFO     Training average loss at step 75500: 0.006151\n",
      "2023-12-01 16:43:49,059 INFO     Training average positive_sample_loss at step 75600: 0.005292\n",
      "2023-12-01 16:43:49,060 INFO     Training average negative_sample_loss at step 75600: 0.006758\n",
      "2023-12-01 16:43:49,060 INFO     Training average loss at step 75600: 0.006025\n",
      "2023-12-01 16:43:54,509 INFO     Training average positive_sample_loss at step 75700: 0.005304\n",
      "2023-12-01 16:43:54,509 INFO     Training average negative_sample_loss at step 75700: 0.007143\n",
      "2023-12-01 16:43:54,509 INFO     Training average loss at step 75700: 0.006223\n",
      "2023-12-01 16:43:59,993 INFO     Training average positive_sample_loss at step 75800: 0.005328\n",
      "2023-12-01 16:43:59,993 INFO     Training average negative_sample_loss at step 75800: 0.006979\n",
      "2023-12-01 16:43:59,993 INFO     Training average loss at step 75800: 0.006153\n",
      "2023-12-01 16:44:06,012 INFO     Training average positive_sample_loss at step 75900: 0.005345\n",
      "2023-12-01 16:44:06,012 INFO     Training average negative_sample_loss at step 75900: 0.007129\n",
      "2023-12-01 16:44:06,012 INFO     Training average loss at step 75900: 0.006237\n",
      "2023-12-01 16:44:11,435 INFO     Training average positive_sample_loss at step 76000: 0.005221\n",
      "2023-12-01 16:44:11,435 INFO     Training average negative_sample_loss at step 76000: 0.006847\n",
      "2023-12-01 16:44:11,435 INFO     Training average loss at step 76000: 0.006034\n",
      "2023-12-01 16:44:16,874 INFO     Training average positive_sample_loss at step 76100: 0.005228\n",
      "2023-12-01 16:44:16,874 INFO     Training average negative_sample_loss at step 76100: 0.006017\n",
      "2023-12-01 16:44:16,874 INFO     Training average loss at step 76100: 0.005623\n",
      "2023-12-01 16:44:22,358 INFO     Training average positive_sample_loss at step 76200: 0.005343\n",
      "2023-12-01 16:44:22,358 INFO     Training average negative_sample_loss at step 76200: 0.007322\n",
      "2023-12-01 16:44:22,358 INFO     Training average loss at step 76200: 0.006333\n",
      "2023-12-01 16:44:27,850 INFO     Training average positive_sample_loss at step 76300: 0.005336\n",
      "2023-12-01 16:44:27,850 INFO     Training average negative_sample_loss at step 76300: 0.007314\n",
      "2023-12-01 16:44:27,850 INFO     Training average loss at step 76300: 0.006325\n",
      "2023-12-01 16:44:33,339 INFO     Training average positive_sample_loss at step 76400: 0.005314\n",
      "2023-12-01 16:44:33,340 INFO     Training average negative_sample_loss at step 76400: 0.007245\n",
      "2023-12-01 16:44:33,340 INFO     Training average loss at step 76400: 0.006279\n",
      "2023-12-01 16:44:39,503 INFO     Training average positive_sample_loss at step 76500: 0.005312\n",
      "2023-12-01 16:44:39,503 INFO     Training average negative_sample_loss at step 76500: 0.006632\n",
      "2023-12-01 16:44:39,503 INFO     Training average loss at step 76500: 0.005972\n",
      "2023-12-01 16:44:45,016 INFO     Training average positive_sample_loss at step 76600: 0.005222\n",
      "2023-12-01 16:44:45,017 INFO     Training average negative_sample_loss at step 76600: 0.006732\n",
      "2023-12-01 16:44:45,017 INFO     Training average loss at step 76600: 0.005977\n",
      "2023-12-01 16:44:50,531 INFO     Training average positive_sample_loss at step 76700: 0.005256\n",
      "2023-12-01 16:44:50,532 INFO     Training average negative_sample_loss at step 76700: 0.006241\n",
      "2023-12-01 16:44:50,532 INFO     Training average loss at step 76700: 0.005749\n",
      "2023-12-01 16:44:56,035 INFO     Training average positive_sample_loss at step 76800: 0.005357\n",
      "2023-12-01 16:44:56,035 INFO     Training average negative_sample_loss at step 76800: 0.006120\n",
      "2023-12-01 16:44:56,035 INFO     Training average loss at step 76800: 0.005739\n",
      "2023-12-01 16:45:01,493 INFO     Training average positive_sample_loss at step 76900: 0.005318\n",
      "2023-12-01 16:45:01,493 INFO     Training average negative_sample_loss at step 76900: 0.007339\n",
      "2023-12-01 16:45:01,493 INFO     Training average loss at step 76900: 0.006328\n",
      "2023-12-01 16:45:06,996 INFO     Training average positive_sample_loss at step 77000: 0.005353\n",
      "2023-12-01 16:45:06,996 INFO     Training average negative_sample_loss at step 77000: 0.006627\n",
      "2023-12-01 16:45:06,996 INFO     Training average loss at step 77000: 0.005990\n",
      "2023-12-01 16:45:13,094 INFO     Training average positive_sample_loss at step 77100: 0.005198\n",
      "2023-12-01 16:45:13,095 INFO     Training average negative_sample_loss at step 77100: 0.006458\n",
      "2023-12-01 16:45:13,095 INFO     Training average loss at step 77100: 0.005828\n",
      "2023-12-01 16:45:18,566 INFO     Training average positive_sample_loss at step 77200: 0.005265\n",
      "2023-12-01 16:45:18,567 INFO     Training average negative_sample_loss at step 77200: 0.006363\n",
      "2023-12-01 16:45:18,567 INFO     Training average loss at step 77200: 0.005814\n",
      "2023-12-01 16:45:24,046 INFO     Training average positive_sample_loss at step 77300: 0.005257\n",
      "2023-12-01 16:45:24,046 INFO     Training average negative_sample_loss at step 77300: 0.006977\n",
      "2023-12-01 16:45:24,046 INFO     Training average loss at step 77300: 0.006117\n",
      "2023-12-01 16:45:29,524 INFO     Training average positive_sample_loss at step 77400: 0.005298\n",
      "2023-12-01 16:45:29,524 INFO     Training average negative_sample_loss at step 77400: 0.006812\n",
      "2023-12-01 16:45:29,524 INFO     Training average loss at step 77400: 0.006055\n",
      "2023-12-01 16:45:35,012 INFO     Training average positive_sample_loss at step 77500: 0.005368\n",
      "2023-12-01 16:45:35,012 INFO     Training average negative_sample_loss at step 77500: 0.007162\n",
      "2023-12-01 16:45:35,012 INFO     Training average loss at step 77500: 0.006265\n",
      "2023-12-01 16:45:41,025 INFO     Training average positive_sample_loss at step 77600: 0.005305\n",
      "2023-12-01 16:45:41,025 INFO     Training average negative_sample_loss at step 77600: 0.007057\n",
      "2023-12-01 16:45:41,025 INFO     Training average loss at step 77600: 0.006181\n",
      "2023-12-01 16:45:46,494 INFO     Training average positive_sample_loss at step 77700: 0.005252\n",
      "2023-12-01 16:45:46,495 INFO     Training average negative_sample_loss at step 77700: 0.006958\n",
      "2023-12-01 16:45:46,495 INFO     Training average loss at step 77700: 0.006105\n",
      "2023-12-01 16:45:51,974 INFO     Training average positive_sample_loss at step 77800: 0.005279\n",
      "2023-12-01 16:45:51,974 INFO     Training average negative_sample_loss at step 77800: 0.006896\n",
      "2023-12-01 16:45:51,975 INFO     Training average loss at step 77800: 0.006088\n",
      "2023-12-01 16:45:57,465 INFO     Training average positive_sample_loss at step 77900: 0.005311\n",
      "2023-12-01 16:45:57,466 INFO     Training average negative_sample_loss at step 77900: 0.006672\n",
      "2023-12-01 16:45:57,466 INFO     Training average loss at step 77900: 0.005992\n",
      "2023-12-01 16:46:02,940 INFO     Training average positive_sample_loss at step 78000: 0.005312\n",
      "2023-12-01 16:46:02,940 INFO     Training average negative_sample_loss at step 78000: 0.006794\n",
      "2023-12-01 16:46:02,940 INFO     Training average loss at step 78000: 0.006053\n",
      "2023-12-01 16:46:08,434 INFO     Training average positive_sample_loss at step 78100: 0.005328\n",
      "2023-12-01 16:46:08,434 INFO     Training average negative_sample_loss at step 78100: 0.006820\n",
      "2023-12-01 16:46:08,434 INFO     Training average loss at step 78100: 0.006074\n",
      "2023-12-01 16:46:14,439 INFO     Training average positive_sample_loss at step 78200: 0.005226\n",
      "2023-12-01 16:46:14,440 INFO     Training average negative_sample_loss at step 78200: 0.006935\n",
      "2023-12-01 16:46:14,440 INFO     Training average loss at step 78200: 0.006080\n",
      "2023-12-01 16:46:19,944 INFO     Training average positive_sample_loss at step 78300: 0.005234\n",
      "2023-12-01 16:46:19,944 INFO     Training average negative_sample_loss at step 78300: 0.005985\n",
      "2023-12-01 16:46:19,944 INFO     Training average loss at step 78300: 0.005610\n",
      "2023-12-01 16:46:25,401 INFO     Training average positive_sample_loss at step 78400: 0.005312\n",
      "2023-12-01 16:46:25,402 INFO     Training average negative_sample_loss at step 78400: 0.006648\n",
      "2023-12-01 16:46:25,402 INFO     Training average loss at step 78400: 0.005980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:46:30,837 INFO     Training average positive_sample_loss at step 78500: 0.005309\n",
      "2023-12-01 16:46:30,837 INFO     Training average negative_sample_loss at step 78500: 0.007002\n",
      "2023-12-01 16:46:30,837 INFO     Training average loss at step 78500: 0.006156\n",
      "2023-12-01 16:46:36,280 INFO     Training average positive_sample_loss at step 78600: 0.005337\n",
      "2023-12-01 16:46:36,281 INFO     Training average negative_sample_loss at step 78600: 0.006918\n",
      "2023-12-01 16:46:36,281 INFO     Training average loss at step 78600: 0.006128\n",
      "2023-12-01 16:46:42,314 INFO     Training average positive_sample_loss at step 78700: 0.005284\n",
      "2023-12-01 16:46:42,314 INFO     Training average negative_sample_loss at step 78700: 0.006936\n",
      "2023-12-01 16:46:42,314 INFO     Training average loss at step 78700: 0.006110\n",
      "2023-12-01 16:46:47,756 INFO     Training average positive_sample_loss at step 78800: 0.005170\n",
      "2023-12-01 16:46:47,757 INFO     Training average negative_sample_loss at step 78800: 0.006941\n",
      "2023-12-01 16:46:47,757 INFO     Training average loss at step 78800: 0.006056\n",
      "2023-12-01 16:46:53,411 INFO     Training average positive_sample_loss at step 78900: 0.005281\n",
      "2023-12-01 16:46:53,411 INFO     Training average negative_sample_loss at step 78900: 0.007354\n",
      "2023-12-01 16:46:53,411 INFO     Training average loss at step 78900: 0.006318\n",
      "2023-12-01 16:46:58,883 INFO     Training average positive_sample_loss at step 79000: 0.005286\n",
      "2023-12-01 16:46:58,884 INFO     Training average negative_sample_loss at step 79000: 0.006524\n",
      "2023-12-01 16:46:58,884 INFO     Training average loss at step 79000: 0.005905\n",
      "2023-12-01 16:47:04,361 INFO     Training average positive_sample_loss at step 79100: 0.005340\n",
      "2023-12-01 16:47:04,361 INFO     Training average negative_sample_loss at step 79100: 0.006511\n",
      "2023-12-01 16:47:04,361 INFO     Training average loss at step 79100: 0.005925\n",
      "2023-12-01 16:47:09,851 INFO     Training average positive_sample_loss at step 79200: 0.005381\n",
      "2023-12-01 16:47:09,851 INFO     Training average negative_sample_loss at step 79200: 0.007228\n",
      "2023-12-01 16:47:09,852 INFO     Training average loss at step 79200: 0.006304\n",
      "2023-12-01 16:47:15,844 INFO     Training average positive_sample_loss at step 79300: 0.005227\n",
      "2023-12-01 16:47:15,844 INFO     Training average negative_sample_loss at step 79300: 0.006826\n",
      "2023-12-01 16:47:15,844 INFO     Training average loss at step 79300: 0.006027\n",
      "2023-12-01 16:47:21,290 INFO     Training average positive_sample_loss at step 79400: 0.005195\n",
      "2023-12-01 16:47:21,291 INFO     Training average negative_sample_loss at step 79400: 0.006682\n",
      "2023-12-01 16:47:21,291 INFO     Training average loss at step 79400: 0.005938\n",
      "2023-12-01 16:47:26,800 INFO     Training average positive_sample_loss at step 79500: 0.005271\n",
      "2023-12-01 16:47:26,800 INFO     Training average negative_sample_loss at step 79500: 0.006946\n",
      "2023-12-01 16:47:26,800 INFO     Training average loss at step 79500: 0.006108\n",
      "2023-12-01 16:47:32,294 INFO     Training average positive_sample_loss at step 79600: 0.005347\n",
      "2023-12-01 16:47:32,295 INFO     Training average negative_sample_loss at step 79600: 0.007164\n",
      "2023-12-01 16:47:32,295 INFO     Training average loss at step 79600: 0.006256\n",
      "2023-12-01 16:47:37,780 INFO     Training average positive_sample_loss at step 79700: 0.005357\n",
      "2023-12-01 16:47:37,781 INFO     Training average negative_sample_loss at step 79700: 0.006896\n",
      "2023-12-01 16:47:37,781 INFO     Training average loss at step 79700: 0.006127\n",
      "2023-12-01 16:47:43,902 INFO     Training average positive_sample_loss at step 79800: 0.005321\n",
      "2023-12-01 16:47:43,902 INFO     Training average negative_sample_loss at step 79800: 0.007015\n",
      "2023-12-01 16:47:43,903 INFO     Training average loss at step 79800: 0.006168\n",
      "2023-12-01 16:47:49,355 INFO     Training average positive_sample_loss at step 79900: 0.005200\n",
      "2023-12-01 16:47:49,355 INFO     Training average negative_sample_loss at step 79900: 0.006646\n",
      "2023-12-01 16:47:49,355 INFO     Training average loss at step 79900: 0.005923\n",
      "2023-12-01 16:48:07,178 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 16:48:08,132 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 16:48:43,502 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 16:48:51,015 INFO     Valid MRR at step 79999: 0.950123\n",
      "2023-12-01 16:48:51,015 INFO     Valid MR at step 79999: 316.971500\n",
      "2023-12-01 16:48:51,016 INFO     Valid HITS@1 at step 79999: 0.945700\n",
      "2023-12-01 16:48:51,016 INFO     Valid HITS@3 at step 79999: 0.952000\n",
      "2023-12-01 16:48:51,016 INFO     Valid HITS@10 at step 79999: 0.957600\n",
      "2023-12-01 16:48:51,016 INFO     Evaluating on Test Dataset...\n",
      "2023-12-01 16:48:51,574 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 16:49:23,923 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 16:49:30,760 INFO     Test MRR at step 79999: 0.949705\n",
      "2023-12-01 16:49:30,760 INFO     Test MR at step 79999: 265.895900\n",
      "2023-12-01 16:49:30,760 INFO     Test HITS@1 at step 79999: 0.943900\n",
      "2023-12-01 16:49:30,760 INFO     Test HITS@3 at step 79999: 0.952800\n",
      "2023-12-01 16:49:30,760 INFO     Test HITS@10 at step 79999: 0.960100\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE wn18 0 0 512 1024 500 12.0 0.5 0.0001 80000 8 -de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vsegreto1/lustrehome/vsegreto1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-01 19:49:58,913 INFO     Model: RotatE\n",
      "2023-12-01 19:49:58,913 INFO     Data Path: data/wn18\n",
      "2023-12-01 19:49:58,913 INFO     #entity: 40943\n",
      "2023-12-01 19:49:58,913 INFO     #relation: 18\n",
      "2023-12-01 19:49:59,199 INFO     #train: 141442\n",
      "2023-12-01 19:49:59,259 INFO     #valid: 5000\n",
      "2023-12-01 19:49:59,282 INFO     #test: 5000\n",
      "2023-12-01 19:49:59,492 INFO     Model Parameter Configuration:\n",
      "2023-12-01 19:49:59,493 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-01 19:49:59,493 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-01 19:49:59,493 INFO     Parameter entity_embedding: torch.Size([40943, 1000]), require_grad = True\n",
      "2023-12-01 19:49:59,493 INFO     Parameter relation_embedding: torch.Size([18, 500]), require_grad = True\n",
      "2023-12-01 19:50:02,544 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-01 19:50:02,544 INFO     Start Training...\n",
      "2023-12-01 19:50:02,544 INFO     init_step = 0\n",
      "2023-12-01 19:50:02,544 INFO     batch_size = 512\n",
      "2023-12-01 19:50:02,544 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-01 19:50:02,544 INFO     hidden_dim = 500\n",
      "2023-12-01 19:50:02,544 INFO     gamma = 12.000000\n",
      "2023-12-01 19:50:02,545 INFO     negative_adversarial_sampling = True\n",
      "2023-12-01 19:50:02,545 INFO     adversarial_temperature = 0.500000\n",
      "2023-12-01 19:50:02,545 INFO     learning_rate = 0\n",
      "2023-12-01 19:50:14,330 INFO     Training average positive_sample_loss at step 0: 2.669853\n",
      "2023-12-01 19:50:14,330 INFO     Training average negative_sample_loss at step 0: 0.077264\n",
      "2023-12-01 19:50:14,330 INFO     Training average loss at step 0: 1.373558\n",
      "2023-12-01 19:50:14,331 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 19:50:15,258 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 19:50:52,290 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 19:50:59,968 INFO     Valid MRR at step 0: 0.000245\n",
      "2023-12-01 19:50:59,968 INFO     Valid MR at step 0: 20331.927300\n",
      "2023-12-01 19:50:59,968 INFO     Valid HITS@1 at step 0: 0.000000\n",
      "2023-12-01 19:50:59,968 INFO     Valid HITS@3 at step 0: 0.000000\n",
      "2023-12-01 19:50:59,968 INFO     Valid HITS@10 at step 0: 0.000300\n",
      "2023-12-01 19:51:14,595 INFO     Training average positive_sample_loss at step 100: 3.477244\n",
      "2023-12-01 19:51:14,596 INFO     Training average negative_sample_loss at step 100: 0.061417\n",
      "2023-12-01 19:51:14,596 INFO     Training average loss at step 100: 1.769330\n",
      "2023-12-01 19:51:28,739 INFO     Training average positive_sample_loss at step 200: 3.072534\n",
      "2023-12-01 19:51:28,739 INFO     Training average negative_sample_loss at step 200: 0.130158\n",
      "2023-12-01 19:51:28,739 INFO     Training average loss at step 200: 1.601346\n",
      "2023-12-01 19:51:42,773 INFO     Training average positive_sample_loss at step 300: 2.397330\n",
      "2023-12-01 19:51:42,774 INFO     Training average negative_sample_loss at step 300: 0.210904\n",
      "2023-12-01 19:51:42,774 INFO     Training average loss at step 300: 1.304117\n",
      "2023-12-01 19:51:56,987 INFO     Training average positive_sample_loss at step 400: 1.822658\n",
      "2023-12-01 19:51:56,987 INFO     Training average negative_sample_loss at step 400: 0.285600\n",
      "2023-12-01 19:51:56,987 INFO     Training average loss at step 400: 1.054129\n",
      "2023-12-01 19:52:11,012 INFO     Training average positive_sample_loss at step 500: 1.371457\n",
      "2023-12-01 19:52:11,012 INFO     Training average negative_sample_loss at step 500: 0.346009\n",
      "2023-12-01 19:52:11,012 INFO     Training average loss at step 500: 0.858733\n",
      "2023-12-01 19:52:26,897 INFO     Training average positive_sample_loss at step 600: 0.932329\n",
      "2023-12-01 19:52:26,898 INFO     Training average negative_sample_loss at step 600: 0.389768\n",
      "2023-12-01 19:52:26,898 INFO     Training average loss at step 600: 0.661049\n",
      "2023-12-01 19:52:40,708 INFO     Training average positive_sample_loss at step 700: 0.680544\n",
      "2023-12-01 19:52:40,708 INFO     Training average negative_sample_loss at step 700: 0.395772\n",
      "2023-12-01 19:52:40,708 INFO     Training average loss at step 700: 0.538158\n",
      "2023-12-01 19:52:54,519 INFO     Training average positive_sample_loss at step 800: 0.603196\n",
      "2023-12-01 19:52:54,519 INFO     Training average negative_sample_loss at step 800: 0.390010\n",
      "2023-12-01 19:52:54,519 INFO     Training average loss at step 800: 0.496603\n",
      "2023-12-01 19:53:08,532 INFO     Training average positive_sample_loss at step 900: 0.540106\n",
      "2023-12-01 19:53:08,532 INFO     Training average negative_sample_loss at step 900: 0.382507\n",
      "2023-12-01 19:53:08,532 INFO     Training average loss at step 900: 0.461307\n",
      "2023-12-01 19:53:22,484 INFO     Training average positive_sample_loss at step 1000: 0.484342\n",
      "2023-12-01 19:53:22,485 INFO     Training average negative_sample_loss at step 1000: 0.371144\n",
      "2023-12-01 19:53:22,485 INFO     Training average loss at step 1000: 0.427743\n",
      "2023-12-01 19:53:36,652 INFO     Training average positive_sample_loss at step 1100: 0.438583\n",
      "2023-12-01 19:53:36,652 INFO     Training average negative_sample_loss at step 1100: 0.359738\n",
      "2023-12-01 19:53:36,653 INFO     Training average loss at step 1100: 0.399160\n",
      "2023-12-01 19:53:53,550 INFO     Training average positive_sample_loss at step 1200: 0.347903\n",
      "2023-12-01 19:53:53,551 INFO     Training average negative_sample_loss at step 1200: 0.331552\n",
      "2023-12-01 19:53:53,551 INFO     Training average loss at step 1200: 0.339727\n",
      "2023-12-01 19:54:07,152 INFO     Training average positive_sample_loss at step 1300: 0.342597\n",
      "2023-12-01 19:54:07,152 INFO     Training average negative_sample_loss at step 1300: 0.306610\n",
      "2023-12-01 19:54:07,153 INFO     Training average loss at step 1300: 0.324604\n",
      "2023-12-01 19:54:20,787 INFO     Training average positive_sample_loss at step 1400: 0.330339\n",
      "2023-12-01 19:54:20,787 INFO     Training average negative_sample_loss at step 1400: 0.288090\n",
      "2023-12-01 19:54:20,787 INFO     Training average loss at step 1400: 0.309214\n",
      "2023-12-01 19:54:35,941 INFO     Training average positive_sample_loss at step 1500: 0.316404\n",
      "2023-12-01 19:54:35,942 INFO     Training average negative_sample_loss at step 1500: 0.272882\n",
      "2023-12-01 19:54:35,942 INFO     Training average loss at step 1500: 0.294643\n",
      "2023-12-01 19:54:50,587 INFO     Training average positive_sample_loss at step 1600: 0.300480\n",
      "2023-12-01 19:54:50,587 INFO     Training average negative_sample_loss at step 1600: 0.258762\n",
      "2023-12-01 19:54:50,587 INFO     Training average loss at step 1600: 0.279621\n",
      "2023-12-01 19:55:07,032 INFO     Training average positive_sample_loss at step 1700: 0.268181\n",
      "2023-12-01 19:55:07,032 INFO     Training average negative_sample_loss at step 1700: 0.242592\n",
      "2023-12-01 19:55:07,032 INFO     Training average loss at step 1700: 0.255387\n",
      "2023-12-01 19:55:21,320 INFO     Training average positive_sample_loss at step 1800: 0.242025\n",
      "2023-12-01 19:55:21,320 INFO     Training average negative_sample_loss at step 1800: 0.219950\n",
      "2023-12-01 19:55:21,320 INFO     Training average loss at step 1800: 0.230987\n",
      "2023-12-01 19:55:35,050 INFO     Training average positive_sample_loss at step 1900: 0.240122\n",
      "2023-12-01 19:55:35,051 INFO     Training average negative_sample_loss at step 1900: 0.206005\n",
      "2023-12-01 19:55:35,051 INFO     Training average loss at step 1900: 0.223064\n",
      "2023-12-01 19:55:48,577 INFO     Training average positive_sample_loss at step 2000: 0.232850\n",
      "2023-12-01 19:55:48,577 INFO     Training average negative_sample_loss at step 2000: 0.195656\n",
      "2023-12-01 19:55:48,577 INFO     Training average loss at step 2000: 0.214253\n",
      "2023-12-01 19:56:02,489 INFO     Training average positive_sample_loss at step 2100: 0.223706\n",
      "2023-12-01 19:56:02,489 INFO     Training average negative_sample_loss at step 2100: 0.185425\n",
      "2023-12-01 19:56:02,489 INFO     Training average loss at step 2100: 0.204565\n",
      "2023-12-01 19:56:16,363 INFO     Training average positive_sample_loss at step 2200: 0.213876\n",
      "2023-12-01 19:56:16,364 INFO     Training average negative_sample_loss at step 2200: 0.176508\n",
      "2023-12-01 19:56:16,364 INFO     Training average loss at step 2200: 0.195192\n",
      "2023-12-01 19:56:32,873 INFO     Training average positive_sample_loss at step 2300: 0.182082\n",
      "2023-12-01 19:56:32,873 INFO     Training average negative_sample_loss at step 2300: 0.162530\n",
      "2023-12-01 19:56:32,873 INFO     Training average loss at step 2300: 0.172306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 19:56:46,336 INFO     Training average positive_sample_loss at step 2400: 0.179425\n",
      "2023-12-01 19:56:46,336 INFO     Training average negative_sample_loss at step 2400: 0.150261\n",
      "2023-12-01 19:56:46,336 INFO     Training average loss at step 2400: 0.164843\n",
      "2023-12-01 19:56:59,849 INFO     Training average positive_sample_loss at step 2500: 0.175229\n",
      "2023-12-01 19:56:59,849 INFO     Training average negative_sample_loss at step 2500: 0.142329\n",
      "2023-12-01 19:56:59,849 INFO     Training average loss at step 2500: 0.158779\n",
      "2023-12-01 19:57:13,779 INFO     Training average positive_sample_loss at step 2600: 0.171368\n",
      "2023-12-01 19:57:13,779 INFO     Training average negative_sample_loss at step 2600: 0.136117\n",
      "2023-12-01 19:57:13,779 INFO     Training average loss at step 2600: 0.153743\n",
      "2023-12-01 19:57:27,558 INFO     Training average positive_sample_loss at step 2700: 0.164285\n",
      "2023-12-01 19:57:27,558 INFO     Training average negative_sample_loss at step 2700: 0.130134\n",
      "2023-12-01 19:57:27,558 INFO     Training average loss at step 2700: 0.147209\n",
      "2023-12-01 19:57:43,643 INFO     Training average positive_sample_loss at step 2800: 0.150316\n",
      "2023-12-01 19:57:43,643 INFO     Training average negative_sample_loss at step 2800: 0.123230\n",
      "2023-12-01 19:57:43,643 INFO     Training average loss at step 2800: 0.136773\n",
      "2023-12-01 19:57:57,642 INFO     Training average positive_sample_loss at step 2900: 0.135592\n",
      "2023-12-01 19:57:57,643 INFO     Training average negative_sample_loss at step 2900: 0.112773\n",
      "2023-12-01 19:57:57,643 INFO     Training average loss at step 2900: 0.124182\n",
      "2023-12-01 19:58:11,852 INFO     Training average positive_sample_loss at step 3000: 0.136091\n",
      "2023-12-01 19:58:11,852 INFO     Training average negative_sample_loss at step 3000: 0.106731\n",
      "2023-12-01 19:58:11,852 INFO     Training average loss at step 3000: 0.121411\n",
      "2023-12-01 19:58:25,515 INFO     Training average positive_sample_loss at step 3100: 0.132694\n",
      "2023-12-01 19:58:25,515 INFO     Training average negative_sample_loss at step 3100: 0.102129\n",
      "2023-12-01 19:58:25,515 INFO     Training average loss at step 3100: 0.117411\n",
      "2023-12-01 19:58:39,931 INFO     Training average positive_sample_loss at step 3200: 0.129155\n",
      "2023-12-01 19:58:39,931 INFO     Training average negative_sample_loss at step 3200: 0.097989\n",
      "2023-12-01 19:58:39,931 INFO     Training average loss at step 3200: 0.113572\n",
      "2023-12-01 19:58:54,061 INFO     Training average positive_sample_loss at step 3300: 0.124470\n",
      "2023-12-01 19:58:54,062 INFO     Training average negative_sample_loss at step 3300: 0.094026\n",
      "2023-12-01 19:58:54,062 INFO     Training average loss at step 3300: 0.109248\n",
      "2023-12-01 19:59:10,946 INFO     Training average positive_sample_loss at step 3400: 0.107758\n",
      "2023-12-01 19:59:10,946 INFO     Training average negative_sample_loss at step 3400: 0.087910\n",
      "2023-12-01 19:59:10,946 INFO     Training average loss at step 3400: 0.097834\n",
      "2023-12-01 19:59:24,688 INFO     Training average positive_sample_loss at step 3500: 0.106574\n",
      "2023-12-01 19:59:24,688 INFO     Training average negative_sample_loss at step 3500: 0.082088\n",
      "2023-12-01 19:59:24,688 INFO     Training average loss at step 3500: 0.094331\n",
      "2023-12-01 19:59:38,104 INFO     Training average positive_sample_loss at step 3600: 0.104760\n",
      "2023-12-01 19:59:38,104 INFO     Training average negative_sample_loss at step 3600: 0.078140\n",
      "2023-12-01 19:59:38,104 INFO     Training average loss at step 3600: 0.091450\n",
      "2023-12-01 19:59:52,213 INFO     Training average positive_sample_loss at step 3700: 0.102338\n",
      "2023-12-01 19:59:52,214 INFO     Training average negative_sample_loss at step 3700: 0.075305\n",
      "2023-12-01 19:59:52,214 INFO     Training average loss at step 3700: 0.088821\n",
      "2023-12-01 20:00:06,467 INFO     Training average positive_sample_loss at step 3800: 0.100027\n",
      "2023-12-01 20:00:06,467 INFO     Training average negative_sample_loss at step 3800: 0.072657\n",
      "2023-12-01 20:00:06,467 INFO     Training average loss at step 3800: 0.086342\n",
      "2023-12-01 20:00:23,211 INFO     Training average positive_sample_loss at step 3900: 0.092741\n",
      "2023-12-01 20:00:23,211 INFO     Training average negative_sample_loss at step 3900: 0.069517\n",
      "2023-12-01 20:00:23,211 INFO     Training average loss at step 3900: 0.081129\n",
      "2023-12-01 20:00:37,043 INFO     Training average positive_sample_loss at step 4000: 0.083151\n",
      "2023-12-01 20:00:37,043 INFO     Training average negative_sample_loss at step 4000: 0.064348\n",
      "2023-12-01 20:00:37,043 INFO     Training average loss at step 4000: 0.073750\n",
      "2023-12-01 20:00:51,211 INFO     Training average positive_sample_loss at step 4100: 0.083921\n",
      "2023-12-01 20:00:51,211 INFO     Training average negative_sample_loss at step 4100: 0.061225\n",
      "2023-12-01 20:00:51,211 INFO     Training average loss at step 4100: 0.072573\n",
      "2023-12-01 20:01:04,576 INFO     Training average positive_sample_loss at step 4200: 0.082826\n",
      "2023-12-01 20:01:04,576 INFO     Training average negative_sample_loss at step 4200: 0.058943\n",
      "2023-12-01 20:01:04,576 INFO     Training average loss at step 4200: 0.070885\n",
      "2023-12-01 20:01:18,491 INFO     Training average positive_sample_loss at step 4300: 0.080825\n",
      "2023-12-01 20:01:18,491 INFO     Training average negative_sample_loss at step 4300: 0.056782\n",
      "2023-12-01 20:01:18,491 INFO     Training average loss at step 4300: 0.068804\n",
      "2023-12-01 20:01:33,229 INFO     Training average positive_sample_loss at step 4400: 0.078762\n",
      "2023-12-01 20:01:33,229 INFO     Training average negative_sample_loss at step 4400: 0.055105\n",
      "2023-12-01 20:01:33,229 INFO     Training average loss at step 4400: 0.066934\n",
      "2023-12-01 20:01:49,566 INFO     Training average positive_sample_loss at step 4500: 0.069027\n",
      "2023-12-01 20:01:49,566 INFO     Training average negative_sample_loss at step 4500: 0.052127\n",
      "2023-12-01 20:01:49,566 INFO     Training average loss at step 4500: 0.060577\n",
      "2023-12-01 20:02:03,534 INFO     Training average positive_sample_loss at step 4600: 0.067358\n",
      "2023-12-01 20:02:03,534 INFO     Training average negative_sample_loss at step 4600: 0.048582\n",
      "2023-12-01 20:02:03,534 INFO     Training average loss at step 4600: 0.057970\n",
      "2023-12-01 20:02:17,009 INFO     Training average positive_sample_loss at step 4700: 0.067387\n",
      "2023-12-01 20:02:17,009 INFO     Training average negative_sample_loss at step 4700: 0.046767\n",
      "2023-12-01 20:02:17,010 INFO     Training average loss at step 4700: 0.057077\n",
      "2023-12-01 20:02:31,198 INFO     Training average positive_sample_loss at step 4800: 0.066696\n",
      "2023-12-01 20:02:31,198 INFO     Training average negative_sample_loss at step 4800: 0.045341\n",
      "2023-12-01 20:02:31,199 INFO     Training average loss at step 4800: 0.056019\n",
      "2023-12-01 20:02:46,422 INFO     Training average positive_sample_loss at step 4900: 0.064934\n",
      "2023-12-01 20:02:46,423 INFO     Training average negative_sample_loss at step 4900: 0.044097\n",
      "2023-12-01 20:02:46,423 INFO     Training average loss at step 4900: 0.054515\n",
      "2023-12-01 20:03:02,413 INFO     Training average positive_sample_loss at step 5000: 0.061160\n",
      "2023-12-01 20:03:02,413 INFO     Training average negative_sample_loss at step 5000: 0.042310\n",
      "2023-12-01 20:03:02,413 INFO     Training average loss at step 5000: 0.051735\n",
      "2023-12-01 20:03:16,330 INFO     Training average positive_sample_loss at step 5100: 0.054245\n",
      "2023-12-01 20:03:16,330 INFO     Training average negative_sample_loss at step 5100: 0.039491\n",
      "2023-12-01 20:03:16,330 INFO     Training average loss at step 5100: 0.046868\n",
      "2023-12-01 20:03:30,163 INFO     Training average positive_sample_loss at step 5200: 0.055448\n",
      "2023-12-01 20:03:30,163 INFO     Training average negative_sample_loss at step 5200: 0.037731\n",
      "2023-12-01 20:03:30,163 INFO     Training average loss at step 5200: 0.046589\n",
      "2023-12-01 20:03:44,258 INFO     Training average positive_sample_loss at step 5300: 0.055242\n",
      "2023-12-01 20:03:44,258 INFO     Training average negative_sample_loss at step 5300: 0.036533\n",
      "2023-12-01 20:03:44,258 INFO     Training average loss at step 5300: 0.045887\n",
      "2023-12-01 20:03:58,685 INFO     Training average positive_sample_loss at step 5400: 0.054078\n",
      "2023-12-01 20:03:58,686 INFO     Training average negative_sample_loss at step 5400: 0.035512\n",
      "2023-12-01 20:03:58,686 INFO     Training average loss at step 5400: 0.044795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 20:04:12,324 INFO     Training average positive_sample_loss at step 5500: 0.052712\n",
      "2023-12-01 20:04:12,324 INFO     Training average negative_sample_loss at step 5500: 0.034635\n",
      "2023-12-01 20:04:12,324 INFO     Training average loss at step 5500: 0.043673\n",
      "2023-12-01 20:04:28,974 INFO     Training average positive_sample_loss at step 5600: 0.046953\n",
      "2023-12-01 20:04:28,974 INFO     Training average negative_sample_loss at step 5600: 0.032898\n",
      "2023-12-01 20:04:28,974 INFO     Training average loss at step 5600: 0.039925\n",
      "2023-12-01 20:04:44,027 INFO     Training average positive_sample_loss at step 5700: 0.045619\n",
      "2023-12-01 20:04:44,027 INFO     Training average negative_sample_loss at step 5700: 0.030946\n",
      "2023-12-01 20:04:44,027 INFO     Training average loss at step 5700: 0.038283\n",
      "2023-12-01 20:04:58,735 INFO     Training average positive_sample_loss at step 5800: 0.046303\n",
      "2023-12-01 20:04:58,736 INFO     Training average negative_sample_loss at step 5800: 0.029995\n",
      "2023-12-01 20:04:58,736 INFO     Training average loss at step 5800: 0.038149\n",
      "2023-12-01 20:05:12,444 INFO     Training average positive_sample_loss at step 5900: 0.045282\n",
      "2023-12-01 20:05:12,445 INFO     Training average negative_sample_loss at step 5900: 0.029097\n",
      "2023-12-01 20:05:12,445 INFO     Training average loss at step 5900: 0.037189\n",
      "2023-12-01 20:05:27,237 INFO     Training average positive_sample_loss at step 6000: 0.044411\n",
      "2023-12-01 20:05:27,238 INFO     Training average negative_sample_loss at step 6000: 0.028258\n",
      "2023-12-01 20:05:27,238 INFO     Training average loss at step 6000: 0.036335\n",
      "2023-12-01 20:05:44,099 INFO     Training average positive_sample_loss at step 6100: 0.042766\n",
      "2023-12-01 20:05:44,099 INFO     Training average negative_sample_loss at step 6100: 0.027489\n",
      "2023-12-01 20:05:44,099 INFO     Training average loss at step 6100: 0.035127\n",
      "2023-12-01 20:05:58,548 INFO     Training average positive_sample_loss at step 6200: 0.037402\n",
      "2023-12-01 20:05:58,548 INFO     Training average negative_sample_loss at step 6200: 0.025847\n",
      "2023-12-01 20:05:58,548 INFO     Training average loss at step 6200: 0.031624\n",
      "2023-12-01 20:06:13,878 INFO     Training average positive_sample_loss at step 6300: 0.038529\n",
      "2023-12-01 20:06:13,878 INFO     Training average negative_sample_loss at step 6300: 0.024673\n",
      "2023-12-01 20:06:13,878 INFO     Training average loss at step 6300: 0.031601\n",
      "2023-12-01 20:06:28,662 INFO     Training average positive_sample_loss at step 6400: 0.038468\n",
      "2023-12-01 20:06:28,662 INFO     Training average negative_sample_loss at step 6400: 0.024060\n",
      "2023-12-01 20:06:28,662 INFO     Training average loss at step 6400: 0.031264\n",
      "2023-12-01 20:06:43,083 INFO     Training average positive_sample_loss at step 6500: 0.038336\n",
      "2023-12-01 20:06:43,084 INFO     Training average negative_sample_loss at step 6500: 0.023601\n",
      "2023-12-01 20:06:43,084 INFO     Training average loss at step 6500: 0.030968\n",
      "2023-12-01 20:06:57,140 INFO     Training average positive_sample_loss at step 6600: 0.037199\n",
      "2023-12-01 20:06:57,140 INFO     Training average negative_sample_loss at step 6600: 0.023131\n",
      "2023-12-01 20:06:57,140 INFO     Training average loss at step 6600: 0.030165\n",
      "2023-12-01 20:07:13,884 INFO     Training average positive_sample_loss at step 6700: 0.033754\n",
      "2023-12-01 20:07:13,884 INFO     Training average negative_sample_loss at step 6700: 0.022128\n",
      "2023-12-01 20:07:13,884 INFO     Training average loss at step 6700: 0.027941\n",
      "2023-12-01 20:07:28,223 INFO     Training average positive_sample_loss at step 6800: 0.032535\n",
      "2023-12-01 20:07:28,223 INFO     Training average negative_sample_loss at step 6800: 0.020929\n",
      "2023-12-01 20:07:28,223 INFO     Training average loss at step 6800: 0.026732\n",
      "2023-12-01 20:07:41,673 INFO     Training average positive_sample_loss at step 6900: 0.032974\n",
      "2023-12-01 20:07:41,673 INFO     Training average negative_sample_loss at step 6900: 0.020302\n",
      "2023-12-01 20:07:41,673 INFO     Training average loss at step 6900: 0.026638\n",
      "2023-12-01 20:07:55,112 INFO     Training average positive_sample_loss at step 7000: 0.032509\n",
      "2023-12-01 20:07:55,112 INFO     Training average negative_sample_loss at step 7000: 0.019812\n",
      "2023-12-01 20:07:55,112 INFO     Training average loss at step 7000: 0.026160\n",
      "2023-12-01 20:08:08,942 INFO     Training average positive_sample_loss at step 7100: 0.031971\n",
      "2023-12-01 20:08:08,942 INFO     Training average negative_sample_loss at step 7100: 0.019337\n",
      "2023-12-01 20:08:08,942 INFO     Training average loss at step 7100: 0.025654\n",
      "2023-12-01 20:08:22,888 INFO     Training average positive_sample_loss at step 7200: 0.031525\n",
      "2023-12-01 20:08:22,888 INFO     Training average negative_sample_loss at step 7200: 0.018920\n",
      "2023-12-01 20:08:22,888 INFO     Training average loss at step 7200: 0.025222\n",
      "2023-12-01 20:08:39,543 INFO     Training average positive_sample_loss at step 7300: 0.027378\n",
      "2023-12-01 20:08:39,543 INFO     Training average negative_sample_loss at step 7300: 0.017960\n",
      "2023-12-01 20:08:39,544 INFO     Training average loss at step 7300: 0.022669\n",
      "2023-12-01 20:08:53,347 INFO     Training average positive_sample_loss at step 7400: 0.028197\n",
      "2023-12-01 20:08:53,347 INFO     Training average negative_sample_loss at step 7400: 0.017258\n",
      "2023-12-01 20:08:53,347 INFO     Training average loss at step 7400: 0.022728\n",
      "2023-12-01 20:09:07,002 INFO     Training average positive_sample_loss at step 7500: 0.028263\n",
      "2023-12-01 20:09:07,002 INFO     Training average negative_sample_loss at step 7500: 0.016940\n",
      "2023-12-01 20:09:07,002 INFO     Training average loss at step 7500: 0.022602\n",
      "2023-12-01 20:09:21,644 INFO     Training average positive_sample_loss at step 7600: 0.028200\n",
      "2023-12-01 20:09:21,645 INFO     Training average negative_sample_loss at step 7600: 0.016620\n",
      "2023-12-01 20:09:21,645 INFO     Training average loss at step 7600: 0.022410\n",
      "2023-12-01 20:09:35,707 INFO     Training average positive_sample_loss at step 7700: 0.027421\n",
      "2023-12-01 20:09:35,707 INFO     Training average negative_sample_loss at step 7700: 0.016310\n",
      "2023-12-01 20:09:35,707 INFO     Training average loss at step 7700: 0.021865\n",
      "2023-12-01 20:09:52,930 INFO     Training average positive_sample_loss at step 7800: 0.025173\n",
      "2023-12-01 20:09:52,930 INFO     Training average negative_sample_loss at step 7800: 0.015678\n",
      "2023-12-01 20:09:52,930 INFO     Training average loss at step 7800: 0.020425\n",
      "2023-12-01 20:10:06,877 INFO     Training average positive_sample_loss at step 7900: 0.023985\n",
      "2023-12-01 20:10:06,877 INFO     Training average negative_sample_loss at step 7900: 0.014943\n",
      "2023-12-01 20:10:06,877 INFO     Training average loss at step 7900: 0.019464\n",
      "2023-12-01 20:10:21,254 INFO     Training average positive_sample_loss at step 8000: 0.024566\n",
      "2023-12-01 20:10:21,254 INFO     Training average negative_sample_loss at step 8000: 0.014491\n",
      "2023-12-01 20:10:21,254 INFO     Training average loss at step 8000: 0.019528\n",
      "2023-12-01 20:10:35,200 INFO     Training average positive_sample_loss at step 8100: 0.024804\n",
      "2023-12-01 20:10:35,201 INFO     Training average negative_sample_loss at step 8100: 0.014402\n",
      "2023-12-01 20:10:35,201 INFO     Training average loss at step 8100: 0.019603\n",
      "2023-12-01 20:10:49,535 INFO     Training average positive_sample_loss at step 8200: 0.024512\n",
      "2023-12-01 20:10:49,535 INFO     Training average negative_sample_loss at step 8200: 0.014174\n",
      "2023-12-01 20:10:49,535 INFO     Training average loss at step 8200: 0.019343\n",
      "2023-12-01 20:11:03,506 INFO     Training average positive_sample_loss at step 8300: 0.023990\n",
      "2023-12-01 20:11:03,506 INFO     Training average negative_sample_loss at step 8300: 0.014026\n",
      "2023-12-01 20:11:03,506 INFO     Training average loss at step 8300: 0.019008\n",
      "2023-12-01 20:11:19,656 INFO     Training average positive_sample_loss at step 8400: 0.020939\n",
      "2023-12-01 20:11:19,657 INFO     Training average negative_sample_loss at step 8400: 0.013347\n",
      "2023-12-01 20:11:19,657 INFO     Training average loss at step 8400: 0.017143\n",
      "2023-12-01 20:11:34,192 INFO     Training average positive_sample_loss at step 8500: 0.021554\n",
      "2023-12-01 20:11:34,192 INFO     Training average negative_sample_loss at step 8500: 0.012859\n",
      "2023-12-01 20:11:34,192 INFO     Training average loss at step 8500: 0.017206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 20:11:48,211 INFO     Training average positive_sample_loss at step 8600: 0.021678\n",
      "2023-12-01 20:11:48,211 INFO     Training average negative_sample_loss at step 8600: 0.012575\n",
      "2023-12-01 20:11:48,211 INFO     Training average loss at step 8600: 0.017126\n",
      "2023-12-01 20:12:02,145 INFO     Training average positive_sample_loss at step 8700: 0.021701\n",
      "2023-12-01 20:12:02,146 INFO     Training average negative_sample_loss at step 8700: 0.012390\n",
      "2023-12-01 20:12:02,146 INFO     Training average loss at step 8700: 0.017045\n",
      "2023-12-01 20:12:16,322 INFO     Training average positive_sample_loss at step 8800: 0.021286\n",
      "2023-12-01 20:12:16,322 INFO     Training average negative_sample_loss at step 8800: 0.012287\n",
      "2023-12-01 20:12:16,322 INFO     Training average loss at step 8800: 0.016787\n",
      "2023-12-01 20:12:32,873 INFO     Training average positive_sample_loss at step 8900: 0.020022\n",
      "2023-12-01 20:12:32,874 INFO     Training average negative_sample_loss at step 8900: 0.012173\n",
      "2023-12-01 20:12:32,874 INFO     Training average loss at step 8900: 0.016098\n",
      "2023-12-01 20:12:46,573 INFO     Training average positive_sample_loss at step 9000: 0.018875\n",
      "2023-12-01 20:12:46,574 INFO     Training average negative_sample_loss at step 9000: 0.011497\n",
      "2023-12-01 20:12:46,574 INFO     Training average loss at step 9000: 0.015186\n",
      "2023-12-01 20:13:00,308 INFO     Training average positive_sample_loss at step 9100: 0.019293\n",
      "2023-12-01 20:13:00,308 INFO     Training average negative_sample_loss at step 9100: 0.011364\n",
      "2023-12-01 20:13:00,308 INFO     Training average loss at step 9100: 0.015329\n",
      "2023-12-01 20:13:14,104 INFO     Training average positive_sample_loss at step 9200: 0.019422\n",
      "2023-12-01 20:13:14,105 INFO     Training average negative_sample_loss at step 9200: 0.011155\n",
      "2023-12-01 20:13:14,105 INFO     Training average loss at step 9200: 0.015289\n",
      "2023-12-01 20:13:28,149 INFO     Training average positive_sample_loss at step 9300: 0.019343\n",
      "2023-12-01 20:13:28,150 INFO     Training average negative_sample_loss at step 9300: 0.011042\n",
      "2023-12-01 20:13:28,150 INFO     Training average loss at step 9300: 0.015192\n",
      "2023-12-01 20:13:42,326 INFO     Training average positive_sample_loss at step 9400: 0.018887\n",
      "2023-12-01 20:13:42,326 INFO     Training average negative_sample_loss at step 9400: 0.011066\n",
      "2023-12-01 20:13:42,326 INFO     Training average loss at step 9400: 0.014977\n",
      "2023-12-01 20:13:58,589 INFO     Training average positive_sample_loss at step 9500: 0.016822\n",
      "2023-12-01 20:13:58,590 INFO     Training average negative_sample_loss at step 9500: 0.010471\n",
      "2023-12-01 20:13:58,590 INFO     Training average loss at step 9500: 0.013647\n",
      "2023-12-01 20:14:12,447 INFO     Training average positive_sample_loss at step 9600: 0.017224\n",
      "2023-12-01 20:14:12,447 INFO     Training average negative_sample_loss at step 9600: 0.010175\n",
      "2023-12-01 20:14:12,447 INFO     Training average loss at step 9600: 0.013700\n",
      "2023-12-01 20:14:26,360 INFO     Training average positive_sample_loss at step 9700: 0.017582\n",
      "2023-12-01 20:14:26,360 INFO     Training average negative_sample_loss at step 9700: 0.010236\n",
      "2023-12-01 20:14:26,360 INFO     Training average loss at step 9700: 0.013909\n",
      "2023-12-01 20:14:40,609 INFO     Training average positive_sample_loss at step 9800: 0.017599\n",
      "2023-12-01 20:14:40,609 INFO     Training average negative_sample_loss at step 9800: 0.009900\n",
      "2023-12-01 20:14:40,609 INFO     Training average loss at step 9800: 0.013749\n",
      "2023-12-01 20:14:54,761 INFO     Training average positive_sample_loss at step 9900: 0.017292\n",
      "2023-12-01 20:14:54,761 INFO     Training average negative_sample_loss at step 9900: 0.009916\n",
      "2023-12-01 20:14:54,762 INFO     Training average loss at step 9900: 0.013604\n",
      "2023-12-01 20:15:24,004 INFO     Training average positive_sample_loss at step 10000: 0.016367\n",
      "2023-12-01 20:15:24,005 INFO     Training average negative_sample_loss at step 10000: 0.009820\n",
      "2023-12-01 20:15:24,005 INFO     Training average loss at step 10000: 0.013093\n",
      "2023-12-01 20:15:24,005 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 20:15:24,579 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 20:15:58,215 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 20:16:06,570 INFO     Valid MRR at step 10000: 0.945679\n",
      "2023-12-01 20:16:06,571 INFO     Valid MR at step 10000: 519.115900\n",
      "2023-12-01 20:16:06,571 INFO     Valid HITS@1 at step 10000: 0.940900\n",
      "2023-12-01 20:16:06,571 INFO     Valid HITS@3 at step 10000: 0.948700\n",
      "2023-12-01 20:16:06,571 INFO     Valid HITS@10 at step 10000: 0.954400\n",
      "2023-12-01 20:16:18,539 INFO     Training average positive_sample_loss at step 10100: 0.015306\n",
      "2023-12-01 20:16:18,539 INFO     Training average negative_sample_loss at step 10100: 0.009421\n",
      "2023-12-01 20:16:18,540 INFO     Training average loss at step 10100: 0.012364\n",
      "2023-12-01 20:16:32,312 INFO     Training average positive_sample_loss at step 10200: 0.015892\n",
      "2023-12-01 20:16:32,312 INFO     Training average negative_sample_loss at step 10200: 0.009208\n",
      "2023-12-01 20:16:32,312 INFO     Training average loss at step 10200: 0.012550\n",
      "2023-12-01 20:16:46,817 INFO     Training average positive_sample_loss at step 10300: 0.015909\n",
      "2023-12-01 20:16:46,817 INFO     Training average negative_sample_loss at step 10300: 0.009162\n",
      "2023-12-01 20:16:46,817 INFO     Training average loss at step 10300: 0.012536\n",
      "2023-12-01 20:17:00,986 INFO     Training average positive_sample_loss at step 10400: 0.015853\n",
      "2023-12-01 20:17:00,986 INFO     Training average negative_sample_loss at step 10400: 0.009226\n",
      "2023-12-01 20:17:00,987 INFO     Training average loss at step 10400: 0.012539\n",
      "2023-12-01 20:17:14,624 INFO     Training average positive_sample_loss at step 10500: 0.015687\n",
      "2023-12-01 20:17:14,625 INFO     Training average negative_sample_loss at step 10500: 0.009037\n",
      "2023-12-01 20:17:14,625 INFO     Training average loss at step 10500: 0.012362\n",
      "2023-12-01 20:17:31,510 INFO     Training average positive_sample_loss at step 10600: 0.014082\n",
      "2023-12-01 20:17:31,510 INFO     Training average negative_sample_loss at step 10600: 0.008774\n",
      "2023-12-01 20:17:31,510 INFO     Training average loss at step 10600: 0.011428\n",
      "2023-12-01 20:17:46,201 INFO     Training average positive_sample_loss at step 10700: 0.014313\n",
      "2023-12-01 20:17:46,201 INFO     Training average negative_sample_loss at step 10700: 0.008488\n",
      "2023-12-01 20:17:46,201 INFO     Training average loss at step 10700: 0.011400\n",
      "2023-12-01 20:18:00,412 INFO     Training average positive_sample_loss at step 10800: 0.014676\n",
      "2023-12-01 20:18:00,413 INFO     Training average negative_sample_loss at step 10800: 0.008604\n",
      "2023-12-01 20:18:00,413 INFO     Training average loss at step 10800: 0.011640\n",
      "2023-12-01 20:18:15,192 INFO     Training average positive_sample_loss at step 10900: 0.014737\n",
      "2023-12-01 20:18:15,192 INFO     Training average negative_sample_loss at step 10900: 0.008645\n",
      "2023-12-01 20:18:15,192 INFO     Training average loss at step 10900: 0.011691\n",
      "2023-12-01 20:18:29,956 INFO     Training average positive_sample_loss at step 11000: 0.014598\n",
      "2023-12-01 20:18:29,956 INFO     Training average negative_sample_loss at step 11000: 0.008591\n",
      "2023-12-01 20:18:29,956 INFO     Training average loss at step 11000: 0.011595\n",
      "2023-12-01 20:18:46,085 INFO     Training average positive_sample_loss at step 11100: 0.013985\n",
      "2023-12-01 20:18:46,085 INFO     Training average negative_sample_loss at step 11100: 0.008394\n",
      "2023-12-01 20:18:46,085 INFO     Training average loss at step 11100: 0.011189\n",
      "2023-12-01 20:19:00,529 INFO     Training average positive_sample_loss at step 11200: 0.013015\n",
      "2023-12-01 20:19:00,529 INFO     Training average negative_sample_loss at step 11200: 0.008147\n",
      "2023-12-01 20:19:00,529 INFO     Training average loss at step 11200: 0.010581\n",
      "2023-12-01 20:19:15,057 INFO     Training average positive_sample_loss at step 11300: 0.013390\n",
      "2023-12-01 20:19:15,058 INFO     Training average negative_sample_loss at step 11300: 0.007902\n",
      "2023-12-01 20:19:15,058 INFO     Training average loss at step 11300: 0.010646\n",
      "2023-12-01 20:19:29,872 INFO     Training average positive_sample_loss at step 11400: 0.013672\n",
      "2023-12-01 20:19:29,873 INFO     Training average negative_sample_loss at step 11400: 0.007966\n",
      "2023-12-01 20:19:29,873 INFO     Training average loss at step 11400: 0.010819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 20:19:43,792 INFO     Training average positive_sample_loss at step 11500: 0.013683\n",
      "2023-12-01 20:19:43,792 INFO     Training average negative_sample_loss at step 11500: 0.007978\n",
      "2023-12-01 20:19:43,792 INFO     Training average loss at step 11500: 0.010831\n",
      "2023-12-01 20:19:57,387 INFO     Training average positive_sample_loss at step 11600: 0.013481\n",
      "2023-12-01 20:19:57,387 INFO     Training average negative_sample_loss at step 11600: 0.007834\n",
      "2023-12-01 20:19:57,387 INFO     Training average loss at step 11600: 0.010657\n",
      "2023-12-01 20:20:13,956 INFO     Training average positive_sample_loss at step 11700: 0.012342\n",
      "2023-12-01 20:20:13,957 INFO     Training average negative_sample_loss at step 11700: 0.007803\n",
      "2023-12-01 20:20:13,957 INFO     Training average loss at step 11700: 0.010073\n",
      "2023-12-01 20:20:27,811 INFO     Training average positive_sample_loss at step 11800: 0.012310\n",
      "2023-12-01 20:20:27,812 INFO     Training average negative_sample_loss at step 11800: 0.007590\n",
      "2023-12-01 20:20:27,812 INFO     Training average loss at step 11800: 0.009950\n",
      "2023-12-01 20:20:41,687 INFO     Training average positive_sample_loss at step 11900: 0.012683\n",
      "2023-12-01 20:20:41,687 INFO     Training average negative_sample_loss at step 11900: 0.007599\n",
      "2023-12-01 20:20:41,688 INFO     Training average loss at step 11900: 0.010141\n",
      "2023-12-01 20:20:56,030 INFO     Training average positive_sample_loss at step 12000: 0.012893\n",
      "2023-12-01 20:20:56,030 INFO     Training average negative_sample_loss at step 12000: 0.007585\n",
      "2023-12-01 20:20:56,030 INFO     Training average loss at step 12000: 0.010239\n",
      "2023-12-01 20:21:09,806 INFO     Training average positive_sample_loss at step 12100: 0.012861\n",
      "2023-12-01 20:21:09,806 INFO     Training average negative_sample_loss at step 12100: 0.007598\n",
      "2023-12-01 20:21:09,806 INFO     Training average loss at step 12100: 0.010229\n",
      "2023-12-01 20:21:27,378 INFO     Training average positive_sample_loss at step 12200: 0.012258\n",
      "2023-12-01 20:21:27,378 INFO     Training average negative_sample_loss at step 12200: 0.007635\n",
      "2023-12-01 20:21:27,379 INFO     Training average loss at step 12200: 0.009947\n",
      "2023-12-01 20:21:40,838 INFO     Training average positive_sample_loss at step 12300: 0.011322\n",
      "2023-12-01 20:21:40,839 INFO     Training average negative_sample_loss at step 12300: 0.007568\n",
      "2023-12-01 20:21:40,839 INFO     Training average loss at step 12300: 0.009445\n",
      "2023-12-01 20:21:54,637 INFO     Training average positive_sample_loss at step 12400: 0.011910\n",
      "2023-12-01 20:21:54,637 INFO     Training average negative_sample_loss at step 12400: 0.007229\n",
      "2023-12-01 20:21:54,637 INFO     Training average loss at step 12400: 0.009570\n",
      "2023-12-01 20:22:08,112 INFO     Training average positive_sample_loss at step 12500: 0.011982\n",
      "2023-12-01 20:22:08,113 INFO     Training average negative_sample_loss at step 12500: 0.007420\n",
      "2023-12-01 20:22:08,113 INFO     Training average loss at step 12500: 0.009701\n",
      "2023-12-01 20:22:22,214 INFO     Training average positive_sample_loss at step 12600: 0.012150\n",
      "2023-12-01 20:22:22,215 INFO     Training average negative_sample_loss at step 12600: 0.007548\n",
      "2023-12-01 20:22:22,215 INFO     Training average loss at step 12600: 0.009849\n",
      "2023-12-01 20:22:36,411 INFO     Training average positive_sample_loss at step 12700: 0.012115\n",
      "2023-12-01 20:22:36,411 INFO     Training average negative_sample_loss at step 12700: 0.007552\n",
      "2023-12-01 20:22:36,412 INFO     Training average loss at step 12700: 0.009834\n",
      "2023-12-01 20:22:52,401 INFO     Training average positive_sample_loss at step 12800: 0.011046\n",
      "2023-12-01 20:22:52,402 INFO     Training average negative_sample_loss at step 12800: 0.007127\n",
      "2023-12-01 20:22:52,402 INFO     Training average loss at step 12800: 0.009086\n",
      "2023-12-01 20:23:06,433 INFO     Training average positive_sample_loss at step 12900: 0.010885\n",
      "2023-12-01 20:23:06,433 INFO     Training average negative_sample_loss at step 12900: 0.006981\n",
      "2023-12-01 20:23:06,433 INFO     Training average loss at step 12900: 0.008933\n",
      "2023-12-01 20:23:20,393 INFO     Training average positive_sample_loss at step 13000: 0.011454\n",
      "2023-12-01 20:23:20,393 INFO     Training average negative_sample_loss at step 13000: 0.006968\n",
      "2023-12-01 20:23:20,393 INFO     Training average loss at step 13000: 0.009211\n",
      "2023-12-01 20:23:34,587 INFO     Training average positive_sample_loss at step 13100: 0.011433\n",
      "2023-12-01 20:23:34,587 INFO     Training average negative_sample_loss at step 13100: 0.006844\n",
      "2023-12-01 20:23:34,587 INFO     Training average loss at step 13100: 0.009139\n",
      "2023-12-01 20:23:49,874 INFO     Training average positive_sample_loss at step 13200: 0.011519\n",
      "2023-12-01 20:23:49,874 INFO     Training average negative_sample_loss at step 13200: 0.007299\n",
      "2023-12-01 20:23:49,874 INFO     Training average loss at step 13200: 0.009409\n",
      "2023-12-01 20:24:08,174 INFO     Training average positive_sample_loss at step 13300: 0.011218\n",
      "2023-12-01 20:24:08,175 INFO     Training average negative_sample_loss at step 13300: 0.007250\n",
      "2023-12-01 20:24:08,175 INFO     Training average loss at step 13300: 0.009234\n",
      "2023-12-01 20:24:22,030 INFO     Training average positive_sample_loss at step 13400: 0.010133\n",
      "2023-12-01 20:24:22,031 INFO     Training average negative_sample_loss at step 13400: 0.006832\n",
      "2023-12-01 20:24:22,031 INFO     Training average loss at step 13400: 0.008483\n",
      "2023-12-01 20:24:35,893 INFO     Training average positive_sample_loss at step 13500: 0.010788\n",
      "2023-12-01 20:24:35,893 INFO     Training average negative_sample_loss at step 13500: 0.007104\n",
      "2023-12-01 20:24:35,894 INFO     Training average loss at step 13500: 0.008946\n",
      "2023-12-01 20:24:49,732 INFO     Training average positive_sample_loss at step 13600: 0.011041\n",
      "2023-12-01 20:24:49,733 INFO     Training average negative_sample_loss at step 13600: 0.006957\n",
      "2023-12-01 20:24:49,733 INFO     Training average loss at step 13600: 0.008999\n",
      "2023-12-01 20:25:03,982 INFO     Training average positive_sample_loss at step 13700: 0.010856\n",
      "2023-12-01 20:25:03,982 INFO     Training average negative_sample_loss at step 13700: 0.007127\n",
      "2023-12-01 20:25:03,982 INFO     Training average loss at step 13700: 0.008991\n",
      "2023-12-01 20:25:18,626 INFO     Training average positive_sample_loss at step 13800: 0.010928\n",
      "2023-12-01 20:25:18,627 INFO     Training average negative_sample_loss at step 13800: 0.007034\n",
      "2023-12-01 20:25:18,627 INFO     Training average loss at step 13800: 0.008981\n",
      "2023-12-01 20:25:34,708 INFO     Training average positive_sample_loss at step 13900: 0.010023\n",
      "2023-12-01 20:25:34,709 INFO     Training average negative_sample_loss at step 13900: 0.006773\n",
      "2023-12-01 20:25:34,709 INFO     Training average loss at step 13900: 0.008398\n",
      "2023-12-01 20:25:48,305 INFO     Training average positive_sample_loss at step 14000: 0.009985\n",
      "2023-12-01 20:25:48,305 INFO     Training average negative_sample_loss at step 14000: 0.006702\n",
      "2023-12-01 20:25:48,306 INFO     Training average loss at step 14000: 0.008344\n",
      "2023-12-01 20:26:02,758 INFO     Training average positive_sample_loss at step 14100: 0.010504\n",
      "2023-12-01 20:26:02,758 INFO     Training average negative_sample_loss at step 14100: 0.006959\n",
      "2023-12-01 20:26:02,758 INFO     Training average loss at step 14100: 0.008732\n",
      "2023-12-01 20:26:17,640 INFO     Training average positive_sample_loss at step 14200: 0.010563\n",
      "2023-12-01 20:26:17,640 INFO     Training average negative_sample_loss at step 14200: 0.006619\n",
      "2023-12-01 20:26:17,640 INFO     Training average loss at step 14200: 0.008591\n",
      "2023-12-01 20:26:31,962 INFO     Training average positive_sample_loss at step 14300: 0.010478\n",
      "2023-12-01 20:26:31,962 INFO     Training average negative_sample_loss at step 14300: 0.006833\n",
      "2023-12-01 20:26:31,962 INFO     Training average loss at step 14300: 0.008656\n",
      "2023-12-01 20:26:46,273 INFO     Training average positive_sample_loss at step 14400: 0.010578\n",
      "2023-12-01 20:26:46,273 INFO     Training average negative_sample_loss at step 14400: 0.006981\n",
      "2023-12-01 20:26:46,273 INFO     Training average loss at step 14400: 0.008780\n",
      "2023-12-01 20:27:04,161 INFO     Training average positive_sample_loss at step 14500: 0.009249\n",
      "2023-12-01 20:27:04,161 INFO     Training average negative_sample_loss at step 14500: 0.006604\n",
      "2023-12-01 20:27:04,161 INFO     Training average loss at step 14500: 0.007927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 20:27:17,874 INFO     Training average positive_sample_loss at step 14600: 0.009886\n",
      "2023-12-01 20:27:17,875 INFO     Training average negative_sample_loss at step 14600: 0.006450\n",
      "2023-12-01 20:27:17,875 INFO     Training average loss at step 14600: 0.008168\n",
      "2023-12-01 20:27:31,507 INFO     Training average positive_sample_loss at step 14700: 0.010196\n",
      "2023-12-01 20:27:31,507 INFO     Training average negative_sample_loss at step 14700: 0.006500\n",
      "2023-12-01 20:27:31,507 INFO     Training average loss at step 14700: 0.008348\n",
      "2023-12-01 20:27:45,374 INFO     Training average positive_sample_loss at step 14800: 0.010177\n",
      "2023-12-01 20:27:45,374 INFO     Training average negative_sample_loss at step 14800: 0.007065\n",
      "2023-12-01 20:27:45,374 INFO     Training average loss at step 14800: 0.008621\n",
      "2023-12-01 20:27:59,068 INFO     Training average positive_sample_loss at step 14900: 0.010052\n",
      "2023-12-01 20:27:59,068 INFO     Training average negative_sample_loss at step 14900: 0.006553\n",
      "2023-12-01 20:27:59,068 INFO     Training average loss at step 14900: 0.008303\n",
      "2023-12-01 20:28:15,892 INFO     Training average positive_sample_loss at step 15000: 0.009456\n",
      "2023-12-01 20:28:15,892 INFO     Training average negative_sample_loss at step 15000: 0.006675\n",
      "2023-12-01 20:28:15,892 INFO     Training average loss at step 15000: 0.008065\n",
      "2023-12-01 20:28:29,555 INFO     Training average positive_sample_loss at step 15100: 0.009296\n",
      "2023-12-01 20:28:29,555 INFO     Training average negative_sample_loss at step 15100: 0.006580\n",
      "2023-12-01 20:28:29,555 INFO     Training average loss at step 15100: 0.007938\n",
      "2023-12-01 20:28:43,638 INFO     Training average positive_sample_loss at step 15200: 0.009662\n",
      "2023-12-01 20:28:43,638 INFO     Training average negative_sample_loss at step 15200: 0.006522\n",
      "2023-12-01 20:28:43,638 INFO     Training average loss at step 15200: 0.008092\n",
      "2023-12-01 20:28:57,796 INFO     Training average positive_sample_loss at step 15300: 0.009710\n",
      "2023-12-01 20:28:57,797 INFO     Training average negative_sample_loss at step 15300: 0.006524\n",
      "2023-12-01 20:28:57,797 INFO     Training average loss at step 15300: 0.008117\n",
      "2023-12-01 20:29:12,315 INFO     Training average positive_sample_loss at step 15400: 0.009839\n",
      "2023-12-01 20:29:12,315 INFO     Training average negative_sample_loss at step 15400: 0.006594\n",
      "2023-12-01 20:29:12,315 INFO     Training average loss at step 15400: 0.008216\n",
      "2023-12-01 20:29:26,661 INFO     Training average positive_sample_loss at step 15500: 0.009748\n",
      "2023-12-01 20:29:26,661 INFO     Training average negative_sample_loss at step 15500: 0.006717\n",
      "2023-12-01 20:29:26,661 INFO     Training average loss at step 15500: 0.008232\n",
      "2023-12-01 20:29:42,953 INFO     Training average positive_sample_loss at step 15600: 0.008867\n",
      "2023-12-01 20:29:42,954 INFO     Training average negative_sample_loss at step 15600: 0.006709\n",
      "2023-12-01 20:29:42,954 INFO     Training average loss at step 15600: 0.007788\n",
      "2023-12-01 20:29:57,431 INFO     Training average positive_sample_loss at step 15700: 0.009282\n",
      "2023-12-01 20:29:57,431 INFO     Training average negative_sample_loss at step 15700: 0.006649\n",
      "2023-12-01 20:29:57,432 INFO     Training average loss at step 15700: 0.007965\n",
      "2023-12-01 20:30:11,692 INFO     Training average positive_sample_loss at step 15800: 0.009454\n",
      "2023-12-01 20:30:11,692 INFO     Training average negative_sample_loss at step 15800: 0.006255\n",
      "2023-12-01 20:30:11,692 INFO     Training average loss at step 15800: 0.007854\n",
      "2023-12-01 20:30:25,111 INFO     Training average positive_sample_loss at step 15900: 0.009552\n",
      "2023-12-01 20:30:25,111 INFO     Training average negative_sample_loss at step 15900: 0.006331\n",
      "2023-12-01 20:30:25,111 INFO     Training average loss at step 15900: 0.007941\n",
      "2023-12-01 20:30:38,444 INFO     Training average positive_sample_loss at step 16000: 0.009498\n",
      "2023-12-01 20:30:38,445 INFO     Training average negative_sample_loss at step 16000: 0.006580\n",
      "2023-12-01 20:30:38,445 INFO     Training average loss at step 16000: 0.008039\n",
      "2023-12-01 20:30:54,846 INFO     Training average positive_sample_loss at step 16100: 0.008996\n",
      "2023-12-01 20:30:54,846 INFO     Training average negative_sample_loss at step 16100: 0.006493\n",
      "2023-12-01 20:30:54,846 INFO     Training average loss at step 16100: 0.007744\n",
      "2023-12-01 20:31:08,367 INFO     Training average positive_sample_loss at step 16200: 0.008589\n",
      "2023-12-01 20:31:08,367 INFO     Training average negative_sample_loss at step 16200: 0.006121\n",
      "2023-12-01 20:31:08,368 INFO     Training average loss at step 16200: 0.007355\n",
      "2023-12-01 20:31:21,997 INFO     Training average positive_sample_loss at step 16300: 0.009063\n",
      "2023-12-01 20:31:21,997 INFO     Training average negative_sample_loss at step 16300: 0.006385\n",
      "2023-12-01 20:31:21,997 INFO     Training average loss at step 16300: 0.007724\n",
      "2023-12-01 20:31:35,884 INFO     Training average positive_sample_loss at step 16400: 0.009297\n",
      "2023-12-01 20:31:35,885 INFO     Training average negative_sample_loss at step 16400: 0.006534\n",
      "2023-12-01 20:31:35,885 INFO     Training average loss at step 16400: 0.007916\n",
      "2023-12-01 20:31:50,208 INFO     Training average positive_sample_loss at step 16500: 0.009336\n",
      "2023-12-01 20:31:50,209 INFO     Training average negative_sample_loss at step 16500: 0.006472\n",
      "2023-12-01 20:31:50,209 INFO     Training average loss at step 16500: 0.007904\n",
      "2023-12-01 20:32:05,004 INFO     Training average positive_sample_loss at step 16600: 0.009235\n",
      "2023-12-01 20:32:05,004 INFO     Training average negative_sample_loss at step 16600: 0.006600\n",
      "2023-12-01 20:32:05,004 INFO     Training average loss at step 16600: 0.007918\n",
      "2023-12-01 20:32:20,147 INFO     Training average positive_sample_loss at step 16700: 0.008431\n",
      "2023-12-01 20:32:20,147 INFO     Training average negative_sample_loss at step 16700: 0.006502\n",
      "2023-12-01 20:32:20,147 INFO     Training average loss at step 16700: 0.007467\n",
      "2023-12-01 20:32:34,104 INFO     Training average positive_sample_loss at step 16800: 0.008705\n",
      "2023-12-01 20:32:34,104 INFO     Training average negative_sample_loss at step 16800: 0.006339\n",
      "2023-12-01 20:32:34,104 INFO     Training average loss at step 16800: 0.007522\n",
      "2023-12-01 20:32:47,719 INFO     Training average positive_sample_loss at step 16900: 0.008938\n",
      "2023-12-01 20:32:47,719 INFO     Training average negative_sample_loss at step 16900: 0.006580\n",
      "2023-12-01 20:32:47,719 INFO     Training average loss at step 16900: 0.007759\n",
      "2023-12-01 20:33:02,091 INFO     Training average positive_sample_loss at step 17000: 0.009217\n",
      "2023-12-01 20:33:02,091 INFO     Training average negative_sample_loss at step 17000: 0.006459\n",
      "2023-12-01 20:33:02,091 INFO     Training average loss at step 17000: 0.007838\n",
      "2023-12-01 20:33:15,987 INFO     Training average positive_sample_loss at step 17100: 0.009067\n",
      "2023-12-01 20:33:15,987 INFO     Training average negative_sample_loss at step 17100: 0.006740\n",
      "2023-12-01 20:33:15,987 INFO     Training average loss at step 17100: 0.007904\n",
      "2023-12-01 20:33:33,810 INFO     Training average positive_sample_loss at step 17200: 0.008771\n",
      "2023-12-01 20:33:33,811 INFO     Training average negative_sample_loss at step 17200: 0.006312\n",
      "2023-12-01 20:33:33,811 INFO     Training average loss at step 17200: 0.007542\n",
      "2023-12-01 20:33:48,533 INFO     Training average positive_sample_loss at step 17300: 0.008338\n",
      "2023-12-01 20:33:48,533 INFO     Training average negative_sample_loss at step 17300: 0.006646\n",
      "2023-12-01 20:33:48,533 INFO     Training average loss at step 17300: 0.007492\n",
      "2023-12-01 20:34:02,430 INFO     Training average positive_sample_loss at step 17400: 0.008584\n",
      "2023-12-01 20:34:02,430 INFO     Training average negative_sample_loss at step 17400: 0.006329\n",
      "2023-12-01 20:34:02,430 INFO     Training average loss at step 17400: 0.007457\n",
      "2023-12-01 20:34:16,394 INFO     Training average positive_sample_loss at step 17500: 0.008957\n",
      "2023-12-01 20:34:16,394 INFO     Training average negative_sample_loss at step 17500: 0.006485\n",
      "2023-12-01 20:34:16,394 INFO     Training average loss at step 17500: 0.007721\n",
      "2023-12-01 20:34:30,543 INFO     Training average positive_sample_loss at step 17600: 0.008973\n",
      "2023-12-01 20:34:30,544 INFO     Training average negative_sample_loss at step 17600: 0.006978\n",
      "2023-12-01 20:34:30,544 INFO     Training average loss at step 17600: 0.007975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 20:34:44,073 INFO     Training average positive_sample_loss at step 17700: 0.008848\n",
      "2023-12-01 20:34:44,073 INFO     Training average negative_sample_loss at step 17700: 0.006545\n",
      "2023-12-01 20:34:44,073 INFO     Training average loss at step 17700: 0.007696\n",
      "2023-12-01 20:35:01,183 INFO     Training average positive_sample_loss at step 17800: 0.008166\n",
      "2023-12-01 20:35:01,184 INFO     Training average negative_sample_loss at step 17800: 0.006447\n",
      "2023-12-01 20:35:01,184 INFO     Training average loss at step 17800: 0.007307\n",
      "2023-12-01 20:35:15,102 INFO     Training average positive_sample_loss at step 17900: 0.008230\n",
      "2023-12-01 20:35:15,103 INFO     Training average negative_sample_loss at step 17900: 0.006264\n",
      "2023-12-01 20:35:15,103 INFO     Training average loss at step 17900: 0.007247\n",
      "2023-12-01 20:35:28,643 INFO     Training average positive_sample_loss at step 18000: 0.008641\n",
      "2023-12-01 20:35:28,643 INFO     Training average negative_sample_loss at step 18000: 0.006475\n",
      "2023-12-01 20:35:28,643 INFO     Training average loss at step 18000: 0.007558\n",
      "2023-12-01 20:35:41,973 INFO     Training average positive_sample_loss at step 18100: 0.008680\n",
      "2023-12-01 20:35:41,974 INFO     Training average negative_sample_loss at step 18100: 0.006422\n",
      "2023-12-01 20:35:41,974 INFO     Training average loss at step 18100: 0.007551\n",
      "2023-12-01 20:35:55,722 INFO     Training average positive_sample_loss at step 18200: 0.008714\n",
      "2023-12-01 20:35:55,723 INFO     Training average negative_sample_loss at step 18200: 0.005981\n",
      "2023-12-01 20:35:55,723 INFO     Training average loss at step 18200: 0.007347\n",
      "2023-12-01 20:36:12,656 INFO     Training average positive_sample_loss at step 18300: 0.008456\n",
      "2023-12-01 20:36:12,656 INFO     Training average negative_sample_loss at step 18300: 0.006316\n",
      "2023-12-01 20:36:12,656 INFO     Training average loss at step 18300: 0.007386\n",
      "2023-12-01 20:36:27,009 INFO     Training average positive_sample_loss at step 18400: 0.007780\n",
      "2023-12-01 20:36:27,009 INFO     Training average negative_sample_loss at step 18400: 0.006438\n",
      "2023-12-01 20:36:27,009 INFO     Training average loss at step 18400: 0.007109\n",
      "2023-12-01 20:36:40,643 INFO     Training average positive_sample_loss at step 18500: 0.008340\n",
      "2023-12-01 20:36:40,644 INFO     Training average negative_sample_loss at step 18500: 0.006111\n",
      "2023-12-01 20:36:40,644 INFO     Training average loss at step 18500: 0.007226\n",
      "2023-12-01 20:36:54,157 INFO     Training average positive_sample_loss at step 18600: 0.008481\n",
      "2023-12-01 20:36:54,158 INFO     Training average negative_sample_loss at step 18600: 0.006610\n",
      "2023-12-01 20:36:54,158 INFO     Training average loss at step 18600: 0.007546\n",
      "2023-12-01 20:37:07,654 INFO     Training average positive_sample_loss at step 18700: 0.008614\n",
      "2023-12-01 20:37:07,654 INFO     Training average negative_sample_loss at step 18700: 0.006371\n",
      "2023-12-01 20:37:07,654 INFO     Training average loss at step 18700: 0.007492\n",
      "2023-12-01 20:37:22,566 INFO     Training average positive_sample_loss at step 18800: 0.008589\n",
      "2023-12-01 20:37:22,567 INFO     Training average negative_sample_loss at step 18800: 0.006182\n",
      "2023-12-01 20:37:22,567 INFO     Training average loss at step 18800: 0.007385\n",
      "2023-12-01 20:37:38,994 INFO     Training average positive_sample_loss at step 18900: 0.007772\n",
      "2023-12-01 20:37:38,995 INFO     Training average negative_sample_loss at step 18900: 0.006641\n",
      "2023-12-01 20:37:38,995 INFO     Training average loss at step 18900: 0.007206\n",
      "2023-12-01 20:37:53,158 INFO     Training average positive_sample_loss at step 19000: 0.007991\n",
      "2023-12-01 20:37:53,158 INFO     Training average negative_sample_loss at step 19000: 0.006523\n",
      "2023-12-01 20:37:53,158 INFO     Training average loss at step 19000: 0.007257\n",
      "2023-12-01 20:38:07,445 INFO     Training average positive_sample_loss at step 19100: 0.008453\n",
      "2023-12-01 20:38:07,446 INFO     Training average negative_sample_loss at step 19100: 0.006259\n",
      "2023-12-01 20:38:07,446 INFO     Training average loss at step 19100: 0.007356\n",
      "2023-12-01 20:38:21,518 INFO     Training average positive_sample_loss at step 19200: 0.008381\n",
      "2023-12-01 20:38:21,518 INFO     Training average negative_sample_loss at step 19200: 0.006168\n",
      "2023-12-01 20:38:21,518 INFO     Training average loss at step 19200: 0.007274\n",
      "2023-12-01 20:38:35,590 INFO     Training average positive_sample_loss at step 19300: 0.008388\n",
      "2023-12-01 20:38:35,590 INFO     Training average negative_sample_loss at step 19300: 0.006237\n",
      "2023-12-01 20:38:35,590 INFO     Training average loss at step 19300: 0.007312\n",
      "2023-12-01 20:38:51,081 INFO     Training average positive_sample_loss at step 19400: 0.008214\n",
      "2023-12-01 20:38:51,082 INFO     Training average negative_sample_loss at step 19400: 0.005952\n",
      "2023-12-01 20:38:51,082 INFO     Training average loss at step 19400: 0.007083\n",
      "2023-12-01 20:39:05,464 INFO     Training average positive_sample_loss at step 19500: 0.007519\n",
      "2023-12-01 20:39:05,465 INFO     Training average negative_sample_loss at step 19500: 0.006363\n",
      "2023-12-01 20:39:05,465 INFO     Training average loss at step 19500: 0.006941\n",
      "2023-12-01 20:39:19,578 INFO     Training average positive_sample_loss at step 19600: 0.007893\n",
      "2023-12-01 20:39:19,578 INFO     Training average negative_sample_loss at step 19600: 0.006470\n",
      "2023-12-01 20:39:19,578 INFO     Training average loss at step 19600: 0.007182\n",
      "2023-12-01 20:39:33,992 INFO     Training average positive_sample_loss at step 19700: 0.008347\n",
      "2023-12-01 20:39:33,992 INFO     Training average negative_sample_loss at step 19700: 0.006018\n",
      "2023-12-01 20:39:33,992 INFO     Training average loss at step 19700: 0.007183\n",
      "2023-12-01 20:39:48,199 INFO     Training average positive_sample_loss at step 19800: 0.008376\n",
      "2023-12-01 20:39:48,199 INFO     Training average negative_sample_loss at step 19800: 0.006411\n",
      "2023-12-01 20:39:48,199 INFO     Training average loss at step 19800: 0.007393\n",
      "2023-12-01 20:40:02,458 INFO     Training average positive_sample_loss at step 19900: 0.008373\n",
      "2023-12-01 20:40:02,458 INFO     Training average negative_sample_loss at step 19900: 0.006434\n",
      "2023-12-01 20:40:02,458 INFO     Training average loss at step 19900: 0.007404\n",
      "2023-12-01 20:40:34,156 INFO     Training average positive_sample_loss at step 20000: 0.007714\n",
      "2023-12-01 20:40:34,157 INFO     Training average negative_sample_loss at step 20000: 0.006551\n",
      "2023-12-01 20:40:34,157 INFO     Training average loss at step 20000: 0.007132\n",
      "2023-12-01 20:40:34,157 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 20:40:34,689 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 20:41:08,367 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 20:41:17,486 INFO     Valid MRR at step 20000: 0.948635\n",
      "2023-12-01 20:41:17,487 INFO     Valid MR at step 20000: 381.548800\n",
      "2023-12-01 20:41:17,487 INFO     Valid HITS@1 at step 20000: 0.944000\n",
      "2023-12-01 20:41:17,487 INFO     Valid HITS@3 at step 20000: 0.950800\n",
      "2023-12-01 20:41:17,487 INFO     Valid HITS@10 at step 20000: 0.957200\n",
      "2023-12-01 20:41:29,692 INFO     Training average positive_sample_loss at step 20100: 0.007789\n",
      "2023-12-01 20:41:29,693 INFO     Training average negative_sample_loss at step 20100: 0.006354\n",
      "2023-12-01 20:41:29,693 INFO     Training average loss at step 20100: 0.007071\n",
      "2023-12-01 20:41:43,587 INFO     Training average positive_sample_loss at step 20200: 0.008001\n",
      "2023-12-01 20:41:43,587 INFO     Training average negative_sample_loss at step 20200: 0.006338\n",
      "2023-12-01 20:41:43,587 INFO     Training average loss at step 20200: 0.007170\n",
      "2023-12-01 20:41:58,086 INFO     Training average positive_sample_loss at step 20300: 0.008369\n",
      "2023-12-01 20:41:58,086 INFO     Training average negative_sample_loss at step 20300: 0.006710\n",
      "2023-12-01 20:41:58,086 INFO     Training average loss at step 20300: 0.007539\n",
      "2023-12-01 20:42:11,993 INFO     Training average positive_sample_loss at step 20400: 0.008196\n",
      "2023-12-01 20:42:11,993 INFO     Training average negative_sample_loss at step 20400: 0.006701\n",
      "2023-12-01 20:42:11,993 INFO     Training average loss at step 20400: 0.007448\n",
      "2023-12-01 20:42:29,079 INFO     Training average positive_sample_loss at step 20500: 0.008259\n",
      "2023-12-01 20:42:29,080 INFO     Training average negative_sample_loss at step 20500: 0.006502\n",
      "2023-12-01 20:42:29,080 INFO     Training average loss at step 20500: 0.007380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 20:42:43,793 INFO     Training average positive_sample_loss at step 20600: 0.007285\n",
      "2023-12-01 20:42:43,793 INFO     Training average negative_sample_loss at step 20600: 0.006074\n",
      "2023-12-01 20:42:43,793 INFO     Training average loss at step 20600: 0.006680\n",
      "2023-12-01 20:42:58,404 INFO     Training average positive_sample_loss at step 20700: 0.007818\n",
      "2023-12-01 20:42:58,404 INFO     Training average negative_sample_loss at step 20700: 0.006318\n",
      "2023-12-01 20:42:58,404 INFO     Training average loss at step 20700: 0.007068\n",
      "2023-12-01 20:43:12,302 INFO     Training average positive_sample_loss at step 20800: 0.008107\n",
      "2023-12-01 20:43:12,302 INFO     Training average negative_sample_loss at step 20800: 0.006542\n",
      "2023-12-01 20:43:12,302 INFO     Training average loss at step 20800: 0.007324\n",
      "2023-12-01 20:43:26,469 INFO     Training average positive_sample_loss at step 20900: 0.008057\n",
      "2023-12-01 20:43:26,469 INFO     Training average negative_sample_loss at step 20900: 0.006060\n",
      "2023-12-01 20:43:26,469 INFO     Training average loss at step 20900: 0.007058\n",
      "2023-12-01 20:43:41,237 INFO     Training average positive_sample_loss at step 21000: 0.008265\n",
      "2023-12-01 20:43:41,238 INFO     Training average negative_sample_loss at step 21000: 0.006712\n",
      "2023-12-01 20:43:41,238 INFO     Training average loss at step 21000: 0.007489\n",
      "2023-12-01 20:43:57,722 INFO     Training average positive_sample_loss at step 21100: 0.007539\n",
      "2023-12-01 20:43:57,722 INFO     Training average negative_sample_loss at step 21100: 0.006451\n",
      "2023-12-01 20:43:57,722 INFO     Training average loss at step 21100: 0.006995\n",
      "2023-12-01 20:44:11,519 INFO     Training average positive_sample_loss at step 21200: 0.007448\n",
      "2023-12-01 20:44:11,519 INFO     Training average negative_sample_loss at step 21200: 0.006265\n",
      "2023-12-01 20:44:11,519 INFO     Training average loss at step 21200: 0.006856\n",
      "2023-12-01 20:44:26,021 INFO     Training average positive_sample_loss at step 21300: 0.007862\n",
      "2023-12-01 20:44:26,022 INFO     Training average negative_sample_loss at step 21300: 0.006667\n",
      "2023-12-01 20:44:26,022 INFO     Training average loss at step 21300: 0.007265\n",
      "2023-12-01 20:44:39,945 INFO     Training average positive_sample_loss at step 21400: 0.008115\n",
      "2023-12-01 20:44:39,946 INFO     Training average negative_sample_loss at step 21400: 0.006534\n",
      "2023-12-01 20:44:39,946 INFO     Training average loss at step 21400: 0.007325\n",
      "2023-12-01 20:44:54,815 INFO     Training average positive_sample_loss at step 21500: 0.008126\n",
      "2023-12-01 20:44:54,815 INFO     Training average negative_sample_loss at step 21500: 0.006317\n",
      "2023-12-01 20:44:54,815 INFO     Training average loss at step 21500: 0.007222\n",
      "2023-12-01 20:45:08,428 INFO     Training average positive_sample_loss at step 21600: 0.008032\n",
      "2023-12-01 20:45:08,428 INFO     Training average negative_sample_loss at step 21600: 0.006282\n",
      "2023-12-01 20:45:08,428 INFO     Training average loss at step 21600: 0.007157\n",
      "2023-12-01 20:45:24,898 INFO     Training average positive_sample_loss at step 21700: 0.007167\n",
      "2023-12-01 20:45:24,898 INFO     Training average negative_sample_loss at step 21700: 0.006131\n",
      "2023-12-01 20:45:24,899 INFO     Training average loss at step 21700: 0.006649\n",
      "2023-12-01 20:45:39,440 INFO     Training average positive_sample_loss at step 21800: 0.007585\n",
      "2023-12-01 20:45:39,441 INFO     Training average negative_sample_loss at step 21800: 0.006352\n",
      "2023-12-01 20:45:39,441 INFO     Training average loss at step 21800: 0.006968\n",
      "2023-12-01 20:45:53,931 INFO     Training average positive_sample_loss at step 21900: 0.007821\n",
      "2023-12-01 20:45:53,931 INFO     Training average negative_sample_loss at step 21900: 0.006219\n",
      "2023-12-01 20:45:53,932 INFO     Training average loss at step 21900: 0.007020\n",
      "2023-12-01 20:46:08,617 INFO     Training average positive_sample_loss at step 22000: 0.007897\n",
      "2023-12-01 20:46:08,618 INFO     Training average negative_sample_loss at step 22000: 0.005761\n",
      "2023-12-01 20:46:08,618 INFO     Training average loss at step 22000: 0.006829\n",
      "2023-12-01 20:46:23,480 INFO     Training average positive_sample_loss at step 22100: 0.007846\n",
      "2023-12-01 20:46:23,480 INFO     Training average negative_sample_loss at step 22100: 0.005992\n",
      "2023-12-01 20:46:23,481 INFO     Training average loss at step 22100: 0.006919\n",
      "2023-12-01 20:46:39,230 INFO     Training average positive_sample_loss at step 22200: 0.007476\n",
      "2023-12-01 20:46:39,231 INFO     Training average negative_sample_loss at step 22200: 0.006436\n",
      "2023-12-01 20:46:39,231 INFO     Training average loss at step 22200: 0.006956\n",
      "2023-12-01 20:46:53,542 INFO     Training average positive_sample_loss at step 22300: 0.007217\n",
      "2023-12-01 20:46:53,542 INFO     Training average negative_sample_loss at step 22300: 0.006490\n",
      "2023-12-01 20:46:53,542 INFO     Training average loss at step 22300: 0.006853\n",
      "2023-12-01 20:47:07,828 INFO     Training average positive_sample_loss at step 22400: 0.007654\n",
      "2023-12-01 20:47:07,828 INFO     Training average negative_sample_loss at step 22400: 0.006296\n",
      "2023-12-01 20:47:07,828 INFO     Training average loss at step 22400: 0.006975\n",
      "2023-12-01 20:47:21,690 INFO     Training average positive_sample_loss at step 22500: 0.007803\n",
      "2023-12-01 20:47:21,691 INFO     Training average negative_sample_loss at step 22500: 0.006090\n",
      "2023-12-01 20:47:21,691 INFO     Training average loss at step 22500: 0.006946\n",
      "2023-12-01 20:47:35,264 INFO     Training average positive_sample_loss at step 22600: 0.007935\n",
      "2023-12-01 20:47:35,265 INFO     Training average negative_sample_loss at step 22600: 0.006202\n",
      "2023-12-01 20:47:35,265 INFO     Training average loss at step 22600: 0.007068\n",
      "2023-12-01 20:47:49,167 INFO     Training average positive_sample_loss at step 22700: 0.007844\n",
      "2023-12-01 20:47:49,168 INFO     Training average negative_sample_loss at step 22700: 0.006899\n",
      "2023-12-01 20:47:49,168 INFO     Training average loss at step 22700: 0.007372\n",
      "2023-12-01 20:48:05,544 INFO     Training average positive_sample_loss at step 22800: 0.007116\n",
      "2023-12-01 20:48:05,545 INFO     Training average negative_sample_loss at step 22800: 0.006544\n",
      "2023-12-01 20:48:05,545 INFO     Training average loss at step 22800: 0.006830\n",
      "2023-12-01 20:48:19,782 INFO     Training average positive_sample_loss at step 22900: 0.007348\n",
      "2023-12-01 20:48:19,782 INFO     Training average negative_sample_loss at step 22900: 0.005781\n",
      "2023-12-01 20:48:19,782 INFO     Training average loss at step 22900: 0.006565\n",
      "2023-12-01 20:48:34,166 INFO     Training average positive_sample_loss at step 23000: 0.007723\n",
      "2023-12-01 20:48:34,166 INFO     Training average negative_sample_loss at step 23000: 0.006800\n",
      "2023-12-01 20:48:34,166 INFO     Training average loss at step 23000: 0.007261\n",
      "2023-12-01 20:48:48,610 INFO     Training average positive_sample_loss at step 23100: 0.007842\n",
      "2023-12-01 20:48:48,611 INFO     Training average negative_sample_loss at step 23100: 0.006656\n",
      "2023-12-01 20:48:48,611 INFO     Training average loss at step 23100: 0.007249\n",
      "2023-12-01 20:49:03,094 INFO     Training average positive_sample_loss at step 23200: 0.007778\n",
      "2023-12-01 20:49:03,094 INFO     Training average negative_sample_loss at step 23200: 0.006422\n",
      "2023-12-01 20:49:03,094 INFO     Training average loss at step 23200: 0.007100\n",
      "2023-12-01 20:49:19,682 INFO     Training average positive_sample_loss at step 23300: 0.007516\n",
      "2023-12-01 20:49:19,683 INFO     Training average negative_sample_loss at step 23300: 0.005988\n",
      "2023-12-01 20:49:19,683 INFO     Training average loss at step 23300: 0.006752\n",
      "2023-12-01 20:49:33,708 INFO     Training average positive_sample_loss at step 23400: 0.007204\n",
      "2023-12-01 20:49:33,708 INFO     Training average negative_sample_loss at step 23400: 0.006567\n",
      "2023-12-01 20:49:33,708 INFO     Training average loss at step 23400: 0.006886\n",
      "2023-12-01 20:49:48,234 INFO     Training average positive_sample_loss at step 23500: 0.007440\n",
      "2023-12-01 20:49:48,234 INFO     Training average negative_sample_loss at step 23500: 0.006296\n",
      "2023-12-01 20:49:48,235 INFO     Training average loss at step 23500: 0.006868\n",
      "2023-12-01 20:50:02,049 INFO     Training average positive_sample_loss at step 23600: 0.007652\n",
      "2023-12-01 20:50:02,049 INFO     Training average negative_sample_loss at step 23600: 0.006559\n",
      "2023-12-01 20:50:02,049 INFO     Training average loss at step 23600: 0.007106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 20:50:16,391 INFO     Training average positive_sample_loss at step 23700: 0.007838\n",
      "2023-12-01 20:50:16,391 INFO     Training average negative_sample_loss at step 23700: 0.006440\n",
      "2023-12-01 20:50:16,391 INFO     Training average loss at step 23700: 0.007139\n",
      "2023-12-01 20:50:30,825 INFO     Training average positive_sample_loss at step 23800: 0.007810\n",
      "2023-12-01 20:50:30,825 INFO     Training average negative_sample_loss at step 23800: 0.005981\n",
      "2023-12-01 20:50:30,825 INFO     Training average loss at step 23800: 0.006895\n",
      "2023-12-01 20:50:47,388 INFO     Training average positive_sample_loss at step 23900: 0.006995\n",
      "2023-12-01 20:50:47,388 INFO     Training average negative_sample_loss at step 23900: 0.006576\n",
      "2023-12-01 20:50:47,388 INFO     Training average loss at step 23900: 0.006786\n",
      "2023-12-01 20:51:02,363 INFO     Training average positive_sample_loss at step 24000: 0.007315\n",
      "2023-12-01 20:51:02,363 INFO     Training average negative_sample_loss at step 24000: 0.006190\n",
      "2023-12-01 20:51:02,363 INFO     Training average loss at step 24000: 0.006753\n",
      "2023-12-01 20:51:17,685 INFO     Training average positive_sample_loss at step 24100: 0.007602\n",
      "2023-12-01 20:51:17,685 INFO     Training average negative_sample_loss at step 24100: 0.006147\n",
      "2023-12-01 20:51:17,685 INFO     Training average loss at step 24100: 0.006875\n",
      "2023-12-01 20:51:32,408 INFO     Training average positive_sample_loss at step 24200: 0.007599\n",
      "2023-12-01 20:51:32,408 INFO     Training average negative_sample_loss at step 24200: 0.006119\n",
      "2023-12-01 20:51:32,408 INFO     Training average loss at step 24200: 0.006859\n",
      "2023-12-01 20:51:46,726 INFO     Training average positive_sample_loss at step 24300: 0.007593\n",
      "2023-12-01 20:51:46,726 INFO     Training average negative_sample_loss at step 24300: 0.006574\n",
      "2023-12-01 20:51:46,726 INFO     Training average loss at step 24300: 0.007084\n",
      "2023-12-01 20:52:03,533 INFO     Training average positive_sample_loss at step 24400: 0.007441\n",
      "2023-12-01 20:52:03,533 INFO     Training average negative_sample_loss at step 24400: 0.006458\n",
      "2023-12-01 20:52:03,533 INFO     Training average loss at step 24400: 0.006950\n",
      "2023-12-01 20:52:17,526 INFO     Training average positive_sample_loss at step 24500: 0.006947\n",
      "2023-12-01 20:52:17,526 INFO     Training average negative_sample_loss at step 24500: 0.005849\n",
      "2023-12-01 20:52:17,526 INFO     Training average loss at step 24500: 0.006398\n",
      "2023-12-01 20:52:31,753 INFO     Training average positive_sample_loss at step 24600: 0.007370\n",
      "2023-12-01 20:52:31,754 INFO     Training average negative_sample_loss at step 24600: 0.006390\n",
      "2023-12-01 20:52:31,754 INFO     Training average loss at step 24600: 0.006880\n",
      "2023-12-01 20:52:46,192 INFO     Training average positive_sample_loss at step 24700: 0.007624\n",
      "2023-12-01 20:52:46,192 INFO     Training average negative_sample_loss at step 24700: 0.006458\n",
      "2023-12-01 20:52:46,192 INFO     Training average loss at step 24700: 0.007041\n",
      "2023-12-01 20:53:00,074 INFO     Training average positive_sample_loss at step 24800: 0.007674\n",
      "2023-12-01 20:53:00,074 INFO     Training average negative_sample_loss at step 24800: 0.006206\n",
      "2023-12-01 20:53:00,074 INFO     Training average loss at step 24800: 0.006940\n",
      "2023-12-01 20:53:13,567 INFO     Training average positive_sample_loss at step 24900: 0.007575\n",
      "2023-12-01 20:53:13,567 INFO     Training average negative_sample_loss at step 24900: 0.006769\n",
      "2023-12-01 20:53:13,567 INFO     Training average loss at step 24900: 0.007172\n",
      "2023-12-01 20:53:29,654 INFO     Training average positive_sample_loss at step 25000: 0.006935\n",
      "2023-12-01 20:53:29,654 INFO     Training average negative_sample_loss at step 25000: 0.006196\n",
      "2023-12-01 20:53:29,654 INFO     Training average loss at step 25000: 0.006565\n",
      "2023-12-01 20:53:43,580 INFO     Training average positive_sample_loss at step 25100: 0.007270\n",
      "2023-12-01 20:53:43,580 INFO     Training average negative_sample_loss at step 25100: 0.006276\n",
      "2023-12-01 20:53:43,580 INFO     Training average loss at step 25100: 0.006773\n",
      "2023-12-01 20:53:57,594 INFO     Training average positive_sample_loss at step 25200: 0.007505\n",
      "2023-12-01 20:53:57,595 INFO     Training average negative_sample_loss at step 25200: 0.006173\n",
      "2023-12-01 20:53:57,595 INFO     Training average loss at step 25200: 0.006839\n",
      "2023-12-01 20:54:11,494 INFO     Training average positive_sample_loss at step 25300: 0.007507\n",
      "2023-12-01 20:54:11,494 INFO     Training average negative_sample_loss at step 25300: 0.006603\n",
      "2023-12-01 20:54:11,494 INFO     Training average loss at step 25300: 0.007055\n",
      "2023-12-01 20:54:24,926 INFO     Training average positive_sample_loss at step 25400: 0.007602\n",
      "2023-12-01 20:54:24,927 INFO     Training average negative_sample_loss at step 25400: 0.006557\n",
      "2023-12-01 20:54:24,927 INFO     Training average loss at step 25400: 0.007080\n",
      "2023-12-01 20:54:42,283 INFO     Training average positive_sample_loss at step 25500: 0.007549\n",
      "2023-12-01 20:54:42,284 INFO     Training average negative_sample_loss at step 25500: 0.006609\n",
      "2023-12-01 20:54:42,284 INFO     Training average loss at step 25500: 0.007079\n",
      "2023-12-01 20:54:56,120 INFO     Training average positive_sample_loss at step 25600: 0.006792\n",
      "2023-12-01 20:54:56,120 INFO     Training average negative_sample_loss at step 25600: 0.005978\n",
      "2023-12-01 20:54:56,121 INFO     Training average loss at step 25600: 0.006385\n",
      "2023-12-01 20:55:09,581 INFO     Training average positive_sample_loss at step 25700: 0.007176\n",
      "2023-12-01 20:55:09,582 INFO     Training average negative_sample_loss at step 25700: 0.005860\n",
      "2023-12-01 20:55:09,582 INFO     Training average loss at step 25700: 0.006518\n",
      "2023-12-01 20:55:23,506 INFO     Training average positive_sample_loss at step 25800: 0.007413\n",
      "2023-12-01 20:55:23,506 INFO     Training average negative_sample_loss at step 25800: 0.006078\n",
      "2023-12-01 20:55:23,506 INFO     Training average loss at step 25800: 0.006746\n",
      "2023-12-01 20:55:37,793 INFO     Training average positive_sample_loss at step 25900: 0.007531\n",
      "2023-12-01 20:55:37,793 INFO     Training average negative_sample_loss at step 25900: 0.006214\n",
      "2023-12-01 20:55:37,793 INFO     Training average loss at step 25900: 0.006873\n",
      "2023-12-01 20:55:51,969 INFO     Training average positive_sample_loss at step 26000: 0.007615\n",
      "2023-12-01 20:55:51,969 INFO     Training average negative_sample_loss at step 26000: 0.006632\n",
      "2023-12-01 20:55:51,969 INFO     Training average loss at step 26000: 0.007124\n",
      "2023-12-01 20:56:09,312 INFO     Training average positive_sample_loss at step 26100: 0.006873\n",
      "2023-12-01 20:56:09,313 INFO     Training average negative_sample_loss at step 26100: 0.006514\n",
      "2023-12-01 20:56:09,313 INFO     Training average loss at step 26100: 0.006694\n",
      "2023-12-01 20:56:22,791 INFO     Training average positive_sample_loss at step 26200: 0.007029\n",
      "2023-12-01 20:56:22,791 INFO     Training average negative_sample_loss at step 26200: 0.006049\n",
      "2023-12-01 20:56:22,791 INFO     Training average loss at step 26200: 0.006539\n",
      "2023-12-01 20:56:36,049 INFO     Training average positive_sample_loss at step 26300: 0.007265\n",
      "2023-12-01 20:56:36,050 INFO     Training average negative_sample_loss at step 26300: 0.006631\n",
      "2023-12-01 20:56:36,050 INFO     Training average loss at step 26300: 0.006948\n",
      "2023-12-01 20:56:49,353 INFO     Training average positive_sample_loss at step 26400: 0.007477\n",
      "2023-12-01 20:56:49,354 INFO     Training average negative_sample_loss at step 26400: 0.006547\n",
      "2023-12-01 20:56:49,354 INFO     Training average loss at step 26400: 0.007012\n",
      "2023-12-01 20:57:03,708 INFO     Training average positive_sample_loss at step 26500: 0.007517\n",
      "2023-12-01 20:57:03,708 INFO     Training average negative_sample_loss at step 26500: 0.006775\n",
      "2023-12-01 20:57:03,709 INFO     Training average loss at step 26500: 0.007146\n",
      "2023-12-01 20:57:19,499 INFO     Training average positive_sample_loss at step 26600: 0.007405\n",
      "2023-12-01 20:57:19,499 INFO     Training average negative_sample_loss at step 26600: 0.006804\n",
      "2023-12-01 20:57:19,499 INFO     Training average loss at step 26600: 0.007105\n",
      "2023-12-01 20:57:33,457 INFO     Training average positive_sample_loss at step 26700: 0.006832\n",
      "2023-12-01 20:57:33,457 INFO     Training average negative_sample_loss at step 26700: 0.006389\n",
      "2023-12-01 20:57:33,457 INFO     Training average loss at step 26700: 0.006610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 20:57:47,560 INFO     Training average positive_sample_loss at step 26800: 0.007123\n",
      "2023-12-01 20:57:47,561 INFO     Training average negative_sample_loss at step 26800: 0.006339\n",
      "2023-12-01 20:57:47,561 INFO     Training average loss at step 26800: 0.006731\n",
      "2023-12-01 20:58:01,375 INFO     Training average positive_sample_loss at step 26900: 0.007374\n",
      "2023-12-01 20:58:01,375 INFO     Training average negative_sample_loss at step 26900: 0.006533\n",
      "2023-12-01 20:58:01,375 INFO     Training average loss at step 26900: 0.006953\n",
      "2023-12-01 20:58:15,672 INFO     Training average positive_sample_loss at step 27000: 0.007437\n",
      "2023-12-01 20:58:15,673 INFO     Training average negative_sample_loss at step 27000: 0.006619\n",
      "2023-12-01 20:58:15,673 INFO     Training average loss at step 27000: 0.007028\n",
      "2023-12-01 20:58:29,779 INFO     Training average positive_sample_loss at step 27100: 0.007485\n",
      "2023-12-01 20:58:29,779 INFO     Training average negative_sample_loss at step 27100: 0.006405\n",
      "2023-12-01 20:58:29,779 INFO     Training average loss at step 27100: 0.006945\n",
      "2023-12-01 20:58:45,653 INFO     Training average positive_sample_loss at step 27200: 0.006946\n",
      "2023-12-01 20:58:45,653 INFO     Training average negative_sample_loss at step 27200: 0.006707\n",
      "2023-12-01 20:58:45,653 INFO     Training average loss at step 27200: 0.006826\n",
      "2023-12-01 20:58:59,098 INFO     Training average positive_sample_loss at step 27300: 0.006925\n",
      "2023-12-01 20:58:59,099 INFO     Training average negative_sample_loss at step 27300: 0.006229\n",
      "2023-12-01 20:58:59,099 INFO     Training average loss at step 27300: 0.006577\n",
      "2023-12-01 20:59:12,644 INFO     Training average positive_sample_loss at step 27400: 0.007236\n",
      "2023-12-01 20:59:12,645 INFO     Training average negative_sample_loss at step 27400: 0.006415\n",
      "2023-12-01 20:59:12,645 INFO     Training average loss at step 27400: 0.006825\n",
      "2023-12-01 20:59:27,069 INFO     Training average positive_sample_loss at step 27500: 0.007306\n",
      "2023-12-01 20:59:27,070 INFO     Training average negative_sample_loss at step 27500: 0.006300\n",
      "2023-12-01 20:59:27,070 INFO     Training average loss at step 27500: 0.006803\n",
      "2023-12-01 20:59:41,933 INFO     Training average positive_sample_loss at step 27600: 0.007369\n",
      "2023-12-01 20:59:41,933 INFO     Training average negative_sample_loss at step 27600: 0.006313\n",
      "2023-12-01 20:59:41,933 INFO     Training average loss at step 27600: 0.006841\n",
      "2023-12-01 20:59:57,542 INFO     Training average positive_sample_loss at step 27700: 0.007396\n",
      "2023-12-01 20:59:57,542 INFO     Training average negative_sample_loss at step 27700: 0.006244\n",
      "2023-12-01 20:59:57,542 INFO     Training average loss at step 27700: 0.006820\n",
      "2023-12-01 21:00:12,593 INFO     Training average positive_sample_loss at step 27800: 0.006574\n",
      "2023-12-01 21:00:12,593 INFO     Training average negative_sample_loss at step 27800: 0.006579\n",
      "2023-12-01 21:00:12,593 INFO     Training average loss at step 27800: 0.006577\n",
      "2023-12-01 21:00:26,771 INFO     Training average positive_sample_loss at step 27900: 0.007131\n",
      "2023-12-01 21:00:26,772 INFO     Training average negative_sample_loss at step 27900: 0.006396\n",
      "2023-12-01 21:00:26,772 INFO     Training average loss at step 27900: 0.006763\n",
      "2023-12-01 21:00:41,196 INFO     Training average positive_sample_loss at step 28000: 0.007222\n",
      "2023-12-01 21:00:41,196 INFO     Training average negative_sample_loss at step 28000: 0.006178\n",
      "2023-12-01 21:00:41,196 INFO     Training average loss at step 28000: 0.006700\n",
      "2023-12-01 21:00:55,780 INFO     Training average positive_sample_loss at step 28100: 0.007367\n",
      "2023-12-01 21:00:55,780 INFO     Training average negative_sample_loss at step 28100: 0.006381\n",
      "2023-12-01 21:00:55,780 INFO     Training average loss at step 28100: 0.006874\n",
      "2023-12-01 21:01:09,176 INFO     Training average positive_sample_loss at step 28200: 0.007361\n",
      "2023-12-01 21:01:09,177 INFO     Training average negative_sample_loss at step 28200: 0.006516\n",
      "2023-12-01 21:01:09,177 INFO     Training average loss at step 28200: 0.006938\n",
      "2023-12-01 21:01:26,173 INFO     Training average positive_sample_loss at step 28300: 0.006935\n",
      "2023-12-01 21:01:26,173 INFO     Training average negative_sample_loss at step 28300: 0.006772\n",
      "2023-12-01 21:01:26,173 INFO     Training average loss at step 28300: 0.006853\n",
      "2023-12-01 21:01:40,385 INFO     Training average positive_sample_loss at step 28400: 0.006794\n",
      "2023-12-01 21:01:40,385 INFO     Training average negative_sample_loss at step 28400: 0.006383\n",
      "2023-12-01 21:01:40,385 INFO     Training average loss at step 28400: 0.006589\n",
      "2023-12-01 21:01:54,422 INFO     Training average positive_sample_loss at step 28500: 0.007218\n",
      "2023-12-01 21:01:54,423 INFO     Training average negative_sample_loss at step 28500: 0.006177\n",
      "2023-12-01 21:01:54,423 INFO     Training average loss at step 28500: 0.006698\n",
      "2023-12-01 21:02:09,275 INFO     Training average positive_sample_loss at step 28600: 0.007212\n",
      "2023-12-01 21:02:09,275 INFO     Training average negative_sample_loss at step 28600: 0.006523\n",
      "2023-12-01 21:02:09,275 INFO     Training average loss at step 28600: 0.006867\n",
      "2023-12-01 21:02:24,252 INFO     Training average positive_sample_loss at step 28700: 0.007357\n",
      "2023-12-01 21:02:24,252 INFO     Training average negative_sample_loss at step 28700: 0.006133\n",
      "2023-12-01 21:02:24,252 INFO     Training average loss at step 28700: 0.006745\n",
      "2023-12-01 21:02:38,231 INFO     Training average positive_sample_loss at step 28800: 0.007335\n",
      "2023-12-01 21:02:38,231 INFO     Training average negative_sample_loss at step 28800: 0.006490\n",
      "2023-12-01 21:02:38,231 INFO     Training average loss at step 28800: 0.006912\n",
      "2023-12-01 21:02:54,285 INFO     Training average positive_sample_loss at step 28900: 0.006679\n",
      "2023-12-01 21:02:54,285 INFO     Training average negative_sample_loss at step 28900: 0.006326\n",
      "2023-12-01 21:02:54,285 INFO     Training average loss at step 28900: 0.006502\n",
      "2023-12-01 21:03:08,187 INFO     Training average positive_sample_loss at step 29000: 0.007004\n",
      "2023-12-01 21:03:08,187 INFO     Training average negative_sample_loss at step 29000: 0.006629\n",
      "2023-12-01 21:03:08,187 INFO     Training average loss at step 29000: 0.006817\n",
      "2023-12-01 21:03:21,890 INFO     Training average positive_sample_loss at step 29100: 0.007203\n",
      "2023-12-01 21:03:21,890 INFO     Training average negative_sample_loss at step 29100: 0.006593\n",
      "2023-12-01 21:03:21,890 INFO     Training average loss at step 29100: 0.006898\n",
      "2023-12-01 21:03:35,758 INFO     Training average positive_sample_loss at step 29200: 0.007358\n",
      "2023-12-01 21:03:35,759 INFO     Training average negative_sample_loss at step 29200: 0.006645\n",
      "2023-12-01 21:03:35,759 INFO     Training average loss at step 29200: 0.007001\n",
      "2023-12-01 21:03:49,851 INFO     Training average positive_sample_loss at step 29300: 0.007394\n",
      "2023-12-01 21:03:49,851 INFO     Training average negative_sample_loss at step 29300: 0.006840\n",
      "2023-12-01 21:03:49,851 INFO     Training average loss at step 29300: 0.007117\n",
      "2023-12-01 21:04:06,318 INFO     Training average positive_sample_loss at step 29400: 0.006921\n",
      "2023-12-01 21:04:06,318 INFO     Training average negative_sample_loss at step 29400: 0.006392\n",
      "2023-12-01 21:04:06,318 INFO     Training average loss at step 29400: 0.006656\n",
      "2023-12-01 21:04:21,240 INFO     Training average positive_sample_loss at step 29500: 0.006771\n",
      "2023-12-01 21:04:21,240 INFO     Training average negative_sample_loss at step 29500: 0.006528\n",
      "2023-12-01 21:04:21,240 INFO     Training average loss at step 29500: 0.006650\n",
      "2023-12-01 21:04:35,378 INFO     Training average positive_sample_loss at step 29600: 0.007178\n",
      "2023-12-01 21:04:35,378 INFO     Training average negative_sample_loss at step 29600: 0.006263\n",
      "2023-12-01 21:04:35,378 INFO     Training average loss at step 29600: 0.006721\n",
      "2023-12-01 21:04:49,287 INFO     Training average positive_sample_loss at step 29700: 0.007145\n",
      "2023-12-01 21:04:49,288 INFO     Training average negative_sample_loss at step 29700: 0.006459\n",
      "2023-12-01 21:04:49,288 INFO     Training average loss at step 29700: 0.006802\n",
      "2023-12-01 21:05:03,080 INFO     Training average positive_sample_loss at step 29800: 0.007341\n",
      "2023-12-01 21:05:03,080 INFO     Training average negative_sample_loss at step 29800: 0.006941\n",
      "2023-12-01 21:05:03,080 INFO     Training average loss at step 29800: 0.007141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:05:16,557 INFO     Training average positive_sample_loss at step 29900: 0.007290\n",
      "2023-12-01 21:05:16,557 INFO     Training average negative_sample_loss at step 29900: 0.006673\n",
      "2023-12-01 21:05:16,557 INFO     Training average loss at step 29900: 0.006982\n",
      "2023-12-01 21:05:46,918 INFO     Training average positive_sample_loss at step 30000: 0.006644\n",
      "2023-12-01 21:05:46,918 INFO     Training average negative_sample_loss at step 30000: 0.006766\n",
      "2023-12-01 21:05:46,918 INFO     Training average loss at step 30000: 0.006705\n",
      "2023-12-01 21:05:46,919 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 21:05:47,671 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 21:06:21,383 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 21:06:30,363 INFO     Valid MRR at step 30000: 0.948924\n",
      "2023-12-01 21:06:30,363 INFO     Valid MR at step 30000: 333.624700\n",
      "2023-12-01 21:06:30,364 INFO     Valid HITS@1 at step 30000: 0.944200\n",
      "2023-12-01 21:06:30,364 INFO     Valid HITS@3 at step 30000: 0.951100\n",
      "2023-12-01 21:06:30,364 INFO     Valid HITS@10 at step 30000: 0.958100\n",
      "2023-12-01 21:06:42,765 INFO     Training average positive_sample_loss at step 30100: 0.006914\n",
      "2023-12-01 21:06:42,765 INFO     Training average negative_sample_loss at step 30100: 0.006310\n",
      "2023-12-01 21:06:42,765 INFO     Training average loss at step 30100: 0.006612\n",
      "2023-12-01 21:06:56,678 INFO     Training average positive_sample_loss at step 30200: 0.007007\n",
      "2023-12-01 21:06:56,678 INFO     Training average negative_sample_loss at step 30200: 0.006074\n",
      "2023-12-01 21:06:56,678 INFO     Training average loss at step 30200: 0.006540\n",
      "2023-12-01 21:07:11,015 INFO     Training average positive_sample_loss at step 30300: 0.007341\n",
      "2023-12-01 21:07:11,015 INFO     Training average negative_sample_loss at step 30300: 0.007177\n",
      "2023-12-01 21:07:11,015 INFO     Training average loss at step 30300: 0.007259\n",
      "2023-12-01 21:07:25,108 INFO     Training average positive_sample_loss at step 30400: 0.007277\n",
      "2023-12-01 21:07:25,108 INFO     Training average negative_sample_loss at step 30400: 0.006452\n",
      "2023-12-01 21:07:25,108 INFO     Training average loss at step 30400: 0.006865\n",
      "2023-12-01 21:07:41,538 INFO     Training average positive_sample_loss at step 30500: 0.007003\n",
      "2023-12-01 21:07:41,539 INFO     Training average negative_sample_loss at step 30500: 0.006605\n",
      "2023-12-01 21:07:41,539 INFO     Training average loss at step 30500: 0.006804\n",
      "2023-12-01 21:07:55,722 INFO     Training average positive_sample_loss at step 30600: 0.006696\n",
      "2023-12-01 21:07:55,722 INFO     Training average negative_sample_loss at step 30600: 0.006386\n",
      "2023-12-01 21:07:55,722 INFO     Training average loss at step 30600: 0.006541\n",
      "2023-12-01 21:08:09,993 INFO     Training average positive_sample_loss at step 30700: 0.006975\n",
      "2023-12-01 21:08:09,993 INFO     Training average negative_sample_loss at step 30700: 0.006233\n",
      "2023-12-01 21:08:09,993 INFO     Training average loss at step 30700: 0.006604\n",
      "2023-12-01 21:08:24,402 INFO     Training average positive_sample_loss at step 30800: 0.007141\n",
      "2023-12-01 21:08:24,402 INFO     Training average negative_sample_loss at step 30800: 0.006511\n",
      "2023-12-01 21:08:24,402 INFO     Training average loss at step 30800: 0.006826\n",
      "2023-12-01 21:08:38,055 INFO     Training average positive_sample_loss at step 30900: 0.007196\n",
      "2023-12-01 21:08:38,056 INFO     Training average negative_sample_loss at step 30900: 0.006562\n",
      "2023-12-01 21:08:38,056 INFO     Training average loss at step 30900: 0.006879\n",
      "2023-12-01 21:08:52,966 INFO     Training average positive_sample_loss at step 31000: 0.007352\n",
      "2023-12-01 21:08:52,966 INFO     Training average negative_sample_loss at step 31000: 0.006677\n",
      "2023-12-01 21:08:52,966 INFO     Training average loss at step 31000: 0.007014\n",
      "2023-12-01 21:09:09,935 INFO     Training average positive_sample_loss at step 31100: 0.006648\n",
      "2023-12-01 21:09:09,935 INFO     Training average negative_sample_loss at step 31100: 0.006507\n",
      "2023-12-01 21:09:09,935 INFO     Training average loss at step 31100: 0.006578\n",
      "2023-12-01 21:09:23,938 INFO     Training average positive_sample_loss at step 31200: 0.006779\n",
      "2023-12-01 21:09:23,939 INFO     Training average negative_sample_loss at step 31200: 0.006498\n",
      "2023-12-01 21:09:23,939 INFO     Training average loss at step 31200: 0.006638\n",
      "2023-12-01 21:09:37,909 INFO     Training average positive_sample_loss at step 31300: 0.007012\n",
      "2023-12-01 21:09:37,910 INFO     Training average negative_sample_loss at step 31300: 0.006112\n",
      "2023-12-01 21:09:37,910 INFO     Training average loss at step 31300: 0.006562\n",
      "2023-12-01 21:09:52,322 INFO     Training average positive_sample_loss at step 31400: 0.007148\n",
      "2023-12-01 21:09:52,322 INFO     Training average negative_sample_loss at step 31400: 0.006246\n",
      "2023-12-01 21:09:52,322 INFO     Training average loss at step 31400: 0.006697\n",
      "2023-12-01 21:10:06,071 INFO     Training average positive_sample_loss at step 31500: 0.007182\n",
      "2023-12-01 21:10:06,071 INFO     Training average negative_sample_loss at step 31500: 0.006289\n",
      "2023-12-01 21:10:06,071 INFO     Training average loss at step 31500: 0.006736\n",
      "2023-12-01 21:10:22,189 INFO     Training average positive_sample_loss at step 31600: 0.007040\n",
      "2023-12-01 21:10:22,190 INFO     Training average negative_sample_loss at step 31600: 0.006957\n",
      "2023-12-01 21:10:22,190 INFO     Training average loss at step 31600: 0.006999\n",
      "2023-12-01 21:10:35,762 INFO     Training average positive_sample_loss at step 31700: 0.006594\n",
      "2023-12-01 21:10:35,762 INFO     Training average negative_sample_loss at step 31700: 0.006210\n",
      "2023-12-01 21:10:35,762 INFO     Training average loss at step 31700: 0.006402\n",
      "2023-12-01 21:10:49,482 INFO     Training average positive_sample_loss at step 31800: 0.006940\n",
      "2023-12-01 21:10:49,482 INFO     Training average negative_sample_loss at step 31800: 0.005841\n",
      "2023-12-01 21:10:49,482 INFO     Training average loss at step 31800: 0.006390\n",
      "2023-12-01 21:11:03,522 INFO     Training average positive_sample_loss at step 31900: 0.007056\n",
      "2023-12-01 21:11:03,522 INFO     Training average negative_sample_loss at step 31900: 0.006361\n",
      "2023-12-01 21:11:03,522 INFO     Training average loss at step 31900: 0.006708\n",
      "2023-12-01 21:11:17,763 INFO     Training average positive_sample_loss at step 32000: 0.007067\n",
      "2023-12-01 21:11:17,764 INFO     Training average negative_sample_loss at step 32000: 0.006111\n",
      "2023-12-01 21:11:17,764 INFO     Training average loss at step 32000: 0.006589\n",
      "2023-12-01 21:11:31,485 INFO     Training average positive_sample_loss at step 32100: 0.007091\n",
      "2023-12-01 21:11:31,485 INFO     Training average negative_sample_loss at step 32100: 0.006262\n",
      "2023-12-01 21:11:31,485 INFO     Training average loss at step 32100: 0.006676\n",
      "2023-12-01 21:11:47,767 INFO     Training average positive_sample_loss at step 32200: 0.006554\n",
      "2023-12-01 21:11:47,768 INFO     Training average negative_sample_loss at step 32200: 0.006406\n",
      "2023-12-01 21:11:47,768 INFO     Training average loss at step 32200: 0.006480\n",
      "2023-12-01 21:12:02,143 INFO     Training average positive_sample_loss at step 32300: 0.006852\n",
      "2023-12-01 21:12:02,143 INFO     Training average negative_sample_loss at step 32300: 0.006390\n",
      "2023-12-01 21:12:02,144 INFO     Training average loss at step 32300: 0.006621\n",
      "2023-12-01 21:12:16,328 INFO     Training average positive_sample_loss at step 32400: 0.007156\n",
      "2023-12-01 21:12:16,328 INFO     Training average negative_sample_loss at step 32400: 0.006865\n",
      "2023-12-01 21:12:16,328 INFO     Training average loss at step 32400: 0.007011\n",
      "2023-12-01 21:12:30,886 INFO     Training average positive_sample_loss at step 32500: 0.007200\n",
      "2023-12-01 21:12:30,886 INFO     Training average negative_sample_loss at step 32500: 0.006420\n",
      "2023-12-01 21:12:30,886 INFO     Training average loss at step 32500: 0.006810\n",
      "2023-12-01 21:12:45,305 INFO     Training average positive_sample_loss at step 32600: 0.007053\n",
      "2023-12-01 21:12:45,305 INFO     Training average negative_sample_loss at step 32600: 0.006234\n",
      "2023-12-01 21:12:45,305 INFO     Training average loss at step 32600: 0.006644\n",
      "2023-12-01 21:13:01,762 INFO     Training average positive_sample_loss at step 32700: 0.006918\n",
      "2023-12-01 21:13:01,762 INFO     Training average negative_sample_loss at step 32700: 0.006339\n",
      "2023-12-01 21:13:01,762 INFO     Training average loss at step 32700: 0.006628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:13:16,216 INFO     Training average positive_sample_loss at step 32800: 0.006473\n",
      "2023-12-01 21:13:16,216 INFO     Training average negative_sample_loss at step 32800: 0.006940\n",
      "2023-12-01 21:13:16,217 INFO     Training average loss at step 32800: 0.006707\n",
      "2023-12-01 21:13:29,976 INFO     Training average positive_sample_loss at step 32900: 0.006913\n",
      "2023-12-01 21:13:29,976 INFO     Training average negative_sample_loss at step 32900: 0.006511\n",
      "2023-12-01 21:13:29,977 INFO     Training average loss at step 32900: 0.006712\n",
      "2023-12-01 21:13:43,557 INFO     Training average positive_sample_loss at step 33000: 0.007087\n",
      "2023-12-01 21:13:43,557 INFO     Training average negative_sample_loss at step 33000: 0.006066\n",
      "2023-12-01 21:13:43,557 INFO     Training average loss at step 33000: 0.006577\n",
      "2023-12-01 21:13:57,626 INFO     Training average positive_sample_loss at step 33100: 0.007121\n",
      "2023-12-01 21:13:57,626 INFO     Training average negative_sample_loss at step 33100: 0.006092\n",
      "2023-12-01 21:13:57,626 INFO     Training average loss at step 33100: 0.006607\n",
      "2023-12-01 21:14:11,890 INFO     Training average positive_sample_loss at step 33200: 0.007178\n",
      "2023-12-01 21:14:11,890 INFO     Training average negative_sample_loss at step 33200: 0.006398\n",
      "2023-12-01 21:14:11,890 INFO     Training average loss at step 33200: 0.006788\n",
      "2023-12-01 21:14:27,230 INFO     Training average positive_sample_loss at step 33300: 0.006610\n",
      "2023-12-01 21:14:27,230 INFO     Training average negative_sample_loss at step 33300: 0.006140\n",
      "2023-12-01 21:14:27,230 INFO     Training average loss at step 33300: 0.006375\n",
      "2023-12-01 21:14:41,961 INFO     Training average positive_sample_loss at step 33400: 0.006639\n",
      "2023-12-01 21:14:41,961 INFO     Training average negative_sample_loss at step 33400: 0.006688\n",
      "2023-12-01 21:14:41,961 INFO     Training average loss at step 33400: 0.006663\n",
      "2023-12-01 21:14:56,848 INFO     Training average positive_sample_loss at step 33500: 0.007003\n",
      "2023-12-01 21:14:56,848 INFO     Training average negative_sample_loss at step 33500: 0.006744\n",
      "2023-12-01 21:14:56,848 INFO     Training average loss at step 33500: 0.006873\n",
      "2023-12-01 21:15:11,405 INFO     Training average positive_sample_loss at step 33600: 0.007087\n",
      "2023-12-01 21:15:11,405 INFO     Training average negative_sample_loss at step 33600: 0.006843\n",
      "2023-12-01 21:15:11,405 INFO     Training average loss at step 33600: 0.006965\n",
      "2023-12-01 21:15:26,048 INFO     Training average positive_sample_loss at step 33700: 0.007137\n",
      "2023-12-01 21:15:26,048 INFO     Training average negative_sample_loss at step 33700: 0.006762\n",
      "2023-12-01 21:15:26,049 INFO     Training average loss at step 33700: 0.006950\n",
      "2023-12-01 21:15:42,823 INFO     Training average positive_sample_loss at step 33800: 0.007064\n",
      "2023-12-01 21:15:42,823 INFO     Training average negative_sample_loss at step 33800: 0.006630\n",
      "2023-12-01 21:15:42,823 INFO     Training average loss at step 33800: 0.006847\n",
      "2023-12-01 21:15:57,694 INFO     Training average positive_sample_loss at step 33900: 0.006441\n",
      "2023-12-01 21:15:57,695 INFO     Training average negative_sample_loss at step 33900: 0.006357\n",
      "2023-12-01 21:15:57,695 INFO     Training average loss at step 33900: 0.006399\n",
      "2023-12-01 21:16:12,072 INFO     Training average positive_sample_loss at step 34000: 0.006918\n",
      "2023-12-01 21:16:12,073 INFO     Training average negative_sample_loss at step 34000: 0.006766\n",
      "2023-12-01 21:16:12,073 INFO     Training average loss at step 34000: 0.006842\n",
      "2023-12-01 21:16:25,688 INFO     Training average positive_sample_loss at step 34100: 0.006998\n",
      "2023-12-01 21:16:25,689 INFO     Training average negative_sample_loss at step 34100: 0.006174\n",
      "2023-12-01 21:16:25,689 INFO     Training average loss at step 34100: 0.006586\n",
      "2023-12-01 21:16:39,678 INFO     Training average positive_sample_loss at step 34200: 0.007026\n",
      "2023-12-01 21:16:39,678 INFO     Training average negative_sample_loss at step 34200: 0.006205\n",
      "2023-12-01 21:16:39,678 INFO     Training average loss at step 34200: 0.006616\n",
      "2023-12-01 21:16:53,434 INFO     Training average positive_sample_loss at step 34300: 0.007125\n",
      "2023-12-01 21:16:53,434 INFO     Training average negative_sample_loss at step 34300: 0.006960\n",
      "2023-12-01 21:16:53,434 INFO     Training average loss at step 34300: 0.007042\n",
      "2023-12-01 21:17:10,618 INFO     Training average positive_sample_loss at step 34400: 0.006676\n",
      "2023-12-01 21:17:10,619 INFO     Training average negative_sample_loss at step 34400: 0.006415\n",
      "2023-12-01 21:17:10,619 INFO     Training average loss at step 34400: 0.006546\n",
      "2023-12-01 21:17:24,545 INFO     Training average positive_sample_loss at step 34500: 0.006632\n",
      "2023-12-01 21:17:24,545 INFO     Training average negative_sample_loss at step 34500: 0.006588\n",
      "2023-12-01 21:17:24,545 INFO     Training average loss at step 34500: 0.006610\n",
      "2023-12-01 21:17:38,479 INFO     Training average positive_sample_loss at step 34600: 0.006833\n",
      "2023-12-01 21:17:38,479 INFO     Training average negative_sample_loss at step 34600: 0.006923\n",
      "2023-12-01 21:17:38,479 INFO     Training average loss at step 34600: 0.006878\n",
      "2023-12-01 21:17:52,433 INFO     Training average positive_sample_loss at step 34700: 0.007070\n",
      "2023-12-01 21:17:52,434 INFO     Training average negative_sample_loss at step 34700: 0.006043\n",
      "2023-12-01 21:17:52,434 INFO     Training average loss at step 34700: 0.006556\n",
      "2023-12-01 21:18:06,246 INFO     Training average positive_sample_loss at step 34800: 0.007105\n",
      "2023-12-01 21:18:06,247 INFO     Training average negative_sample_loss at step 34800: 0.006270\n",
      "2023-12-01 21:18:06,247 INFO     Training average loss at step 34800: 0.006687\n",
      "2023-12-01 21:18:20,047 INFO     Training average positive_sample_loss at step 34900: 0.007131\n",
      "2023-12-01 21:18:20,048 INFO     Training average negative_sample_loss at step 34900: 0.006191\n",
      "2023-12-01 21:18:20,048 INFO     Training average loss at step 34900: 0.006661\n",
      "2023-12-01 21:18:36,734 INFO     Training average positive_sample_loss at step 35000: 0.006308\n",
      "2023-12-01 21:18:36,735 INFO     Training average negative_sample_loss at step 35000: 0.006412\n",
      "2023-12-01 21:18:36,735 INFO     Training average loss at step 35000: 0.006360\n",
      "2023-12-01 21:18:50,966 INFO     Training average positive_sample_loss at step 35100: 0.006783\n",
      "2023-12-01 21:18:50,967 INFO     Training average negative_sample_loss at step 35100: 0.006447\n",
      "2023-12-01 21:18:50,967 INFO     Training average loss at step 35100: 0.006615\n",
      "2023-12-01 21:19:05,790 INFO     Training average positive_sample_loss at step 35200: 0.006914\n",
      "2023-12-01 21:19:05,791 INFO     Training average negative_sample_loss at step 35200: 0.006146\n",
      "2023-12-01 21:19:05,791 INFO     Training average loss at step 35200: 0.006530\n",
      "2023-12-01 21:19:19,638 INFO     Training average positive_sample_loss at step 35300: 0.007062\n",
      "2023-12-01 21:19:19,638 INFO     Training average negative_sample_loss at step 35300: 0.006595\n",
      "2023-12-01 21:19:19,638 INFO     Training average loss at step 35300: 0.006829\n",
      "2023-12-01 21:19:33,199 INFO     Training average positive_sample_loss at step 35400: 0.007001\n",
      "2023-12-01 21:19:33,200 INFO     Training average negative_sample_loss at step 35400: 0.006401\n",
      "2023-12-01 21:19:33,200 INFO     Training average loss at step 35400: 0.006701\n",
      "2023-12-01 21:19:50,256 INFO     Training average positive_sample_loss at step 35500: 0.006632\n",
      "2023-12-01 21:19:50,256 INFO     Training average negative_sample_loss at step 35500: 0.006669\n",
      "2023-12-01 21:19:50,256 INFO     Training average loss at step 35500: 0.006650\n",
      "2023-12-01 21:20:04,387 INFO     Training average positive_sample_loss at step 35600: 0.006560\n",
      "2023-12-01 21:20:04,388 INFO     Training average negative_sample_loss at step 35600: 0.006397\n",
      "2023-12-01 21:20:04,388 INFO     Training average loss at step 35600: 0.006479\n",
      "2023-12-01 21:20:18,099 INFO     Training average positive_sample_loss at step 35700: 0.006937\n",
      "2023-12-01 21:20:18,100 INFO     Training average negative_sample_loss at step 35700: 0.006378\n",
      "2023-12-01 21:20:18,100 INFO     Training average loss at step 35700: 0.006657\n",
      "2023-12-01 21:20:31,389 INFO     Training average positive_sample_loss at step 35800: 0.006972\n",
      "2023-12-01 21:20:31,389 INFO     Training average negative_sample_loss at step 35800: 0.006413\n",
      "2023-12-01 21:20:31,389 INFO     Training average loss at step 35800: 0.006692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:20:45,460 INFO     Training average positive_sample_loss at step 35900: 0.007039\n",
      "2023-12-01 21:20:45,461 INFO     Training average negative_sample_loss at step 35900: 0.006356\n",
      "2023-12-01 21:20:45,461 INFO     Training average loss at step 35900: 0.006698\n",
      "2023-12-01 21:21:00,217 INFO     Training average positive_sample_loss at step 36000: 0.007066\n",
      "2023-12-01 21:21:00,217 INFO     Training average negative_sample_loss at step 36000: 0.006709\n",
      "2023-12-01 21:21:00,217 INFO     Training average loss at step 36000: 0.006888\n",
      "2023-12-01 21:21:16,346 INFO     Training average positive_sample_loss at step 36100: 0.006316\n",
      "2023-12-01 21:21:16,346 INFO     Training average negative_sample_loss at step 36100: 0.006171\n",
      "2023-12-01 21:21:16,346 INFO     Training average loss at step 36100: 0.006243\n",
      "2023-12-01 21:21:30,034 INFO     Training average positive_sample_loss at step 36200: 0.006666\n",
      "2023-12-01 21:21:30,035 INFO     Training average negative_sample_loss at step 36200: 0.006473\n",
      "2023-12-01 21:21:30,035 INFO     Training average loss at step 36200: 0.006569\n",
      "2023-12-01 21:21:44,129 INFO     Training average positive_sample_loss at step 36300: 0.006917\n",
      "2023-12-01 21:21:44,129 INFO     Training average negative_sample_loss at step 36300: 0.006590\n",
      "2023-12-01 21:21:44,129 INFO     Training average loss at step 36300: 0.006753\n",
      "2023-12-01 21:21:59,765 INFO     Training average positive_sample_loss at step 36400: 0.007120\n",
      "2023-12-01 21:21:59,765 INFO     Training average negative_sample_loss at step 36400: 0.007227\n",
      "2023-12-01 21:21:59,765 INFO     Training average loss at step 36400: 0.007173\n",
      "2023-12-01 21:22:14,826 INFO     Training average positive_sample_loss at step 36500: 0.007029\n",
      "2023-12-01 21:22:14,826 INFO     Training average negative_sample_loss at step 36500: 0.006329\n",
      "2023-12-01 21:22:14,827 INFO     Training average loss at step 36500: 0.006679\n",
      "2023-12-01 21:22:31,601 INFO     Training average positive_sample_loss at step 36600: 0.006719\n",
      "2023-12-01 21:22:31,602 INFO     Training average negative_sample_loss at step 36600: 0.006815\n",
      "2023-12-01 21:22:31,602 INFO     Training average loss at step 36600: 0.006767\n",
      "2023-12-01 21:22:46,313 INFO     Training average positive_sample_loss at step 36700: 0.006604\n",
      "2023-12-01 21:22:46,313 INFO     Training average negative_sample_loss at step 36700: 0.006973\n",
      "2023-12-01 21:22:46,314 INFO     Training average loss at step 36700: 0.006789\n",
      "2023-12-01 21:23:00,255 INFO     Training average positive_sample_loss at step 36800: 0.006844\n",
      "2023-12-01 21:23:00,255 INFO     Training average negative_sample_loss at step 36800: 0.006401\n",
      "2023-12-01 21:23:00,255 INFO     Training average loss at step 36800: 0.006622\n",
      "2023-12-01 21:23:14,640 INFO     Training average positive_sample_loss at step 36900: 0.006991\n",
      "2023-12-01 21:23:14,640 INFO     Training average negative_sample_loss at step 36900: 0.006515\n",
      "2023-12-01 21:23:14,640 INFO     Training average loss at step 36900: 0.006753\n",
      "2023-12-01 21:23:28,511 INFO     Training average positive_sample_loss at step 37000: 0.006955\n",
      "2023-12-01 21:23:28,511 INFO     Training average negative_sample_loss at step 37000: 0.006325\n",
      "2023-12-01 21:23:28,511 INFO     Training average loss at step 37000: 0.006640\n",
      "2023-12-01 21:23:42,012 INFO     Training average positive_sample_loss at step 37100: 0.007047\n",
      "2023-12-01 21:23:42,012 INFO     Training average negative_sample_loss at step 37100: 0.006084\n",
      "2023-12-01 21:23:42,012 INFO     Training average loss at step 37100: 0.006566\n",
      "2023-12-01 21:23:59,345 INFO     Training average positive_sample_loss at step 37200: 0.006230\n",
      "2023-12-01 21:23:59,345 INFO     Training average negative_sample_loss at step 37200: 0.006350\n",
      "2023-12-01 21:23:59,345 INFO     Training average loss at step 37200: 0.006290\n",
      "2023-12-01 21:24:13,558 INFO     Training average positive_sample_loss at step 37300: 0.006606\n",
      "2023-12-01 21:24:13,558 INFO     Training average negative_sample_loss at step 37300: 0.006303\n",
      "2023-12-01 21:24:13,559 INFO     Training average loss at step 37300: 0.006454\n",
      "2023-12-01 21:24:27,918 INFO     Training average positive_sample_loss at step 37400: 0.006858\n",
      "2023-12-01 21:24:27,918 INFO     Training average negative_sample_loss at step 37400: 0.006864\n",
      "2023-12-01 21:24:27,918 INFO     Training average loss at step 37400: 0.006861\n",
      "2023-12-01 21:24:41,708 INFO     Training average positive_sample_loss at step 37500: 0.007083\n",
      "2023-12-01 21:24:41,708 INFO     Training average negative_sample_loss at step 37500: 0.006802\n",
      "2023-12-01 21:24:41,708 INFO     Training average loss at step 37500: 0.006943\n",
      "2023-12-01 21:24:55,621 INFO     Training average positive_sample_loss at step 37600: 0.007063\n",
      "2023-12-01 21:24:55,621 INFO     Training average negative_sample_loss at step 37600: 0.006529\n",
      "2023-12-01 21:24:55,621 INFO     Training average loss at step 37600: 0.006796\n",
      "2023-12-01 21:25:11,504 INFO     Training average positive_sample_loss at step 37700: 0.006766\n",
      "2023-12-01 21:25:11,504 INFO     Training average negative_sample_loss at step 37700: 0.006704\n",
      "2023-12-01 21:25:11,504 INFO     Training average loss at step 37700: 0.006735\n",
      "2023-12-01 21:25:26,018 INFO     Training average positive_sample_loss at step 37800: 0.006477\n",
      "2023-12-01 21:25:26,018 INFO     Training average negative_sample_loss at step 37800: 0.006205\n",
      "2023-12-01 21:25:26,018 INFO     Training average loss at step 37800: 0.006341\n",
      "2023-12-01 21:25:40,188 INFO     Training average positive_sample_loss at step 37900: 0.006651\n",
      "2023-12-01 21:25:40,188 INFO     Training average negative_sample_loss at step 37900: 0.006210\n",
      "2023-12-01 21:25:40,188 INFO     Training average loss at step 37900: 0.006431\n",
      "2023-12-01 21:25:54,360 INFO     Training average positive_sample_loss at step 38000: 0.006981\n",
      "2023-12-01 21:25:54,361 INFO     Training average negative_sample_loss at step 38000: 0.006342\n",
      "2023-12-01 21:25:54,361 INFO     Training average loss at step 38000: 0.006662\n",
      "2023-12-01 21:26:08,132 INFO     Training average positive_sample_loss at step 38100: 0.006942\n",
      "2023-12-01 21:26:08,132 INFO     Training average negative_sample_loss at step 38100: 0.006629\n",
      "2023-12-01 21:26:08,132 INFO     Training average loss at step 38100: 0.006785\n",
      "2023-12-01 21:26:22,682 INFO     Training average positive_sample_loss at step 38200: 0.007078\n",
      "2023-12-01 21:26:22,682 INFO     Training average negative_sample_loss at step 38200: 0.006214\n",
      "2023-12-01 21:26:22,682 INFO     Training average loss at step 38200: 0.006646\n",
      "2023-12-01 21:26:38,931 INFO     Training average positive_sample_loss at step 38300: 0.006321\n",
      "2023-12-01 21:26:38,932 INFO     Training average negative_sample_loss at step 38300: 0.006555\n",
      "2023-12-01 21:26:38,932 INFO     Training average loss at step 38300: 0.006438\n",
      "2023-12-01 21:26:53,813 INFO     Training average positive_sample_loss at step 38400: 0.006625\n",
      "2023-12-01 21:26:53,813 INFO     Training average negative_sample_loss at step 38400: 0.006743\n",
      "2023-12-01 21:26:53,813 INFO     Training average loss at step 38400: 0.006684\n",
      "2023-12-01 21:27:07,519 INFO     Training average positive_sample_loss at step 38500: 0.006886\n",
      "2023-12-01 21:27:07,519 INFO     Training average negative_sample_loss at step 38500: 0.006271\n",
      "2023-12-01 21:27:07,519 INFO     Training average loss at step 38500: 0.006579\n",
      "2023-12-01 21:27:21,293 INFO     Training average positive_sample_loss at step 38600: 0.006966\n",
      "2023-12-01 21:27:21,293 INFO     Training average negative_sample_loss at step 38600: 0.006768\n",
      "2023-12-01 21:27:21,293 INFO     Training average loss at step 38600: 0.006867\n",
      "2023-12-01 21:27:35,291 INFO     Training average positive_sample_loss at step 38700: 0.007010\n",
      "2023-12-01 21:27:35,291 INFO     Training average negative_sample_loss at step 38700: 0.006203\n",
      "2023-12-01 21:27:35,291 INFO     Training average loss at step 38700: 0.006607\n",
      "2023-12-01 21:27:51,393 INFO     Training average positive_sample_loss at step 38800: 0.006715\n",
      "2023-12-01 21:27:51,394 INFO     Training average negative_sample_loss at step 38800: 0.006496\n",
      "2023-12-01 21:27:51,394 INFO     Training average loss at step 38800: 0.006605\n",
      "2023-12-01 21:28:05,452 INFO     Training average positive_sample_loss at step 38900: 0.006374\n",
      "2023-12-01 21:28:05,453 INFO     Training average negative_sample_loss at step 38900: 0.006585\n",
      "2023-12-01 21:28:05,453 INFO     Training average loss at step 38900: 0.006480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:28:20,162 INFO     Training average positive_sample_loss at step 39000: 0.006753\n",
      "2023-12-01 21:28:20,163 INFO     Training average negative_sample_loss at step 39000: 0.006039\n",
      "2023-12-01 21:28:20,163 INFO     Training average loss at step 39000: 0.006396\n",
      "2023-12-01 21:28:33,932 INFO     Training average positive_sample_loss at step 39100: 0.006914\n",
      "2023-12-01 21:28:33,933 INFO     Training average negative_sample_loss at step 39100: 0.006948\n",
      "2023-12-01 21:28:33,933 INFO     Training average loss at step 39100: 0.006931\n",
      "2023-12-01 21:28:47,715 INFO     Training average positive_sample_loss at step 39200: 0.006982\n",
      "2023-12-01 21:28:47,716 INFO     Training average negative_sample_loss at step 39200: 0.006455\n",
      "2023-12-01 21:28:47,716 INFO     Training average loss at step 39200: 0.006719\n",
      "2023-12-01 21:29:01,583 INFO     Training average positive_sample_loss at step 39300: 0.006967\n",
      "2023-12-01 21:29:01,583 INFO     Training average negative_sample_loss at step 39300: 0.006730\n",
      "2023-12-01 21:29:01,583 INFO     Training average loss at step 39300: 0.006849\n",
      "2023-12-01 21:29:18,475 INFO     Training average positive_sample_loss at step 39400: 0.006392\n",
      "2023-12-01 21:29:18,476 INFO     Training average negative_sample_loss at step 39400: 0.006451\n",
      "2023-12-01 21:29:18,476 INFO     Training average loss at step 39400: 0.006421\n",
      "2023-12-01 21:29:32,373 INFO     Training average positive_sample_loss at step 39500: 0.006597\n",
      "2023-12-01 21:29:32,373 INFO     Training average negative_sample_loss at step 39500: 0.006289\n",
      "2023-12-01 21:29:32,373 INFO     Training average loss at step 39500: 0.006443\n",
      "2023-12-01 21:29:47,136 INFO     Training average positive_sample_loss at step 39600: 0.006790\n",
      "2023-12-01 21:29:47,136 INFO     Training average negative_sample_loss at step 39600: 0.006087\n",
      "2023-12-01 21:29:47,136 INFO     Training average loss at step 39600: 0.006438\n",
      "2023-12-01 21:30:00,774 INFO     Training average positive_sample_loss at step 39700: 0.006726\n",
      "2023-12-01 21:30:00,774 INFO     Training average negative_sample_loss at step 39700: 0.006033\n",
      "2023-12-01 21:30:00,774 INFO     Training average loss at step 39700: 0.006380\n",
      "2023-12-01 21:30:14,204 INFO     Training average positive_sample_loss at step 39800: 0.006948\n",
      "2023-12-01 21:30:14,204 INFO     Training average negative_sample_loss at step 39800: 0.006628\n",
      "2023-12-01 21:30:14,204 INFO     Training average loss at step 39800: 0.006788\n",
      "2023-12-01 21:30:30,871 INFO     Training average positive_sample_loss at step 39900: 0.006814\n",
      "2023-12-01 21:30:30,871 INFO     Training average negative_sample_loss at step 39900: 0.006441\n",
      "2023-12-01 21:30:30,871 INFO     Training average loss at step 39900: 0.006628\n",
      "2023-12-01 21:30:45,020 INFO     Change learning_rate to 0.000010 at step 40000\n",
      "2023-12-01 21:30:50,400 INFO     Training average positive_sample_loss at step 40000: 0.006271\n",
      "2023-12-01 21:30:50,400 INFO     Training average negative_sample_loss at step 40000: 0.006627\n",
      "2023-12-01 21:30:50,400 INFO     Training average loss at step 40000: 0.006449\n",
      "2023-12-01 21:30:50,400 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 21:30:51,336 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 21:31:27,632 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 21:31:36,069 INFO     Valid MRR at step 40000: 0.948672\n",
      "2023-12-01 21:31:36,069 INFO     Valid MR at step 40000: 306.397300\n",
      "2023-12-01 21:31:36,069 INFO     Valid HITS@1 at step 40000: 0.943600\n",
      "2023-12-01 21:31:36,069 INFO     Valid HITS@3 at step 40000: 0.950900\n",
      "2023-12-01 21:31:36,069 INFO     Valid HITS@10 at step 40000: 0.958000\n",
      "2023-12-01 21:31:48,431 INFO     Training average positive_sample_loss at step 40100: 0.006603\n",
      "2023-12-01 21:31:48,432 INFO     Training average negative_sample_loss at step 40100: 0.005996\n",
      "2023-12-01 21:31:48,432 INFO     Training average loss at step 40100: 0.006299\n",
      "2023-12-01 21:32:02,104 INFO     Training average positive_sample_loss at step 40200: 0.006406\n",
      "2023-12-01 21:32:02,104 INFO     Training average negative_sample_loss at step 40200: 0.006639\n",
      "2023-12-01 21:32:02,104 INFO     Training average loss at step 40200: 0.006523\n",
      "2023-12-01 21:32:16,231 INFO     Training average positive_sample_loss at step 40300: 0.006338\n",
      "2023-12-01 21:32:16,231 INFO     Training average negative_sample_loss at step 40300: 0.006303\n",
      "2023-12-01 21:32:16,231 INFO     Training average loss at step 40300: 0.006321\n",
      "2023-12-01 21:32:30,484 INFO     Training average positive_sample_loss at step 40400: 0.006286\n",
      "2023-12-01 21:32:30,484 INFO     Training average negative_sample_loss at step 40400: 0.007280\n",
      "2023-12-01 21:32:30,484 INFO     Training average loss at step 40400: 0.006783\n",
      "2023-12-01 21:32:46,777 INFO     Training average positive_sample_loss at step 40500: 0.005886\n",
      "2023-12-01 21:32:46,777 INFO     Training average negative_sample_loss at step 40500: 0.006349\n",
      "2023-12-01 21:32:46,777 INFO     Training average loss at step 40500: 0.006118\n",
      "2023-12-01 21:33:00,454 INFO     Training average positive_sample_loss at step 40600: 0.005678\n",
      "2023-12-01 21:33:00,454 INFO     Training average negative_sample_loss at step 40600: 0.006469\n",
      "2023-12-01 21:33:00,455 INFO     Training average loss at step 40600: 0.006074\n",
      "2023-12-01 21:33:15,060 INFO     Training average positive_sample_loss at step 40700: 0.005641\n",
      "2023-12-01 21:33:15,060 INFO     Training average negative_sample_loss at step 40700: 0.006228\n",
      "2023-12-01 21:33:15,061 INFO     Training average loss at step 40700: 0.005934\n",
      "2023-12-01 21:33:30,348 INFO     Training average positive_sample_loss at step 40800: 0.005653\n",
      "2023-12-01 21:33:30,349 INFO     Training average negative_sample_loss at step 40800: 0.006194\n",
      "2023-12-01 21:33:30,349 INFO     Training average loss at step 40800: 0.005923\n",
      "2023-12-01 21:33:43,868 INFO     Training average positive_sample_loss at step 40900: 0.005592\n",
      "2023-12-01 21:33:43,869 INFO     Training average negative_sample_loss at step 40900: 0.006493\n",
      "2023-12-01 21:33:43,869 INFO     Training average loss at step 40900: 0.006042\n",
      "2023-12-01 21:34:00,824 INFO     Training average positive_sample_loss at step 41000: 0.005671\n",
      "2023-12-01 21:34:00,824 INFO     Training average negative_sample_loss at step 41000: 0.006596\n",
      "2023-12-01 21:34:00,824 INFO     Training average loss at step 41000: 0.006133\n",
      "2023-12-01 21:34:14,872 INFO     Training average positive_sample_loss at step 41100: 0.005406\n",
      "2023-12-01 21:34:14,872 INFO     Training average negative_sample_loss at step 41100: 0.006160\n",
      "2023-12-01 21:34:14,872 INFO     Training average loss at step 41100: 0.005783\n",
      "2023-12-01 21:34:28,563 INFO     Training average positive_sample_loss at step 41200: 0.005375\n",
      "2023-12-01 21:34:28,563 INFO     Training average negative_sample_loss at step 41200: 0.006123\n",
      "2023-12-01 21:34:28,563 INFO     Training average loss at step 41200: 0.005749\n",
      "2023-12-01 21:34:41,821 INFO     Training average positive_sample_loss at step 41300: 0.005470\n",
      "2023-12-01 21:34:41,821 INFO     Training average negative_sample_loss at step 41300: 0.006374\n",
      "2023-12-01 21:34:41,821 INFO     Training average loss at step 41300: 0.005922\n",
      "2023-12-01 21:34:55,901 INFO     Training average positive_sample_loss at step 41400: 0.005481\n",
      "2023-12-01 21:34:55,902 INFO     Training average negative_sample_loss at step 41400: 0.006726\n",
      "2023-12-01 21:34:55,902 INFO     Training average loss at step 41400: 0.006104\n",
      "2023-12-01 21:35:10,469 INFO     Training average positive_sample_loss at step 41500: 0.005434\n",
      "2023-12-01 21:35:10,470 INFO     Training average negative_sample_loss at step 41500: 0.006576\n",
      "2023-12-01 21:35:10,470 INFO     Training average loss at step 41500: 0.006005\n",
      "2023-12-01 21:35:26,857 INFO     Training average positive_sample_loss at step 41600: 0.005428\n",
      "2023-12-01 21:35:26,857 INFO     Training average negative_sample_loss at step 41600: 0.006524\n",
      "2023-12-01 21:35:26,857 INFO     Training average loss at step 41600: 0.005976\n",
      "2023-12-01 21:35:41,697 INFO     Training average positive_sample_loss at step 41700: 0.005292\n",
      "2023-12-01 21:35:41,698 INFO     Training average negative_sample_loss at step 41700: 0.006305\n",
      "2023-12-01 21:35:41,698 INFO     Training average loss at step 41700: 0.005798\n",
      "2023-12-01 21:35:55,390 INFO     Training average positive_sample_loss at step 41800: 0.005318\n",
      "2023-12-01 21:35:55,390 INFO     Training average negative_sample_loss at step 41800: 0.006210\n",
      "2023-12-01 21:35:55,390 INFO     Training average loss at step 41800: 0.005764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:36:09,793 INFO     Training average positive_sample_loss at step 41900: 0.005241\n",
      "2023-12-01 21:36:09,793 INFO     Training average negative_sample_loss at step 41900: 0.006316\n",
      "2023-12-01 21:36:09,793 INFO     Training average loss at step 41900: 0.005778\n",
      "2023-12-01 21:36:24,137 INFO     Training average positive_sample_loss at step 42000: 0.005443\n",
      "2023-12-01 21:36:24,137 INFO     Training average negative_sample_loss at step 42000: 0.006399\n",
      "2023-12-01 21:36:24,137 INFO     Training average loss at step 42000: 0.005921\n",
      "2023-12-01 21:36:39,094 INFO     Training average positive_sample_loss at step 42100: 0.005431\n",
      "2023-12-01 21:36:39,095 INFO     Training average negative_sample_loss at step 42100: 0.006263\n",
      "2023-12-01 21:36:39,095 INFO     Training average loss at step 42100: 0.005847\n",
      "2023-12-01 21:36:56,584 INFO     Training average positive_sample_loss at step 42200: 0.005208\n",
      "2023-12-01 21:36:56,584 INFO     Training average negative_sample_loss at step 42200: 0.006575\n",
      "2023-12-01 21:36:56,584 INFO     Training average loss at step 42200: 0.005892\n",
      "2023-12-01 21:37:10,696 INFO     Training average positive_sample_loss at step 42300: 0.005256\n",
      "2023-12-01 21:37:10,697 INFO     Training average negative_sample_loss at step 42300: 0.005912\n",
      "2023-12-01 21:37:10,697 INFO     Training average loss at step 42300: 0.005584\n",
      "2023-12-01 21:37:24,363 INFO     Training average positive_sample_loss at step 42400: 0.005279\n",
      "2023-12-01 21:37:24,363 INFO     Training average negative_sample_loss at step 42400: 0.006042\n",
      "2023-12-01 21:37:24,363 INFO     Training average loss at step 42400: 0.005661\n",
      "2023-12-01 21:37:37,863 INFO     Training average positive_sample_loss at step 42500: 0.005267\n",
      "2023-12-01 21:37:37,864 INFO     Training average negative_sample_loss at step 42500: 0.006211\n",
      "2023-12-01 21:37:37,864 INFO     Training average loss at step 42500: 0.005739\n",
      "2023-12-01 21:37:52,538 INFO     Training average positive_sample_loss at step 42600: 0.005395\n",
      "2023-12-01 21:37:52,538 INFO     Training average negative_sample_loss at step 42600: 0.006844\n",
      "2023-12-01 21:37:52,538 INFO     Training average loss at step 42600: 0.006120\n",
      "2023-12-01 21:38:10,496 INFO     Training average positive_sample_loss at step 42700: 0.005195\n",
      "2023-12-01 21:38:10,496 INFO     Training average negative_sample_loss at step 42700: 0.005993\n",
      "2023-12-01 21:38:10,496 INFO     Training average loss at step 42700: 0.005594\n",
      "2023-12-01 21:38:24,229 INFO     Training average positive_sample_loss at step 42800: 0.005202\n",
      "2023-12-01 21:38:24,230 INFO     Training average negative_sample_loss at step 42800: 0.006511\n",
      "2023-12-01 21:38:24,230 INFO     Training average loss at step 42800: 0.005856\n",
      "2023-12-01 21:38:38,016 INFO     Training average positive_sample_loss at step 42900: 0.005220\n",
      "2023-12-01 21:38:38,016 INFO     Training average negative_sample_loss at step 42900: 0.006336\n",
      "2023-12-01 21:38:38,016 INFO     Training average loss at step 42900: 0.005778\n",
      "2023-12-01 21:38:51,782 INFO     Training average positive_sample_loss at step 43000: 0.005300\n",
      "2023-12-01 21:38:51,782 INFO     Training average negative_sample_loss at step 43000: 0.006567\n",
      "2023-12-01 21:38:51,782 INFO     Training average loss at step 43000: 0.005933\n",
      "2023-12-01 21:39:06,157 INFO     Training average positive_sample_loss at step 43100: 0.005291\n",
      "2023-12-01 21:39:06,157 INFO     Training average negative_sample_loss at step 43100: 0.006155\n",
      "2023-12-01 21:39:06,157 INFO     Training average loss at step 43100: 0.005723\n",
      "2023-12-01 21:39:19,963 INFO     Training average positive_sample_loss at step 43200: 0.005306\n",
      "2023-12-01 21:39:19,964 INFO     Training average negative_sample_loss at step 43200: 0.006141\n",
      "2023-12-01 21:39:19,964 INFO     Training average loss at step 43200: 0.005723\n",
      "2023-12-01 21:39:36,020 INFO     Training average positive_sample_loss at step 43300: 0.005238\n",
      "2023-12-01 21:39:36,020 INFO     Training average negative_sample_loss at step 43300: 0.006953\n",
      "2023-12-01 21:39:36,020 INFO     Training average loss at step 43300: 0.006095\n",
      "2023-12-01 21:39:49,828 INFO     Training average positive_sample_loss at step 43400: 0.005223\n",
      "2023-12-01 21:39:49,828 INFO     Training average negative_sample_loss at step 43400: 0.005841\n",
      "2023-12-01 21:39:49,828 INFO     Training average loss at step 43400: 0.005532\n",
      "2023-12-01 21:40:03,550 INFO     Training average positive_sample_loss at step 43500: 0.005158\n",
      "2023-12-01 21:40:03,551 INFO     Training average negative_sample_loss at step 43500: 0.006483\n",
      "2023-12-01 21:40:03,551 INFO     Training average loss at step 43500: 0.005821\n",
      "2023-12-01 21:40:17,093 INFO     Training average positive_sample_loss at step 43600: 0.005212\n",
      "2023-12-01 21:40:17,093 INFO     Training average negative_sample_loss at step 43600: 0.005828\n",
      "2023-12-01 21:40:17,093 INFO     Training average loss at step 43600: 0.005520\n",
      "2023-12-01 21:40:31,447 INFO     Training average positive_sample_loss at step 43700: 0.005335\n",
      "2023-12-01 21:40:31,447 INFO     Training average negative_sample_loss at step 43700: 0.006217\n",
      "2023-12-01 21:40:31,447 INFO     Training average loss at step 43700: 0.005776\n",
      "2023-12-01 21:40:47,763 INFO     Training average positive_sample_loss at step 43800: 0.005189\n",
      "2023-12-01 21:40:47,763 INFO     Training average negative_sample_loss at step 43800: 0.006298\n",
      "2023-12-01 21:40:47,763 INFO     Training average loss at step 43800: 0.005744\n",
      "2023-12-01 21:41:01,455 INFO     Training average positive_sample_loss at step 43900: 0.005154\n",
      "2023-12-01 21:41:01,455 INFO     Training average negative_sample_loss at step 43900: 0.006615\n",
      "2023-12-01 21:41:01,455 INFO     Training average loss at step 43900: 0.005885\n",
      "2023-12-01 21:41:15,325 INFO     Training average positive_sample_loss at step 44000: 0.005211\n",
      "2023-12-01 21:41:15,326 INFO     Training average negative_sample_loss at step 44000: 0.005998\n",
      "2023-12-01 21:41:15,326 INFO     Training average loss at step 44000: 0.005604\n",
      "2023-12-01 21:41:30,217 INFO     Training average positive_sample_loss at step 44100: 0.005214\n",
      "2023-12-01 21:41:30,217 INFO     Training average negative_sample_loss at step 44100: 0.006438\n",
      "2023-12-01 21:41:30,217 INFO     Training average loss at step 44100: 0.005826\n",
      "2023-12-01 21:41:44,996 INFO     Training average positive_sample_loss at step 44200: 0.005311\n",
      "2023-12-01 21:41:44,997 INFO     Training average negative_sample_loss at step 44200: 0.006298\n",
      "2023-12-01 21:41:44,997 INFO     Training average loss at step 44200: 0.005805\n",
      "2023-12-01 21:41:59,593 INFO     Training average positive_sample_loss at step 44300: 0.005231\n",
      "2023-12-01 21:41:59,594 INFO     Training average negative_sample_loss at step 44300: 0.005950\n",
      "2023-12-01 21:41:59,594 INFO     Training average loss at step 44300: 0.005591\n",
      "2023-12-01 21:42:15,340 INFO     Training average positive_sample_loss at step 44400: 0.005164\n",
      "2023-12-01 21:42:15,340 INFO     Training average negative_sample_loss at step 44400: 0.006444\n",
      "2023-12-01 21:42:15,340 INFO     Training average loss at step 44400: 0.005804\n",
      "2023-12-01 21:42:28,883 INFO     Training average positive_sample_loss at step 44500: 0.005176\n",
      "2023-12-01 21:42:28,883 INFO     Training average negative_sample_loss at step 44500: 0.006724\n",
      "2023-12-01 21:42:28,883 INFO     Training average loss at step 44500: 0.005950\n",
      "2023-12-01 21:42:43,245 INFO     Training average positive_sample_loss at step 44600: 0.005208\n",
      "2023-12-01 21:42:43,246 INFO     Training average negative_sample_loss at step 44600: 0.006273\n",
      "2023-12-01 21:42:43,246 INFO     Training average loss at step 44600: 0.005740\n",
      "2023-12-01 21:42:57,051 INFO     Training average positive_sample_loss at step 44700: 0.005321\n",
      "2023-12-01 21:42:57,051 INFO     Training average negative_sample_loss at step 44700: 0.006176\n",
      "2023-12-01 21:42:57,051 INFO     Training average loss at step 44700: 0.005749\n",
      "2023-12-01 21:43:10,645 INFO     Training average positive_sample_loss at step 44800: 0.005262\n",
      "2023-12-01 21:43:10,645 INFO     Training average negative_sample_loss at step 44800: 0.006431\n",
      "2023-12-01 21:43:10,645 INFO     Training average loss at step 44800: 0.005847\n",
      "2023-12-01 21:43:27,175 INFO     Training average positive_sample_loss at step 44900: 0.005199\n",
      "2023-12-01 21:43:27,175 INFO     Training average negative_sample_loss at step 44900: 0.006045\n",
      "2023-12-01 21:43:27,175 INFO     Training average loss at step 44900: 0.005622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:43:41,567 INFO     Training average positive_sample_loss at step 45000: 0.005124\n",
      "2023-12-01 21:43:41,567 INFO     Training average negative_sample_loss at step 45000: 0.006237\n",
      "2023-12-01 21:43:41,567 INFO     Training average loss at step 45000: 0.005680\n",
      "2023-12-01 21:43:55,601 INFO     Training average positive_sample_loss at step 45100: 0.005170\n",
      "2023-12-01 21:43:55,602 INFO     Training average negative_sample_loss at step 45100: 0.006423\n",
      "2023-12-01 21:43:55,602 INFO     Training average loss at step 45100: 0.005796\n",
      "2023-12-01 21:44:09,363 INFO     Training average positive_sample_loss at step 45200: 0.005206\n",
      "2023-12-01 21:44:09,363 INFO     Training average negative_sample_loss at step 45200: 0.006879\n",
      "2023-12-01 21:44:09,363 INFO     Training average loss at step 45200: 0.006042\n",
      "2023-12-01 21:44:22,950 INFO     Training average positive_sample_loss at step 45300: 0.005308\n",
      "2023-12-01 21:44:22,951 INFO     Training average negative_sample_loss at step 45300: 0.006275\n",
      "2023-12-01 21:44:22,951 INFO     Training average loss at step 45300: 0.005791\n",
      "2023-12-01 21:44:38,862 INFO     Training average positive_sample_loss at step 45400: 0.005292\n",
      "2023-12-01 21:44:38,862 INFO     Training average negative_sample_loss at step 45400: 0.006022\n",
      "2023-12-01 21:44:38,862 INFO     Training average loss at step 45400: 0.005657\n",
      "2023-12-01 21:44:56,323 INFO     Training average positive_sample_loss at step 45500: 0.005193\n",
      "2023-12-01 21:44:56,323 INFO     Training average negative_sample_loss at step 45500: 0.006130\n",
      "2023-12-01 21:44:56,323 INFO     Training average loss at step 45500: 0.005661\n",
      "2023-12-01 21:45:10,256 INFO     Training average positive_sample_loss at step 45600: 0.005186\n",
      "2023-12-01 21:45:10,256 INFO     Training average negative_sample_loss at step 45600: 0.006603\n",
      "2023-12-01 21:45:10,257 INFO     Training average loss at step 45600: 0.005895\n",
      "2023-12-01 21:45:24,925 INFO     Training average positive_sample_loss at step 45700: 0.005155\n",
      "2023-12-01 21:45:24,925 INFO     Training average negative_sample_loss at step 45700: 0.005894\n",
      "2023-12-01 21:45:24,925 INFO     Training average loss at step 45700: 0.005524\n",
      "2023-12-01 21:45:38,930 INFO     Training average positive_sample_loss at step 45800: 0.005234\n",
      "2023-12-01 21:45:38,930 INFO     Training average negative_sample_loss at step 45800: 0.006189\n",
      "2023-12-01 21:45:38,930 INFO     Training average loss at step 45800: 0.005711\n",
      "2023-12-01 21:45:53,662 INFO     Training average positive_sample_loss at step 45900: 0.005302\n",
      "2023-12-01 21:45:53,662 INFO     Training average negative_sample_loss at step 45900: 0.006529\n",
      "2023-12-01 21:45:53,662 INFO     Training average loss at step 45900: 0.005915\n",
      "2023-12-01 21:46:09,947 INFO     Training average positive_sample_loss at step 46000: 0.005257\n",
      "2023-12-01 21:46:09,947 INFO     Training average negative_sample_loss at step 46000: 0.005772\n",
      "2023-12-01 21:46:09,947 INFO     Training average loss at step 46000: 0.005514\n",
      "2023-12-01 21:46:24,139 INFO     Training average positive_sample_loss at step 46100: 0.005067\n",
      "2023-12-01 21:46:24,140 INFO     Training average negative_sample_loss at step 46100: 0.006158\n",
      "2023-12-01 21:46:24,140 INFO     Training average loss at step 46100: 0.005612\n",
      "2023-12-01 21:46:38,267 INFO     Training average positive_sample_loss at step 46200: 0.005190\n",
      "2023-12-01 21:46:38,267 INFO     Training average negative_sample_loss at step 46200: 0.005874\n",
      "2023-12-01 21:46:38,267 INFO     Training average loss at step 46200: 0.005532\n",
      "2023-12-01 21:46:52,354 INFO     Training average positive_sample_loss at step 46300: 0.005291\n",
      "2023-12-01 21:46:52,354 INFO     Training average negative_sample_loss at step 46300: 0.006410\n",
      "2023-12-01 21:46:52,354 INFO     Training average loss at step 46300: 0.005851\n",
      "2023-12-01 21:47:06,481 INFO     Training average positive_sample_loss at step 46400: 0.005289\n",
      "2023-12-01 21:47:06,481 INFO     Training average negative_sample_loss at step 46400: 0.006060\n",
      "2023-12-01 21:47:06,481 INFO     Training average loss at step 46400: 0.005674\n",
      "2023-12-01 21:47:20,351 INFO     Training average positive_sample_loss at step 46500: 0.005268\n",
      "2023-12-01 21:47:20,351 INFO     Training average negative_sample_loss at step 46500: 0.006267\n",
      "2023-12-01 21:47:20,351 INFO     Training average loss at step 46500: 0.005768\n",
      "2023-12-01 21:47:36,976 INFO     Training average positive_sample_loss at step 46600: 0.005167\n",
      "2023-12-01 21:47:36,977 INFO     Training average negative_sample_loss at step 46600: 0.006337\n",
      "2023-12-01 21:47:36,977 INFO     Training average loss at step 46600: 0.005752\n",
      "2023-12-01 21:47:50,770 INFO     Training average positive_sample_loss at step 46700: 0.005121\n",
      "2023-12-01 21:47:50,770 INFO     Training average negative_sample_loss at step 46700: 0.005841\n",
      "2023-12-01 21:47:50,770 INFO     Training average loss at step 46700: 0.005481\n",
      "2023-12-01 21:48:04,441 INFO     Training average positive_sample_loss at step 46800: 0.005250\n",
      "2023-12-01 21:48:04,442 INFO     Training average negative_sample_loss at step 46800: 0.006201\n",
      "2023-12-01 21:48:04,442 INFO     Training average loss at step 46800: 0.005725\n",
      "2023-12-01 21:48:18,032 INFO     Training average positive_sample_loss at step 46900: 0.005213\n",
      "2023-12-01 21:48:18,033 INFO     Training average negative_sample_loss at step 46900: 0.006230\n",
      "2023-12-01 21:48:18,033 INFO     Training average loss at step 46900: 0.005721\n",
      "2023-12-01 21:48:31,365 INFO     Training average positive_sample_loss at step 47000: 0.005333\n",
      "2023-12-01 21:48:31,365 INFO     Training average negative_sample_loss at step 47000: 0.006549\n",
      "2023-12-01 21:48:31,365 INFO     Training average loss at step 47000: 0.005941\n",
      "2023-12-01 21:48:47,422 INFO     Training average positive_sample_loss at step 47100: 0.005273\n",
      "2023-12-01 21:48:47,423 INFO     Training average negative_sample_loss at step 47100: 0.006139\n",
      "2023-12-01 21:48:47,423 INFO     Training average loss at step 47100: 0.005706\n",
      "2023-12-01 21:49:01,439 INFO     Training average positive_sample_loss at step 47200: 0.005132\n",
      "2023-12-01 21:49:01,439 INFO     Training average negative_sample_loss at step 47200: 0.005556\n",
      "2023-12-01 21:49:01,439 INFO     Training average loss at step 47200: 0.005344\n",
      "2023-12-01 21:49:15,235 INFO     Training average positive_sample_loss at step 47300: 0.005195\n",
      "2023-12-01 21:49:15,236 INFO     Training average negative_sample_loss at step 47300: 0.006067\n",
      "2023-12-01 21:49:15,236 INFO     Training average loss at step 47300: 0.005631\n",
      "2023-12-01 21:49:29,015 INFO     Training average positive_sample_loss at step 47400: 0.005241\n",
      "2023-12-01 21:49:29,016 INFO     Training average negative_sample_loss at step 47400: 0.005990\n",
      "2023-12-01 21:49:29,016 INFO     Training average loss at step 47400: 0.005616\n",
      "2023-12-01 21:49:43,583 INFO     Training average positive_sample_loss at step 47500: 0.005276\n",
      "2023-12-01 21:49:43,583 INFO     Training average negative_sample_loss at step 47500: 0.006398\n",
      "2023-12-01 21:49:43,583 INFO     Training average loss at step 47500: 0.005837\n",
      "2023-12-01 21:49:57,563 INFO     Training average positive_sample_loss at step 47600: 0.005212\n",
      "2023-12-01 21:49:57,563 INFO     Training average negative_sample_loss at step 47600: 0.006354\n",
      "2023-12-01 21:49:57,563 INFO     Training average loss at step 47600: 0.005783\n",
      "2023-12-01 21:50:13,736 INFO     Training average positive_sample_loss at step 47700: 0.005258\n",
      "2023-12-01 21:50:13,737 INFO     Training average negative_sample_loss at step 47700: 0.006021\n",
      "2023-12-01 21:50:13,737 INFO     Training average loss at step 47700: 0.005639\n",
      "2023-12-01 21:50:27,716 INFO     Training average positive_sample_loss at step 47800: 0.005178\n",
      "2023-12-01 21:50:27,716 INFO     Training average negative_sample_loss at step 47800: 0.006707\n",
      "2023-12-01 21:50:27,716 INFO     Training average loss at step 47800: 0.005942\n",
      "2023-12-01 21:50:42,304 INFO     Training average positive_sample_loss at step 47900: 0.005191\n",
      "2023-12-01 21:50:42,305 INFO     Training average negative_sample_loss at step 47900: 0.006409\n",
      "2023-12-01 21:50:42,305 INFO     Training average loss at step 47900: 0.005800\n",
      "2023-12-01 21:50:55,875 INFO     Training average positive_sample_loss at step 48000: 0.005230\n",
      "2023-12-01 21:50:55,875 INFO     Training average negative_sample_loss at step 48000: 0.006143\n",
      "2023-12-01 21:50:55,875 INFO     Training average loss at step 48000: 0.005686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:51:09,553 INFO     Training average positive_sample_loss at step 48100: 0.005229\n",
      "2023-12-01 21:51:09,554 INFO     Training average negative_sample_loss at step 48100: 0.006436\n",
      "2023-12-01 21:51:09,554 INFO     Training average loss at step 48100: 0.005832\n",
      "2023-12-01 21:51:26,696 INFO     Training average positive_sample_loss at step 48200: 0.005268\n",
      "2023-12-01 21:51:26,697 INFO     Training average negative_sample_loss at step 48200: 0.006301\n",
      "2023-12-01 21:51:26,697 INFO     Training average loss at step 48200: 0.005784\n",
      "2023-12-01 21:51:40,627 INFO     Training average positive_sample_loss at step 48300: 0.005085\n",
      "2023-12-01 21:51:40,627 INFO     Training average negative_sample_loss at step 48300: 0.006204\n",
      "2023-12-01 21:51:40,627 INFO     Training average loss at step 48300: 0.005645\n",
      "2023-12-01 21:51:54,180 INFO     Training average positive_sample_loss at step 48400: 0.005222\n",
      "2023-12-01 21:51:54,181 INFO     Training average negative_sample_loss at step 48400: 0.006016\n",
      "2023-12-01 21:51:54,181 INFO     Training average loss at step 48400: 0.005619\n",
      "2023-12-01 21:52:08,420 INFO     Training average positive_sample_loss at step 48500: 0.005204\n",
      "2023-12-01 21:52:08,421 INFO     Training average negative_sample_loss at step 48500: 0.006398\n",
      "2023-12-01 21:52:08,421 INFO     Training average loss at step 48500: 0.005801\n",
      "2023-12-01 21:52:22,251 INFO     Training average positive_sample_loss at step 48600: 0.005221\n",
      "2023-12-01 21:52:22,251 INFO     Training average negative_sample_loss at step 48600: 0.005501\n",
      "2023-12-01 21:52:22,251 INFO     Training average loss at step 48600: 0.005361\n",
      "2023-12-01 21:52:35,778 INFO     Training average positive_sample_loss at step 48700: 0.005343\n",
      "2023-12-01 21:52:35,779 INFO     Training average negative_sample_loss at step 48700: 0.006375\n",
      "2023-12-01 21:52:35,779 INFO     Training average loss at step 48700: 0.005859\n",
      "2023-12-01 21:52:52,296 INFO     Training average positive_sample_loss at step 48800: 0.005202\n",
      "2023-12-01 21:52:52,296 INFO     Training average negative_sample_loss at step 48800: 0.006728\n",
      "2023-12-01 21:52:52,296 INFO     Training average loss at step 48800: 0.005965\n",
      "2023-12-01 21:53:06,541 INFO     Training average positive_sample_loss at step 48900: 0.005161\n",
      "2023-12-01 21:53:06,541 INFO     Training average negative_sample_loss at step 48900: 0.005975\n",
      "2023-12-01 21:53:06,541 INFO     Training average loss at step 48900: 0.005568\n",
      "2023-12-01 21:53:20,566 INFO     Training average positive_sample_loss at step 49000: 0.005212\n",
      "2023-12-01 21:53:20,566 INFO     Training average negative_sample_loss at step 49000: 0.006288\n",
      "2023-12-01 21:53:20,566 INFO     Training average loss at step 49000: 0.005750\n",
      "2023-12-01 21:53:34,127 INFO     Training average positive_sample_loss at step 49100: 0.005250\n",
      "2023-12-01 21:53:34,127 INFO     Training average negative_sample_loss at step 49100: 0.006181\n",
      "2023-12-01 21:53:34,127 INFO     Training average loss at step 49100: 0.005716\n",
      "2023-12-01 21:53:48,380 INFO     Training average positive_sample_loss at step 49200: 0.005258\n",
      "2023-12-01 21:53:48,380 INFO     Training average negative_sample_loss at step 49200: 0.005965\n",
      "2023-12-01 21:53:48,380 INFO     Training average loss at step 49200: 0.005612\n",
      "2023-12-01 21:54:02,828 INFO     Training average positive_sample_loss at step 49300: 0.005288\n",
      "2023-12-01 21:54:02,829 INFO     Training average negative_sample_loss at step 49300: 0.006101\n",
      "2023-12-01 21:54:02,829 INFO     Training average loss at step 49300: 0.005694\n",
      "2023-12-01 21:54:20,196 INFO     Training average positive_sample_loss at step 49400: 0.005178\n",
      "2023-12-01 21:54:20,197 INFO     Training average negative_sample_loss at step 49400: 0.005963\n",
      "2023-12-01 21:54:20,197 INFO     Training average loss at step 49400: 0.005571\n",
      "2023-12-01 21:54:33,845 INFO     Training average positive_sample_loss at step 49500: 0.005187\n",
      "2023-12-01 21:54:33,845 INFO     Training average negative_sample_loss at step 49500: 0.005936\n",
      "2023-12-01 21:54:33,845 INFO     Training average loss at step 49500: 0.005561\n",
      "2023-12-01 21:54:47,415 INFO     Training average positive_sample_loss at step 49600: 0.005151\n",
      "2023-12-01 21:54:47,415 INFO     Training average negative_sample_loss at step 49600: 0.005984\n",
      "2023-12-01 21:54:47,415 INFO     Training average loss at step 49600: 0.005568\n",
      "2023-12-01 21:55:02,113 INFO     Training average positive_sample_loss at step 49700: 0.005248\n",
      "2023-12-01 21:55:02,114 INFO     Training average negative_sample_loss at step 49700: 0.005953\n",
      "2023-12-01 21:55:02,114 INFO     Training average loss at step 49700: 0.005601\n",
      "2023-12-01 21:55:16,438 INFO     Training average positive_sample_loss at step 49800: 0.005272\n",
      "2023-12-01 21:55:16,438 INFO     Training average negative_sample_loss at step 49800: 0.006005\n",
      "2023-12-01 21:55:16,438 INFO     Training average loss at step 49800: 0.005639\n",
      "2023-12-01 21:55:32,548 INFO     Training average positive_sample_loss at step 49900: 0.005260\n",
      "2023-12-01 21:55:32,548 INFO     Training average negative_sample_loss at step 49900: 0.005508\n",
      "2023-12-01 21:55:32,548 INFO     Training average loss at step 49900: 0.005384\n",
      "2023-12-01 21:55:54,036 INFO     Training average positive_sample_loss at step 50000: 0.005140\n",
      "2023-12-01 21:55:54,036 INFO     Training average negative_sample_loss at step 50000: 0.006610\n",
      "2023-12-01 21:55:54,036 INFO     Training average loss at step 50000: 0.005875\n",
      "2023-12-01 21:55:54,036 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 21:55:54,580 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 21:56:32,739 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 21:56:41,538 INFO     Valid MRR at step 50000: 0.949153\n",
      "2023-12-01 21:56:41,539 INFO     Valid MR at step 50000: 292.897200\n",
      "2023-12-01 21:56:41,539 INFO     Valid HITS@1 at step 50000: 0.944000\n",
      "2023-12-01 21:56:41,539 INFO     Valid HITS@3 at step 50000: 0.952000\n",
      "2023-12-01 21:56:41,539 INFO     Valid HITS@10 at step 50000: 0.958400\n",
      "2023-12-01 21:56:53,658 INFO     Training average positive_sample_loss at step 50100: 0.005193\n",
      "2023-12-01 21:56:53,658 INFO     Training average negative_sample_loss at step 50100: 0.006233\n",
      "2023-12-01 21:56:53,658 INFO     Training average loss at step 50100: 0.005713\n",
      "2023-12-01 21:57:08,018 INFO     Training average positive_sample_loss at step 50200: 0.005231\n",
      "2023-12-01 21:57:08,018 INFO     Training average negative_sample_loss at step 50200: 0.006408\n",
      "2023-12-01 21:57:08,018 INFO     Training average loss at step 50200: 0.005819\n",
      "2023-12-01 21:57:22,107 INFO     Training average positive_sample_loss at step 50300: 0.005289\n",
      "2023-12-01 21:57:22,107 INFO     Training average negative_sample_loss at step 50300: 0.005821\n",
      "2023-12-01 21:57:22,107 INFO     Training average loss at step 50300: 0.005555\n",
      "2023-12-01 21:57:36,159 INFO     Training average positive_sample_loss at step 50400: 0.005288\n",
      "2023-12-01 21:57:36,160 INFO     Training average negative_sample_loss at step 50400: 0.006254\n",
      "2023-12-01 21:57:36,160 INFO     Training average loss at step 50400: 0.005771\n",
      "2023-12-01 21:57:52,660 INFO     Training average positive_sample_loss at step 50500: 0.005174\n",
      "2023-12-01 21:57:52,660 INFO     Training average negative_sample_loss at step 50500: 0.006562\n",
      "2023-12-01 21:57:52,660 INFO     Training average loss at step 50500: 0.005868\n",
      "2023-12-01 21:58:06,363 INFO     Training average positive_sample_loss at step 50600: 0.005150\n",
      "2023-12-01 21:58:06,364 INFO     Training average negative_sample_loss at step 50600: 0.005758\n",
      "2023-12-01 21:58:06,364 INFO     Training average loss at step 50600: 0.005454\n",
      "2023-12-01 21:58:19,944 INFO     Training average positive_sample_loss at step 50700: 0.005267\n",
      "2023-12-01 21:58:19,944 INFO     Training average negative_sample_loss at step 50700: 0.006769\n",
      "2023-12-01 21:58:19,944 INFO     Training average loss at step 50700: 0.006018\n",
      "2023-12-01 21:58:34,842 INFO     Training average positive_sample_loss at step 50800: 0.005215\n",
      "2023-12-01 21:58:34,842 INFO     Training average negative_sample_loss at step 50800: 0.005799\n",
      "2023-12-01 21:58:34,842 INFO     Training average loss at step 50800: 0.005507\n",
      "2023-12-01 21:58:49,199 INFO     Training average positive_sample_loss at step 50900: 0.005286\n",
      "2023-12-01 21:58:49,199 INFO     Training average negative_sample_loss at step 50900: 0.006540\n",
      "2023-12-01 21:58:49,199 INFO     Training average loss at step 50900: 0.005913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:59:06,529 INFO     Training average positive_sample_loss at step 51000: 0.005293\n",
      "2023-12-01 21:59:06,530 INFO     Training average negative_sample_loss at step 51000: 0.006094\n",
      "2023-12-01 21:59:06,530 INFO     Training average loss at step 51000: 0.005693\n",
      "2023-12-01 21:59:20,477 INFO     Training average positive_sample_loss at step 51100: 0.005116\n",
      "2023-12-01 21:59:20,477 INFO     Training average negative_sample_loss at step 51100: 0.005958\n",
      "2023-12-01 21:59:20,477 INFO     Training average loss at step 51100: 0.005537\n",
      "2023-12-01 21:59:34,091 INFO     Training average positive_sample_loss at step 51200: 0.005259\n",
      "2023-12-01 21:59:34,092 INFO     Training average negative_sample_loss at step 51200: 0.005942\n",
      "2023-12-01 21:59:34,092 INFO     Training average loss at step 51200: 0.005600\n",
      "2023-12-01 21:59:48,424 INFO     Training average positive_sample_loss at step 51300: 0.005259\n",
      "2023-12-01 21:59:48,425 INFO     Training average negative_sample_loss at step 51300: 0.006161\n",
      "2023-12-01 21:59:48,425 INFO     Training average loss at step 51300: 0.005710\n",
      "2023-12-01 22:00:02,744 INFO     Training average positive_sample_loss at step 51400: 0.005233\n",
      "2023-12-01 22:00:02,744 INFO     Training average negative_sample_loss at step 51400: 0.006416\n",
      "2023-12-01 22:00:02,744 INFO     Training average loss at step 51400: 0.005825\n",
      "2023-12-01 22:00:17,236 INFO     Training average positive_sample_loss at step 51500: 0.005307\n",
      "2023-12-01 22:00:17,236 INFO     Training average negative_sample_loss at step 51500: 0.005791\n",
      "2023-12-01 22:00:17,236 INFO     Training average loss at step 51500: 0.005549\n",
      "2023-12-01 22:00:33,637 INFO     Training average positive_sample_loss at step 51600: 0.005194\n",
      "2023-12-01 22:00:33,638 INFO     Training average negative_sample_loss at step 51600: 0.005926\n",
      "2023-12-01 22:00:33,638 INFO     Training average loss at step 51600: 0.005560\n",
      "2023-12-01 22:00:47,737 INFO     Training average positive_sample_loss at step 51700: 0.005188\n",
      "2023-12-01 22:00:47,738 INFO     Training average negative_sample_loss at step 51700: 0.006000\n",
      "2023-12-01 22:00:47,738 INFO     Training average loss at step 51700: 0.005594\n",
      "2023-12-01 22:01:02,113 INFO     Training average positive_sample_loss at step 51800: 0.005237\n",
      "2023-12-01 22:01:02,113 INFO     Training average negative_sample_loss at step 51800: 0.005531\n",
      "2023-12-01 22:01:02,114 INFO     Training average loss at step 51800: 0.005384\n",
      "2023-12-01 22:01:16,236 INFO     Training average positive_sample_loss at step 51900: 0.005213\n",
      "2023-12-01 22:01:16,236 INFO     Training average negative_sample_loss at step 51900: 0.005747\n",
      "2023-12-01 22:01:16,236 INFO     Training average loss at step 51900: 0.005480\n",
      "2023-12-01 22:01:30,029 INFO     Training average positive_sample_loss at step 52000: 0.005255\n",
      "2023-12-01 22:01:30,029 INFO     Training average negative_sample_loss at step 52000: 0.005871\n",
      "2023-12-01 22:01:30,029 INFO     Training average loss at step 52000: 0.005563\n",
      "2023-12-01 22:01:46,861 INFO     Training average positive_sample_loss at step 52100: 0.005235\n",
      "2023-12-01 22:01:46,862 INFO     Training average negative_sample_loss at step 52100: 0.006017\n",
      "2023-12-01 22:01:46,862 INFO     Training average loss at step 52100: 0.005626\n",
      "2023-12-01 22:02:01,000 INFO     Training average positive_sample_loss at step 52200: 0.005100\n",
      "2023-12-01 22:02:01,001 INFO     Training average negative_sample_loss at step 52200: 0.006259\n",
      "2023-12-01 22:02:01,001 INFO     Training average loss at step 52200: 0.005679\n",
      "2023-12-01 22:02:14,977 INFO     Training average positive_sample_loss at step 52300: 0.005240\n",
      "2023-12-01 22:02:14,978 INFO     Training average negative_sample_loss at step 52300: 0.006071\n",
      "2023-12-01 22:02:14,978 INFO     Training average loss at step 52300: 0.005656\n",
      "2023-12-01 22:02:28,730 INFO     Training average positive_sample_loss at step 52400: 0.005273\n",
      "2023-12-01 22:02:28,730 INFO     Training average negative_sample_loss at step 52400: 0.005906\n",
      "2023-12-01 22:02:28,730 INFO     Training average loss at step 52400: 0.005590\n",
      "2023-12-01 22:02:42,631 INFO     Training average positive_sample_loss at step 52500: 0.005251\n",
      "2023-12-01 22:02:42,631 INFO     Training average negative_sample_loss at step 52500: 0.005990\n",
      "2023-12-01 22:02:42,631 INFO     Training average loss at step 52500: 0.005620\n",
      "2023-12-01 22:02:55,843 INFO     Training average positive_sample_loss at step 52600: 0.005265\n",
      "2023-12-01 22:02:55,843 INFO     Training average negative_sample_loss at step 52600: 0.006300\n",
      "2023-12-01 22:02:55,843 INFO     Training average loss at step 52600: 0.005783\n",
      "2023-12-01 22:03:12,271 INFO     Training average positive_sample_loss at step 52700: 0.005156\n",
      "2023-12-01 22:03:12,271 INFO     Training average negative_sample_loss at step 52700: 0.006027\n",
      "2023-12-01 22:03:12,271 INFO     Training average loss at step 52700: 0.005591\n",
      "2023-12-01 22:03:27,151 INFO     Training average positive_sample_loss at step 52800: 0.005165\n",
      "2023-12-01 22:03:27,151 INFO     Training average negative_sample_loss at step 52800: 0.006098\n",
      "2023-12-01 22:03:27,151 INFO     Training average loss at step 52800: 0.005632\n",
      "2023-12-01 22:03:40,810 INFO     Training average positive_sample_loss at step 52900: 0.005251\n",
      "2023-12-01 22:03:40,810 INFO     Training average negative_sample_loss at step 52900: 0.005425\n",
      "2023-12-01 22:03:40,810 INFO     Training average loss at step 52900: 0.005338\n",
      "2023-12-01 22:03:54,418 INFO     Training average positive_sample_loss at step 53000: 0.005240\n",
      "2023-12-01 22:03:54,418 INFO     Training average negative_sample_loss at step 53000: 0.006087\n",
      "2023-12-01 22:03:54,418 INFO     Training average loss at step 53000: 0.005663\n",
      "2023-12-01 22:04:08,064 INFO     Training average positive_sample_loss at step 53100: 0.005287\n",
      "2023-12-01 22:04:08,064 INFO     Training average negative_sample_loss at step 53100: 0.006279\n",
      "2023-12-01 22:04:08,065 INFO     Training average loss at step 53100: 0.005783\n",
      "2023-12-01 22:04:23,936 INFO     Training average positive_sample_loss at step 53200: 0.005253\n",
      "2023-12-01 22:04:23,936 INFO     Training average negative_sample_loss at step 53200: 0.005894\n",
      "2023-12-01 22:04:23,936 INFO     Training average loss at step 53200: 0.005574\n",
      "2023-12-01 22:04:37,788 INFO     Training average positive_sample_loss at step 53300: 0.005161\n",
      "2023-12-01 22:04:37,789 INFO     Training average negative_sample_loss at step 53300: 0.006126\n",
      "2023-12-01 22:04:37,789 INFO     Training average loss at step 53300: 0.005643\n",
      "2023-12-01 22:04:51,547 INFO     Training average positive_sample_loss at step 53400: 0.005162\n",
      "2023-12-01 22:04:51,547 INFO     Training average negative_sample_loss at step 53400: 0.005559\n",
      "2023-12-01 22:04:51,547 INFO     Training average loss at step 53400: 0.005361\n",
      "2023-12-01 22:05:04,919 INFO     Training average positive_sample_loss at step 53500: 0.005235\n",
      "2023-12-01 22:05:04,920 INFO     Training average negative_sample_loss at step 53500: 0.005763\n",
      "2023-12-01 22:05:04,920 INFO     Training average loss at step 53500: 0.005499\n",
      "2023-12-01 22:05:19,094 INFO     Training average positive_sample_loss at step 53600: 0.005223\n",
      "2023-12-01 22:05:19,094 INFO     Training average negative_sample_loss at step 53600: 0.005622\n",
      "2023-12-01 22:05:19,094 INFO     Training average loss at step 53600: 0.005422\n",
      "2023-12-01 22:05:33,342 INFO     Training average positive_sample_loss at step 53700: 0.005300\n",
      "2023-12-01 22:05:33,342 INFO     Training average negative_sample_loss at step 53700: 0.005707\n",
      "2023-12-01 22:05:33,342 INFO     Training average loss at step 53700: 0.005504\n",
      "2023-12-01 22:05:49,327 INFO     Training average positive_sample_loss at step 53800: 0.005181\n",
      "2023-12-01 22:05:49,327 INFO     Training average negative_sample_loss at step 53800: 0.006163\n",
      "2023-12-01 22:05:49,327 INFO     Training average loss at step 53800: 0.005672\n",
      "2023-12-01 22:06:03,003 INFO     Training average positive_sample_loss at step 53900: 0.005136\n",
      "2023-12-01 22:06:03,003 INFO     Training average negative_sample_loss at step 53900: 0.005594\n",
      "2023-12-01 22:06:03,003 INFO     Training average loss at step 53900: 0.005365\n",
      "2023-12-01 22:06:16,947 INFO     Training average positive_sample_loss at step 54000: 0.005197\n",
      "2023-12-01 22:06:16,947 INFO     Training average negative_sample_loss at step 54000: 0.005705\n",
      "2023-12-01 22:06:16,947 INFO     Training average loss at step 54000: 0.005451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 22:06:30,835 INFO     Training average positive_sample_loss at step 54100: 0.005195\n",
      "2023-12-01 22:06:30,835 INFO     Training average negative_sample_loss at step 54100: 0.005846\n",
      "2023-12-01 22:06:30,835 INFO     Training average loss at step 54100: 0.005520\n",
      "2023-12-01 22:06:45,132 INFO     Training average positive_sample_loss at step 54200: 0.005340\n",
      "2023-12-01 22:06:45,132 INFO     Training average negative_sample_loss at step 54200: 0.006029\n",
      "2023-12-01 22:06:45,132 INFO     Training average loss at step 54200: 0.005684\n",
      "2023-12-01 22:07:01,985 INFO     Training average positive_sample_loss at step 54300: 0.005336\n",
      "2023-12-01 22:07:01,985 INFO     Training average negative_sample_loss at step 54300: 0.005983\n",
      "2023-12-01 22:07:01,985 INFO     Training average loss at step 54300: 0.005660\n",
      "2023-12-01 22:07:15,681 INFO     Training average positive_sample_loss at step 54400: 0.005148\n",
      "2023-12-01 22:07:15,682 INFO     Training average negative_sample_loss at step 54400: 0.006766\n",
      "2023-12-01 22:07:15,682 INFO     Training average loss at step 54400: 0.005957\n",
      "2023-12-01 22:07:30,689 INFO     Training average positive_sample_loss at step 54500: 0.005147\n",
      "2023-12-01 22:07:30,690 INFO     Training average negative_sample_loss at step 54500: 0.005892\n",
      "2023-12-01 22:07:30,690 INFO     Training average loss at step 54500: 0.005520\n",
      "2023-12-01 22:07:44,345 INFO     Training average positive_sample_loss at step 54600: 0.005257\n",
      "2023-12-01 22:07:44,345 INFO     Training average negative_sample_loss at step 54600: 0.006117\n",
      "2023-12-01 22:07:44,345 INFO     Training average loss at step 54600: 0.005687\n",
      "2023-12-01 22:07:59,067 INFO     Training average positive_sample_loss at step 54700: 0.005250\n",
      "2023-12-01 22:07:59,067 INFO     Training average negative_sample_loss at step 54700: 0.006313\n",
      "2023-12-01 22:07:59,067 INFO     Training average loss at step 54700: 0.005782\n",
      "2023-12-01 22:08:13,340 INFO     Training average positive_sample_loss at step 54800: 0.005301\n",
      "2023-12-01 22:08:13,340 INFO     Training average negative_sample_loss at step 54800: 0.006025\n",
      "2023-12-01 22:08:13,340 INFO     Training average loss at step 54800: 0.005663\n",
      "2023-12-01 22:08:29,556 INFO     Training average positive_sample_loss at step 54900: 0.005189\n",
      "2023-12-01 22:08:29,556 INFO     Training average negative_sample_loss at step 54900: 0.005390\n",
      "2023-12-01 22:08:29,556 INFO     Training average loss at step 54900: 0.005290\n",
      "2023-12-01 22:08:43,105 INFO     Training average positive_sample_loss at step 55000: 0.005200\n",
      "2023-12-01 22:08:43,106 INFO     Training average negative_sample_loss at step 55000: 0.006256\n",
      "2023-12-01 22:08:43,106 INFO     Training average loss at step 55000: 0.005728\n",
      "2023-12-01 22:08:56,846 INFO     Training average positive_sample_loss at step 55100: 0.005203\n",
      "2023-12-01 22:08:56,846 INFO     Training average negative_sample_loss at step 55100: 0.006164\n",
      "2023-12-01 22:08:56,846 INFO     Training average loss at step 55100: 0.005684\n",
      "2023-12-01 22:09:10,734 INFO     Training average positive_sample_loss at step 55200: 0.005227\n",
      "2023-12-01 22:09:10,734 INFO     Training average negative_sample_loss at step 55200: 0.006054\n",
      "2023-12-01 22:09:10,734 INFO     Training average loss at step 55200: 0.005640\n",
      "2023-12-01 22:09:24,768 INFO     Training average positive_sample_loss at step 55300: 0.005264\n",
      "2023-12-01 22:09:24,769 INFO     Training average negative_sample_loss at step 55300: 0.006487\n",
      "2023-12-01 22:09:24,769 INFO     Training average loss at step 55300: 0.005875\n",
      "2023-12-01 22:09:40,572 INFO     Training average positive_sample_loss at step 55400: 0.005275\n",
      "2023-12-01 22:09:40,573 INFO     Training average negative_sample_loss at step 55400: 0.006210\n",
      "2023-12-01 22:09:40,573 INFO     Training average loss at step 55400: 0.005743\n",
      "2023-12-01 22:09:55,161 INFO     Training average positive_sample_loss at step 55500: 0.005178\n",
      "2023-12-01 22:09:55,161 INFO     Training average negative_sample_loss at step 55500: 0.005961\n",
      "2023-12-01 22:09:55,162 INFO     Training average loss at step 55500: 0.005569\n",
      "2023-12-01 22:10:09,550 INFO     Training average positive_sample_loss at step 55600: 0.005203\n",
      "2023-12-01 22:10:09,550 INFO     Training average negative_sample_loss at step 55600: 0.006054\n",
      "2023-12-01 22:10:09,551 INFO     Training average loss at step 55600: 0.005629\n",
      "2023-12-01 22:10:24,297 INFO     Training average positive_sample_loss at step 55700: 0.005164\n",
      "2023-12-01 22:10:24,297 INFO     Training average negative_sample_loss at step 55700: 0.005700\n",
      "2023-12-01 22:10:24,297 INFO     Training average loss at step 55700: 0.005432\n",
      "2023-12-01 22:10:37,558 INFO     Training average positive_sample_loss at step 55800: 0.005221\n",
      "2023-12-01 22:10:37,558 INFO     Training average negative_sample_loss at step 55800: 0.005681\n",
      "2023-12-01 22:10:37,558 INFO     Training average loss at step 55800: 0.005451\n",
      "2023-12-01 22:10:52,152 INFO     Training average positive_sample_loss at step 55900: 0.005300\n",
      "2023-12-01 22:10:52,152 INFO     Training average negative_sample_loss at step 55900: 0.005662\n",
      "2023-12-01 22:10:52,153 INFO     Training average loss at step 55900: 0.005481\n",
      "2023-12-01 22:11:08,258 INFO     Training average positive_sample_loss at step 56000: 0.005180\n",
      "2023-12-01 22:11:08,258 INFO     Training average negative_sample_loss at step 56000: 0.006199\n",
      "2023-12-01 22:11:08,258 INFO     Training average loss at step 56000: 0.005689\n",
      "2023-12-01 22:11:22,125 INFO     Training average positive_sample_loss at step 56100: 0.005187\n",
      "2023-12-01 22:11:22,126 INFO     Training average negative_sample_loss at step 56100: 0.006060\n",
      "2023-12-01 22:11:22,126 INFO     Training average loss at step 56100: 0.005624\n",
      "2023-12-01 22:11:35,906 INFO     Training average positive_sample_loss at step 56200: 0.005230\n",
      "2023-12-01 22:11:35,906 INFO     Training average negative_sample_loss at step 56200: 0.005972\n",
      "2023-12-01 22:11:35,907 INFO     Training average loss at step 56200: 0.005601\n",
      "2023-12-01 22:11:49,473 INFO     Training average positive_sample_loss at step 56300: 0.005209\n",
      "2023-12-01 22:11:49,473 INFO     Training average negative_sample_loss at step 56300: 0.006352\n",
      "2023-12-01 22:11:49,474 INFO     Training average loss at step 56300: 0.005780\n",
      "2023-12-01 22:12:03,404 INFO     Training average positive_sample_loss at step 56400: 0.005234\n",
      "2023-12-01 22:12:03,404 INFO     Training average negative_sample_loss at step 56400: 0.005798\n",
      "2023-12-01 22:12:03,404 INFO     Training average loss at step 56400: 0.005516\n",
      "2023-12-01 22:12:16,965 INFO     Training average positive_sample_loss at step 56500: 0.005274\n",
      "2023-12-01 22:12:16,965 INFO     Training average negative_sample_loss at step 56500: 0.006226\n",
      "2023-12-01 22:12:16,965 INFO     Training average loss at step 56500: 0.005750\n",
      "2023-12-01 22:12:33,916 INFO     Training average positive_sample_loss at step 56600: 0.005098\n",
      "2023-12-01 22:12:33,917 INFO     Training average negative_sample_loss at step 56600: 0.006108\n",
      "2023-12-01 22:12:33,917 INFO     Training average loss at step 56600: 0.005603\n",
      "2023-12-01 22:12:47,633 INFO     Training average positive_sample_loss at step 56700: 0.005147\n",
      "2023-12-01 22:12:47,633 INFO     Training average negative_sample_loss at step 56700: 0.006354\n",
      "2023-12-01 22:12:47,633 INFO     Training average loss at step 56700: 0.005750\n",
      "2023-12-01 22:13:01,366 INFO     Training average positive_sample_loss at step 56800: 0.005179\n",
      "2023-12-01 22:13:01,366 INFO     Training average negative_sample_loss at step 56800: 0.006015\n",
      "2023-12-01 22:13:01,367 INFO     Training average loss at step 56800: 0.005597\n",
      "2023-12-01 22:13:15,302 INFO     Training average positive_sample_loss at step 56900: 0.005326\n",
      "2023-12-01 22:13:15,302 INFO     Training average negative_sample_loss at step 56900: 0.006228\n",
      "2023-12-01 22:13:15,302 INFO     Training average loss at step 56900: 0.005777\n",
      "2023-12-01 22:13:29,300 INFO     Training average positive_sample_loss at step 57000: 0.005321\n",
      "2023-12-01 22:13:29,300 INFO     Training average negative_sample_loss at step 57000: 0.006473\n",
      "2023-12-01 22:13:29,300 INFO     Training average loss at step 57000: 0.005897\n",
      "2023-12-01 22:13:45,822 INFO     Training average positive_sample_loss at step 57100: 0.005271\n",
      "2023-12-01 22:13:45,822 INFO     Training average negative_sample_loss at step 57100: 0.005446\n",
      "2023-12-01 22:13:45,822 INFO     Training average loss at step 57100: 0.005359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 22:14:00,073 INFO     Training average positive_sample_loss at step 57200: 0.005129\n",
      "2023-12-01 22:14:00,073 INFO     Training average negative_sample_loss at step 57200: 0.005596\n",
      "2023-12-01 22:14:00,073 INFO     Training average loss at step 57200: 0.005363\n",
      "2023-12-01 22:14:14,147 INFO     Training average positive_sample_loss at step 57300: 0.005201\n",
      "2023-12-01 22:14:14,147 INFO     Training average negative_sample_loss at step 57300: 0.006044\n",
      "2023-12-01 22:14:14,147 INFO     Training average loss at step 57300: 0.005623\n",
      "2023-12-01 22:14:27,751 INFO     Training average positive_sample_loss at step 57400: 0.005215\n",
      "2023-12-01 22:14:27,751 INFO     Training average negative_sample_loss at step 57400: 0.005743\n",
      "2023-12-01 22:14:27,751 INFO     Training average loss at step 57400: 0.005479\n",
      "2023-12-01 22:14:41,493 INFO     Training average positive_sample_loss at step 57500: 0.005226\n",
      "2023-12-01 22:14:41,493 INFO     Training average negative_sample_loss at step 57500: 0.005965\n",
      "2023-12-01 22:14:41,493 INFO     Training average loss at step 57500: 0.005596\n",
      "2023-12-01 22:14:55,722 INFO     Training average positive_sample_loss at step 57600: 0.005299\n",
      "2023-12-01 22:14:55,723 INFO     Training average negative_sample_loss at step 57600: 0.005858\n",
      "2023-12-01 22:14:55,723 INFO     Training average loss at step 57600: 0.005578\n",
      "2023-12-01 22:15:13,164 INFO     Training average positive_sample_loss at step 57700: 0.005145\n",
      "2023-12-01 22:15:13,165 INFO     Training average negative_sample_loss at step 57700: 0.006187\n",
      "2023-12-01 22:15:13,165 INFO     Training average loss at step 57700: 0.005666\n",
      "2023-12-01 22:15:27,760 INFO     Training average positive_sample_loss at step 57800: 0.005160\n",
      "2023-12-01 22:15:27,760 INFO     Training average negative_sample_loss at step 57800: 0.005863\n",
      "2023-12-01 22:15:27,760 INFO     Training average loss at step 57800: 0.005512\n",
      "2023-12-01 22:15:41,820 INFO     Training average positive_sample_loss at step 57900: 0.005205\n",
      "2023-12-01 22:15:41,820 INFO     Training average negative_sample_loss at step 57900: 0.006301\n",
      "2023-12-01 22:15:41,820 INFO     Training average loss at step 57900: 0.005753\n",
      "2023-12-01 22:15:56,709 INFO     Training average positive_sample_loss at step 58000: 0.005276\n",
      "2023-12-01 22:15:56,709 INFO     Training average negative_sample_loss at step 58000: 0.007001\n",
      "2023-12-01 22:15:56,709 INFO     Training average loss at step 58000: 0.006139\n",
      "2023-12-01 22:16:10,278 INFO     Training average positive_sample_loss at step 58100: 0.005306\n",
      "2023-12-01 22:16:10,279 INFO     Training average negative_sample_loss at step 58100: 0.006035\n",
      "2023-12-01 22:16:10,279 INFO     Training average loss at step 58100: 0.005670\n",
      "2023-12-01 22:16:26,672 INFO     Training average positive_sample_loss at step 58200: 0.005214\n",
      "2023-12-01 22:16:26,673 INFO     Training average negative_sample_loss at step 58200: 0.006355\n",
      "2023-12-01 22:16:26,673 INFO     Training average loss at step 58200: 0.005785\n",
      "2023-12-01 22:16:40,351 INFO     Training average positive_sample_loss at step 58300: 0.005142\n",
      "2023-12-01 22:16:40,351 INFO     Training average negative_sample_loss at step 58300: 0.005766\n",
      "2023-12-01 22:16:40,351 INFO     Training average loss at step 58300: 0.005454\n",
      "2023-12-01 22:16:54,572 INFO     Training average positive_sample_loss at step 58400: 0.005222\n",
      "2023-12-01 22:16:54,573 INFO     Training average negative_sample_loss at step 58400: 0.006227\n",
      "2023-12-01 22:16:54,573 INFO     Training average loss at step 58400: 0.005724\n",
      "2023-12-01 22:17:08,571 INFO     Training average positive_sample_loss at step 58500: 0.005251\n",
      "2023-12-01 22:17:08,571 INFO     Training average negative_sample_loss at step 58500: 0.006499\n",
      "2023-12-01 22:17:08,571 INFO     Training average loss at step 58500: 0.005875\n",
      "2023-12-01 22:17:22,380 INFO     Training average positive_sample_loss at step 58600: 0.005216\n",
      "2023-12-01 22:17:22,381 INFO     Training average negative_sample_loss at step 58600: 0.005646\n",
      "2023-12-01 22:17:22,381 INFO     Training average loss at step 58600: 0.005431\n",
      "2023-12-01 22:17:37,205 INFO     Training average positive_sample_loss at step 58700: 0.005273\n",
      "2023-12-01 22:17:37,206 INFO     Training average negative_sample_loss at step 58700: 0.005606\n",
      "2023-12-01 22:17:37,206 INFO     Training average loss at step 58700: 0.005439\n",
      "2023-12-01 22:17:54,315 INFO     Training average positive_sample_loss at step 58800: 0.005181\n",
      "2023-12-01 22:17:54,315 INFO     Training average negative_sample_loss at step 58800: 0.005742\n",
      "2023-12-01 22:17:54,315 INFO     Training average loss at step 58800: 0.005462\n",
      "2023-12-01 22:18:08,330 INFO     Training average positive_sample_loss at step 58900: 0.005203\n",
      "2023-12-01 22:18:08,330 INFO     Training average negative_sample_loss at step 58900: 0.005939\n",
      "2023-12-01 22:18:08,330 INFO     Training average loss at step 58900: 0.005571\n",
      "2023-12-01 22:18:21,979 INFO     Training average positive_sample_loss at step 59000: 0.005241\n",
      "2023-12-01 22:18:21,979 INFO     Training average negative_sample_loss at step 59000: 0.006071\n",
      "2023-12-01 22:18:21,979 INFO     Training average loss at step 59000: 0.005656\n",
      "2023-12-01 22:18:35,454 INFO     Training average positive_sample_loss at step 59100: 0.005222\n",
      "2023-12-01 22:18:35,455 INFO     Training average negative_sample_loss at step 59100: 0.006151\n",
      "2023-12-01 22:18:35,455 INFO     Training average loss at step 59100: 0.005686\n",
      "2023-12-01 22:18:49,591 INFO     Training average positive_sample_loss at step 59200: 0.005246\n",
      "2023-12-01 22:18:49,591 INFO     Training average negative_sample_loss at step 59200: 0.005829\n",
      "2023-12-01 22:18:49,591 INFO     Training average loss at step 59200: 0.005537\n",
      "2023-12-01 22:19:05,846 INFO     Training average positive_sample_loss at step 59300: 0.005204\n",
      "2023-12-01 22:19:05,846 INFO     Training average negative_sample_loss at step 59300: 0.006086\n",
      "2023-12-01 22:19:05,847 INFO     Training average loss at step 59300: 0.005645\n",
      "2023-12-01 22:19:19,712 INFO     Training average positive_sample_loss at step 59400: 0.005163\n",
      "2023-12-01 22:19:19,712 INFO     Training average negative_sample_loss at step 59400: 0.005879\n",
      "2023-12-01 22:19:19,712 INFO     Training average loss at step 59400: 0.005521\n",
      "2023-12-01 22:19:33,660 INFO     Training average positive_sample_loss at step 59500: 0.005184\n",
      "2023-12-01 22:19:33,660 INFO     Training average negative_sample_loss at step 59500: 0.005910\n",
      "2023-12-01 22:19:33,661 INFO     Training average loss at step 59500: 0.005547\n",
      "2023-12-01 22:19:48,380 INFO     Training average positive_sample_loss at step 59600: 0.005189\n",
      "2023-12-01 22:19:48,380 INFO     Training average negative_sample_loss at step 59600: 0.006347\n",
      "2023-12-01 22:19:48,380 INFO     Training average loss at step 59600: 0.005768\n",
      "2023-12-01 22:20:02,150 INFO     Training average positive_sample_loss at step 59700: 0.005298\n",
      "2023-12-01 22:20:02,151 INFO     Training average negative_sample_loss at step 59700: 0.006135\n",
      "2023-12-01 22:20:02,151 INFO     Training average loss at step 59700: 0.005716\n",
      "2023-12-01 22:20:16,933 INFO     Training average positive_sample_loss at step 59800: 0.005268\n",
      "2023-12-01 22:20:16,934 INFO     Training average negative_sample_loss at step 59800: 0.006777\n",
      "2023-12-01 22:20:16,934 INFO     Training average loss at step 59800: 0.006022\n",
      "2023-12-01 22:20:33,722 INFO     Training average positive_sample_loss at step 59900: 0.005194\n",
      "2023-12-01 22:20:33,723 INFO     Training average negative_sample_loss at step 59900: 0.005709\n",
      "2023-12-01 22:20:33,723 INFO     Training average loss at step 59900: 0.005452\n",
      "2023-12-01 22:20:56,627 INFO     Training average positive_sample_loss at step 60000: 0.005143\n",
      "2023-12-01 22:20:56,627 INFO     Training average negative_sample_loss at step 60000: 0.006663\n",
      "2023-12-01 22:20:56,627 INFO     Training average loss at step 60000: 0.005903\n",
      "2023-12-01 22:20:56,627 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 22:20:57,201 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 22:21:33,339 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 22:21:41,465 INFO     Valid MRR at step 60000: 0.949321\n",
      "2023-12-01 22:21:41,466 INFO     Valid MR at step 60000: 294.167700\n",
      "2023-12-01 22:21:41,466 INFO     Valid HITS@1 at step 60000: 0.944200\n",
      "2023-12-01 22:21:41,466 INFO     Valid HITS@3 at step 60000: 0.952200\n",
      "2023-12-01 22:21:41,466 INFO     Valid HITS@10 at step 60000: 0.958500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 22:21:53,750 INFO     Training average positive_sample_loss at step 60100: 0.005208\n",
      "2023-12-01 22:21:53,750 INFO     Training average negative_sample_loss at step 60100: 0.006093\n",
      "2023-12-01 22:21:53,750 INFO     Training average loss at step 60100: 0.005650\n",
      "2023-12-01 22:22:08,088 INFO     Training average positive_sample_loss at step 60200: 0.005284\n",
      "2023-12-01 22:22:08,089 INFO     Training average negative_sample_loss at step 60200: 0.006323\n",
      "2023-12-01 22:22:08,089 INFO     Training average loss at step 60200: 0.005803\n",
      "2023-12-01 22:22:21,844 INFO     Training average positive_sample_loss at step 60300: 0.005275\n",
      "2023-12-01 22:22:21,845 INFO     Training average negative_sample_loss at step 60300: 0.006026\n",
      "2023-12-01 22:22:21,845 INFO     Training average loss at step 60300: 0.005651\n",
      "2023-12-01 22:22:38,437 INFO     Training average positive_sample_loss at step 60400: 0.005217\n",
      "2023-12-01 22:22:38,438 INFO     Training average negative_sample_loss at step 60400: 0.005452\n",
      "2023-12-01 22:22:38,438 INFO     Training average loss at step 60400: 0.005334\n",
      "2023-12-01 22:22:52,413 INFO     Training average positive_sample_loss at step 60500: 0.005113\n",
      "2023-12-01 22:22:52,414 INFO     Training average negative_sample_loss at step 60500: 0.006054\n",
      "2023-12-01 22:22:52,414 INFO     Training average loss at step 60500: 0.005583\n",
      "2023-12-01 22:23:06,437 INFO     Training average positive_sample_loss at step 60600: 0.005218\n",
      "2023-12-01 22:23:06,438 INFO     Training average negative_sample_loss at step 60600: 0.006413\n",
      "2023-12-01 22:23:06,438 INFO     Training average loss at step 60600: 0.005815\n",
      "2023-12-01 22:23:20,776 INFO     Training average positive_sample_loss at step 60700: 0.005180\n",
      "2023-12-01 22:23:20,776 INFO     Training average negative_sample_loss at step 60700: 0.005797\n",
      "2023-12-01 22:23:20,776 INFO     Training average loss at step 60700: 0.005489\n",
      "2023-12-01 22:23:34,896 INFO     Training average positive_sample_loss at step 60800: 0.005327\n",
      "2023-12-01 22:23:34,897 INFO     Training average negative_sample_loss at step 60800: 0.005821\n",
      "2023-12-01 22:23:34,897 INFO     Training average loss at step 60800: 0.005574\n",
      "2023-12-01 22:23:49,116 INFO     Training average positive_sample_loss at step 60900: 0.005274\n",
      "2023-12-01 22:23:49,116 INFO     Training average negative_sample_loss at step 60900: 0.006057\n",
      "2023-12-01 22:23:49,116 INFO     Training average loss at step 60900: 0.005666\n",
      "2023-12-01 22:24:05,341 INFO     Training average positive_sample_loss at step 61000: 0.005188\n",
      "2023-12-01 22:24:05,341 INFO     Training average negative_sample_loss at step 61000: 0.005706\n",
      "2023-12-01 22:24:05,341 INFO     Training average loss at step 61000: 0.005447\n",
      "2023-12-01 22:24:19,313 INFO     Training average positive_sample_loss at step 61100: 0.005173\n",
      "2023-12-01 22:24:19,313 INFO     Training average negative_sample_loss at step 61100: 0.005712\n",
      "2023-12-01 22:24:19,313 INFO     Training average loss at step 61100: 0.005442\n",
      "2023-12-01 22:24:33,838 INFO     Training average positive_sample_loss at step 61200: 0.005157\n",
      "2023-12-01 22:24:33,839 INFO     Training average negative_sample_loss at step 61200: 0.006062\n",
      "2023-12-01 22:24:33,839 INFO     Training average loss at step 61200: 0.005610\n",
      "2023-12-01 22:24:48,301 INFO     Training average positive_sample_loss at step 61300: 0.005247\n",
      "2023-12-01 22:24:48,301 INFO     Training average negative_sample_loss at step 61300: 0.005982\n",
      "2023-12-01 22:24:48,301 INFO     Training average loss at step 61300: 0.005614\n",
      "2023-12-01 22:25:02,163 INFO     Training average positive_sample_loss at step 61400: 0.005325\n",
      "2023-12-01 22:25:02,163 INFO     Training average negative_sample_loss at step 61400: 0.006391\n",
      "2023-12-01 22:25:02,163 INFO     Training average loss at step 61400: 0.005858\n",
      "2023-12-01 22:25:19,515 INFO     Training average positive_sample_loss at step 61500: 0.005290\n",
      "2023-12-01 22:25:19,515 INFO     Training average negative_sample_loss at step 61500: 0.005921\n",
      "2023-12-01 22:25:19,515 INFO     Training average loss at step 61500: 0.005605\n",
      "2023-12-01 22:25:33,160 INFO     Training average positive_sample_loss at step 61600: 0.005138\n",
      "2023-12-01 22:25:33,161 INFO     Training average negative_sample_loss at step 61600: 0.006072\n",
      "2023-12-01 22:25:33,161 INFO     Training average loss at step 61600: 0.005605\n",
      "2023-12-01 22:25:47,649 INFO     Training average positive_sample_loss at step 61700: 0.005173\n",
      "2023-12-01 22:25:47,649 INFO     Training average negative_sample_loss at step 61700: 0.005511\n",
      "2023-12-01 22:25:47,649 INFO     Training average loss at step 61700: 0.005342\n",
      "2023-12-01 22:26:02,904 INFO     Training average positive_sample_loss at step 61800: 0.005230\n",
      "2023-12-01 22:26:02,905 INFO     Training average negative_sample_loss at step 61800: 0.005925\n",
      "2023-12-01 22:26:02,905 INFO     Training average loss at step 61800: 0.005578\n",
      "2023-12-01 22:26:17,123 INFO     Training average positive_sample_loss at step 61900: 0.005258\n",
      "2023-12-01 22:26:17,123 INFO     Training average negative_sample_loss at step 61900: 0.006051\n",
      "2023-12-01 22:26:17,123 INFO     Training average loss at step 61900: 0.005654\n",
      "2023-12-01 22:26:31,691 INFO     Training average positive_sample_loss at step 62000: 0.005231\n",
      "2023-12-01 22:26:31,691 INFO     Training average negative_sample_loss at step 62000: 0.005956\n",
      "2023-12-01 22:26:31,692 INFO     Training average loss at step 62000: 0.005594\n",
      "2023-12-01 22:26:47,784 INFO     Training average positive_sample_loss at step 62100: 0.005216\n",
      "2023-12-01 22:26:47,785 INFO     Training average negative_sample_loss at step 62100: 0.006121\n",
      "2023-12-01 22:26:47,785 INFO     Training average loss at step 62100: 0.005668\n",
      "2023-12-01 22:27:01,660 INFO     Training average positive_sample_loss at step 62200: 0.005100\n",
      "2023-12-01 22:27:01,660 INFO     Training average negative_sample_loss at step 62200: 0.006131\n",
      "2023-12-01 22:27:01,660 INFO     Training average loss at step 62200: 0.005616\n",
      "2023-12-01 22:27:15,941 INFO     Training average positive_sample_loss at step 62300: 0.005197\n",
      "2023-12-01 22:27:15,942 INFO     Training average negative_sample_loss at step 62300: 0.006108\n",
      "2023-12-01 22:27:15,942 INFO     Training average loss at step 62300: 0.005652\n",
      "2023-12-01 22:27:30,531 INFO     Training average positive_sample_loss at step 62400: 0.005272\n",
      "2023-12-01 22:27:30,531 INFO     Training average negative_sample_loss at step 62400: 0.005965\n",
      "2023-12-01 22:27:30,532 INFO     Training average loss at step 62400: 0.005618\n",
      "2023-12-01 22:27:44,574 INFO     Training average positive_sample_loss at step 62500: 0.005292\n",
      "2023-12-01 22:27:44,574 INFO     Training average negative_sample_loss at step 62500: 0.005874\n",
      "2023-12-01 22:27:44,575 INFO     Training average loss at step 62500: 0.005583\n",
      "2023-12-01 22:27:58,407 INFO     Training average positive_sample_loss at step 62600: 0.005260\n",
      "2023-12-01 22:27:58,408 INFO     Training average negative_sample_loss at step 62600: 0.006249\n",
      "2023-12-01 22:27:58,408 INFO     Training average loss at step 62600: 0.005754\n",
      "2023-12-01 22:28:14,937 INFO     Training average positive_sample_loss at step 62700: 0.005161\n",
      "2023-12-01 22:28:14,938 INFO     Training average negative_sample_loss at step 62700: 0.006306\n",
      "2023-12-01 22:28:14,938 INFO     Training average loss at step 62700: 0.005734\n",
      "2023-12-01 22:28:29,000 INFO     Training average positive_sample_loss at step 62800: 0.005176\n",
      "2023-12-01 22:28:29,001 INFO     Training average negative_sample_loss at step 62800: 0.005688\n",
      "2023-12-01 22:28:29,001 INFO     Training average loss at step 62800: 0.005432\n",
      "2023-12-01 22:28:43,055 INFO     Training average positive_sample_loss at step 62900: 0.005213\n",
      "2023-12-01 22:28:43,055 INFO     Training average negative_sample_loss at step 62900: 0.005307\n",
      "2023-12-01 22:28:43,055 INFO     Training average loss at step 62900: 0.005260\n",
      "2023-12-01 22:28:57,985 INFO     Training average positive_sample_loss at step 63000: 0.005276\n",
      "2023-12-01 22:28:57,986 INFO     Training average negative_sample_loss at step 63000: 0.006479\n",
      "2023-12-01 22:28:57,986 INFO     Training average loss at step 63000: 0.005877\n",
      "2023-12-01 22:29:12,001 INFO     Training average positive_sample_loss at step 63100: 0.005257\n",
      "2023-12-01 22:29:12,001 INFO     Training average negative_sample_loss at step 63100: 0.005675\n",
      "2023-12-01 22:29:12,001 INFO     Training average loss at step 63100: 0.005466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 22:29:28,308 INFO     Training average positive_sample_loss at step 63200: 0.005155\n",
      "2023-12-01 22:29:28,309 INFO     Training average negative_sample_loss at step 63200: 0.006227\n",
      "2023-12-01 22:29:28,309 INFO     Training average loss at step 63200: 0.005691\n",
      "2023-12-01 22:29:42,250 INFO     Training average positive_sample_loss at step 63300: 0.005188\n",
      "2023-12-01 22:29:42,251 INFO     Training average negative_sample_loss at step 63300: 0.006417\n",
      "2023-12-01 22:29:42,251 INFO     Training average loss at step 63300: 0.005803\n",
      "2023-12-01 22:29:55,526 INFO     Training average positive_sample_loss at step 63400: 0.005175\n",
      "2023-12-01 22:29:55,526 INFO     Training average negative_sample_loss at step 63400: 0.005652\n",
      "2023-12-01 22:29:55,526 INFO     Training average loss at step 63400: 0.005413\n",
      "2023-12-01 22:30:09,723 INFO     Training average positive_sample_loss at step 63500: 0.005239\n",
      "2023-12-01 22:30:09,723 INFO     Training average negative_sample_loss at step 63500: 0.005560\n",
      "2023-12-01 22:30:09,723 INFO     Training average loss at step 63500: 0.005399\n",
      "2023-12-01 22:30:23,875 INFO     Training average positive_sample_loss at step 63600: 0.005249\n",
      "2023-12-01 22:30:23,876 INFO     Training average negative_sample_loss at step 63600: 0.006439\n",
      "2023-12-01 22:30:23,876 INFO     Training average loss at step 63600: 0.005844\n",
      "2023-12-01 22:30:37,242 INFO     Training average positive_sample_loss at step 63700: 0.005292\n",
      "2023-12-01 22:30:37,243 INFO     Training average negative_sample_loss at step 63700: 0.005945\n",
      "2023-12-01 22:30:37,243 INFO     Training average loss at step 63700: 0.005619\n",
      "2023-12-01 22:30:53,739 INFO     Training average positive_sample_loss at step 63800: 0.005123\n",
      "2023-12-01 22:30:53,739 INFO     Training average negative_sample_loss at step 63800: 0.005959\n",
      "2023-12-01 22:30:53,740 INFO     Training average loss at step 63800: 0.005541\n",
      "2023-12-01 22:31:07,549 INFO     Training average positive_sample_loss at step 63900: 0.005155\n",
      "2023-12-01 22:31:07,549 INFO     Training average negative_sample_loss at step 63900: 0.006090\n",
      "2023-12-01 22:31:07,549 INFO     Training average loss at step 63900: 0.005622\n",
      "2023-12-01 22:31:21,687 INFO     Training average positive_sample_loss at step 64000: 0.005275\n",
      "2023-12-01 22:31:21,687 INFO     Training average negative_sample_loss at step 64000: 0.006342\n",
      "2023-12-01 22:31:21,687 INFO     Training average loss at step 64000: 0.005808\n",
      "2023-12-01 22:31:35,179 INFO     Training average positive_sample_loss at step 64100: 0.005274\n",
      "2023-12-01 22:31:35,179 INFO     Training average negative_sample_loss at step 64100: 0.005967\n",
      "2023-12-01 22:31:35,179 INFO     Training average loss at step 64100: 0.005620\n",
      "2023-12-01 22:31:49,026 INFO     Training average positive_sample_loss at step 64200: 0.005244\n",
      "2023-12-01 22:31:49,026 INFO     Training average negative_sample_loss at step 64200: 0.006147\n",
      "2023-12-01 22:31:49,026 INFO     Training average loss at step 64200: 0.005695\n",
      "2023-12-01 22:32:05,537 INFO     Training average positive_sample_loss at step 64300: 0.005228\n",
      "2023-12-01 22:32:05,538 INFO     Training average negative_sample_loss at step 64300: 0.006488\n",
      "2023-12-01 22:32:05,538 INFO     Training average loss at step 64300: 0.005858\n",
      "2023-12-01 22:32:19,146 INFO     Training average positive_sample_loss at step 64400: 0.005143\n",
      "2023-12-01 22:32:19,146 INFO     Training average negative_sample_loss at step 64400: 0.006209\n",
      "2023-12-01 22:32:19,146 INFO     Training average loss at step 64400: 0.005676\n",
      "2023-12-01 22:32:32,952 INFO     Training average positive_sample_loss at step 64500: 0.005187\n",
      "2023-12-01 22:32:32,952 INFO     Training average negative_sample_loss at step 64500: 0.005653\n",
      "2023-12-01 22:32:32,952 INFO     Training average loss at step 64500: 0.005420\n",
      "2023-12-01 22:32:47,012 INFO     Training average positive_sample_loss at step 64600: 0.005247\n",
      "2023-12-01 22:32:47,012 INFO     Training average negative_sample_loss at step 64600: 0.006296\n",
      "2023-12-01 22:32:47,012 INFO     Training average loss at step 64600: 0.005771\n",
      "2023-12-01 22:33:00,588 INFO     Training average positive_sample_loss at step 64700: 0.005235\n",
      "2023-12-01 22:33:00,589 INFO     Training average negative_sample_loss at step 64700: 0.006033\n",
      "2023-12-01 22:33:00,589 INFO     Training average loss at step 64700: 0.005634\n",
      "2023-12-01 22:33:14,084 INFO     Training average positive_sample_loss at step 64800: 0.005277\n",
      "2023-12-01 22:33:14,084 INFO     Training average negative_sample_loss at step 64800: 0.006484\n",
      "2023-12-01 22:33:14,084 INFO     Training average loss at step 64800: 0.005881\n",
      "2023-12-01 22:33:30,704 INFO     Training average positive_sample_loss at step 64900: 0.005169\n",
      "2023-12-01 22:33:30,704 INFO     Training average negative_sample_loss at step 64900: 0.005984\n",
      "2023-12-01 22:33:30,704 INFO     Training average loss at step 64900: 0.005576\n",
      "2023-12-01 22:33:44,217 INFO     Training average positive_sample_loss at step 65000: 0.005227\n",
      "2023-12-01 22:33:44,217 INFO     Training average negative_sample_loss at step 65000: 0.005923\n",
      "2023-12-01 22:33:44,217 INFO     Training average loss at step 65000: 0.005575\n",
      "2023-12-01 22:33:57,855 INFO     Training average positive_sample_loss at step 65100: 0.005247\n",
      "2023-12-01 22:33:57,855 INFO     Training average negative_sample_loss at step 65100: 0.006113\n",
      "2023-12-01 22:33:57,855 INFO     Training average loss at step 65100: 0.005680\n",
      "2023-12-01 22:34:11,913 INFO     Training average positive_sample_loss at step 65200: 0.005196\n",
      "2023-12-01 22:34:11,914 INFO     Training average negative_sample_loss at step 65200: 0.006015\n",
      "2023-12-01 22:34:11,914 INFO     Training average loss at step 65200: 0.005606\n",
      "2023-12-01 22:34:25,909 INFO     Training average positive_sample_loss at step 65300: 0.005233\n",
      "2023-12-01 22:34:25,909 INFO     Training average negative_sample_loss at step 65300: 0.005780\n",
      "2023-12-01 22:34:25,909 INFO     Training average loss at step 65300: 0.005506\n",
      "2023-12-01 22:34:42,263 INFO     Training average positive_sample_loss at step 65400: 0.005193\n",
      "2023-12-01 22:34:42,263 INFO     Training average negative_sample_loss at step 65400: 0.006709\n",
      "2023-12-01 22:34:42,263 INFO     Training average loss at step 65400: 0.005951\n",
      "2023-12-01 22:34:56,878 INFO     Training average positive_sample_loss at step 65500: 0.005157\n",
      "2023-12-01 22:34:56,878 INFO     Training average negative_sample_loss at step 65500: 0.005861\n",
      "2023-12-01 22:34:56,878 INFO     Training average loss at step 65500: 0.005509\n",
      "2023-12-01 22:35:11,359 INFO     Training average positive_sample_loss at step 65600: 0.005198\n",
      "2023-12-01 22:35:11,359 INFO     Training average negative_sample_loss at step 65600: 0.006100\n",
      "2023-12-01 22:35:11,359 INFO     Training average loss at step 65600: 0.005649\n",
      "2023-12-01 22:35:25,680 INFO     Training average positive_sample_loss at step 65700: 0.005182\n",
      "2023-12-01 22:35:25,680 INFO     Training average negative_sample_loss at step 65700: 0.006121\n",
      "2023-12-01 22:35:25,680 INFO     Training average loss at step 65700: 0.005652\n",
      "2023-12-01 22:35:39,323 INFO     Training average positive_sample_loss at step 65800: 0.005224\n",
      "2023-12-01 22:35:39,324 INFO     Training average negative_sample_loss at step 65800: 0.005957\n",
      "2023-12-01 22:35:39,324 INFO     Training average loss at step 65800: 0.005591\n",
      "2023-12-01 22:35:53,583 INFO     Training average positive_sample_loss at step 65900: 0.005293\n",
      "2023-12-01 22:35:53,583 INFO     Training average negative_sample_loss at step 65900: 0.006269\n",
      "2023-12-01 22:35:53,583 INFO     Training average loss at step 65900: 0.005781\n",
      "2023-12-01 22:36:09,957 INFO     Training average positive_sample_loss at step 66000: 0.005148\n",
      "2023-12-01 22:36:09,957 INFO     Training average negative_sample_loss at step 66000: 0.005906\n",
      "2023-12-01 22:36:09,957 INFO     Training average loss at step 66000: 0.005527\n",
      "2023-12-01 22:36:23,446 INFO     Training average positive_sample_loss at step 66100: 0.005204\n",
      "2023-12-01 22:36:23,447 INFO     Training average negative_sample_loss at step 66100: 0.006094\n",
      "2023-12-01 22:36:23,447 INFO     Training average loss at step 66100: 0.005649\n",
      "2023-12-01 22:36:36,808 INFO     Training average positive_sample_loss at step 66200: 0.005228\n",
      "2023-12-01 22:36:36,809 INFO     Training average negative_sample_loss at step 66200: 0.006044\n",
      "2023-12-01 22:36:36,809 INFO     Training average loss at step 66200: 0.005636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 22:36:50,089 INFO     Training average positive_sample_loss at step 66300: 0.005180\n",
      "2023-12-01 22:36:50,089 INFO     Training average negative_sample_loss at step 66300: 0.005357\n",
      "2023-12-01 22:36:50,089 INFO     Training average loss at step 66300: 0.005268\n",
      "2023-12-01 22:37:03,544 INFO     Training average positive_sample_loss at step 66400: 0.005238\n",
      "2023-12-01 22:37:03,544 INFO     Training average negative_sample_loss at step 66400: 0.005946\n",
      "2023-12-01 22:37:03,544 INFO     Training average loss at step 66400: 0.005592\n",
      "2023-12-01 22:37:19,627 INFO     Training average positive_sample_loss at step 66500: 0.005220\n",
      "2023-12-01 22:37:19,627 INFO     Training average negative_sample_loss at step 66500: 0.006074\n",
      "2023-12-01 22:37:19,627 INFO     Training average loss at step 66500: 0.005647\n",
      "2023-12-01 22:37:33,360 INFO     Training average positive_sample_loss at step 66600: 0.005141\n",
      "2023-12-01 22:37:33,360 INFO     Training average negative_sample_loss at step 66600: 0.005912\n",
      "2023-12-01 22:37:33,360 INFO     Training average loss at step 66600: 0.005527\n",
      "2023-12-01 22:37:47,193 INFO     Training average positive_sample_loss at step 66700: 0.005163\n",
      "2023-12-01 22:37:47,194 INFO     Training average negative_sample_loss at step 66700: 0.005925\n",
      "2023-12-01 22:37:47,194 INFO     Training average loss at step 66700: 0.005544\n",
      "2023-12-01 22:38:00,958 INFO     Training average positive_sample_loss at step 66800: 0.005215\n",
      "2023-12-01 22:38:00,959 INFO     Training average negative_sample_loss at step 66800: 0.005919\n",
      "2023-12-01 22:38:00,959 INFO     Training average loss at step 66800: 0.005567\n",
      "2023-12-01 22:38:15,064 INFO     Training average positive_sample_loss at step 66900: 0.005235\n",
      "2023-12-01 22:38:15,065 INFO     Training average negative_sample_loss at step 66900: 0.006147\n",
      "2023-12-01 22:38:15,065 INFO     Training average loss at step 66900: 0.005691\n",
      "2023-12-01 22:38:28,451 INFO     Training average positive_sample_loss at step 67000: 0.005285\n",
      "2023-12-01 22:38:28,451 INFO     Training average negative_sample_loss at step 67000: 0.006026\n",
      "2023-12-01 22:38:28,451 INFO     Training average loss at step 67000: 0.005655\n",
      "2023-12-01 22:38:45,617 INFO     Training average positive_sample_loss at step 67100: 0.005152\n",
      "2023-12-01 22:38:45,617 INFO     Training average negative_sample_loss at step 67100: 0.005972\n",
      "2023-12-01 22:38:45,617 INFO     Training average loss at step 67100: 0.005562\n",
      "2023-12-01 22:38:59,594 INFO     Training average positive_sample_loss at step 67200: 0.005151\n",
      "2023-12-01 22:38:59,594 INFO     Training average negative_sample_loss at step 67200: 0.005593\n",
      "2023-12-01 22:38:59,594 INFO     Training average loss at step 67200: 0.005372\n",
      "2023-12-01 22:39:13,552 INFO     Training average positive_sample_loss at step 67300: 0.005234\n",
      "2023-12-01 22:39:13,552 INFO     Training average negative_sample_loss at step 67300: 0.005884\n",
      "2023-12-01 22:39:13,552 INFO     Training average loss at step 67300: 0.005559\n",
      "2023-12-01 22:39:27,641 INFO     Training average positive_sample_loss at step 67400: 0.005223\n",
      "2023-12-01 22:39:27,641 INFO     Training average negative_sample_loss at step 67400: 0.006023\n",
      "2023-12-01 22:39:27,641 INFO     Training average loss at step 67400: 0.005623\n",
      "2023-12-01 22:39:41,313 INFO     Training average positive_sample_loss at step 67500: 0.005245\n",
      "2023-12-01 22:39:41,314 INFO     Training average negative_sample_loss at step 67500: 0.005815\n",
      "2023-12-01 22:39:41,314 INFO     Training average loss at step 67500: 0.005530\n",
      "2023-12-01 22:39:58,443 INFO     Training average positive_sample_loss at step 67600: 0.005260\n",
      "2023-12-01 22:39:58,443 INFO     Training average negative_sample_loss at step 67600: 0.005379\n",
      "2023-12-01 22:39:58,443 INFO     Training average loss at step 67600: 0.005320\n",
      "2023-12-01 22:40:12,298 INFO     Training average positive_sample_loss at step 67700: 0.005144\n",
      "2023-12-01 22:40:12,299 INFO     Training average negative_sample_loss at step 67700: 0.006297\n",
      "2023-12-01 22:40:12,299 INFO     Training average loss at step 67700: 0.005720\n",
      "2023-12-01 22:40:26,265 INFO     Training average positive_sample_loss at step 67800: 0.005134\n",
      "2023-12-01 22:40:26,265 INFO     Training average negative_sample_loss at step 67800: 0.006587\n",
      "2023-12-01 22:40:26,265 INFO     Training average loss at step 67800: 0.005861\n",
      "2023-12-01 22:40:39,967 INFO     Training average positive_sample_loss at step 67900: 0.005221\n",
      "2023-12-01 22:40:39,967 INFO     Training average negative_sample_loss at step 67900: 0.005807\n",
      "2023-12-01 22:40:39,967 INFO     Training average loss at step 67900: 0.005514\n",
      "2023-12-01 22:40:54,304 INFO     Training average positive_sample_loss at step 68000: 0.005236\n",
      "2023-12-01 22:40:54,304 INFO     Training average negative_sample_loss at step 68000: 0.005874\n",
      "2023-12-01 22:40:54,304 INFO     Training average loss at step 68000: 0.005555\n",
      "2023-12-01 22:41:08,836 INFO     Training average positive_sample_loss at step 68100: 0.005263\n",
      "2023-12-01 22:41:08,836 INFO     Training average negative_sample_loss at step 68100: 0.006336\n",
      "2023-12-01 22:41:08,836 INFO     Training average loss at step 68100: 0.005799\n",
      "2023-12-01 22:41:25,933 INFO     Training average positive_sample_loss at step 68200: 0.005195\n",
      "2023-12-01 22:41:25,933 INFO     Training average negative_sample_loss at step 68200: 0.006362\n",
      "2023-12-01 22:41:25,933 INFO     Training average loss at step 68200: 0.005778\n",
      "2023-12-01 22:41:40,159 INFO     Training average positive_sample_loss at step 68300: 0.005131\n",
      "2023-12-01 22:41:40,159 INFO     Training average negative_sample_loss at step 68300: 0.006304\n",
      "2023-12-01 22:41:40,160 INFO     Training average loss at step 68300: 0.005718\n",
      "2023-12-01 22:41:54,521 INFO     Training average positive_sample_loss at step 68400: 0.005203\n",
      "2023-12-01 22:41:54,521 INFO     Training average negative_sample_loss at step 68400: 0.005507\n",
      "2023-12-01 22:41:54,521 INFO     Training average loss at step 68400: 0.005355\n",
      "2023-12-01 22:42:09,246 INFO     Training average positive_sample_loss at step 68500: 0.005250\n",
      "2023-12-01 22:42:09,246 INFO     Training average negative_sample_loss at step 68500: 0.006478\n",
      "2023-12-01 22:42:09,246 INFO     Training average loss at step 68500: 0.005864\n",
      "2023-12-01 22:42:24,047 INFO     Training average positive_sample_loss at step 68600: 0.005270\n",
      "2023-12-01 22:42:24,047 INFO     Training average negative_sample_loss at step 68600: 0.006528\n",
      "2023-12-01 22:42:24,047 INFO     Training average loss at step 68600: 0.005899\n",
      "2023-12-01 22:42:40,764 INFO     Training average positive_sample_loss at step 68700: 0.005183\n",
      "2023-12-01 22:42:40,764 INFO     Training average negative_sample_loss at step 68700: 0.006288\n",
      "2023-12-01 22:42:40,764 INFO     Training average loss at step 68700: 0.005735\n",
      "2023-12-01 22:42:54,531 INFO     Training average positive_sample_loss at step 68800: 0.005120\n",
      "2023-12-01 22:42:54,532 INFO     Training average negative_sample_loss at step 68800: 0.006118\n",
      "2023-12-01 22:42:54,532 INFO     Training average loss at step 68800: 0.005619\n",
      "2023-12-01 22:43:08,252 INFO     Training average positive_sample_loss at step 68900: 0.005178\n",
      "2023-12-01 22:43:08,252 INFO     Training average negative_sample_loss at step 68900: 0.006010\n",
      "2023-12-01 22:43:08,252 INFO     Training average loss at step 68900: 0.005594\n",
      "2023-12-01 22:43:21,828 INFO     Training average positive_sample_loss at step 69000: 0.005185\n",
      "2023-12-01 22:43:21,829 INFO     Training average negative_sample_loss at step 69000: 0.006456\n",
      "2023-12-01 22:43:21,829 INFO     Training average loss at step 69000: 0.005820\n",
      "2023-12-01 22:43:35,800 INFO     Training average positive_sample_loss at step 69100: 0.005213\n",
      "2023-12-01 22:43:35,800 INFO     Training average negative_sample_loss at step 69100: 0.005198\n",
      "2023-12-01 22:43:35,800 INFO     Training average loss at step 69100: 0.005206\n",
      "2023-12-01 22:43:50,639 INFO     Training average positive_sample_loss at step 69200: 0.005309\n",
      "2023-12-01 22:43:50,639 INFO     Training average negative_sample_loss at step 69200: 0.005958\n",
      "2023-12-01 22:43:50,639 INFO     Training average loss at step 69200: 0.005634\n",
      "2023-12-01 22:44:07,103 INFO     Training average positive_sample_loss at step 69300: 0.005227\n",
      "2023-12-01 22:44:07,104 INFO     Training average negative_sample_loss at step 69300: 0.005729\n",
      "2023-12-01 22:44:07,104 INFO     Training average loss at step 69300: 0.005478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 22:44:21,383 INFO     Training average positive_sample_loss at step 69400: 0.005173\n",
      "2023-12-01 22:44:21,384 INFO     Training average negative_sample_loss at step 69400: 0.005590\n",
      "2023-12-01 22:44:21,384 INFO     Training average loss at step 69400: 0.005381\n",
      "2023-12-01 22:44:35,914 INFO     Training average positive_sample_loss at step 69500: 0.005153\n",
      "2023-12-01 22:44:35,914 INFO     Training average negative_sample_loss at step 69500: 0.006171\n",
      "2023-12-01 22:44:35,914 INFO     Training average loss at step 69500: 0.005662\n",
      "2023-12-01 22:44:49,847 INFO     Training average positive_sample_loss at step 69600: 0.005214\n",
      "2023-12-01 22:44:49,848 INFO     Training average negative_sample_loss at step 69600: 0.006161\n",
      "2023-12-01 22:44:49,848 INFO     Training average loss at step 69600: 0.005688\n",
      "2023-12-01 22:45:03,827 INFO     Training average positive_sample_loss at step 69700: 0.005228\n",
      "2023-12-01 22:45:03,827 INFO     Training average negative_sample_loss at step 69700: 0.006350\n",
      "2023-12-01 22:45:03,827 INFO     Training average loss at step 69700: 0.005789\n",
      "2023-12-01 22:45:17,464 INFO     Training average positive_sample_loss at step 69800: 0.005277\n",
      "2023-12-01 22:45:17,464 INFO     Training average negative_sample_loss at step 69800: 0.005698\n",
      "2023-12-01 22:45:17,464 INFO     Training average loss at step 69800: 0.005488\n",
      "2023-12-01 22:45:34,358 INFO     Training average positive_sample_loss at step 69900: 0.005125\n",
      "2023-12-01 22:45:34,358 INFO     Training average negative_sample_loss at step 69900: 0.006807\n",
      "2023-12-01 22:45:34,358 INFO     Training average loss at step 69900: 0.005966\n",
      "2023-12-01 22:46:00,676 INFO     Training average positive_sample_loss at step 70000: 0.005118\n",
      "2023-12-01 22:46:00,677 INFO     Training average negative_sample_loss at step 70000: 0.005822\n",
      "2023-12-01 22:46:00,677 INFO     Training average loss at step 70000: 0.005470\n",
      "2023-12-01 22:46:00,677 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-01 22:46:01,214 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-01 22:46:35,157 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-01 22:46:44,041 INFO     Valid MRR at step 70000: 0.949332\n",
      "2023-12-01 22:46:44,042 INFO     Valid MR at step 70000: 294.371200\n",
      "2023-12-01 22:46:44,042 INFO     Valid HITS@1 at step 70000: 0.944500\n",
      "2023-12-01 22:46:44,042 INFO     Valid HITS@3 at step 70000: 0.951700\n",
      "2023-12-01 22:46:44,042 INFO     Valid HITS@10 at step 70000: 0.958600\n",
      "2023-12-01 22:46:55,845 INFO     Training average positive_sample_loss at step 70100: 0.005184\n",
      "2023-12-01 22:46:55,846 INFO     Training average negative_sample_loss at step 70100: 0.005842\n",
      "2023-12-01 22:46:55,846 INFO     Training average loss at step 70100: 0.005513\n",
      "2023-12-01 22:47:10,004 INFO     Training average positive_sample_loss at step 70200: 0.005274\n",
      "2023-12-01 22:47:10,004 INFO     Training average negative_sample_loss at step 70200: 0.006280\n",
      "2023-12-01 22:47:10,005 INFO     Training average loss at step 70200: 0.005777\n",
      "2023-12-01 22:47:23,977 INFO     Training average positive_sample_loss at step 70300: 0.005320\n",
      "2023-12-01 22:47:23,978 INFO     Training average negative_sample_loss at step 70300: 0.006231\n",
      "2023-12-01 22:47:23,978 INFO     Training average loss at step 70300: 0.005775\n",
      "2023-12-01 22:47:40,865 INFO     Training average positive_sample_loss at step 70400: 0.005206\n",
      "2023-12-01 22:47:40,866 INFO     Training average negative_sample_loss at step 70400: 0.006113\n",
      "2023-12-01 22:47:40,866 INFO     Training average loss at step 70400: 0.005660\n",
      "2023-12-01 22:47:54,197 INFO     Training average positive_sample_loss at step 70500: 0.005147\n",
      "2023-12-01 22:47:54,198 INFO     Training average negative_sample_loss at step 70500: 0.005885\n",
      "2023-12-01 22:47:54,198 INFO     Training average loss at step 70500: 0.005516\n",
      "2023-12-01 22:48:07,616 INFO     Training average positive_sample_loss at step 70600: 0.005177\n",
      "2023-12-01 22:48:07,616 INFO     Training average negative_sample_loss at step 70600: 0.006458\n",
      "2023-12-01 22:48:07,616 INFO     Training average loss at step 70600: 0.005817\n",
      "2023-12-01 22:48:21,223 INFO     Training average positive_sample_loss at step 70700: 0.005227\n",
      "2023-12-01 22:48:21,223 INFO     Training average negative_sample_loss at step 70700: 0.005587\n",
      "2023-12-01 22:48:21,223 INFO     Training average loss at step 70700: 0.005407\n",
      "2023-12-01 22:48:34,884 INFO     Training average positive_sample_loss at step 70800: 0.005213\n",
      "2023-12-01 22:48:34,885 INFO     Training average negative_sample_loss at step 70800: 0.005822\n",
      "2023-12-01 22:48:34,885 INFO     Training average loss at step 70800: 0.005518\n",
      "2023-12-01 22:48:48,549 INFO     Training average positive_sample_loss at step 70900: 0.005262\n",
      "2023-12-01 22:48:48,549 INFO     Training average negative_sample_loss at step 70900: 0.006068\n",
      "2023-12-01 22:48:48,549 INFO     Training average loss at step 70900: 0.005665\n",
      "2023-12-01 22:49:05,080 INFO     Training average positive_sample_loss at step 71000: 0.005189\n",
      "2023-12-01 22:49:05,081 INFO     Training average negative_sample_loss at step 71000: 0.006123\n",
      "2023-12-01 22:49:05,081 INFO     Training average loss at step 71000: 0.005656\n",
      "2023-12-01 22:49:19,889 INFO     Training average positive_sample_loss at step 71100: 0.005147\n",
      "2023-12-01 22:49:19,889 INFO     Training average negative_sample_loss at step 71100: 0.005989\n",
      "2023-12-01 22:49:19,889 INFO     Training average loss at step 71100: 0.005568\n",
      "2023-12-01 22:49:33,857 INFO     Training average positive_sample_loss at step 71200: 0.005154\n",
      "2023-12-01 22:49:33,857 INFO     Training average negative_sample_loss at step 71200: 0.006007\n",
      "2023-12-01 22:49:33,857 INFO     Training average loss at step 71200: 0.005581\n",
      "2023-12-01 22:49:48,430 INFO     Training average positive_sample_loss at step 71300: 0.005221\n",
      "2023-12-01 22:49:48,430 INFO     Training average negative_sample_loss at step 71300: 0.006354\n",
      "2023-12-01 22:49:48,430 INFO     Training average loss at step 71300: 0.005787\n",
      "2023-12-01 22:50:03,143 INFO     Training average positive_sample_loss at step 71400: 0.005245\n",
      "2023-12-01 22:50:03,144 INFO     Training average negative_sample_loss at step 71400: 0.005989\n",
      "2023-12-01 22:50:03,144 INFO     Training average loss at step 71400: 0.005617\n",
      "2023-12-01 22:50:20,609 INFO     Training average positive_sample_loss at step 71500: 0.005219\n",
      "2023-12-01 22:50:20,614 INFO     Training average negative_sample_loss at step 71500: 0.005914\n",
      "2023-12-01 22:50:20,614 INFO     Training average loss at step 71500: 0.005567\n",
      "2023-12-01 22:50:34,874 INFO     Training average positive_sample_loss at step 71600: 0.005189\n",
      "2023-12-01 22:50:34,875 INFO     Training average negative_sample_loss at step 71600: 0.005889\n",
      "2023-12-01 22:50:34,875 INFO     Training average loss at step 71600: 0.005539\n",
      "2023-12-01 22:50:49,227 INFO     Training average positive_sample_loss at step 71700: 0.005212\n",
      "2023-12-01 22:50:49,227 INFO     Training average negative_sample_loss at step 71700: 0.005280\n",
      "2023-12-01 22:50:49,227 INFO     Training average loss at step 71700: 0.005246\n",
      "2023-12-01 22:51:04,012 INFO     Training average positive_sample_loss at step 71800: 0.005182\n",
      "2023-12-01 22:51:04,012 INFO     Training average negative_sample_loss at step 71800: 0.006087\n",
      "2023-12-01 22:51:04,013 INFO     Training average loss at step 71800: 0.005634\n",
      "2023-12-01 22:51:19,019 INFO     Training average positive_sample_loss at step 71900: 0.005232\n",
      "2023-12-01 22:51:19,020 INFO     Training average negative_sample_loss at step 71900: 0.005847\n",
      "2023-12-01 22:51:19,020 INFO     Training average loss at step 71900: 0.005540\n",
      "2023-12-01 22:51:32,778 INFO     Training average positive_sample_loss at step 72000: 0.005223\n",
      "2023-12-01 22:51:32,778 INFO     Training average negative_sample_loss at step 72000: 0.006210\n",
      "2023-12-01 22:51:32,778 INFO     Training average loss at step 72000: 0.005717\n",
      "2023-12-01 22:51:48,406 INFO     Training average positive_sample_loss at step 72100: 0.005146\n",
      "2023-12-01 22:51:48,406 INFO     Training average negative_sample_loss at step 72100: 0.005918\n",
      "2023-12-01 22:51:48,407 INFO     Training average loss at step 72100: 0.005532\n",
      "2023-12-01 22:52:02,702 INFO     Training average positive_sample_loss at step 72200: 0.005173\n",
      "2023-12-01 22:52:02,702 INFO     Training average negative_sample_loss at step 72200: 0.005880\n",
      "2023-12-01 22:52:02,702 INFO     Training average loss at step 72200: 0.005526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 22:52:16,261 INFO     Training average positive_sample_loss at step 72300: 0.005243\n",
      "2023-12-01 22:52:16,262 INFO     Training average negative_sample_loss at step 72300: 0.006193\n",
      "2023-12-01 22:52:16,262 INFO     Training average loss at step 72300: 0.005718\n",
      "2023-12-01 22:52:31,029 INFO     Training average positive_sample_loss at step 72400: 0.005195\n",
      "2023-12-01 22:52:31,030 INFO     Training average negative_sample_loss at step 72400: 0.005550\n",
      "2023-12-01 22:52:31,030 INFO     Training average loss at step 72400: 0.005372\n",
      "2023-12-01 22:52:46,179 INFO     Training average positive_sample_loss at step 72500: 0.005218\n",
      "2023-12-01 22:52:46,179 INFO     Training average negative_sample_loss at step 72500: 0.006638\n",
      "2023-12-01 22:52:46,179 INFO     Training average loss at step 72500: 0.005928\n",
      "2023-12-01 22:53:02,511 INFO     Training average positive_sample_loss at step 72600: 0.005219\n",
      "2023-12-01 22:53:02,511 INFO     Training average negative_sample_loss at step 72600: 0.005964\n",
      "2023-12-01 22:53:02,512 INFO     Training average loss at step 72600: 0.005591\n",
      "2023-12-01 22:53:17,141 INFO     Training average positive_sample_loss at step 72700: 0.005074\n",
      "2023-12-01 22:53:17,141 INFO     Training average negative_sample_loss at step 72700: 0.005620\n",
      "2023-12-01 22:53:17,141 INFO     Training average loss at step 72700: 0.005347\n",
      "2023-12-01 22:53:30,829 INFO     Training average positive_sample_loss at step 72800: 0.005223\n",
      "2023-12-01 22:53:30,829 INFO     Training average negative_sample_loss at step 72800: 0.006034\n",
      "2023-12-01 22:53:30,829 INFO     Training average loss at step 72800: 0.005628\n",
      "2023-12-01 22:53:45,076 INFO     Training average positive_sample_loss at step 72900: 0.005157\n",
      "2023-12-01 22:53:45,077 INFO     Training average negative_sample_loss at step 72900: 0.006133\n",
      "2023-12-01 22:53:45,077 INFO     Training average loss at step 72900: 0.005645\n",
      "2023-12-01 22:53:59,693 INFO     Training average positive_sample_loss at step 73000: 0.005268\n",
      "2023-12-01 22:53:59,693 INFO     Training average negative_sample_loss at step 73000: 0.005965\n",
      "2023-12-01 22:53:59,693 INFO     Training average loss at step 73000: 0.005616\n",
      "2023-12-01 22:54:13,507 INFO     Training average positive_sample_loss at step 73100: 0.005300\n",
      "2023-12-01 22:54:13,507 INFO     Training average negative_sample_loss at step 73100: 0.006130\n",
      "2023-12-01 22:54:13,507 INFO     Training average loss at step 73100: 0.005715\n",
      "2023-12-01 22:54:30,405 INFO     Training average positive_sample_loss at step 73200: 0.005168\n",
      "2023-12-01 22:54:30,405 INFO     Training average negative_sample_loss at step 73200: 0.005684\n",
      "2023-12-01 22:54:30,405 INFO     Training average loss at step 73200: 0.005426\n",
      "2023-12-01 22:54:44,998 INFO     Training average positive_sample_loss at step 73300: 0.005149\n",
      "2023-12-01 22:54:44,999 INFO     Training average negative_sample_loss at step 73300: 0.006108\n",
      "2023-12-01 22:54:44,999 INFO     Training average loss at step 73300: 0.005628\n",
      "2023-12-01 22:54:59,449 INFO     Training average positive_sample_loss at step 73400: 0.005241\n",
      "2023-12-01 22:54:59,449 INFO     Training average negative_sample_loss at step 73400: 0.006092\n",
      "2023-12-01 22:54:59,449 INFO     Training average loss at step 73400: 0.005666\n",
      "2023-12-01 22:55:12,988 INFO     Training average positive_sample_loss at step 73500: 0.005222\n",
      "2023-12-01 22:55:12,989 INFO     Training average negative_sample_loss at step 73500: 0.006154\n",
      "2023-12-01 22:55:12,989 INFO     Training average loss at step 73500: 0.005688\n",
      "2023-12-01 22:55:26,414 INFO     Training average positive_sample_loss at step 73600: 0.005239\n",
      "2023-12-01 22:55:26,414 INFO     Training average negative_sample_loss at step 73600: 0.005589\n",
      "2023-12-01 22:55:26,414 INFO     Training average loss at step 73600: 0.005414\n",
      "2023-12-01 22:55:42,397 INFO     Training average positive_sample_loss at step 73700: 0.005222\n",
      "2023-12-01 22:55:42,397 INFO     Training average negative_sample_loss at step 73700: 0.005548\n",
      "2023-12-01 22:55:42,397 INFO     Training average loss at step 73700: 0.005385\n",
      "2023-12-01 22:55:56,549 INFO     Training average positive_sample_loss at step 73800: 0.005115\n",
      "2023-12-01 22:55:56,549 INFO     Training average negative_sample_loss at step 73800: 0.006188\n",
      "2023-12-01 22:55:56,549 INFO     Training average loss at step 73800: 0.005651\n",
      "2023-12-01 22:56:10,438 INFO     Training average positive_sample_loss at step 73900: 0.005202\n",
      "2023-12-01 22:56:10,438 INFO     Training average negative_sample_loss at step 73900: 0.006337\n",
      "2023-12-01 22:56:10,438 INFO     Training average loss at step 73900: 0.005770\n",
      "2023-12-01 22:56:24,753 INFO     Training average positive_sample_loss at step 74000: 0.005181\n",
      "2023-12-01 22:56:24,753 INFO     Training average negative_sample_loss at step 74000: 0.006522\n",
      "2023-12-01 22:56:24,753 INFO     Training average loss at step 74000: 0.005851\n",
      "2023-12-01 22:56:38,657 INFO     Training average positive_sample_loss at step 74100: 0.005234\n",
      "2023-12-01 22:56:38,657 INFO     Training average negative_sample_loss at step 74100: 0.006151\n",
      "2023-12-01 22:56:38,657 INFO     Training average loss at step 74100: 0.005692\n",
      "2023-12-01 22:56:52,868 INFO     Training average positive_sample_loss at step 74200: 0.005266\n",
      "2023-12-01 22:56:52,868 INFO     Training average negative_sample_loss at step 74200: 0.006049\n",
      "2023-12-01 22:56:52,868 INFO     Training average loss at step 74200: 0.005658\n",
      "2023-12-01 22:57:09,158 INFO     Training average positive_sample_loss at step 74300: 0.005162\n",
      "2023-12-01 22:57:09,159 INFO     Training average negative_sample_loss at step 74300: 0.005629\n",
      "2023-12-01 22:57:09,159 INFO     Training average loss at step 74300: 0.005395\n",
      "2023-12-01 22:57:22,946 INFO     Training average positive_sample_loss at step 74400: 0.005134\n",
      "2023-12-01 22:57:22,946 INFO     Training average negative_sample_loss at step 74400: 0.005869\n",
      "2023-12-01 22:57:22,946 INFO     Training average loss at step 74400: 0.005502\n",
      "2023-12-01 22:57:36,548 INFO     Training average positive_sample_loss at step 74500: 0.005175\n",
      "2023-12-01 22:57:36,548 INFO     Training average negative_sample_loss at step 74500: 0.006106\n",
      "2023-12-01 22:57:36,548 INFO     Training average loss at step 74500: 0.005640\n",
      "2023-12-01 22:57:50,536 INFO     Training average positive_sample_loss at step 74600: 0.005259\n",
      "2023-12-01 22:57:50,536 INFO     Training average negative_sample_loss at step 74600: 0.005637\n",
      "2023-12-01 22:57:50,536 INFO     Training average loss at step 74600: 0.005448\n",
      "2023-12-01 22:58:04,778 INFO     Training average positive_sample_loss at step 74700: 0.005241\n",
      "2023-12-01 22:58:04,778 INFO     Training average negative_sample_loss at step 74700: 0.006400\n",
      "2023-12-01 22:58:04,778 INFO     Training average loss at step 74700: 0.005820\n",
      "2023-12-01 22:58:20,167 INFO     Training average positive_sample_loss at step 74800: 0.005216\n",
      "2023-12-01 22:58:20,167 INFO     Training average negative_sample_loss at step 74800: 0.005442\n",
      "2023-12-01 22:58:20,167 INFO     Training average loss at step 74800: 0.005329\n",
      "2023-12-01 22:58:34,195 INFO     Training average positive_sample_loss at step 74900: 0.005118\n",
      "2023-12-01 22:58:34,195 INFO     Training average negative_sample_loss at step 74900: 0.005728\n",
      "2023-12-01 22:58:34,195 INFO     Training average loss at step 74900: 0.005423\n",
      "2023-12-01 22:58:48,180 INFO     Training average positive_sample_loss at step 75000: 0.005166\n",
      "2023-12-01 22:58:48,180 INFO     Training average negative_sample_loss at step 75000: 0.005454\n",
      "2023-12-01 22:58:48,180 INFO     Training average loss at step 75000: 0.005310\n",
      "2023-12-01 22:59:02,245 INFO     Training average positive_sample_loss at step 75100: 0.005187\n",
      "2023-12-01 22:59:02,245 INFO     Training average negative_sample_loss at step 75100: 0.005705\n",
      "2023-12-01 22:59:02,245 INFO     Training average loss at step 75100: 0.005446\n",
      "2023-12-01 22:59:16,116 INFO     Training average positive_sample_loss at step 75200: 0.005222\n",
      "2023-12-01 22:59:16,117 INFO     Training average negative_sample_loss at step 75200: 0.005826\n",
      "2023-12-01 22:59:16,117 INFO     Training average loss at step 75200: 0.005524\n",
      "2023-12-01 22:59:30,740 INFO     Training average positive_sample_loss at step 75300: 0.005264\n",
      "2023-12-01 22:59:30,741 INFO     Training average negative_sample_loss at step 75300: 0.006054\n",
      "2023-12-01 22:59:30,741 INFO     Training average loss at step 75300: 0.005659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 22:59:46,624 INFO     Training average positive_sample_loss at step 75400: 0.005225\r\n",
      "2023-12-01 22:59:46,625 INFO     Training average negative_sample_loss at step 75400: 0.006595\r\n",
      "2023-12-01 22:59:46,625 INFO     Training average loss at step 75400: 0.005910\r\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE wn18 0 0 512 1024 500 12.0 0.5 0.0001 80000 8 -de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento di RotatE con la variante NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "Start Training......\n",
      "2023-12-09 18:38:06,011 INFO     Model: RotatE\n",
      "2023-12-09 18:38:06,012 INFO     Data Path: data/wn18\n",
      "2023-12-09 18:38:06,012 INFO     #entity: 40943\n",
      "2023-12-09 18:38:06,012 INFO     #relation: 18\n",
      "2023-12-09 18:38:06,216 INFO     #train: 141442\n",
      "2023-12-09 18:38:06,250 INFO     #valid: 5000\n",
      "2023-12-09 18:38:06,274 INFO     #test: 5000\n",
      "2023-12-09 18:38:06,483 INFO     Model Parameter Configuration:\n",
      "2023-12-09 18:38:06,484 INFO     Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2023-12-09 18:38:06,484 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2023-12-09 18:38:06,484 INFO     Parameter entity_embedding: torch.Size([40943, 1000]), require_grad = True\n",
      "2023-12-09 18:38:06,484 INFO     Parameter relation_embedding: torch.Size([18, 500]), require_grad = True\n",
      "2023-12-09 18:38:08,512 INFO     Ramdomly Initializing RotatE Model...\n",
      "2023-12-09 18:38:08,513 INFO     Start Training...\n",
      "2023-12-09 18:38:08,513 INFO     init_step = 0\n",
      "2023-12-09 18:38:08,513 INFO     batch_size = 512\n",
      "2023-12-09 18:38:08,513 INFO     negative_adversarial_sampling = 1\n",
      "2023-12-09 18:38:08,513 INFO     hidden_dim = 500\n",
      "2023-12-09 18:38:08,513 INFO     gamma = 12.000000\n",
      "2023-12-09 18:38:08,513 INFO     negative_adversarial_sampling = True\n",
      "2023-12-09 18:38:08,513 INFO     adversarial_temperature = 0.500000\n",
      "2023-12-09 18:38:08,513 INFO     learning_rate = 0\n",
      "2023-12-09 18:38:30,938 INFO     Training average positive_sample_loss at step 0: 2.684911\n",
      "2023-12-09 18:38:30,938 INFO     Training average negative_sample_loss at step 0: 0.076806\n",
      "2023-12-09 18:38:30,939 INFO     Training average loss at step 0: 1.380859\n",
      "2023-12-09 18:38:30,939 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 18:38:31,517 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 18:39:09,172 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 18:39:16,023 INFO     Valid MRR at step 0: 0.000388\n",
      "2023-12-09 18:39:16,023 INFO     Valid MR at step 0: 20411.254600\n",
      "2023-12-09 18:39:16,023 INFO     Valid HITS@1 at step 0: 0.000000\n",
      "2023-12-09 18:39:16,023 INFO     Valid HITS@3 at step 0: 0.000400\n",
      "2023-12-09 18:39:16,023 INFO     Valid HITS@10 at step 0: 0.000500\n",
      "2023-12-09 18:39:31,927 INFO     Training average positive_sample_loss at step 100: 3.481667\n",
      "2023-12-09 18:39:31,928 INFO     Training average negative_sample_loss at step 100: 0.061081\n",
      "2023-12-09 18:39:31,928 INFO     Training average loss at step 100: 1.771374\n",
      "2023-12-09 18:39:47,396 INFO     Training average positive_sample_loss at step 200: 3.076114\n",
      "2023-12-09 18:39:47,396 INFO     Training average negative_sample_loss at step 200: 0.129141\n",
      "2023-12-09 18:39:47,396 INFO     Training average loss at step 200: 1.602627\n",
      "2023-12-09 18:40:03,623 INFO     Training average positive_sample_loss at step 300: 2.381853\n",
      "2023-12-09 18:40:03,624 INFO     Training average negative_sample_loss at step 300: 0.210675\n",
      "2023-12-09 18:40:03,624 INFO     Training average loss at step 300: 1.296264\n",
      "2023-12-09 18:40:17,172 INFO     Training average positive_sample_loss at step 400: 1.812495\n",
      "2023-12-09 18:40:17,172 INFO     Training average negative_sample_loss at step 400: 0.286401\n",
      "2023-12-09 18:40:17,172 INFO     Training average loss at step 400: 1.049448\n",
      "2023-12-09 18:40:31,757 INFO     Training average positive_sample_loss at step 500: 1.362108\n",
      "2023-12-09 18:40:31,757 INFO     Training average negative_sample_loss at step 500: 0.348602\n",
      "2023-12-09 18:40:31,757 INFO     Training average loss at step 500: 0.855355\n",
      "2023-12-09 18:40:51,356 INFO     Training average positive_sample_loss at step 600: 0.926524\n",
      "2023-12-09 18:40:51,357 INFO     Training average negative_sample_loss at step 600: 0.391111\n",
      "2023-12-09 18:40:51,357 INFO     Training average loss at step 600: 0.658817\n",
      "2023-12-09 18:41:05,227 INFO     Training average positive_sample_loss at step 700: 0.676394\n",
      "2023-12-09 18:41:05,228 INFO     Training average negative_sample_loss at step 700: 0.396241\n",
      "2023-12-09 18:41:05,228 INFO     Training average loss at step 700: 0.536318\n",
      "2023-12-09 18:41:18,494 INFO     Training average positive_sample_loss at step 800: 0.603514\n",
      "2023-12-09 18:41:18,494 INFO     Training average negative_sample_loss at step 800: 0.389840\n",
      "2023-12-09 18:41:18,494 INFO     Training average loss at step 800: 0.496677\n",
      "2023-12-09 18:41:32,145 INFO     Training average positive_sample_loss at step 900: 0.537977\n",
      "2023-12-09 18:41:32,145 INFO     Training average negative_sample_loss at step 900: 0.383391\n",
      "2023-12-09 18:41:32,145 INFO     Training average loss at step 900: 0.460684\n",
      "2023-12-09 18:41:46,083 INFO     Training average positive_sample_loss at step 1000: 0.484702\n",
      "2023-12-09 18:41:46,084 INFO     Training average negative_sample_loss at step 1000: 0.372067\n",
      "2023-12-09 18:41:46,084 INFO     Training average loss at step 1000: 0.428385\n",
      "2023-12-09 18:42:00,476 INFO     Training average positive_sample_loss at step 1100: 0.438928\n",
      "2023-12-09 18:42:00,476 INFO     Training average negative_sample_loss at step 1100: 0.358133\n",
      "2023-12-09 18:42:00,476 INFO     Training average loss at step 1100: 0.398530\n",
      "2023-12-09 18:42:19,003 INFO     Training average positive_sample_loss at step 1200: 0.347270\n",
      "2023-12-09 18:42:19,003 INFO     Training average negative_sample_loss at step 1200: 0.331848\n",
      "2023-12-09 18:42:19,003 INFO     Training average loss at step 1200: 0.339559\n",
      "2023-12-09 18:42:33,331 INFO     Training average positive_sample_loss at step 1300: 0.340818\n",
      "2023-12-09 18:42:33,331 INFO     Training average negative_sample_loss at step 1300: 0.305585\n",
      "2023-12-09 18:42:33,331 INFO     Training average loss at step 1300: 0.323202\n",
      "2023-12-09 18:42:46,309 INFO     Training average positive_sample_loss at step 1400: 0.331020\n",
      "2023-12-09 18:42:46,309 INFO     Training average negative_sample_loss at step 1400: 0.288262\n",
      "2023-12-09 18:42:46,309 INFO     Training average loss at step 1400: 0.309641\n",
      "2023-12-09 18:43:00,603 INFO     Training average positive_sample_loss at step 1500: 0.315705\n",
      "2023-12-09 18:43:00,603 INFO     Training average negative_sample_loss at step 1500: 0.272635\n",
      "2023-12-09 18:43:00,603 INFO     Training average loss at step 1500: 0.294170\n",
      "2023-12-09 18:43:14,842 INFO     Training average positive_sample_loss at step 1600: 0.299660\n",
      "2023-12-09 18:43:14,842 INFO     Training average negative_sample_loss at step 1600: 0.258361\n",
      "2023-12-09 18:43:14,843 INFO     Training average loss at step 1600: 0.279011\n",
      "2023-12-09 18:43:32,162 INFO     Training average positive_sample_loss at step 1700: 0.268262\n",
      "2023-12-09 18:43:32,163 INFO     Training average negative_sample_loss at step 1700: 0.242073\n",
      "2023-12-09 18:43:32,163 INFO     Training average loss at step 1700: 0.255168\n",
      "2023-12-09 18:43:45,841 INFO     Training average positive_sample_loss at step 1800: 0.241514\n",
      "2023-12-09 18:43:45,842 INFO     Training average negative_sample_loss at step 1800: 0.219792\n",
      "2023-12-09 18:43:45,842 INFO     Training average loss at step 1800: 0.230653\n",
      "2023-12-09 18:44:00,154 INFO     Training average positive_sample_loss at step 1900: 0.238916\n",
      "2023-12-09 18:44:00,154 INFO     Training average negative_sample_loss at step 1900: 0.205323\n",
      "2023-12-09 18:44:00,154 INFO     Training average loss at step 1900: 0.222120\n",
      "2023-12-09 18:44:14,545 INFO     Training average positive_sample_loss at step 2000: 0.232893\n",
      "2023-12-09 18:44:14,546 INFO     Training average negative_sample_loss at step 2000: 0.194894\n",
      "2023-12-09 18:44:14,546 INFO     Training average loss at step 2000: 0.213894\n",
      "2023-12-09 18:44:29,257 INFO     Training average positive_sample_loss at step 2100: 0.224234\n",
      "2023-12-09 18:44:29,258 INFO     Training average negative_sample_loss at step 2100: 0.185579\n",
      "2023-12-09 18:44:29,258 INFO     Training average loss at step 2100: 0.204907\n",
      "2023-12-09 18:44:43,802 INFO     Training average positive_sample_loss at step 2200: 0.211433\n",
      "2023-12-09 18:44:43,802 INFO     Training average negative_sample_loss at step 2200: 0.175788\n",
      "2023-12-09 18:44:43,802 INFO     Training average loss at step 2200: 0.193611\n",
      "2023-12-09 18:45:01,015 INFO     Training average positive_sample_loss at step 2300: 0.180805\n",
      "2023-12-09 18:45:01,016 INFO     Training average negative_sample_loss at step 2300: 0.161833\n",
      "2023-12-09 18:45:01,016 INFO     Training average loss at step 2300: 0.171319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 18:45:14,404 INFO     Training average positive_sample_loss at step 2400: 0.178711\n",
      "2023-12-09 18:45:14,404 INFO     Training average negative_sample_loss at step 2400: 0.149877\n",
      "2023-12-09 18:45:14,404 INFO     Training average loss at step 2400: 0.164294\n",
      "2023-12-09 18:45:28,964 INFO     Training average positive_sample_loss at step 2500: 0.175691\n",
      "2023-12-09 18:45:28,964 INFO     Training average negative_sample_loss at step 2500: 0.141979\n",
      "2023-12-09 18:45:28,964 INFO     Training average loss at step 2500: 0.158835\n",
      "2023-12-09 18:45:43,363 INFO     Training average positive_sample_loss at step 2600: 0.170961\n",
      "2023-12-09 18:45:43,363 INFO     Training average negative_sample_loss at step 2600: 0.135780\n",
      "2023-12-09 18:45:43,363 INFO     Training average loss at step 2600: 0.153371\n",
      "2023-12-09 18:45:57,572 INFO     Training average positive_sample_loss at step 2700: 0.163334\n",
      "2023-12-09 18:45:57,572 INFO     Training average negative_sample_loss at step 2700: 0.129468\n",
      "2023-12-09 18:45:57,572 INFO     Training average loss at step 2700: 0.146401\n",
      "2023-12-09 18:46:13,842 INFO     Training average positive_sample_loss at step 2800: 0.150117\n",
      "2023-12-09 18:46:13,842 INFO     Training average negative_sample_loss at step 2800: 0.122592\n",
      "2023-12-09 18:46:13,842 INFO     Training average loss at step 2800: 0.136354\n",
      "2023-12-09 18:46:28,253 INFO     Training average positive_sample_loss at step 2900: 0.134959\n",
      "2023-12-09 18:46:28,254 INFO     Training average negative_sample_loss at step 2900: 0.112445\n",
      "2023-12-09 18:46:28,254 INFO     Training average loss at step 2900: 0.123702\n",
      "2023-12-09 18:46:42,633 INFO     Training average positive_sample_loss at step 3000: 0.134888\n",
      "2023-12-09 18:46:42,633 INFO     Training average negative_sample_loss at step 3000: 0.106369\n",
      "2023-12-09 18:46:42,633 INFO     Training average loss at step 3000: 0.120628\n",
      "2023-12-09 18:46:55,635 INFO     Training average positive_sample_loss at step 3100: 0.132258\n",
      "2023-12-09 18:46:55,635 INFO     Training average negative_sample_loss at step 3100: 0.101640\n",
      "2023-12-09 18:46:55,635 INFO     Training average loss at step 3100: 0.116949\n",
      "2023-12-09 18:47:10,048 INFO     Training average positive_sample_loss at step 3200: 0.128827\n",
      "2023-12-09 18:47:10,049 INFO     Training average negative_sample_loss at step 3200: 0.097587\n",
      "2023-12-09 18:47:10,049 INFO     Training average loss at step 3200: 0.113207\n",
      "2023-12-09 18:47:24,386 INFO     Training average positive_sample_loss at step 3300: 0.124066\n",
      "2023-12-09 18:47:24,386 INFO     Training average negative_sample_loss at step 3300: 0.093631\n",
      "2023-12-09 18:47:24,386 INFO     Training average loss at step 3300: 0.108849\n",
      "2023-12-09 18:47:41,112 INFO     Training average positive_sample_loss at step 3400: 0.107245\n",
      "2023-12-09 18:47:41,113 INFO     Training average negative_sample_loss at step 3400: 0.087710\n",
      "2023-12-09 18:47:41,113 INFO     Training average loss at step 3400: 0.097478\n",
      "2023-12-09 18:47:55,764 INFO     Training average positive_sample_loss at step 3500: 0.105979\n",
      "2023-12-09 18:47:55,764 INFO     Training average negative_sample_loss at step 3500: 0.081548\n",
      "2023-12-09 18:47:55,764 INFO     Training average loss at step 3500: 0.093764\n",
      "2023-12-09 18:48:10,093 INFO     Training average positive_sample_loss at step 3600: 0.104181\n",
      "2023-12-09 18:48:10,094 INFO     Training average negative_sample_loss at step 3600: 0.077989\n",
      "2023-12-09 18:48:10,094 INFO     Training average loss at step 3600: 0.091085\n",
      "2023-12-09 18:48:24,476 INFO     Training average positive_sample_loss at step 3700: 0.102037\n",
      "2023-12-09 18:48:24,476 INFO     Training average negative_sample_loss at step 3700: 0.074826\n",
      "2023-12-09 18:48:24,477 INFO     Training average loss at step 3700: 0.088431\n",
      "2023-12-09 18:48:37,998 INFO     Training average positive_sample_loss at step 3800: 0.099236\n",
      "2023-12-09 18:48:37,999 INFO     Training average negative_sample_loss at step 3800: 0.072294\n",
      "2023-12-09 18:48:37,999 INFO     Training average loss at step 3800: 0.085765\n",
      "2023-12-09 18:48:55,617 INFO     Training average positive_sample_loss at step 3900: 0.092450\n",
      "2023-12-09 18:48:55,617 INFO     Training average negative_sample_loss at step 3900: 0.069156\n",
      "2023-12-09 18:48:55,618 INFO     Training average loss at step 3900: 0.080803\n",
      "2023-12-09 18:49:09,869 INFO     Training average positive_sample_loss at step 4000: 0.082504\n",
      "2023-12-09 18:49:09,870 INFO     Training average negative_sample_loss at step 4000: 0.063955\n",
      "2023-12-09 18:49:09,870 INFO     Training average loss at step 4000: 0.073229\n",
      "2023-12-09 18:49:22,832 INFO     Training average positive_sample_loss at step 4100: 0.083390\n",
      "2023-12-09 18:49:22,832 INFO     Training average negative_sample_loss at step 4100: 0.060805\n",
      "2023-12-09 18:49:22,832 INFO     Training average loss at step 4100: 0.072098\n",
      "2023-12-09 18:49:37,623 INFO     Training average positive_sample_loss at step 4200: 0.082610\n",
      "2023-12-09 18:49:37,623 INFO     Training average negative_sample_loss at step 4200: 0.058637\n",
      "2023-12-09 18:49:37,623 INFO     Training average loss at step 4200: 0.070623\n",
      "2023-12-09 18:49:52,471 INFO     Training average positive_sample_loss at step 4300: 0.080487\n",
      "2023-12-09 18:49:52,471 INFO     Training average negative_sample_loss at step 4300: 0.056590\n",
      "2023-12-09 18:49:52,471 INFO     Training average loss at step 4300: 0.068539\n",
      "2023-12-09 18:50:06,814 INFO     Training average positive_sample_loss at step 4400: 0.078215\n",
      "2023-12-09 18:50:06,814 INFO     Training average negative_sample_loss at step 4400: 0.054865\n",
      "2023-12-09 18:50:06,814 INFO     Training average loss at step 4400: 0.066540\n",
      "2023-12-09 18:50:24,034 INFO     Training average positive_sample_loss at step 4500: 0.068800\n",
      "2023-12-09 18:50:24,034 INFO     Training average negative_sample_loss at step 4500: 0.051643\n",
      "2023-12-09 18:50:24,034 INFO     Training average loss at step 4500: 0.060221\n",
      "2023-12-09 18:50:38,416 INFO     Training average positive_sample_loss at step 4600: 0.066824\n",
      "2023-12-09 18:50:38,416 INFO     Training average negative_sample_loss at step 4600: 0.048377\n",
      "2023-12-09 18:50:38,416 INFO     Training average loss at step 4600: 0.057600\n",
      "2023-12-09 18:50:52,564 INFO     Training average positive_sample_loss at step 4700: 0.067016\n",
      "2023-12-09 18:50:52,564 INFO     Training average negative_sample_loss at step 4700: 0.046494\n",
      "2023-12-09 18:50:52,564 INFO     Training average loss at step 4700: 0.056755\n",
      "2023-12-09 18:51:05,686 INFO     Training average positive_sample_loss at step 4800: 0.065937\n",
      "2023-12-09 18:51:05,686 INFO     Training average negative_sample_loss at step 4800: 0.045089\n",
      "2023-12-09 18:51:05,686 INFO     Training average loss at step 4800: 0.055513\n",
      "2023-12-09 18:51:20,446 INFO     Training average positive_sample_loss at step 4900: 0.064699\n",
      "2023-12-09 18:51:20,446 INFO     Training average negative_sample_loss at step 4900: 0.043685\n",
      "2023-12-09 18:51:20,446 INFO     Training average loss at step 4900: 0.054192\n",
      "2023-12-09 18:51:38,468 INFO     Training average positive_sample_loss at step 5000: 0.061177\n",
      "2023-12-09 18:51:38,468 INFO     Training average negative_sample_loss at step 5000: 0.042188\n",
      "2023-12-09 18:51:38,468 INFO     Training average loss at step 5000: 0.051683\n",
      "2023-12-09 18:51:52,287 INFO     Training average positive_sample_loss at step 5100: 0.054102\n",
      "2023-12-09 18:51:52,287 INFO     Training average negative_sample_loss at step 5100: 0.039339\n",
      "2023-12-09 18:51:52,288 INFO     Training average loss at step 5100: 0.046721\n",
      "2023-12-09 18:52:07,378 INFO     Training average positive_sample_loss at step 5200: 0.055147\n",
      "2023-12-09 18:52:07,378 INFO     Training average negative_sample_loss at step 5200: 0.037632\n",
      "2023-12-09 18:52:07,378 INFO     Training average loss at step 5200: 0.046390\n",
      "2023-12-09 18:52:21,930 INFO     Training average positive_sample_loss at step 5300: 0.054566\n",
      "2023-12-09 18:52:21,930 INFO     Training average negative_sample_loss at step 5300: 0.036340\n",
      "2023-12-09 18:52:21,930 INFO     Training average loss at step 5300: 0.045453\n",
      "2023-12-09 18:52:36,270 INFO     Training average positive_sample_loss at step 5400: 0.053759\n",
      "2023-12-09 18:52:36,270 INFO     Training average negative_sample_loss at step 5400: 0.035282\n",
      "2023-12-09 18:52:36,270 INFO     Training average loss at step 5400: 0.044520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 18:52:49,716 INFO     Training average positive_sample_loss at step 5500: 0.052389\n",
      "2023-12-09 18:52:49,716 INFO     Training average negative_sample_loss at step 5500: 0.034349\n",
      "2023-12-09 18:52:49,716 INFO     Training average loss at step 5500: 0.043369\n",
      "2023-12-09 18:53:07,126 INFO     Training average positive_sample_loss at step 5600: 0.046569\n",
      "2023-12-09 18:53:07,127 INFO     Training average negative_sample_loss at step 5600: 0.032647\n",
      "2023-12-09 18:53:07,127 INFO     Training average loss at step 5600: 0.039608\n",
      "2023-12-09 18:53:21,575 INFO     Training average positive_sample_loss at step 5700: 0.045002\n",
      "2023-12-09 18:53:21,575 INFO     Training average negative_sample_loss at step 5700: 0.030740\n",
      "2023-12-09 18:53:21,575 INFO     Training average loss at step 5700: 0.037871\n",
      "2023-12-09 18:53:34,698 INFO     Training average positive_sample_loss at step 5800: 0.045849\n",
      "2023-12-09 18:53:34,698 INFO     Training average negative_sample_loss at step 5800: 0.029666\n",
      "2023-12-09 18:53:34,698 INFO     Training average loss at step 5800: 0.037758\n",
      "2023-12-09 18:53:49,227 INFO     Training average positive_sample_loss at step 5900: 0.045243\n",
      "2023-12-09 18:53:49,227 INFO     Training average negative_sample_loss at step 5900: 0.028904\n",
      "2023-12-09 18:53:49,227 INFO     Training average loss at step 5900: 0.037073\n",
      "2023-12-09 18:54:03,853 INFO     Training average positive_sample_loss at step 6000: 0.044543\n",
      "2023-12-09 18:54:03,853 INFO     Training average negative_sample_loss at step 6000: 0.028207\n",
      "2023-12-09 18:54:03,853 INFO     Training average loss at step 6000: 0.036375\n",
      "2023-12-09 18:54:21,692 INFO     Training average positive_sample_loss at step 6100: 0.042508\n",
      "2023-12-09 18:54:21,693 INFO     Training average negative_sample_loss at step 6100: 0.027372\n",
      "2023-12-09 18:54:21,693 INFO     Training average loss at step 6100: 0.034940\n",
      "2023-12-09 18:54:36,228 INFO     Training average positive_sample_loss at step 6200: 0.037173\n",
      "2023-12-09 18:54:36,228 INFO     Training average negative_sample_loss at step 6200: 0.025646\n",
      "2023-12-09 18:54:36,228 INFO     Training average loss at step 6200: 0.031410\n",
      "2023-12-09 18:54:50,485 INFO     Training average positive_sample_loss at step 6300: 0.038355\n",
      "2023-12-09 18:54:50,485 INFO     Training average negative_sample_loss at step 6300: 0.024614\n",
      "2023-12-09 18:54:50,485 INFO     Training average loss at step 6300: 0.031484\n",
      "2023-12-09 18:55:04,831 INFO     Training average positive_sample_loss at step 6400: 0.038326\n",
      "2023-12-09 18:55:04,831 INFO     Training average negative_sample_loss at step 6400: 0.023981\n",
      "2023-12-09 18:55:04,831 INFO     Training average loss at step 6400: 0.031153\n",
      "2023-12-09 18:55:17,815 INFO     Training average positive_sample_loss at step 6500: 0.037876\n",
      "2023-12-09 18:55:17,815 INFO     Training average negative_sample_loss at step 6500: 0.023420\n",
      "2023-12-09 18:55:17,815 INFO     Training average loss at step 6500: 0.030648\n",
      "2023-12-09 18:55:32,141 INFO     Training average positive_sample_loss at step 6600: 0.037045\n",
      "2023-12-09 18:55:32,141 INFO     Training average negative_sample_loss at step 6600: 0.022911\n",
      "2023-12-09 18:55:32,141 INFO     Training average loss at step 6600: 0.029978\n",
      "2023-12-09 18:55:49,889 INFO     Training average positive_sample_loss at step 6700: 0.033521\n",
      "2023-12-09 18:55:49,889 INFO     Training average negative_sample_loss at step 6700: 0.021966\n",
      "2023-12-09 18:55:49,889 INFO     Training average loss at step 6700: 0.027743\n",
      "2023-12-09 18:56:04,524 INFO     Training average positive_sample_loss at step 6800: 0.032292\n",
      "2023-12-09 18:56:04,524 INFO     Training average negative_sample_loss at step 6800: 0.020783\n",
      "2023-12-09 18:56:04,524 INFO     Training average loss at step 6800: 0.026537\n",
      "2023-12-09 18:56:18,879 INFO     Training average positive_sample_loss at step 6900: 0.032257\n",
      "2023-12-09 18:56:18,879 INFO     Training average negative_sample_loss at step 6900: 0.020110\n",
      "2023-12-09 18:56:18,879 INFO     Training average loss at step 6900: 0.026184\n",
      "2023-12-09 18:56:33,236 INFO     Training average positive_sample_loss at step 7000: 0.032515\n",
      "2023-12-09 18:56:33,236 INFO     Training average negative_sample_loss at step 7000: 0.019607\n",
      "2023-12-09 18:56:33,236 INFO     Training average loss at step 7000: 0.026061\n",
      "2023-12-09 18:56:47,562 INFO     Training average positive_sample_loss at step 7100: 0.032064\n",
      "2023-12-09 18:56:47,562 INFO     Training average negative_sample_loss at step 7100: 0.019348\n",
      "2023-12-09 18:56:47,562 INFO     Training average loss at step 7100: 0.025706\n",
      "2023-12-09 18:57:00,491 INFO     Training average positive_sample_loss at step 7200: 0.031476\n",
      "2023-12-09 18:57:00,491 INFO     Training average negative_sample_loss at step 7200: 0.018857\n",
      "2023-12-09 18:57:00,491 INFO     Training average loss at step 7200: 0.025167\n",
      "2023-12-09 18:57:17,898 INFO     Training average positive_sample_loss at step 7300: 0.027219\n",
      "2023-12-09 18:57:17,898 INFO     Training average negative_sample_loss at step 7300: 0.017941\n",
      "2023-12-09 18:57:17,898 INFO     Training average loss at step 7300: 0.022580\n",
      "2023-12-09 18:57:32,330 INFO     Training average positive_sample_loss at step 7400: 0.027777\n",
      "2023-12-09 18:57:32,330 INFO     Training average negative_sample_loss at step 7400: 0.017160\n",
      "2023-12-09 18:57:32,330 INFO     Training average loss at step 7400: 0.022468\n",
      "2023-12-09 18:57:45,570 INFO     Training average positive_sample_loss at step 7500: 0.028245\n",
      "2023-12-09 18:57:45,570 INFO     Training average negative_sample_loss at step 7500: 0.016767\n",
      "2023-12-09 18:57:45,570 INFO     Training average loss at step 7500: 0.022506\n",
      "2023-12-09 18:57:59,903 INFO     Training average positive_sample_loss at step 7600: 0.027922\n",
      "2023-12-09 18:57:59,904 INFO     Training average negative_sample_loss at step 7600: 0.016520\n",
      "2023-12-09 18:57:59,904 INFO     Training average loss at step 7600: 0.022221\n",
      "2023-12-09 18:58:14,254 INFO     Training average positive_sample_loss at step 7700: 0.027271\n",
      "2023-12-09 18:58:14,255 INFO     Training average negative_sample_loss at step 7700: 0.016196\n",
      "2023-12-09 18:58:14,255 INFO     Training average loss at step 7700: 0.021733\n",
      "2023-12-09 18:58:31,101 INFO     Training average positive_sample_loss at step 7800: 0.025253\n",
      "2023-12-09 18:58:31,101 INFO     Training average negative_sample_loss at step 7800: 0.015767\n",
      "2023-12-09 18:58:31,102 INFO     Training average loss at step 7800: 0.020510\n",
      "2023-12-09 18:58:45,572 INFO     Training average positive_sample_loss at step 7900: 0.024098\n",
      "2023-12-09 18:58:45,573 INFO     Training average negative_sample_loss at step 7900: 0.014901\n",
      "2023-12-09 18:58:45,573 INFO     Training average loss at step 7900: 0.019499\n",
      "2023-12-09 18:58:59,811 INFO     Training average positive_sample_loss at step 8000: 0.024383\n",
      "2023-12-09 18:58:59,811 INFO     Training average negative_sample_loss at step 8000: 0.014478\n",
      "2023-12-09 18:58:59,811 INFO     Training average loss at step 8000: 0.019430\n",
      "2023-12-09 18:59:14,094 INFO     Training average positive_sample_loss at step 8100: 0.024414\n",
      "2023-12-09 18:59:14,095 INFO     Training average negative_sample_loss at step 8100: 0.014237\n",
      "2023-12-09 18:59:14,095 INFO     Training average loss at step 8100: 0.019326\n",
      "2023-12-09 18:59:28,428 INFO     Training average positive_sample_loss at step 8200: 0.024211\n",
      "2023-12-09 18:59:28,428 INFO     Training average negative_sample_loss at step 8200: 0.014117\n",
      "2023-12-09 18:59:28,428 INFO     Training average loss at step 8200: 0.019164\n",
      "2023-12-09 18:59:42,275 INFO     Training average positive_sample_loss at step 8300: 0.023634\n",
      "2023-12-09 18:59:42,275 INFO     Training average negative_sample_loss at step 8300: 0.013805\n",
      "2023-12-09 18:59:42,276 INFO     Training average loss at step 8300: 0.018720\n",
      "2023-12-09 18:59:59,275 INFO     Training average positive_sample_loss at step 8400: 0.020892\n",
      "2023-12-09 18:59:59,276 INFO     Training average negative_sample_loss at step 8400: 0.013341\n",
      "2023-12-09 18:59:59,276 INFO     Training average loss at step 8400: 0.017117\n",
      "2023-12-09 19:00:12,928 INFO     Training average positive_sample_loss at step 8500: 0.021426\n",
      "2023-12-09 19:00:12,928 INFO     Training average negative_sample_loss at step 8500: 0.012701\n",
      "2023-12-09 19:00:12,928 INFO     Training average loss at step 8500: 0.017063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:00:27,072 INFO     Training average positive_sample_loss at step 8600: 0.021697\n",
      "2023-12-09 19:00:27,072 INFO     Training average negative_sample_loss at step 8600: 0.012519\n",
      "2023-12-09 19:00:27,072 INFO     Training average loss at step 8600: 0.017108\n",
      "2023-12-09 19:00:41,022 INFO     Training average positive_sample_loss at step 8700: 0.021514\n",
      "2023-12-09 19:00:41,022 INFO     Training average negative_sample_loss at step 8700: 0.012438\n",
      "2023-12-09 19:00:41,022 INFO     Training average loss at step 8700: 0.016976\n",
      "2023-12-09 19:00:54,470 INFO     Training average positive_sample_loss at step 8800: 0.021356\n",
      "2023-12-09 19:00:54,471 INFO     Training average negative_sample_loss at step 8800: 0.012320\n",
      "2023-12-09 19:00:54,471 INFO     Training average loss at step 8800: 0.016838\n",
      "2023-12-09 19:01:12,178 INFO     Training average positive_sample_loss at step 8900: 0.019568\n",
      "2023-12-09 19:01:12,178 INFO     Training average negative_sample_loss at step 8900: 0.012017\n",
      "2023-12-09 19:01:12,178 INFO     Training average loss at step 8900: 0.015792\n",
      "2023-12-09 19:01:26,254 INFO     Training average positive_sample_loss at step 9000: 0.018788\n",
      "2023-12-09 19:01:26,255 INFO     Training average negative_sample_loss at step 9000: 0.011454\n",
      "2023-12-09 19:01:26,255 INFO     Training average loss at step 9000: 0.015121\n",
      "2023-12-09 19:01:40,167 INFO     Training average positive_sample_loss at step 9100: 0.019113\n",
      "2023-12-09 19:01:40,167 INFO     Training average negative_sample_loss at step 9100: 0.011049\n",
      "2023-12-09 19:01:40,167 INFO     Training average loss at step 9100: 0.015081\n",
      "2023-12-09 19:01:54,071 INFO     Training average positive_sample_loss at step 9200: 0.019316\n",
      "2023-12-09 19:01:54,071 INFO     Training average negative_sample_loss at step 9200: 0.011103\n",
      "2023-12-09 19:01:54,071 INFO     Training average loss at step 9200: 0.015209\n",
      "2023-12-09 19:02:08,116 INFO     Training average positive_sample_loss at step 9300: 0.019067\n",
      "2023-12-09 19:02:08,116 INFO     Training average negative_sample_loss at step 9300: 0.011025\n",
      "2023-12-09 19:02:08,116 INFO     Training average loss at step 9300: 0.015046\n",
      "2023-12-09 19:02:22,577 INFO     Training average positive_sample_loss at step 9400: 0.018875\n",
      "2023-12-09 19:02:22,577 INFO     Training average negative_sample_loss at step 9400: 0.010779\n",
      "2023-12-09 19:02:22,577 INFO     Training average loss at step 9400: 0.014827\n",
      "2023-12-09 19:02:39,473 INFO     Training average positive_sample_loss at step 9500: 0.016691\n",
      "2023-12-09 19:02:39,473 INFO     Training average negative_sample_loss at step 9500: 0.010491\n",
      "2023-12-09 19:02:39,473 INFO     Training average loss at step 9500: 0.013591\n",
      "2023-12-09 19:02:53,415 INFO     Training average positive_sample_loss at step 9600: 0.017160\n",
      "2023-12-09 19:02:53,416 INFO     Training average negative_sample_loss at step 9600: 0.010157\n",
      "2023-12-09 19:02:53,416 INFO     Training average loss at step 9600: 0.013658\n",
      "2023-12-09 19:03:06,671 INFO     Training average positive_sample_loss at step 9700: 0.017245\n",
      "2023-12-09 19:03:06,671 INFO     Training average negative_sample_loss at step 9700: 0.010025\n",
      "2023-12-09 19:03:06,671 INFO     Training average loss at step 9700: 0.013635\n",
      "2023-12-09 19:03:20,581 INFO     Training average positive_sample_loss at step 9800: 0.017419\n",
      "2023-12-09 19:03:20,581 INFO     Training average negative_sample_loss at step 9800: 0.009950\n",
      "2023-12-09 19:03:20,581 INFO     Training average loss at step 9800: 0.013684\n",
      "2023-12-09 19:03:33,987 INFO     Training average positive_sample_loss at step 9900: 0.017202\n",
      "2023-12-09 19:03:33,988 INFO     Training average negative_sample_loss at step 9900: 0.009915\n",
      "2023-12-09 19:03:33,988 INFO     Training average loss at step 9900: 0.013559\n",
      "2023-12-09 19:04:07,870 INFO     Training average positive_sample_loss at step 10000: 0.016249\n",
      "2023-12-09 19:04:07,870 INFO     Training average negative_sample_loss at step 10000: 0.009605\n",
      "2023-12-09 19:04:07,870 INFO     Training average loss at step 10000: 0.012927\n",
      "2023-12-09 19:04:07,870 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 19:04:08,551 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 19:04:58,810 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 19:05:09,312 INFO     Valid MRR at step 10000: 0.947001\n",
      "2023-12-09 19:05:09,312 INFO     Valid MR at step 10000: 510.230000\n",
      "2023-12-09 19:05:09,312 INFO     Valid HITS@1 at step 10000: 0.942500\n",
      "2023-12-09 19:05:09,312 INFO     Valid HITS@3 at step 10000: 0.949400\n",
      "2023-12-09 19:05:09,312 INFO     Valid HITS@10 at step 10000: 0.955000\n",
      "2023-12-09 19:05:22,359 INFO     Training average positive_sample_loss at step 10100: 0.015145\n",
      "2023-12-09 19:05:22,359 INFO     Training average negative_sample_loss at step 10100: 0.009383\n",
      "2023-12-09 19:05:22,359 INFO     Training average loss at step 10100: 0.012264\n",
      "2023-12-09 19:05:36,379 INFO     Training average positive_sample_loss at step 10200: 0.015840\n",
      "2023-12-09 19:05:36,380 INFO     Training average negative_sample_loss at step 10200: 0.009246\n",
      "2023-12-09 19:05:36,380 INFO     Training average loss at step 10200: 0.012543\n",
      "2023-12-09 19:05:49,926 INFO     Training average positive_sample_loss at step 10300: 0.015860\n",
      "2023-12-09 19:05:49,926 INFO     Training average negative_sample_loss at step 10300: 0.009264\n",
      "2023-12-09 19:05:49,926 INFO     Training average loss at step 10300: 0.012562\n",
      "2023-12-09 19:06:02,920 INFO     Training average positive_sample_loss at step 10400: 0.015843\n",
      "2023-12-09 19:06:02,920 INFO     Training average negative_sample_loss at step 10400: 0.009223\n",
      "2023-12-09 19:06:02,920 INFO     Training average loss at step 10400: 0.012533\n",
      "2023-12-09 19:06:17,133 INFO     Training average positive_sample_loss at step 10500: 0.015542\n",
      "2023-12-09 19:06:17,133 INFO     Training average negative_sample_loss at step 10500: 0.009108\n",
      "2023-12-09 19:06:17,133 INFO     Training average loss at step 10500: 0.012325\n",
      "2023-12-09 19:06:34,208 INFO     Training average positive_sample_loss at step 10600: 0.013959\n",
      "2023-12-09 19:06:34,208 INFO     Training average negative_sample_loss at step 10600: 0.008841\n",
      "2023-12-09 19:06:34,208 INFO     Training average loss at step 10600: 0.011400\n",
      "2023-12-09 19:06:47,333 INFO     Training average positive_sample_loss at step 10700: 0.014165\n",
      "2023-12-09 19:06:47,334 INFO     Training average negative_sample_loss at step 10700: 0.008489\n",
      "2023-12-09 19:06:47,334 INFO     Training average loss at step 10700: 0.011327\n",
      "2023-12-09 19:07:01,727 INFO     Training average positive_sample_loss at step 10800: 0.014627\n",
      "2023-12-09 19:07:01,727 INFO     Training average negative_sample_loss at step 10800: 0.008540\n",
      "2023-12-09 19:07:01,727 INFO     Training average loss at step 10800: 0.011583\n",
      "2023-12-09 19:07:15,801 INFO     Training average positive_sample_loss at step 10900: 0.014674\n",
      "2023-12-09 19:07:15,802 INFO     Training average negative_sample_loss at step 10900: 0.008437\n",
      "2023-12-09 19:07:15,802 INFO     Training average loss at step 10900: 0.011556\n",
      "2023-12-09 19:07:28,280 INFO     Training average positive_sample_loss at step 11000: 0.014493\n",
      "2023-12-09 19:07:28,280 INFO     Training average negative_sample_loss at step 11000: 0.008398\n",
      "2023-12-09 19:07:28,280 INFO     Training average loss at step 11000: 0.011445\n",
      "2023-12-09 19:07:45,662 INFO     Training average positive_sample_loss at step 11100: 0.013964\n",
      "2023-12-09 19:07:45,662 INFO     Training average negative_sample_loss at step 11100: 0.008362\n",
      "2023-12-09 19:07:45,662 INFO     Training average loss at step 11100: 0.011163\n",
      "2023-12-09 19:08:00,069 INFO     Training average positive_sample_loss at step 11200: 0.012870\n",
      "2023-12-09 19:08:00,070 INFO     Training average negative_sample_loss at step 11200: 0.008105\n",
      "2023-12-09 19:08:00,070 INFO     Training average loss at step 11200: 0.010487\n",
      "2023-12-09 19:08:12,829 INFO     Training average positive_sample_loss at step 11300: 0.013424\n",
      "2023-12-09 19:08:12,829 INFO     Training average negative_sample_loss at step 11300: 0.008166\n",
      "2023-12-09 19:08:12,829 INFO     Training average loss at step 11300: 0.010795\n",
      "2023-12-09 19:08:26,426 INFO     Training average positive_sample_loss at step 11400: 0.013467\n",
      "2023-12-09 19:08:26,427 INFO     Training average negative_sample_loss at step 11400: 0.008003\n",
      "2023-12-09 19:08:26,427 INFO     Training average loss at step 11400: 0.010735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:08:40,357 INFO     Training average positive_sample_loss at step 11500: 0.013611\n",
      "2023-12-09 19:08:40,358 INFO     Training average negative_sample_loss at step 11500: 0.008112\n",
      "2023-12-09 19:08:40,358 INFO     Training average loss at step 11500: 0.010861\n",
      "2023-12-09 19:08:54,186 INFO     Training average positive_sample_loss at step 11600: 0.013408\n",
      "2023-12-09 19:08:54,186 INFO     Training average negative_sample_loss at step 11600: 0.007949\n",
      "2023-12-09 19:08:54,186 INFO     Training average loss at step 11600: 0.010678\n",
      "2023-12-09 19:09:10,883 INFO     Training average positive_sample_loss at step 11700: 0.012160\n",
      "2023-12-09 19:09:10,883 INFO     Training average negative_sample_loss at step 11700: 0.007960\n",
      "2023-12-09 19:09:10,883 INFO     Training average loss at step 11700: 0.010060\n",
      "2023-12-09 19:09:25,039 INFO     Training average positive_sample_loss at step 11800: 0.012263\n",
      "2023-12-09 19:09:25,039 INFO     Training average negative_sample_loss at step 11800: 0.007653\n",
      "2023-12-09 19:09:25,039 INFO     Training average loss at step 11800: 0.009958\n",
      "2023-12-09 19:09:38,920 INFO     Training average positive_sample_loss at step 11900: 0.012754\n",
      "2023-12-09 19:09:38,921 INFO     Training average negative_sample_loss at step 11900: 0.007448\n",
      "2023-12-09 19:09:38,921 INFO     Training average loss at step 11900: 0.010101\n",
      "2023-12-09 19:09:52,281 INFO     Training average positive_sample_loss at step 12000: 0.012741\n",
      "2023-12-09 19:09:52,282 INFO     Training average negative_sample_loss at step 12000: 0.007491\n",
      "2023-12-09 19:09:52,282 INFO     Training average loss at step 12000: 0.010116\n",
      "2023-12-09 19:10:06,645 INFO     Training average positive_sample_loss at step 12100: 0.012622\n",
      "2023-12-09 19:10:06,645 INFO     Training average negative_sample_loss at step 12100: 0.007635\n",
      "2023-12-09 19:10:06,645 INFO     Training average loss at step 12100: 0.010129\n",
      "2023-12-09 19:10:23,622 INFO     Training average positive_sample_loss at step 12200: 0.012313\n",
      "2023-12-09 19:10:23,622 INFO     Training average negative_sample_loss at step 12200: 0.007733\n",
      "2023-12-09 19:10:23,622 INFO     Training average loss at step 12200: 0.010023\n",
      "2023-12-09 19:10:37,745 INFO     Training average positive_sample_loss at step 12300: 0.011293\n",
      "2023-12-09 19:10:37,745 INFO     Training average negative_sample_loss at step 12300: 0.007413\n",
      "2023-12-09 19:10:37,745 INFO     Training average loss at step 12300: 0.009353\n",
      "2023-12-09 19:10:51,737 INFO     Training average positive_sample_loss at step 12400: 0.011740\n",
      "2023-12-09 19:10:51,738 INFO     Training average negative_sample_loss at step 12400: 0.007135\n",
      "2023-12-09 19:10:51,738 INFO     Training average loss at step 12400: 0.009437\n",
      "2023-12-09 19:11:06,775 INFO     Training average positive_sample_loss at step 12500: 0.012031\n",
      "2023-12-09 19:11:06,775 INFO     Training average negative_sample_loss at step 12500: 0.007258\n",
      "2023-12-09 19:11:06,775 INFO     Training average loss at step 12500: 0.009645\n",
      "2023-12-09 19:11:19,737 INFO     Training average positive_sample_loss at step 12600: 0.012002\n",
      "2023-12-09 19:11:19,737 INFO     Training average negative_sample_loss at step 12600: 0.007435\n",
      "2023-12-09 19:11:19,737 INFO     Training average loss at step 12600: 0.009719\n",
      "2023-12-09 19:11:35,664 INFO     Training average positive_sample_loss at step 12700: 0.011869\n",
      "2023-12-09 19:11:35,665 INFO     Training average negative_sample_loss at step 12700: 0.007402\n",
      "2023-12-09 19:11:35,665 INFO     Training average loss at step 12700: 0.009635\n",
      "2023-12-09 19:11:52,445 INFO     Training average positive_sample_loss at step 12800: 0.010914\n",
      "2023-12-09 19:11:52,445 INFO     Training average negative_sample_loss at step 12800: 0.006995\n",
      "2023-12-09 19:11:52,445 INFO     Training average loss at step 12800: 0.008955\n",
      "2023-12-09 19:12:06,864 INFO     Training average positive_sample_loss at step 12900: 0.010892\n",
      "2023-12-09 19:12:06,865 INFO     Training average negative_sample_loss at step 12900: 0.007145\n",
      "2023-12-09 19:12:06,865 INFO     Training average loss at step 12900: 0.009018\n",
      "2023-12-09 19:12:20,686 INFO     Training average positive_sample_loss at step 13000: 0.011428\n",
      "2023-12-09 19:12:20,686 INFO     Training average negative_sample_loss at step 13000: 0.007116\n",
      "2023-12-09 19:12:20,686 INFO     Training average loss at step 13000: 0.009272\n",
      "2023-12-09 19:12:34,136 INFO     Training average positive_sample_loss at step 13100: 0.011349\n",
      "2023-12-09 19:12:34,137 INFO     Training average negative_sample_loss at step 13100: 0.007087\n",
      "2023-12-09 19:12:34,137 INFO     Training average loss at step 13100: 0.009218\n",
      "2023-12-09 19:12:47,313 INFO     Training average positive_sample_loss at step 13200: 0.011402\n",
      "2023-12-09 19:12:47,313 INFO     Training average negative_sample_loss at step 13200: 0.007212\n",
      "2023-12-09 19:12:47,313 INFO     Training average loss at step 13200: 0.009307\n",
      "2023-12-09 19:13:04,819 INFO     Training average positive_sample_loss at step 13300: 0.011274\n",
      "2023-12-09 19:13:04,819 INFO     Training average negative_sample_loss at step 13300: 0.007319\n",
      "2023-12-09 19:13:04,819 INFO     Training average loss at step 13300: 0.009296\n",
      "2023-12-09 19:13:18,368 INFO     Training average positive_sample_loss at step 13400: 0.010072\n",
      "2023-12-09 19:13:18,368 INFO     Training average negative_sample_loss at step 13400: 0.006778\n",
      "2023-12-09 19:13:18,368 INFO     Training average loss at step 13400: 0.008425\n",
      "2023-12-09 19:13:32,703 INFO     Training average positive_sample_loss at step 13500: 0.010569\n",
      "2023-12-09 19:13:32,704 INFO     Training average negative_sample_loss at step 13500: 0.006958\n",
      "2023-12-09 19:13:32,704 INFO     Training average loss at step 13500: 0.008764\n",
      "2023-12-09 19:13:46,645 INFO     Training average positive_sample_loss at step 13600: 0.010895\n",
      "2023-12-09 19:13:46,646 INFO     Training average negative_sample_loss at step 13600: 0.006743\n",
      "2023-12-09 19:13:46,646 INFO     Training average loss at step 13600: 0.008819\n",
      "2023-12-09 19:13:59,881 INFO     Training average positive_sample_loss at step 13700: 0.010905\n",
      "2023-12-09 19:13:59,881 INFO     Training average negative_sample_loss at step 13700: 0.006874\n",
      "2023-12-09 19:13:59,881 INFO     Training average loss at step 13700: 0.008890\n",
      "2023-12-09 19:14:12,891 INFO     Training average positive_sample_loss at step 13800: 0.010871\n",
      "2023-12-09 19:14:12,891 INFO     Training average negative_sample_loss at step 13800: 0.007119\n",
      "2023-12-09 19:14:12,892 INFO     Training average loss at step 13800: 0.008995\n",
      "2023-12-09 19:14:30,436 INFO     Training average positive_sample_loss at step 13900: 0.010069\n",
      "2023-12-09 19:14:30,436 INFO     Training average negative_sample_loss at step 13900: 0.007077\n",
      "2023-12-09 19:14:30,436 INFO     Training average loss at step 13900: 0.008573\n",
      "2023-12-09 19:14:45,570 INFO     Training average positive_sample_loss at step 14000: 0.009945\n",
      "2023-12-09 19:14:45,570 INFO     Training average negative_sample_loss at step 14000: 0.006786\n",
      "2023-12-09 19:14:45,570 INFO     Training average loss at step 14000: 0.008366\n",
      "2023-12-09 19:14:58,894 INFO     Training average positive_sample_loss at step 14100: 0.010343\n",
      "2023-12-09 19:14:58,894 INFO     Training average negative_sample_loss at step 14100: 0.006649\n",
      "2023-12-09 19:14:58,894 INFO     Training average loss at step 14100: 0.008496\n",
      "2023-12-09 19:15:12,851 INFO     Training average positive_sample_loss at step 14200: 0.010479\n",
      "2023-12-09 19:15:12,851 INFO     Training average negative_sample_loss at step 14200: 0.006744\n",
      "2023-12-09 19:15:12,851 INFO     Training average loss at step 14200: 0.008611\n",
      "2023-12-09 19:15:26,623 INFO     Training average positive_sample_loss at step 14300: 0.010472\n",
      "2023-12-09 19:15:26,623 INFO     Training average negative_sample_loss at step 14300: 0.006675\n",
      "2023-12-09 19:15:26,623 INFO     Training average loss at step 14300: 0.008573\n",
      "2023-12-09 19:15:40,025 INFO     Training average positive_sample_loss at step 14400: 0.010363\n",
      "2023-12-09 19:15:40,026 INFO     Training average negative_sample_loss at step 14400: 0.006873\n",
      "2023-12-09 19:15:40,026 INFO     Training average loss at step 14400: 0.008618\n",
      "2023-12-09 19:15:57,167 INFO     Training average positive_sample_loss at step 14500: 0.009336\n",
      "2023-12-09 19:15:57,168 INFO     Training average negative_sample_loss at step 14500: 0.006678\n",
      "2023-12-09 19:15:57,168 INFO     Training average loss at step 14500: 0.008007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:16:10,947 INFO     Training average positive_sample_loss at step 14600: 0.009766\n",
      "2023-12-09 19:16:10,948 INFO     Training average negative_sample_loss at step 14600: 0.006733\n",
      "2023-12-09 19:16:10,948 INFO     Training average loss at step 14600: 0.008249\n",
      "2023-12-09 19:16:25,411 INFO     Training average positive_sample_loss at step 14700: 0.010029\n",
      "2023-12-09 19:16:25,411 INFO     Training average negative_sample_loss at step 14700: 0.006737\n",
      "2023-12-09 19:16:25,411 INFO     Training average loss at step 14700: 0.008383\n",
      "2023-12-09 19:16:39,438 INFO     Training average positive_sample_loss at step 14800: 0.010222\n",
      "2023-12-09 19:16:39,438 INFO     Training average negative_sample_loss at step 14800: 0.006682\n",
      "2023-12-09 19:16:39,438 INFO     Training average loss at step 14800: 0.008452\n",
      "2023-12-09 19:16:53,518 INFO     Training average positive_sample_loss at step 14900: 0.010044\n",
      "2023-12-09 19:16:53,518 INFO     Training average negative_sample_loss at step 14900: 0.006584\n",
      "2023-12-09 19:16:53,518 INFO     Training average loss at step 14900: 0.008314\n",
      "2023-12-09 19:17:10,396 INFO     Training average positive_sample_loss at step 15000: 0.009469\n",
      "2023-12-09 19:17:10,396 INFO     Training average negative_sample_loss at step 15000: 0.006958\n",
      "2023-12-09 19:17:10,396 INFO     Training average loss at step 15000: 0.008213\n",
      "2023-12-09 19:17:24,687 INFO     Training average positive_sample_loss at step 15100: 0.009251\n",
      "2023-12-09 19:17:24,687 INFO     Training average negative_sample_loss at step 15100: 0.006617\n",
      "2023-12-09 19:17:24,688 INFO     Training average loss at step 15100: 0.007934\n",
      "2023-12-09 19:17:38,783 INFO     Training average positive_sample_loss at step 15200: 0.009628\n",
      "2023-12-09 19:17:38,784 INFO     Training average negative_sample_loss at step 15200: 0.006794\n",
      "2023-12-09 19:17:38,784 INFO     Training average loss at step 15200: 0.008211\n",
      "2023-12-09 19:17:51,227 INFO     Training average positive_sample_loss at step 15300: 0.009789\n",
      "2023-12-09 19:17:51,227 INFO     Training average negative_sample_loss at step 15300: 0.006432\n",
      "2023-12-09 19:17:51,227 INFO     Training average loss at step 15300: 0.008111\n",
      "2023-12-09 19:18:05,470 INFO     Training average positive_sample_loss at step 15400: 0.009764\n",
      "2023-12-09 19:18:05,471 INFO     Training average negative_sample_loss at step 15400: 0.006311\n",
      "2023-12-09 19:18:05,471 INFO     Training average loss at step 15400: 0.008037\n",
      "2023-12-09 19:18:19,081 INFO     Training average positive_sample_loss at step 15500: 0.009648\n",
      "2023-12-09 19:18:19,081 INFO     Training average negative_sample_loss at step 15500: 0.006672\n",
      "2023-12-09 19:18:19,081 INFO     Training average loss at step 15500: 0.008160\n",
      "2023-12-09 19:18:36,660 INFO     Training average positive_sample_loss at step 15600: 0.008822\n",
      "2023-12-09 19:18:36,661 INFO     Training average negative_sample_loss at step 15600: 0.006583\n",
      "2023-12-09 19:18:36,661 INFO     Training average loss at step 15600: 0.007703\n",
      "2023-12-09 19:18:50,761 INFO     Training average positive_sample_loss at step 15700: 0.009155\n",
      "2023-12-09 19:18:50,761 INFO     Training average negative_sample_loss at step 15700: 0.006686\n",
      "2023-12-09 19:18:50,762 INFO     Training average loss at step 15700: 0.007920\n",
      "2023-12-09 19:19:04,302 INFO     Training average positive_sample_loss at step 15800: 0.009328\n",
      "2023-12-09 19:19:04,303 INFO     Training average negative_sample_loss at step 15800: 0.006321\n",
      "2023-12-09 19:19:04,303 INFO     Training average loss at step 15800: 0.007825\n",
      "2023-12-09 19:19:18,339 INFO     Training average positive_sample_loss at step 15900: 0.009532\n",
      "2023-12-09 19:19:18,339 INFO     Training average negative_sample_loss at step 15900: 0.006936\n",
      "2023-12-09 19:19:18,339 INFO     Training average loss at step 15900: 0.008234\n",
      "2023-12-09 19:19:31,756 INFO     Training average positive_sample_loss at step 16000: 0.009550\n",
      "2023-12-09 19:19:31,756 INFO     Training average negative_sample_loss at step 16000: 0.006506\n",
      "2023-12-09 19:19:31,756 INFO     Training average loss at step 16000: 0.008028\n",
      "2023-12-09 19:19:48,620 INFO     Training average positive_sample_loss at step 16100: 0.009049\n",
      "2023-12-09 19:19:48,620 INFO     Training average negative_sample_loss at step 16100: 0.006354\n",
      "2023-12-09 19:19:48,620 INFO     Training average loss at step 16100: 0.007702\n",
      "2023-12-09 19:20:02,692 INFO     Training average positive_sample_loss at step 16200: 0.008622\n",
      "2023-12-09 19:20:02,692 INFO     Training average negative_sample_loss at step 16200: 0.006581\n",
      "2023-12-09 19:20:02,692 INFO     Training average loss at step 16200: 0.007602\n",
      "2023-12-09 19:20:16,434 INFO     Training average positive_sample_loss at step 16300: 0.009068\n",
      "2023-12-09 19:20:16,434 INFO     Training average negative_sample_loss at step 16300: 0.006448\n",
      "2023-12-09 19:20:16,434 INFO     Training average loss at step 16300: 0.007758\n",
      "2023-12-09 19:20:30,789 INFO     Training average positive_sample_loss at step 16400: 0.009223\n",
      "2023-12-09 19:20:30,789 INFO     Training average negative_sample_loss at step 16400: 0.006301\n",
      "2023-12-09 19:20:30,789 INFO     Training average loss at step 16400: 0.007762\n",
      "2023-12-09 19:20:44,615 INFO     Training average positive_sample_loss at step 16500: 0.009294\n",
      "2023-12-09 19:20:44,615 INFO     Training average negative_sample_loss at step 16500: 0.006677\n",
      "2023-12-09 19:20:44,616 INFO     Training average loss at step 16500: 0.007985\n",
      "2023-12-09 19:20:58,483 INFO     Training average positive_sample_loss at step 16600: 0.009299\n",
      "2023-12-09 19:20:58,484 INFO     Training average negative_sample_loss at step 16600: 0.006643\n",
      "2023-12-09 19:20:58,484 INFO     Training average loss at step 16600: 0.007971\n",
      "2023-12-09 19:21:16,073 INFO     Training average positive_sample_loss at step 16700: 0.008200\n",
      "2023-12-09 19:21:16,073 INFO     Training average negative_sample_loss at step 16700: 0.006576\n",
      "2023-12-09 19:21:16,073 INFO     Training average loss at step 16700: 0.007388\n",
      "2023-12-09 19:21:29,897 INFO     Training average positive_sample_loss at step 16800: 0.008785\n",
      "2023-12-09 19:21:29,897 INFO     Training average negative_sample_loss at step 16800: 0.006276\n",
      "2023-12-09 19:21:29,897 INFO     Training average loss at step 16800: 0.007530\n",
      "2023-12-09 19:21:43,452 INFO     Training average positive_sample_loss at step 16900: 0.008964\n",
      "2023-12-09 19:21:43,453 INFO     Training average negative_sample_loss at step 16900: 0.006674\n",
      "2023-12-09 19:21:43,453 INFO     Training average loss at step 16900: 0.007819\n",
      "2023-12-09 19:21:57,243 INFO     Training average positive_sample_loss at step 17000: 0.009132\n",
      "2023-12-09 19:21:57,243 INFO     Training average negative_sample_loss at step 17000: 0.006377\n",
      "2023-12-09 19:21:57,243 INFO     Training average loss at step 17000: 0.007755\n",
      "2023-12-09 19:22:11,116 INFO     Training average positive_sample_loss at step 17100: 0.009055\n",
      "2023-12-09 19:22:11,116 INFO     Training average negative_sample_loss at step 17100: 0.006716\n",
      "2023-12-09 19:22:11,116 INFO     Training average loss at step 17100: 0.007886\n",
      "2023-12-09 19:22:27,870 INFO     Training average positive_sample_loss at step 17200: 0.008826\n",
      "2023-12-09 19:22:27,871 INFO     Training average negative_sample_loss at step 17200: 0.006307\n",
      "2023-12-09 19:22:27,871 INFO     Training average loss at step 17200: 0.007567\n",
      "2023-12-09 19:22:42,111 INFO     Training average positive_sample_loss at step 17300: 0.008150\n",
      "2023-12-09 19:22:42,112 INFO     Training average negative_sample_loss at step 17300: 0.006444\n",
      "2023-12-09 19:22:42,112 INFO     Training average loss at step 17300: 0.007297\n",
      "2023-12-09 19:22:56,355 INFO     Training average positive_sample_loss at step 17400: 0.008680\n",
      "2023-12-09 19:22:56,356 INFO     Training average negative_sample_loss at step 17400: 0.006354\n",
      "2023-12-09 19:22:56,356 INFO     Training average loss at step 17400: 0.007517\n",
      "2023-12-09 19:23:10,753 INFO     Training average positive_sample_loss at step 17500: 0.008785\n",
      "2023-12-09 19:23:10,753 INFO     Training average negative_sample_loss at step 17500: 0.006572\n",
      "2023-12-09 19:23:10,753 INFO     Training average loss at step 17500: 0.007678\n",
      "2023-12-09 19:23:24,538 INFO     Training average positive_sample_loss at step 17600: 0.009028\n",
      "2023-12-09 19:23:24,538 INFO     Training average negative_sample_loss at step 17600: 0.006748\n",
      "2023-12-09 19:23:24,538 INFO     Training average loss at step 17600: 0.007888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:23:36,947 INFO     Training average positive_sample_loss at step 17700: 0.008837\n",
      "2023-12-09 19:23:36,947 INFO     Training average negative_sample_loss at step 17700: 0.006671\n",
      "2023-12-09 19:23:36,947 INFO     Training average loss at step 17700: 0.007754\n",
      "2023-12-09 19:23:52,937 INFO     Training average positive_sample_loss at step 17800: 0.008066\n",
      "2023-12-09 19:23:52,938 INFO     Training average negative_sample_loss at step 17800: 0.006180\n",
      "2023-12-09 19:23:52,938 INFO     Training average loss at step 17800: 0.007123\n",
      "2023-12-09 19:24:08,186 INFO     Training average positive_sample_loss at step 17900: 0.008287\n",
      "2023-12-09 19:24:08,186 INFO     Training average negative_sample_loss at step 17900: 0.006121\n",
      "2023-12-09 19:24:08,186 INFO     Training average loss at step 17900: 0.007204\n",
      "2023-12-09 19:24:22,617 INFO     Training average positive_sample_loss at step 18000: 0.008513\n",
      "2023-12-09 19:24:22,617 INFO     Training average negative_sample_loss at step 18000: 0.006107\n",
      "2023-12-09 19:24:22,617 INFO     Training average loss at step 18000: 0.007310\n",
      "2023-12-09 19:24:36,093 INFO     Training average positive_sample_loss at step 18100: 0.008785\n",
      "2023-12-09 19:24:36,094 INFO     Training average negative_sample_loss at step 18100: 0.006036\n",
      "2023-12-09 19:24:36,094 INFO     Training average loss at step 18100: 0.007411\n",
      "2023-12-09 19:24:51,229 INFO     Training average positive_sample_loss at step 18200: 0.008648\n",
      "2023-12-09 19:24:51,229 INFO     Training average negative_sample_loss at step 18200: 0.006618\n",
      "2023-12-09 19:24:51,229 INFO     Training average loss at step 18200: 0.007633\n",
      "2023-12-09 19:25:08,057 INFO     Training average positive_sample_loss at step 18300: 0.008345\n",
      "2023-12-09 19:25:08,057 INFO     Training average negative_sample_loss at step 18300: 0.006484\n",
      "2023-12-09 19:25:08,057 INFO     Training average loss at step 18300: 0.007414\n",
      "2023-12-09 19:25:21,806 INFO     Training average positive_sample_loss at step 18400: 0.007855\n",
      "2023-12-09 19:25:21,806 INFO     Training average negative_sample_loss at step 18400: 0.006031\n",
      "2023-12-09 19:25:21,806 INFO     Training average loss at step 18400: 0.006943\n",
      "2023-12-09 19:25:35,800 INFO     Training average positive_sample_loss at step 18500: 0.008293\n",
      "2023-12-09 19:25:35,800 INFO     Training average negative_sample_loss at step 18500: 0.006419\n",
      "2023-12-09 19:25:35,800 INFO     Training average loss at step 18500: 0.007356\n",
      "2023-12-09 19:25:49,713 INFO     Training average positive_sample_loss at step 18600: 0.008467\n",
      "2023-12-09 19:25:49,713 INFO     Training average negative_sample_loss at step 18600: 0.006448\n",
      "2023-12-09 19:25:49,713 INFO     Training average loss at step 18600: 0.007457\n",
      "2023-12-09 19:26:03,361 INFO     Training average positive_sample_loss at step 18700: 0.008446\n",
      "2023-12-09 19:26:03,362 INFO     Training average negative_sample_loss at step 18700: 0.006038\n",
      "2023-12-09 19:26:03,362 INFO     Training average loss at step 18700: 0.007242\n",
      "2023-12-09 19:26:17,289 INFO     Training average positive_sample_loss at step 18800: 0.008447\n",
      "2023-12-09 19:26:17,289 INFO     Training average negative_sample_loss at step 18800: 0.006720\n",
      "2023-12-09 19:26:17,289 INFO     Training average loss at step 18800: 0.007583\n",
      "2023-12-09 19:26:34,718 INFO     Training average positive_sample_loss at step 18900: 0.007917\n",
      "2023-12-09 19:26:34,718 INFO     Training average negative_sample_loss at step 18900: 0.006170\n",
      "2023-12-09 19:26:34,718 INFO     Training average loss at step 18900: 0.007043\n",
      "2023-12-09 19:26:47,783 INFO     Training average positive_sample_loss at step 19000: 0.007937\n",
      "2023-12-09 19:26:47,784 INFO     Training average negative_sample_loss at step 19000: 0.006455\n",
      "2023-12-09 19:26:47,784 INFO     Training average loss at step 19000: 0.007196\n",
      "2023-12-09 19:27:01,954 INFO     Training average positive_sample_loss at step 19100: 0.008356\n",
      "2023-12-09 19:27:01,955 INFO     Training average negative_sample_loss at step 19100: 0.006024\n",
      "2023-12-09 19:27:01,955 INFO     Training average loss at step 19100: 0.007190\n",
      "2023-12-09 19:27:15,536 INFO     Training average positive_sample_loss at step 19200: 0.008372\n",
      "2023-12-09 19:27:15,536 INFO     Training average negative_sample_loss at step 19200: 0.006491\n",
      "2023-12-09 19:27:15,536 INFO     Training average loss at step 19200: 0.007431\n",
      "2023-12-09 19:27:29,303 INFO     Training average positive_sample_loss at step 19300: 0.008333\n",
      "2023-12-09 19:27:29,303 INFO     Training average negative_sample_loss at step 19300: 0.006448\n",
      "2023-12-09 19:27:29,303 INFO     Training average loss at step 19300: 0.007390\n",
      "2023-12-09 19:27:46,975 INFO     Training average positive_sample_loss at step 19400: 0.008279\n",
      "2023-12-09 19:27:46,976 INFO     Training average negative_sample_loss at step 19400: 0.007159\n",
      "2023-12-09 19:27:46,976 INFO     Training average loss at step 19400: 0.007719\n",
      "2023-12-09 19:28:02,545 INFO     Training average positive_sample_loss at step 19500: 0.007575\n",
      "2023-12-09 19:28:02,545 INFO     Training average negative_sample_loss at step 19500: 0.006187\n",
      "2023-12-09 19:28:02,545 INFO     Training average loss at step 19500: 0.006881\n",
      "2023-12-09 19:28:16,008 INFO     Training average positive_sample_loss at step 19600: 0.008161\n",
      "2023-12-09 19:28:16,009 INFO     Training average negative_sample_loss at step 19600: 0.006548\n",
      "2023-12-09 19:28:16,009 INFO     Training average loss at step 19600: 0.007354\n",
      "2023-12-09 19:28:30,522 INFO     Training average positive_sample_loss at step 19700: 0.008216\n",
      "2023-12-09 19:28:30,522 INFO     Training average negative_sample_loss at step 19700: 0.006301\n",
      "2023-12-09 19:28:30,522 INFO     Training average loss at step 19700: 0.007258\n",
      "2023-12-09 19:28:45,369 INFO     Training average positive_sample_loss at step 19800: 0.008357\n",
      "2023-12-09 19:28:45,369 INFO     Training average negative_sample_loss at step 19800: 0.006295\n",
      "2023-12-09 19:28:45,369 INFO     Training average loss at step 19800: 0.007326\n",
      "2023-12-09 19:28:59,441 INFO     Training average positive_sample_loss at step 19900: 0.008280\n",
      "2023-12-09 19:28:59,441 INFO     Training average negative_sample_loss at step 19900: 0.006248\n",
      "2023-12-09 19:28:59,441 INFO     Training average loss at step 19900: 0.007264\n",
      "2023-12-09 19:29:31,378 INFO     Training average positive_sample_loss at step 20000: 0.007658\n",
      "2023-12-09 19:29:31,378 INFO     Training average negative_sample_loss at step 20000: 0.006412\n",
      "2023-12-09 19:29:31,378 INFO     Training average loss at step 20000: 0.007035\n",
      "2023-12-09 19:29:31,379 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 19:29:32,032 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 19:30:26,726 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 19:30:38,201 INFO     Valid MRR at step 20000: 0.949058\n",
      "2023-12-09 19:30:38,201 INFO     Valid MR at step 20000: 369.524800\n",
      "2023-12-09 19:30:38,201 INFO     Valid HITS@1 at step 20000: 0.944800\n",
      "2023-12-09 19:30:38,201 INFO     Valid HITS@3 at step 20000: 0.950500\n",
      "2023-12-09 19:30:38,201 INFO     Valid HITS@10 at step 20000: 0.957700\n",
      "2023-12-09 19:30:52,198 INFO     Training average positive_sample_loss at step 20100: 0.007768\n",
      "2023-12-09 19:30:52,199 INFO     Training average negative_sample_loss at step 20100: 0.006627\n",
      "2023-12-09 19:30:52,199 INFO     Training average loss at step 20100: 0.007198\n",
      "2023-12-09 19:31:06,521 INFO     Training average positive_sample_loss at step 20200: 0.008015\n",
      "2023-12-09 19:31:06,521 INFO     Training average negative_sample_loss at step 20200: 0.006390\n",
      "2023-12-09 19:31:06,521 INFO     Training average loss at step 20200: 0.007202\n",
      "2023-12-09 19:31:21,086 INFO     Training average positive_sample_loss at step 20300: 0.008119\n",
      "2023-12-09 19:31:21,086 INFO     Training average negative_sample_loss at step 20300: 0.006428\n",
      "2023-12-09 19:31:21,086 INFO     Training average loss at step 20300: 0.007273\n",
      "2023-12-09 19:31:35,088 INFO     Training average positive_sample_loss at step 20400: 0.008184\n",
      "2023-12-09 19:31:35,088 INFO     Training average negative_sample_loss at step 20400: 0.006525\n",
      "2023-12-09 19:31:35,088 INFO     Training average loss at step 20400: 0.007355\n",
      "2023-12-09 19:31:51,543 INFO     Training average positive_sample_loss at step 20500: 0.008187\n",
      "2023-12-09 19:31:51,544 INFO     Training average negative_sample_loss at step 20500: 0.006357\n",
      "2023-12-09 19:31:51,544 INFO     Training average loss at step 20500: 0.007272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:32:05,722 INFO     Training average positive_sample_loss at step 20600: 0.007433\n",
      "2023-12-09 19:32:05,723 INFO     Training average negative_sample_loss at step 20600: 0.006551\n",
      "2023-12-09 19:32:05,723 INFO     Training average loss at step 20600: 0.006992\n",
      "2023-12-09 19:32:19,843 INFO     Training average positive_sample_loss at step 20700: 0.007779\n",
      "2023-12-09 19:32:19,844 INFO     Training average negative_sample_loss at step 20700: 0.006492\n",
      "2023-12-09 19:32:19,844 INFO     Training average loss at step 20700: 0.007135\n",
      "2023-12-09 19:32:34,367 INFO     Training average positive_sample_loss at step 20800: 0.007976\n",
      "2023-12-09 19:32:34,368 INFO     Training average negative_sample_loss at step 20800: 0.006508\n",
      "2023-12-09 19:32:34,368 INFO     Training average loss at step 20800: 0.007242\n",
      "2023-12-09 19:32:47,948 INFO     Training average positive_sample_loss at step 20900: 0.008134\n",
      "2023-12-09 19:32:47,949 INFO     Training average negative_sample_loss at step 20900: 0.006058\n",
      "2023-12-09 19:32:47,949 INFO     Training average loss at step 20900: 0.007096\n",
      "2023-12-09 19:33:01,564 INFO     Training average positive_sample_loss at step 21000: 0.008193\n",
      "2023-12-09 19:33:01,565 INFO     Training average negative_sample_loss at step 21000: 0.006235\n",
      "2023-12-09 19:33:01,565 INFO     Training average loss at step 21000: 0.007214\n",
      "2023-12-09 19:33:18,926 INFO     Training average positive_sample_loss at step 21100: 0.007553\n",
      "2023-12-09 19:33:18,926 INFO     Training average negative_sample_loss at step 21100: 0.006480\n",
      "2023-12-09 19:33:18,926 INFO     Training average loss at step 21100: 0.007017\n",
      "2023-12-09 19:33:32,205 INFO     Training average positive_sample_loss at step 21200: 0.007497\n",
      "2023-12-09 19:33:32,205 INFO     Training average negative_sample_loss at step 21200: 0.006448\n",
      "2023-12-09 19:33:32,205 INFO     Training average loss at step 21200: 0.006972\n",
      "2023-12-09 19:33:46,699 INFO     Training average positive_sample_loss at step 21300: 0.007778\n",
      "2023-12-09 19:33:46,699 INFO     Training average negative_sample_loss at step 21300: 0.005822\n",
      "2023-12-09 19:33:46,699 INFO     Training average loss at step 21300: 0.006800\n",
      "2023-12-09 19:34:00,529 INFO     Training average positive_sample_loss at step 21400: 0.008011\n",
      "2023-12-09 19:34:00,529 INFO     Training average negative_sample_loss at step 21400: 0.006703\n",
      "2023-12-09 19:34:00,529 INFO     Training average loss at step 21400: 0.007357\n",
      "2023-12-09 19:34:13,737 INFO     Training average positive_sample_loss at step 21500: 0.007986\n",
      "2023-12-09 19:34:13,738 INFO     Training average negative_sample_loss at step 21500: 0.006309\n",
      "2023-12-09 19:34:13,738 INFO     Training average loss at step 21500: 0.007147\n",
      "2023-12-09 19:34:28,151 INFO     Training average positive_sample_loss at step 21600: 0.008027\n",
      "2023-12-09 19:34:28,151 INFO     Training average negative_sample_loss at step 21600: 0.006198\n",
      "2023-12-09 19:34:28,151 INFO     Training average loss at step 21600: 0.007112\n",
      "2023-12-09 19:34:45,154 INFO     Training average positive_sample_loss at step 21700: 0.007184\n",
      "2023-12-09 19:34:45,154 INFO     Training average negative_sample_loss at step 21700: 0.006472\n",
      "2023-12-09 19:34:45,154 INFO     Training average loss at step 21700: 0.006828\n",
      "2023-12-09 19:34:58,477 INFO     Training average positive_sample_loss at step 21800: 0.007651\n",
      "2023-12-09 19:34:58,478 INFO     Training average negative_sample_loss at step 21800: 0.006286\n",
      "2023-12-09 19:34:58,478 INFO     Training average loss at step 21800: 0.006968\n",
      "2023-12-09 19:35:13,655 INFO     Training average positive_sample_loss at step 21900: 0.007802\n",
      "2023-12-09 19:35:13,655 INFO     Training average negative_sample_loss at step 21900: 0.006655\n",
      "2023-12-09 19:35:13,655 INFO     Training average loss at step 21900: 0.007229\n",
      "2023-12-09 19:35:27,806 INFO     Training average positive_sample_loss at step 22000: 0.007958\n",
      "2023-12-09 19:35:27,806 INFO     Training average negative_sample_loss at step 22000: 0.006439\n",
      "2023-12-09 19:35:27,806 INFO     Training average loss at step 22000: 0.007199\n",
      "2023-12-09 19:35:41,690 INFO     Training average positive_sample_loss at step 22100: 0.007887\n",
      "2023-12-09 19:35:41,690 INFO     Training average negative_sample_loss at step 22100: 0.006310\n",
      "2023-12-09 19:35:41,690 INFO     Training average loss at step 22100: 0.007098\n",
      "2023-12-09 19:35:57,456 INFO     Training average positive_sample_loss at step 22200: 0.007569\n",
      "2023-12-09 19:35:57,456 INFO     Training average negative_sample_loss at step 22200: 0.006691\n",
      "2023-12-09 19:35:57,456 INFO     Training average loss at step 22200: 0.007130\n",
      "2023-12-09 19:36:12,006 INFO     Training average positive_sample_loss at step 22300: 0.007235\n",
      "2023-12-09 19:36:12,006 INFO     Training average negative_sample_loss at step 22300: 0.006532\n",
      "2023-12-09 19:36:12,006 INFO     Training average loss at step 22300: 0.006884\n",
      "2023-12-09 19:36:25,437 INFO     Training average positive_sample_loss at step 22400: 0.007788\n",
      "2023-12-09 19:36:25,437 INFO     Training average negative_sample_loss at step 22400: 0.006659\n",
      "2023-12-09 19:36:25,437 INFO     Training average loss at step 22400: 0.007224\n",
      "2023-12-09 19:36:39,276 INFO     Training average positive_sample_loss at step 22500: 0.007920\n",
      "2023-12-09 19:36:39,276 INFO     Training average negative_sample_loss at step 22500: 0.006719\n",
      "2023-12-09 19:36:39,276 INFO     Training average loss at step 22500: 0.007319\n",
      "2023-12-09 19:36:52,706 INFO     Training average positive_sample_loss at step 22600: 0.007971\n",
      "2023-12-09 19:36:52,707 INFO     Training average negative_sample_loss at step 22600: 0.006061\n",
      "2023-12-09 19:36:52,707 INFO     Training average loss at step 22600: 0.007016\n",
      "2023-12-09 19:37:07,512 INFO     Training average positive_sample_loss at step 22700: 0.007739\n",
      "2023-12-09 19:37:07,512 INFO     Training average negative_sample_loss at step 22700: 0.006298\n",
      "2023-12-09 19:37:07,512 INFO     Training average loss at step 22700: 0.007018\n",
      "2023-12-09 19:37:24,846 INFO     Training average positive_sample_loss at step 22800: 0.007035\n",
      "2023-12-09 19:37:24,846 INFO     Training average negative_sample_loss at step 22800: 0.006400\n",
      "2023-12-09 19:37:24,847 INFO     Training average loss at step 22800: 0.006717\n",
      "2023-12-09 19:37:38,697 INFO     Training average positive_sample_loss at step 22900: 0.007434\n",
      "2023-12-09 19:37:38,697 INFO     Training average negative_sample_loss at step 22900: 0.005845\n",
      "2023-12-09 19:37:38,697 INFO     Training average loss at step 22900: 0.006639\n",
      "2023-12-09 19:37:52,479 INFO     Training average positive_sample_loss at step 23000: 0.007773\n",
      "2023-12-09 19:37:52,479 INFO     Training average negative_sample_loss at step 23000: 0.006391\n",
      "2023-12-09 19:37:52,479 INFO     Training average loss at step 23000: 0.007082\n",
      "2023-12-09 19:38:05,851 INFO     Training average positive_sample_loss at step 23100: 0.007672\n",
      "2023-12-09 19:38:05,851 INFO     Training average negative_sample_loss at step 23100: 0.006060\n",
      "2023-12-09 19:38:05,851 INFO     Training average loss at step 23100: 0.006866\n",
      "2023-12-09 19:38:19,558 INFO     Training average positive_sample_loss at step 23200: 0.007774\n",
      "2023-12-09 19:38:19,559 INFO     Training average negative_sample_loss at step 23200: 0.006500\n",
      "2023-12-09 19:38:19,559 INFO     Training average loss at step 23200: 0.007137\n",
      "2023-12-09 19:38:36,788 INFO     Training average positive_sample_loss at step 23300: 0.007501\n",
      "2023-12-09 19:38:36,788 INFO     Training average negative_sample_loss at step 23300: 0.006693\n",
      "2023-12-09 19:38:36,788 INFO     Training average loss at step 23300: 0.007097\n",
      "2023-12-09 19:38:51,806 INFO     Training average positive_sample_loss at step 23400: 0.007134\n",
      "2023-12-09 19:38:51,806 INFO     Training average negative_sample_loss at step 23400: 0.006176\n",
      "2023-12-09 19:38:51,807 INFO     Training average loss at step 23400: 0.006655\n",
      "2023-12-09 19:39:05,970 INFO     Training average positive_sample_loss at step 23500: 0.007462\n",
      "2023-12-09 19:39:05,971 INFO     Training average negative_sample_loss at step 23500: 0.006672\n",
      "2023-12-09 19:39:05,971 INFO     Training average loss at step 23500: 0.007067\n",
      "2023-12-09 19:39:20,710 INFO     Training average positive_sample_loss at step 23600: 0.007685\n",
      "2023-12-09 19:39:20,711 INFO     Training average negative_sample_loss at step 23600: 0.006484\n",
      "2023-12-09 19:39:20,711 INFO     Training average loss at step 23600: 0.007085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:39:34,136 INFO     Training average positive_sample_loss at step 23700: 0.007688\n",
      "2023-12-09 19:39:34,136 INFO     Training average negative_sample_loss at step 23700: 0.005957\n",
      "2023-12-09 19:39:34,136 INFO     Training average loss at step 23700: 0.006822\n",
      "2023-12-09 19:39:48,305 INFO     Training average positive_sample_loss at step 23800: 0.007705\n",
      "2023-12-09 19:39:48,306 INFO     Training average negative_sample_loss at step 23800: 0.006852\n",
      "2023-12-09 19:39:48,306 INFO     Training average loss at step 23800: 0.007278\n",
      "2023-12-09 19:40:05,105 INFO     Training average positive_sample_loss at step 23900: 0.007034\n",
      "2023-12-09 19:40:05,105 INFO     Training average negative_sample_loss at step 23900: 0.006542\n",
      "2023-12-09 19:40:05,105 INFO     Training average loss at step 23900: 0.006788\n",
      "2023-12-09 19:40:18,409 INFO     Training average positive_sample_loss at step 24000: 0.007176\n",
      "2023-12-09 19:40:18,410 INFO     Training average negative_sample_loss at step 24000: 0.006056\n",
      "2023-12-09 19:40:18,410 INFO     Training average loss at step 24000: 0.006616\n",
      "2023-12-09 19:40:32,405 INFO     Training average positive_sample_loss at step 24100: 0.007462\n",
      "2023-12-09 19:40:32,406 INFO     Training average negative_sample_loss at step 24100: 0.006128\n",
      "2023-12-09 19:40:32,406 INFO     Training average loss at step 24100: 0.006795\n",
      "2023-12-09 19:40:46,856 INFO     Training average positive_sample_loss at step 24200: 0.007764\n",
      "2023-12-09 19:40:46,857 INFO     Training average negative_sample_loss at step 24200: 0.006215\n",
      "2023-12-09 19:40:46,857 INFO     Training average loss at step 24200: 0.006990\n",
      "2023-12-09 19:41:00,484 INFO     Training average positive_sample_loss at step 24300: 0.007639\n",
      "2023-12-09 19:41:00,484 INFO     Training average negative_sample_loss at step 24300: 0.006752\n",
      "2023-12-09 19:41:00,484 INFO     Training average loss at step 24300: 0.007195\n",
      "2023-12-09 19:41:17,971 INFO     Training average positive_sample_loss at step 24400: 0.007459\n",
      "2023-12-09 19:41:17,971 INFO     Training average negative_sample_loss at step 24400: 0.006419\n",
      "2023-12-09 19:41:17,971 INFO     Training average loss at step 24400: 0.006939\n",
      "2023-12-09 19:41:32,098 INFO     Training average positive_sample_loss at step 24500: 0.006937\n",
      "2023-12-09 19:41:32,099 INFO     Training average negative_sample_loss at step 24500: 0.006306\n",
      "2023-12-09 19:41:32,099 INFO     Training average loss at step 24500: 0.006622\n",
      "2023-12-09 19:41:45,674 INFO     Training average positive_sample_loss at step 24600: 0.007282\n",
      "2023-12-09 19:41:45,674 INFO     Training average negative_sample_loss at step 24600: 0.006285\n",
      "2023-12-09 19:41:45,674 INFO     Training average loss at step 24600: 0.006784\n",
      "2023-12-09 19:41:59,977 INFO     Training average positive_sample_loss at step 24700: 0.007591\n",
      "2023-12-09 19:41:59,977 INFO     Training average negative_sample_loss at step 24700: 0.006631\n",
      "2023-12-09 19:41:59,977 INFO     Training average loss at step 24700: 0.007111\n",
      "2023-12-09 19:42:14,121 INFO     Training average positive_sample_loss at step 24800: 0.007663\n",
      "2023-12-09 19:42:14,122 INFO     Training average negative_sample_loss at step 24800: 0.006232\n",
      "2023-12-09 19:42:14,122 INFO     Training average loss at step 24800: 0.006947\n",
      "2023-12-09 19:42:28,714 INFO     Training average positive_sample_loss at step 24900: 0.007553\n",
      "2023-12-09 19:42:28,715 INFO     Training average negative_sample_loss at step 24900: 0.006478\n",
      "2023-12-09 19:42:28,715 INFO     Training average loss at step 24900: 0.007015\n",
      "2023-12-09 19:42:45,929 INFO     Training average positive_sample_loss at step 25000: 0.007113\n",
      "2023-12-09 19:42:45,930 INFO     Training average negative_sample_loss at step 25000: 0.007092\n",
      "2023-12-09 19:42:45,930 INFO     Training average loss at step 25000: 0.007102\n",
      "2023-12-09 19:42:59,994 INFO     Training average positive_sample_loss at step 25100: 0.007206\n",
      "2023-12-09 19:42:59,994 INFO     Training average negative_sample_loss at step 25100: 0.006262\n",
      "2023-12-09 19:42:59,994 INFO     Training average loss at step 25100: 0.006734\n",
      "2023-12-09 19:43:14,101 INFO     Training average positive_sample_loss at step 25200: 0.007483\n",
      "2023-12-09 19:43:14,101 INFO     Training average negative_sample_loss at step 25200: 0.006675\n",
      "2023-12-09 19:43:14,102 INFO     Training average loss at step 25200: 0.007079\n",
      "2023-12-09 19:43:28,538 INFO     Training average positive_sample_loss at step 25300: 0.007425\n",
      "2023-12-09 19:43:28,538 INFO     Training average negative_sample_loss at step 25300: 0.005918\n",
      "2023-12-09 19:43:28,538 INFO     Training average loss at step 25300: 0.006672\n",
      "2023-12-09 19:43:42,507 INFO     Training average positive_sample_loss at step 25400: 0.007586\n",
      "2023-12-09 19:43:42,507 INFO     Training average negative_sample_loss at step 25400: 0.006632\n",
      "2023-12-09 19:43:42,507 INFO     Training average loss at step 25400: 0.007109\n",
      "2023-12-09 19:43:58,971 INFO     Training average positive_sample_loss at step 25500: 0.007357\n",
      "2023-12-09 19:43:58,971 INFO     Training average negative_sample_loss at step 25500: 0.006175\n",
      "2023-12-09 19:43:58,971 INFO     Training average loss at step 25500: 0.006766\n",
      "2023-12-09 19:44:13,899 INFO     Training average positive_sample_loss at step 25600: 0.006772\n",
      "2023-12-09 19:44:13,900 INFO     Training average negative_sample_loss at step 25600: 0.007033\n",
      "2023-12-09 19:44:13,900 INFO     Training average loss at step 25600: 0.006902\n",
      "2023-12-09 19:44:27,629 INFO     Training average positive_sample_loss at step 25700: 0.007342\n",
      "2023-12-09 19:44:27,629 INFO     Training average negative_sample_loss at step 25700: 0.006458\n",
      "2023-12-09 19:44:27,630 INFO     Training average loss at step 25700: 0.006900\n",
      "2023-12-09 19:44:40,680 INFO     Training average positive_sample_loss at step 25800: 0.007486\n",
      "2023-12-09 19:44:40,680 INFO     Training average negative_sample_loss at step 25800: 0.006489\n",
      "2023-12-09 19:44:40,680 INFO     Training average loss at step 25800: 0.006987\n",
      "2023-12-09 19:44:54,326 INFO     Training average positive_sample_loss at step 25900: 0.007556\n",
      "2023-12-09 19:44:54,327 INFO     Training average negative_sample_loss at step 25900: 0.006663\n",
      "2023-12-09 19:44:54,327 INFO     Training average loss at step 25900: 0.007109\n",
      "2023-12-09 19:45:08,225 INFO     Training average positive_sample_loss at step 26000: 0.007638\n",
      "2023-12-09 19:45:08,225 INFO     Training average negative_sample_loss at step 26000: 0.006583\n",
      "2023-12-09 19:45:08,225 INFO     Training average loss at step 26000: 0.007111\n",
      "2023-12-09 19:45:24,797 INFO     Training average positive_sample_loss at step 26100: 0.006929\n",
      "2023-12-09 19:45:24,797 INFO     Training average negative_sample_loss at step 26100: 0.006422\n",
      "2023-12-09 19:45:24,797 INFO     Training average loss at step 26100: 0.006675\n",
      "2023-12-09 19:45:39,028 INFO     Training average positive_sample_loss at step 26200: 0.007071\n",
      "2023-12-09 19:45:39,029 INFO     Training average negative_sample_loss at step 26200: 0.006473\n",
      "2023-12-09 19:45:39,029 INFO     Training average loss at step 26200: 0.006772\n",
      "2023-12-09 19:45:53,165 INFO     Training average positive_sample_loss at step 26300: 0.007369\n",
      "2023-12-09 19:45:53,166 INFO     Training average negative_sample_loss at step 26300: 0.005914\n",
      "2023-12-09 19:45:53,166 INFO     Training average loss at step 26300: 0.006641\n",
      "2023-12-09 19:46:07,197 INFO     Training average positive_sample_loss at step 26400: 0.007443\n",
      "2023-12-09 19:46:07,198 INFO     Training average negative_sample_loss at step 26400: 0.006546\n",
      "2023-12-09 19:46:07,198 INFO     Training average loss at step 26400: 0.006994\n",
      "2023-12-09 19:46:20,398 INFO     Training average positive_sample_loss at step 26500: 0.007601\n",
      "2023-12-09 19:46:20,398 INFO     Training average negative_sample_loss at step 26500: 0.006276\n",
      "2023-12-09 19:46:20,398 INFO     Training average loss at step 26500: 0.006939\n",
      "2023-12-09 19:46:37,276 INFO     Training average positive_sample_loss at step 26600: 0.007233\n",
      "2023-12-09 19:46:37,276 INFO     Training average negative_sample_loss at step 26600: 0.006702\n",
      "2023-12-09 19:46:37,276 INFO     Training average loss at step 26600: 0.006968\n",
      "2023-12-09 19:46:52,663 INFO     Training average positive_sample_loss at step 26700: 0.006715\n",
      "2023-12-09 19:46:52,664 INFO     Training average negative_sample_loss at step 26700: 0.006030\n",
      "2023-12-09 19:46:52,664 INFO     Training average loss at step 26700: 0.006372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:47:05,993 INFO     Training average positive_sample_loss at step 26800: 0.007137\n",
      "2023-12-09 19:47:05,994 INFO     Training average negative_sample_loss at step 26800: 0.006302\n",
      "2023-12-09 19:47:05,994 INFO     Training average loss at step 26800: 0.006720\n",
      "2023-12-09 19:47:19,668 INFO     Training average positive_sample_loss at step 26900: 0.007292\n",
      "2023-12-09 19:47:19,668 INFO     Training average negative_sample_loss at step 26900: 0.006577\n",
      "2023-12-09 19:47:19,668 INFO     Training average loss at step 26900: 0.006935\n",
      "2023-12-09 19:47:33,785 INFO     Training average positive_sample_loss at step 27000: 0.007455\n",
      "2023-12-09 19:47:33,785 INFO     Training average negative_sample_loss at step 27000: 0.006715\n",
      "2023-12-09 19:47:33,785 INFO     Training average loss at step 27000: 0.007085\n",
      "2023-12-09 19:47:47,788 INFO     Training average positive_sample_loss at step 27100: 0.007479\n",
      "2023-12-09 19:47:47,789 INFO     Training average negative_sample_loss at step 27100: 0.006439\n",
      "2023-12-09 19:47:47,789 INFO     Training average loss at step 27100: 0.006959\n",
      "2023-12-09 19:48:04,321 INFO     Training average positive_sample_loss at step 27200: 0.006844\n",
      "2023-12-09 19:48:04,322 INFO     Training average negative_sample_loss at step 27200: 0.006685\n",
      "2023-12-09 19:48:04,322 INFO     Training average loss at step 27200: 0.006765\n",
      "2023-12-09 19:48:18,102 INFO     Training average positive_sample_loss at step 27300: 0.006899\n",
      "2023-12-09 19:48:18,102 INFO     Training average negative_sample_loss at step 27300: 0.006127\n",
      "2023-12-09 19:48:18,102 INFO     Training average loss at step 27300: 0.006513\n",
      "2023-12-09 19:48:30,885 INFO     Training average positive_sample_loss at step 27400: 0.007256\n",
      "2023-12-09 19:48:30,885 INFO     Training average negative_sample_loss at step 27400: 0.006033\n",
      "2023-12-09 19:48:30,885 INFO     Training average loss at step 27400: 0.006644\n",
      "2023-12-09 19:48:44,780 INFO     Training average positive_sample_loss at step 27500: 0.007400\n",
      "2023-12-09 19:48:44,781 INFO     Training average negative_sample_loss at step 27500: 0.006363\n",
      "2023-12-09 19:48:44,781 INFO     Training average loss at step 27500: 0.006882\n",
      "2023-12-09 19:48:58,186 INFO     Training average positive_sample_loss at step 27600: 0.007398\n",
      "2023-12-09 19:48:58,186 INFO     Training average negative_sample_loss at step 27600: 0.006395\n",
      "2023-12-09 19:48:58,186 INFO     Training average loss at step 27600: 0.006896\n",
      "2023-12-09 19:49:12,626 INFO     Training average positive_sample_loss at step 27700: 0.007360\n",
      "2023-12-09 19:49:12,626 INFO     Training average negative_sample_loss at step 27700: 0.006707\n",
      "2023-12-09 19:49:12,626 INFO     Training average loss at step 27700: 0.007033\n",
      "2023-12-09 19:49:28,908 INFO     Training average positive_sample_loss at step 27800: 0.006634\n",
      "2023-12-09 19:49:28,908 INFO     Training average negative_sample_loss at step 27800: 0.006716\n",
      "2023-12-09 19:49:28,909 INFO     Training average loss at step 27800: 0.006675\n",
      "2023-12-09 19:49:42,332 INFO     Training average positive_sample_loss at step 27900: 0.006980\n",
      "2023-12-09 19:49:42,332 INFO     Training average negative_sample_loss at step 27900: 0.006353\n",
      "2023-12-09 19:49:42,332 INFO     Training average loss at step 27900: 0.006667\n",
      "2023-12-09 19:49:55,816 INFO     Training average positive_sample_loss at step 28000: 0.007309\n",
      "2023-12-09 19:49:55,816 INFO     Training average negative_sample_loss at step 28000: 0.006249\n",
      "2023-12-09 19:49:55,816 INFO     Training average loss at step 28000: 0.006779\n",
      "2023-12-09 19:50:09,779 INFO     Training average positive_sample_loss at step 28100: 0.007398\n",
      "2023-12-09 19:50:09,780 INFO     Training average negative_sample_loss at step 28100: 0.005940\n",
      "2023-12-09 19:50:09,780 INFO     Training average loss at step 28100: 0.006669\n",
      "2023-12-09 19:50:26,597 INFO     Training average positive_sample_loss at step 28200: 0.007389\n",
      "2023-12-09 19:50:26,598 INFO     Training average negative_sample_loss at step 28200: 0.006189\n",
      "2023-12-09 19:50:26,598 INFO     Training average loss at step 28200: 0.006789\n",
      "2023-12-09 19:50:44,254 INFO     Training average positive_sample_loss at step 28300: 0.006801\n",
      "2023-12-09 19:50:44,254 INFO     Training average negative_sample_loss at step 28300: 0.006727\n",
      "2023-12-09 19:50:44,255 INFO     Training average loss at step 28300: 0.006764\n",
      "2023-12-09 19:50:59,279 INFO     Training average positive_sample_loss at step 28400: 0.006760\n",
      "2023-12-09 19:50:59,280 INFO     Training average negative_sample_loss at step 28400: 0.006007\n",
      "2023-12-09 19:50:59,280 INFO     Training average loss at step 28400: 0.006383\n",
      "2023-12-09 19:51:13,952 INFO     Training average positive_sample_loss at step 28500: 0.007193\n",
      "2023-12-09 19:51:13,952 INFO     Training average negative_sample_loss at step 28500: 0.005855\n",
      "2023-12-09 19:51:13,952 INFO     Training average loss at step 28500: 0.006524\n",
      "2023-12-09 19:51:27,731 INFO     Training average positive_sample_loss at step 28600: 0.007395\n",
      "2023-12-09 19:51:27,732 INFO     Training average negative_sample_loss at step 28600: 0.006669\n",
      "2023-12-09 19:51:27,732 INFO     Training average loss at step 28600: 0.007032\n",
      "2023-12-09 19:51:40,880 INFO     Training average positive_sample_loss at step 28700: 0.007308\n",
      "2023-12-09 19:51:40,880 INFO     Training average negative_sample_loss at step 28700: 0.006735\n",
      "2023-12-09 19:51:40,881 INFO     Training average loss at step 28700: 0.007022\n",
      "2023-12-09 19:51:54,929 INFO     Training average positive_sample_loss at step 28800: 0.007410\n",
      "2023-12-09 19:51:54,929 INFO     Training average negative_sample_loss at step 28800: 0.007257\n",
      "2023-12-09 19:51:54,929 INFO     Training average loss at step 28800: 0.007333\n",
      "2023-12-09 19:52:11,614 INFO     Training average positive_sample_loss at step 28900: 0.006744\n",
      "2023-12-09 19:52:11,615 INFO     Training average negative_sample_loss at step 28900: 0.006646\n",
      "2023-12-09 19:52:11,615 INFO     Training average loss at step 28900: 0.006695\n",
      "2023-12-09 19:52:26,188 INFO     Training average positive_sample_loss at step 29000: 0.006924\n",
      "2023-12-09 19:52:26,188 INFO     Training average negative_sample_loss at step 29000: 0.006298\n",
      "2023-12-09 19:52:26,188 INFO     Training average loss at step 29000: 0.006611\n",
      "2023-12-09 19:52:40,556 INFO     Training average positive_sample_loss at step 29100: 0.007326\n",
      "2023-12-09 19:52:40,556 INFO     Training average negative_sample_loss at step 29100: 0.006030\n",
      "2023-12-09 19:52:40,556 INFO     Training average loss at step 29100: 0.006678\n",
      "2023-12-09 19:52:55,320 INFO     Training average positive_sample_loss at step 29200: 0.007225\n",
      "2023-12-09 19:52:55,320 INFO     Training average negative_sample_loss at step 29200: 0.006465\n",
      "2023-12-09 19:52:55,320 INFO     Training average loss at step 29200: 0.006845\n",
      "2023-12-09 19:53:09,655 INFO     Training average positive_sample_loss at step 29300: 0.007367\n",
      "2023-12-09 19:53:09,655 INFO     Training average negative_sample_loss at step 29300: 0.006463\n",
      "2023-12-09 19:53:09,655 INFO     Training average loss at step 29300: 0.006915\n",
      "2023-12-09 19:53:26,642 INFO     Training average positive_sample_loss at step 29400: 0.006903\n",
      "2023-12-09 19:53:26,642 INFO     Training average negative_sample_loss at step 29400: 0.006442\n",
      "2023-12-09 19:53:26,642 INFO     Training average loss at step 29400: 0.006672\n",
      "2023-12-09 19:53:40,563 INFO     Training average positive_sample_loss at step 29500: 0.006728\n",
      "2023-12-09 19:53:40,563 INFO     Training average negative_sample_loss at step 29500: 0.006274\n",
      "2023-12-09 19:53:40,563 INFO     Training average loss at step 29500: 0.006501\n",
      "2023-12-09 19:53:53,504 INFO     Training average positive_sample_loss at step 29600: 0.006969\n",
      "2023-12-09 19:53:53,505 INFO     Training average negative_sample_loss at step 29600: 0.006080\n",
      "2023-12-09 19:53:53,505 INFO     Training average loss at step 29600: 0.006524\n",
      "2023-12-09 19:54:07,328 INFO     Training average positive_sample_loss at step 29700: 0.007200\n",
      "2023-12-09 19:54:07,329 INFO     Training average negative_sample_loss at step 29700: 0.006090\n",
      "2023-12-09 19:54:07,329 INFO     Training average loss at step 29700: 0.006645\n",
      "2023-12-09 19:54:21,571 INFO     Training average positive_sample_loss at step 29800: 0.007280\n",
      "2023-12-09 19:54:21,572 INFO     Training average negative_sample_loss at step 29800: 0.006752\n",
      "2023-12-09 19:54:21,572 INFO     Training average loss at step 29800: 0.007016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 19:54:35,879 INFO     Training average positive_sample_loss at step 29900: 0.007226\n",
      "2023-12-09 19:54:35,879 INFO     Training average negative_sample_loss at step 29900: 0.006466\n",
      "2023-12-09 19:54:35,879 INFO     Training average loss at step 29900: 0.006846\n",
      "2023-12-09 19:55:10,931 INFO     Training average positive_sample_loss at step 30000: 0.006457\n",
      "2023-12-09 19:55:10,931 INFO     Training average negative_sample_loss at step 30000: 0.006469\n",
      "2023-12-09 19:55:10,931 INFO     Training average loss at step 30000: 0.006463\n",
      "2023-12-09 19:55:10,931 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 19:55:11,633 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 19:56:04,835 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 19:56:18,294 INFO     Valid MRR at step 30000: 0.948886\n",
      "2023-12-09 19:56:18,294 INFO     Valid MR at step 30000: 322.221600\n",
      "2023-12-09 19:56:18,294 INFO     Valid HITS@1 at step 30000: 0.943800\n",
      "2023-12-09 19:56:18,294 INFO     Valid HITS@3 at step 30000: 0.951300\n",
      "2023-12-09 19:56:18,294 INFO     Valid HITS@10 at step 30000: 0.957500\n",
      "2023-12-09 19:56:32,219 INFO     Training average positive_sample_loss at step 30100: 0.006867\n",
      "2023-12-09 19:56:32,220 INFO     Training average negative_sample_loss at step 30100: 0.006296\n",
      "2023-12-09 19:56:32,220 INFO     Training average loss at step 30100: 0.006581\n",
      "2023-12-09 19:56:46,204 INFO     Training average positive_sample_loss at step 30200: 0.007197\n",
      "2023-12-09 19:56:46,205 INFO     Training average negative_sample_loss at step 30200: 0.006120\n",
      "2023-12-09 19:56:46,205 INFO     Training average loss at step 30200: 0.006659\n",
      "2023-12-09 19:57:01,202 INFO     Training average positive_sample_loss at step 30300: 0.007187\n",
      "2023-12-09 19:57:01,203 INFO     Training average negative_sample_loss at step 30300: 0.006665\n",
      "2023-12-09 19:57:01,203 INFO     Training average loss at step 30300: 0.006926\n",
      "2023-12-09 19:57:15,218 INFO     Training average positive_sample_loss at step 30400: 0.007309\n",
      "2023-12-09 19:57:15,218 INFO     Training average negative_sample_loss at step 30400: 0.006398\n",
      "2023-12-09 19:57:15,218 INFO     Training average loss at step 30400: 0.006853\n",
      "2023-12-09 19:57:31,124 INFO     Training average positive_sample_loss at step 30500: 0.006868\n",
      "2023-12-09 19:57:31,124 INFO     Training average negative_sample_loss at step 30500: 0.006439\n",
      "2023-12-09 19:57:31,124 INFO     Training average loss at step 30500: 0.006654\n",
      "2023-12-09 19:57:45,080 INFO     Training average positive_sample_loss at step 30600: 0.006609\n",
      "2023-12-09 19:57:45,080 INFO     Training average negative_sample_loss at step 30600: 0.006904\n",
      "2023-12-09 19:57:45,080 INFO     Training average loss at step 30600: 0.006757\n",
      "2023-12-09 19:57:59,084 INFO     Training average positive_sample_loss at step 30700: 0.006980\n",
      "2023-12-09 19:57:59,085 INFO     Training average negative_sample_loss at step 30700: 0.006208\n",
      "2023-12-09 19:57:59,085 INFO     Training average loss at step 30700: 0.006594\n",
      "2023-12-09 19:58:11,687 INFO     Training average positive_sample_loss at step 30800: 0.007288\n",
      "2023-12-09 19:58:11,687 INFO     Training average negative_sample_loss at step 30800: 0.006617\n",
      "2023-12-09 19:58:11,687 INFO     Training average loss at step 30800: 0.006953\n",
      "2023-12-09 19:58:25,893 INFO     Training average positive_sample_loss at step 30900: 0.007198\n",
      "2023-12-09 19:58:25,893 INFO     Training average negative_sample_loss at step 30900: 0.006216\n",
      "2023-12-09 19:58:25,893 INFO     Training average loss at step 30900: 0.006707\n",
      "2023-12-09 19:58:40,881 INFO     Training average positive_sample_loss at step 31000: 0.007235\n",
      "2023-12-09 19:58:40,882 INFO     Training average negative_sample_loss at step 31000: 0.006308\n",
      "2023-12-09 19:58:40,882 INFO     Training average loss at step 31000: 0.006772\n",
      "2023-12-09 19:58:57,750 INFO     Training average positive_sample_loss at step 31100: 0.006647\n",
      "2023-12-09 19:58:57,751 INFO     Training average negative_sample_loss at step 31100: 0.006585\n",
      "2023-12-09 19:58:57,751 INFO     Training average loss at step 31100: 0.006616\n",
      "2023-12-09 19:59:11,574 INFO     Training average positive_sample_loss at step 31200: 0.006750\n",
      "2023-12-09 19:59:11,574 INFO     Training average negative_sample_loss at step 31200: 0.006229\n",
      "2023-12-09 19:59:11,574 INFO     Training average loss at step 31200: 0.006490\n",
      "2023-12-09 19:59:25,465 INFO     Training average positive_sample_loss at step 31300: 0.007080\n",
      "2023-12-09 19:59:25,466 INFO     Training average negative_sample_loss at step 31300: 0.006824\n",
      "2023-12-09 19:59:25,466 INFO     Training average loss at step 31300: 0.006952\n",
      "2023-12-09 19:59:39,425 INFO     Training average positive_sample_loss at step 31400: 0.007185\n",
      "2023-12-09 19:59:39,425 INFO     Training average negative_sample_loss at step 31400: 0.006545\n",
      "2023-12-09 19:59:39,425 INFO     Training average loss at step 31400: 0.006865\n",
      "2023-12-09 19:59:53,200 INFO     Training average positive_sample_loss at step 31500: 0.007251\n",
      "2023-12-09 19:59:53,200 INFO     Training average negative_sample_loss at step 31500: 0.005708\n",
      "2023-12-09 19:59:53,200 INFO     Training average loss at step 31500: 0.006480\n",
      "2023-12-09 20:00:10,619 INFO     Training average positive_sample_loss at step 31600: 0.006961\n",
      "2023-12-09 20:00:10,620 INFO     Training average negative_sample_loss at step 31600: 0.006501\n",
      "2023-12-09 20:00:10,620 INFO     Training average loss at step 31600: 0.006731\n",
      "2023-12-09 20:00:24,131 INFO     Training average positive_sample_loss at step 31700: 0.006522\n",
      "2023-12-09 20:00:24,132 INFO     Training average negative_sample_loss at step 31700: 0.006779\n",
      "2023-12-09 20:00:24,132 INFO     Training average loss at step 31700: 0.006650\n",
      "2023-12-09 20:00:38,551 INFO     Training average positive_sample_loss at step 31800: 0.006935\n",
      "2023-12-09 20:00:38,551 INFO     Training average negative_sample_loss at step 31800: 0.006580\n",
      "2023-12-09 20:00:38,551 INFO     Training average loss at step 31800: 0.006757\n",
      "2023-12-09 20:00:52,511 INFO     Training average positive_sample_loss at step 31900: 0.007075\n",
      "2023-12-09 20:00:52,512 INFO     Training average negative_sample_loss at step 31900: 0.006628\n",
      "2023-12-09 20:00:52,512 INFO     Training average loss at step 31900: 0.006852\n",
      "2023-12-09 20:01:06,389 INFO     Training average positive_sample_loss at step 32000: 0.007228\n",
      "2023-12-09 20:01:06,389 INFO     Training average negative_sample_loss at step 32000: 0.006514\n",
      "2023-12-09 20:01:06,389 INFO     Training average loss at step 32000: 0.006871\n",
      "2023-12-09 20:01:20,105 INFO     Training average positive_sample_loss at step 32100: 0.007191\n",
      "2023-12-09 20:01:20,106 INFO     Training average negative_sample_loss at step 32100: 0.006925\n",
      "2023-12-09 20:01:20,106 INFO     Training average loss at step 32100: 0.007058\n",
      "2023-12-09 20:01:37,772 INFO     Training average positive_sample_loss at step 32200: 0.006668\n",
      "2023-12-09 20:01:37,772 INFO     Training average negative_sample_loss at step 32200: 0.006331\n",
      "2023-12-09 20:01:37,773 INFO     Training average loss at step 32200: 0.006500\n",
      "2023-12-09 20:01:51,269 INFO     Training average positive_sample_loss at step 32300: 0.006770\n",
      "2023-12-09 20:01:51,269 INFO     Training average negative_sample_loss at step 32300: 0.006422\n",
      "2023-12-09 20:01:51,269 INFO     Training average loss at step 32300: 0.006596\n",
      "2023-12-09 20:02:04,258 INFO     Training average positive_sample_loss at step 32400: 0.007024\n",
      "2023-12-09 20:02:04,258 INFO     Training average negative_sample_loss at step 32400: 0.006311\n",
      "2023-12-09 20:02:04,258 INFO     Training average loss at step 32400: 0.006667\n",
      "2023-12-09 20:02:18,347 INFO     Training average positive_sample_loss at step 32500: 0.007139\n",
      "2023-12-09 20:02:18,347 INFO     Training average negative_sample_loss at step 32500: 0.006953\n",
      "2023-12-09 20:02:18,347 INFO     Training average loss at step 32500: 0.007046\n",
      "2023-12-09 20:02:32,846 INFO     Training average positive_sample_loss at step 32600: 0.007191\n",
      "2023-12-09 20:02:32,847 INFO     Training average negative_sample_loss at step 32600: 0.006415\n",
      "2023-12-09 20:02:32,847 INFO     Training average loss at step 32600: 0.006803\n",
      "2023-12-09 20:02:49,277 INFO     Training average positive_sample_loss at step 32700: 0.006930\n",
      "2023-12-09 20:02:49,278 INFO     Training average negative_sample_loss at step 32700: 0.006532\n",
      "2023-12-09 20:02:49,278 INFO     Training average loss at step 32700: 0.006731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:03:03,446 INFO     Training average positive_sample_loss at step 32800: 0.006571\n",
      "2023-12-09 20:03:03,447 INFO     Training average negative_sample_loss at step 32800: 0.006769\n",
      "2023-12-09 20:03:03,447 INFO     Training average loss at step 32800: 0.006670\n",
      "2023-12-09 20:03:17,280 INFO     Training average positive_sample_loss at step 32900: 0.006913\n",
      "2023-12-09 20:03:17,280 INFO     Training average negative_sample_loss at step 32900: 0.006260\n",
      "2023-12-09 20:03:17,280 INFO     Training average loss at step 32900: 0.006587\n",
      "2023-12-09 20:03:30,534 INFO     Training average positive_sample_loss at step 33000: 0.007158\n",
      "2023-12-09 20:03:30,534 INFO     Training average negative_sample_loss at step 33000: 0.007204\n",
      "2023-12-09 20:03:30,535 INFO     Training average loss at step 33000: 0.007181\n",
      "2023-12-09 20:03:44,843 INFO     Training average positive_sample_loss at step 33100: 0.007124\n",
      "2023-12-09 20:03:44,843 INFO     Training average negative_sample_loss at step 33100: 0.006736\n",
      "2023-12-09 20:03:44,843 INFO     Training average loss at step 33100: 0.006930\n",
      "2023-12-09 20:03:58,963 INFO     Training average positive_sample_loss at step 33200: 0.007247\n",
      "2023-12-09 20:03:58,964 INFO     Training average negative_sample_loss at step 33200: 0.006580\n",
      "2023-12-09 20:03:58,964 INFO     Training average loss at step 33200: 0.006913\n",
      "2023-12-09 20:04:15,890 INFO     Training average positive_sample_loss at step 33300: 0.006679\n",
      "2023-12-09 20:04:15,890 INFO     Training average negative_sample_loss at step 33300: 0.006829\n",
      "2023-12-09 20:04:15,890 INFO     Training average loss at step 33300: 0.006754\n",
      "2023-12-09 20:04:30,144 INFO     Training average positive_sample_loss at step 33400: 0.006665\n",
      "2023-12-09 20:04:30,144 INFO     Training average negative_sample_loss at step 33400: 0.006085\n",
      "2023-12-09 20:04:30,144 INFO     Training average loss at step 33400: 0.006375\n",
      "2023-12-09 20:04:43,934 INFO     Training average positive_sample_loss at step 33500: 0.006880\n",
      "2023-12-09 20:04:43,934 INFO     Training average negative_sample_loss at step 33500: 0.006302\n",
      "2023-12-09 20:04:43,934 INFO     Training average loss at step 33500: 0.006591\n",
      "2023-12-09 20:04:56,763 INFO     Training average positive_sample_loss at step 33600: 0.006938\n",
      "2023-12-09 20:04:56,763 INFO     Training average negative_sample_loss at step 33600: 0.006341\n",
      "2023-12-09 20:04:56,763 INFO     Training average loss at step 33600: 0.006640\n",
      "2023-12-09 20:05:10,992 INFO     Training average positive_sample_loss at step 33700: 0.007150\n",
      "2023-12-09 20:05:10,992 INFO     Training average negative_sample_loss at step 33700: 0.006728\n",
      "2023-12-09 20:05:10,992 INFO     Training average loss at step 33700: 0.006939\n",
      "2023-12-09 20:05:28,889 INFO     Training average positive_sample_loss at step 33800: 0.007087\n",
      "2023-12-09 20:05:28,889 INFO     Training average negative_sample_loss at step 33800: 0.006041\n",
      "2023-12-09 20:05:28,889 INFO     Training average loss at step 33800: 0.006564\n",
      "2023-12-09 20:05:42,436 INFO     Training average positive_sample_loss at step 33900: 0.006378\n",
      "2023-12-09 20:05:42,437 INFO     Training average negative_sample_loss at step 33900: 0.006852\n",
      "2023-12-09 20:05:42,437 INFO     Training average loss at step 33900: 0.006615\n",
      "2023-12-09 20:05:57,083 INFO     Training average positive_sample_loss at step 34000: 0.006807\n",
      "2023-12-09 20:05:57,083 INFO     Training average negative_sample_loss at step 34000: 0.005718\n",
      "2023-12-09 20:05:57,083 INFO     Training average loss at step 34000: 0.006263\n",
      "2023-12-09 20:06:11,090 INFO     Training average positive_sample_loss at step 34100: 0.006977\n",
      "2023-12-09 20:06:11,090 INFO     Training average negative_sample_loss at step 34100: 0.006544\n",
      "2023-12-09 20:06:11,090 INFO     Training average loss at step 34100: 0.006760\n",
      "2023-12-09 20:06:25,377 INFO     Training average positive_sample_loss at step 34200: 0.007017\n",
      "2023-12-09 20:06:25,378 INFO     Training average negative_sample_loss at step 34200: 0.006797\n",
      "2023-12-09 20:06:25,378 INFO     Training average loss at step 34200: 0.006907\n",
      "2023-12-09 20:06:39,534 INFO     Training average positive_sample_loss at step 34300: 0.007116\n",
      "2023-12-09 20:06:39,534 INFO     Training average negative_sample_loss at step 34300: 0.006097\n",
      "2023-12-09 20:06:39,534 INFO     Training average loss at step 34300: 0.006607\n",
      "2023-12-09 20:06:56,542 INFO     Training average positive_sample_loss at step 34400: 0.006555\n",
      "2023-12-09 20:06:56,542 INFO     Training average negative_sample_loss at step 34400: 0.006434\n",
      "2023-12-09 20:06:56,542 INFO     Training average loss at step 34400: 0.006495\n",
      "2023-12-09 20:07:10,022 INFO     Training average positive_sample_loss at step 34500: 0.006561\n",
      "2023-12-09 20:07:10,022 INFO     Training average negative_sample_loss at step 34500: 0.006437\n",
      "2023-12-09 20:07:10,022 INFO     Training average loss at step 34500: 0.006499\n",
      "2023-12-09 20:07:24,615 INFO     Training average positive_sample_loss at step 34600: 0.006909\n",
      "2023-12-09 20:07:24,616 INFO     Training average negative_sample_loss at step 34600: 0.006334\n",
      "2023-12-09 20:07:24,616 INFO     Training average loss at step 34600: 0.006621\n",
      "2023-12-09 20:07:38,609 INFO     Training average positive_sample_loss at step 34700: 0.007076\n",
      "2023-12-09 20:07:38,609 INFO     Training average negative_sample_loss at step 34700: 0.006576\n",
      "2023-12-09 20:07:38,609 INFO     Training average loss at step 34700: 0.006826\n",
      "2023-12-09 20:07:52,204 INFO     Training average positive_sample_loss at step 34800: 0.007051\n",
      "2023-12-09 20:07:52,205 INFO     Training average negative_sample_loss at step 34800: 0.006402\n",
      "2023-12-09 20:07:52,205 INFO     Training average loss at step 34800: 0.006726\n",
      "2023-12-09 20:08:05,053 INFO     Training average positive_sample_loss at step 34900: 0.007076\n",
      "2023-12-09 20:08:05,053 INFO     Training average negative_sample_loss at step 34900: 0.006484\n",
      "2023-12-09 20:08:05,054 INFO     Training average loss at step 34900: 0.006780\n",
      "2023-12-09 20:08:21,967 INFO     Training average positive_sample_loss at step 35000: 0.006356\n",
      "2023-12-09 20:08:21,967 INFO     Training average negative_sample_loss at step 35000: 0.006585\n",
      "2023-12-09 20:08:21,967 INFO     Training average loss at step 35000: 0.006471\n",
      "2023-12-09 20:08:35,404 INFO     Training average positive_sample_loss at step 35100: 0.006822\n",
      "2023-12-09 20:08:35,404 INFO     Training average negative_sample_loss at step 35100: 0.006693\n",
      "2023-12-09 20:08:35,404 INFO     Training average loss at step 35100: 0.006758\n",
      "2023-12-09 20:08:49,264 INFO     Training average positive_sample_loss at step 35200: 0.007009\n",
      "2023-12-09 20:08:49,265 INFO     Training average negative_sample_loss at step 35200: 0.006668\n",
      "2023-12-09 20:08:49,265 INFO     Training average loss at step 35200: 0.006839\n",
      "2023-12-09 20:09:03,655 INFO     Training average positive_sample_loss at step 35300: 0.007104\n",
      "2023-12-09 20:09:03,655 INFO     Training average negative_sample_loss at step 35300: 0.006033\n",
      "2023-12-09 20:09:03,655 INFO     Training average loss at step 35300: 0.006569\n",
      "2023-12-09 20:09:17,899 INFO     Training average positive_sample_loss at step 35400: 0.007198\n",
      "2023-12-09 20:09:17,899 INFO     Training average negative_sample_loss at step 35400: 0.006978\n",
      "2023-12-09 20:09:17,899 INFO     Training average loss at step 35400: 0.007088\n",
      "2023-12-09 20:09:34,234 INFO     Training average positive_sample_loss at step 35500: 0.006707\n",
      "2023-12-09 20:09:34,234 INFO     Training average negative_sample_loss at step 35500: 0.006713\n",
      "2023-12-09 20:09:34,235 INFO     Training average loss at step 35500: 0.006710\n",
      "2023-12-09 20:09:48,266 INFO     Training average positive_sample_loss at step 35600: 0.006666\n",
      "2023-12-09 20:09:48,266 INFO     Training average negative_sample_loss at step 35600: 0.006391\n",
      "2023-12-09 20:09:48,266 INFO     Training average loss at step 35600: 0.006528\n",
      "2023-12-09 20:10:02,218 INFO     Training average positive_sample_loss at step 35700: 0.006866\n",
      "2023-12-09 20:10:02,218 INFO     Training average negative_sample_loss at step 35700: 0.006906\n",
      "2023-12-09 20:10:02,218 INFO     Training average loss at step 35700: 0.006886\n",
      "2023-12-09 20:10:16,625 INFO     Training average positive_sample_loss at step 35800: 0.007013\n",
      "2023-12-09 20:10:16,625 INFO     Training average negative_sample_loss at step 35800: 0.005960\n",
      "2023-12-09 20:10:16,625 INFO     Training average loss at step 35800: 0.006487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:10:30,091 INFO     Training average positive_sample_loss at step 35900: 0.007071\n",
      "2023-12-09 20:10:30,091 INFO     Training average negative_sample_loss at step 35900: 0.006447\n",
      "2023-12-09 20:10:30,091 INFO     Training average loss at step 35900: 0.006759\n",
      "2023-12-09 20:10:44,824 INFO     Training average positive_sample_loss at step 36000: 0.006891\n",
      "2023-12-09 20:10:44,824 INFO     Training average negative_sample_loss at step 36000: 0.006651\n",
      "2023-12-09 20:10:44,824 INFO     Training average loss at step 36000: 0.006771\n",
      "2023-12-09 20:11:02,473 INFO     Training average positive_sample_loss at step 36100: 0.006403\n",
      "2023-12-09 20:11:02,474 INFO     Training average negative_sample_loss at step 36100: 0.006314\n",
      "2023-12-09 20:11:02,474 INFO     Training average loss at step 36100: 0.006358\n",
      "2023-12-09 20:11:16,102 INFO     Training average positive_sample_loss at step 36200: 0.006703\n",
      "2023-12-09 20:11:16,102 INFO     Training average negative_sample_loss at step 36200: 0.006142\n",
      "2023-12-09 20:11:16,102 INFO     Training average loss at step 36200: 0.006422\n",
      "2023-12-09 20:11:29,703 INFO     Training average positive_sample_loss at step 36300: 0.006924\n",
      "2023-12-09 20:11:29,704 INFO     Training average negative_sample_loss at step 36300: 0.006786\n",
      "2023-12-09 20:11:29,704 INFO     Training average loss at step 36300: 0.006855\n",
      "2023-12-09 20:11:42,888 INFO     Training average positive_sample_loss at step 36400: 0.007039\n",
      "2023-12-09 20:11:42,888 INFO     Training average negative_sample_loss at step 36400: 0.006691\n",
      "2023-12-09 20:11:42,888 INFO     Training average loss at step 36400: 0.006865\n",
      "2023-12-09 20:11:56,927 INFO     Training average positive_sample_loss at step 36500: 0.007023\n",
      "2023-12-09 20:11:56,927 INFO     Training average negative_sample_loss at step 36500: 0.006346\n",
      "2023-12-09 20:11:56,927 INFO     Training average loss at step 36500: 0.006685\n",
      "2023-12-09 20:12:13,356 INFO     Training average positive_sample_loss at step 36600: 0.006647\n",
      "2023-12-09 20:12:13,357 INFO     Training average negative_sample_loss at step 36600: 0.006871\n",
      "2023-12-09 20:12:13,357 INFO     Training average loss at step 36600: 0.006759\n",
      "2023-12-09 20:12:27,279 INFO     Training average positive_sample_loss at step 36700: 0.006547\n",
      "2023-12-09 20:12:27,280 INFO     Training average negative_sample_loss at step 36700: 0.006601\n",
      "2023-12-09 20:12:27,280 INFO     Training average loss at step 36700: 0.006574\n",
      "2023-12-09 20:12:41,212 INFO     Training average positive_sample_loss at step 36800: 0.006846\n",
      "2023-12-09 20:12:41,213 INFO     Training average negative_sample_loss at step 36800: 0.006622\n",
      "2023-12-09 20:12:41,213 INFO     Training average loss at step 36800: 0.006734\n",
      "2023-12-09 20:12:54,509 INFO     Training average positive_sample_loss at step 36900: 0.006934\n",
      "2023-12-09 20:12:54,509 INFO     Training average negative_sample_loss at step 36900: 0.006020\n",
      "2023-12-09 20:12:54,509 INFO     Training average loss at step 36900: 0.006477\n",
      "2023-12-09 20:13:10,431 INFO     Training average positive_sample_loss at step 37000: 0.006997\n",
      "2023-12-09 20:13:10,431 INFO     Training average negative_sample_loss at step 37000: 0.007132\n",
      "2023-12-09 20:13:10,431 INFO     Training average loss at step 37000: 0.007064\n",
      "2023-12-09 20:13:23,932 INFO     Training average positive_sample_loss at step 37100: 0.007018\n",
      "2023-12-09 20:13:23,933 INFO     Training average negative_sample_loss at step 37100: 0.007017\n",
      "2023-12-09 20:13:23,933 INFO     Training average loss at step 37100: 0.007017\n",
      "2023-12-09 20:13:41,480 INFO     Training average positive_sample_loss at step 37200: 0.006482\n",
      "2023-12-09 20:13:41,481 INFO     Training average negative_sample_loss at step 37200: 0.006634\n",
      "2023-12-09 20:13:41,481 INFO     Training average loss at step 37200: 0.006558\n",
      "2023-12-09 20:13:55,455 INFO     Training average positive_sample_loss at step 37300: 0.006679\n",
      "2023-12-09 20:13:55,456 INFO     Training average negative_sample_loss at step 37300: 0.006369\n",
      "2023-12-09 20:13:55,456 INFO     Training average loss at step 37300: 0.006524\n",
      "2023-12-09 20:14:09,539 INFO     Training average positive_sample_loss at step 37400: 0.006817\n",
      "2023-12-09 20:14:09,539 INFO     Training average negative_sample_loss at step 37400: 0.007071\n",
      "2023-12-09 20:14:09,539 INFO     Training average loss at step 37400: 0.006944\n",
      "2023-12-09 20:14:24,090 INFO     Training average positive_sample_loss at step 37500: 0.007064\n",
      "2023-12-09 20:14:24,090 INFO     Training average negative_sample_loss at step 37500: 0.006569\n",
      "2023-12-09 20:14:24,090 INFO     Training average loss at step 37500: 0.006816\n",
      "2023-12-09 20:14:38,799 INFO     Training average positive_sample_loss at step 37600: 0.007135\n",
      "2023-12-09 20:14:38,799 INFO     Training average negative_sample_loss at step 37600: 0.006334\n",
      "2023-12-09 20:14:38,800 INFO     Training average loss at step 37600: 0.006734\n",
      "2023-12-09 20:14:55,187 INFO     Training average positive_sample_loss at step 37700: 0.006699\n",
      "2023-12-09 20:14:55,188 INFO     Training average negative_sample_loss at step 37700: 0.006831\n",
      "2023-12-09 20:14:55,188 INFO     Training average loss at step 37700: 0.006765\n",
      "2023-12-09 20:15:09,815 INFO     Training average positive_sample_loss at step 37800: 0.006352\n",
      "2023-12-09 20:15:09,816 INFO     Training average negative_sample_loss at step 37800: 0.006331\n",
      "2023-12-09 20:15:09,816 INFO     Training average loss at step 37800: 0.006342\n",
      "2023-12-09 20:15:24,338 INFO     Training average positive_sample_loss at step 37900: 0.006775\n",
      "2023-12-09 20:15:24,339 INFO     Training average negative_sample_loss at step 37900: 0.006893\n",
      "2023-12-09 20:15:24,339 INFO     Training average loss at step 37900: 0.006834\n",
      "2023-12-09 20:15:38,040 INFO     Training average positive_sample_loss at step 38000: 0.006946\n",
      "2023-12-09 20:15:38,040 INFO     Training average negative_sample_loss at step 38000: 0.006502\n",
      "2023-12-09 20:15:38,040 INFO     Training average loss at step 38000: 0.006724\n",
      "2023-12-09 20:15:51,363 INFO     Training average positive_sample_loss at step 38100: 0.007052\n",
      "2023-12-09 20:15:51,363 INFO     Training average negative_sample_loss at step 38100: 0.006593\n",
      "2023-12-09 20:15:51,363 INFO     Training average loss at step 38100: 0.006823\n",
      "2023-12-09 20:16:05,142 INFO     Training average positive_sample_loss at step 38200: 0.007086\n",
      "2023-12-09 20:16:05,143 INFO     Training average negative_sample_loss at step 38200: 0.006937\n",
      "2023-12-09 20:16:05,143 INFO     Training average loss at step 38200: 0.007012\n",
      "2023-12-09 20:16:22,461 INFO     Training average positive_sample_loss at step 38300: 0.006317\n",
      "2023-12-09 20:16:22,462 INFO     Training average negative_sample_loss at step 38300: 0.006529\n",
      "2023-12-09 20:16:22,462 INFO     Training average loss at step 38300: 0.006423\n",
      "2023-12-09 20:16:36,812 INFO     Training average positive_sample_loss at step 38400: 0.006640\n",
      "2023-12-09 20:16:36,812 INFO     Training average negative_sample_loss at step 38400: 0.006470\n",
      "2023-12-09 20:16:36,812 INFO     Training average loss at step 38400: 0.006555\n",
      "2023-12-09 20:16:51,312 INFO     Training average positive_sample_loss at step 38500: 0.006892\n",
      "2023-12-09 20:16:51,312 INFO     Training average negative_sample_loss at step 38500: 0.006431\n",
      "2023-12-09 20:16:51,312 INFO     Training average loss at step 38500: 0.006661\n",
      "2023-12-09 20:17:04,656 INFO     Training average positive_sample_loss at step 38600: 0.006979\n",
      "2023-12-09 20:17:04,656 INFO     Training average negative_sample_loss at step 38600: 0.006682\n",
      "2023-12-09 20:17:04,656 INFO     Training average loss at step 38600: 0.006831\n",
      "2023-12-09 20:17:18,864 INFO     Training average positive_sample_loss at step 38700: 0.006955\n",
      "2023-12-09 20:17:18,865 INFO     Training average negative_sample_loss at step 38700: 0.006215\n",
      "2023-12-09 20:17:18,865 INFO     Training average loss at step 38700: 0.006585\n",
      "2023-12-09 20:17:35,442 INFO     Training average positive_sample_loss at step 38800: 0.006744\n",
      "2023-12-09 20:17:35,442 INFO     Training average negative_sample_loss at step 38800: 0.007035\n",
      "2023-12-09 20:17:35,442 INFO     Training average loss at step 38800: 0.006889\n",
      "2023-12-09 20:17:49,932 INFO     Training average positive_sample_loss at step 38900: 0.006402\n",
      "2023-12-09 20:17:49,933 INFO     Training average negative_sample_loss at step 38900: 0.006763\n",
      "2023-12-09 20:17:49,933 INFO     Training average loss at step 38900: 0.006582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:18:04,870 INFO     Training average positive_sample_loss at step 39000: 0.006833\n",
      "2023-12-09 20:18:04,870 INFO     Training average negative_sample_loss at step 39000: 0.006664\n",
      "2023-12-09 20:18:04,870 INFO     Training average loss at step 39000: 0.006749\n",
      "2023-12-09 20:18:18,905 INFO     Training average positive_sample_loss at step 39100: 0.006911\n",
      "2023-12-09 20:18:18,906 INFO     Training average negative_sample_loss at step 39100: 0.006689\n",
      "2023-12-09 20:18:18,906 INFO     Training average loss at step 39100: 0.006800\n",
      "2023-12-09 20:18:32,903 INFO     Training average positive_sample_loss at step 39200: 0.006888\n",
      "2023-12-09 20:18:32,903 INFO     Training average negative_sample_loss at step 39200: 0.006288\n",
      "2023-12-09 20:18:32,903 INFO     Training average loss at step 39200: 0.006588\n",
      "2023-12-09 20:18:48,073 INFO     Training average positive_sample_loss at step 39300: 0.007053\n",
      "2023-12-09 20:18:48,073 INFO     Training average negative_sample_loss at step 39300: 0.006864\n",
      "2023-12-09 20:18:48,073 INFO     Training average loss at step 39300: 0.006959\n",
      "2023-12-09 20:19:05,003 INFO     Training average positive_sample_loss at step 39400: 0.006471\n",
      "2023-12-09 20:19:05,003 INFO     Training average negative_sample_loss at step 39400: 0.006513\n",
      "2023-12-09 20:19:05,003 INFO     Training average loss at step 39400: 0.006492\n",
      "2023-12-09 20:19:19,244 INFO     Training average positive_sample_loss at step 39500: 0.006466\n",
      "2023-12-09 20:19:19,245 INFO     Training average negative_sample_loss at step 39500: 0.006613\n",
      "2023-12-09 20:19:19,245 INFO     Training average loss at step 39500: 0.006539\n",
      "2023-12-09 20:19:32,879 INFO     Training average positive_sample_loss at step 39600: 0.006886\n",
      "2023-12-09 20:19:32,879 INFO     Training average negative_sample_loss at step 39600: 0.006160\n",
      "2023-12-09 20:19:32,879 INFO     Training average loss at step 39600: 0.006523\n",
      "2023-12-09 20:19:46,790 INFO     Training average positive_sample_loss at step 39700: 0.006958\n",
      "2023-12-09 20:19:46,790 INFO     Training average negative_sample_loss at step 39700: 0.007007\n",
      "2023-12-09 20:19:46,790 INFO     Training average loss at step 39700: 0.006982\n",
      "2023-12-09 20:19:58,985 INFO     Training average positive_sample_loss at step 39800: 0.007049\n",
      "2023-12-09 20:19:58,985 INFO     Training average negative_sample_loss at step 39800: 0.006556\n",
      "2023-12-09 20:19:58,985 INFO     Training average loss at step 39800: 0.006802\n",
      "2023-12-09 20:20:16,304 INFO     Training average positive_sample_loss at step 39900: 0.006935\n",
      "2023-12-09 20:20:16,305 INFO     Training average negative_sample_loss at step 39900: 0.006153\n",
      "2023-12-09 20:20:16,305 INFO     Training average loss at step 39900: 0.006544\n",
      "2023-12-09 20:20:30,725 INFO     Change learning_rate to 0.000010 at step 40000\n",
      "2023-12-09 20:20:39,690 INFO     Training average positive_sample_loss at step 40000: 0.006316\n",
      "2023-12-09 20:20:39,690 INFO     Training average negative_sample_loss at step 40000: 0.006465\n",
      "2023-12-09 20:20:39,690 INFO     Training average loss at step 40000: 0.006390\n",
      "2023-12-09 20:20:39,690 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 20:20:40,352 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 20:21:34,706 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 20:21:48,477 INFO     Valid MRR at step 40000: 0.948709\n",
      "2023-12-09 20:21:48,477 INFO     Valid MR at step 40000: 304.471200\n",
      "2023-12-09 20:21:48,478 INFO     Valid HITS@1 at step 40000: 0.943700\n",
      "2023-12-09 20:21:48,478 INFO     Valid HITS@3 at step 40000: 0.951600\n",
      "2023-12-09 20:21:48,478 INFO     Valid HITS@10 at step 40000: 0.957800\n",
      "2023-12-09 20:22:01,067 INFO     Training average positive_sample_loss at step 40100: 0.006425\n",
      "2023-12-09 20:22:01,068 INFO     Training average negative_sample_loss at step 40100: 0.006849\n",
      "2023-12-09 20:22:01,068 INFO     Training average loss at step 40100: 0.006637\n",
      "2023-12-09 20:22:16,512 INFO     Training average positive_sample_loss at step 40200: 0.006391\n",
      "2023-12-09 20:22:16,512 INFO     Training average negative_sample_loss at step 40200: 0.006801\n",
      "2023-12-09 20:22:16,512 INFO     Training average loss at step 40200: 0.006596\n",
      "2023-12-09 20:22:30,502 INFO     Training average positive_sample_loss at step 40300: 0.006386\n",
      "2023-12-09 20:22:30,502 INFO     Training average negative_sample_loss at step 40300: 0.006284\n",
      "2023-12-09 20:22:30,502 INFO     Training average loss at step 40300: 0.006335\n",
      "2023-12-09 20:22:43,675 INFO     Training average positive_sample_loss at step 40400: 0.006181\n",
      "2023-12-09 20:22:43,676 INFO     Training average negative_sample_loss at step 40400: 0.006744\n",
      "2023-12-09 20:22:43,676 INFO     Training average loss at step 40400: 0.006463\n",
      "2023-12-09 20:23:00,816 INFO     Training average positive_sample_loss at step 40500: 0.005830\n",
      "2023-12-09 20:23:00,816 INFO     Training average negative_sample_loss at step 40500: 0.006201\n",
      "2023-12-09 20:23:00,816 INFO     Training average loss at step 40500: 0.006016\n",
      "2023-12-09 20:23:15,100 INFO     Training average positive_sample_loss at step 40600: 0.005619\n",
      "2023-12-09 20:23:15,100 INFO     Training average negative_sample_loss at step 40600: 0.006422\n",
      "2023-12-09 20:23:15,100 INFO     Training average loss at step 40600: 0.006020\n",
      "2023-12-09 20:23:29,417 INFO     Training average positive_sample_loss at step 40700: 0.005582\n",
      "2023-12-09 20:23:29,417 INFO     Training average negative_sample_loss at step 40700: 0.006028\n",
      "2023-12-09 20:23:29,417 INFO     Training average loss at step 40700: 0.005805\n",
      "2023-12-09 20:23:43,378 INFO     Training average positive_sample_loss at step 40800: 0.005603\n",
      "2023-12-09 20:23:43,379 INFO     Training average negative_sample_loss at step 40800: 0.006551\n",
      "2023-12-09 20:23:43,379 INFO     Training average loss at step 40800: 0.006077\n",
      "2023-12-09 20:23:56,545 INFO     Training average positive_sample_loss at step 40900: 0.005644\n",
      "2023-12-09 20:23:56,546 INFO     Training average negative_sample_loss at step 40900: 0.006445\n",
      "2023-12-09 20:23:56,546 INFO     Training average loss at step 40900: 0.006044\n",
      "2023-12-09 20:24:13,323 INFO     Training average positive_sample_loss at step 41000: 0.005637\n",
      "2023-12-09 20:24:13,324 INFO     Training average negative_sample_loss at step 41000: 0.006730\n",
      "2023-12-09 20:24:13,324 INFO     Training average loss at step 41000: 0.006184\n",
      "2023-12-09 20:24:26,562 INFO     Training average positive_sample_loss at step 41100: 0.005392\n",
      "2023-12-09 20:24:26,562 INFO     Training average negative_sample_loss at step 41100: 0.006404\n",
      "2023-12-09 20:24:26,562 INFO     Training average loss at step 41100: 0.005898\n",
      "2023-12-09 20:24:39,808 INFO     Training average positive_sample_loss at step 41200: 0.005392\n",
      "2023-12-09 20:24:39,808 INFO     Training average negative_sample_loss at step 41200: 0.006744\n",
      "2023-12-09 20:24:39,808 INFO     Training average loss at step 41200: 0.006068\n",
      "2023-12-09 20:24:53,935 INFO     Training average positive_sample_loss at step 41300: 0.005418\n",
      "2023-12-09 20:24:53,935 INFO     Training average negative_sample_loss at step 41300: 0.006110\n",
      "2023-12-09 20:24:53,935 INFO     Training average loss at step 41300: 0.005764\n",
      "2023-12-09 20:25:06,661 INFO     Training average positive_sample_loss at step 41400: 0.005450\n",
      "2023-12-09 20:25:06,661 INFO     Training average negative_sample_loss at step 41400: 0.006242\n",
      "2023-12-09 20:25:06,661 INFO     Training average loss at step 41400: 0.005846\n",
      "2023-12-09 20:25:21,743 INFO     Training average positive_sample_loss at step 41500: 0.005490\n",
      "2023-12-09 20:25:21,743 INFO     Training average negative_sample_loss at step 41500: 0.006291\n",
      "2023-12-09 20:25:21,743 INFO     Training average loss at step 41500: 0.005890\n",
      "2023-12-09 20:25:38,178 INFO     Training average positive_sample_loss at step 41600: 0.005334\n",
      "2023-12-09 20:25:38,178 INFO     Training average negative_sample_loss at step 41600: 0.006149\n",
      "2023-12-09 20:25:38,178 INFO     Training average loss at step 41600: 0.005741\n",
      "2023-12-09 20:25:53,353 INFO     Training average positive_sample_loss at step 41700: 0.005254\n",
      "2023-12-09 20:25:53,353 INFO     Training average negative_sample_loss at step 41700: 0.006161\n",
      "2023-12-09 20:25:53,353 INFO     Training average loss at step 41700: 0.005707\n",
      "2023-12-09 20:26:07,066 INFO     Training average positive_sample_loss at step 41800: 0.005314\n",
      "2023-12-09 20:26:07,066 INFO     Training average negative_sample_loss at step 41800: 0.006166\n",
      "2023-12-09 20:26:07,067 INFO     Training average loss at step 41800: 0.005740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:26:21,096 INFO     Training average positive_sample_loss at step 41900: 0.005388\n",
      "2023-12-09 20:26:21,096 INFO     Training average negative_sample_loss at step 41900: 0.006402\n",
      "2023-12-09 20:26:21,096 INFO     Training average loss at step 41900: 0.005895\n",
      "2023-12-09 20:26:34,328 INFO     Training average positive_sample_loss at step 42000: 0.005302\n",
      "2023-12-09 20:26:34,328 INFO     Training average negative_sample_loss at step 42000: 0.006646\n",
      "2023-12-09 20:26:34,328 INFO     Training average loss at step 42000: 0.005974\n",
      "2023-12-09 20:26:48,423 INFO     Training average positive_sample_loss at step 42100: 0.005438\n",
      "2023-12-09 20:26:48,424 INFO     Training average negative_sample_loss at step 42100: 0.006522\n",
      "2023-12-09 20:26:48,424 INFO     Training average loss at step 42100: 0.005980\n",
      "2023-12-09 20:27:05,439 INFO     Training average positive_sample_loss at step 42200: 0.005191\n",
      "2023-12-09 20:27:05,440 INFO     Training average negative_sample_loss at step 42200: 0.006239\n",
      "2023-12-09 20:27:05,440 INFO     Training average loss at step 42200: 0.005715\n",
      "2023-12-09 20:27:19,236 INFO     Training average positive_sample_loss at step 42300: 0.005261\n",
      "2023-12-09 20:27:19,236 INFO     Training average negative_sample_loss at step 42300: 0.006056\n",
      "2023-12-09 20:27:19,236 INFO     Training average loss at step 42300: 0.005658\n",
      "2023-12-09 20:27:33,284 INFO     Training average positive_sample_loss at step 42400: 0.005244\n",
      "2023-12-09 20:27:33,285 INFO     Training average negative_sample_loss at step 42400: 0.006588\n",
      "2023-12-09 20:27:33,285 INFO     Training average loss at step 42400: 0.005916\n",
      "2023-12-09 20:27:47,919 INFO     Training average positive_sample_loss at step 42500: 0.005348\n",
      "2023-12-09 20:27:47,919 INFO     Training average negative_sample_loss at step 42500: 0.005696\n",
      "2023-12-09 20:27:47,919 INFO     Training average loss at step 42500: 0.005522\n",
      "2023-12-09 20:28:01,823 INFO     Training average positive_sample_loss at step 42600: 0.005295\n",
      "2023-12-09 20:28:01,823 INFO     Training average negative_sample_loss at step 42600: 0.006100\n",
      "2023-12-09 20:28:01,823 INFO     Training average loss at step 42600: 0.005698\n",
      "2023-12-09 20:28:18,798 INFO     Training average positive_sample_loss at step 42700: 0.005258\n",
      "2023-12-09 20:28:18,798 INFO     Training average negative_sample_loss at step 42700: 0.006210\n",
      "2023-12-09 20:28:18,798 INFO     Training average loss at step 42700: 0.005734\n",
      "2023-12-09 20:28:33,595 INFO     Training average positive_sample_loss at step 42800: 0.005237\n",
      "2023-12-09 20:28:33,595 INFO     Training average negative_sample_loss at step 42800: 0.006739\n",
      "2023-12-09 20:28:33,595 INFO     Training average loss at step 42800: 0.005988\n",
      "2023-12-09 20:28:47,358 INFO     Training average positive_sample_loss at step 42900: 0.005209\n",
      "2023-12-09 20:28:47,358 INFO     Training average negative_sample_loss at step 42900: 0.006356\n",
      "2023-12-09 20:28:47,358 INFO     Training average loss at step 42900: 0.005782\n",
      "2023-12-09 20:29:01,122 INFO     Training average positive_sample_loss at step 43000: 0.005206\n",
      "2023-12-09 20:29:01,122 INFO     Training average negative_sample_loss at step 43000: 0.006347\n",
      "2023-12-09 20:29:01,122 INFO     Training average loss at step 43000: 0.005776\n",
      "2023-12-09 20:29:14,937 INFO     Training average positive_sample_loss at step 43100: 0.005264\n",
      "2023-12-09 20:29:14,938 INFO     Training average negative_sample_loss at step 43100: 0.006149\n",
      "2023-12-09 20:29:14,938 INFO     Training average loss at step 43100: 0.005706\n",
      "2023-12-09 20:29:28,051 INFO     Training average positive_sample_loss at step 43200: 0.005334\n",
      "2023-12-09 20:29:28,051 INFO     Training average negative_sample_loss at step 43200: 0.006616\n",
      "2023-12-09 20:29:28,052 INFO     Training average loss at step 43200: 0.005975\n",
      "2023-12-09 20:29:46,109 INFO     Training average positive_sample_loss at step 43300: 0.005183\n",
      "2023-12-09 20:29:46,109 INFO     Training average negative_sample_loss at step 43300: 0.006296\n",
      "2023-12-09 20:29:46,109 INFO     Training average loss at step 43300: 0.005739\n",
      "2023-12-09 20:30:00,349 INFO     Training average positive_sample_loss at step 43400: 0.005199\n",
      "2023-12-09 20:30:00,349 INFO     Training average negative_sample_loss at step 43400: 0.006260\n",
      "2023-12-09 20:30:00,349 INFO     Training average loss at step 43400: 0.005729\n",
      "2023-12-09 20:30:13,552 INFO     Training average positive_sample_loss at step 43500: 0.005204\n",
      "2023-12-09 20:30:13,553 INFO     Training average negative_sample_loss at step 43500: 0.006552\n",
      "2023-12-09 20:30:13,553 INFO     Training average loss at step 43500: 0.005878\n",
      "2023-12-09 20:30:27,492 INFO     Training average positive_sample_loss at step 43600: 0.005270\n",
      "2023-12-09 20:30:27,493 INFO     Training average negative_sample_loss at step 43600: 0.006122\n",
      "2023-12-09 20:30:27,493 INFO     Training average loss at step 43600: 0.005696\n",
      "2023-12-09 20:30:41,711 INFO     Training average positive_sample_loss at step 43700: 0.005268\n",
      "2023-12-09 20:30:41,711 INFO     Training average negative_sample_loss at step 43700: 0.006428\n",
      "2023-12-09 20:30:41,711 INFO     Training average loss at step 43700: 0.005848\n",
      "2023-12-09 20:30:58,649 INFO     Training average positive_sample_loss at step 43800: 0.005206\n",
      "2023-12-09 20:30:58,649 INFO     Training average negative_sample_loss at step 43800: 0.006388\n",
      "2023-12-09 20:30:58,649 INFO     Training average loss at step 43800: 0.005797\n",
      "2023-12-09 20:31:12,782 INFO     Training average positive_sample_loss at step 43900: 0.005104\n",
      "2023-12-09 20:31:12,782 INFO     Training average negative_sample_loss at step 43900: 0.006084\n",
      "2023-12-09 20:31:12,782 INFO     Training average loss at step 43900: 0.005594\n",
      "2023-12-09 20:31:26,606 INFO     Training average positive_sample_loss at step 44000: 0.005226\n",
      "2023-12-09 20:31:26,606 INFO     Training average negative_sample_loss at step 44000: 0.005731\n",
      "2023-12-09 20:31:26,606 INFO     Training average loss at step 44000: 0.005478\n",
      "2023-12-09 20:31:40,096 INFO     Training average positive_sample_loss at step 44100: 0.005250\n",
      "2023-12-09 20:31:40,097 INFO     Training average negative_sample_loss at step 44100: 0.006948\n",
      "2023-12-09 20:31:40,097 INFO     Training average loss at step 44100: 0.006099\n",
      "2023-12-09 20:31:54,722 INFO     Training average positive_sample_loss at step 44200: 0.005297\n",
      "2023-12-09 20:31:54,722 INFO     Training average negative_sample_loss at step 44200: 0.005724\n",
      "2023-12-09 20:31:54,722 INFO     Training average loss at step 44200: 0.005511\n",
      "2023-12-09 20:32:09,151 INFO     Training average positive_sample_loss at step 44300: 0.005298\n",
      "2023-12-09 20:32:09,151 INFO     Training average negative_sample_loss at step 44300: 0.005658\n",
      "2023-12-09 20:32:09,151 INFO     Training average loss at step 44300: 0.005478\n",
      "2023-12-09 20:32:25,732 INFO     Training average positive_sample_loss at step 44400: 0.005144\n",
      "2023-12-09 20:32:25,733 INFO     Training average negative_sample_loss at step 44400: 0.006007\n",
      "2023-12-09 20:32:25,733 INFO     Training average loss at step 44400: 0.005575\n",
      "2023-12-09 20:32:40,720 INFO     Training average positive_sample_loss at step 44500: 0.005138\n",
      "2023-12-09 20:32:40,720 INFO     Training average negative_sample_loss at step 44500: 0.006136\n",
      "2023-12-09 20:32:40,720 INFO     Training average loss at step 44500: 0.005637\n",
      "2023-12-09 20:32:54,726 INFO     Training average positive_sample_loss at step 44600: 0.005248\n",
      "2023-12-09 20:32:54,727 INFO     Training average negative_sample_loss at step 44600: 0.006192\n",
      "2023-12-09 20:32:54,727 INFO     Training average loss at step 44600: 0.005720\n",
      "2023-12-09 20:33:08,038 INFO     Training average positive_sample_loss at step 44700: 0.005264\n",
      "2023-12-09 20:33:08,039 INFO     Training average negative_sample_loss at step 44700: 0.006404\n",
      "2023-12-09 20:33:08,039 INFO     Training average loss at step 44700: 0.005834\n",
      "2023-12-09 20:33:22,885 INFO     Training average positive_sample_loss at step 44800: 0.005316\n",
      "2023-12-09 20:33:22,885 INFO     Training average negative_sample_loss at step 44800: 0.006291\n",
      "2023-12-09 20:33:22,885 INFO     Training average loss at step 44800: 0.005803\n",
      "2023-12-09 20:33:39,797 INFO     Training average positive_sample_loss at step 44900: 0.005194\n",
      "2023-12-09 20:33:39,797 INFO     Training average negative_sample_loss at step 44900: 0.005999\n",
      "2023-12-09 20:33:39,797 INFO     Training average loss at step 44900: 0.005596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:33:53,973 INFO     Training average positive_sample_loss at step 45000: 0.005081\n",
      "2023-12-09 20:33:53,974 INFO     Training average negative_sample_loss at step 45000: 0.007065\n",
      "2023-12-09 20:33:53,974 INFO     Training average loss at step 45000: 0.006073\n",
      "2023-12-09 20:34:07,970 INFO     Training average positive_sample_loss at step 45100: 0.005215\n",
      "2023-12-09 20:34:07,971 INFO     Training average negative_sample_loss at step 45100: 0.006568\n",
      "2023-12-09 20:34:07,971 INFO     Training average loss at step 45100: 0.005891\n",
      "2023-12-09 20:34:22,574 INFO     Training average positive_sample_loss at step 45200: 0.005224\n",
      "2023-12-09 20:34:22,574 INFO     Training average negative_sample_loss at step 45200: 0.005944\n",
      "2023-12-09 20:34:22,574 INFO     Training average loss at step 45200: 0.005584\n",
      "2023-12-09 20:34:36,652 INFO     Training average positive_sample_loss at step 45300: 0.005311\n",
      "2023-12-09 20:34:36,652 INFO     Training average negative_sample_loss at step 45300: 0.006135\n",
      "2023-12-09 20:34:36,652 INFO     Training average loss at step 45300: 0.005723\n",
      "2023-12-09 20:34:50,012 INFO     Training average positive_sample_loss at step 45400: 0.005296\n",
      "2023-12-09 20:34:50,013 INFO     Training average negative_sample_loss at step 45400: 0.005885\n",
      "2023-12-09 20:34:50,013 INFO     Training average loss at step 45400: 0.005590\n",
      "2023-12-09 20:35:07,701 INFO     Training average positive_sample_loss at step 45500: 0.005197\n",
      "2023-12-09 20:35:07,702 INFO     Training average negative_sample_loss at step 45500: 0.006278\n",
      "2023-12-09 20:35:07,702 INFO     Training average loss at step 45500: 0.005737\n",
      "2023-12-09 20:35:21,863 INFO     Training average positive_sample_loss at step 45600: 0.005191\n",
      "2023-12-09 20:35:21,957 INFO     Training average negative_sample_loss at step 45600: 0.006346\n",
      "2023-12-09 20:35:21,971 INFO     Training average loss at step 45600: 0.005768\n",
      "2023-12-09 20:35:39,516 INFO     Training average positive_sample_loss at step 45700: 0.005166\n",
      "2023-12-09 20:35:39,516 INFO     Training average negative_sample_loss at step 45700: 0.006027\n",
      "2023-12-09 20:35:39,516 INFO     Training average loss at step 45700: 0.005596\n",
      "2023-12-09 20:35:53,986 INFO     Training average positive_sample_loss at step 45800: 0.005204\n",
      "2023-12-09 20:35:53,986 INFO     Training average negative_sample_loss at step 45800: 0.006039\n",
      "2023-12-09 20:35:53,986 INFO     Training average loss at step 45800: 0.005622\n",
      "2023-12-09 20:36:07,141 INFO     Training average positive_sample_loss at step 45900: 0.005300\n",
      "2023-12-09 20:36:07,141 INFO     Training average negative_sample_loss at step 45900: 0.006310\n",
      "2023-12-09 20:36:07,141 INFO     Training average loss at step 45900: 0.005805\n",
      "2023-12-09 20:36:24,870 INFO     Training average positive_sample_loss at step 46000: 0.005277\n",
      "2023-12-09 20:36:24,870 INFO     Training average negative_sample_loss at step 46000: 0.005900\n",
      "2023-12-09 20:36:24,870 INFO     Training average loss at step 46000: 0.005588\n",
      "2023-12-09 20:36:38,504 INFO     Training average positive_sample_loss at step 46100: 0.005176\n",
      "2023-12-09 20:36:38,504 INFO     Training average negative_sample_loss at step 46100: 0.006026\n",
      "2023-12-09 20:36:38,504 INFO     Training average loss at step 46100: 0.005601\n",
      "2023-12-09 20:36:52,311 INFO     Training average positive_sample_loss at step 46200: 0.005173\n",
      "2023-12-09 20:36:52,311 INFO     Training average negative_sample_loss at step 46200: 0.005806\n",
      "2023-12-09 20:36:52,311 INFO     Training average loss at step 46200: 0.005489\n",
      "2023-12-09 20:37:06,701 INFO     Training average positive_sample_loss at step 46300: 0.005192\n",
      "2023-12-09 20:37:06,701 INFO     Training average negative_sample_loss at step 46300: 0.006346\n",
      "2023-12-09 20:37:06,701 INFO     Training average loss at step 46300: 0.005769\n",
      "2023-12-09 20:37:20,548 INFO     Training average positive_sample_loss at step 46400: 0.005241\n",
      "2023-12-09 20:37:20,548 INFO     Training average negative_sample_loss at step 46400: 0.005853\n",
      "2023-12-09 20:37:20,549 INFO     Training average loss at step 46400: 0.005547\n",
      "2023-12-09 20:37:34,286 INFO     Training average positive_sample_loss at step 46500: 0.005270\n",
      "2023-12-09 20:37:34,286 INFO     Training average negative_sample_loss at step 46500: 0.005927\n",
      "2023-12-09 20:37:34,286 INFO     Training average loss at step 46500: 0.005598\n",
      "2023-12-09 20:37:51,043 INFO     Training average positive_sample_loss at step 46600: 0.005200\n",
      "2023-12-09 20:37:51,044 INFO     Training average negative_sample_loss at step 46600: 0.006582\n",
      "2023-12-09 20:37:51,044 INFO     Training average loss at step 46600: 0.005891\n",
      "2023-12-09 20:38:05,147 INFO     Training average positive_sample_loss at step 46700: 0.005150\n",
      "2023-12-09 20:38:05,148 INFO     Training average negative_sample_loss at step 46700: 0.006120\n",
      "2023-12-09 20:38:05,148 INFO     Training average loss at step 46700: 0.005635\n",
      "2023-12-09 20:38:18,433 INFO     Training average positive_sample_loss at step 46800: 0.005161\n",
      "2023-12-09 20:38:18,434 INFO     Training average negative_sample_loss at step 46800: 0.006896\n",
      "2023-12-09 20:38:18,434 INFO     Training average loss at step 46800: 0.006029\n",
      "2023-12-09 20:38:32,175 INFO     Training average positive_sample_loss at step 46900: 0.005302\n",
      "2023-12-09 20:38:32,175 INFO     Training average negative_sample_loss at step 46900: 0.006501\n",
      "2023-12-09 20:38:32,175 INFO     Training average loss at step 46900: 0.005901\n",
      "2023-12-09 20:38:46,153 INFO     Training average positive_sample_loss at step 47000: 0.005257\n",
      "2023-12-09 20:38:46,153 INFO     Training average negative_sample_loss at step 47000: 0.005457\n",
      "2023-12-09 20:38:46,153 INFO     Training average loss at step 47000: 0.005357\n",
      "2023-12-09 20:39:02,337 INFO     Training average positive_sample_loss at step 47100: 0.005302\n",
      "2023-12-09 20:39:02,338 INFO     Training average negative_sample_loss at step 47100: 0.005751\n",
      "2023-12-09 20:39:02,338 INFO     Training average loss at step 47100: 0.005527\n",
      "2023-12-09 20:39:16,907 INFO     Training average positive_sample_loss at step 47200: 0.005135\n",
      "2023-12-09 20:39:16,907 INFO     Training average negative_sample_loss at step 47200: 0.006145\n",
      "2023-12-09 20:39:16,907 INFO     Training average loss at step 47200: 0.005640\n",
      "2023-12-09 20:39:30,877 INFO     Training average positive_sample_loss at step 47300: 0.005159\n",
      "2023-12-09 20:39:30,878 INFO     Training average negative_sample_loss at step 47300: 0.005837\n",
      "2023-12-09 20:39:30,878 INFO     Training average loss at step 47300: 0.005498\n",
      "2023-12-09 20:39:46,510 INFO     Training average positive_sample_loss at step 47400: 0.005221\n",
      "2023-12-09 20:39:46,511 INFO     Training average negative_sample_loss at step 47400: 0.005914\n",
      "2023-12-09 20:39:46,511 INFO     Training average loss at step 47400: 0.005567\n",
      "2023-12-09 20:40:00,788 INFO     Training average positive_sample_loss at step 47500: 0.005251\n",
      "2023-12-09 20:40:00,789 INFO     Training average negative_sample_loss at step 47500: 0.006334\n",
      "2023-12-09 20:40:00,789 INFO     Training average loss at step 47500: 0.005793\n",
      "2023-12-09 20:40:14,291 INFO     Training average positive_sample_loss at step 47600: 0.005280\n",
      "2023-12-09 20:40:14,291 INFO     Training average negative_sample_loss at step 47600: 0.005858\n",
      "2023-12-09 20:40:14,291 INFO     Training average loss at step 47600: 0.005569\n",
      "2023-12-09 20:40:31,879 INFO     Training average positive_sample_loss at step 47700: 0.005236\n",
      "2023-12-09 20:40:31,880 INFO     Training average negative_sample_loss at step 47700: 0.005840\n",
      "2023-12-09 20:40:31,880 INFO     Training average loss at step 47700: 0.005538\n",
      "2023-12-09 20:40:44,661 INFO     Training average positive_sample_loss at step 47800: 0.005218\n",
      "2023-12-09 20:40:44,662 INFO     Training average negative_sample_loss at step 47800: 0.005974\n",
      "2023-12-09 20:40:44,662 INFO     Training average loss at step 47800: 0.005596\n",
      "2023-12-09 20:40:58,557 INFO     Training average positive_sample_loss at step 47900: 0.005183\n",
      "2023-12-09 20:40:58,557 INFO     Training average negative_sample_loss at step 47900: 0.006403\n",
      "2023-12-09 20:40:58,557 INFO     Training average loss at step 47900: 0.005793\n",
      "2023-12-09 20:41:12,481 INFO     Training average positive_sample_loss at step 48000: 0.005192\n",
      "2023-12-09 20:41:12,481 INFO     Training average negative_sample_loss at step 48000: 0.006084\n",
      "2023-12-09 20:41:12,481 INFO     Training average loss at step 48000: 0.005638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:41:25,278 INFO     Training average positive_sample_loss at step 48100: 0.005331\n",
      "2023-12-09 20:41:25,278 INFO     Training average negative_sample_loss at step 48100: 0.006312\n",
      "2023-12-09 20:41:25,278 INFO     Training average loss at step 48100: 0.005821\n",
      "2023-12-09 20:41:42,295 INFO     Training average positive_sample_loss at step 48200: 0.005267\n",
      "2023-12-09 20:41:42,295 INFO     Training average negative_sample_loss at step 48200: 0.006551\n",
      "2023-12-09 20:41:42,295 INFO     Training average loss at step 48200: 0.005909\n",
      "2023-12-09 20:41:56,815 INFO     Training average positive_sample_loss at step 48300: 0.005212\n",
      "2023-12-09 20:41:56,815 INFO     Training average negative_sample_loss at step 48300: 0.006049\n",
      "2023-12-09 20:41:56,815 INFO     Training average loss at step 48300: 0.005630\n",
      "2023-12-09 20:42:10,243 INFO     Training average positive_sample_loss at step 48400: 0.005188\n",
      "2023-12-09 20:42:10,243 INFO     Training average negative_sample_loss at step 48400: 0.005736\n",
      "2023-12-09 20:42:10,243 INFO     Training average loss at step 48400: 0.005462\n",
      "2023-12-09 20:42:24,753 INFO     Training average positive_sample_loss at step 48500: 0.005204\n",
      "2023-12-09 20:42:24,753 INFO     Training average negative_sample_loss at step 48500: 0.006469\n",
      "2023-12-09 20:42:24,753 INFO     Training average loss at step 48500: 0.005836\n",
      "2023-12-09 20:42:38,046 INFO     Training average positive_sample_loss at step 48600: 0.005227\n",
      "2023-12-09 20:42:38,046 INFO     Training average negative_sample_loss at step 48600: 0.006121\n",
      "2023-12-09 20:42:38,046 INFO     Training average loss at step 48600: 0.005674\n",
      "2023-12-09 20:42:51,907 INFO     Training average positive_sample_loss at step 48700: 0.005282\n",
      "2023-12-09 20:42:51,907 INFO     Training average negative_sample_loss at step 48700: 0.005577\n",
      "2023-12-09 20:42:51,907 INFO     Training average loss at step 48700: 0.005429\n",
      "2023-12-09 20:43:07,890 INFO     Training average positive_sample_loss at step 48800: 0.005224\n",
      "2023-12-09 20:43:07,890 INFO     Training average negative_sample_loss at step 48800: 0.006186\n",
      "2023-12-09 20:43:07,890 INFO     Training average loss at step 48800: 0.005705\n",
      "2023-12-09 20:43:21,954 INFO     Training average positive_sample_loss at step 48900: 0.005155\n",
      "2023-12-09 20:43:21,954 INFO     Training average negative_sample_loss at step 48900: 0.006166\n",
      "2023-12-09 20:43:21,954 INFO     Training average loss at step 48900: 0.005661\n",
      "2023-12-09 20:43:36,220 INFO     Training average positive_sample_loss at step 49000: 0.005233\n",
      "2023-12-09 20:43:36,221 INFO     Training average negative_sample_loss at step 49000: 0.006019\n",
      "2023-12-09 20:43:36,221 INFO     Training average loss at step 49000: 0.005626\n",
      "2023-12-09 20:43:50,940 INFO     Training average positive_sample_loss at step 49100: 0.005259\n",
      "2023-12-09 20:43:50,941 INFO     Training average negative_sample_loss at step 49100: 0.005867\n",
      "2023-12-09 20:43:50,941 INFO     Training average loss at step 49100: 0.005563\n",
      "2023-12-09 20:44:04,698 INFO     Training average positive_sample_loss at step 49200: 0.005267\n",
      "2023-12-09 20:44:04,698 INFO     Training average negative_sample_loss at step 49200: 0.006320\n",
      "2023-12-09 20:44:04,698 INFO     Training average loss at step 49200: 0.005794\n",
      "2023-12-09 20:44:18,285 INFO     Training average positive_sample_loss at step 49300: 0.005250\n",
      "2023-12-09 20:44:18,285 INFO     Training average negative_sample_loss at step 49300: 0.006330\n",
      "2023-12-09 20:44:18,285 INFO     Training average loss at step 49300: 0.005790\n",
      "2023-12-09 20:44:36,215 INFO     Training average positive_sample_loss at step 49400: 0.005148\n",
      "2023-12-09 20:44:36,216 INFO     Training average negative_sample_loss at step 49400: 0.005789\n",
      "2023-12-09 20:44:36,216 INFO     Training average loss at step 49400: 0.005469\n",
      "2023-12-09 20:44:50,192 INFO     Training average positive_sample_loss at step 49500: 0.005215\n",
      "2023-12-09 20:44:50,192 INFO     Training average negative_sample_loss at step 49500: 0.006107\n",
      "2023-12-09 20:44:50,192 INFO     Training average loss at step 49500: 0.005661\n",
      "2023-12-09 20:45:04,250 INFO     Training average positive_sample_loss at step 49600: 0.005216\n",
      "2023-12-09 20:45:04,250 INFO     Training average negative_sample_loss at step 49600: 0.006322\n",
      "2023-12-09 20:45:04,250 INFO     Training average loss at step 49600: 0.005769\n",
      "2023-12-09 20:45:18,379 INFO     Training average positive_sample_loss at step 49700: 0.005231\n",
      "2023-12-09 20:45:18,380 INFO     Training average negative_sample_loss at step 49700: 0.006242\n",
      "2023-12-09 20:45:18,380 INFO     Training average loss at step 49700: 0.005737\n",
      "2023-12-09 20:45:33,126 INFO     Training average positive_sample_loss at step 49800: 0.005330\n",
      "2023-12-09 20:45:33,127 INFO     Training average negative_sample_loss at step 49800: 0.006355\n",
      "2023-12-09 20:45:33,127 INFO     Training average loss at step 49800: 0.005842\n",
      "2023-12-09 20:45:49,660 INFO     Training average positive_sample_loss at step 49900: 0.005250\n",
      "2023-12-09 20:45:49,660 INFO     Training average negative_sample_loss at step 49900: 0.006057\n",
      "2023-12-09 20:45:49,660 INFO     Training average loss at step 49900: 0.005653\n",
      "2023-12-09 20:46:20,044 INFO     Training average positive_sample_loss at step 50000: 0.005169\n",
      "2023-12-09 20:46:20,044 INFO     Training average negative_sample_loss at step 50000: 0.006160\n",
      "2023-12-09 20:46:20,044 INFO     Training average loss at step 50000: 0.005664\n",
      "2023-12-09 20:46:20,044 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 20:46:21,087 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 20:47:13,531 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 20:47:27,159 INFO     Valid MRR at step 50000: 0.948942\n",
      "2023-12-09 20:47:27,159 INFO     Valid MR at step 50000: 290.921300\n",
      "2023-12-09 20:47:27,159 INFO     Valid HITS@1 at step 50000: 0.943900\n",
      "2023-12-09 20:47:27,159 INFO     Valid HITS@3 at step 50000: 0.951600\n",
      "2023-12-09 20:47:27,159 INFO     Valid HITS@10 at step 50000: 0.957500\n",
      "2023-12-09 20:47:40,968 INFO     Training average positive_sample_loss at step 50100: 0.005160\n",
      "2023-12-09 20:47:40,968 INFO     Training average negative_sample_loss at step 50100: 0.005855\n",
      "2023-12-09 20:47:40,968 INFO     Training average loss at step 50100: 0.005508\n",
      "2023-12-09 20:47:53,626 INFO     Training average positive_sample_loss at step 50200: 0.005301\n",
      "2023-12-09 20:47:53,626 INFO     Training average negative_sample_loss at step 50200: 0.006028\n",
      "2023-12-09 20:47:53,626 INFO     Training average loss at step 50200: 0.005665\n",
      "2023-12-09 20:48:08,049 INFO     Training average positive_sample_loss at step 50300: 0.005266\n",
      "2023-12-09 20:48:08,050 INFO     Training average negative_sample_loss at step 50300: 0.005985\n",
      "2023-12-09 20:48:08,050 INFO     Training average loss at step 50300: 0.005625\n",
      "2023-12-09 20:48:22,085 INFO     Training average positive_sample_loss at step 50400: 0.005318\n",
      "2023-12-09 20:48:22,085 INFO     Training average negative_sample_loss at step 50400: 0.005978\n",
      "2023-12-09 20:48:22,085 INFO     Training average loss at step 50400: 0.005648\n",
      "2023-12-09 20:48:39,843 INFO     Training average positive_sample_loss at step 50500: 0.005116\n",
      "2023-12-09 20:48:39,843 INFO     Training average negative_sample_loss at step 50500: 0.006415\n",
      "2023-12-09 20:48:39,844 INFO     Training average loss at step 50500: 0.005766\n",
      "2023-12-09 20:48:53,469 INFO     Training average positive_sample_loss at step 50600: 0.005237\n",
      "2023-12-09 20:48:53,469 INFO     Training average negative_sample_loss at step 50600: 0.005665\n",
      "2023-12-09 20:48:53,469 INFO     Training average loss at step 50600: 0.005451\n",
      "2023-12-09 20:49:07,405 INFO     Training average positive_sample_loss at step 50700: 0.005230\n",
      "2023-12-09 20:49:07,405 INFO     Training average negative_sample_loss at step 50700: 0.006652\n",
      "2023-12-09 20:49:07,405 INFO     Training average loss at step 50700: 0.005941\n",
      "2023-12-09 20:49:22,329 INFO     Training average positive_sample_loss at step 50800: 0.005253\n",
      "2023-12-09 20:49:22,330 INFO     Training average negative_sample_loss at step 50800: 0.005897\n",
      "2023-12-09 20:49:22,330 INFO     Training average loss at step 50800: 0.005575\n",
      "2023-12-09 20:49:37,412 INFO     Training average positive_sample_loss at step 50900: 0.005287\n",
      "2023-12-09 20:49:37,412 INFO     Training average negative_sample_loss at step 50900: 0.006060\n",
      "2023-12-09 20:49:37,412 INFO     Training average loss at step 50900: 0.005673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:49:54,187 INFO     Training average positive_sample_loss at step 51000: 0.005270\n",
      "2023-12-09 20:49:54,188 INFO     Training average negative_sample_loss at step 51000: 0.006819\n",
      "2023-12-09 20:49:54,188 INFO     Training average loss at step 51000: 0.006045\n",
      "2023-12-09 20:50:08,421 INFO     Training average positive_sample_loss at step 51100: 0.005179\n",
      "2023-12-09 20:50:08,421 INFO     Training average negative_sample_loss at step 51100: 0.006610\n",
      "2023-12-09 20:50:08,421 INFO     Training average loss at step 51100: 0.005895\n",
      "2023-12-09 20:50:23,004 INFO     Training average positive_sample_loss at step 51200: 0.005160\n",
      "2023-12-09 20:50:23,004 INFO     Training average negative_sample_loss at step 51200: 0.006126\n",
      "2023-12-09 20:50:23,004 INFO     Training average loss at step 51200: 0.005643\n",
      "2023-12-09 20:50:37,399 INFO     Training average positive_sample_loss at step 51300: 0.005246\n",
      "2023-12-09 20:50:37,399 INFO     Training average negative_sample_loss at step 51300: 0.006135\n",
      "2023-12-09 20:50:37,400 INFO     Training average loss at step 51300: 0.005691\n",
      "2023-12-09 20:50:50,285 INFO     Training average positive_sample_loss at step 51400: 0.005285\n",
      "2023-12-09 20:50:50,286 INFO     Training average negative_sample_loss at step 51400: 0.005768\n",
      "2023-12-09 20:50:50,286 INFO     Training average loss at step 51400: 0.005526\n",
      "2023-12-09 20:51:04,482 INFO     Training average positive_sample_loss at step 51500: 0.005278\n",
      "2023-12-09 20:51:04,482 INFO     Training average negative_sample_loss at step 51500: 0.005639\n",
      "2023-12-09 20:51:04,482 INFO     Training average loss at step 51500: 0.005458\n",
      "2023-12-09 20:51:21,690 INFO     Training average positive_sample_loss at step 51600: 0.005216\n",
      "2023-12-09 20:51:21,691 INFO     Training average negative_sample_loss at step 51600: 0.005810\n",
      "2023-12-09 20:51:21,691 INFO     Training average loss at step 51600: 0.005513\n",
      "2023-12-09 20:51:35,048 INFO     Training average positive_sample_loss at step 51700: 0.005150\n",
      "2023-12-09 20:51:35,048 INFO     Training average negative_sample_loss at step 51700: 0.006509\n",
      "2023-12-09 20:51:35,048 INFO     Training average loss at step 51700: 0.005830\n",
      "2023-12-09 20:51:49,547 INFO     Training average positive_sample_loss at step 51800: 0.005289\n",
      "2023-12-09 20:51:49,547 INFO     Training average negative_sample_loss at step 51800: 0.006205\n",
      "2023-12-09 20:51:49,547 INFO     Training average loss at step 51800: 0.005747\n",
      "2023-12-09 20:52:03,535 INFO     Training average positive_sample_loss at step 51900: 0.005212\n",
      "2023-12-09 20:52:03,536 INFO     Training average negative_sample_loss at step 51900: 0.005606\n",
      "2023-12-09 20:52:03,536 INFO     Training average loss at step 51900: 0.005409\n",
      "2023-12-09 20:52:17,974 INFO     Training average positive_sample_loss at step 52000: 0.005338\n",
      "2023-12-09 20:52:17,975 INFO     Training average negative_sample_loss at step 52000: 0.005894\n",
      "2023-12-09 20:52:17,975 INFO     Training average loss at step 52000: 0.005616\n",
      "2023-12-09 20:52:34,477 INFO     Training average positive_sample_loss at step 52100: 0.005202\n",
      "2023-12-09 20:52:34,478 INFO     Training average negative_sample_loss at step 52100: 0.005882\n",
      "2023-12-09 20:52:34,478 INFO     Training average loss at step 52100: 0.005542\n",
      "2023-12-09 20:52:48,702 INFO     Training average positive_sample_loss at step 52200: 0.005203\n",
      "2023-12-09 20:52:48,703 INFO     Training average negative_sample_loss at step 52200: 0.005820\n",
      "2023-12-09 20:52:48,703 INFO     Training average loss at step 52200: 0.005512\n",
      "2023-12-09 20:53:02,791 INFO     Training average positive_sample_loss at step 52300: 0.005169\n",
      "2023-12-09 20:53:02,791 INFO     Training average negative_sample_loss at step 52300: 0.006032\n",
      "2023-12-09 20:53:02,791 INFO     Training average loss at step 52300: 0.005601\n",
      "2023-12-09 20:53:17,437 INFO     Training average positive_sample_loss at step 52400: 0.005207\n",
      "2023-12-09 20:53:17,437 INFO     Training average negative_sample_loss at step 52400: 0.005811\n",
      "2023-12-09 20:53:17,437 INFO     Training average loss at step 52400: 0.005509\n",
      "2023-12-09 20:53:31,357 INFO     Training average positive_sample_loss at step 52500: 0.005261\n",
      "2023-12-09 20:53:31,357 INFO     Training average negative_sample_loss at step 52500: 0.005760\n",
      "2023-12-09 20:53:31,357 INFO     Training average loss at step 52500: 0.005511\n",
      "2023-12-09 20:53:44,467 INFO     Training average positive_sample_loss at step 52600: 0.005331\n",
      "2023-12-09 20:53:44,468 INFO     Training average negative_sample_loss at step 52600: 0.005920\n",
      "2023-12-09 20:53:44,468 INFO     Training average loss at step 52600: 0.005625\n",
      "2023-12-09 20:54:01,682 INFO     Training average positive_sample_loss at step 52700: 0.005192\n",
      "2023-12-09 20:54:01,682 INFO     Training average negative_sample_loss at step 52700: 0.006117\n",
      "2023-12-09 20:54:01,682 INFO     Training average loss at step 52700: 0.005654\n",
      "2023-12-09 20:54:15,897 INFO     Training average positive_sample_loss at step 52800: 0.005208\n",
      "2023-12-09 20:54:15,898 INFO     Training average negative_sample_loss at step 52800: 0.006989\n",
      "2023-12-09 20:54:15,898 INFO     Training average loss at step 52800: 0.006098\n",
      "2023-12-09 20:54:28,663 INFO     Training average positive_sample_loss at step 52900: 0.005230\n",
      "2023-12-09 20:54:28,663 INFO     Training average negative_sample_loss at step 52900: 0.006221\n",
      "2023-12-09 20:54:28,663 INFO     Training average loss at step 52900: 0.005725\n",
      "2023-12-09 20:54:43,256 INFO     Training average positive_sample_loss at step 53000: 0.005270\n",
      "2023-12-09 20:54:43,256 INFO     Training average negative_sample_loss at step 53000: 0.006259\n",
      "2023-12-09 20:54:43,256 INFO     Training average loss at step 53000: 0.005764\n",
      "2023-12-09 20:54:57,773 INFO     Training average positive_sample_loss at step 53100: 0.005252\n",
      "2023-12-09 20:54:57,774 INFO     Training average negative_sample_loss at step 53100: 0.005797\n",
      "2023-12-09 20:54:57,774 INFO     Training average loss at step 53100: 0.005525\n",
      "2023-12-09 20:55:15,421 INFO     Training average positive_sample_loss at step 53200: 0.005301\n",
      "2023-12-09 20:55:15,421 INFO     Training average negative_sample_loss at step 53200: 0.006491\n",
      "2023-12-09 20:55:15,421 INFO     Training average loss at step 53200: 0.005896\n",
      "2023-12-09 20:55:29,813 INFO     Training average positive_sample_loss at step 53300: 0.005188\n",
      "2023-12-09 20:55:29,813 INFO     Training average negative_sample_loss at step 53300: 0.006698\n",
      "2023-12-09 20:55:29,813 INFO     Training average loss at step 53300: 0.005943\n",
      "2023-12-09 20:55:44,123 INFO     Training average positive_sample_loss at step 53400: 0.005194\n",
      "2023-12-09 20:55:44,124 INFO     Training average negative_sample_loss at step 53400: 0.006133\n",
      "2023-12-09 20:55:44,124 INFO     Training average loss at step 53400: 0.005663\n",
      "2023-12-09 20:55:57,724 INFO     Training average positive_sample_loss at step 53500: 0.005225\n",
      "2023-12-09 20:55:57,725 INFO     Training average negative_sample_loss at step 53500: 0.005711\n",
      "2023-12-09 20:55:57,725 INFO     Training average loss at step 53500: 0.005468\n",
      "2023-12-09 20:56:12,414 INFO     Training average positive_sample_loss at step 53600: 0.005232\n",
      "2023-12-09 20:56:12,414 INFO     Training average negative_sample_loss at step 53600: 0.005747\n",
      "2023-12-09 20:56:12,415 INFO     Training average loss at step 53600: 0.005490\n",
      "2023-12-09 20:56:26,300 INFO     Training average positive_sample_loss at step 53700: 0.005246\n",
      "2023-12-09 20:56:26,300 INFO     Training average negative_sample_loss at step 53700: 0.006428\n",
      "2023-12-09 20:56:26,300 INFO     Training average loss at step 53700: 0.005837\n",
      "2023-12-09 20:56:42,585 INFO     Training average positive_sample_loss at step 53800: 0.005243\n",
      "2023-12-09 20:56:42,585 INFO     Training average negative_sample_loss at step 53800: 0.006533\n",
      "2023-12-09 20:56:42,585 INFO     Training average loss at step 53800: 0.005888\n",
      "2023-12-09 20:56:58,076 INFO     Training average positive_sample_loss at step 53900: 0.005212\n",
      "2023-12-09 20:56:58,076 INFO     Training average negative_sample_loss at step 53900: 0.006070\n",
      "2023-12-09 20:56:58,076 INFO     Training average loss at step 53900: 0.005641\n",
      "2023-12-09 20:57:12,242 INFO     Training average positive_sample_loss at step 54000: 0.005191\n",
      "2023-12-09 20:57:12,242 INFO     Training average negative_sample_loss at step 54000: 0.006082\n",
      "2023-12-09 20:57:12,243 INFO     Training average loss at step 54000: 0.005636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 20:57:25,986 INFO     Training average positive_sample_loss at step 54100: 0.005257\n",
      "2023-12-09 20:57:25,986 INFO     Training average negative_sample_loss at step 54100: 0.006324\n",
      "2023-12-09 20:57:25,986 INFO     Training average loss at step 54100: 0.005791\n",
      "2023-12-09 20:57:39,673 INFO     Training average positive_sample_loss at step 54200: 0.005292\n",
      "2023-12-09 20:57:39,673 INFO     Training average negative_sample_loss at step 54200: 0.005089\n",
      "2023-12-09 20:57:39,674 INFO     Training average loss at step 54200: 0.005190\n",
      "2023-12-09 20:57:58,449 INFO     Training average positive_sample_loss at step 54300: 0.005315\n",
      "2023-12-09 20:57:58,449 INFO     Training average negative_sample_loss at step 54300: 0.005855\n",
      "2023-12-09 20:57:58,449 INFO     Training average loss at step 54300: 0.005585\n",
      "2023-12-09 20:58:14,971 INFO     Training average positive_sample_loss at step 54400: 0.005133\n",
      "2023-12-09 20:58:14,971 INFO     Training average negative_sample_loss at step 54400: 0.005976\n",
      "2023-12-09 20:58:14,971 INFO     Training average loss at step 54400: 0.005555\n",
      "2023-12-09 20:58:28,977 INFO     Training average positive_sample_loss at step 54500: 0.005219\n",
      "2023-12-09 20:58:28,977 INFO     Training average negative_sample_loss at step 54500: 0.006244\n",
      "2023-12-09 20:58:28,977 INFO     Training average loss at step 54500: 0.005731\n",
      "2023-12-09 20:58:41,798 INFO     Training average positive_sample_loss at step 54600: 0.005238\n",
      "2023-12-09 20:58:41,799 INFO     Training average negative_sample_loss at step 54600: 0.005473\n",
      "2023-12-09 20:58:41,799 INFO     Training average loss at step 54600: 0.005356\n",
      "2023-12-09 20:58:55,885 INFO     Training average positive_sample_loss at step 54700: 0.005264\n",
      "2023-12-09 20:58:55,885 INFO     Training average negative_sample_loss at step 54700: 0.005839\n",
      "2023-12-09 20:58:55,885 INFO     Training average loss at step 54700: 0.005551\n",
      "2023-12-09 20:59:09,225 INFO     Training average positive_sample_loss at step 54800: 0.005281\n",
      "2023-12-09 20:59:09,225 INFO     Training average negative_sample_loss at step 54800: 0.006205\n",
      "2023-12-09 20:59:09,225 INFO     Training average loss at step 54800: 0.005743\n",
      "2023-12-09 20:59:26,842 INFO     Training average positive_sample_loss at step 54900: 0.005215\n",
      "2023-12-09 20:59:26,842 INFO     Training average negative_sample_loss at step 54900: 0.005916\n",
      "2023-12-09 20:59:26,843 INFO     Training average loss at step 54900: 0.005566\n",
      "2023-12-09 20:59:40,785 INFO     Training average positive_sample_loss at step 55000: 0.005162\n",
      "2023-12-09 20:59:40,786 INFO     Training average negative_sample_loss at step 55000: 0.006254\n",
      "2023-12-09 20:59:40,786 INFO     Training average loss at step 55000: 0.005708\n",
      "2023-12-09 20:59:55,108 INFO     Training average positive_sample_loss at step 55100: 0.005233\n",
      "2023-12-09 20:59:55,109 INFO     Training average negative_sample_loss at step 55100: 0.005453\n",
      "2023-12-09 20:59:55,109 INFO     Training average loss at step 55100: 0.005343\n",
      "2023-12-09 21:00:08,887 INFO     Training average positive_sample_loss at step 55200: 0.005227\n",
      "2023-12-09 21:00:08,887 INFO     Training average negative_sample_loss at step 55200: 0.005524\n",
      "2023-12-09 21:00:08,887 INFO     Training average loss at step 55200: 0.005375\n",
      "2023-12-09 21:00:22,758 INFO     Training average positive_sample_loss at step 55300: 0.005254\n",
      "2023-12-09 21:00:22,758 INFO     Training average negative_sample_loss at step 55300: 0.005829\n",
      "2023-12-09 21:00:22,758 INFO     Training average loss at step 55300: 0.005542\n",
      "2023-12-09 21:00:37,607 INFO     Training average positive_sample_loss at step 55400: 0.005295\n",
      "2023-12-09 21:00:37,607 INFO     Training average negative_sample_loss at step 55400: 0.005838\n",
      "2023-12-09 21:00:37,607 INFO     Training average loss at step 55400: 0.005566\n",
      "2023-12-09 21:00:53,758 INFO     Training average positive_sample_loss at step 55500: 0.005114\n",
      "2023-12-09 21:00:53,758 INFO     Training average negative_sample_loss at step 55500: 0.006296\n",
      "2023-12-09 21:00:53,758 INFO     Training average loss at step 55500: 0.005705\n",
      "2023-12-09 21:01:07,436 INFO     Training average positive_sample_loss at step 55600: 0.005194\n",
      "2023-12-09 21:01:07,437 INFO     Training average negative_sample_loss at step 55600: 0.005981\n",
      "2023-12-09 21:01:07,437 INFO     Training average loss at step 55600: 0.005587\n",
      "2023-12-09 21:01:21,876 INFO     Training average positive_sample_loss at step 55700: 0.005296\n",
      "2023-12-09 21:01:21,876 INFO     Training average negative_sample_loss at step 55700: 0.006217\n",
      "2023-12-09 21:01:21,876 INFO     Training average loss at step 55700: 0.005756\n",
      "2023-12-09 21:01:36,588 INFO     Training average positive_sample_loss at step 55800: 0.005251\n",
      "2023-12-09 21:01:36,589 INFO     Training average negative_sample_loss at step 55800: 0.006167\n",
      "2023-12-09 21:01:36,589 INFO     Training average loss at step 55800: 0.005709\n",
      "2023-12-09 21:01:50,460 INFO     Training average positive_sample_loss at step 55900: 0.005242\n",
      "2023-12-09 21:01:50,460 INFO     Training average negative_sample_loss at step 55900: 0.006042\n",
      "2023-12-09 21:01:50,460 INFO     Training average loss at step 55900: 0.005642\n",
      "2023-12-09 21:02:07,074 INFO     Training average positive_sample_loss at step 56000: 0.005278\n",
      "2023-12-09 21:02:07,074 INFO     Training average negative_sample_loss at step 56000: 0.006006\n",
      "2023-12-09 21:02:07,074 INFO     Training average loss at step 56000: 0.005642\n",
      "2023-12-09 21:02:21,732 INFO     Training average positive_sample_loss at step 56100: 0.005121\n",
      "2023-12-09 21:02:21,732 INFO     Training average negative_sample_loss at step 56100: 0.006236\n",
      "2023-12-09 21:02:21,732 INFO     Training average loss at step 56100: 0.005679\n",
      "2023-12-09 21:02:36,673 INFO     Training average positive_sample_loss at step 56200: 0.005229\n",
      "2023-12-09 21:02:36,674 INFO     Training average negative_sample_loss at step 56200: 0.005592\n",
      "2023-12-09 21:02:36,674 INFO     Training average loss at step 56200: 0.005410\n",
      "2023-12-09 21:02:51,627 INFO     Training average positive_sample_loss at step 56300: 0.005252\n",
      "2023-12-09 21:02:51,628 INFO     Training average negative_sample_loss at step 56300: 0.006008\n",
      "2023-12-09 21:02:51,628 INFO     Training average loss at step 56300: 0.005630\n",
      "2023-12-09 21:03:05,553 INFO     Training average positive_sample_loss at step 56400: 0.005287\n",
      "2023-12-09 21:03:05,553 INFO     Training average negative_sample_loss at step 56400: 0.006331\n",
      "2023-12-09 21:03:05,553 INFO     Training average loss at step 56400: 0.005809\n",
      "2023-12-09 21:03:19,515 INFO     Training average positive_sample_loss at step 56500: 0.005273\n",
      "2023-12-09 21:03:19,515 INFO     Training average negative_sample_loss at step 56500: 0.006535\n",
      "2023-12-09 21:03:19,515 INFO     Training average loss at step 56500: 0.005904\n",
      "2023-12-09 21:03:36,036 INFO     Training average positive_sample_loss at step 56600: 0.005119\n",
      "2023-12-09 21:03:36,036 INFO     Training average negative_sample_loss at step 56600: 0.005830\n",
      "2023-12-09 21:03:36,037 INFO     Training average loss at step 56600: 0.005475\n",
      "2023-12-09 21:03:50,608 INFO     Training average positive_sample_loss at step 56700: 0.005243\n",
      "2023-12-09 21:03:50,609 INFO     Training average negative_sample_loss at step 56700: 0.006489\n",
      "2023-12-09 21:03:50,609 INFO     Training average loss at step 56700: 0.005866\n",
      "2023-12-09 21:04:05,828 INFO     Training average positive_sample_loss at step 56800: 0.005177\n",
      "2023-12-09 21:04:05,828 INFO     Training average negative_sample_loss at step 56800: 0.005832\n",
      "2023-12-09 21:04:05,828 INFO     Training average loss at step 56800: 0.005504\n",
      "2023-12-09 21:04:19,552 INFO     Training average positive_sample_loss at step 56900: 0.005290\n",
      "2023-12-09 21:04:19,553 INFO     Training average negative_sample_loss at step 56900: 0.006291\n",
      "2023-12-09 21:04:19,553 INFO     Training average loss at step 56900: 0.005791\n",
      "2023-12-09 21:04:34,387 INFO     Training average positive_sample_loss at step 57000: 0.005255\n",
      "2023-12-09 21:04:34,387 INFO     Training average negative_sample_loss at step 57000: 0.005731\n",
      "2023-12-09 21:04:34,387 INFO     Training average loss at step 57000: 0.005493\n",
      "2023-12-09 21:04:51,230 INFO     Training average positive_sample_loss at step 57100: 0.005246\n",
      "2023-12-09 21:04:51,230 INFO     Training average negative_sample_loss at step 57100: 0.006014\n",
      "2023-12-09 21:04:51,230 INFO     Training average loss at step 57100: 0.005630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:05:04,683 INFO     Training average positive_sample_loss at step 57200: 0.005188\n",
      "2023-12-09 21:05:04,684 INFO     Training average negative_sample_loss at step 57200: 0.005863\n",
      "2023-12-09 21:05:04,684 INFO     Training average loss at step 57200: 0.005525\n",
      "2023-12-09 21:05:18,808 INFO     Training average positive_sample_loss at step 57300: 0.005188\n",
      "2023-12-09 21:05:18,808 INFO     Training average negative_sample_loss at step 57300: 0.006014\n",
      "2023-12-09 21:05:18,808 INFO     Training average loss at step 57300: 0.005601\n",
      "2023-12-09 21:05:32,958 INFO     Training average positive_sample_loss at step 57400: 0.005234\n",
      "2023-12-09 21:05:32,958 INFO     Training average negative_sample_loss at step 57400: 0.006293\n",
      "2023-12-09 21:05:32,958 INFO     Training average loss at step 57400: 0.005764\n",
      "2023-12-09 21:05:46,902 INFO     Training average positive_sample_loss at step 57500: 0.005291\n",
      "2023-12-09 21:05:46,902 INFO     Training average negative_sample_loss at step 57500: 0.005913\n",
      "2023-12-09 21:05:46,903 INFO     Training average loss at step 57500: 0.005602\n",
      "2023-12-09 21:06:02,742 INFO     Training average positive_sample_loss at step 57600: 0.005288\n",
      "2023-12-09 21:06:02,742 INFO     Training average negative_sample_loss at step 57600: 0.006069\n",
      "2023-12-09 21:06:02,742 INFO     Training average loss at step 57600: 0.005678\n",
      "2023-12-09 21:06:19,467 INFO     Training average positive_sample_loss at step 57700: 0.005161\n",
      "2023-12-09 21:06:19,468 INFO     Training average negative_sample_loss at step 57700: 0.005510\n",
      "2023-12-09 21:06:19,468 INFO     Training average loss at step 57700: 0.005336\n",
      "2023-12-09 21:06:33,830 INFO     Training average positive_sample_loss at step 57800: 0.005155\n",
      "2023-12-09 21:06:33,830 INFO     Training average negative_sample_loss at step 57800: 0.006917\n",
      "2023-12-09 21:06:33,830 INFO     Training average loss at step 57800: 0.006036\n",
      "2023-12-09 21:06:48,045 INFO     Training average positive_sample_loss at step 57900: 0.005278\n",
      "2023-12-09 21:06:48,045 INFO     Training average negative_sample_loss at step 57900: 0.006157\n",
      "2023-12-09 21:06:48,045 INFO     Training average loss at step 57900: 0.005718\n",
      "2023-12-09 21:07:01,923 INFO     Training average positive_sample_loss at step 58000: 0.005240\n",
      "2023-12-09 21:07:01,924 INFO     Training average negative_sample_loss at step 58000: 0.006095\n",
      "2023-12-09 21:07:01,924 INFO     Training average loss at step 58000: 0.005667\n",
      "2023-12-09 21:07:14,796 INFO     Training average positive_sample_loss at step 58100: 0.005275\n",
      "2023-12-09 21:07:14,796 INFO     Training average negative_sample_loss at step 58100: 0.005537\n",
      "2023-12-09 21:07:14,796 INFO     Training average loss at step 58100: 0.005406\n",
      "2023-12-09 21:07:31,682 INFO     Training average positive_sample_loss at step 58200: 0.005241\n",
      "2023-12-09 21:07:31,682 INFO     Training average negative_sample_loss at step 58200: 0.006068\n",
      "2023-12-09 21:07:31,682 INFO     Training average loss at step 58200: 0.005654\n",
      "2023-12-09 21:07:45,678 INFO     Training average positive_sample_loss at step 58300: 0.005168\n",
      "2023-12-09 21:07:45,679 INFO     Training average negative_sample_loss at step 58300: 0.005860\n",
      "2023-12-09 21:07:45,679 INFO     Training average loss at step 58300: 0.005514\n",
      "2023-12-09 21:07:58,712 INFO     Training average positive_sample_loss at step 58400: 0.005152\n",
      "2023-12-09 21:07:58,712 INFO     Training average negative_sample_loss at step 58400: 0.005991\n",
      "2023-12-09 21:07:58,712 INFO     Training average loss at step 58400: 0.005571\n",
      "2023-12-09 21:08:13,039 INFO     Training average positive_sample_loss at step 58500: 0.005239\n",
      "2023-12-09 21:08:13,039 INFO     Training average negative_sample_loss at step 58500: 0.005766\n",
      "2023-12-09 21:08:13,039 INFO     Training average loss at step 58500: 0.005503\n",
      "2023-12-09 21:08:26,791 INFO     Training average positive_sample_loss at step 58600: 0.005363\n",
      "2023-12-09 21:08:26,791 INFO     Training average negative_sample_loss at step 58600: 0.006576\n",
      "2023-12-09 21:08:26,792 INFO     Training average loss at step 58600: 0.005969\n",
      "2023-12-09 21:08:40,992 INFO     Training average positive_sample_loss at step 58700: 0.005220\n",
      "2023-12-09 21:08:40,992 INFO     Training average negative_sample_loss at step 58700: 0.005986\n",
      "2023-12-09 21:08:40,992 INFO     Training average loss at step 58700: 0.005603\n",
      "2023-12-09 21:08:59,250 INFO     Training average positive_sample_loss at step 58800: 0.005160\n",
      "2023-12-09 21:08:59,250 INFO     Training average negative_sample_loss at step 58800: 0.005512\n",
      "2023-12-09 21:08:59,250 INFO     Training average loss at step 58800: 0.005336\n",
      "2023-12-09 21:09:13,573 INFO     Training average positive_sample_loss at step 58900: 0.005149\n",
      "2023-12-09 21:09:13,573 INFO     Training average negative_sample_loss at step 58900: 0.005948\n",
      "2023-12-09 21:09:13,573 INFO     Training average loss at step 58900: 0.005548\n",
      "2023-12-09 21:09:27,935 INFO     Training average positive_sample_loss at step 59000: 0.005227\n",
      "2023-12-09 21:09:27,935 INFO     Training average negative_sample_loss at step 59000: 0.005534\n",
      "2023-12-09 21:09:27,935 INFO     Training average loss at step 59000: 0.005380\n",
      "2023-12-09 21:09:41,081 INFO     Training average positive_sample_loss at step 59100: 0.005218\n",
      "2023-12-09 21:09:41,081 INFO     Training average negative_sample_loss at step 59100: 0.006046\n",
      "2023-12-09 21:09:41,081 INFO     Training average loss at step 59100: 0.005632\n",
      "2023-12-09 21:09:55,430 INFO     Training average positive_sample_loss at step 59200: 0.005282\n",
      "2023-12-09 21:09:55,431 INFO     Training average negative_sample_loss at step 59200: 0.006191\n",
      "2023-12-09 21:09:55,431 INFO     Training average loss at step 59200: 0.005736\n",
      "2023-12-09 21:10:12,838 INFO     Training average positive_sample_loss at step 59300: 0.005274\n",
      "2023-12-09 21:10:12,838 INFO     Training average negative_sample_loss at step 59300: 0.006429\n",
      "2023-12-09 21:10:12,838 INFO     Training average loss at step 59300: 0.005852\n",
      "2023-12-09 21:10:27,702 INFO     Training average positive_sample_loss at step 59400: 0.005188\n",
      "2023-12-09 21:10:27,703 INFO     Training average negative_sample_loss at step 59400: 0.005977\n",
      "2023-12-09 21:10:27,703 INFO     Training average loss at step 59400: 0.005582\n",
      "2023-12-09 21:10:42,050 INFO     Training average positive_sample_loss at step 59500: 0.005216\n",
      "2023-12-09 21:10:42,050 INFO     Training average negative_sample_loss at step 59500: 0.005998\n",
      "2023-12-09 21:10:42,050 INFO     Training average loss at step 59500: 0.005607\n",
      "2023-12-09 21:10:56,419 INFO     Training average positive_sample_loss at step 59600: 0.005231\n",
      "2023-12-09 21:10:56,420 INFO     Training average negative_sample_loss at step 59600: 0.005832\n",
      "2023-12-09 21:10:56,420 INFO     Training average loss at step 59600: 0.005531\n",
      "2023-12-09 21:11:10,152 INFO     Training average positive_sample_loss at step 59700: 0.005214\n",
      "2023-12-09 21:11:10,153 INFO     Training average negative_sample_loss at step 59700: 0.005642\n",
      "2023-12-09 21:11:10,153 INFO     Training average loss at step 59700: 0.005428\n",
      "2023-12-09 21:11:23,987 INFO     Training average positive_sample_loss at step 59800: 0.005274\n",
      "2023-12-09 21:11:23,987 INFO     Training average negative_sample_loss at step 59800: 0.005546\n",
      "2023-12-09 21:11:23,987 INFO     Training average loss at step 59800: 0.005410\n",
      "2023-12-09 21:11:41,584 INFO     Training average positive_sample_loss at step 59900: 0.005186\n",
      "2023-12-09 21:11:41,585 INFO     Training average negative_sample_loss at step 59900: 0.006342\n",
      "2023-12-09 21:11:41,585 INFO     Training average loss at step 59900: 0.005764\n",
      "2023-12-09 21:12:08,318 INFO     Training average positive_sample_loss at step 60000: 0.005191\n",
      "2023-12-09 21:12:08,318 INFO     Training average negative_sample_loss at step 60000: 0.006011\n",
      "2023-12-09 21:12:08,318 INFO     Training average loss at step 60000: 0.005601\n",
      "2023-12-09 21:12:08,318 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 21:12:08,905 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 21:13:19,133 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 21:13:36,101 INFO     Valid MRR at step 60000: 0.949207\n",
      "2023-12-09 21:13:36,101 INFO     Valid MR at step 60000: 291.442200\n",
      "2023-12-09 21:13:36,101 INFO     Valid HITS@1 at step 60000: 0.944400\n",
      "2023-12-09 21:13:36,101 INFO     Valid HITS@3 at step 60000: 0.951800\n",
      "2023-12-09 21:13:36,101 INFO     Valid HITS@10 at step 60000: 0.957600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:13:50,517 INFO     Training average positive_sample_loss at step 60100: 0.005214\n",
      "2023-12-09 21:13:50,518 INFO     Training average negative_sample_loss at step 60100: 0.006054\n",
      "2023-12-09 21:13:50,518 INFO     Training average loss at step 60100: 0.005634\n",
      "2023-12-09 21:14:04,676 INFO     Training average positive_sample_loss at step 60200: 0.005206\n",
      "2023-12-09 21:14:04,676 INFO     Training average negative_sample_loss at step 60200: 0.006039\n",
      "2023-12-09 21:14:04,676 INFO     Training average loss at step 60200: 0.005622\n",
      "2023-12-09 21:14:17,879 INFO     Training average positive_sample_loss at step 60300: 0.005268\n",
      "2023-12-09 21:14:17,879 INFO     Training average negative_sample_loss at step 60300: 0.006133\n",
      "2023-12-09 21:14:17,879 INFO     Training average loss at step 60300: 0.005700\n",
      "2023-12-09 21:14:35,077 INFO     Training average positive_sample_loss at step 60400: 0.005262\n",
      "2023-12-09 21:14:35,078 INFO     Training average negative_sample_loss at step 60400: 0.006141\n",
      "2023-12-09 21:14:35,078 INFO     Training average loss at step 60400: 0.005701\n",
      "2023-12-09 21:14:49,569 INFO     Training average positive_sample_loss at step 60500: 0.005145\n",
      "2023-12-09 21:14:49,569 INFO     Training average negative_sample_loss at step 60500: 0.005891\n",
      "2023-12-09 21:14:49,569 INFO     Training average loss at step 60500: 0.005518\n",
      "2023-12-09 21:15:02,862 INFO     Training average positive_sample_loss at step 60600: 0.005171\n",
      "2023-12-09 21:15:02,863 INFO     Training average negative_sample_loss at step 60600: 0.005901\n",
      "2023-12-09 21:15:02,863 INFO     Training average loss at step 60600: 0.005536\n",
      "2023-12-09 21:15:17,374 INFO     Training average positive_sample_loss at step 60700: 0.005254\n",
      "2023-12-09 21:15:17,374 INFO     Training average negative_sample_loss at step 60700: 0.006170\n",
      "2023-12-09 21:15:17,375 INFO     Training average loss at step 60700: 0.005712\n",
      "2023-12-09 21:15:31,873 INFO     Training average positive_sample_loss at step 60800: 0.005266\n",
      "2023-12-09 21:15:31,874 INFO     Training average negative_sample_loss at step 60800: 0.005663\n",
      "2023-12-09 21:15:31,874 INFO     Training average loss at step 60800: 0.005465\n",
      "2023-12-09 21:15:45,597 INFO     Training average positive_sample_loss at step 60900: 0.005262\n",
      "2023-12-09 21:15:45,597 INFO     Training average negative_sample_loss at step 60900: 0.005997\n",
      "2023-12-09 21:15:45,597 INFO     Training average loss at step 60900: 0.005629\n",
      "2023-12-09 21:16:02,492 INFO     Training average positive_sample_loss at step 61000: 0.005203\n",
      "2023-12-09 21:16:02,493 INFO     Training average negative_sample_loss at step 61000: 0.006817\n",
      "2023-12-09 21:16:02,493 INFO     Training average loss at step 61000: 0.006010\n",
      "2023-12-09 21:16:16,671 INFO     Training average positive_sample_loss at step 61100: 0.005126\n",
      "2023-12-09 21:16:16,671 INFO     Training average negative_sample_loss at step 61100: 0.006262\n",
      "2023-12-09 21:16:16,671 INFO     Training average loss at step 61100: 0.005694\n",
      "2023-12-09 21:16:31,361 INFO     Training average positive_sample_loss at step 61200: 0.005251\n",
      "2023-12-09 21:16:31,362 INFO     Training average negative_sample_loss at step 61200: 0.005785\n",
      "2023-12-09 21:16:31,362 INFO     Training average loss at step 61200: 0.005518\n",
      "2023-12-09 21:16:45,646 INFO     Training average positive_sample_loss at step 61300: 0.005222\n",
      "2023-12-09 21:16:45,646 INFO     Training average negative_sample_loss at step 61300: 0.006572\n",
      "2023-12-09 21:16:45,646 INFO     Training average loss at step 61300: 0.005897\n",
      "2023-12-09 21:17:00,076 INFO     Training average positive_sample_loss at step 61400: 0.005312\n",
      "2023-12-09 21:17:00,077 INFO     Training average negative_sample_loss at step 61400: 0.005722\n",
      "2023-12-09 21:17:00,077 INFO     Training average loss at step 61400: 0.005517\n",
      "2023-12-09 21:17:17,452 INFO     Training average positive_sample_loss at step 61500: 0.005229\n",
      "2023-12-09 21:17:17,453 INFO     Training average negative_sample_loss at step 61500: 0.006082\n",
      "2023-12-09 21:17:17,453 INFO     Training average loss at step 61500: 0.005656\n",
      "2023-12-09 21:17:32,109 INFO     Training average positive_sample_loss at step 61600: 0.005147\n",
      "2023-12-09 21:17:32,109 INFO     Training average negative_sample_loss at step 61600: 0.005951\n",
      "2023-12-09 21:17:32,109 INFO     Training average loss at step 61600: 0.005549\n",
      "2023-12-09 21:17:46,936 INFO     Training average positive_sample_loss at step 61700: 0.005176\n",
      "2023-12-09 21:17:46,937 INFO     Training average negative_sample_loss at step 61700: 0.005834\n",
      "2023-12-09 21:17:46,937 INFO     Training average loss at step 61700: 0.005505\n",
      "2023-12-09 21:18:01,316 INFO     Training average positive_sample_loss at step 61800: 0.005189\n",
      "2023-12-09 21:18:01,316 INFO     Training average negative_sample_loss at step 61800: 0.005626\n",
      "2023-12-09 21:18:01,316 INFO     Training average loss at step 61800: 0.005408\n",
      "2023-12-09 21:18:14,516 INFO     Training average positive_sample_loss at step 61900: 0.005238\n",
      "2023-12-09 21:18:14,517 INFO     Training average negative_sample_loss at step 61900: 0.006119\n",
      "2023-12-09 21:18:14,517 INFO     Training average loss at step 61900: 0.005678\n",
      "2023-12-09 21:18:29,645 INFO     Training average positive_sample_loss at step 62000: 0.005342\n",
      "2023-12-09 21:18:29,645 INFO     Training average negative_sample_loss at step 62000: 0.006231\n",
      "2023-12-09 21:18:29,645 INFO     Training average loss at step 62000: 0.005786\n",
      "2023-12-09 21:18:47,112 INFO     Training average positive_sample_loss at step 62100: 0.005191\n",
      "2023-12-09 21:18:47,112 INFO     Training average negative_sample_loss at step 62100: 0.005688\n",
      "2023-12-09 21:18:47,112 INFO     Training average loss at step 62100: 0.005440\n",
      "2023-12-09 21:19:02,129 INFO     Training average positive_sample_loss at step 62200: 0.005166\n",
      "2023-12-09 21:19:02,129 INFO     Training average negative_sample_loss at step 62200: 0.005544\n",
      "2023-12-09 21:19:02,129 INFO     Training average loss at step 62200: 0.005355\n",
      "2023-12-09 21:19:16,732 INFO     Training average positive_sample_loss at step 62300: 0.005190\n",
      "2023-12-09 21:19:16,732 INFO     Training average negative_sample_loss at step 62300: 0.006370\n",
      "2023-12-09 21:19:16,733 INFO     Training average loss at step 62300: 0.005780\n",
      "2023-12-09 21:19:31,155 INFO     Training average positive_sample_loss at step 62400: 0.005270\n",
      "2023-12-09 21:19:31,156 INFO     Training average negative_sample_loss at step 62400: 0.006219\n",
      "2023-12-09 21:19:31,156 INFO     Training average loss at step 62400: 0.005745\n",
      "2023-12-09 21:19:45,506 INFO     Training average positive_sample_loss at step 62500: 0.005254\n",
      "2023-12-09 21:19:45,506 INFO     Training average negative_sample_loss at step 62500: 0.006079\n",
      "2023-12-09 21:19:45,506 INFO     Training average loss at step 62500: 0.005666\n",
      "2023-12-09 21:19:58,487 INFO     Training average positive_sample_loss at step 62600: 0.005270\n",
      "2023-12-09 21:19:58,487 INFO     Training average negative_sample_loss at step 62600: 0.006311\n",
      "2023-12-09 21:19:58,487 INFO     Training average loss at step 62600: 0.005791\n",
      "2023-12-09 21:20:16,735 INFO     Training average positive_sample_loss at step 62700: 0.005156\n",
      "2023-12-09 21:20:16,736 INFO     Training average negative_sample_loss at step 62700: 0.005806\n",
      "2023-12-09 21:20:16,736 INFO     Training average loss at step 62700: 0.005481\n",
      "2023-12-09 21:20:31,215 INFO     Training average positive_sample_loss at step 62800: 0.005123\n",
      "2023-12-09 21:20:31,215 INFO     Training average negative_sample_loss at step 62800: 0.006302\n",
      "2023-12-09 21:20:31,215 INFO     Training average loss at step 62800: 0.005713\n",
      "2023-12-09 21:20:44,221 INFO     Training average positive_sample_loss at step 62900: 0.005231\n",
      "2023-12-09 21:20:44,221 INFO     Training average negative_sample_loss at step 62900: 0.006261\n",
      "2023-12-09 21:20:44,221 INFO     Training average loss at step 62900: 0.005746\n",
      "2023-12-09 21:20:58,608 INFO     Training average positive_sample_loss at step 63000: 0.005266\n",
      "2023-12-09 21:20:58,608 INFO     Training average negative_sample_loss at step 63000: 0.006207\n",
      "2023-12-09 21:20:58,608 INFO     Training average loss at step 63000: 0.005736\n",
      "2023-12-09 21:21:12,914 INFO     Training average positive_sample_loss at step 63100: 0.005231\n",
      "2023-12-09 21:21:12,915 INFO     Training average negative_sample_loss at step 63100: 0.005576\n",
      "2023-12-09 21:21:12,915 INFO     Training average loss at step 63100: 0.005404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:21:32,383 INFO     Training average positive_sample_loss at step 63200: 0.005213\n",
      "2023-12-09 21:21:32,384 INFO     Training average negative_sample_loss at step 63200: 0.005964\n",
      "2023-12-09 21:21:32,384 INFO     Training average loss at step 63200: 0.005589\n",
      "2023-12-09 21:21:47,910 INFO     Training average positive_sample_loss at step 63300: 0.005134\n",
      "2023-12-09 21:21:47,910 INFO     Training average negative_sample_loss at step 63300: 0.006323\n",
      "2023-12-09 21:21:47,911 INFO     Training average loss at step 63300: 0.005728\n",
      "2023-12-09 21:22:01,451 INFO     Training average positive_sample_loss at step 63400: 0.005218\n",
      "2023-12-09 21:22:01,451 INFO     Training average negative_sample_loss at step 63400: 0.005955\n",
      "2023-12-09 21:22:01,451 INFO     Training average loss at step 63400: 0.005586\n",
      "2023-12-09 21:22:15,277 INFO     Training average positive_sample_loss at step 63500: 0.005253\n",
      "2023-12-09 21:22:15,277 INFO     Training average negative_sample_loss at step 63500: 0.006186\n",
      "2023-12-09 21:22:15,277 INFO     Training average loss at step 63500: 0.005720\n",
      "2023-12-09 21:22:29,125 INFO     Training average positive_sample_loss at step 63600: 0.005210\n",
      "2023-12-09 21:22:29,126 INFO     Training average negative_sample_loss at step 63600: 0.006124\n",
      "2023-12-09 21:22:29,126 INFO     Training average loss at step 63600: 0.005667\n",
      "2023-12-09 21:22:43,443 INFO     Training average positive_sample_loss at step 63700: 0.005319\n",
      "2023-12-09 21:22:43,443 INFO     Training average negative_sample_loss at step 63700: 0.006536\n",
      "2023-12-09 21:22:43,443 INFO     Training average loss at step 63700: 0.005928\n",
      "2023-12-09 21:23:00,941 INFO     Training average positive_sample_loss at step 63800: 0.005131\n",
      "2023-12-09 21:23:00,941 INFO     Training average negative_sample_loss at step 63800: 0.005775\n",
      "2023-12-09 21:23:00,941 INFO     Training average loss at step 63800: 0.005453\n",
      "2023-12-09 21:23:15,366 INFO     Training average positive_sample_loss at step 63900: 0.005156\n",
      "2023-12-09 21:23:15,366 INFO     Training average negative_sample_loss at step 63900: 0.005925\n",
      "2023-12-09 21:23:15,366 INFO     Training average loss at step 63900: 0.005541\n",
      "2023-12-09 21:23:28,728 INFO     Training average positive_sample_loss at step 64000: 0.005226\n",
      "2023-12-09 21:23:28,728 INFO     Training average negative_sample_loss at step 64000: 0.006882\n",
      "2023-12-09 21:23:28,728 INFO     Training average loss at step 64000: 0.006054\n",
      "2023-12-09 21:23:43,468 INFO     Training average positive_sample_loss at step 64100: 0.005205\n",
      "2023-12-09 21:23:43,468 INFO     Training average negative_sample_loss at step 64100: 0.005951\n",
      "2023-12-09 21:23:43,468 INFO     Training average loss at step 64100: 0.005578\n",
      "2023-12-09 21:23:57,974 INFO     Training average positive_sample_loss at step 64200: 0.005309\n",
      "2023-12-09 21:23:57,975 INFO     Training average negative_sample_loss at step 64200: 0.006276\n",
      "2023-12-09 21:23:57,975 INFO     Training average loss at step 64200: 0.005792\n",
      "2023-12-09 21:24:15,295 INFO     Training average positive_sample_loss at step 64300: 0.005264\n",
      "2023-12-09 21:24:15,295 INFO     Training average negative_sample_loss at step 64300: 0.006053\n",
      "2023-12-09 21:24:15,295 INFO     Training average loss at step 64300: 0.005659\n",
      "2023-12-09 21:24:29,506 INFO     Training average positive_sample_loss at step 64400: 0.005151\n",
      "2023-12-09 21:24:29,506 INFO     Training average negative_sample_loss at step 64400: 0.005956\n",
      "2023-12-09 21:24:29,506 INFO     Training average loss at step 64400: 0.005553\n",
      "2023-12-09 21:24:43,729 INFO     Training average positive_sample_loss at step 64500: 0.005134\n",
      "2023-12-09 21:24:43,730 INFO     Training average negative_sample_loss at step 64500: 0.006321\n",
      "2023-12-09 21:24:43,730 INFO     Training average loss at step 64500: 0.005727\n",
      "2023-12-09 21:24:58,278 INFO     Training average positive_sample_loss at step 64600: 0.005226\n",
      "2023-12-09 21:24:58,278 INFO     Training average negative_sample_loss at step 64600: 0.005372\n",
      "2023-12-09 21:24:58,278 INFO     Training average loss at step 64600: 0.005299\n",
      "2023-12-09 21:25:11,866 INFO     Training average positive_sample_loss at step 64700: 0.005283\n",
      "2023-12-09 21:25:11,866 INFO     Training average negative_sample_loss at step 64700: 0.006337\n",
      "2023-12-09 21:25:11,867 INFO     Training average loss at step 64700: 0.005810\n",
      "2023-12-09 21:25:25,596 INFO     Training average positive_sample_loss at step 64800: 0.005306\n",
      "2023-12-09 21:25:25,596 INFO     Training average negative_sample_loss at step 64800: 0.005767\n",
      "2023-12-09 21:25:25,597 INFO     Training average loss at step 64800: 0.005537\n",
      "2023-12-09 21:25:41,549 INFO     Training average positive_sample_loss at step 64900: 0.005199\n",
      "2023-12-09 21:25:41,549 INFO     Training average negative_sample_loss at step 64900: 0.006506\n",
      "2023-12-09 21:25:41,549 INFO     Training average loss at step 64900: 0.005853\n",
      "2023-12-09 21:25:55,515 INFO     Training average positive_sample_loss at step 65000: 0.005170\n",
      "2023-12-09 21:25:55,515 INFO     Training average negative_sample_loss at step 65000: 0.005681\n",
      "2023-12-09 21:25:55,515 INFO     Training average loss at step 65000: 0.005425\n",
      "2023-12-09 21:26:09,450 INFO     Training average positive_sample_loss at step 65100: 0.005228\n",
      "2023-12-09 21:26:09,451 INFO     Training average negative_sample_loss at step 65100: 0.005698\n",
      "2023-12-09 21:26:09,451 INFO     Training average loss at step 65100: 0.005463\n",
      "2023-12-09 21:26:23,520 INFO     Training average positive_sample_loss at step 65200: 0.005225\n",
      "2023-12-09 21:26:23,520 INFO     Training average negative_sample_loss at step 65200: 0.005425\n",
      "2023-12-09 21:26:23,520 INFO     Training average loss at step 65200: 0.005325\n",
      "2023-12-09 21:26:37,097 INFO     Training average positive_sample_loss at step 65300: 0.005248\n",
      "2023-12-09 21:26:37,097 INFO     Training average negative_sample_loss at step 65300: 0.006651\n",
      "2023-12-09 21:26:37,097 INFO     Training average loss at step 65300: 0.005949\n",
      "2023-12-09 21:26:53,632 INFO     Training average positive_sample_loss at step 65400: 0.005197\n",
      "2023-12-09 21:26:53,632 INFO     Training average negative_sample_loss at step 65400: 0.006077\n",
      "2023-12-09 21:26:53,632 INFO     Training average loss at step 65400: 0.005637\n",
      "2023-12-09 21:27:07,663 INFO     Training average positive_sample_loss at step 65500: 0.005112\n",
      "2023-12-09 21:27:07,664 INFO     Training average negative_sample_loss at step 65500: 0.006297\n",
      "2023-12-09 21:27:07,664 INFO     Training average loss at step 65500: 0.005704\n",
      "2023-12-09 21:27:21,070 INFO     Training average positive_sample_loss at step 65600: 0.005227\n",
      "2023-12-09 21:27:21,070 INFO     Training average negative_sample_loss at step 65600: 0.006340\n",
      "2023-12-09 21:27:21,070 INFO     Training average loss at step 65600: 0.005784\n",
      "2023-12-09 21:27:35,659 INFO     Training average positive_sample_loss at step 65700: 0.005234\n",
      "2023-12-09 21:27:35,659 INFO     Training average negative_sample_loss at step 65700: 0.006030\n",
      "2023-12-09 21:27:35,659 INFO     Training average loss at step 65700: 0.005632\n",
      "2023-12-09 21:27:49,689 INFO     Training average positive_sample_loss at step 65800: 0.005268\n",
      "2023-12-09 21:27:49,690 INFO     Training average negative_sample_loss at step 65800: 0.006137\n",
      "2023-12-09 21:27:49,690 INFO     Training average loss at step 65800: 0.005703\n",
      "2023-12-09 21:28:03,964 INFO     Training average positive_sample_loss at step 65900: 0.005257\n",
      "2023-12-09 21:28:03,964 INFO     Training average negative_sample_loss at step 65900: 0.006310\n",
      "2023-12-09 21:28:03,964 INFO     Training average loss at step 65900: 0.005783\n",
      "2023-12-09 21:28:20,651 INFO     Training average positive_sample_loss at step 66000: 0.005154\n",
      "2023-12-09 21:28:20,652 INFO     Training average negative_sample_loss at step 66000: 0.006978\n",
      "2023-12-09 21:28:20,652 INFO     Training average loss at step 66000: 0.006066\n",
      "2023-12-09 21:28:34,149 INFO     Training average positive_sample_loss at step 66100: 0.005201\n",
      "2023-12-09 21:28:34,149 INFO     Training average negative_sample_loss at step 66100: 0.006050\n",
      "2023-12-09 21:28:34,149 INFO     Training average loss at step 66100: 0.005625\n",
      "2023-12-09 21:28:47,950 INFO     Training average positive_sample_loss at step 66200: 0.005182\n",
      "2023-12-09 21:28:47,951 INFO     Training average negative_sample_loss at step 66200: 0.006309\n",
      "2023-12-09 21:28:47,951 INFO     Training average loss at step 66200: 0.005746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:29:01,527 INFO     Training average positive_sample_loss at step 66300: 0.005297\n",
      "2023-12-09 21:29:01,527 INFO     Training average negative_sample_loss at step 66300: 0.006716\n",
      "2023-12-09 21:29:01,527 INFO     Training average loss at step 66300: 0.006007\n",
      "2023-12-09 21:29:15,719 INFO     Training average positive_sample_loss at step 66400: 0.005237\n",
      "2023-12-09 21:29:15,719 INFO     Training average negative_sample_loss at step 66400: 0.005860\n",
      "2023-12-09 21:29:15,719 INFO     Training average loss at step 66400: 0.005549\n",
      "2023-12-09 21:29:33,841 INFO     Training average positive_sample_loss at step 66500: 0.005232\n",
      "2023-12-09 21:29:33,842 INFO     Training average negative_sample_loss at step 66500: 0.005775\n",
      "2023-12-09 21:29:33,842 INFO     Training average loss at step 66500: 0.005504\n",
      "2023-12-09 21:29:47,280 INFO     Training average positive_sample_loss at step 66600: 0.005162\n",
      "2023-12-09 21:29:47,280 INFO     Training average negative_sample_loss at step 66600: 0.006155\n",
      "2023-12-09 21:29:47,280 INFO     Training average loss at step 66600: 0.005658\n",
      "2023-12-09 21:30:01,645 INFO     Training average positive_sample_loss at step 66700: 0.005197\n",
      "2023-12-09 21:30:01,645 INFO     Training average negative_sample_loss at step 66700: 0.005934\n",
      "2023-12-09 21:30:01,645 INFO     Training average loss at step 66700: 0.005565\n",
      "2023-12-09 21:30:16,271 INFO     Training average positive_sample_loss at step 66800: 0.005233\n",
      "2023-12-09 21:30:16,272 INFO     Training average negative_sample_loss at step 66800: 0.006189\n",
      "2023-12-09 21:30:16,272 INFO     Training average loss at step 66800: 0.005711\n",
      "2023-12-09 21:30:30,697 INFO     Training average positive_sample_loss at step 66900: 0.005256\n",
      "2023-12-09 21:30:30,697 INFO     Training average negative_sample_loss at step 66900: 0.006361\n",
      "2023-12-09 21:30:30,698 INFO     Training average loss at step 66900: 0.005809\n",
      "2023-12-09 21:30:44,806 INFO     Training average positive_sample_loss at step 67000: 0.005279\n",
      "2023-12-09 21:30:44,807 INFO     Training average negative_sample_loss at step 67000: 0.006309\n",
      "2023-12-09 21:30:44,807 INFO     Training average loss at step 67000: 0.005794\n",
      "2023-12-09 21:31:01,335 INFO     Training average positive_sample_loss at step 67100: 0.005177\n",
      "2023-12-09 21:31:01,336 INFO     Training average negative_sample_loss at step 67100: 0.007284\n",
      "2023-12-09 21:31:01,336 INFO     Training average loss at step 67100: 0.006230\n",
      "2023-12-09 21:31:15,680 INFO     Training average positive_sample_loss at step 67200: 0.005219\n",
      "2023-12-09 21:31:15,681 INFO     Training average negative_sample_loss at step 67200: 0.006044\n",
      "2023-12-09 21:31:15,681 INFO     Training average loss at step 67200: 0.005632\n",
      "2023-12-09 21:31:30,094 INFO     Training average positive_sample_loss at step 67300: 0.005163\n",
      "2023-12-09 21:31:30,095 INFO     Training average negative_sample_loss at step 67300: 0.006043\n",
      "2023-12-09 21:31:30,095 INFO     Training average loss at step 67300: 0.005603\n",
      "2023-12-09 21:31:44,085 INFO     Training average positive_sample_loss at step 67400: 0.005221\n",
      "2023-12-09 21:31:44,086 INFO     Training average negative_sample_loss at step 67400: 0.005220\n",
      "2023-12-09 21:31:44,086 INFO     Training average loss at step 67400: 0.005220\n",
      "2023-12-09 21:31:57,575 INFO     Training average positive_sample_loss at step 67500: 0.005318\n",
      "2023-12-09 21:31:57,575 INFO     Training average negative_sample_loss at step 67500: 0.005723\n",
      "2023-12-09 21:31:57,575 INFO     Training average loss at step 67500: 0.005521\n",
      "2023-12-09 21:32:14,807 INFO     Training average positive_sample_loss at step 67600: 0.005177\n",
      "2023-12-09 21:32:14,808 INFO     Training average negative_sample_loss at step 67600: 0.005349\n",
      "2023-12-09 21:32:14,808 INFO     Training average loss at step 67600: 0.005263\n",
      "2023-12-09 21:32:27,756 INFO     Training average positive_sample_loss at step 67700: 0.005159\n",
      "2023-12-09 21:32:27,756 INFO     Training average negative_sample_loss at step 67700: 0.006400\n",
      "2023-12-09 21:32:27,756 INFO     Training average loss at step 67700: 0.005780\n",
      "2023-12-09 21:32:41,929 INFO     Training average positive_sample_loss at step 67800: 0.005186\n",
      "2023-12-09 21:32:41,930 INFO     Training average negative_sample_loss at step 67800: 0.005706\n",
      "2023-12-09 21:32:41,930 INFO     Training average loss at step 67800: 0.005446\n",
      "2023-12-09 21:32:56,519 INFO     Training average positive_sample_loss at step 67900: 0.005263\n",
      "2023-12-09 21:32:56,520 INFO     Training average negative_sample_loss at step 67900: 0.005933\n",
      "2023-12-09 21:32:56,520 INFO     Training average loss at step 67900: 0.005598\n",
      "2023-12-09 21:33:11,084 INFO     Training average positive_sample_loss at step 68000: 0.005210\n",
      "2023-12-09 21:33:11,084 INFO     Training average negative_sample_loss at step 68000: 0.005970\n",
      "2023-12-09 21:33:11,084 INFO     Training average loss at step 68000: 0.005590\n",
      "2023-12-09 21:33:26,234 INFO     Training average positive_sample_loss at step 68100: 0.005286\n",
      "2023-12-09 21:33:26,234 INFO     Training average negative_sample_loss at step 68100: 0.005624\n",
      "2023-12-09 21:33:26,235 INFO     Training average loss at step 68100: 0.005455\n",
      "2023-12-09 21:33:43,941 INFO     Training average positive_sample_loss at step 68200: 0.005113\n",
      "2023-12-09 21:33:43,941 INFO     Training average negative_sample_loss at step 68200: 0.006029\n",
      "2023-12-09 21:33:43,941 INFO     Training average loss at step 68200: 0.005571\n",
      "2023-12-09 21:33:57,547 INFO     Training average positive_sample_loss at step 68300: 0.005160\n",
      "2023-12-09 21:33:57,548 INFO     Training average negative_sample_loss at step 68300: 0.006362\n",
      "2023-12-09 21:33:57,548 INFO     Training average loss at step 68300: 0.005761\n",
      "2023-12-09 21:34:11,809 INFO     Training average positive_sample_loss at step 68400: 0.005217\n",
      "2023-12-09 21:34:11,810 INFO     Training average negative_sample_loss at step 68400: 0.005647\n",
      "2023-12-09 21:34:11,810 INFO     Training average loss at step 68400: 0.005432\n",
      "2023-12-09 21:34:25,639 INFO     Training average positive_sample_loss at step 68500: 0.005229\n",
      "2023-12-09 21:34:25,640 INFO     Training average negative_sample_loss at step 68500: 0.005851\n",
      "2023-12-09 21:34:25,640 INFO     Training average loss at step 68500: 0.005540\n",
      "2023-12-09 21:34:39,291 INFO     Training average positive_sample_loss at step 68600: 0.005262\n",
      "2023-12-09 21:34:39,291 INFO     Training average negative_sample_loss at step 68600: 0.005723\n",
      "2023-12-09 21:34:39,291 INFO     Training average loss at step 68600: 0.005493\n",
      "2023-12-09 21:34:56,171 INFO     Training average positive_sample_loss at step 68700: 0.005293\n",
      "2023-12-09 21:34:56,172 INFO     Training average negative_sample_loss at step 68700: 0.005782\n",
      "2023-12-09 21:34:56,172 INFO     Training average loss at step 68700: 0.005538\n",
      "2023-12-09 21:35:09,910 INFO     Training average positive_sample_loss at step 68800: 0.005120\n",
      "2023-12-09 21:35:09,911 INFO     Training average negative_sample_loss at step 68800: 0.005842\n",
      "2023-12-09 21:35:09,911 INFO     Training average loss at step 68800: 0.005481\n",
      "2023-12-09 21:35:23,925 INFO     Training average positive_sample_loss at step 68900: 0.005166\n",
      "2023-12-09 21:35:23,925 INFO     Training average negative_sample_loss at step 68900: 0.005788\n",
      "2023-12-09 21:35:23,925 INFO     Training average loss at step 68900: 0.005477\n",
      "2023-12-09 21:35:38,075 INFO     Training average positive_sample_loss at step 69000: 0.005233\n",
      "2023-12-09 21:35:38,076 INFO     Training average negative_sample_loss at step 69000: 0.006386\n",
      "2023-12-09 21:35:38,076 INFO     Training average loss at step 69000: 0.005809\n",
      "2023-12-09 21:35:52,442 INFO     Training average positive_sample_loss at step 69100: 0.005259\n",
      "2023-12-09 21:35:52,442 INFO     Training average negative_sample_loss at step 69100: 0.006807\n",
      "2023-12-09 21:35:52,442 INFO     Training average loss at step 69100: 0.006033\n",
      "2023-12-09 21:36:07,181 INFO     Training average positive_sample_loss at step 69200: 0.005235\n",
      "2023-12-09 21:36:07,182 INFO     Training average negative_sample_loss at step 69200: 0.005450\n",
      "2023-12-09 21:36:07,182 INFO     Training average loss at step 69200: 0.005342\n",
      "2023-12-09 21:36:24,428 INFO     Training average positive_sample_loss at step 69300: 0.005201\n",
      "2023-12-09 21:36:24,428 INFO     Training average negative_sample_loss at step 69300: 0.005993\n",
      "2023-12-09 21:36:24,428 INFO     Training average loss at step 69300: 0.005597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:36:38,077 INFO     Training average positive_sample_loss at step 69400: 0.005144\n",
      "2023-12-09 21:36:38,077 INFO     Training average negative_sample_loss at step 69400: 0.005844\n",
      "2023-12-09 21:36:38,077 INFO     Training average loss at step 69400: 0.005494\n",
      "2023-12-09 21:36:51,245 INFO     Training average positive_sample_loss at step 69500: 0.005181\n",
      "2023-12-09 21:36:51,245 INFO     Training average negative_sample_loss at step 69500: 0.006457\n",
      "2023-12-09 21:36:51,245 INFO     Training average loss at step 69500: 0.005819\n",
      "2023-12-09 21:37:05,756 INFO     Training average positive_sample_loss at step 69600: 0.005244\n",
      "2023-12-09 21:37:05,756 INFO     Training average negative_sample_loss at step 69600: 0.006245\n",
      "2023-12-09 21:37:05,757 INFO     Training average loss at step 69600: 0.005744\n",
      "2023-12-09 21:37:19,667 INFO     Training average positive_sample_loss at step 69700: 0.005258\n",
      "2023-12-09 21:37:19,667 INFO     Training average negative_sample_loss at step 69700: 0.006139\n",
      "2023-12-09 21:37:19,667 INFO     Training average loss at step 69700: 0.005698\n",
      "2023-12-09 21:37:33,588 INFO     Training average positive_sample_loss at step 69800: 0.005279\n",
      "2023-12-09 21:37:33,589 INFO     Training average negative_sample_loss at step 69800: 0.005582\n",
      "2023-12-09 21:37:33,589 INFO     Training average loss at step 69800: 0.005431\n",
      "2023-12-09 21:37:50,134 INFO     Training average positive_sample_loss at step 69900: 0.005102\n",
      "2023-12-09 21:37:50,135 INFO     Training average negative_sample_loss at step 69900: 0.005762\n",
      "2023-12-09 21:37:50,135 INFO     Training average loss at step 69900: 0.005432\n",
      "2023-12-09 21:38:18,915 INFO     Training average positive_sample_loss at step 70000: 0.005172\n",
      "2023-12-09 21:38:18,915 INFO     Training average negative_sample_loss at step 70000: 0.005482\n",
      "2023-12-09 21:38:18,915 INFO     Training average loss at step 70000: 0.005327\n",
      "2023-12-09 21:38:18,915 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 21:38:19,476 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 21:39:13,319 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 21:39:26,812 INFO     Valid MRR at step 70000: 0.949140\n",
      "2023-12-09 21:39:26,812 INFO     Valid MR at step 70000: 292.309700\n",
      "2023-12-09 21:39:26,812 INFO     Valid HITS@1 at step 70000: 0.944400\n",
      "2023-12-09 21:39:26,812 INFO     Valid HITS@3 at step 70000: 0.951200\n",
      "2023-12-09 21:39:26,812 INFO     Valid HITS@10 at step 70000: 0.958000\n",
      "2023-12-09 21:39:39,462 INFO     Training average positive_sample_loss at step 70100: 0.005248\n",
      "2023-12-09 21:39:39,462 INFO     Training average negative_sample_loss at step 70100: 0.006123\n",
      "2023-12-09 21:39:39,462 INFO     Training average loss at step 70100: 0.005686\n",
      "2023-12-09 21:39:53,869 INFO     Training average positive_sample_loss at step 70200: 0.005148\n",
      "2023-12-09 21:39:53,869 INFO     Training average negative_sample_loss at step 70200: 0.005731\n",
      "2023-12-09 21:39:53,869 INFO     Training average loss at step 70200: 0.005439\n",
      "2023-12-09 21:40:07,513 INFO     Training average positive_sample_loss at step 70300: 0.005270\n",
      "2023-12-09 21:40:07,513 INFO     Training average negative_sample_loss at step 70300: 0.005955\n",
      "2023-12-09 21:40:07,513 INFO     Training average loss at step 70300: 0.005612\n",
      "2023-12-09 21:40:24,441 INFO     Training average positive_sample_loss at step 70400: 0.005282\n",
      "2023-12-09 21:40:24,442 INFO     Training average negative_sample_loss at step 70400: 0.005663\n",
      "2023-12-09 21:40:24,442 INFO     Training average loss at step 70400: 0.005473\n",
      "2023-12-09 21:40:37,625 INFO     Training average positive_sample_loss at step 70500: 0.005151\n",
      "2023-12-09 21:40:37,626 INFO     Training average negative_sample_loss at step 70500: 0.006118\n",
      "2023-12-09 21:40:37,626 INFO     Training average loss at step 70500: 0.005634\n",
      "2023-12-09 21:40:53,159 INFO     Training average positive_sample_loss at step 70600: 0.005179\n",
      "2023-12-09 21:40:53,160 INFO     Training average negative_sample_loss at step 70600: 0.006137\n",
      "2023-12-09 21:40:53,160 INFO     Training average loss at step 70600: 0.005658\n",
      "2023-12-09 21:41:06,339 INFO     Training average positive_sample_loss at step 70700: 0.005222\n",
      "2023-12-09 21:41:06,340 INFO     Training average negative_sample_loss at step 70700: 0.006132\n",
      "2023-12-09 21:41:06,340 INFO     Training average loss at step 70700: 0.005677\n",
      "2023-12-09 21:41:20,423 INFO     Training average positive_sample_loss at step 70800: 0.005236\n",
      "2023-12-09 21:41:20,424 INFO     Training average negative_sample_loss at step 70800: 0.006115\n",
      "2023-12-09 21:41:20,424 INFO     Training average loss at step 70800: 0.005676\n",
      "2023-12-09 21:41:33,907 INFO     Training average positive_sample_loss at step 70900: 0.005274\n",
      "2023-12-09 21:41:33,907 INFO     Training average negative_sample_loss at step 70900: 0.006338\n",
      "2023-12-09 21:41:33,908 INFO     Training average loss at step 70900: 0.005806\n",
      "2023-12-09 21:41:49,894 INFO     Training average positive_sample_loss at step 71000: 0.005144\n",
      "2023-12-09 21:41:49,894 INFO     Training average negative_sample_loss at step 71000: 0.005857\n",
      "2023-12-09 21:41:49,894 INFO     Training average loss at step 71000: 0.005501\n",
      "2023-12-09 21:42:04,074 INFO     Training average positive_sample_loss at step 71100: 0.005189\n",
      "2023-12-09 21:42:04,074 INFO     Training average negative_sample_loss at step 71100: 0.006188\n",
      "2023-12-09 21:42:04,074 INFO     Training average loss at step 71100: 0.005688\n",
      "2023-12-09 21:42:18,096 INFO     Training average positive_sample_loss at step 71200: 0.005128\n",
      "2023-12-09 21:42:18,096 INFO     Training average negative_sample_loss at step 71200: 0.005950\n",
      "2023-12-09 21:42:18,096 INFO     Training average loss at step 71200: 0.005539\n",
      "2023-12-09 21:42:32,020 INFO     Training average positive_sample_loss at step 71300: 0.005266\n",
      "2023-12-09 21:42:32,020 INFO     Training average negative_sample_loss at step 71300: 0.005922\n",
      "2023-12-09 21:42:32,020 INFO     Training average loss at step 71300: 0.005594\n",
      "2023-12-09 21:42:46,362 INFO     Training average positive_sample_loss at step 71400: 0.005313\n",
      "2023-12-09 21:42:46,362 INFO     Training average negative_sample_loss at step 71400: 0.006153\n",
      "2023-12-09 21:42:46,362 INFO     Training average loss at step 71400: 0.005733\n",
      "2023-12-09 21:43:03,276 INFO     Training average positive_sample_loss at step 71500: 0.005189\n",
      "2023-12-09 21:43:03,277 INFO     Training average negative_sample_loss at step 71500: 0.006530\n",
      "2023-12-09 21:43:03,277 INFO     Training average loss at step 71500: 0.005859\n",
      "2023-12-09 21:43:17,346 INFO     Training average positive_sample_loss at step 71600: 0.005111\n",
      "2023-12-09 21:43:17,346 INFO     Training average negative_sample_loss at step 71600: 0.006014\n",
      "2023-12-09 21:43:17,347 INFO     Training average loss at step 71600: 0.005563\n",
      "2023-12-09 21:43:30,738 INFO     Training average positive_sample_loss at step 71700: 0.005215\n",
      "2023-12-09 21:43:30,739 INFO     Training average negative_sample_loss at step 71700: 0.005948\n",
      "2023-12-09 21:43:30,739 INFO     Training average loss at step 71700: 0.005582\n",
      "2023-12-09 21:43:44,376 INFO     Training average positive_sample_loss at step 71800: 0.005286\n",
      "2023-12-09 21:43:44,376 INFO     Training average negative_sample_loss at step 71800: 0.006052\n",
      "2023-12-09 21:43:44,376 INFO     Training average loss at step 71800: 0.005669\n",
      "2023-12-09 21:43:58,766 INFO     Training average positive_sample_loss at step 71900: 0.005195\n",
      "2023-12-09 21:43:58,767 INFO     Training average negative_sample_loss at step 71900: 0.005734\n",
      "2023-12-09 21:43:58,767 INFO     Training average loss at step 71900: 0.005464\n",
      "2023-12-09 21:44:13,306 INFO     Training average positive_sample_loss at step 72000: 0.005261\n",
      "2023-12-09 21:44:13,306 INFO     Training average negative_sample_loss at step 72000: 0.005762\n",
      "2023-12-09 21:44:13,307 INFO     Training average loss at step 72000: 0.005511\n",
      "2023-12-09 21:44:32,654 INFO     Training average positive_sample_loss at step 72100: 0.005116\n",
      "2023-12-09 21:44:32,654 INFO     Training average negative_sample_loss at step 72100: 0.006235\n",
      "2023-12-09 21:44:32,654 INFO     Training average loss at step 72100: 0.005676\n",
      "2023-12-09 21:44:48,363 INFO     Training average positive_sample_loss at step 72200: 0.005160\n",
      "2023-12-09 21:44:48,363 INFO     Training average negative_sample_loss at step 72200: 0.006293\n",
      "2023-12-09 21:44:48,363 INFO     Training average loss at step 72200: 0.005726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:45:01,647 INFO     Training average positive_sample_loss at step 72300: 0.005182\n",
      "2023-12-09 21:45:01,647 INFO     Training average negative_sample_loss at step 72300: 0.006484\n",
      "2023-12-09 21:45:01,647 INFO     Training average loss at step 72300: 0.005833\n",
      "2023-12-09 21:45:15,330 INFO     Training average positive_sample_loss at step 72400: 0.005241\n",
      "2023-12-09 21:45:15,331 INFO     Training average negative_sample_loss at step 72400: 0.005615\n",
      "2023-12-09 21:45:15,331 INFO     Training average loss at step 72400: 0.005428\n",
      "2023-12-09 21:45:28,842 INFO     Training average positive_sample_loss at step 72500: 0.005281\n",
      "2023-12-09 21:45:28,843 INFO     Training average negative_sample_loss at step 72500: 0.006086\n",
      "2023-12-09 21:45:28,843 INFO     Training average loss at step 72500: 0.005684\n",
      "2023-12-09 21:45:45,513 INFO     Training average positive_sample_loss at step 72600: 0.005228\n",
      "2023-12-09 21:45:45,514 INFO     Training average negative_sample_loss at step 72600: 0.005817\n",
      "2023-12-09 21:45:45,514 INFO     Training average loss at step 72600: 0.005522\n",
      "2023-12-09 21:45:59,589 INFO     Training average positive_sample_loss at step 72700: 0.005116\n",
      "2023-12-09 21:45:59,590 INFO     Training average negative_sample_loss at step 72700: 0.006005\n",
      "2023-12-09 21:45:59,590 INFO     Training average loss at step 72700: 0.005561\n",
      "2023-12-09 21:46:13,663 INFO     Training average positive_sample_loss at step 72800: 0.005210\n",
      "2023-12-09 21:46:13,663 INFO     Training average negative_sample_loss at step 72800: 0.006078\n",
      "2023-12-09 21:46:13,663 INFO     Training average loss at step 72800: 0.005644\n",
      "2023-12-09 21:46:27,953 INFO     Training average positive_sample_loss at step 72900: 0.005184\n",
      "2023-12-09 21:46:27,954 INFO     Training average negative_sample_loss at step 72900: 0.005869\n",
      "2023-12-09 21:46:27,954 INFO     Training average loss at step 72900: 0.005526\n",
      "2023-12-09 21:46:41,985 INFO     Training average positive_sample_loss at step 73000: 0.005245\n",
      "2023-12-09 21:46:41,985 INFO     Training average negative_sample_loss at step 73000: 0.005782\n",
      "2023-12-09 21:46:41,985 INFO     Training average loss at step 73000: 0.005513\n",
      "2023-12-09 21:46:56,265 INFO     Training average positive_sample_loss at step 73100: 0.005286\n",
      "2023-12-09 21:46:56,265 INFO     Training average negative_sample_loss at step 73100: 0.005597\n",
      "2023-12-09 21:46:56,265 INFO     Training average loss at step 73100: 0.005442\n",
      "2023-12-09 21:47:11,862 INFO     Training average positive_sample_loss at step 73200: 0.005130\n",
      "2023-12-09 21:47:11,862 INFO     Training average negative_sample_loss at step 73200: 0.005876\n",
      "2023-12-09 21:47:11,862 INFO     Training average loss at step 73200: 0.005503\n",
      "2023-12-09 21:47:25,799 INFO     Training average positive_sample_loss at step 73300: 0.005179\n",
      "2023-12-09 21:47:25,799 INFO     Training average negative_sample_loss at step 73300: 0.005812\n",
      "2023-12-09 21:47:25,799 INFO     Training average loss at step 73300: 0.005496\n",
      "2023-12-09 21:47:39,316 INFO     Training average positive_sample_loss at step 73400: 0.005186\n",
      "2023-12-09 21:47:39,317 INFO     Training average negative_sample_loss at step 73400: 0.005806\n",
      "2023-12-09 21:47:39,317 INFO     Training average loss at step 73400: 0.005496\n",
      "2023-12-09 21:47:53,130 INFO     Training average positive_sample_loss at step 73500: 0.005227\n",
      "2023-12-09 21:47:53,130 INFO     Training average negative_sample_loss at step 73500: 0.006746\n",
      "2023-12-09 21:47:53,130 INFO     Training average loss at step 73500: 0.005987\n",
      "2023-12-09 21:48:06,035 INFO     Training average positive_sample_loss at step 73600: 0.005253\n",
      "2023-12-09 21:48:06,036 INFO     Training average negative_sample_loss at step 73600: 0.006127\n",
      "2023-12-09 21:48:06,036 INFO     Training average loss at step 73600: 0.005690\n",
      "2023-12-09 21:48:21,380 INFO     Training average positive_sample_loss at step 73700: 0.005231\n",
      "2023-12-09 21:48:21,380 INFO     Training average negative_sample_loss at step 73700: 0.005763\n",
      "2023-12-09 21:48:21,380 INFO     Training average loss at step 73700: 0.005497\n",
      "2023-12-09 21:48:35,503 INFO     Training average positive_sample_loss at step 73800: 0.005115\n",
      "2023-12-09 21:48:35,504 INFO     Training average negative_sample_loss at step 73800: 0.006316\n",
      "2023-12-09 21:48:35,504 INFO     Training average loss at step 73800: 0.005715\n",
      "2023-12-09 21:48:49,543 INFO     Training average positive_sample_loss at step 73900: 0.005199\n",
      "2023-12-09 21:48:49,544 INFO     Training average negative_sample_loss at step 73900: 0.005899\n",
      "2023-12-09 21:48:49,544 INFO     Training average loss at step 73900: 0.005549\n",
      "2023-12-09 21:49:02,414 INFO     Training average positive_sample_loss at step 74000: 0.005156\n",
      "2023-12-09 21:49:02,414 INFO     Training average negative_sample_loss at step 74000: 0.005966\n",
      "2023-12-09 21:49:02,414 INFO     Training average loss at step 74000: 0.005561\n",
      "2023-12-09 21:49:16,141 INFO     Training average positive_sample_loss at step 74100: 0.005278\n",
      "2023-12-09 21:49:16,141 INFO     Training average negative_sample_loss at step 74100: 0.005854\n",
      "2023-12-09 21:49:16,141 INFO     Training average loss at step 74100: 0.005566\n",
      "2023-12-09 21:49:29,995 INFO     Training average positive_sample_loss at step 74200: 0.005289\n",
      "2023-12-09 21:49:29,995 INFO     Training average negative_sample_loss at step 74200: 0.005779\n",
      "2023-12-09 21:49:29,995 INFO     Training average loss at step 74200: 0.005534\n",
      "2023-12-09 21:49:46,080 INFO     Training average positive_sample_loss at step 74300: 0.005171\n",
      "2023-12-09 21:49:46,080 INFO     Training average negative_sample_loss at step 74300: 0.005770\n",
      "2023-12-09 21:49:46,080 INFO     Training average loss at step 74300: 0.005471\n",
      "2023-12-09 21:49:59,760 INFO     Training average positive_sample_loss at step 74400: 0.005186\n",
      "2023-12-09 21:49:59,761 INFO     Training average negative_sample_loss at step 74400: 0.006449\n",
      "2023-12-09 21:49:59,761 INFO     Training average loss at step 74400: 0.005817\n",
      "2023-12-09 21:50:14,100 INFO     Training average positive_sample_loss at step 74500: 0.005194\n",
      "2023-12-09 21:50:14,100 INFO     Training average negative_sample_loss at step 74500: 0.005823\n",
      "2023-12-09 21:50:14,100 INFO     Training average loss at step 74500: 0.005509\n",
      "2023-12-09 21:50:28,005 INFO     Training average positive_sample_loss at step 74600: 0.005247\n",
      "2023-12-09 21:50:28,005 INFO     Training average negative_sample_loss at step 74600: 0.006359\n",
      "2023-12-09 21:50:28,005 INFO     Training average loss at step 74600: 0.005803\n",
      "2023-12-09 21:50:41,295 INFO     Training average positive_sample_loss at step 74700: 0.005264\n",
      "2023-12-09 21:50:41,295 INFO     Training average negative_sample_loss at step 74700: 0.005876\n",
      "2023-12-09 21:50:41,295 INFO     Training average loss at step 74700: 0.005570\n",
      "2023-12-09 21:50:57,352 INFO     Training average positive_sample_loss at step 74800: 0.005149\n",
      "2023-12-09 21:50:57,352 INFO     Training average negative_sample_loss at step 74800: 0.005739\n",
      "2023-12-09 21:50:57,352 INFO     Training average loss at step 74800: 0.005444\n",
      "2023-12-09 21:51:11,045 INFO     Training average positive_sample_loss at step 74900: 0.005101\n",
      "2023-12-09 21:51:11,045 INFO     Training average negative_sample_loss at step 74900: 0.005919\n",
      "2023-12-09 21:51:11,045 INFO     Training average loss at step 74900: 0.005510\n",
      "2023-12-09 21:51:24,570 INFO     Training average positive_sample_loss at step 75000: 0.005185\n",
      "2023-12-09 21:51:24,571 INFO     Training average negative_sample_loss at step 75000: 0.005371\n",
      "2023-12-09 21:51:24,571 INFO     Training average loss at step 75000: 0.005278\n",
      "2023-12-09 21:51:38,122 INFO     Training average positive_sample_loss at step 75100: 0.005258\n",
      "2023-12-09 21:51:38,122 INFO     Training average negative_sample_loss at step 75100: 0.006538\n",
      "2023-12-09 21:51:38,122 INFO     Training average loss at step 75100: 0.005898\n",
      "2023-12-09 21:51:51,804 INFO     Training average positive_sample_loss at step 75200: 0.005220\n",
      "2023-12-09 21:51:51,805 INFO     Training average negative_sample_loss at step 75200: 0.006089\n",
      "2023-12-09 21:51:51,805 INFO     Training average loss at step 75200: 0.005655\n",
      "2023-12-09 21:52:04,624 INFO     Training average positive_sample_loss at step 75300: 0.005154\n",
      "2023-12-09 21:52:04,624 INFO     Training average negative_sample_loss at step 75300: 0.005817\n",
      "2023-12-09 21:52:04,624 INFO     Training average loss at step 75300: 0.005485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:52:20,967 INFO     Training average positive_sample_loss at step 75400: 0.005232\n",
      "2023-12-09 21:52:20,967 INFO     Training average negative_sample_loss at step 75400: 0.005629\n",
      "2023-12-09 21:52:20,967 INFO     Training average loss at step 75400: 0.005431\n",
      "2023-12-09 21:52:33,954 INFO     Training average positive_sample_loss at step 75500: 0.005154\n",
      "2023-12-09 21:52:33,954 INFO     Training average negative_sample_loss at step 75500: 0.005871\n",
      "2023-12-09 21:52:33,954 INFO     Training average loss at step 75500: 0.005512\n",
      "2023-12-09 21:52:47,589 INFO     Training average positive_sample_loss at step 75600: 0.005183\n",
      "2023-12-09 21:52:47,590 INFO     Training average negative_sample_loss at step 75600: 0.006058\n",
      "2023-12-09 21:52:47,590 INFO     Training average loss at step 75600: 0.005620\n",
      "2023-12-09 21:53:02,185 INFO     Training average positive_sample_loss at step 75700: 0.005205\n",
      "2023-12-09 21:53:02,186 INFO     Training average negative_sample_loss at step 75700: 0.006270\n",
      "2023-12-09 21:53:02,186 INFO     Training average loss at step 75700: 0.005738\n",
      "2023-12-09 21:53:15,457 INFO     Training average positive_sample_loss at step 75800: 0.005241\n",
      "2023-12-09 21:53:15,457 INFO     Training average negative_sample_loss at step 75800: 0.005789\n",
      "2023-12-09 21:53:15,457 INFO     Training average loss at step 75800: 0.005515\n",
      "2023-12-09 21:53:31,932 INFO     Training average positive_sample_loss at step 75900: 0.005262\n",
      "2023-12-09 21:53:31,932 INFO     Training average negative_sample_loss at step 75900: 0.006776\n",
      "2023-12-09 21:53:31,933 INFO     Training average loss at step 75900: 0.006019\n",
      "2023-12-09 21:53:46,273 INFO     Training average positive_sample_loss at step 76000: 0.005161\n",
      "2023-12-09 21:53:46,274 INFO     Training average negative_sample_loss at step 76000: 0.005805\n",
      "2023-12-09 21:53:46,274 INFO     Training average loss at step 76000: 0.005483\n",
      "2023-12-09 21:53:59,447 INFO     Training average positive_sample_loss at step 76100: 0.005166\n",
      "2023-12-09 21:53:59,447 INFO     Training average negative_sample_loss at step 76100: 0.005821\n",
      "2023-12-09 21:53:59,447 INFO     Training average loss at step 76100: 0.005493\n",
      "2023-12-09 21:54:13,491 INFO     Training average positive_sample_loss at step 76200: 0.005255\n",
      "2023-12-09 21:54:13,491 INFO     Training average negative_sample_loss at step 76200: 0.006189\n",
      "2023-12-09 21:54:13,492 INFO     Training average loss at step 76200: 0.005722\n",
      "2023-12-09 21:54:27,441 INFO     Training average positive_sample_loss at step 76300: 0.005187\n",
      "2023-12-09 21:54:27,442 INFO     Training average negative_sample_loss at step 76300: 0.006250\n",
      "2023-12-09 21:54:27,442 INFO     Training average loss at step 76300: 0.005718\n",
      "2023-12-09 21:54:40,928 INFO     Training average positive_sample_loss at step 76400: 0.005209\n",
      "2023-12-09 21:54:40,928 INFO     Training average negative_sample_loss at step 76400: 0.006363\n",
      "2023-12-09 21:54:40,928 INFO     Training average loss at step 76400: 0.005786\n",
      "2023-12-09 21:54:56,913 INFO     Training average positive_sample_loss at step 76500: 0.005216\n",
      "2023-12-09 21:54:56,913 INFO     Training average negative_sample_loss at step 76500: 0.005951\n",
      "2023-12-09 21:54:56,914 INFO     Training average loss at step 76500: 0.005584\n",
      "2023-12-09 21:55:10,143 INFO     Training average positive_sample_loss at step 76600: 0.005132\n",
      "2023-12-09 21:55:10,143 INFO     Training average negative_sample_loss at step 76600: 0.005889\n",
      "2023-12-09 21:55:10,143 INFO     Training average loss at step 76600: 0.005511\n",
      "2023-12-09 21:55:24,271 INFO     Training average positive_sample_loss at step 76700: 0.005153\n",
      "2023-12-09 21:55:24,271 INFO     Training average negative_sample_loss at step 76700: 0.006068\n",
      "2023-12-09 21:55:24,271 INFO     Training average loss at step 76700: 0.005610\n",
      "2023-12-09 21:55:37,866 INFO     Training average positive_sample_loss at step 76800: 0.005260\n",
      "2023-12-09 21:55:37,866 INFO     Training average negative_sample_loss at step 76800: 0.006436\n",
      "2023-12-09 21:55:37,866 INFO     Training average loss at step 76800: 0.005848\n",
      "2023-12-09 21:55:51,870 INFO     Training average positive_sample_loss at step 76900: 0.005253\n",
      "2023-12-09 21:55:51,870 INFO     Training average negative_sample_loss at step 76900: 0.006246\n",
      "2023-12-09 21:55:51,871 INFO     Training average loss at step 76900: 0.005750\n",
      "2023-12-09 21:56:05,265 INFO     Training average positive_sample_loss at step 77000: 0.005266\n",
      "2023-12-09 21:56:05,265 INFO     Training average negative_sample_loss at step 77000: 0.005950\n",
      "2023-12-09 21:56:05,265 INFO     Training average loss at step 77000: 0.005608\n",
      "2023-12-09 21:56:22,006 INFO     Training average positive_sample_loss at step 77100: 0.005136\n",
      "2023-12-09 21:56:22,007 INFO     Training average negative_sample_loss at step 77100: 0.005760\n",
      "2023-12-09 21:56:22,007 INFO     Training average loss at step 77100: 0.005448\n",
      "2023-12-09 21:56:35,714 INFO     Training average positive_sample_loss at step 77200: 0.005197\n",
      "2023-12-09 21:56:35,715 INFO     Training average negative_sample_loss at step 77200: 0.005893\n",
      "2023-12-09 21:56:35,715 INFO     Training average loss at step 77200: 0.005545\n",
      "2023-12-09 21:56:48,921 INFO     Training average positive_sample_loss at step 77300: 0.005186\n",
      "2023-12-09 21:56:48,921 INFO     Training average negative_sample_loss at step 77300: 0.005725\n",
      "2023-12-09 21:56:48,921 INFO     Training average loss at step 77300: 0.005455\n",
      "2023-12-09 21:57:02,774 INFO     Training average positive_sample_loss at step 77400: 0.005151\n",
      "2023-12-09 21:57:02,775 INFO     Training average negative_sample_loss at step 77400: 0.005969\n",
      "2023-12-09 21:57:02,775 INFO     Training average loss at step 77400: 0.005560\n",
      "2023-12-09 21:57:16,612 INFO     Training average positive_sample_loss at step 77500: 0.005297\n",
      "2023-12-09 21:57:16,613 INFO     Training average negative_sample_loss at step 77500: 0.005866\n",
      "2023-12-09 21:57:16,613 INFO     Training average loss at step 77500: 0.005581\n",
      "2023-12-09 21:57:31,321 INFO     Training average positive_sample_loss at step 77600: 0.005195\n",
      "2023-12-09 21:57:31,321 INFO     Training average negative_sample_loss at step 77600: 0.005825\n",
      "2023-12-09 21:57:31,321 INFO     Training average loss at step 77600: 0.005510\n",
      "2023-12-09 21:57:44,942 INFO     Training average positive_sample_loss at step 77700: 0.005147\n",
      "2023-12-09 21:57:44,943 INFO     Training average negative_sample_loss at step 77700: 0.006193\n",
      "2023-12-09 21:57:44,943 INFO     Training average loss at step 77700: 0.005670\n",
      "2023-12-09 21:57:58,473 INFO     Training average positive_sample_loss at step 77800: 0.005159\n",
      "2023-12-09 21:57:58,473 INFO     Training average negative_sample_loss at step 77800: 0.005608\n",
      "2023-12-09 21:57:58,473 INFO     Training average loss at step 77800: 0.005384\n",
      "2023-12-09 21:58:11,745 INFO     Training average positive_sample_loss at step 77900: 0.005210\n",
      "2023-12-09 21:58:11,745 INFO     Training average negative_sample_loss at step 77900: 0.006088\n",
      "2023-12-09 21:58:11,745 INFO     Training average loss at step 77900: 0.005649\n",
      "2023-12-09 21:58:25,599 INFO     Training average positive_sample_loss at step 78000: 0.005282\n",
      "2023-12-09 21:58:25,599 INFO     Training average negative_sample_loss at step 78000: 0.006008\n",
      "2023-12-09 21:58:25,599 INFO     Training average loss at step 78000: 0.005645\n",
      "2023-12-09 21:58:39,175 INFO     Training average positive_sample_loss at step 78100: 0.005216\n",
      "2023-12-09 21:58:39,176 INFO     Training average negative_sample_loss at step 78100: 0.005950\n",
      "2023-12-09 21:58:39,176 INFO     Training average loss at step 78100: 0.005583\n",
      "2023-12-09 21:58:56,932 INFO     Training average positive_sample_loss at step 78200: 0.005149\n",
      "2023-12-09 21:58:56,933 INFO     Training average negative_sample_loss at step 78200: 0.005847\n",
      "2023-12-09 21:58:56,933 INFO     Training average loss at step 78200: 0.005498\n",
      "2023-12-09 21:59:12,752 INFO     Training average positive_sample_loss at step 78300: 0.005169\n",
      "2023-12-09 21:59:12,752 INFO     Training average negative_sample_loss at step 78300: 0.006224\n",
      "2023-12-09 21:59:12,752 INFO     Training average loss at step 78300: 0.005697\n",
      "2023-12-09 21:59:26,530 INFO     Training average positive_sample_loss at step 78400: 0.005130\n",
      "2023-12-09 21:59:26,531 INFO     Training average negative_sample_loss at step 78400: 0.005880\n",
      "2023-12-09 21:59:26,531 INFO     Training average loss at step 78400: 0.005505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 21:59:40,208 INFO     Training average positive_sample_loss at step 78500: 0.005258\n",
      "2023-12-09 21:59:40,209 INFO     Training average negative_sample_loss at step 78500: 0.006278\n",
      "2023-12-09 21:59:40,209 INFO     Training average loss at step 78500: 0.005768\n",
      "2023-12-09 21:59:53,863 INFO     Training average positive_sample_loss at step 78600: 0.005214\n",
      "2023-12-09 21:59:53,863 INFO     Training average negative_sample_loss at step 78600: 0.006187\n",
      "2023-12-09 21:59:53,863 INFO     Training average loss at step 78600: 0.005701\n",
      "2023-12-09 22:00:10,841 INFO     Training average positive_sample_loss at step 78700: 0.005217\n",
      "2023-12-09 22:00:10,841 INFO     Training average negative_sample_loss at step 78700: 0.006039\n",
      "2023-12-09 22:00:10,841 INFO     Training average loss at step 78700: 0.005628\n",
      "2023-12-09 22:00:26,118 INFO     Training average positive_sample_loss at step 78800: 0.005094\n",
      "2023-12-09 22:00:26,119 INFO     Training average negative_sample_loss at step 78800: 0.005807\n",
      "2023-12-09 22:00:26,119 INFO     Training average loss at step 78800: 0.005450\n",
      "2023-12-09 22:00:40,674 INFO     Training average positive_sample_loss at step 78900: 0.005158\n",
      "2023-12-09 22:00:40,674 INFO     Training average negative_sample_loss at step 78900: 0.006586\n",
      "2023-12-09 22:00:40,674 INFO     Training average loss at step 78900: 0.005872\n",
      "2023-12-09 22:00:53,855 INFO     Training average positive_sample_loss at step 79000: 0.005218\n",
      "2023-12-09 22:00:53,855 INFO     Training average negative_sample_loss at step 79000: 0.005334\n",
      "2023-12-09 22:00:53,855 INFO     Training average loss at step 79000: 0.005276\n",
      "2023-12-09 22:01:08,095 INFO     Training average positive_sample_loss at step 79100: 0.005239\n",
      "2023-12-09 22:01:08,096 INFO     Training average negative_sample_loss at step 79100: 0.005730\n",
      "2023-12-09 22:01:08,096 INFO     Training average loss at step 79100: 0.005485\n",
      "2023-12-09 22:01:21,746 INFO     Training average positive_sample_loss at step 79200: 0.005289\n",
      "2023-12-09 22:01:21,747 INFO     Training average negative_sample_loss at step 79200: 0.005969\n",
      "2023-12-09 22:01:21,747 INFO     Training average loss at step 79200: 0.005629\n",
      "2023-12-09 22:01:38,354 INFO     Training average positive_sample_loss at step 79300: 0.005162\n",
      "2023-12-09 22:01:38,354 INFO     Training average negative_sample_loss at step 79300: 0.006903\n",
      "2023-12-09 22:01:38,354 INFO     Training average loss at step 79300: 0.006032\n",
      "2023-12-09 22:01:52,071 INFO     Training average positive_sample_loss at step 79400: 0.005127\n",
      "2023-12-09 22:01:52,071 INFO     Training average negative_sample_loss at step 79400: 0.006392\n",
      "2023-12-09 22:01:52,072 INFO     Training average loss at step 79400: 0.005760\n",
      "2023-12-09 22:02:05,977 INFO     Training average positive_sample_loss at step 79500: 0.005235\n",
      "2023-12-09 22:02:05,977 INFO     Training average negative_sample_loss at step 79500: 0.006190\n",
      "2023-12-09 22:02:05,978 INFO     Training average loss at step 79500: 0.005712\n",
      "2023-12-09 22:02:20,343 INFO     Training average positive_sample_loss at step 79600: 0.005237\n",
      "2023-12-09 22:02:20,343 INFO     Training average negative_sample_loss at step 79600: 0.006286\n",
      "2023-12-09 22:02:20,343 INFO     Training average loss at step 79600: 0.005761\n",
      "2023-12-09 22:02:34,241 INFO     Training average positive_sample_loss at step 79700: 0.005243\n",
      "2023-12-09 22:02:34,241 INFO     Training average negative_sample_loss at step 79700: 0.006146\n",
      "2023-12-09 22:02:34,241 INFO     Training average loss at step 79700: 0.005695\n",
      "2023-12-09 22:02:50,411 INFO     Training average positive_sample_loss at step 79800: 0.005181\n",
      "2023-12-09 22:02:50,411 INFO     Training average negative_sample_loss at step 79800: 0.006091\n",
      "2023-12-09 22:02:50,411 INFO     Training average loss at step 79800: 0.005636\n",
      "2023-12-09 22:03:04,722 INFO     Training average positive_sample_loss at step 79900: 0.005135\n",
      "2023-12-09 22:03:04,722 INFO     Training average negative_sample_loss at step 79900: 0.006027\n",
      "2023-12-09 22:03:04,722 INFO     Training average loss at step 79900: 0.005581\n",
      "2023-12-09 22:03:35,157 INFO     Evaluating on Valid Dataset...\n",
      "2023-12-09 22:03:35,917 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 22:04:13,064 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 22:04:21,891 INFO     Valid MRR at step 79999: 0.948932\n",
      "2023-12-09 22:04:21,892 INFO     Valid MR at step 79999: 291.256000\n",
      "2023-12-09 22:04:21,892 INFO     Valid HITS@1 at step 79999: 0.944200\n",
      "2023-12-09 22:04:21,892 INFO     Valid HITS@3 at step 79999: 0.951100\n",
      "2023-12-09 22:04:21,892 INFO     Valid HITS@10 at step 79999: 0.957800\n",
      "2023-12-09 22:04:21,892 INFO     Evaluating on Test Dataset...\n",
      "2023-12-09 22:04:22,385 INFO     Evaluating the model... (0/1250)\n",
      "2023-12-09 22:04:54,271 INFO     Evaluating the model... (1000/1250)\n",
      "2023-12-09 22:05:01,307 INFO     Test MRR at step 79999: 0.949245\n",
      "2023-12-09 22:05:01,307 INFO     Test MR at step 79999: 246.261600\n",
      "2023-12-09 22:05:01,307 INFO     Test HITS@1 at step 79999: 0.943700\n",
      "2023-12-09 22:05:01,307 INFO     Test HITS@3 at step 79999: 0.951900\n",
      "2023-12-09 22:05:01,307 INFO     Test HITS@10 at step 79999: 0.959700\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh train RotatE wn18 0 0 512 1024 500 12.0 0.5 0.0001 80000 8 -de"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
